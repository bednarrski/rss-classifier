{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from api import inoreader_api, inoreader_scraping\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "percentile = 33.3\n",
    "workers_split = 0.8\n",
    "manager_split = 0.8\n",
    "\n",
    "\n",
    "def rewrite(x):\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape feeds starting from a concrete moment and store them in a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv\n",
      "200 OK\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=_Nk9_0aC_XZN\n",
      "200 OK\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "start_time = 1517463300 #1508112001\n",
    "feed = 'user/-/label/arXiv'\n",
    "file_name = 'articles_raw.json'\n",
    "\n",
    "number_scraped = inoreader_scraping.scrape(feed, start_time, file_name)\n",
    "print(number_scraped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the feeds from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open(file_name, 'r')\n",
    "json_string = f.read()\n",
    "f.close\n",
    "\n",
    "json_object = json.loads(json_string)\n",
    "all_articles = json_object['all_articles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_abstract_string(abs_dict):\n",
    "    abs_string = abs_dict['content']\n",
    "    abs_string = re.search('<p>(.*)</p>', abs_string, flags=re.DOTALL)\n",
    "    return abs_string.group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_canonical_string(canonical_list):\n",
    "    url_dict = canonical_list[0]\n",
    "    url = url_dict['href']\n",
    "    return url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create preprocessed and cleaned DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piotr.bednarski/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/piotr.bednarski/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/piotr.bednarski/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/piotr.bednarski/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "all_articles_pd = pd.DataFrame(all_articles)\n",
    "all_articles_pd = all_articles_pd[['canonical', 'author', 'categories', 'published', 'title', 'summary']]\n",
    "\n",
    "for i in range(len(all_articles_pd)):\n",
    "    all_articles_pd['summary'][i] = get_abstract_string(all_articles_pd['summary'][i])\n",
    "    all_articles_pd['canonical'][i] = get_canonical_string(all_articles_pd['canonical'][i])\n",
    "    \n",
    "all_articles_pd['read'] = False\n",
    "all_articles_pd['liked'] = False\n",
    "\n",
    "for i in range(len(all_articles_pd)):\n",
    "    if 'user/1005689817/state/com.google/read' in all_articles_pd['categories'][i]:\n",
    "        all_articles_pd['read'][i] = True\n",
    "    if 'user/1005689817/state/com.google/like' in all_articles_pd['categories'][i]:\n",
    "        all_articles_pd['liked'][i] = True\n",
    "\n",
    "del all_articles_pd['categories']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#all_articles_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "2842\n"
     ]
    }
   ],
   "source": [
    "tagged_articles_pd = all_articles_pd[all_articles_pd['read'] == True]\n",
    "\n",
    "with open('old_articles_good_and_bad.pickle', 'rb') as f:\n",
    "    # Pickle the 'data' dictionary using the highest protocol available.\n",
    "    old_tagged_articles_pd = pickle.load(f)\n",
    "    \n",
    "print(len(tagged_articles_pd))\n",
    "print(len(old_tagged_articles_pd))\n",
    "    \n",
    "tagged_articles_pd = pd.concat([tagged_articles_pd, old_tagged_articles_pd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tagged_articles_unique_pd = tagged_articles_pd.sort_values(by=['canonical', 'liked'], ascending=False).reset_index(drop=True)\n",
    "to_drop = tagged_articles_unique_pd.duplicated(subset = ['canonical'], keep='first')\n",
    "to_drop = list(to_drop[to_drop == False].index.values)\n",
    "\n",
    "tagged_articles_unique_pd = tagged_articles_unique_pd[tagged_articles_unique_pd.index.isin(to_drop)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2882\n",
      "2842\n"
     ]
    }
   ],
   "source": [
    "print(len(tagged_articles_pd))\n",
    "print(len(tagged_articles_unique_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Do you want to save new dataset?\n",
    "if True:\n",
    "    with open('old_articles_good_and_bad.pickle', 'wb') as f:\n",
    "        # Pickle the 'data' dictionary using the highest protocol available.\n",
    "        pickle.dump(tagged_articles_unique_pd, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    del tagged_articles_unique_pd\n",
    "\n",
    "    with open('old_articles_good_and_bad.pickle', 'rb') as f:\n",
    "        # Pickle the 'data' dictionary using the highest protocol available.\n",
    "        tagged_articles_unique_pd = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_ = list(tagged_articles_unique_pd['author']+' '+tagged_articles_unique_pd['title']+' '+tagged_articles_unique_pd['summary'])\n",
    "y_ = list(tagged_articles_unique_pd['liked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index_shuffled = [i for i in range(len(X_))]\n",
    "random.shuffle(index_shuffled)\n",
    "X = []\n",
    "y = []\n",
    "for i in index_shuffled:\n",
    "    X.append(X_[i])\n",
    "    y.append(y_[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('stopwords/english') as f:\n",
    "    stopwords = [line.strip() for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1714\n",
      "1271\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def text_to_word_sequence(text,\n",
    "                          filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "                          lower=True, split=\" \"):\n",
    "    if lower: text = text.lower()\n",
    "    if type(text) == str:\n",
    "        translate_table = {ord(c): ord(t) for c,t in zip(filters, split*len(filters)) }\n",
    "    else:\n",
    "        translate_table = maketrans(filters, split * len(filters))\n",
    "    text = text.translate(translate_table)\n",
    "    seq = text.split(split)\n",
    "    return [i for i in seq if i]\n",
    "\n",
    "print(len(X[4]))\n",
    "\n",
    "for i in range(len(X)):\n",
    "    seq = text_to_word_sequence(X[i])\n",
    "    clean_seq = [word for word in seq if word not in stopwords]\n",
    "    X[i] = ' '.join(clean_seq)\n",
    "    \n",
    "print(len(X[4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving or loading the data and LE and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2273\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "data_dict = {\n",
    "    'X' : X,\n",
    "    'y' : y\n",
    "}\n",
    "pickle.dump(data_dict,open(\"data.pickle\", \"wb\" ) )\n",
    "\n",
    "\n",
    "limit = int(0.8*len(X))\n",
    "print(limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2273\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "data_dict = pickle.load(open( \"data.pickle\", \"rb\" ) )\n",
    "X = data_dict['X']\n",
    "y = data_dict['y']\n",
    "limit = int(workers_split*len(X))\n",
    "print(limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_ = X\n",
    "y_ = y\n",
    "index_shuffled = [i for i in range(len(X_))]\n",
    "random.shuffle(index_shuffled)\n",
    "X = []\n",
    "y = []\n",
    "for i in index_shuffled:\n",
    "    X.append(X_[i])\n",
    "    y.append(y_[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF -> NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piotr.bednarski/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/piotr.bednarski/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8629173989455184, 0.9246920276012371)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "\n",
    "\n",
    "model_nb_tfidf = Pipeline([\n",
    "    (\"tfidf_vectorizer\", TfidfVectorizer()),\\\n",
    "    (\"nb\", BernoulliNB())\n",
    "])\n",
    "\n",
    "\n",
    "X_train = X[:limit]\n",
    "X_test = X[limit:]\n",
    "\n",
    "y_train = y[:limit]\n",
    "y_test = y[limit:]\n",
    "\n",
    "model_nb_tfidf.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = model_nb_tfidf.predict(X_test)\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "acc, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.671353251318102 0.6245364737927355 190 569\n",
      "33.391915641476274 % -  16\n",
      "\n",
      "\n",
      "Rejected 69.59% of wrong ones\n",
      "Accepted 51.90% of good ones\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piotr.bednarski/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+00, 9.70644603e-23],\n",
       "       [1.00000000e+00, 2.85458808e-28],\n",
       "       [1.00000000e+00, 8.60715938e-18],\n",
       "       [1.00000000e+00, 9.40542671e-22],\n",
       "       [1.00000000e+00, 1.87443829e-25]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted_proba = model_nb_tfidf.predict_proba(X_test)\n",
    "#y_predicted = (y_predicted_proba[:,1] > 0.15)\n",
    "y_predicted = (y_predicted_proba[:,1] > np.percentile(y_predicted_proba[:,1],100-percentile))\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)/len(y_predicted)*100.0,\"% - \", int(sum(y_predicted)/len(y_predicted)*50.0))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected %.2f%% of wrong ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == False)])*100.0/(len(y_test)-sum(y_test))))\n",
    "print(\"Accepted %.2f%% of good ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == True)])*100.0/sum(y_test)))\n",
    "\n",
    "y_predicted_proba[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CountVect -> NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piotr.bednarski/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8611599297012302, 0.9254013220018887)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "\n",
    "\n",
    "model_nb = Pipeline([\n",
    "    #('vect', CountVectorizer(ngram_range=(1,3),stop_words='english')),\\\n",
    "    (\"count_vectorizer\", CountVectorizer(analyzer=rewrite)),\\\n",
    "    (\"nb\", BernoulliNB())\n",
    "])\n",
    "\n",
    "X_train = X[:limit]\n",
    "X_test = X[limit:]\n",
    "\n",
    "y_train = y[:limit]\n",
    "y_test = y[limit:]\n",
    "\n",
    "model_nb.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = model_nb.predict(X_test)\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "acc, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6274165202108963 0.5745076206748814 189 569\n",
      "33.21616871704745 % -  16\n",
      "\n",
      "\n",
      "Rejected 67.14% of wrong ones\n",
      "Accepted 35.44% of good ones\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.90025749, 0.09974251],\n",
       "       [0.8491482 , 0.1508518 ],\n",
       "       [0.85701935, 0.14298065],\n",
       "       [0.88100145, 0.11899855],\n",
       "       [0.79902012, 0.20097988]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted_proba = model_nb.predict_proba(X_test)\n",
    "#y_predicted = (y_predicted_proba[:,1] > 0.1296)\n",
    "y_predicted = (y_predicted_proba[:,1] > np.percentile(y_predicted_proba[:,1],100-percentile))\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected %.2f%% of wrong ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == False)])*100.0/(len(y_test)-sum(y_test))))\n",
    "print(\"Accepted %.2f%% of good ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == True)])*100.0/sum(y_test)))\n",
    "\n",
    "y_predicted_proba[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF -> SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piotr.bednarski/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8734622144112478, 0.9105588145009768)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "\n",
    "model_svc_tfidf = Pipeline([\n",
    "    ('vect', CountVectorizer(ngram_range=(1,3), min_df=1, max_df=1.0,stop_words='english')),\n",
    "    #('vect', CountVectorizer(ngram_range=(3,6),analyzer='char_wb', min_df=10, max_df=0.95,stop_words='english')),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    (\"svc\", SVC(kernel='linear', probability=True, class_weight = 'balanced'))\n",
    "    #(\"svc\", SVC(kernel='linear', probability=True))\n",
    "])\n",
    "\n",
    "X_train = X[:limit]\n",
    "X_test = X[limit:]\n",
    "\n",
    "y_train = y[:limit]\n",
    "y_test = y[limit:]\n",
    "\n",
    "model_svc_tfidf.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = model_svc_tfidf.predict(X_test)\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "acc, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piotr.bednarski/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6994727592267135 0.6566616952864051 190 569\n",
      "33.391915641476274 % -  16\n",
      "\n",
      "\n",
      "Rejected 71.22% of wrong ones\n",
      "Accepted 62.03% of good ones\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.88636717, 0.11363283],\n",
       "       [0.76948017, 0.23051983],\n",
       "       [0.73359045, 0.26640955],\n",
       "       [0.88674613, 0.11325387],\n",
       "       [0.73129525, 0.26870475]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted_proba = model_svc_tfidf.predict_proba(X_test)\n",
    "#y_predicted = (y_predicted_proba[:,1] > 0.12)\n",
    "y_predicted = (y_predicted_proba[:,1] > np.percentile(y_predicted_proba[:,1],100-percentile))\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected %.2f%% of wrong ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == False)])*100.0/(len(y_test)-sum(y_test))))\n",
    "print(\"Accepted %.2f%% of good ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == True)])*100.0/sum(y_test)))\n",
    "\n",
    "y_predicted_proba[0:5]\n",
    "\n",
    "#(0.62077922077922076, 0.55417162908266104, 162, 385)\n",
    "#(42.077922077922075, '% - ', 21)\n",
    "#('Rejected good ones: ', 15, '/', 46)\n",
    "#('Accepted wrong ones:', 131, '/', 339)\n",
    "#('Rejected wrong ones: ', 208, '/', 339)\n",
    "#('Accepted good ones:', 31, '/', 46)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-17.664323374340952"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(X_test_df[(y_predicted == y_test) & (y_predicted == False)])*100.0/len(y_test)-sum(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piotr.bednarski/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7592267135325131, 0.7376903666583554)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "\n",
    "model_svc_tfidf = Pipeline([\n",
    "    #('vect', CountVectorizer(ngram_range=(1,3), min_df=1, max_df=1.0,stop_words='english')),\n",
    "    ('vect', CountVectorizer(ngram_range=(3,6),analyzer='char_wb', min_df=10, max_df=0.95,stop_words='english')),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    (\"svc\", SVC(kernel='linear', probability=True, class_weight = 'balanced'))\n",
    "    #(\"svc\", SVC(kernel='linear', probability=True))\n",
    "])\n",
    "\n",
    "X_train = X[:limit]\n",
    "X_test = X[limit:]\n",
    "\n",
    "y_train = y[:limit]\n",
    "y_test = y[limit:]\n",
    "\n",
    "model_svc_tfidf.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = model_svc_tfidf.predict(X_test)\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "acc, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piotr.bednarski/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.671353251318102 0.6245364737927355 190 569\n",
      "33.391915641476274 % -  16\n",
      "\n",
      "\n",
      "Rejected 69.59% of wrong ones\n",
      "Accepted 51.90% of good ones\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.92838879, 0.07161121],\n",
       "       [0.85805825, 0.14194175],\n",
       "       [0.77031503, 0.22968497],\n",
       "       [0.77720921, 0.22279079],\n",
       "       [0.81252914, 0.18747086]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted_proba = model_svc_tfidf.predict_proba(X_test)\n",
    "#y_predicted = (y_predicted_proba[:,1] > 0.12)\n",
    "y_predicted = (y_predicted_proba[:,1] > np.percentile(y_predicted_proba[:,1],100-percentile))\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected %.2f%% of wrong ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == False)])*100.0/(len(y_test)-sum(y_test))))\n",
    "print(\"Accepted %.2f%% of good ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == True)])*100.0/sum(y_test)))\n",
    "\n",
    "y_predicted_proba[0:5]\n",
    "\n",
    "#(0.62077922077922076, 0.55417162908266104, 162, 385)\n",
    "#(42.077922077922075, '% - ', 21)\n",
    "#('Rejected good ones: ', 15, '/', 46)\n",
    "#('Accepted wrong ones:', 131, '/', 339)\n",
    "#('Rejected wrong ones: ', 208, '/', 339)\n",
    "#('Accepted good ones:', 31, '/', 46)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count -> SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8699472759226714, 0.9124936207913477)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "\n",
    "model_svc = Pipeline([\n",
    "    #('vect', CountVectorizer()),\n",
    "    ('vect', CountVectorizer(ngram_range=(1,3), min_df=1, max_df=1.0,stop_words='english')),\n",
    "    #('vect', CountVectorizer(ngram_range=(3,6),analyzer='char_wb', min_df=10, max_df=0.95,stop_words='english')),\n",
    "    #('tfidf', TfidfTransformer()),\n",
    "    (\"svc\", SVC(kernel='linear', probability=True, class_weight = 'balanced'))\n",
    "    #(\"svc\", SVC(kernel='linear', probability=True))\n",
    "])\n",
    "\n",
    "X_train = X[:limit]\n",
    "X_test = X[limit:]\n",
    "\n",
    "y_train = y[:limit]\n",
    "y_test = y[limit:]\n",
    "\n",
    "model_svc.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = model_svc.predict(X_test)\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "acc, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6924428822495606 0.6486303899129877 190 569\n",
      "33.391915641476274 % -  16\n",
      "\n",
      "\n",
      "Rejected 70.82% of wrong ones\n",
      "Accepted 59.49% of good ones\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.91687543, 0.08312457],\n",
       "       [0.81945877, 0.18054123],\n",
       "       [0.76135586, 0.23864414],\n",
       "       [0.90760683, 0.09239317],\n",
       "       [0.77642323, 0.22357677]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted_proba = model_svc.predict_proba(X_test)\n",
    "#y_predicted = (y_predicted_proba[:,1] > 0.12)\n",
    "y_predicted = (y_predicted_proba[:,1] > np.percentile(y_predicted_proba[:,1],100-percentile))\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected %.2f%% of wrong ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == False)])*100.0/(len(y_test)-sum(y_test))))\n",
    "print(\"Accepted %.2f%% of good ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == True)])*100.0/sum(y_test)))\n",
    "\n",
    "y_predicted_proba[0:5]\n",
    "\n",
    "#(0.62077922077922076, 0.55417162908266104, 162, 385)\n",
    "#(42.077922077922075, '% - ', 21)\n",
    "#('Rejected good ones: ', 15, '/', 46)\n",
    "#('Accepted wrong ones:', 131, '/', 339)\n",
    "#('Rejected wrong ones: ', 208, '/', 339)\n",
    "#('Accepted good ones:', 31, '/', 46)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extree - pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'raz'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = ['raz']\n",
    "'_'.join(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing word vectors.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import models.embedding_matrix as embedding\n",
    "#reload(embedding)\n",
    "\n",
    "DATASETS_DIR = '../ml-research/datasets/'\n",
    "WIKI_DIR = DATASETS_DIR+'wiki.pl/'\n",
    "embeddings_file = WIKI_DIR+'wiki.pl.vec'\n",
    "\n",
    "print('Indexing word vectors.')\n",
    "\n",
    "word2vec_pretrained = {}\n",
    "f = open(embeddings_file, encoding='utf-8')\n",
    "\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = '_'.join(values[:-300])\n",
    "    coefs = np.asarray(values[-300:], dtype='float32')\n",
    "    word2vec_pretrained[word] = coefs\n",
    "f.close()\n",
    "\n",
    "# train word2vec on all the texts - both training and test set\n",
    "# we're not using test labels, just texts so this is fine\n",
    "model = Word2Vec(X, size=100, window=5, min_count=5, workers=2)\n",
    "w2v_custom = {w: vec for w, vec in zip(model.wv.index2word, model.wv.syn0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "class MeanEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        self.dim = len(next(iter(word2vec.items())))\n",
    "        \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        return self \n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "            np.mean([self.word2vec[w] for w in words if w in self.word2vec] \n",
    "                    or [np.zeros(self.dim)], axis=0)\n",
    "            for words in X\n",
    "        ])\n",
    "    \n",
    "# and a tf-idf version of the same\n",
    "\n",
    "class TfidfEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        self.word2weight = None\n",
    "        self.dim = len(next(iter(word2vec.items())))\n",
    "        \n",
    "    def max_idf_func():\n",
    "        return self.max_idf\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        #tfidf = TfidfVectorizer(analyzer=lambda x: x)\n",
    "        tfidf = TfidfVectorizer(analyzer=rewrite)\n",
    "        tfidf.fit(X)\n",
    "        # if a word was never seen - it must be at least as infrequent\n",
    "        # as any of the known words - so the default idf is the max of \n",
    "        # known idf's\n",
    "        self.max_idf = max(tfidf.idf_)\n",
    "        self.word2weight = defaultdict(\n",
    "            #lambda: max_idf, \n",
    "            self.max_idf_func, \n",
    "            [(w, tfidf.idf_[i]) for w, i in tfidf.vocabulary_.items()])\n",
    "    \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "                np.mean([self.word2vec[w] * self.word2weight[w]\n",
    "                         for w in words if w in self.word2vec] or\n",
    "                        [np.zeros(self.dim)], axis=0)\n",
    "                for words in X\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extra Trees classifier is almost universally great, let's stack it with our embeddings\n",
    "\n",
    "etree_w2v = Pipeline([(\"word2vec vectorizer\", MeanEmbeddingVectorizer(word2vec_pretrained)), \n",
    "                        (\"extra trees\", ExtraTreesClassifier(n_estimators=50))])\n",
    "etree_w2v_tfidf = Pipeline([(\"word2vec vectorizer\", TfidfEmbeddingVectorizer(word2vec_pretrained)), \n",
    "                        (\"svc\", ExtraTreesClassifier(n_estimators=50))])\n",
    "svc_w2v = Pipeline([(\"word2vec vectorizer\", MeanEmbeddingVectorizer(word2vec_pretrained)), \n",
    "                        (\"extra trees\", SVC(kernel=\"linear\", probability=True))])\n",
    "svc_w2v_tfidf = Pipeline([(\"word2vec vectorizer\", TfidfEmbeddingVectorizer(word2vec_pretrained)), \n",
    "                        (\"svc\", SVC(kernel=\"linear\", probability=True))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7012302284710018 0.660992592229878 175 569\n",
      "30.755711775043938 % -  15\n",
      "\n",
      "\n",
      "Rejected 72.86% of wrong ones\n",
      "Accepted 53.16% of good ones\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.92, 0.08],\n",
       "       [0.74, 0.26],\n",
       "       [0.9 , 0.1 ],\n",
       "       [0.88, 0.12],\n",
       "       [0.94, 0.06]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "X_train = X[:limit]\n",
    "X_test = X[limit:]\n",
    "\n",
    "y_train = y[:limit]\n",
    "y_test = y[limit:]\n",
    "\n",
    "etree_w2v.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = etree_w2v.predict(X_test)\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "\n",
    "y_predicted_proba = etree_w2v.predict_proba(X_test)\n",
    "#y_predicted = (y_predicted_proba[:,1] > 0.12)\n",
    "y_predicted = (y_predicted_proba[:,1] > np.percentile(y_predicted_proba[:,1],100-percentile))\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected %.2f%% of wrong ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == False)])*100.0/(len(y_test)-sum(y_test))))\n",
    "print(\"Accepted %.2f%% of good ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == True)])*100.0/sum(y_test)))\n",
    "\n",
    "y_predicted_proba[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6836555360281195 0.640679920913884 177 569\n",
      "31.10720562390158 % -  15\n",
      "\n",
      "\n",
      "Rejected 71.63% of wrong ones\n",
      "Accepted 48.10% of good ones\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.94, 0.06],\n",
       "       [0.68, 0.32],\n",
       "       [0.86, 0.14],\n",
       "       [0.9 , 0.1 ],\n",
       "       [0.84, 0.16]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X[:limit]\n",
    "X_test = X[limit:]\n",
    "\n",
    "y_train = y[:limit]\n",
    "y_test = y[limit:]\n",
    "\n",
    "etree_w2v_tfidf.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = etree_w2v_tfidf.predict(X_test)\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "\n",
    "y_predicted_proba = etree_w2v_tfidf.predict_proba(X_test)\n",
    "#y_predicted = (y_predicted_proba[:,1] > 0.12)\n",
    "y_predicted = (y_predicted_proba[:,1] > np.percentile(y_predicted_proba[:,1],100-percentile))\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected %.2f%% of wrong ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == False)])*100.0/(len(y_test)-sum(y_test))))\n",
    "print(\"Accepted %.2f%% of good ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == True)])*100.0/sum(y_test)))\n",
    "\n",
    "y_predicted_proba[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piotr.bednarski/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6432337434094904 0.5924112522990657 190 569\n",
      "33.391915641476274 % -  16\n",
      "\n",
      "\n",
      "Rejected 67.96% of wrong ones\n",
      "Accepted 41.77% of good ones\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.8580664 , 0.1419336 ],\n",
       "       [0.86940546, 0.13059454],\n",
       "       [0.85672142, 0.14327858],\n",
       "       [0.8303504 , 0.1696496 ],\n",
       "       [0.86112771, 0.13887229]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X[:limit]\n",
    "X_test = X[limit:]\n",
    "\n",
    "y_train = y[:limit]\n",
    "y_test = y[limit:]\n",
    "\n",
    "svc_w2v.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = svc_w2v.predict(X_test)\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "\n",
    "y_predicted_proba = svc_w2v.predict_proba(X_test)\n",
    "#y_predicted = (y_predicted_proba[:,1] > 0.12)\n",
    "y_predicted = (y_predicted_proba[:,1] > np.percentile(y_predicted_proba[:,1],100-percentile))\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected %.2f%% of wrong ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == False)])*100.0/(len(y_test)-sum(y_test))))\n",
    "print(\"Accepted %.2f%% of good ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == True)])*100.0/sum(y_test)))\n",
    "\n",
    "y_predicted_proba[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piotr.bednarski/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6256590509666081 0.5723329888655222 190 569\n",
      "33.391915641476274 % -  16\n",
      "\n",
      "\n",
      "Rejected 66.94% of wrong ones\n",
      "Accepted 35.44% of good ones\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.8661225 , 0.1338775 ],\n",
       "       [0.81659765, 0.18340235],\n",
       "       [0.85982743, 0.14017257],\n",
       "       [0.84394802, 0.15605198],\n",
       "       [0.85900345, 0.14099655]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X[:limit]\n",
    "X_test = X[limit:]\n",
    "\n",
    "y_train = y[:limit]\n",
    "y_test = y[limit:]\n",
    "\n",
    "svc_w2v_tfidf.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = svc_w2v_tfidf.predict(X_test)\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "\n",
    "y_predicted_proba = svc_w2v_tfidf.predict_proba(X_test)\n",
    "#y_predicted = (y_predicted_proba[:,1] > 0.12)\n",
    "y_predicted = (y_predicted_proba[:,1] > np.percentile(y_predicted_proba[:,1],100-percentile))\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected %.2f%% of wrong ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == False)])*100.0/(len(y_test)-sum(y_test))))\n",
    "print(\"Accepted %.2f%% of good ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == True)])*100.0/sum(y_test)))\n",
    "\n",
    "y_predicted_proba[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extree - Custom embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extra Trees classifier is almost universally great, let's stack it with our embeddings\n",
    "\n",
    "etree_w2v_custom = Pipeline([(\"word2vec vectorizer\", MeanEmbeddingVectorizer(w2v_custom)), \n",
    "                        (\"extra trees\", ExtraTreesClassifier(n_estimators=50))])\n",
    "etree_w2v_tfidf_custom = Pipeline([(\"word2vec vectorizer\", TfidfEmbeddingVectorizer(w2v_custom)), \n",
    "                        (\"svc\", ExtraTreesClassifier(n_estimators=50))])\n",
    "svc_w2v_custom = Pipeline([(\"word2vec vectorizer\", MeanEmbeddingVectorizer(w2v_custom)), \n",
    "                        (\"extra trees\", SVC(kernel=\"linear\", probability=True))])\n",
    "svc_w2v_tfidf_custom = Pipeline([(\"word2vec vectorizer\", TfidfEmbeddingVectorizer(w2v_custom)), \n",
    "                        (\"svc\", SVC(kernel=\"linear\", probability=True))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6660808435852372 0.6196284976250672 183 569\n",
      "32.161687170474515 % -  16\n",
      "\n",
      "\n",
      "Rejected 70.00% of wrong ones\n",
      "Accepted 45.57% of good ones\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.92, 0.08],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.96, 0.04],\n",
       "       [0.92, 0.08],\n",
       "       [0.94, 0.06]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X[:limit]\n",
    "X_test = X[limit:]\n",
    "\n",
    "y_train = y[:limit]\n",
    "y_test = y[limit:]\n",
    "\n",
    "etree_w2v_custom.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = etree_w2v_custom.predict(X_test)\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "\n",
    "y_predicted_proba = etree_w2v_custom.predict_proba(X_test)\n",
    "#y_predicted = (y_predicted_proba[:,1] > 0.12)\n",
    "y_predicted = (y_predicted_proba[:,1] > np.percentile(y_predicted_proba[:,1],100-percentile))\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected %.2f%% of wrong ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == False)])*100.0/(len(y_test)-sum(y_test))))\n",
    "print(\"Accepted %.2f%% of good ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == True)])*100.0/sum(y_test)))\n",
    "\n",
    "y_predicted_proba[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6906854130052724 0.6515018373542099 163 569\n",
      "28.646748681898067 % -  14\n",
      "\n",
      "\n",
      "Rejected 73.47% of wrong ones\n",
      "Accepted 41.77% of good ones\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.9 , 0.1 ],\n",
       "       [0.74, 0.26],\n",
       "       [0.94, 0.06],\n",
       "       [0.8 , 0.2 ],\n",
       "       [0.92, 0.08]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X[:limit]\n",
    "X_test = X[limit:]\n",
    "\n",
    "y_train = y[:limit]\n",
    "y_test = y[limit:]\n",
    "\n",
    "etree_w2v_tfidf_custom.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = etree_w2v_tfidf_custom.predict(X_test)\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "\n",
    "y_predicted_proba = etree_w2v_tfidf_custom.predict_proba(X_test)\n",
    "#y_predicted = (y_predicted_proba[:,1] > 0.12)\n",
    "y_predicted = (y_predicted_proba[:,1] > np.percentile(y_predicted_proba[:,1],100-percentile))\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected %.2f%% of wrong ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == False)])*100.0/(len(y_test)-sum(y_test))))\n",
    "print(\"Accepted %.2f%% of good ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == True)])*100.0/sum(y_test)))\n",
    "\n",
    "y_predicted_proba[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piotr.bednarski/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6362038664323374 0.5843799469256483 190 569\n",
      "33.391915641476274 % -  16\n",
      "\n",
      "\n",
      "Rejected 67.55% of wrong ones\n",
      "Accepted 39.24% of good ones\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.85324609, 0.14675391],\n",
       "       [0.85401489, 0.14598511],\n",
       "       [0.85879894, 0.14120106],\n",
       "       [0.85619372, 0.14380628],\n",
       "       [0.8501659 , 0.1498341 ]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X[:limit]\n",
    "X_test = X[limit:]\n",
    "\n",
    "y_train = y[:limit]\n",
    "y_test = y[limit:]\n",
    "\n",
    "svc_w2v_custom.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = svc_w2v_custom.predict(X_test)\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "\n",
    "y_predicted_proba = svc_w2v_custom.predict_proba(X_test)\n",
    "#y_predicted = (y_predicted_proba[:,1] > 0.12)\n",
    "y_predicted = (y_predicted_proba[:,1] > np.percentile(y_predicted_proba[:,1],100-percentile))\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected %.2f%% of wrong ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == False)])*100.0/(len(y_test)-sum(y_test))))\n",
    "print(\"Accepted %.2f%% of good ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == True)])*100.0/sum(y_test)))\n",
    "\n",
    "y_predicted_proba[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piotr.bednarski/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6186291739894552 0.5643016834921047 190 569\n",
      "33.391915641476274 % -  16\n",
      "\n",
      "\n",
      "Rejected 66.53% of wrong ones\n",
      "Accepted 32.91% of good ones\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.8913196 , 0.1086804 ],\n",
       "       [0.84070935, 0.15929065],\n",
       "       [0.84047309, 0.15952691],\n",
       "       [0.84088717, 0.15911283],\n",
       "       [0.85585463, 0.14414537]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X[:limit]\n",
    "X_test = X[limit:]\n",
    "\n",
    "y_train = y[:limit]\n",
    "y_test = y[limit:]\n",
    "\n",
    "svc_w2v_tfidf_custom.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = svc_w2v_tfidf_custom.predict(X_test)\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "\n",
    "y_predicted_proba = svc_w2v_tfidf_custom.predict_proba(X_test)\n",
    "#y_predicted = (y_predicted_proba[:,1] > 0.12)\n",
    "y_predicted = (y_predicted_proba[:,1] > np.percentile(y_predicted_proba[:,1],100-percentile))\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected %.2f%% of wrong ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == False)])*100.0/(len(y_test)-sum(y_test))))\n",
    "print(\"Accepted %.2f%% of good ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == True)])*100.0/sum(y_test)))\n",
    "\n",
    "y_predicted_proba[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression and SGD - both on embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "\n",
    "logistic_w2v = Pipeline([(\"word2vec vectorizer\", MeanEmbeddingVectorizer(word2vec_pretrained)), \n",
    "                        (\"logistic\", LogisticRegression())])\n",
    "logistic_w2v_tfidf = Pipeline([(\"word2vec vectorizer\", TfidfEmbeddingVectorizer(word2vec_pretrained)), \n",
    "                        (\"logistic\", LogisticRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piotr.bednarski/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6678383128295254 0.6205208211060266 190 569\n",
      "33.391915641476274 % -  16\n",
      "\n",
      "\n",
      "Rejected 69.39% of wrong ones\n",
      "Accepted 50.63% of good ones\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.91185228, 0.08814772],\n",
       "       [0.8557203 , 0.1442797 ],\n",
       "       [0.86363746, 0.13636254],\n",
       "       [0.82217058, 0.17782942],\n",
       "       [0.89523583, 0.10476417]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X[:limit]\n",
    "X_test = X[limit:]\n",
    "\n",
    "y_train = y[:limit]\n",
    "y_test = y[limit:]\n",
    "\n",
    "logistic_w2v.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = logistic_w2v.predict(X_test)\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "\n",
    "y_predicted_proba = logistic_w2v.predict_proba(X_test)\n",
    "#y_predicted = (y_predicted_proba[:,1] > 0.12)\n",
    "y_predicted = (y_predicted_proba[:,1] > np.percentile(y_predicted_proba[:,1],100-percentile))\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected %.2f%% of wrong ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == False)])*100.0/(len(y_test)-sum(y_test))))\n",
    "print(\"Accepted %.2f%% of good ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == True)])*100.0/sum(y_test)))\n",
    "\n",
    "y_predicted_proba[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piotr.bednarski/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6678383128295254 0.6205208211060266 190 569\n",
      "33.391915641476274 % -  16\n",
      "\n",
      "\n",
      "Rejected 69.39% of wrong ones\n",
      "Accepted 50.63% of good ones\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.91247311, 0.08752689],\n",
       "       [0.8551975 , 0.1448025 ],\n",
       "       [0.86355652, 0.13644348],\n",
       "       [0.82287978, 0.17712022],\n",
       "       [0.89443603, 0.10556397]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X[:limit]\n",
    "X_test = X[limit:]\n",
    "\n",
    "y_train = y[:limit]\n",
    "y_test = y[limit:]\n",
    "\n",
    "logistic_w2v_tfidf.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = logistic_w2v_tfidf.predict(X_test)\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "\n",
    "y_predicted_proba = logistic_w2v_tfidf.predict_proba(X_test)\n",
    "#y_predicted = (y_predicted_proba[:,1] > 0.12)\n",
    "y_predicted = (y_predicted_proba[:,1] > np.percentile(y_predicted_proba[:,1],100-percentile))\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected %.2f%% of wrong ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == False)])*100.0/(len(y_test)-sum(y_test))))\n",
    "print(\"Accepted %.2f%% of good ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == True)])*100.0/sum(y_test)))\n",
    "\n",
    "y_predicted_proba[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "\n",
    "sgd_w2v = Pipeline([(\"word2vec vectorizer\", MeanEmbeddingVectorizer(word2vec_pretrained)), \n",
    "                        (\"logistic\", SGDClassifier(loss = 'log'))])\n",
    "sgd_w2v_tfidf = Pipeline([(\"word2vec vectorizer\", TfidfEmbeddingVectorizer(word2vec_pretrained)), \n",
    "                        (\"logistic\", SGDClassifier(loss = 'log'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6678383128295254 0.6205208211060266 190 569\n",
      "33.391915641476274 % -  16\n",
      "\n",
      "\n",
      "Rejected 69.39% of wrong ones\n",
      "Accepted 50.63% of good ones\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[9.99576146e-01, 4.23854459e-04],\n",
       "       [9.75468794e-01, 2.45312064e-02],\n",
       "       [9.89032356e-01, 1.09676440e-02],\n",
       "       [9.58967792e-01, 4.10322079e-02],\n",
       "       [9.98485960e-01, 1.51404010e-03]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X[:limit]\n",
    "X_test = X[limit:]\n",
    "\n",
    "y_train = y[:limit]\n",
    "y_test = y[limit:]\n",
    "\n",
    "sgd_w2v.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = sgd_w2v.predict(X_test)\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "\n",
    "y_predicted_proba = sgd_w2v.predict_proba(X_test)\n",
    "#y_predicted = (y_predicted_proba[:,1] > 0.12)\n",
    "y_predicted = (y_predicted_proba[:,1] > np.percentile(y_predicted_proba[:,1],100-percentile))\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected %.2f%% of wrong ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == False)])*100.0/(len(y_test)-sum(y_test))))\n",
    "print(\"Accepted %.2f%% of good ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == True)])*100.0/sum(y_test)))\n",
    "\n",
    "y_predicted_proba[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piotr.bednarski/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6678383128295254 0.6205208211060266 190 569\n",
      "33.391915641476274 % -  16\n",
      "\n",
      "\n",
      "Rejected 69.39% of wrong ones\n",
      "Accepted 50.63% of good ones\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[9.99944325e-01, 5.56748540e-05],\n",
       "       [9.97504215e-01, 2.49578457e-03],\n",
       "       [9.98696108e-01, 1.30389228e-03],\n",
       "       [9.94701956e-01, 5.29804364e-03],\n",
       "       [9.99803779e-01, 1.96220966e-04]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X[:limit]\n",
    "X_test = X[limit:]\n",
    "\n",
    "y_train = y[:limit]\n",
    "y_test = y[limit:]\n",
    "\n",
    "sgd_w2v_tfidf.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = sgd_w2v_tfidf.predict(X_test)\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "\n",
    "y_predicted_proba = sgd_w2v_tfidf.predict_proba(X_test)\n",
    "#y_predicted = (y_predicted_proba[:,1] > 0.12)\n",
    "y_predicted = (y_predicted_proba[:,1] > np.percentile(y_predicted_proba[:,1],100-percentile))\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected %.2f%% of wrong ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == False)])*100.0/(len(y_test)-sum(y_test))))\n",
    "print(\"Accepted %.2f%% of good ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == True)])*100.0/sum(y_test)))\n",
    "\n",
    "y_predicted_proba[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Saving/loading models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "def datetime_string():\n",
    "    localtime = time.localtime(time.time())\n",
    "    datetime_str = str(localtime.tm_year)\n",
    "    if(localtime.tm_mon < 10):\n",
    "        datetime_str += '0'\n",
    "    datetime_str += str(localtime.tm_mon)\n",
    "    if(localtime.tm_mday < 10):\n",
    "        datetime_str += '0'\n",
    "    datetime_str += str(localtime.tm_mday) + '_'\n",
    "    if(localtime.tm_hour < 10):\n",
    "        datetime_str += '0'\n",
    "    datetime_str += str(localtime.tm_hour)\n",
    "    if(localtime.tm_min < 10):\n",
    "        datetime_str += '0'\n",
    "    datetime_str += str(localtime.tm_min) + '_'\n",
    "    \n",
    "    return datetime_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "contents_dict = {\n",
    "    'model_svc_sklearn' : model_svc,\n",
    "    'model_svc_tfidf_sklearn' : model_svc_tfidf,\n",
    "    \n",
    "    'model_nb_sklearn' : model_nb,\n",
    "    'model_nb_tfidf_sklearn' : model_nb_tfidf,\n",
    "    \n",
    "    'etree_w2v_sklearn' : etree_w2v,\n",
    "    'etree_w2v_tfidf_sklearn' : etree_w2v_tfidf,\n",
    "    \n",
    "    'svc_w2v_sklearn' : svc_w2v,\n",
    "    'svc_w2v_tfidf_sklearn' : svc_w2v_tfidf,\n",
    "    \n",
    "    'etree_w2v_custom_sklearn' : etree_w2v_custom,\n",
    "    'etree_w2v_tfidf_custom_sklearn' : etree_w2v_tfidf_custom,\n",
    "    \n",
    "    'svc_w2v_custom_sklearn' : svc_w2v_custom,\n",
    "    'svc_w2v_tfidf_custom_sklearn' : svc_w2v_tfidf_custom,\n",
    "    \n",
    "    'logistic_w2v_sklearn' : logistic_w2v,\n",
    "    'logistic_w2v_tfidf_sklearn' : logistic_w2v_tfidf,\n",
    "    \n",
    "    'sgd_w2v_sklearn' : sgd_w2v,\n",
    "    'sgd_w2v_tfidf_sklearn' : sgd_w2v_tfidf\n",
    "}\n",
    "\n",
    "dat_str = datetime_string()\n",
    "with open(\"models/\"+dat_str+\"ensemble_models.pickle\", 'wb') as f:\n",
    "    pickle.dump(contents_dict, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('models/'+dat_str+'ensemble_models.pickle', 'rb') as f:\n",
    "    contents_dict = pickle.load(f)\n",
    "\n",
    "model_svc = contents_dict['model_svc_sklearn']\n",
    "model_svc_tfidf = contents_dict['model_svc_tfidf_sklearn']\n",
    "\n",
    "model_nb = contents_dict['model_nb_sklearn']\n",
    "model_nb_tfidf = contents_dict['model_nb_tfidf_sklearn']\n",
    "\n",
    "etree_w2v = contents_dict['etree_w2v_sklearn']\n",
    "etree_w2v_tfidf = contents_dict['etree_w2v_tfidf_sklearn']\n",
    "\n",
    "svc_w2v = contents_dict['svc_w2v_sklearn']\n",
    "svc_w2v_tfidf = contents_dict['svc_w2v_tfidf_sklearn']\n",
    "\n",
    "etree_w2v_custom = contents_dict['etree_w2v_custom_sklearn']\n",
    "etree_w2v_tfidf_custom = contents_dict['etree_w2v_tfidf_custom_sklearn']\n",
    "\n",
    "svc_w2v_custom = contents_dict['svc_w2v_custom_sklearn']\n",
    "svc_w2v_tfidf_custom = contents_dict['svc_w2v_tfidf_custom_sklearn']\n",
    "\n",
    "logistic_w2v = contents_dict['logistic_w2v_sklearn']\n",
    "logistic_w2v_tfidf = contents_dict['logistic_w2v_tfidf_sklearn']\n",
    "\n",
    "sgd_w2v = contents_dict['sgd_w2v_sklearn']\n",
    "sgd_w2v_tfidf = contents_dict['sgd_w2v_tfidf_sklearn']\n",
    "\n",
    "#hyperparameters_cnn = contents_dict['hyperparameters_cnn']\n",
    "#hyperparameters_lstm = contents_dict['hyperparameters_lstm']\n",
    "\n",
    "#label_encoder = contents_dict['label_encoder']\n",
    "#tokenize = contents_dict['tokenizer']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building an ensembler - Without data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "XE = X[limit:]\n",
    "yE = y[limit:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piotr.bednarski/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[8.31245735e-02, 7.16112089e-02, 9.97425098e-02, ...,\n",
       "        8.75268871e-02, 4.23854459e-04, 5.56748540e-05],\n",
       "       [1.80541233e-01, 1.41941749e-01, 1.50851802e-01, ...,\n",
       "        1.44802504e-01, 2.45312064e-02, 2.49578457e-03],\n",
       "       [2.38644144e-01, 2.29684972e-01, 1.42980648e-01, ...,\n",
       "        1.36443478e-01, 1.09676440e-02, 1.30389228e-03],\n",
       "       ...,\n",
       "       [6.14596006e-02, 8.83271220e-02, 1.37707001e-01, ...,\n",
       "        1.41290684e-01, 9.02131204e-03, 1.38908149e-03],\n",
       "       [1.74858074e-01, 1.12533986e-01, 1.00451489e-01, ...,\n",
       "        1.76793514e-01, 5.10137450e-02, 6.48895369e-03],\n",
       "       [6.36446265e-02, 9.91164046e-02, 1.15527476e-01, ...,\n",
       "        8.91333021e-02, 7.10986448e-04, 7.26152548e-05]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "XE_intermediate = np.column_stack((\n",
    "        model_svc.predict_proba(XE)[:,1],\n",
    "        model_svc_tfidf.predict_proba(XE)[:,1],\n",
    "    \n",
    "        model_nb.predict_proba(XE)[:,1],\n",
    "        model_nb_tfidf.predict_proba(XE)[:,1],\n",
    "\n",
    "        etree_w2v.predict_proba(XE)[:,1],\n",
    "        etree_w2v_tfidf.predict_proba(XE)[:,1],\n",
    "\n",
    "        svc_w2v.predict_proba(XE)[:,1],\n",
    "        svc_w2v_tfidf.predict_proba(XE)[:,1],\n",
    "\n",
    "        etree_w2v_custom.predict_proba(XE)[:,1],\n",
    "        etree_w2v_tfidf_custom.predict_proba(XE)[:,1],\n",
    "\n",
    "        svc_w2v_custom.predict_proba(XE)[:,1],\n",
    "        svc_w2v_tfidf_custom.predict_proba(XE)[:,1],\n",
    "\n",
    "        logistic_w2v.predict_proba(XE)[:,1],\n",
    "        logistic_w2v_tfidf.predict_proba(XE)[:,1],\n",
    "\n",
    "        sgd_w2v.predict_proba(XE)[:,1],\n",
    "        sgd_w2v_tfidf.predict_proba(XE)[:,1]\n",
    "    ))\n",
    "XE_intermediate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455\n"
     ]
    }
   ],
   "source": [
    "limitE = int(manager_split*len(XE_intermediate))\n",
    "print(limitE)\n",
    "\n",
    "X_train = XE_intermediate[:limitE]\n",
    "X_test = XE_intermediate[limitE:]\n",
    "\n",
    "y_train = yE[:limitE]\n",
    "y_test = yE[limitE:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7192982456140351 0.6854928017718717 38 114\n",
      "33.333333333333336 % -  16\n",
      "\n",
      "\n",
      "Rejected 72.92% of wrong ones\n",
      "Accepted 66.67% of good ones\n",
      "Median: 0.122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piotr.bednarski/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.92402155, 0.07597845],\n",
       "       [0.67944746, 0.32055254],\n",
       "       [0.88375643, 0.11624357],\n",
       "       [0.87820354, 0.12179646],\n",
       "       [0.76001233, 0.23998767]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "logi = LogisticRegression()\n",
    "logi.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = logi.predict(X_test)\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "\n",
    "y_predicted_proba = logi.predict_proba(X_test)\n",
    "y_predicted = (y_predicted_proba[:,1] > np.percentile(y_predicted_proba[:,1],100-percentile))\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected %.2f%% of wrong ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == False)])*100.0/(len(y_test)-sum(y_test))))\n",
    "print(\"Accepted %.2f%% of good ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == True)])*100.0/sum(y_test)))\n",
    "print(\"Median: %.3f\" % np.median(y_predicted_proba[:,1]))\n",
    "\n",
    "y_predicted_proba[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best ratings:\n",
    "Rejected 53.94% of wrong ones\n",
    "\n",
    "Accepted 77.05% of good ones\n",
    "\n",
    "Median: 0.043"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piotr.bednarski/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "max_rej = 20.0\n",
    "max_acc = 20.0\n",
    "\n",
    "XE_intermediate_full = np.column_stack((\n",
    "        model_svc.predict_proba(XE)[:,1],\n",
    "        model_svc_tfidf.predict_proba(XE)[:,1],\n",
    "\n",
    "        model_nb.predict_proba(XE)[:,1],\n",
    "        model_nb_tfidf.predict_proba(XE)[:,1], #----------\n",
    "\n",
    "        etree_w2v.predict_proba(XE)[:,1],\n",
    "        etree_w2v_tfidf.predict_proba(XE)[:,1],\n",
    "\n",
    "        svc_w2v.predict_proba(XE)[:,1],\n",
    "        svc_w2v_tfidf.predict_proba(XE)[:,1], #----------\n",
    "\n",
    "        etree_w2v_custom.predict_proba(XE)[:,1],\n",
    "        etree_w2v_tfidf_custom.predict_proba(XE)[:,1],\n",
    "\n",
    "        svc_w2v_custom.predict_proba(XE)[:,1],\n",
    "        svc_w2v_tfidf_custom.predict_proba(XE)[:,1], #----------\n",
    "\n",
    "        logistic_w2v.predict_proba(XE)[:,1],\n",
    "        logistic_w2v_tfidf.predict_proba(XE)[:,1],\n",
    "\n",
    "        sgd_w2v.predict_proba(XE)[:,1],\n",
    "        sgd_w2v_tfidf.predict_proba(XE)[:,1]\n",
    "    ))\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1]\n",
      "1\n",
      "Rejected 72.92% of wrong ones\n",
      "Accepted 66.67% of good ones\n",
      "Median: 0.142\n",
      "\n",
      "\n",
      "[1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1]\n",
      "2\n",
      "Rejected 72.92% of wrong ones\n",
      "Accepted 66.67% of good ones\n",
      "Median: 0.140\n",
      "\n",
      "\n",
      "[1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "3\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.137\n",
      "\n",
      "\n",
      "[1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1]\n",
      "4\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.140\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piotr.bednarski/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "5\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.138\n",
      "\n",
      "\n",
      "[1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1]\n",
      "6\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.138\n",
      "\n",
      "\n",
      "[1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1]\n",
      "7\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.144\n",
      "\n",
      "\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1]\n",
      "8\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.144\n",
      "\n",
      "\n",
      "[1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1]\n",
      "9\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.141\n",
      "\n",
      "\n",
      "[1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "10\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.137\n",
      "\n",
      "\n",
      "[1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1]\n",
      "11\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.145\n",
      "\n",
      "\n",
      "[1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1]\n",
      "12\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.137\n",
      "\n",
      "\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1]\n",
      "13\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.144\n",
      "\n",
      "\n",
      "[1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0]\n",
      "14\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.138\n",
      "\n",
      "\n",
      "[1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0]\n",
      "15\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.140\n",
      "\n",
      "\n",
      "[1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0]\n",
      "16\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.141\n",
      "\n",
      "\n",
      "[1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1]\n",
      "17\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.137\n",
      "\n",
      "\n",
      "[1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0]\n",
      "18\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.139\n",
      "\n",
      "\n",
      "[1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1]\n",
      "19\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.140\n",
      "\n",
      "\n",
      "[1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1]\n",
      "20\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.143\n",
      "\n",
      "\n",
      "[1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "21\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.142\n",
      "\n",
      "\n",
      "[1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1]\n",
      "22\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.144\n",
      "\n",
      "\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1]\n",
      "23\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.145\n",
      "\n",
      "\n",
      "[1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1]\n",
      "24\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.144\n",
      "\n",
      "\n",
      "[1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0]\n",
      "25\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.141\n",
      "\n",
      "\n",
      "[1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "26\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.139\n",
      "\n",
      "\n",
      "[1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1]\n",
      "27\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.140\n",
      "\n",
      "\n",
      "[1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1]\n",
      "28\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.138\n",
      "\n",
      "\n",
      "[1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1]\n",
      "29\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.140\n",
      "\n",
      "\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0]\n",
      "30\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.144\n",
      "\n",
      "\n",
      "[1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1]\n",
      "31\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.142\n",
      "\n",
      "\n",
      "[1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "32\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.138\n",
      "\n",
      "\n",
      "[1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1]\n",
      "33\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.144\n",
      "\n",
      "\n",
      "[1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]\n",
      "34\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.138\n",
      "\n",
      "\n",
      "[1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0]\n",
      "35\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.141\n",
      "\n",
      "\n",
      "[1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1]\n",
      "36\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.140\n",
      "\n",
      "\n",
      "[1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1]\n",
      "37\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.145\n",
      "\n",
      "\n",
      "[1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0]\n",
      "38\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.145\n",
      "\n",
      "\n",
      "[1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1]\n",
      "39\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.138\n",
      "\n",
      "\n",
      "[1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0]\n",
      "40\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.138\n",
      "\n",
      "\n",
      "[1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0]\n",
      "41\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.139\n",
      "\n",
      "\n",
      "[1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1]\n",
      "42\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.143\n",
      "\n",
      "\n",
      "[1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0]\n",
      "43\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.140\n",
      "\n",
      "\n",
      "[1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0]\n",
      "44\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.140\n",
      "\n",
      "\n",
      "[1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0]\n",
      "45\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.140\n",
      "\n",
      "\n",
      "[1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1]\n",
      "46\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.140\n",
      "\n",
      "\n",
      "[1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1]\n",
      "47\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.137\n",
      "\n",
      "\n",
      "[1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1]\n",
      "48\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.138\n",
      "\n",
      "\n",
      "[1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1]\n",
      "49\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.140\n",
      "\n",
      "\n",
      "[1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1]\n",
      "50\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.139\n",
      "\n",
      "\n",
      "[1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "51\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.138\n",
      "\n",
      "\n",
      "[1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1]\n",
      "52\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.144\n",
      "\n",
      "\n",
      "[1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0]\n",
      "53\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.137\n",
      "\n",
      "\n",
      "[1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0]\n",
      "54\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.144\n",
      "\n",
      "\n",
      "[1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "55\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.138\n",
      "\n",
      "\n",
      "[1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1]\n",
      "56\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.138\n",
      "\n",
      "\n",
      "[1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1]\n",
      "57\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.138\n",
      "\n",
      "\n",
      "[1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1]\n",
      "58\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.140\n",
      "\n",
      "\n",
      "[1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1]\n",
      "59\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.139\n",
      "\n",
      "\n",
      "[1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1]\n",
      "60\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.140\n",
      "\n",
      "\n",
      "[1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1]\n",
      "61\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.140\n",
      "\n",
      "\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1]\n",
      "62\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.144\n",
      "\n",
      "\n",
      "[1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]\n",
      "63\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.141\n",
      "\n",
      "\n",
      "[1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1]\n",
      "64\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.144\n",
      "\n",
      "\n",
      "[1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0]\n",
      "65\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.137\n",
      "\n",
      "\n",
      "[1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0]\n",
      "66\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.137\n",
      "\n",
      "\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1]\n",
      "67\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.144\n",
      "\n",
      "\n",
      "[1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "68\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.137\n",
      "\n",
      "\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1]\n",
      "69\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.144\n",
      "\n",
      "\n",
      "[1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1]\n",
      "70\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.140\n",
      "\n",
      "\n",
      "[1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1]\n",
      "71\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.140\n",
      "\n",
      "\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]\n",
      "72\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.144\n",
      "\n",
      "\n",
      "[1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1]\n",
      "73\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.139\n",
      "\n",
      "\n",
      "[1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1]\n",
      "74\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.145\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1]\n",
      "75\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.137\n",
      "\n",
      "\n",
      "[1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1]\n",
      "76\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.143\n",
      "\n",
      "\n",
      "[1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1]\n",
      "77\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.141\n",
      "\n",
      "\n",
      "[1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1]\n",
      "78\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.138\n",
      "\n",
      "\n",
      "[1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1]\n",
      "79\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.140\n",
      "\n",
      "\n",
      "[1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]\n",
      "80\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.144\n",
      "\n",
      "\n",
      "[1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1]\n",
      "81\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.143\n",
      "\n",
      "\n",
      "[1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1]\n",
      "82\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.137\n",
      "\n",
      "\n",
      "[1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1]\n",
      "83\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.140\n",
      "\n",
      "\n",
      "[1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1]\n",
      "84\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.140\n",
      "\n",
      "\n",
      "[1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1]\n",
      "85\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.144\n",
      "\n",
      "\n",
      "[1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1]\n",
      "86\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.142\n",
      "\n",
      "\n",
      "[1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1]\n",
      "87\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.140\n",
      "\n",
      "\n",
      "[1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0]\n",
      "88\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.140\n",
      "\n",
      "\n",
      "[1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1]\n",
      "89\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.139\n",
      "\n",
      "\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0]\n",
      "90\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.144\n",
      "\n",
      "\n",
      "[1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1]\n",
      "91\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.137\n",
      "\n",
      "\n",
      "[1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0]\n",
      "92\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.144\n",
      "\n",
      "\n",
      "[1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1]\n",
      "93\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.140\n",
      "\n",
      "\n",
      "[1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1]\n",
      "94\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.143\n",
      "\n",
      "\n",
      "[1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1]\n",
      "95\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.138\n",
      "\n",
      "\n",
      "[1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1]\n",
      "96\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.138\n",
      "\n",
      "\n",
      "[1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1]\n",
      "97\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.140\n",
      "\n",
      "\n",
      "[1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1]\n",
      "98\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.140\n",
      "\n",
      "\n",
      "[1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0]\n",
      "99\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.138\n",
      "\n",
      "\n",
      "[1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1]\n",
      "100\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.144\n",
      "\n",
      "\n",
      "[1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]\n",
      "101\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.140\n",
      "\n",
      "\n",
      "[1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1]\n",
      "102\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.140\n",
      "\n",
      "\n",
      "[1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "103\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.137\n",
      "\n",
      "\n",
      "[1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1]\n",
      "104\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.144\n",
      "\n",
      "\n",
      "[1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1]\n",
      "105\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.139\n",
      "\n",
      "\n",
      "[1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1]\n",
      "106\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.138\n",
      "\n",
      "\n",
      "[1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0]\n",
      "107\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.137\n",
      "\n",
      "\n",
      "[1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1]\n",
      "108\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.140\n",
      "\n",
      "\n",
      "[1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0]\n",
      "109\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.143\n",
      "\n",
      "\n",
      "[1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1]\n",
      "110\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.142\n",
      "\n",
      "\n",
      "[1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0]\n",
      "111\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.141\n",
      "\n",
      "\n",
      "[1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1]\n",
      "112\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.144\n",
      "\n",
      "\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0]\n",
      "113\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.144\n",
      "\n",
      "\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1]\n",
      "114\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.144\n",
      "\n",
      "\n",
      "[1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0]\n",
      "115\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.140\n",
      "\n",
      "\n",
      "[1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0]\n",
      "116\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.142\n",
      "\n",
      "\n",
      "[1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0]\n",
      "117\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.143\n",
      "\n",
      "\n",
      "[1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1]\n",
      "118\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.145\n",
      "\n",
      "\n",
      "[1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0]\n",
      "119\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.137\n",
      "\n",
      "\n",
      "[1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0]\n",
      "120\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.143\n",
      "\n",
      "\n",
      "[1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1]\n",
      "121\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.141\n",
      "\n",
      "\n",
      "[1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0]\n",
      "122\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.140\n",
      "\n",
      "\n",
      "[1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0]\n",
      "123\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.144\n",
      "\n",
      "\n",
      "[1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1]\n",
      "124\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.140\n",
      "\n",
      "\n",
      "[1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0]\n",
      "125\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.144\n",
      "\n",
      "\n",
      "[1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1]\n",
      "126\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.142\n",
      "\n",
      "\n",
      "[1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1]\n",
      "127\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.142\n",
      "\n",
      "\n",
      "[1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]\n",
      "128\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.141\n",
      "\n",
      "\n",
      "[1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0]\n",
      "129\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.144\n",
      "\n",
      "\n",
      "[1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1]\n",
      "130\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.139\n",
      "\n",
      "\n",
      "[1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1]\n",
      "131\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.139\n",
      "\n",
      "\n",
      "[1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1]\n",
      "132\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.138\n",
      "\n",
      "\n",
      "[1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1]\n",
      "133\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.139\n",
      "\n",
      "\n",
      "[1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1]\n",
      "134\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.144\n",
      "\n",
      "\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1]\n",
      "135\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.139\n",
      "\n",
      "\n",
      "[1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0]\n",
      "136\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.143\n",
      "\n",
      "\n",
      "[1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]\n",
      "137\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.140\n",
      "\n",
      "\n",
      "[1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0]\n",
      "138\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.140\n",
      "\n",
      "\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1]\n",
      "139\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.140\n",
      "\n",
      "\n",
      "[1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0]\n",
      "140\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.140\n",
      "\n",
      "\n",
      "[1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1]\n",
      "141\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.144\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1]\n",
      "142\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.141\n",
      "\n",
      "\n",
      "[1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1]\n",
      "143\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.138\n",
      "\n",
      "\n",
      "[1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0]\n",
      "144\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.139\n",
      "\n",
      "\n",
      "[1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1]\n",
      "145\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.141\n",
      "\n",
      "\n",
      "[1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1]\n",
      "146\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.140\n",
      "\n",
      "\n",
      "[1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1]\n",
      "147\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.144\n",
      "\n",
      "\n",
      "[1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1]\n",
      "148\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.138\n",
      "\n",
      "\n",
      "[1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1]\n",
      "149\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.142\n",
      "\n",
      "\n",
      "[1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1]\n",
      "150\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.138\n",
      "\n",
      "\n",
      "[1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1]\n",
      "151\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.144\n",
      "\n",
      "\n",
      "[1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1]\n",
      "152\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.138\n",
      "\n",
      "\n",
      "[1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1]\n",
      "153\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.138\n",
      "\n",
      "\n",
      "[1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1]\n",
      "154\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.140\n",
      "\n",
      "\n",
      "[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0]\n",
      "155\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.143\n",
      "\n",
      "\n",
      "[1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1]\n",
      "156\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.137\n",
      "\n",
      "\n",
      "[1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1]\n",
      "157\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.144\n",
      "\n",
      "\n",
      "[1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1]\n",
      "158\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.144\n",
      "\n",
      "\n",
      "[1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0]\n",
      "159\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.139\n",
      "\n",
      "\n",
      "[1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1]\n",
      "160\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.137\n",
      "\n",
      "\n",
      "[1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]\n",
      "161\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.141\n",
      "\n",
      "\n",
      "[1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1]\n",
      "162\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.140\n",
      "\n",
      "\n",
      "[1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1]\n",
      "163\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.136\n",
      "\n",
      "\n",
      "[1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1]\n",
      "164\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.144\n",
      "\n",
      "\n",
      "[1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "165\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.137\n",
      "\n",
      "\n",
      "[1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1]\n",
      "166\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.138\n",
      "\n",
      "\n",
      "[1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0]\n",
      "167\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.141\n",
      "\n",
      "\n",
      "[1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0]\n",
      "168\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.141\n",
      "\n",
      "\n",
      "[1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0]\n",
      "169\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.141\n",
      "\n",
      "\n",
      "[1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "170\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.141\n",
      "\n",
      "\n",
      "[1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1]\n",
      "171\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.139\n",
      "\n",
      "\n",
      "[1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1]\n",
      "172\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.140\n",
      "\n",
      "\n",
      "[1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1]\n",
      "173\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.140\n",
      "\n",
      "\n",
      "[1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1]\n",
      "174\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.139\n",
      "\n",
      "\n",
      "[1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0]\n",
      "175\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.140\n",
      "\n",
      "\n",
      "[1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1]\n",
      "176\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.136\n",
      "\n",
      "\n",
      "[1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1]\n",
      "177\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.145\n",
      "\n",
      "\n",
      "[1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1]\n",
      "178\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.139\n",
      "\n",
      "\n",
      "[1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0]\n",
      "179\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.145\n",
      "\n",
      "\n",
      "[1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1]\n",
      "180\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.143\n",
      "\n",
      "\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0]\n",
      "181\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.143\n",
      "\n",
      "\n",
      "[1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1]\n",
      "182\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.145\n",
      "\n",
      "\n",
      "[1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1]\n",
      "183\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.143\n",
      "\n",
      "\n",
      "[1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0]\n",
      "184\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.141\n",
      "\n",
      "\n",
      "[1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0]\n",
      "185\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.137\n",
      "\n",
      "\n",
      "[1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1]\n",
      "186\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.143\n",
      "\n",
      "\n",
      "[1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1]\n",
      "187\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.140\n",
      "\n",
      "\n",
      "[1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
      "188\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.141\n",
      "\n",
      "\n",
      "[1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0]\n",
      "189\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.143\n",
      "\n",
      "\n",
      "[1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1]\n",
      "190\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.140\n",
      "\n",
      "\n",
      "[1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0]\n",
      "191\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.140\n",
      "\n",
      "\n",
      "[1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0]\n",
      "192\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.140\n",
      "\n",
      "\n",
      "[1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0]\n",
      "193\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.140\n",
      "\n",
      "\n",
      "[1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0]\n",
      "194\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.145\n",
      "\n",
      "\n",
      "[1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1]\n",
      "195\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.143\n",
      "\n",
      "\n",
      "[1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1]\n",
      "196\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.139\n",
      "\n",
      "\n",
      "[1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0]\n",
      "197\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.141\n",
      "\n",
      "\n",
      "[1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0]\n",
      "198\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.145\n",
      "\n",
      "\n",
      "[1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1]\n",
      "199\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.142\n",
      "\n",
      "\n",
      "[1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "200\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.138\n",
      "\n",
      "\n",
      "[1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0]\n",
      "201\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.138\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.0\n",
    "mask_list = []\n",
    "threshold_list = []\n",
    "while(True):\n",
    "    threshold = threshold + 0.1\n",
    "    rand_vect = np.random.rand(16) > threshold\n",
    "    XE_intermediate = XE_intermediate_full[:,rand_vect]\n",
    "    if threshold > 0.85:\n",
    "        threshold = 0.0\n",
    "    if XE_intermediate.shape[1] < 1:\n",
    "        continue\n",
    "        \n",
    "    rand_vect_int = []\n",
    "    for i in range(len(rand_vect)):\n",
    "        if rand_vect[i] == True:\n",
    "            rand_vect_int.append(1)\n",
    "        else:\n",
    "            rand_vect_int.append(0)\n",
    "    if rand_vect_int in mask_list:\n",
    "        continue\n",
    "\n",
    "    limitE = int(manager_split*len(XE_intermediate))\n",
    "    #print(limitE)\n",
    "\n",
    "    X_train = XE_intermediate[:limitE]\n",
    "    X_test = XE_intermediate[limitE:]\n",
    "\n",
    "    y_train = yE[:limitE]\n",
    "    y_test = yE[limitE:]\n",
    "\n",
    "    from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "    from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "    logi = LogisticRegression()\n",
    "    logi.fit(X_train, y_train)\n",
    "\n",
    "    y_predicted = logi.predict(X_test)\n",
    "    acc = accuracy_score(y_predicted, y_test)\n",
    "    f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "\n",
    "    y_predicted_proba = logi.predict_proba(X_test)\n",
    "    #y_predicted = (y_predicted_proba[:,1] > np.percentile(y_predicted_proba[:,1],100-28.5))\n",
    "    y_predicted = (y_predicted_proba[:,1] > np.percentile(y_predicted_proba[:,1],100-percentile))\n",
    "\n",
    "    acc = accuracy_score(y_predicted, y_test)\n",
    "    f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "    #print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "    #print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "    #print(\"\\n\")\n",
    "    \n",
    "    rej = len(X_test_df[(y_predicted == y_test) & (y_predicted == False)])*100.0/(len(y_test)-sum(y_test))\n",
    "    acc = len(X_test_df[(y_predicted == y_test) & (y_predicted == True)])*100.0/sum(y_test)\n",
    "    \n",
    "    X_test_df = pd.DataFrame(X_test)\n",
    "    if (rej >= max_rej and acc >= max_acc):\n",
    "        max_rej = rej \n",
    "        max_acc = acc\n",
    "        mask_list.append(rand_vect_int)\n",
    "        threshold_list.append(np.percentile(y_predicted_proba[:,1],100-percentile))\n",
    "        print(rand_vect_int)\n",
    "        print(len(mask_list))\n",
    "        print(\"Rejected %.2f%% of wrong ones\" % rej)\n",
    "        print(\"Accepted %.2f%% of good ones\" % acc)\n",
    "        print(\"Median: %.3f\\n\\n\" % np.percentile(y_predicted_proba[:,1],100-percentile))\n",
    "        if len(mask_list) > 200:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "[0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0]\n",
    "41\n",
    "Rejected 72.32% of wrong ones\n",
    "Accepted 78.57% of good ones\n",
    "Median: 0.169\n",
    "\n",
    "\n",
    "[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1]\n",
    "42\n",
    "Rejected 72.32% of wrong ones\n",
    "Accepted 78.57% of good ones\n",
    "Median: 0.169\n",
    "\n",
    "percentile 33%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.97014925, 0.54228856, 0.64179104, 0.66666667,\n",
       "       0.62189055, 0.6119403 , 0.60199005, 0.60696517, 0.75621891,\n",
       "       0.60199005, 0.76616915, 0.72636816, 0.72139303, 0.54726368,\n",
       "       0.67661692])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_list_np = np.array([np.array(xi) for xi in mask_list])\n",
    "\n",
    "mask_list_np.sum(axis=0)/len(mask_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYaFLUiP+H0jD1s2IcysCAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9ec6efc6a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = mask_list_np.sum(axis=1)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(a, bins=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16])  # arguments are passed to np.histogram\n",
    "plt.title(\"Histogram\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indices = a.argsort()\n",
    "indices = range(len(a))\n",
    "best_mask = mask_list[indices[-1]]\n",
    "best_threshold = threshold_list[indices[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[True, True, False, True, False, True, True, True, True, True, True, True, True, False, True, False]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(569, 12)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_vect = []\n",
    "for x in best_mask:\n",
    "    rand_vect.append(x == 1)\n",
    "print(rand_vect)\n",
    "XE_intermediate = XE_intermediate_full[:,rand_vect]\n",
    "XE_intermediate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455\n"
     ]
    }
   ],
   "source": [
    "limitE = int(manager_split*len(XE_intermediate))\n",
    "print(limitE)\n",
    "\n",
    "X_train = XE_intermediate[:limitE]\n",
    "X_test = XE_intermediate[limitE:]\n",
    "\n",
    "y_train = yE[:limitE]\n",
    "y_test = yE[limitE:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7368421052631579 0.7051495016611297 38 114\n",
      "33.333333333333336 % -  16\n",
      "\n",
      "\n",
      "Rejected 73.96% of wrong ones\n",
      "Accepted 72.22% of good ones\n",
      "Median: 0.137735466\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.91888857, 0.08111143],\n",
       "       [0.7083779 , 0.2916221 ],\n",
       "       [0.88867641, 0.11132359],\n",
       "       [0.8777093 , 0.1222907 ],\n",
       "       [0.77955744, 0.22044256]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "#logi = LogisticRegression()\n",
    "#logi.fit(X_train, y_train)\n",
    "\n",
    "y_predicted_proba = logi.predict_proba(X_test)\n",
    "#y_predicted = (y_predicted_proba[:,1] > np.percentile(y_predicted_proba[:,1],100-percentile))\n",
    "y_predicted = (y_predicted_proba[:,1] > best_threshold)\n",
    "\n",
    "\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected %.2f%% of wrong ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == False)])*100.0/(len(y_test)-sum(y_test))))\n",
    "print(\"Accepted %.2f%% of good ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == True)])*100.0/sum(y_test)))\n",
    "print(\"Median: %.9f\" % np.percentile(y_predicted_proba[:,1],100-percentile))\n",
    "\n",
    "y_predicted_proba[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "contents_dict = {\n",
    "    'model_svc_sklearn' : model_svc,\n",
    "    'model_svc_tfidf_sklearn' : model_svc_tfidf,\n",
    "    \n",
    "    'model_nb_sklearn' : model_nb,\n",
    "    'model_nb_tfidf_sklearn' : model_nb_tfidf,\n",
    "    \n",
    "    'etree_w2v_sklearn' : etree_w2v,\n",
    "    'etree_w2v_tfidf_sklearn' : etree_w2v_tfidf,\n",
    "    \n",
    "    'svc_w2v_sklearn' : svc_w2v,\n",
    "    'svc_w2v_tfidf_sklearn' : svc_w2v_tfidf,\n",
    "    \n",
    "    'etree_w2v_custom_sklearn' : etree_w2v_custom,\n",
    "    'etree_w2v_tfidf_custom_sklearn' : etree_w2v_tfidf_custom,\n",
    "    \n",
    "    'svc_w2v_custom_sklearn' : svc_w2v_custom,\n",
    "    'svc_w2v_tfidf_custom_sklearn' : svc_w2v_tfidf_custom,\n",
    "    \n",
    "    'logistic_w2v_sklearn' : logistic_w2v,\n",
    "    'logistic_w2v_tfidf_sklearn' : logistic_w2v_tfidf,\n",
    "    \n",
    "    'sgd_w2v_sklearn' : sgd_w2v,\n",
    "    'sgd_w2v_tfidf_sklearn' : sgd_w2v_tfidf,\n",
    "    \n",
    "    'best_mask' : best_mask,\n",
    "    'percentile' : 100-percentile,\n",
    "    'best_threshold' : best_threshold,\n",
    "    'ensembler' : logi\n",
    "}\n",
    "\n",
    "with open(\"models/\"+dat_str+\"ensemble_models_with_manager.pickle\", 'wb') as f:\n",
    "    pickle.dump(contents_dict, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Current model\n",
    "\n",
    "Rejected 73.96% of wrong ones\n",
    "\n",
    "Accepted 72.22% of good ones\n",
    "\n",
    "Threshold: 0.137735466\n",
    "\n",
    "[True, True, False, True, False, True, True, True, True, True, True, True, True, False, True, False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
