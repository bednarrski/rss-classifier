{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from api import inoreader_api, inoreader_scraping\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape feeds starting from a concrete moment and store them in a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=JTePEJg2wToU\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=ko5u3jhWBRiS\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=H02AP5pr5lDb\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=Y77LiMducIzS\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=7MA6LG8mNhXI\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=hZd3y635FoZ0\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=WYuBXYk4wHqT\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=xCu2j7gOgSrU\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=IZism2J77pfh\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=_SFaAjaXPd5E\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=XiyN29FudzF4\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=iguzglKH3zng\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=ZyJTFf6ynDj5\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=P1bQQjgtX6bZ\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=7UtOOC42D7z2\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=IfeLzy19tS2z\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=awWc2AyZREZZ\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=8xebiPFbLyrH\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=19jDuNh3SO70\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=Q1KRgNUlyQ3b\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=8z6E9Z8FRrkL\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=NwFEUyrbQ8Rl\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=ckCCWLRR4ACy\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=an_rnPJQ7wsO\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=mACc_uaU7pQt\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=Pbs6gmYwOKBK\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=9jFa545ul7rE\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=xgP6oqNmAqMK\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=UxoHmA8190Wq\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=2pjhpLj396kZ\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=MpTCM8mZdCtA\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=nFNE1O_1bDAU\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=EO0npG1jP4yN\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=2hADJYY2xz1e\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=SCqDgbqKSpKg\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=1KcgLuJ4EG69\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=8p9e2zNHnE2j\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=RZI9wEwxHqg3\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=4A8MPtoge_uT\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=NbmpJr3T2PY1\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=8j2dsOtJLGlC\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=Je3WZy4MP3gA\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=ZyHzPNg8qLqW\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=wKd2I5S1NZlD\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=Jx6l2dnOwDN7\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=gaUggaD2iosN\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=70gGtf9JxBWx\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=QE1brwjzr8Mb\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=PNFn3EqLR6mj\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=7gWOKY7hjYpI\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=8YKcSsMWwZmS\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=ZBgHUxNhNTIf\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=O3U8ywgY2_eQ\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=3mqXSSp5Fcqh\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=6aNZ0BcPoLAT\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=53eF8Rj0N2fi\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=n2obtkKF27Dy\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=RssJ1etYbXAG\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=LJQL4Cgo5pTG\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=6pHEusOw_957\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=gnOkYY4yuUII\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=3WrEhcP5dGDj\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=OCWfeXhg1HAy\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=fNLwwF18Alaf\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=twQx45TWH47s\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=pln_udtd_TJg\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=jIk0hbd4iH9i\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=a9uQmS2FTyZ3\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=cZqz9qNlStYR\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=kU7PsOsm7Xfx\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=Z69OljKWcNwR\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=TARrg2fokjJh\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=YKYT3T55bGLp\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=1FY0mqpj3dOo\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=7DIurWXBQ3X6\n",
      "(200, 'OK')\n",
      "1500\n"
     ]
    }
   ],
   "source": [
    "start_time = 1508112001\n",
    "feed = 'user/-/label/arXiv'\n",
    "file_name = 'articles_raw.json'\n",
    "\n",
    "number_scraped = inoreader_scraping.scrape(feed, start_time, file_name)\n",
    "print(number_scraped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the feeds from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open(file_name, 'r')\n",
    "json_string = f.read()\n",
    "f.close\n",
    "\n",
    "json_object = json.loads(json_string)\n",
    "all_articles = json_object['all_articles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_abstract_string(abs_dict):\n",
    "    abs_string = abs_dict['content']\n",
    "    abs_string = re.search('<p>(.*)</p>', abs_string, flags=re.DOTALL)\n",
    "    return abs_string.group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_canonical_string(canonical_list):\n",
    "    url_dict = canonical_list[0]\n",
    "    url = url_dict['href']\n",
    "    return url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create preprocessed and cleaned DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piotr.bednarski/ml-env-27-gpu/lib/python2.7/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/piotr.bednarski/ml-env-27-gpu/lib/python2.7/site-packages/ipykernel/__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/piotr.bednarski/ml-env-27-gpu/lib/python2.7/site-packages/ipykernel/__main__.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/piotr.bednarski/ml-env-27-gpu/lib/python2.7/site-packages/ipykernel/__main__.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "all_articles_pd = pd.DataFrame(all_articles)\n",
    "all_articles_pd = all_articles_pd[['canonical', 'author', 'categories', 'published', 'title', 'summary']]\n",
    "\n",
    "for i in range(len(all_articles_pd)):\n",
    "    all_articles_pd['summary'][i] = get_abstract_string(all_articles_pd['summary'][i])\n",
    "    all_articles_pd['canonical'][i] = get_canonical_string(all_articles_pd['canonical'][i])\n",
    "    \n",
    "all_articles_pd['read'] = False\n",
    "all_articles_pd['liked'] = False\n",
    "\n",
    "for i in range(len(all_articles_pd)):\n",
    "    if 'user/1005689817/state/com.google/read' in all_articles_pd['categories'][i]:\n",
    "        all_articles_pd['read'][i] = True\n",
    "    if 'user/1005689817/state/com.google/like' in all_articles_pd['categories'][i]:\n",
    "        all_articles_pd['liked'][i] = True\n",
    "\n",
    "del all_articles_pd['categories']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#all_articles_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tagged_articles_pd = all_articles_pd[all_articles_pd['read'] == True]\n",
    "\n",
    "with open('old_articles_proto2.pickle', 'rb') as f:\n",
    "    # Pickle the 'data' dictionary using the highest protocol available.\n",
    "    old_tagged_articles_pd = pickle.load(f)\n",
    "    \n",
    "tagged_articles_pd = pd.concat([tagged_articles_pd, old_tagged_articles_pd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tagged_articles_unique_pd = tagged_articles_pd.sort_values(by=['canonical', 'liked'], ascending=False).reset_index(drop=True)\n",
    "to_drop = tagged_articles_unique_pd.duplicated(subset = ['canonical'], keep='first')\n",
    "to_drop = list(to_drop[to_drop == False].index.values)\n",
    "\n",
    "tagged_articles_unique_pd = tagged_articles_unique_pd[tagged_articles_unique_pd.index.isin(to_drop)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2477\n",
      "2291\n"
     ]
    }
   ],
   "source": [
    "print(len(tagged_articles_pd))\n",
    "print(len(tagged_articles_unique_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_ = list(tagged_articles_unique_pd['author']+' '+tagged_articles_unique_pd['title']+' '+tagged_articles_unique_pd['summary'])\n",
    "y_ = list(tagged_articles_unique_pd['liked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index_shuffled = [i for i in range(len(X_))]\n",
    "random.shuffle(index_shuffled)\n",
    "X = []\n",
    "y = []\n",
    "for i in index_shuffled:\n",
    "    X.append(X_[i])\n",
    "    y.append(y_[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras.preprocessing.text\n",
    "from string import maketrans\n",
    "\n",
    "def text_to_word_sequence(text,\n",
    "                          filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "                          lower=True, split=\" \"):\n",
    "    if lower: text = text.lower()\n",
    "    if type(text) == unicode:\n",
    "        translate_table = {ord(c): ord(t) for c,t in zip(filters, split*len(filters)) }\n",
    "    else:\n",
    "        translate_table = maketrans(filters, split * len(filters))\n",
    "    text = text.translate(translate_table)\n",
    "    seq = text.split(split)\n",
    "    return [i for i in seq if i]\n",
    "    \n",
    "keras.preprocessing.text.text_to_word_sequence = text_to_word_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('stopwords/english') as f:\n",
    "    stopwords = [line.strip() for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1752\n",
      "1375\n"
     ]
    }
   ],
   "source": [
    "print(len(X[4]))\n",
    "\n",
    "for i in range(len(X)):\n",
    "    seq = text_to_word_sequence(X[i])\n",
    "    clean_seq = [word for word in seq if word not in stopwords]\n",
    "    X[i] = ' '.join(clean_seq)\n",
    "    \n",
    "print(len(X[4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF -> NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piotr.bednarski/ml-env-27-gpu/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.87363834422657949, 0.93044217946178742)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "\n",
    "\n",
    "model_nb_tfidf = Pipeline([\n",
    "    (\"tfidf_vectorizer\", TfidfVectorizer()),\\\n",
    "    (\"nb\", BernoulliNB())\n",
    "])\n",
    "\n",
    "limit = int(0.8*len(X))\n",
    "\n",
    "X_train = X[:limit]\n",
    "X_test = X[limit:]\n",
    "\n",
    "y_train = y[:limit]\n",
    "y_test = y[limit:]\n",
    "\n",
    "model_nb_tfidf.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = model_nb_tfidf.predict(X_test)\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "acc, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.87363834422657949, 0.93044217946178742, 1, 459)\n",
      "(0.0, '% - ', 0)\n",
      "\n",
      "\n",
      "('Rejected good ones: ', 58, '/', 59)\n",
      "('Accepted wrong ones:', 0, '/', 400)\n",
      "\n",
      "\n",
      "('Rejected wrong ones: ', 400, '/', 400)\n",
      "('Accepted good ones:', 1, '/', 59)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  1.00000000e+00,   1.58518609e-22],\n",
       "       [  1.00000000e+00,   5.73102913e-25],\n",
       "       [  1.00000000e+00,   1.22361153e-20],\n",
       "       [  1.00000000e+00,   1.92059761e-27],\n",
       "       [  1.00000000e+00,   1.42798101e-27],\n",
       "       [  1.00000000e+00,   2.08910338e-19],\n",
       "       [  1.00000000e+00,   1.76131726e-20],\n",
       "       [  1.00000000e+00,   2.45596218e-21],\n",
       "       [  1.00000000e+00,   1.56119364e-29],\n",
       "       [  1.00000000e+00,   2.35762884e-20],\n",
       "       [  1.00000000e+00,   8.64037478e-22],\n",
       "       [  1.00000000e+00,   6.10035549e-26],\n",
       "       [  1.00000000e+00,   3.96787238e-25],\n",
       "       [  1.00000000e+00,   6.85356878e-19],\n",
       "       [  1.00000000e+00,   1.28185943e-27],\n",
       "       [  1.00000000e+00,   2.14660138e-25],\n",
       "       [  1.00000000e+00,   1.29052376e-17],\n",
       "       [  1.00000000e+00,   1.92287800e-33],\n",
       "       [  1.00000000e+00,   1.26667490e-28],\n",
       "       [  1.00000000e+00,   8.56545049e-25]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted_proba = model_nb_tfidf.predict_proba(X_test)\n",
    "#y_predicted = (y_predicted_proba[:,1] > 0.15)\n",
    "y_predicted = (y_predicted_proba[:,1] > 0.10)\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)/len(y_predicted)*100.0,\"% - \", int(sum(y_predicted)/len(y_predicted)*50.0))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected good ones: \", len(X_test_df[(y_predicted != y_test) & (y_predicted == False)]), \"/\", sum(y_test))\n",
    "print(\"Accepted wrong ones:\", len(X_test_df[(y_predicted != y_test) & (y_predicted == True)]), \"/\", len(y_test)-sum(y_test))\n",
    "print(\"\\n\")\n",
    "print(\"Rejected wrong ones: \", len(X_test_df[(y_predicted == y_test) & (y_predicted == False)]), \"/\", len(y_test)-sum(y_test))\n",
    "print(\"Accepted good ones:\", len(X_test_df[(y_predicted == y_test) & (y_predicted == True)]), \"/\", sum(y_test))\n",
    "\n",
    "y_predicted_proba[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CountVect -> NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.86928104575163401, 0.9280436339259871)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "\n",
    "\n",
    "model_nb = Pipeline([\n",
    "    #('vect', CountVectorizer(ngram_range=(1,3),stop_words='english')),\\\n",
    "    (\"count_vectorizer\", CountVectorizer(analyzer=lambda x: x)),\\\n",
    "    (\"nb\", BernoulliNB())\n",
    "])\n",
    "\n",
    "limit = int(0.8*len(X))\n",
    "\n",
    "X_train = X[:limit]\n",
    "X_test = X[limit:]\n",
    "\n",
    "y_train = y[:limit]\n",
    "y_test = y[limit:]\n",
    "\n",
    "model_nb.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = model_nb.predict(X_test)\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "acc, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.492374727669 0.412945570237 240 459\n",
      "52.2875816993 % -  26\n",
      "\n",
      "\n",
      "('Rejected good ones: ', 26, '/', 59)\n",
      "('Accepted wrong ones:', 207, '/', 400)\n",
      "\n",
      "\n",
      "('Rejected wrong ones: ', 193, '/', 400)\n",
      "('Accepted good ones:', 33, '/', 59)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.90724926,  0.09275074],\n",
       "       [ 0.88212477,  0.11787523],\n",
       "       [ 0.88863817,  0.11136183],\n",
       "       [ 0.87350152,  0.12649848],\n",
       "       [ 0.71997751,  0.28002249]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted_proba = model_nb.predict_proba(X_test)\n",
    "#y_predicted = (y_predicted_proba[:,1] > 0.1296)\n",
    "y_predicted = (y_predicted_proba[:,1] > 0.1325)\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print acc, f1, sum(y_predicted), len(y_predicted)\n",
    "print sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected good ones: \", len(X_test_df[(y_predicted != y_test) & (y_predicted == False)]), \"/\", sum(y_test))\n",
    "print(\"Accepted wrong ones:\", len(X_test_df[(y_predicted != y_test) & (y_predicted == True)]), \"/\", len(y_test)-sum(y_test))\n",
    "print(\"\\n\")\n",
    "print(\"Rejected wrong ones: \", len(X_test_df[(y_predicted == y_test) & (y_predicted == False)]), \"/\", len(y_test)-sum(y_test))\n",
    "print(\"Accepted good ones:\", len(X_test_df[(y_predicted == y_test) & (y_predicted == True)]), \"/\", sum(y_test))\n",
    "\n",
    "y_predicted_proba[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF -> SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.87363834422657949, 0.90303015793211872)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "\n",
    "model_svc_tfidf = Pipeline([\n",
    "    ('vect', CountVectorizer(ngram_range=(1,3), min_df=1, max_df=1.0,stop_words='english')),\n",
    "    #('vect', CountVectorizer(ngram_range=(3,6),analyzer='char_wb', min_df=10, max_df=0.95,stop_words='english')),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    (\"svc\", SVC(kernel='linear', probability=True, class_weight = 'balanced'))\n",
    "    #(\"svc\", SVC(kernel='linear', probability=True))\n",
    "])\n",
    "\n",
    "limit = int(0.8*len(X))\n",
    "\n",
    "X_train = X[:limit]\n",
    "X_test = X[limit:]\n",
    "\n",
    "y_train = y[:limit]\n",
    "y_test = y[limit:]\n",
    "\n",
    "model_svc_tfidf.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = model_svc_tfidf.predict(X_test)\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "acc, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.54466230936819171, 0.47242990028776016, 234, 459)\n",
      "(50.980392156862742, '% - ', 25)\n",
      "\n",
      "\n",
      "('Rejected good ones: ', 17, '/', 59)\n",
      "('Accepted wrong ones:', 192, '/', 400)\n",
      "\n",
      "\n",
      "('Rejected wrong ones: ', 208, '/', 400)\n",
      "('Accepted good ones:', 42, '/', 59)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.94092044,  0.05907956],\n",
       "       [ 0.84434891,  0.15565109],\n",
       "       [ 0.54224251,  0.45775749],\n",
       "       [ 0.83406955,  0.16593045],\n",
       "       [ 0.73648449,  0.26351551]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted_proba = model_svc_tfidf.predict_proba(X_test)\n",
    "#y_predicted = (y_predicted_proba[:,1] > 0.12)\n",
    "y_predicted = (y_predicted_proba[:,1] > 0.103)\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected good ones: \", len(X_test_df[(y_predicted != y_test) & (y_predicted == False)]), \"/\", sum(y_test))\n",
    "print(\"Accepted wrong ones:\", len(X_test_df[(y_predicted != y_test) & (y_predicted == True)]), \"/\", len(y_test)-sum(y_test))\n",
    "print(\"\\n\")\n",
    "print(\"Rejected wrong ones: \", len(X_test_df[(y_predicted == y_test) & (y_predicted == False)]), \"/\", len(y_test)-sum(y_test))\n",
    "print(\"Accepted good ones:\", len(X_test_df[(y_predicted == y_test) & (y_predicted == True)]), \"/\", sum(y_test))\n",
    "\n",
    "y_predicted_proba[0:5]\n",
    "\n",
    "#(0.62077922077922076, 0.55417162908266104, 162, 385)\n",
    "#(42.077922077922075, '% - ', 21)\n",
    "#('Rejected good ones: ', 15, '/', 46)\n",
    "#('Accepted wrong ones:', 131, '/', 339)\n",
    "#('Rejected wrong ones: ', 208, '/', 339)\n",
    "#('Accepted good ones:', 31, '/', 46)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.75381263616557737, 0.72792879524256249)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "\n",
    "model_svc_tfidf = Pipeline([\n",
    "    #('vect', CountVectorizer(ngram_range=(1,3), min_df=1, max_df=1.0,stop_words='english')),\n",
    "    ('vect', CountVectorizer(ngram_range=(3,6),analyzer='char_wb', min_df=10, max_df=0.95,stop_words='english')),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    (\"svc\", SVC(kernel='linear', probability=True, class_weight = 'balanced'))\n",
    "    #(\"svc\", SVC(kernel='linear', probability=True))\n",
    "])\n",
    "\n",
    "limit = int(0.8*len(X))\n",
    "\n",
    "X_train = X[:limit]\n",
    "X_test = X[limit:]\n",
    "\n",
    "y_train = y[:limit]\n",
    "y_test = y[limit:]\n",
    "\n",
    "model_svc_tfidf.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = model_svc_tfidf.predict(X_test)\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "acc, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.54466230936819171, 0.47377147015084436, 242, 459)\n",
      "(52.723311546840961, '% - ', 26)\n",
      "\n",
      "\n",
      "('Rejected good ones: ', 13, '/', 59)\n",
      "('Accepted wrong ones:', 196, '/', 400)\n",
      "\n",
      "\n",
      "('Rejected wrong ones: ', 204, '/', 400)\n",
      "('Accepted good ones:', 46, '/', 59)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.93441022,  0.06558978],\n",
       "       [ 0.88950514,  0.11049486],\n",
       "       [ 0.74734157,  0.25265843],\n",
       "       [ 0.777364  ,  0.222636  ],\n",
       "       [ 0.82147691,  0.17852309]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted_proba = model_svc_tfidf.predict_proba(X_test)\n",
    "#y_predicted = (y_predicted_proba[:,1] > 0.12)\n",
    "y_predicted = (y_predicted_proba[:,1] > 0.111)\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected good ones: \", len(X_test_df[(y_predicted != y_test) & (y_predicted == False)]), \"/\", sum(y_test))\n",
    "print(\"Accepted wrong ones:\", len(X_test_df[(y_predicted != y_test) & (y_predicted == True)]), \"/\", len(y_test)-sum(y_test))\n",
    "print(\"\\n\")\n",
    "print(\"Rejected wrong ones: \", len(X_test_df[(y_predicted == y_test) & (y_predicted == False)]), \"/\", len(y_test)-sum(y_test))\n",
    "print(\"Accepted good ones:\", len(X_test_df[(y_predicted == y_test) & (y_predicted == True)]), \"/\", sum(y_test))\n",
    "\n",
    "y_predicted_proba[0:5]\n",
    "\n",
    "#(0.62077922077922076, 0.55417162908266104, 162, 385)\n",
    "#(42.077922077922075, '% - ', 21)\n",
    "#('Rejected good ones: ', 15, '/', 46)\n",
    "#('Accepted wrong ones:', 131, '/', 339)\n",
    "#('Rejected wrong ones: ', 208, '/', 339)\n",
    "#('Accepted good ones:', 31, '/', 46)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count -> SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.88017429193899777, 0.92530370731874068)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "\n",
    "model_svc = Pipeline([\n",
    "    #('vect', CountVectorizer()),\n",
    "    ('vect', CountVectorizer(ngram_range=(1,3), min_df=1, max_df=1.0,stop_words='english')),\n",
    "    #('vect', CountVectorizer(ngram_range=(3,6),analyzer='char_wb', min_df=10, max_df=0.95,stop_words='english')),\n",
    "    #('tfidf', TfidfTransformer()),\n",
    "    (\"svc\", SVC(kernel='linear', probability=True, class_weight = 'balanced'))\n",
    "    #(\"svc\", SVC(kernel='linear', probability=True))\n",
    "])\n",
    "\n",
    "limit = int(0.8*len(X))\n",
    "\n",
    "X_train = X[:limit]\n",
    "X_test = X[limit:]\n",
    "\n",
    "y_train = y[:limit]\n",
    "y_test = y[limit:]\n",
    "\n",
    "model_svc.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = model_svc.predict(X_test)\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "acc, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.52723311546840956, 0.45441338588939351, 246, 459)\n",
      "(53.594771241830067, '% - ', 26)\n",
      "\n",
      "\n",
      "('Rejected good ones: ', 15, '/', 59)\n",
      "('Accepted wrong ones:', 202, '/', 400)\n",
      "\n",
      "\n",
      "('Rejected wrong ones: ', 198, '/', 400)\n",
      "('Accepted good ones:', 44, '/', 59)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.93393117,  0.06606883],\n",
       "       [ 0.80241335,  0.19758665],\n",
       "       [ 0.85912636,  0.14087364],\n",
       "       [ 0.90998925,  0.09001075],\n",
       "       [ 0.82931786,  0.17068214]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted_proba = model_svc.predict_proba(X_test)\n",
    "#y_predicted = (y_predicted_proba[:,1] > 0.12)\n",
    "y_predicted = (y_predicted_proba[:,1] > 0.11)\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected good ones: \", len(X_test_df[(y_predicted != y_test) & (y_predicted == False)]), \"/\", sum(y_test))\n",
    "print(\"Accepted wrong ones:\", len(X_test_df[(y_predicted != y_test) & (y_predicted == True)]), \"/\", len(y_test)-sum(y_test))\n",
    "print(\"\\n\")\n",
    "print(\"Rejected wrong ones: \", len(X_test_df[(y_predicted == y_test) & (y_predicted == False)]), \"/\", len(y_test)-sum(y_test))\n",
    "print(\"Accepted good ones:\", len(X_test_df[(y_predicted == y_test) & (y_predicted == True)]), \"/\", sum(y_test))\n",
    "\n",
    "y_predicted_proba[0:5]\n",
    "\n",
    "#(0.62077922077922076, 0.55417162908266104, 162, 385)\n",
    "#(42.077922077922075, '% - ', 21)\n",
    "#('Rejected good ones: ', 15, '/', 46)\n",
    "#('Accepted wrong ones:', 131, '/', 339)\n",
    "#('Rejected wrong ones: ', 208, '/', 339)\n",
    "#('Accepted good ones:', 31, '/', 46)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embeddings preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import (Input, Embedding, SimpleRNN, Dense, Activation, TimeDistributed, Bidirectional, LSTM, GaussianNoise)\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model\n",
    "from keras.utils import plot_model #Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATASETS_DIR = '../ml-research/datasets/'\n",
    "GLOVE_DIR = DATASETS_DIR+'glove.6B/'\n",
    "WIKI_EN_DIR = DATASETS_DIR+'wiki.en/'\n",
    "#embeddings_file = os.path.join(GLOVE_DIR, 'glove.6B.300d.txt')\n",
    "embeddings_file = os.path.join(WIKI_EN_DIR, 'wiki.en.vec')\n",
    "\n",
    "# Word embeddings' constraints\n",
    "MAX_NB_WORDS = 20000  # Number of most common words for tokenizer\n",
    "EMBEDDING_DIM = 300   # Embeddings dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras.preprocessing.text\n",
    "from string import maketrans\n",
    "\n",
    "def text_to_word_sequence(text,\n",
    "                          filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "                          lower=True, split=\" \"):\n",
    "    if lower: text = text.lower()\n",
    "    if type(text) == unicode:\n",
    "        translate_table = {ord(c): ord(t) for c,t in zip(filters, split*len(filters)) }\n",
    "    else:\n",
    "        translate_table = maketrans(filters, split * len(filters))\n",
    "    text = text.translate(translate_table)\n",
    "    seq = text.split(split)\n",
    "    return [i for i in seq if i]\n",
    "    \n",
    "keras.preprocessing.text.text_to_word_sequence = text_to_word_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24827 unique tokens.\n",
      "78\n",
      "24826\n"
     ]
    }
   ],
   "source": [
    "# Tokenizing and creating word index\n",
    "\n",
    "additional_words = ['unk', 'num']\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(X+additional_words)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "# inversing the word_index.\n",
    "index_word = dict((k,v) for v,k in word_index.items())\n",
    "\n",
    "# example\n",
    "print(word_index['adversarial'])\n",
    "print(word_index['unk'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing word vectors.\n",
      "Found 2519371 word vectors.\n",
      "Creating Word Embeddings matrix...\n",
      "Word Embeddings matrix was successfuly created.\n"
     ]
    }
   ],
   "source": [
    "import models.embedding_matrix as embedding\n",
    "\n",
    "embedding_matrix = embedding.create_embedding_matrix(embeddings_file, MAX_NB_WORDS, EMBEDDING_DIM, word_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import (Input, Embedding, SimpleRNN, Dense, Activation, TimeDistributed, Bidirectional,\n",
    "                          LSTM, GaussianNoise,Conv1D, MaxPooling1D, Flatten, Dropout)\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    'conv_units': 128,\n",
    "    'hidden_units_1': 128,\n",
    "    'hidden_units_2': 64,\n",
    "    'dropout': 0.5,\n",
    "    'pooling' : 5,\n",
    "    'gauss_stddev' : 0.0002,\n",
    "    'epochs' : 15,\n",
    "    'folds' : 5,\n",
    "    'nclasses' : 2,\n",
    "    'max_seq_len' : 300,\n",
    "    'learning_rate' : 0.001,\n",
    "    'stopwords' : True\n",
    "}\n",
    "\n",
    "hyperparameters = {\n",
    "    'conv_units': 64,\n",
    "    'hidden_units_1': 64,\n",
    "    'hidden_units_2': 32,\n",
    "    'dropout': 0.5,\n",
    "    'pooling' : 5,\n",
    "    'gauss_stddev' : 0.0002,\n",
    "    'epochs' : 15,\n",
    "    'folds' : 5,\n",
    "    'nclasses' : 2,\n",
    "    'max_seq_len' : 300,\n",
    "    'learning_rate' : 0.001,\n",
    "    'stopwords' : True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBcOF+w95RvUDAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f77a1d18b90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X_sequences = tokenizer.texts_to_sequences(X)\n",
    "X_sequences_len = []\n",
    "for item in X_sequences:\n",
    "    X_sequences_len.append(\n",
    "                            min( len(item), 1000\n",
    "                               ))\n",
    "    \n",
    "X_sequences_padded = pad_sequences(X_sequences, maxlen=hyperparameters['max_seq_len'])\n",
    "\n",
    "plt.hist(X_sequences_len, 50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn import preprocessing\n",
    "\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "label_encoder.fit(y)\n",
    "\n",
    "y_num = label_encoder.transform(y)\n",
    "y_matrix = to_categorical(y_num,hyperparameters['nclasses'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1832 samples, validate on 459 samples\n",
      "Epoch 1/15\n",
      "1832/1832 [==============================] - 6s - loss: 1.1941 - categorical_accuracy: 0.4623 - val_loss: 0.6931 - val_categorical_accuracy: 0.4357\n",
      "Epoch 2/15\n",
      "1832/1832 [==============================] - 6s - loss: 1.1868 - categorical_accuracy: 0.7582 - val_loss: 0.6293 - val_categorical_accuracy: 0.8453\n",
      "Epoch 3/15\n",
      "1832/1832 [==============================] - 6s - loss: 1.1767 - categorical_accuracy: 0.6365 - val_loss: 0.6386 - val_categorical_accuracy: 0.7081\n",
      "Epoch 4/15\n",
      "1832/1832 [==============================] - 6s - loss: 1.1599 - categorical_accuracy: 0.6927 - val_loss: 0.6496 - val_categorical_accuracy: 0.5599\n",
      "Epoch 5/15\n",
      "1832/1832 [==============================] - 6s - loss: 1.1438 - categorical_accuracy: 0.5852 - val_loss: 0.7380 - val_categorical_accuracy: 0.3508\n",
      "Epoch 6/15\n",
      "1832/1832 [==============================] - 6s - loss: 1.0997 - categorical_accuracy: 0.6365 - val_loss: 0.5047 - val_categorical_accuracy: 0.7560\n",
      "Epoch 7/15\n",
      "1832/1832 [==============================] - 6s - loss: 1.0127 - categorical_accuracy: 0.6807 - val_loss: 0.7313 - val_categorical_accuracy: 0.4989\n",
      "Epoch 8/15\n",
      "1832/1832 [==============================] - 6s - loss: 0.9327 - categorical_accuracy: 0.6643 - val_loss: 0.5012 - val_categorical_accuracy: 0.7516\n",
      "Epoch 9/15\n",
      "1832/1832 [==============================] - 6s - loss: 0.7777 - categorical_accuracy: 0.7686 - val_loss: 0.6196 - val_categorical_accuracy: 0.6427\n",
      "Epoch 10/15\n",
      "1832/1832 [==============================] - 6s - loss: 0.5836 - categorical_accuracy: 0.8401 - val_loss: 0.4822 - val_categorical_accuracy: 0.8192\n",
      "Epoch 11/15\n",
      "1832/1832 [==============================] - 6s - loss: 0.3890 - categorical_accuracy: 0.8930 - val_loss: 0.4840 - val_categorical_accuracy: 0.8279\n",
      "Epoch 12/15\n",
      "1832/1832 [==============================] - 6s - loss: 0.1980 - categorical_accuracy: 0.9536 - val_loss: 0.5714 - val_categorical_accuracy: 0.8431\n",
      "Epoch 13/15\n",
      "1832/1832 [==============================] - 6s - loss: 0.1001 - categorical_accuracy: 0.9831 - val_loss: 0.7828 - val_categorical_accuracy: 0.7647\n",
      "Epoch 14/15\n",
      "1832/1832 [==============================] - 6s - loss: 0.0567 - categorical_accuracy: 0.9885 - val_loss: 0.7918 - val_categorical_accuracy: 0.8497\n",
      "Epoch 15/15\n",
      "1832/1832 [==============================] - 6s - loss: 0.0371 - categorical_accuracy: 0.9956 - val_loss: 1.0029 - val_categorical_accuracy: 0.7168\n",
      "(0.71677559912854028, 0.75514678374155497)\n",
      "[[295 102]\n",
      " [ 28  34]]\n",
      "Train on 1833 samples, validate on 458 samples\n",
      "Epoch 1/15\n",
      "1833/1833 [==============================] - 6s - loss: 1.1950 - categorical_accuracy: 0.6323 - val_loss: 0.6954 - val_categorical_accuracy: 0.1834\n",
      "Epoch 2/15\n",
      "1833/1833 [==============================] - 6s - loss: 1.1853 - categorical_accuracy: 0.2897 - val_loss: 0.7051 - val_categorical_accuracy: 0.1441\n",
      "Epoch 3/15\n",
      "1833/1833 [==============================] - 6s - loss: 1.1850 - categorical_accuracy: 0.1724 - val_loss: 0.7025 - val_categorical_accuracy: 0.1463\n",
      "Epoch 4/15\n",
      "1833/1833 [==============================] - 6s - loss: 1.1830 - categorical_accuracy: 0.4479 - val_loss: 0.6866 - val_categorical_accuracy: 0.5568\n",
      "Epoch 5/15\n",
      "1833/1833 [==============================] - 6s - loss: 1.1743 - categorical_accuracy: 0.6809 - val_loss: 0.7001 - val_categorical_accuracy: 0.3821\n",
      "Epoch 6/15\n",
      "1833/1833 [==============================] - 6s - loss: 1.1566 - categorical_accuracy: 0.6077 - val_loss: 0.5932 - val_categorical_accuracy: 0.7096\n",
      "Epoch 7/15\n",
      "1833/1833 [==============================] - 6s - loss: 1.1154 - categorical_accuracy: 0.5597 - val_loss: 0.5708 - val_categorical_accuracy: 0.8166\n",
      "Epoch 8/15\n",
      "1833/1833 [==============================] - 6s - loss: 1.0663 - categorical_accuracy: 0.6748 - val_loss: 0.5892 - val_categorical_accuracy: 0.6747\n",
      "Epoch 9/15\n",
      "1833/1833 [==============================] - 6s - loss: 0.9628 - categorical_accuracy: 0.7305 - val_loss: 0.8566 - val_categorical_accuracy: 0.4869\n",
      "Epoch 10/15\n",
      "1833/1833 [==============================] - 6s - loss: 0.8669 - categorical_accuracy: 0.7523 - val_loss: 0.5327 - val_categorical_accuracy: 0.7642\n",
      "Epoch 11/15\n",
      "1833/1833 [==============================] - 6s - loss: 0.6979 - categorical_accuracy: 0.8189 - val_loss: 0.4433 - val_categorical_accuracy: 0.8581\n",
      "Epoch 12/15\n",
      "1833/1833 [==============================] - 6s - loss: 0.7151 - categorical_accuracy: 0.8358 - val_loss: 0.5720 - val_categorical_accuracy: 0.7336\n",
      "Epoch 13/15\n",
      "1833/1833 [==============================] - 6s - loss: 0.4773 - categorical_accuracy: 0.8947 - val_loss: 0.5122 - val_categorical_accuracy: 0.8253\n",
      "Epoch 14/15\n",
      "1833/1833 [==============================] - 6s - loss: 0.2914 - categorical_accuracy: 0.9373 - val_loss: 0.5680 - val_categorical_accuracy: 0.8013\n",
      "Epoch 15/15\n",
      "1833/1833 [==============================] - 6s - loss: 0.1809 - categorical_accuracy: 0.9651 - val_loss: 0.7196 - val_categorical_accuracy: 0.7249\n",
      "(0.72489082969432317, 0.75647708629882504)\n",
      "[[299  93]\n",
      " [ 33  33]]\n",
      "Train on 1833 samples, validate on 458 samples\n",
      "Epoch 1/15\n",
      "1833/1833 [==============================] - 6s - loss: 1.1945 - categorical_accuracy: 0.8276 - val_loss: 0.6874 - val_categorical_accuracy: 0.8646\n",
      "Epoch 2/15\n",
      "1833/1833 [==============================] - 6s - loss: 1.1821 - categorical_accuracy: 0.7921 - val_loss: 0.5824 - val_categorical_accuracy: 0.8646\n",
      "Epoch 3/15\n",
      "1833/1833 [==============================] - 6s - loss: 1.1908 - categorical_accuracy: 0.6858 - val_loss: 0.6152 - val_categorical_accuracy: 0.8690\n",
      "Epoch 4/15\n",
      "1833/1833 [==============================] - 6s - loss: 1.1635 - categorical_accuracy: 0.7409 - val_loss: 0.6315 - val_categorical_accuracy: 0.7118\n",
      "Epoch 5/15\n",
      "1833/1833 [==============================] - 6s - loss: 1.1466 - categorical_accuracy: 0.7381 - val_loss: 0.6237 - val_categorical_accuracy: 0.6528\n",
      "Epoch 6/15\n",
      "1833/1833 [==============================] - 6s - loss: 1.1079 - categorical_accuracy: 0.6989 - val_loss: 0.5203 - val_categorical_accuracy: 0.7402\n",
      "Epoch 7/15\n",
      "1833/1833 [==============================] - 6s - loss: 1.0371 - categorical_accuracy: 0.7065 - val_loss: 0.5170 - val_categorical_accuracy: 0.7511\n",
      "Epoch 8/15\n",
      "1833/1833 [==============================] - 6s - loss: 0.9483 - categorical_accuracy: 0.7370 - val_loss: 0.6842 - val_categorical_accuracy: 0.5087\n",
      "Epoch 9/15\n",
      "1833/1833 [==============================] - 6s - loss: 0.7851 - categorical_accuracy: 0.7632 - val_loss: 0.5102 - val_categorical_accuracy: 0.7511\n",
      "Epoch 10/15\n",
      "1833/1833 [==============================] - 6s - loss: 0.6797 - categorical_accuracy: 0.7883 - val_loss: 0.5653 - val_categorical_accuracy: 0.7249\n",
      "Epoch 11/15\n",
      "1833/1833 [==============================] - 6s - loss: 0.5007 - categorical_accuracy: 0.8696 - val_loss: 0.5746 - val_categorical_accuracy: 0.7904\n",
      "Epoch 12/15\n",
      "1833/1833 [==============================] - 6s - loss: 0.3401 - categorical_accuracy: 0.9209 - val_loss: 0.7038 - val_categorical_accuracy: 0.8537\n",
      "Epoch 13/15\n",
      "1833/1833 [==============================] - 6s - loss: 0.3092 - categorical_accuracy: 0.9165 - val_loss: 0.7158 - val_categorical_accuracy: 0.8755\n",
      "Epoch 14/15\n",
      "1833/1833 [==============================] - 6s - loss: 0.1914 - categorical_accuracy: 0.9569 - val_loss: 0.7457 - val_categorical_accuracy: 0.7882\n",
      "Epoch 15/15\n",
      "1833/1833 [==============================] - 6s - loss: 0.1275 - categorical_accuracy: 0.9744 - val_loss: 0.8633 - val_categorical_accuracy: 0.8122\n",
      "(0.81222707423580787, 0.80956931674383559)\n",
      "[[355  41]\n",
      " [ 45  17]]\n",
      "Train on 1833 samples, validate on 458 samples\n",
      "Epoch 1/15\n",
      "1833/1833 [==============================] - 6s - loss: 1.1792 - categorical_accuracy: 0.8423 - val_loss: 0.6922 - val_categorical_accuracy: 0.7882\n",
      "Epoch 2/15\n",
      "1833/1833 [==============================] - 6s - loss: 1.1748 - categorical_accuracy: 0.7245 - val_loss: 0.6909 - val_categorical_accuracy: 0.7991\n",
      "Epoch 3/15\n",
      "1833/1833 [==============================] - 6s - loss: 1.1713 - categorical_accuracy: 0.7556 - val_loss: 0.6378 - val_categorical_accuracy: 0.8450\n",
      "Epoch 4/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1833/1833 [==============================] - 6s - loss: 1.1651 - categorical_accuracy: 0.6683 - val_loss: 0.5995 - val_categorical_accuracy: 0.8493\n",
      "Epoch 5/15\n",
      "1833/1833 [==============================] - 6s - loss: 1.1382 - categorical_accuracy: 0.7087 - val_loss: 0.7107 - val_categorical_accuracy: 0.2817\n",
      "Epoch 6/15\n",
      "1833/1833 [==============================] - 6s - loss: 1.1429 - categorical_accuracy: 0.5657 - val_loss: 0.7001 - val_categorical_accuracy: 0.3646\n",
      "Epoch 7/15\n",
      "1833/1833 [==============================] - 6s - loss: 1.0960 - categorical_accuracy: 0.6688 - val_loss: 0.6847 - val_categorical_accuracy: 0.4258\n",
      "Epoch 8/15\n",
      "1833/1833 [==============================] - 6s - loss: 1.0494 - categorical_accuracy: 0.6427 - val_loss: 0.7576 - val_categorical_accuracy: 0.4061\n",
      "Epoch 9/15\n",
      "1833/1833 [==============================] - 6s - loss: 0.9628 - categorical_accuracy: 0.6901 - val_loss: 0.6551 - val_categorical_accuracy: 0.5655\n",
      "Epoch 10/15\n",
      "1833/1833 [==============================] - 6s - loss: 0.8211 - categorical_accuracy: 0.7387 - val_loss: 0.5440 - val_categorical_accuracy: 0.7511\n",
      "Epoch 11/15\n",
      "1833/1833 [==============================] - 6s - loss: 0.6427 - categorical_accuracy: 0.8178 - val_loss: 0.5309 - val_categorical_accuracy: 0.7904\n",
      "Epoch 12/15\n",
      "1833/1833 [==============================] - 6s - loss: 0.4354 - categorical_accuracy: 0.8843 - val_loss: 0.6902 - val_categorical_accuracy: 0.7293\n",
      "Epoch 13/15\n",
      "1833/1833 [==============================] - 6s - loss: 0.2813 - categorical_accuracy: 0.9307 - val_loss: 0.8197 - val_categorical_accuracy: 0.8253\n",
      "Epoch 14/15\n",
      "1833/1833 [==============================] - 6s - loss: 0.2344 - categorical_accuracy: 0.9482 - val_loss: 0.7484 - val_categorical_accuracy: 0.7882\n",
      "Epoch 15/15\n",
      "1833/1833 [==============================] - 6s - loss: 0.2578 - categorical_accuracy: 0.9416 - val_loss: 0.7110 - val_categorical_accuracy: 0.8122\n",
      "(0.81222707423580787, 0.79595517548218853)\n",
      "[[356  31]\n",
      " [ 55  16]]\n",
      "Train on 1833 samples, validate on 458 samples\n",
      "Epoch 1/15\n",
      "1833/1833 [==============================] - 6s - loss: 1.1890 - categorical_accuracy: 0.5739 - val_loss: 0.6894 - val_categorical_accuracy: 0.7511\n",
      "Epoch 2/15\n",
      "1833/1833 [==============================] - 6s - loss: 1.1872 - categorical_accuracy: 0.2591 - val_loss: 0.6952 - val_categorical_accuracy: 0.3122\n",
      "Epoch 3/15\n",
      "1833/1833 [==============================] - 6s - loss: 1.1848 - categorical_accuracy: 0.2891 - val_loss: 0.6797 - val_categorical_accuracy: 0.7140\n",
      "Epoch 4/15\n",
      "1833/1833 [==============================] - 6s - loss: 1.1641 - categorical_accuracy: 0.6050 - val_loss: 0.6800 - val_categorical_accuracy: 0.5109\n",
      "Epoch 5/15\n",
      "1833/1833 [==============================] - 6s - loss: 1.1761 - categorical_accuracy: 0.5079 - val_loss: 0.7032 - val_categorical_accuracy: 0.4651\n",
      "Epoch 6/15\n",
      "1833/1833 [==============================] - 6s - loss: 1.1256 - categorical_accuracy: 0.7610 - val_loss: 0.6586 - val_categorical_accuracy: 0.5502\n",
      "Epoch 7/15\n",
      "1833/1833 [==============================] - 6s - loss: 1.0829 - categorical_accuracy: 0.6645 - val_loss: 0.4836 - val_categorical_accuracy: 0.8035\n",
      "Epoch 8/15\n",
      "1833/1833 [==============================] - 6s - loss: 0.9896 - categorical_accuracy: 0.6934 - val_loss: 0.7642 - val_categorical_accuracy: 0.5240\n",
      "Epoch 9/15\n",
      "1833/1833 [==============================] - 6s - loss: 0.9184 - categorical_accuracy: 0.7158 - val_loss: 0.7107 - val_categorical_accuracy: 0.5590\n",
      "Epoch 10/15\n",
      "1833/1833 [==============================] - 6s - loss: 0.7543 - categorical_accuracy: 0.8145 - val_loss: 0.6392 - val_categorical_accuracy: 0.6747\n",
      "Epoch 11/15\n",
      "1833/1833 [==============================] - 6s - loss: 0.6179 - categorical_accuracy: 0.8374 - val_loss: 0.4159 - val_categorical_accuracy: 0.8472\n",
      "Epoch 12/15\n",
      "1833/1833 [==============================] - 6s - loss: 0.4012 - categorical_accuracy: 0.9073 - val_loss: 0.5610 - val_categorical_accuracy: 0.8100\n",
      "Epoch 13/15\n",
      "1833/1833 [==============================] - 6s - loss: 0.2507 - categorical_accuracy: 0.9356 - val_loss: 0.5380 - val_categorical_accuracy: 0.8406\n",
      "Epoch 14/15\n",
      "1833/1833 [==============================] - 6s - loss: 0.1803 - categorical_accuracy: 0.9613 - val_loss: 0.6349 - val_categorical_accuracy: 0.8515\n",
      "Epoch 15/15\n",
      "1833/1833 [==============================] - 6s - loss: 0.2654 - categorical_accuracy: 0.9340 - val_loss: 0.5954 - val_categorical_accuracy: 0.8559\n",
      "(0.85589519650655022, 0.83145623930592161)\n",
      "[[378  15]\n",
      " [ 51  14]]\n",
      "(0.85589519650655022, 0.83145623930592161)\n",
      "[[ 1683.   282.]\n",
      " [  212.   114.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "import utils.evaluation as evaluation\n",
    "from keras import metrics\n",
    "\n",
    "\n",
    "class_weight = {0 : 1.,\n",
    "    1: (len(y)-sum(y))/sum(y)}\n",
    "\n",
    "acc_list = []\n",
    "f1_list = []\n",
    "cm_summed = np.zeros((2,2))\n",
    "kf = KFold(n_splits=5, shuffle = True)\n",
    "for train_index, test_index in kf.split(X_sequences):\n",
    "    K.clear_session()\n",
    "    \n",
    "    X_sequences_padded = pad_sequences(X_sequences, maxlen=hyperparameters['max_seq_len'])\n",
    "\n",
    "    num_words = embedding_matrix.shape[0]\n",
    "    embedding_dim = embedding_matrix.shape[1]\n",
    "\n",
    "    embedding_layer = Embedding(num_words,\n",
    "                                embedding_dim,\n",
    "                                weights=[embedding_matrix],\n",
    "                                input_length=hyperparameters['max_seq_len'],\n",
    "                                trainable=False)\n",
    "\n",
    "    # train a 1D convnet with global maxpooling\n",
    "    sequence_input = Input(shape=(hyperparameters['max_seq_len'],), dtype='int32')\n",
    "    embedded_sequences = embedding_layer(sequence_input)\n",
    "\n",
    "    #x = GaussianNoise(hyperparameters['gauss_stddev'])(embedded_sequences)\n",
    "    x = embedded_sequences\n",
    "    x = Conv1D(2*hyperparameters['conv_units'], 5, activation='relu')(x)\n",
    "    x = MaxPooling1D(5)(x)\n",
    "    x = Conv1D(hyperparameters['conv_units'], 5, activation='relu')(x)\n",
    "    x = MaxPooling1D(5)(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(hyperparameters['hidden_units_1'], activation='relu')(x)\n",
    "    x = Dropout(hyperparameters['dropout'])(x)\n",
    "    x = Dense(hyperparameters['hidden_units_2'], activation='relu')(x)\n",
    "    preds = Dense(hyperparameters['nclasses'], activation='softmax')(x)\n",
    "\n",
    "    model = Model(sequence_input, preds)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=[metrics.categorical_accuracy])\n",
    "\n",
    "    \n",
    "    X_train, X_test = X_sequences_padded[train_index], X_sequences_padded[test_index]\n",
    "    y_train, y_test = y_matrix[train_index], y_matrix[test_index]\n",
    "\n",
    "    # train\n",
    "    model.fit(X_train, y_train,\n",
    "              batch_size=128,\n",
    "              epochs=hyperparameters['epochs'],\n",
    "              class_weight=class_weight,\n",
    "              validation_data=(X_test, y_test))\n",
    "\n",
    "    # run\n",
    "    ground_truth = y_test.argmax(1)\n",
    "    predictions = [list(map(lambda x: x, model.predict_on_batch(np.asarray([x])).argmax(1)))[0] \\\n",
    "            for x in X_test]\n",
    "    \n",
    "    \n",
    "    acc = evaluation.accuracy(ground_truth, predictions)\n",
    "    f1 = evaluation.eval_f1_score(ground_truth, predictions)    \n",
    "    cm = evaluation.cm_matrix(ground_truth, predictions)\n",
    "    acc_list.append(acc)\n",
    "    f1_list.append(f1)\n",
    "    cm_summed = cm_summed + cm\n",
    "    print(acc, f1)\n",
    "    print(cm)\n",
    "    \n",
    "    #break\n",
    "    #del model\n",
    "    #K.clear_session()\n",
    "    \n",
    "print(np.asarray(acc).mean(), np.asarray(f1).mean())\n",
    "print(cm_summed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ground_truth = y_test.argmax(1)\n",
    "predictions = [list(map(lambda x: x, model.predict_on_batch(np.asarray([x]))))[0] \\\n",
    "        for x in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.8493449781659389, 0.87193668889072495, 32, 458)\n",
      "(6.9868995633187776, '% - ', 3)\n",
      "\n",
      "\n",
      "('Rejected good ones: ', 51, '/', 65)\n",
      "('Accepted wrong ones:', 18, '/', 393)\n",
      "\n",
      "\n",
      "('Rejected wrong ones: ', 375, '/', 393)\n",
      "('Accepted good ones:', 14, '/', 65)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.98890406,  0.01109599],\n",
       "       [ 0.99792647,  0.00207355],\n",
       "       [ 0.72244519,  0.27755478],\n",
       "       [ 0.99236143,  0.00763849],\n",
       "       [ 0.73416519,  0.26583484]], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted_proba_np = np.asarray(predictions)\n",
    "#y_predicted = (y_predicted_proba_np[:,1] > 0.001)\n",
    "y_predicted = (y_predicted_proba_np[:,1] > 0.4791)\n",
    "\n",
    "acc = accuracy_score(y_predicted, ground_truth)\n",
    "f1 = f1_score(y_predicted, ground_truth, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected good ones: \", len(X_test_df[(y_predicted != ground_truth) & (y_predicted == False)]), \"/\", sum(ground_truth))\n",
    "print(\"Accepted wrong ones:\", len(X_test_df[(y_predicted != ground_truth) & (y_predicted == True)]), \"/\", len(ground_truth)-sum(ground_truth))\n",
    "print(\"\\n\")\n",
    "print(\"Rejected wrong ones: \", len(X_test_df[(y_predicted == ground_truth) & (y_predicted == False)]), \"/\", len(ground_truth)-sum(ground_truth))\n",
    "print(\"Accepted good ones:\", len(X_test_df[(y_predicted == ground_truth) & (y_predicted == True)]), \"/\", sum(ground_truth))\n",
    "\n",
    "# 15% bezbolesnie odrzucic - 0.000008\n",
    "\n",
    "y_predicted_proba_np[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    'conv_units': 128,\n",
    "    'hidden_units_1': 128,\n",
    "    'hidden_units_2': 64,\n",
    "    'dropout': 0.5,\n",
    "    'pooling' : 5,\n",
    "    'gauss_stddev' : 0.0002,\n",
    "    'epochs' : 15,\n",
    "    'folds' : 5,\n",
    "    'nclasses' : 2,\n",
    "    'max_seq_len' : 300,\n",
    "    'learning_rate' : 0.001,\n",
    "    'stopwords' : True\n",
    "}\n",
    "\n",
    "hyperparameters = {\n",
    "    'conv_units': 64,\n",
    "    'hidden_units_1': 64,\n",
    "    'hidden_units_2': 32,\n",
    "    'dropout': 0.5,\n",
    "    'pooling' : 5,\n",
    "    'gauss_stddev' : 0.0002,\n",
    "    'epochs' : 5,\n",
    "    'folds' : 5,\n",
    "    'nclasses' : 2,\n",
    "    'max_seq_len' : 300,\n",
    "    'learning_rate' : 0.001,\n",
    "    'stopwords' : True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW BEST: epoch 0 valid F1 =  0.777536276565 in 82.3033540249 (sec)                               \n",
      "[learning] epoch 1 >> 0.05% completed in 0.07 (sec)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piotr.bednarski/ml-env-27-gpu/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.84749455337690627, 0.77753627656513336) 76.11 (sec)\n",
      "[[389   0]\n",
      " [ 70   0]]\n",
      "NEW BEST: epoch 0 valid F1 =  0.817447931229 in 82.3144071102 (sec)                               \n",
      "(0.87554585152838427, 0.8174479312290619)n 76.42 (sec)\n",
      "[[401   0]\n",
      " [ 57   0]]\n",
      "NEW BEST: epoch 0 valid F1 =  0.786339952989 in 81.6556458473 (sec)                               \n",
      "(0.85371179039301315, 0.78633995298861747) 74.48 (sec)\n",
      "[[391   0]\n",
      " [ 67   0]]\n",
      "NEW BEST: epoch 0 valid F1 =  0.773980000517 in 81.5137979984 (sec)                               \n",
      "(0.84497816593886466, 0.77398000051678251) 75.34 (sec)\n",
      "[[387   0]\n",
      " [ 71   0]]\n",
      "NEW BEST: epoch 0 valid F1 =  0.804969483388 in 81.173429966 (sec)                               \n",
      "(0.86681222707423577, 0.80496948338823771) 75.01 (sec)\n",
      "[[397   0]\n",
      " [ 61   0]]\n",
      "(0.86681222707423577, 0.80496948338823771)\n",
      "[[ 1965.     0.]\n",
      " [  326.     0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "import utils.evaluation as evaluation\n",
    "from keras import metrics\n",
    "import time\n",
    "import sys\n",
    "\n",
    "\n",
    "class_weight = {0 : 1.,\n",
    "    1: (len(y)-sum(y))/sum(y)}\n",
    "\n",
    "acc_list = []\n",
    "f1_list = []\n",
    "cm_summed = np.zeros((2,2))\n",
    "kf = KFold(n_splits=5, shuffle = True)\n",
    "for train_index, test_index in kf.split(X_sequences):\n",
    "    K.clear_session()\n",
    "\n",
    "    num_words = embedding_matrix.shape[0]\n",
    "    embedding_dim = embedding_matrix.shape[1]\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Embedding(num_words,\n",
    "                                embedding_dim,\n",
    "                                weights=[embedding_matrix],\n",
    "                                trainable=False))\n",
    "\n",
    "    model.add(Bidirectional(LSTM(hyperparameters['conv_units'], activation='sigmoid', return_sequences=False)))\n",
    "    model.add(GaussianNoise(hyperparameters['gauss_stddev']))\n",
    "    model.add(Dropout(hyperparameters['dropout']))\n",
    "    model.add(Dense(units=hyperparameters['hidden_units_1']))\n",
    "    if hyperparameters['hidden_units_2'] > 0:\n",
    "        model.add(Dense(units=hyperparameters['hidden_units_2']))\n",
    "    model.add(Dense(units=hyperparameters['nclasses']))\n",
    "    model.add(Activation(\"softmax\"))\n",
    "\n",
    "    optimizer = RMSprop(lr=hyperparameters['learning_rate'])\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  #optimizer='adadelta',\n",
    "                  metrics=['acc'])\n",
    "\n",
    "    #print(model.summary())\n",
    "    \n",
    "    X_train, X_test = np.asarray(X_sequences)[train_index], np.asarray(X_sequences)[test_index]\n",
    "    y_train, y_test = y_matrix[train_index], y_matrix[test_index]\n",
    "\n",
    "    # train\n",
    "    nsentences = len(X_train)\n",
    "    best_f1 = -np.inf\n",
    "    for epoch in xrange(hyperparameters['epochs']):\n",
    "        # Shuffle datasets\n",
    "        #shuffle([x_train, y_train], 42)\n",
    "        tic = time.time()\n",
    "        for i in xrange(nsentences):\n",
    "            X_lstm = np.asarray([X_train[i]])\n",
    "            Y_lstm = y_train[i].reshape((1,hyperparameters['nclasses']))\n",
    "            if X_lstm.shape[1] == 1:\n",
    "                continue # Bug with X, Y of len 1\n",
    "            model.train_on_batch(X_lstm, Y_lstm)\n",
    "            print '[learning] epoch %i >> %2.2f%%'%(epoch,(i+1)*100./nsentences)+\\\n",
    "                    ' completed in %.2f (sec)\\r'%(time.time()-tic),\n",
    "            sys.stdout.flush()\n",
    "\n",
    "        # Evaluation // back into the real world : idx -> words\n",
    "        predictions = [map(lambda x: x, model.predict_on_batch(np.asarray([x])).argmax(1))[0] \\\n",
    "            for x in X_test]\n",
    "        ground_truth = y_test.argmax(1)\n",
    "\n",
    "        f1_valid = evaluation.eval_f1_score(ground_truth, predictions)\n",
    "\n",
    "        if f1_valid > best_f1:\n",
    "            best_f1 = f1_valid\n",
    "            model.save_weights('best_model_lstm.h5', overwrite=True)\n",
    "            print 'NEW BEST: epoch', epoch, 'valid F1 = ', f1_valid, 'in', str(time.time()-tic), '(sec)',' '*30\n",
    "\n",
    "        # load best performing model\n",
    "        model.load_weights('best_model_lstm.h5')\n",
    "\n",
    "    # eval\n",
    "    ground_truth = y_test.argmax(1)\n",
    "    predictions = [list(map(lambda x: x, model.predict_on_batch(np.asarray([x])).argmax(1)))[0] \\\n",
    "            for x in X_test]\n",
    "    \n",
    "    \n",
    "    acc = evaluation.accuracy(ground_truth, predictions)\n",
    "    f1 = evaluation.eval_f1_score(ground_truth, predictions)    \n",
    "    cm = evaluation.cm_matrix(ground_truth, predictions)\n",
    "    acc_list.append(acc)\n",
    "    f1_list.append(f1)\n",
    "    cm_summed = cm_summed + cm\n",
    "    print(acc, f1)\n",
    "    print(cm)\n",
    "    \n",
    "    #break\n",
    "    #del model\n",
    "    #K.clear_session()\n",
    "    \n",
    "print(np.asarray(acc).mean(), np.asarray(f1).mean())\n",
    "print(cm_summed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ground_truth = y_test.argmax(1)\n",
    "predictions = [list(map(lambda x: x, model.predict_on_batch(np.asarray([x]))))[0] \\\n",
    "        for x in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.86681222707423577, 0.92865497076023384, 0, 458)\n",
      "(0.0, '% - ', 0)\n",
      "\n",
      "\n",
      "('Rejected good ones: ', 61, '/', 61)\n",
      "('Accepted wrong ones:', 0, '/', 397)\n",
      "\n",
      "\n",
      "('Rejected wrong ones: ', 397, '/', 397)\n",
      "('Accepted good ones:', 0, '/', 61)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piotr.bednarski/ml-env-27-gpu/lib/python2.7/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.98358256,  0.01641743],\n",
       "       [ 0.98408616,  0.01591388],\n",
       "       [ 0.9837181 ,  0.01628186],\n",
       "       [ 0.98273844,  0.01726162],\n",
       "       [ 0.98360783,  0.01639212]], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted_proba_np = np.asarray(predictions)\n",
    "#y_predicted = (y_predicted_proba_np[:,1] > 0.001)\n",
    "y_predicted = (y_predicted_proba_np[:,1] > 0.4791)\n",
    "\n",
    "acc = accuracy_score(y_predicted, ground_truth)\n",
    "f1 = f1_score(y_predicted, ground_truth, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected good ones: \", len(X_test_df[(y_predicted != ground_truth) & (y_predicted == False)]), \"/\", sum(ground_truth))\n",
    "print(\"Accepted wrong ones:\", len(X_test_df[(y_predicted != ground_truth) & (y_predicted == True)]), \"/\", len(ground_truth)-sum(ground_truth))\n",
    "print(\"\\n\")\n",
    "print(\"Rejected wrong ones: \", len(X_test_df[(y_predicted == ground_truth) & (y_predicted == False)]), \"/\", len(ground_truth)-sum(ground_truth))\n",
    "print(\"Accepted good ones:\", len(X_test_df[(y_predicted == ground_truth) & (y_predicted == True)]), \"/\", sum(ground_truth))\n",
    "\n",
    "# 15% bezbolesnie odrzucic - 0.000008\n",
    "\n",
    "y_predicted_proba_np[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extree - pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing word vectors.\n",
      "Found 1032578 word vectors.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "import models.embedding_matrix as embedding\n",
    "reload(embedding)\n",
    "\n",
    "DATASETS_DIR = '../ml-research/datasets/'\n",
    "WIKI_DIR = DATASETS_DIR+'wiki.pl/'\n",
    "embeddings_file = WIKI_DIR+'wiki.pl.vec'\n",
    "\n",
    "word2vec_pretrained = embedding.create_embedding_dictionary(embeddings_file)\n",
    "\n",
    "# train word2vec on all the texts - both training and test set\n",
    "# we're not using test labels, just texts so this is fine\n",
    "model = Word2Vec(X, size=100, window=5, min_count=5, workers=2)\n",
    "w2v_custom = {w: vec for w, vec in zip(model.wv.index2word, model.wv.syn0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "class MeanEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        self.dim = len(word2vec.itervalues().next())\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        return self \n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "            np.mean([self.word2vec[w] for w in words if w in self.word2vec] \n",
    "                    or [np.zeros(self.dim)], axis=0)\n",
    "            for words in X\n",
    "        ])\n",
    "    \n",
    "# and a tf-idf version of the same\n",
    "\n",
    "class TfidfEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        self.word2weight = None\n",
    "        self.dim = len(word2vec.itervalues().next())\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        tfidf = TfidfVectorizer(analyzer=lambda x: x)\n",
    "        tfidf.fit(X)\n",
    "        # if a word was never seen - it must be at least as infrequent\n",
    "        # as any of the known words - so the default idf is the max of \n",
    "        # known idf's\n",
    "        max_idf = max(tfidf.idf_)\n",
    "        self.word2weight = defaultdict(\n",
    "            lambda: max_idf, \n",
    "            [(w, tfidf.idf_[i]) for w, i in tfidf.vocabulary_.items()])\n",
    "    \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "                np.mean([self.word2vec[w] * self.word2weight[w]\n",
    "                         for w in words if w in self.word2vec] or\n",
    "                        [np.zeros(self.dim)], axis=0)\n",
    "                for words in X\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extra Trees classifier is almost universally great, let's stack it with our embeddings\n",
    "\n",
    "etree_w2v = Pipeline([(\"word2vec vectorizer\", MeanEmbeddingVectorizer(word2vec_pretrained)), \n",
    "                        (\"extra trees\", ExtraTreesClassifier(n_estimators=50))])\n",
    "etree_w2v_tfidf = Pipeline([(\"word2vec vectorizer\", TfidfEmbeddingVectorizer(word2vec_pretrained)), \n",
    "                        (\"svc\", ExtraTreesClassifier(n_estimators=50))])\n",
    "svc_w2v = Pipeline([(\"word2vec vectorizer\", MeanEmbeddingVectorizer(word2vec_pretrained)), \n",
    "                        (\"extra trees\", SVC(kernel=\"linear\", probability=True))])\n",
    "svc_w2v_tfidf = Pipeline([(\"word2vec vectorizer\", TfidfEmbeddingVectorizer(word2vec_pretrained)), \n",
    "                        (\"svc\", SVC(kernel=\"linear\", probability=True))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.57516339869281041, 0.50514987506555498, 206, 459)\n",
      "(44.880174291938999, '% - ', 22)\n",
      "\n",
      "\n",
      "('Rejected good ones: ', 24, '/', 59)\n",
      "('Accepted wrong ones:', 171, '/', 400)\n",
      "\n",
      "\n",
      "('Rejected wrong ones: ', 229, '/', 400)\n",
      "('Accepted good ones:', 35, '/', 59)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.88,  0.12],\n",
       "       [ 0.92,  0.08],\n",
       "       [ 0.82,  0.18],\n",
       "       [ 0.84,  0.16],\n",
       "       [ 0.8 ,  0.2 ]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "limit = int(0.8*len(X))\n",
    "\n",
    "X_train = X[:limit]\n",
    "X_test = X[limit:]\n",
    "\n",
    "y_train = y[:limit]\n",
    "y_test = y[limit:]\n",
    "\n",
    "etree_w2v.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = etree_w2v.predict(X_test)\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "\n",
    "y_predicted_proba = etree_w2v.predict_proba(X_test)\n",
    "#y_predicted = (y_predicted_proba[:,1] > 0.12)\n",
    "y_predicted = (y_predicted_proba[:,1] > 0.14)\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected good ones: \", len(X_test_df[(y_predicted != y_test) & (y_predicted == False)]), \"/\", sum(y_test))\n",
    "print(\"Accepted wrong ones:\", len(X_test_df[(y_predicted != y_test) & (y_predicted == True)]), \"/\", len(y_test)-sum(y_test))\n",
    "print(\"\\n\")\n",
    "print(\"Rejected wrong ones: \", len(X_test_df[(y_predicted == y_test) & (y_predicted == False)]), \"/\", len(y_test)-sum(y_test))\n",
    "print(\"Accepted good ones:\", len(X_test_df[(y_predicted == y_test) & (y_predicted == True)]), \"/\", sum(y_test))\n",
    "\n",
    "y_predicted_proba[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.49673202614379086, 0.42011096742383297, 250, 459)\n",
      "(54.466230936819173, '% - ', 27)\n",
      "\n",
      "\n",
      "('Rejected good ones: ', 20, '/', 59)\n",
      "('Accepted wrong ones:', 211, '/', 400)\n",
      "\n",
      "\n",
      "('Rejected wrong ones: ', 189, '/', 400)\n",
      "('Accepted good ones:', 39, '/', 59)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.84,  0.16],\n",
       "       [ 0.92,  0.08],\n",
       "       [ 0.64,  0.36],\n",
       "       [ 0.82,  0.18],\n",
       "       [ 0.78,  0.22]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "limit = int(0.8*len(X))\n",
    "\n",
    "X_train = X[:limit]\n",
    "X_test = X[limit:]\n",
    "\n",
    "y_train = y[:limit]\n",
    "y_test = y[limit:]\n",
    "\n",
    "etree_w2v_tfidf.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = etree_w2v_tfidf.predict(X_test)\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "\n",
    "y_predicted_proba = etree_w2v_tfidf.predict_proba(X_test)\n",
    "#y_predicted = (y_predicted_proba[:,1] > 0.12)\n",
    "y_predicted = (y_predicted_proba[:,1] > 0.137)\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected good ones: \", len(X_test_df[(y_predicted != y_test) & (y_predicted == False)]), \"/\", sum(y_test))\n",
    "print(\"Accepted wrong ones:\", len(X_test_df[(y_predicted != y_test) & (y_predicted == True)]), \"/\", len(y_test)-sum(y_test))\n",
    "print(\"\\n\")\n",
    "print(\"Rejected wrong ones: \", len(X_test_df[(y_predicted == y_test) & (y_predicted == False)]), \"/\", len(y_test)-sum(y_test))\n",
    "print(\"Accepted good ones:\", len(X_test_df[(y_predicted == y_test) & (y_predicted == True)]), \"/\", sum(y_test))\n",
    "\n",
    "y_predicted_proba[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.17211328976034859, 0.21444661229595413, 429, 459)\n",
      "(93.464052287581694, '% - ', 46)\n",
      "\n",
      "\n",
      "('Rejected good ones: ', 5, '/', 59)\n",
      "('Accepted wrong ones:', 375, '/', 400)\n",
      "\n",
      "\n",
      "('Rejected wrong ones: ', 25, '/', 400)\n",
      "('Accepted good ones:', 54, '/', 59)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.85762497,  0.14237503],\n",
       "       [ 0.84878176,  0.15121824],\n",
       "       [ 0.85285423,  0.14714577],\n",
       "       [ 0.85577165,  0.14422835],\n",
       "       [ 0.8724824 ,  0.1275176 ]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "limit = int(0.8*len(X))\n",
    "\n",
    "X_train = X[:limit]\n",
    "X_test = X[limit:]\n",
    "\n",
    "y_train = y[:limit]\n",
    "y_test = y[limit:]\n",
    "\n",
    "svc_w2v.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = svc_w2v.predict(X_test)\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "\n",
    "y_predicted_proba = svc_w2v.predict_proba(X_test)\n",
    "#y_predicted = (y_predicted_proba[:,1] > 0.12)\n",
    "y_predicted = (y_predicted_proba[:,1] > 0.135)\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected good ones: \", len(X_test_df[(y_predicted != y_test) & (y_predicted == False)]), \"/\", sum(y_test))\n",
    "print(\"Accepted wrong ones:\", len(X_test_df[(y_predicted != y_test) & (y_predicted == True)]), \"/\", len(y_test)-sum(y_test))\n",
    "print(\"\\n\")\n",
    "print(\"Rejected wrong ones: \", len(X_test_df[(y_predicted == y_test) & (y_predicted == False)]), \"/\", len(y_test)-sum(y_test))\n",
    "print(\"Accepted good ones:\", len(X_test_df[(y_predicted == y_test) & (y_predicted == True)]), \"/\", sum(y_test))\n",
    "\n",
    "y_predicted_proba[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.47930283224400871, 0.40262111977310061, 260, 459)\n",
      "(56.644880174291941, '% - ', 28)\n",
      "\n",
      "\n",
      "('Rejected good ones: ', 19, '/', 59)\n",
      "('Accepted wrong ones:', 220, '/', 400)\n",
      "\n",
      "\n",
      "('Rejected wrong ones: ', 180, '/', 400)\n",
      "('Accepted good ones:', 40, '/', 59)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.86786059,  0.13213941],\n",
       "       [ 0.86327764,  0.13672236],\n",
       "       [ 0.76340207,  0.23659793],\n",
       "       [ 0.79307556,  0.20692444],\n",
       "       [ 0.88066841,  0.11933159]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "limit = int(0.8*len(X))\n",
    "\n",
    "X_train = X[:limit]\n",
    "X_test = X[limit:]\n",
    "\n",
    "y_train = y[:limit]\n",
    "y_test = y[limit:]\n",
    "\n",
    "svc_w2v_tfidf.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = svc_w2v_tfidf.predict(X_test)\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "\n",
    "y_predicted_proba = svc_w2v_tfidf.predict_proba(X_test)\n",
    "#y_predicted = (y_predicted_proba[:,1] > 0.12)\n",
    "y_predicted = (y_predicted_proba[:,1] > 0.145)\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected good ones: \", len(X_test_df[(y_predicted != y_test) & (y_predicted == False)]), \"/\", sum(y_test))\n",
    "print(\"Accepted wrong ones:\", len(X_test_df[(y_predicted != y_test) & (y_predicted == True)]), \"/\", len(y_test)-sum(y_test))\n",
    "print(\"\\n\")\n",
    "print(\"Rejected wrong ones: \", len(X_test_df[(y_predicted == y_test) & (y_predicted == False)]), \"/\", len(y_test)-sum(y_test))\n",
    "print(\"Accepted good ones:\", len(X_test_df[(y_predicted == y_test) & (y_predicted == True)]), \"/\", sum(y_test))\n",
    "\n",
    "y_predicted_proba[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extra Trees classifier is almost universally great, let's stack it with our embeddings\n",
    "\n",
    "etree_w2v = Pipeline([(\"word2vec vectorizer\", MeanEmbeddingVectorizer(w2v_custom)), \n",
    "                        (\"extra trees\", ExtraTreesClassifier(n_estimators=50))])\n",
    "etree_w2v_tfidf = Pipeline([(\"word2vec vectorizer\", TfidfEmbeddingVectorizer(w2v_custom)), \n",
    "                        (\"svc\", ExtraTreesClassifier(n_estimators=50))])\n",
    "svc_w2v = Pipeline([(\"word2vec vectorizer\", MeanEmbeddingVectorizer(w2v_custom)), \n",
    "                        (\"extra trees\", SVC(kernel=\"linear\", probability=True))])\n",
    "svc_w2v_tfidf = Pipeline([(\"word2vec vectorizer\", TfidfEmbeddingVectorizer(w2v_custom)), \n",
    "                        (\"svc\", SVC(kernel=\"linear\", probability=True))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.55337690631808278, 0.48041183955555933, 216, 459)\n",
      "(47.058823529411768, '% - ', 23)\n",
      "\n",
      "\n",
      "('Rejected good ones: ', 24, '/', 59)\n",
      "('Accepted wrong ones:', 181, '/', 400)\n",
      "\n",
      "\n",
      "('Rejected wrong ones: ', 219, '/', 400)\n",
      "('Accepted good ones:', 35, '/', 59)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.82,  0.18],\n",
       "       [ 0.92,  0.08],\n",
       "       [ 0.68,  0.32],\n",
       "       [ 0.76,  0.24],\n",
       "       [ 0.82,  0.18]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "limit = int(0.8*len(X))\n",
    "\n",
    "X_train = X[:limit]\n",
    "X_test = X[limit:]\n",
    "\n",
    "y_train = y[:limit]\n",
    "y_test = y[limit:]\n",
    "\n",
    "etree_w2v.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = etree_w2v.predict(X_test)\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "\n",
    "y_predicted_proba = etree_w2v.predict_proba(X_test)\n",
    "#y_predicted = (y_predicted_proba[:,1] > 0.12)\n",
    "y_predicted = (y_predicted_proba[:,1] > 0.14)\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected good ones: \", len(X_test_df[(y_predicted != y_test) & (y_predicted == False)]), \"/\", sum(y_test))\n",
    "print(\"Accepted wrong ones:\", len(X_test_df[(y_predicted != y_test) & (y_predicted == True)]), \"/\", len(y_test)-sum(y_test))\n",
    "print(\"\\n\")\n",
    "print(\"Rejected wrong ones: \", len(X_test_df[(y_predicted == y_test) & (y_predicted == False)]), \"/\", len(y_test)-sum(y_test))\n",
    "print(\"Accepted good ones:\", len(X_test_df[(y_predicted == y_test) & (y_predicted == True)]), \"/\", sum(y_test))\n",
    "\n",
    "y_predicted_proba[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.49019607843137253, 0.41652912567945249, 265, 459)\n",
      "(57.734204793028326, '% - ', 28)\n",
      "\n",
      "\n",
      "('Rejected good ones: ', 14, '/', 59)\n",
      "('Accepted wrong ones:', 220, '/', 400)\n",
      "\n",
      "\n",
      "('Rejected wrong ones: ', 180, '/', 400)\n",
      "('Accepted good ones:', 45, '/', 59)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.9 ,  0.1 ],\n",
       "       [ 0.84,  0.16],\n",
       "       [ 0.6 ,  0.4 ],\n",
       "       [ 0.74,  0.26],\n",
       "       [ 0.82,  0.18]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "limit = int(0.8*len(X))\n",
    "\n",
    "X_train = X[:limit]\n",
    "X_test = X[limit:]\n",
    "\n",
    "y_train = y[:limit]\n",
    "y_test = y[limit:]\n",
    "\n",
    "etree_w2v_tfidf.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = etree_w2v_tfidf.predict(X_test)\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "\n",
    "y_predicted_proba = etree_w2v_tfidf.predict_proba(X_test)\n",
    "#y_predicted = (y_predicted_proba[:,1] > 0.12)\n",
    "y_predicted = (y_predicted_proba[:,1] > 0.137)\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected good ones: \", len(X_test_df[(y_predicted != y_test) & (y_predicted == False)]), \"/\", sum(y_test))\n",
    "print(\"Accepted wrong ones:\", len(X_test_df[(y_predicted != y_test) & (y_predicted == True)]), \"/\", len(y_test)-sum(y_test))\n",
    "print(\"\\n\")\n",
    "print(\"Rejected wrong ones: \", len(X_test_df[(y_predicted == y_test) & (y_predicted == False)]), \"/\", len(y_test)-sum(y_test))\n",
    "print(\"Accepted good ones:\", len(X_test_df[(y_predicted == y_test) & (y_predicted == True)]), \"/\", sum(y_test))\n",
    "\n",
    "y_predicted_proba[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.15686274509803921, 0.21831936604736449, 440, 459)\n",
      "(95.860566448801748, '% - ', 47)\n",
      "\n",
      "\n",
      "('Rejected good ones: ', 3, '/', 59)\n",
      "('Accepted wrong ones:', 384, '/', 400)\n",
      "\n",
      "\n",
      "('Rejected wrong ones: ', 16, '/', 400)\n",
      "('Accepted good ones:', 56, '/', 59)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.86527334,  0.13472666],\n",
       "       [ 0.85885273,  0.14114727],\n",
       "       [ 0.84894977,  0.15105023],\n",
       "       [ 0.8493436 ,  0.1506564 ],\n",
       "       [ 0.86885006,  0.13114994]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "limit = int(0.8*len(X))\n",
    "\n",
    "X_train = X[:limit]\n",
    "X_test = X[limit:]\n",
    "\n",
    "y_train = y[:limit]\n",
    "y_test = y[limit:]\n",
    "\n",
    "svc_w2v.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = svc_w2v.predict(X_test)\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "\n",
    "y_predicted_proba = svc_w2v.predict_proba(X_test)\n",
    "#y_predicted = (y_predicted_proba[:,1] > 0.12)\n",
    "y_predicted = (y_predicted_proba[:,1] > 0.135)\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected good ones: \", len(X_test_df[(y_predicted != y_test) & (y_predicted == False)]), \"/\", sum(y_test))\n",
    "print(\"Accepted wrong ones:\", len(X_test_df[(y_predicted != y_test) & (y_predicted == True)]), \"/\", len(y_test)-sum(y_test))\n",
    "print(\"\\n\")\n",
    "print(\"Rejected wrong ones: \", len(X_test_df[(y_predicted == y_test) & (y_predicted == False)]), \"/\", len(y_test)-sum(y_test))\n",
    "print(\"Accepted good ones:\", len(X_test_df[(y_predicted == y_test) & (y_predicted == True)]), \"/\", sum(y_test))\n",
    "\n",
    "y_predicted_proba[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.42483660130718953, 0.34597046149502186, 277, 459)\n",
      "(60.348583877995644, '% - ', 30)\n",
      "\n",
      "\n",
      "('Rejected good ones: ', 23, '/', 59)\n",
      "('Accepted wrong ones:', 241, '/', 400)\n",
      "\n",
      "\n",
      "('Rejected wrong ones: ', 159, '/', 400)\n",
      "('Accepted good ones:', 36, '/', 59)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.84304971,  0.15695029],\n",
       "       [ 0.83967855,  0.16032145],\n",
       "       [ 0.85324922,  0.14675078],\n",
       "       [ 0.81685939,  0.18314061],\n",
       "       [ 0.85141499,  0.14858501]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "limit = int(0.8*len(X))\n",
    "\n",
    "X_train = X[:limit]\n",
    "X_test = X[limit:]\n",
    "\n",
    "y_train = y[:limit]\n",
    "y_test = y[limit:]\n",
    "\n",
    "svc_w2v_tfidf.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = svc_w2v_tfidf.predict(X_test)\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "\n",
    "y_predicted_proba = svc_w2v_tfidf.predict_proba(X_test)\n",
    "#y_predicted = (y_predicted_proba[:,1] > 0.12)\n",
    "y_predicted = (y_predicted_proba[:,1] > 0.145)\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected good ones: \", len(X_test_df[(y_predicted != y_test) & (y_predicted == False)]), \"/\", sum(y_test))\n",
    "print(\"Accepted wrong ones:\", len(X_test_df[(y_predicted != y_test) & (y_predicted == True)]), \"/\", len(y_test)-sum(y_test))\n",
    "print(\"\\n\")\n",
    "print(\"Rejected wrong ones: \", len(X_test_df[(y_predicted == y_test) & (y_predicted == False)]), \"/\", len(y_test)-sum(y_test))\n",
    "print(\"Accepted good ones:\", len(X_test_df[(y_predicted == y_test) & (y_predicted == True)]), \"/\", sum(y_test))\n",
    "\n",
    "y_predicted_proba[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
