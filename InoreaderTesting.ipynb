{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from api import inoreader_api, inoreader_scraping\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape feeds starting from a concrete moment and store them in a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=7uHM43eq65sQ\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=OnOWIennSGyt\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=3xSqnMGMr6ah\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=Ai7HBZIqU4FF\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=9F3PtA3wOrNz\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=13DqSobe6n51\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=q5nNLOJ9WPyh\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=3YX7eOgiYNOR\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=z4fokuxe7fkN\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=uNcM6NTYFZ9i\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=U6j8I4tUI1Gf\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=znuyBHKIAtX3\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=CP2_t95nNRQH\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=AuRH0U6BeE1q\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=0xkMTTNB3loB\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=kYesKrW6wKI7\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=bGWSOPONjOuA\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=RnyWGWQboU7w\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=L7EFYbK85SDq\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=FkP2BoINFDx9\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=xj1mgqo6tCUg\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=ZbFTCG4fswe2\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=NQocYgW2C_IW\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=zORlKGKB7Pum\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=rqF4FzAA03mg\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=IPRnWZFl11aS\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=fCRpf98Qcd_l\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=WH_HioybeYYt\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=j6KwLaln8TbK\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=jlFS02xGmAkL\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=43RoNEf_Mxkr\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=gMtjPuBh90ty\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=WguGTt6OiTzF\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=nucn5QHsXSPM\n",
      "(200, 'OK')\n",
      "680\n"
     ]
    }
   ],
   "source": [
    "start_time = 1508112001\n",
    "feed = 'user/-/label/arXiv'\n",
    "file_name = 'articles_raw.json'\n",
    "\n",
    "number_scraped = inoreader_scraping.scrape(feed, start_time, file_name)\n",
    "print(number_scraped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the feeds from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open(file_name, 'r')\n",
    "json_string = f.read()\n",
    "f.close\n",
    "\n",
    "json_object = json.loads(json_string)\n",
    "all_articles = json_object['all_articles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_abstract_string(abs_dict):\n",
    "    abs_string = abs_dict['content']\n",
    "    abs_string = re.search('<p>(.*)</p>', abs_string, flags=re.DOTALL)\n",
    "    return abs_string.group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_canonical_string(canonical_list):\n",
    "    url_dict = canonical_list[0]\n",
    "    url = url_dict['href']\n",
    "    return url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create preprocessed and cleaned DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piotr.bednarski/ml-env-27-gpu/lib/python2.7/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/piotr.bednarski/ml-env-27-gpu/lib/python2.7/site-packages/ipykernel/__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/piotr.bednarski/ml-env-27-gpu/lib/python2.7/site-packages/ipykernel/__main__.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/piotr.bednarski/ml-env-27-gpu/lib/python2.7/site-packages/ipykernel/__main__.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "all_articles_pd = pd.DataFrame(all_articles)\n",
    "all_articles_pd = all_articles_pd[['canonical', 'author', 'categories', 'published', 'title', 'summary']]\n",
    "\n",
    "for i in range(len(all_articles_pd)):\n",
    "    all_articles_pd['summary'][i] = get_abstract_string(all_articles_pd['summary'][i])\n",
    "    all_articles_pd['canonical'][i] = get_canonical_string(all_articles_pd['canonical'][i])\n",
    "    \n",
    "all_articles_pd['read'] = False\n",
    "all_articles_pd['liked'] = False\n",
    "\n",
    "for i in range(len(all_articles_pd)):\n",
    "    if 'user/1005689817/state/com.google/read' in all_articles_pd['categories'][i]:\n",
    "        all_articles_pd['read'][i] = True\n",
    "    if 'user/1005689817/state/com.google/like' in all_articles_pd['categories'][i]:\n",
    "        all_articles_pd['liked'][i] = True\n",
    "\n",
    "del all_articles_pd['categories']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#all_articles_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tagged_articles_pd = all_articles_pd[all_articles_pd['read'] == True]\n",
    "\n",
    "with open('old_articles_proto2.pickle', 'rb') as f:\n",
    "    # Pickle the 'data' dictionary using the highest protocol available.\n",
    "    old_tagged_articles_pd = pickle.load(f)\n",
    "    \n",
    "tagged_articles_pd = pd.concat([tagged_articles_pd, old_tagged_articles_pd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tagged_articles_unique_pd = tagged_articles_pd.sort_values(by=['canonical', 'liked'], ascending=False).reset_index(drop=True)\n",
    "to_drop = tagged_articles_unique_pd.duplicated(subset = ['canonical'], keep='first')\n",
    "to_drop = list(to_drop[to_drop == False].index.values)\n",
    "\n",
    "tagged_articles_unique_pd = tagged_articles_unique_pd[tagged_articles_unique_pd.index.isin(to_drop)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2072\n",
      "1921\n"
     ]
    }
   ],
   "source": [
    "print(len(tagged_articles_pd))\n",
    "print(len(tagged_articles_unique_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_ = list(tagged_articles_unique_pd['author']+' '+tagged_articles_unique_pd['title']+' '+tagged_articles_unique_pd['summary'])\n",
    "y_ = list(tagged_articles_unique_pd['liked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index_shuffled = [i for i in range(len(X_))]\n",
    "random.shuffle(index_shuffled)\n",
    "X = []\n",
    "y = []\n",
    "for i in index_shuffled:\n",
    "    X.append(X_[i])\n",
    "    y.append(y_[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piotr.bednarski/ml-env-27-gpu/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/piotr.bednarski/ml-env-27-gpu/lib/python2.7/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.88051948051948048, 0.93646408839779005)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "\n",
    "\n",
    "model_nb_tfidf = Pipeline([\n",
    "    (\"tfidf_vectorizer\", TfidfVectorizer()),\\\n",
    "    (\"nb\", BernoulliNB())\n",
    "])\n",
    "\n",
    "limit = int(0.8*len(X))\n",
    "\n",
    "X_train = X[:limit]\n",
    "X_test = X[limit:]\n",
    "\n",
    "y_train = y[:limit]\n",
    "y_test = y[limit:]\n",
    "\n",
    "model_nb_tfidf.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = model_nb_tfidf.predict(X_test)\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "acc, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.88051948051948048, 0.93646408839779005, 0, 385)\n",
      "(0.0, '% - ', 0)\n",
      "\n",
      "\n",
      "('Rejected good ones: ', 46, '/', 46)\n",
      "('Accepted wrong ones:', 0, '/', 339)\n",
      "\n",
      "\n",
      "('Rejected wrong ones: ', 339, '/', 339)\n",
      "('Accepted good ones:', 0, '/', 46)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  1.00000000e+00,   1.18133160e-34],\n",
       "       [  1.00000000e+00,   7.35170919e-16],\n",
       "       [  1.00000000e+00,   5.32768237e-31],\n",
       "       [  1.00000000e+00,   4.86440164e-16],\n",
       "       [  1.00000000e+00,   3.90074658e-34],\n",
       "       [  1.00000000e+00,   7.13279499e-23],\n",
       "       [  1.00000000e+00,   1.82177062e-31],\n",
       "       [  1.00000000e+00,   1.81678132e-24],\n",
       "       [  1.00000000e+00,   4.91826925e-24],\n",
       "       [  1.00000000e+00,   4.10522696e-27],\n",
       "       [  1.00000000e+00,   3.17230768e-26],\n",
       "       [  1.00000000e+00,   6.30238887e-35],\n",
       "       [  1.00000000e+00,   3.06020941e-28],\n",
       "       [  1.00000000e+00,   1.67367766e-24],\n",
       "       [  1.00000000e+00,   2.52710551e-13],\n",
       "       [  1.00000000e+00,   8.28137608e-31],\n",
       "       [  1.00000000e+00,   1.59084546e-26],\n",
       "       [  1.00000000e+00,   1.03249087e-30],\n",
       "       [  1.00000000e+00,   5.49285943e-35],\n",
       "       [  1.00000000e+00,   1.55856405e-18]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted_proba = model_nb_tfidf.predict_proba(X_test)\n",
    "#y_predicted = (y_predicted_proba[:,1] > 0.15)\n",
    "y_predicted = (y_predicted_proba[:,1] > 0.15)\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)/len(y_predicted)*100.0,\"% - \", int(sum(y_predicted)/len(y_predicted)*50.0))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected good ones: \", len(X_test_df[(y_predicted != y_test) & (y_predicted == False)]), \"/\", sum(y_test))\n",
    "print(\"Accepted wrong ones:\", len(X_test_df[(y_predicted != y_test) & (y_predicted == True)]), \"/\", len(y_test)-sum(y_test))\n",
    "print(\"\\n\")\n",
    "print(\"Rejected wrong ones: \", len(X_test_df[(y_predicted == y_test) & (y_predicted == False)]), \"/\", len(y_test)-sum(y_test))\n",
    "print(\"Accepted good ones:\", len(X_test_df[(y_predicted == y_test) & (y_predicted == True)]), \"/\", sum(y_test))\n",
    "\n",
    "y_predicted_proba[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.83636363636363631, 0.83560472500292382)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "\n",
    "model_svc = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    (\"svc\", SVC(kernel='linear', probability=True, class_weight = 'balanced'))\n",
    "    #(\"svc\", SVC(kernel='linear', probability=True))\n",
    "])\n",
    "\n",
    "limit = int(0.8*len(X))\n",
    "\n",
    "X_train = X[:limit]\n",
    "X_test = X[limit:]\n",
    "\n",
    "y_train = y[:limit]\n",
    "y_test = y[limit:]\n",
    "\n",
    "model_svc.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = model_svc.predict(X_test)\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "acc, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.207792207792208"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_predicted)*100.0/len(y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.62077922077922076, 0.55417162908266104, 162, 385)\n",
      "(42.077922077922075, '% - ', 21)\n",
      "\n",
      "\n",
      "('Rejected good ones: ', 15, '/', 46)\n",
      "('Accepted wrong ones:', 131, '/', 339)\n",
      "\n",
      "\n",
      "('Rejected wrong ones: ', 208, '/', 339)\n",
      "('Accepted good ones:', 31, '/', 46)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.93817162,  0.06182838],\n",
       "       [ 0.84223308,  0.15776692],\n",
       "       [ 0.941168  ,  0.058832  ],\n",
       "       [ 0.61092299,  0.38907701],\n",
       "       [ 0.97170942,  0.02829058],\n",
       "       [ 0.72072388,  0.27927612],\n",
       "       [ 0.86393076,  0.13606924],\n",
       "       [ 0.54117657,  0.45882343],\n",
       "       [ 0.88251754,  0.11748246],\n",
       "       [ 0.90149347,  0.09850653],\n",
       "       [ 0.87437685,  0.12562315],\n",
       "       [ 0.94512628,  0.05487372],\n",
       "       [ 0.93473601,  0.06526399],\n",
       "       [ 0.61726959,  0.38273041],\n",
       "       [ 0.67709269,  0.32290731],\n",
       "       [ 0.85880704,  0.14119296],\n",
       "       [ 0.92850848,  0.07149152],\n",
       "       [ 0.92717007,  0.07282993],\n",
       "       [ 0.94933672,  0.05066328],\n",
       "       [ 0.90996198,  0.09003802]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted_proba = model_svc.predict_proba(X_test)\n",
    "#y_predicted = (y_predicted_proba[:,1] > 0.15)\n",
    "y_predicted = (y_predicted_proba[:,1] > 0.14)\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected good ones: \", len(X_test_df[(y_predicted != y_test) & (y_predicted == False)]), \"/\", sum(y_test))\n",
    "print(\"Accepted wrong ones:\", len(X_test_df[(y_predicted != y_test) & (y_predicted == True)]), \"/\", len(y_test)-sum(y_test))\n",
    "print(\"\\n\")\n",
    "print(\"Rejected wrong ones: \", len(X_test_df[(y_predicted == y_test) & (y_predicted == False)]), \"/\", len(y_test)-sum(y_test))\n",
    "print(\"Accepted good ones:\", len(X_test_df[(y_predicted == y_test) & (y_predicted == True)]), \"/\", sum(y_test))\n",
    "\n",
    "y_predicted_proba[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import (Input, Embedding, SimpleRNN, Dense, Activation, TimeDistributed, Bidirectional, LSTM, GaussianNoise)\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model\n",
    "from keras.utils import plot_model #Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATASETS_DIR = '../ml-research/datasets/'\n",
    "GLOVE_DIR = DATASETS_DIR+'glove.6B/'\n",
    "WIKI_EN_DIR = DATASETS_DIR+'wiki.en/'\n",
    "#embeddings_file = os.path.join(GLOVE_DIR, 'glove.6B.300d.txt')\n",
    "embeddings_file = os.path.join(WIKI_EN_DIR, 'wiki.en.vec')\n",
    "\n",
    "# Word embeddings' constraints\n",
    "MAX_NB_WORDS = 20000  # Number of most common words for tokenizer\n",
    "EMBEDDING_DIM = 300   # Embeddings dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.preprocessing.text\n",
    "from string import maketrans\n",
    "\n",
    "def text_to_word_sequence(text,\n",
    "                          filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "                          lower=True, split=\" \"):\n",
    "    if lower: text = text.lower()\n",
    "    if type(text) == unicode:\n",
    "        translate_table = {ord(c): ord(t) for c,t in zip(filters, split*len(filters)) }\n",
    "    else:\n",
    "        translate_table = maketrans(filters, split * len(filters))\n",
    "    text = text.translate(translate_table)\n",
    "    seq = text.split(split)\n",
    "    return [i for i in seq if i]\n",
    "    \n",
    "keras.preprocessing.text.text_to_word_sequence = text_to_word_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22583 unique tokens.\n",
      "138\n",
      "22582\n"
     ]
    }
   ],
   "source": [
    "# Tokenizing and creating word index\n",
    "\n",
    "additional_words = ['unk', 'num']\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(X+additional_words)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "# inversing the word_index.\n",
    "index_word = dict((k,v) for v,k in word_index.items())\n",
    "\n",
    "# example\n",
    "print(word_index['adversarial'])\n",
    "print(word_index['unk'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing word vectors.\n",
      "Found 2519371 word vectors.\n",
      "Creating Word Embeddings matrix...\n",
      "Word Embeddings matrix was successfuly created.\n"
     ]
    }
   ],
   "source": [
    "import models.embedding_matrix as embedding\n",
    "\n",
    "embedding_matrix = embedding.create_embedding_matrix(embeddings_file, MAX_NB_WORDS, EMBEDDING_DIM, word_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import (Input, Embedding, SimpleRNN, Dense, Activation, TimeDistributed, Bidirectional,\n",
    "                          LSTM, GaussianNoise,Conv1D, MaxPooling1D, Flatten, Dropout)\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    'conv_units': 128,\n",
    "    'hidden_units_1': 64,\n",
    "    'hidden_units_2': 32,\n",
    "    'dropout': 0.5,\n",
    "    'pooling' : 5,\n",
    "    'gauss_stddev' : 0.001,\n",
    "    'epochs' : 10,\n",
    "    'folds' : 5,\n",
    "    'nclasses' : 2,\n",
    "    'max_seq_len' : 300,\n",
    "    'learning_rate' : 0.01,\n",
    "    'stopwords' : True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAD8CAYAAACW/ATfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAD9hJREFUeJzt3V2MXVd5xvH/UyeEj6AS14PrxnHHrSyqgGiJRhEtCEUY\nSEoQzkUVGYnKbSNZldIWClJqg9SoF5ZMW1G4KJUskuKKNKnFh2IBpRgDiipBgvMFdhxjlzjErh2b\nUgS0VUrC24vZ0CN7nBmffY7PeNb/J43O3mvvM/P6vXi8tM7e+6SqkCQtbT836QIkSeNn2EtSAwx7\nSWqAYS9JDTDsJakBhr0kNcCwl6QGGPaS1ADDXpIacMmkCwBYsWJFTU9PT7oMSbqoPPjgg9+tqqmF\nnLsown56epp9+/ZNugxJuqgkeXKh57qMI0kNMOwlqQGGvSQ1wLCXpAYY9pLUgHnDPsmdSU4l2T/H\nsfcmqSQrBsa2JjmS5FCS60ddsCTp/C1kZv8x4IYzB5NcBbwF+M7A2NXARuCV3Xs+kmTZSCqVJA1t\n3rCvqvuA781x6G+A24DB7zXcANxTVc9U1RPAEeDaURQqSRreUGv2STYAx6vq0TMOXQk8NbB/rBuT\nJE3Qed9Bm+TFwPuYXcIZWpLNwGaANWvW9PlVGoPpLZ+dc/zo9hsvcCWSRmGYmf2vAmuBR5McBVYD\nDyX5ReA4cNXAuau7sbNU1Y6qmqmqmampBT3aQZI0pPMO+6r6ZlW9vKqmq2qa2aWaa6rqJLAb2Jjk\nsiRrgXXAAyOtWJJ03hZy6eXdwFeBVyQ5luSWc51bVQeAXcBjwOeBW6vquVEVK0kazrxr9lX1jnmO\nT5+xvw3Y1q8sSdIoeQetJDXAsJekBhj2ktQAw16SGmDYS1IDDHtJaoBhL0kNMOwlqQGGvSQ1wLCX\npAYY9pLUAMNekhpg2EtSAwx7SWqAYS9JDTDsJakBhr0kNcCwl6QGGPaS1ADDXpIaMO8Xjkt9TG/5\n7JzjR7ffeIErkdo278w+yZ1JTiXZPzD2V0keT/KNJJ9O8rKBY1uTHElyKMn14ypckrRwC1nG+Rhw\nwxlje4BXVdWrgW8BWwGSXA1sBF7ZvecjSZaNrFpJ0lDmXcapqvuSTJ8x9oWB3a8Bv9NtbwDuqapn\ngCeSHAGuBb46kmo1L5dNJM1lFB/Q/gHwz932lcBTA8eOdWNnSbI5yb4k+06fPj2CMiRJ59Ir7JO8\nH3gWuOt831tVO6pqpqpmpqam+pQhSZrH0FfjJPk94G3A+qqqbvg4cNXAaau7MS0RLhNJF6ehZvZJ\nbgBuA95eVf89cGg3sDHJZUnWAuuAB/qXKUnqY96ZfZK7geuAFUmOAbcze/XNZcCeJABfq6o/rKoD\nSXYBjzG7vHNrVT03ruIlSQuzkKtx3jHH8B3Pc/42YFufoiRJo+XjEiSpAYa9JDXAsJekBvggtMad\n61JKSUuLM3tJaoBhL0kNMOwlqQGGvSQ1wLCXpAZ4NY5Gwqt6pMXNmb0kNcCwl6QGGPaS1ADDXpIa\n4Ae0FyE/DJV0vpzZS1IDDHtJaoBhL0kNcM2+Ea7zS21zZi9JDZg37JPcmeRUkv0DY8uT7ElyuHu9\nYuDY1iRHkhxKcv24CpckLdxCZvYfA244Y2wLsLeq1gF7u32SXA1sBF7ZvecjSZaNrFpJ0lDmDfuq\nug/43hnDG4Cd3fZO4KaB8Xuq6pmqegI4Alw7ololSUMads1+ZVWd6LZPAiu77SuBpwbOO9aNSZIm\nqPcHtFVVQJ3v+5JsTrIvyb7Tp0/3LUOS9DyGDfunk6wC6F5PdePHgasGzlvdjZ2lqnZU1UxVzUxN\nTQ1ZhiRpIYYN+93Apm57E3DvwPjGJJclWQusAx7oV6Ikqa95b6pKcjdwHbAiyTHgdmA7sCvJLcCT\nwM0AVXUgyS7gMeBZ4Naqem5MtUuSFmjesK+qd5zj0PpznL8N2NanKEnSaHkHrSQ1wLCXpAYY9pLU\nAMNekhpg2EtSAwx7SWqAYS9JDfCbqnRRONc3bR3dfuMFrkS6ODmzl6QGGPaS1ADDXpIaYNhLUgMM\ne0lqgGEvSQ0w7CWpAYa9JDXAm6q0qJzr5ilJ/Tizl6QGGPaS1ADDXpIa4Jr9Iub6taRR6TWzT/Kn\nSQ4k2Z/k7iQvTLI8yZ4kh7vXK0ZVrCRpOEOHfZIrgT8BZqrqVcAyYCOwBdhbVeuAvd2+JGmC+q7Z\nXwK8KMklwIuBfwc2ADu74zuBm3r+DUlST0Ov2VfV8SR/DXwH+B/gC1X1hSQrq+pEd9pJYOVc70+y\nGdgMsGbNmmHLWBJaXJtv8d8sTVKfZZwrmJ3FrwV+CXhJkncOnlNVBdRc76+qHVU1U1UzU1NTw5Yh\nSVqAPss4bwKeqKrTVfVj4FPAbwFPJ1kF0L2e6l+mJKmPPmH/HeC1SV6cJMB64CCwG9jUnbMJuLdf\niZKkvvqs2d+f5BPAQ8CzwMPADuByYFeSW4AngZtHUagkaXi9bqqqqtuB288YfobZWb4kaZHwcQmS\n1ADDXpIa4LNxdFE71/X6R7ffeIErkRY3Z/aS1ADDXpIaYNhLUgMMe0lqgGEvSQ0w7CWpAYa9JDXA\nsJekBhj2ktQAw16SGmDYS1IDDHtJaoBhL0kNMOwlqQGGvSQ1wLCXpAYY9pLUgF5hn+RlST6R5PEk\nB5P8ZpLlSfYkOdy9XjGqYiVJw+k7s/8w8Pmq+jXg14GDwBZgb1WtA/Z2+5KkCRo67JP8PPAG4A6A\nqvrfqvo+sAHY2Z22E7ipb5GSpH76zOzXAqeBv0/ycJKPJnkJsLKqTnTnnARW9i1SktRPn7C/BLgG\n+Luqeg3wX5yxZFNVBdRcb06yOcm+JPtOnz7dowxJ0nz6hP0x4FhV3d/tf4LZ8H86ySqA7vXUXG+u\nqh1VNVNVM1NTUz3KkCTNZ+iwr6qTwFNJXtENrQceA3YDm7qxTcC9vSqUJPV2Sc/3/zFwV5IXAN8G\nfp/Z/0B2JbkFeBK4ueffkCT11Cvsq+oRYGaOQ+v7/F6pr+ktnz3nsaPbb7yAlUiLg3fQSlIDDHtJ\naoBhL0kNMOwlqQGGvSQ1wLCXpAYY9pLUAMNekhpg2EtSAwx7SWpA32fjSEveuR694GMXdDFxZi9J\nDTDsJakBhr0kNcCwl6QGGPaS1ADDXpIaYNhLUgMMe0lqgDdVqTneJKUWGfZjYJhIWmx6L+MkWZbk\n4SSf6faXJ9mT5HD3ekX/MiVJfYxizf5dwMGB/S3A3qpaB+zt9iVJE9RrGSfJauBGYBvwnm54A3Bd\nt70T+ArwZ33+jnQhnGv5TVoK+s7sPwTcBvxkYGxlVZ3otk8CK3v+DUlST0PP7JO8DThVVQ8muW6u\nc6qqktQ53r8Z2AywZs2aYcuYKGeCki4WfWb2rwPenuQocA/wxiQfB55Osgqgez0115urakdVzVTV\nzNTUVI8yJEnzGTrsq2prVa2uqmlgI/ClqnonsBvY1J22Cbi3d5WSpF7GcQftduDNSQ4Db+r2JUkT\nNJKbqqrqK8xedUNV/QewfhS/V5I0Gj4bR5Ia4OMSLiCv3pE0Kc7sJakBhr0kNcCwl6QGGPaS1ADD\nXpIaYNhLUgMMe0lqgGEvSQ0w7CWpAd5BK42YXzivxciZvSQ1wLCXpAYY9pLUAMNekhpg2EtSAwx7\nSWqAYS9JDTDsJakBhr0kNWDoO2iTXAX8A7ASKGBHVX04yXLgn4Bp4Chwc1X9Z/9SpcXF7xTWxaTP\nzP5Z4L1VdTXwWuDWJFcDW4C9VbUO2NvtS5ImaOiwr6oTVfVQt/1D4CBwJbAB2NmdthO4qW+RkqR+\nRvIgtCTTwGuA+4GVVXWiO3SS2WWeud6zGdgMsGbNmlGUIS1qPiBNk9T7A9oklwOfBN5dVT8YPFZV\nxex6/lmqakdVzVTVzNTUVN8yJEnPo1fYJ7mU2aC/q6o+1Q0/nWRVd3wVcKpfiZKkvvpcjRPgDuBg\nVX1w4NBuYBOwvXu9t1eF0hLn8o4uhD5r9q8Dfhf4ZpJHurH3MRvyu5LcAjwJ3NyvRElSX0OHfVX9\nK5BzHF4/7O+dJGdYkpYq76CVpAYY9pLUAL9wfAG8LV7Sxc6ZvSQ1wLCXpAa4jCNdZLxqTMMw7KVF\nys+KNEou40hSAwx7SWqAYS9JDTDsJakBhr0kNWBJXI3jpWiS9Pyc2UtSAwx7SWrAkljGkeRypp7f\nkg5770CUpFku40hSAwx7SWqAYS9JDRhb2Ce5IcmhJEeSbBnX35EkzW8sH9AmWQb8LfBm4Bjw9SS7\nq+qxcfw9Sec2zIUKXsGz9IzrapxrgSNV9W2AJPcAGwDDXrqIeXnn8Cbdu3Et41wJPDWwf6wbkyRN\nwMSus0+yGdjc7f4oyaFJ1TIGK4DvTrqIRci+nG1R9iQfGO/581iUPRmX8+jdXH355YW+eVxhfxy4\namB/dTf2M1W1A9gxpr8/UUn2VdXMpOtYbOzL2ezJ2ezJ3Pr2ZVzLOF8H1iVZm+QFwEZg95j+liRp\nHmOZ2VfVs0n+CPgXYBlwZ1UdGMffkiTNb2xr9lX1OeBz4/r9i9ySXJ4aAftyNntyNnsyt159SVWN\nqhBJ0iLl4xIkqQGG/RCS3JnkVJL9A2PLk+xJcrh7vWLg2NbusRGHklw/marHK8lVSb6c5LEkB5K8\nqxtvti9JXpjkgSSPdj35i2682Z78VJJlSR5O8plu354kR5N8M8kjSfZ1Y6PrS1X5c54/wBuAa4D9\nA2N/CWzptrcAH+i2rwYeBS4D1gL/Biyb9L9hDD1ZBVzTbb8U+Fb3b2+2L0CAy7vtS4H7gde23JOB\n3rwH+EfgM92+PYGjwIozxkbWF2f2Q6iq+4DvnTG8AdjZbe8EbhoYv6eqnqmqJ4AjzD5OYkmpqhNV\n9VC3/UPgILN3TTfbl5r1o2730u6naLgnAElWAzcCHx0Ybronz2NkfTHsR2dlVZ3otk8CK7vt5h4d\nkWQaeA2zM9mm+9ItVzwCnAL2VFXzPQE+BNwG/GRgrPWewOxE4ItJHuyeMAAj7MuS/lrCSamqStLk\nZU5JLgc+Cby7qn6Q5GfHWuxLVT0H/EaSlwGfTvKqM4431ZMkbwNOVdWDSa6b65zWejLg9VV1PMnL\ngT1JHh882LcvzuxH5+kkqwC611Pd+LyPjlgqklzKbNDfVVWf6oab7wtAVX0f+DJwA2335HXA25Mc\nBe4B3pjk47TdEwCq6nj3egr4NLPLMiPri2E/OruBTd32JuDegfGNSS5LshZYBzwwgfrGKrNT+DuA\ng1X1wYFDzfYlyVQ3oyfJi5j9fofHabgnVbW1qlZX1TSzj1H5UlW9k4Z7ApDkJUle+tNt4C3AfkbZ\nl0l/An0x/gB3AyeAHzO7VnYL8AvAXuAw8EVg+cD572f20/JDwG9Puv4x9eT1zK45fgN4pPt5a8t9\nAV4NPNz1ZD/w5914sz05oz/X8f9X4zTdE+BXmL265lHgAPD+UffFO2glqQEu40hSAwx7SWqAYS9J\nDTDsJakBhr0kNcCwl6QGGPaS1ADDXpIa8H/Z5Mgsx2DCNwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdbd9307050>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X_sequences = tokenizer.texts_to_sequences(X)\n",
    "X_sequences_len = []\n",
    "for item in X_sequences:\n",
    "    X_sequences_len.append(\n",
    "                            min( len(item), 1000\n",
    "                               ))\n",
    "    \n",
    "X_sequences_padded = pad_sequences(X_sequences, maxlen=hyperparameters['max_seq_len'])\n",
    "\n",
    "plt.hist(X_sequences_len, 50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn import preprocessing\n",
    "\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "label_encoder.fit(y)\n",
    "\n",
    "y_num = label_encoder.transform(y)\n",
    "y_matrix = to_categorical(y_num,hyperparameters['nclasses'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "(len(y)-sum(y))/sum(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1536 samples, validate on 385 samples\n",
      "Epoch 1/10\n",
      "1536/1536 [==============================] - 7s - loss: 1.1714 - categorical_accuracy: 0.7161 - val_loss: 0.6959 - val_categorical_accuracy: 0.3481\n",
      "Epoch 2/10\n",
      "1536/1536 [==============================] - 6s - loss: 1.1363 - categorical_accuracy: 0.6263 - val_loss: 0.6127 - val_categorical_accuracy: 0.8597\n",
      "Epoch 3/10\n",
      "1536/1536 [==============================] - 6s - loss: 1.1285 - categorical_accuracy: 0.7936 - val_loss: 0.6380 - val_categorical_accuracy: 0.8390\n",
      "Epoch 4/10\n",
      "1536/1536 [==============================] - 6s - loss: 1.0916 - categorical_accuracy: 0.7949 - val_loss: 0.6753 - val_categorical_accuracy: 0.5610\n",
      "Epoch 5/10\n",
      "1536/1536 [==============================] - 6s - loss: 1.0275 - categorical_accuracy: 0.7389 - val_loss: 0.5300 - val_categorical_accuracy: 0.7844\n",
      "Epoch 6/10\n",
      "1536/1536 [==============================] - 6s - loss: 0.9074 - categorical_accuracy: 0.7917 - val_loss: 0.7279 - val_categorical_accuracy: 0.5039\n",
      "Epoch 7/10\n",
      "1536/1536 [==============================] - 6s - loss: 0.7625 - categorical_accuracy: 0.8040 - val_loss: 0.4103 - val_categorical_accuracy: 0.8442\n",
      "Epoch 8/10\n",
      "1536/1536 [==============================] - 6s - loss: 0.5018 - categorical_accuracy: 0.9180 - val_loss: 0.4822 - val_categorical_accuracy: 0.7714\n",
      "Epoch 9/10\n",
      "1536/1536 [==============================] - 6s - loss: 0.2806 - categorical_accuracy: 0.9603 - val_loss: 0.4842 - val_categorical_accuracy: 0.8026\n",
      "Epoch 10/10\n",
      "1536/1536 [==============================] - 6s - loss: 0.1533 - categorical_accuracy: 0.9792 - val_loss: 0.6006 - val_categorical_accuracy: 0.8519\n",
      "(0.8519480519480519, 0.80203713140428434)\n",
      "[[ 326.    6.]\n",
      " [  51.    2.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "import utils.evaluation as evaluation\n",
    "from keras import metrics\n",
    "\n",
    "\n",
    "class_weight = {0 : 1.,\n",
    "    1: (len(y)-sum(y))/sum(y)}\n",
    "\n",
    "acc_list = []\n",
    "f1_list = []\n",
    "cm_summed = np.zeros((2,2))\n",
    "kf = KFold(n_splits=5, shuffle = True)\n",
    "for train_index, test_index in kf.split(X_sequences):\n",
    "    K.clear_session()\n",
    "    \n",
    "    X_sequences_padded = pad_sequences(X_sequences, maxlen=hyperparameters['max_seq_len'])\n",
    "\n",
    "    num_words = embedding_matrix.shape[0]\n",
    "    embedding_dim = embedding_matrix.shape[1]\n",
    "\n",
    "    embedding_layer = Embedding(num_words,\n",
    "                                embedding_dim,\n",
    "                                weights=[embedding_matrix],\n",
    "                                input_length=hyperparameters['max_seq_len'],\n",
    "                                trainable=False)\n",
    "\n",
    "    # train a 1D convnet with global maxpooling\n",
    "    sequence_input = Input(shape=(hyperparameters['max_seq_len'],), dtype='int32')\n",
    "    embedded_sequences = embedding_layer(sequence_input)\n",
    "\n",
    "    #x = GaussianNoise(hyperparameters['gauss_stddev'])(embedded_sequences)\n",
    "    x = embedded_sequences\n",
    "    x = Conv1D(hyperparameters['conv_units'], 7, activation='relu')(x)\n",
    "    x = MaxPooling1D(7)(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(hyperparameters['hidden_units_1'], activation='relu')(x)\n",
    "    x = Dropout(hyperparameters['dropout'])(x)\n",
    "    x = Dense(hyperparameters['hidden_units_2'], activation='relu')(x)\n",
    "    preds = Dense(hyperparameters['nclasses'], activation='softmax')(x)\n",
    "\n",
    "    model = Model(sequence_input, preds)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=[metrics.categorical_accuracy])\n",
    "\n",
    "    \n",
    "    X_train, X_test = X_sequences_padded[train_index], X_sequences_padded[test_index]\n",
    "    y_train, y_test = y_matrix[train_index], y_matrix[test_index]\n",
    "\n",
    "    # train\n",
    "    model.fit(X_train, y_train,\n",
    "              batch_size=128,\n",
    "              epochs=hyperparameters['epochs'],\n",
    "              class_weight=class_weight,\n",
    "              validation_data=(X_test, y_test))\n",
    "\n",
    "    # run\n",
    "    ground_truth = y_test.argmax(1)\n",
    "    predictions = [list(map(lambda x: x, model.predict_on_batch(np.asarray([x])).argmax(1)))[0] \\\n",
    "            for x in X_test]\n",
    "    \n",
    "    \n",
    "    acc = evaluation.accuracy(ground_truth, predictions)\n",
    "    f1 = evaluation.eval_f1_score(ground_truth, predictions)    \n",
    "    cm = evaluation.cm_matrix(ground_truth, predictions)\n",
    "    acc_list.append(acc)\n",
    "    f1_list.append(f1)\n",
    "    cm_summed = cm_summed + cm\n",
    "    print(acc, f1)\n",
    "    print(cm)\n",
    "    \n",
    "    #break\n",
    "    #del model\n",
    "    #K.clear_session()\n",
    "    \n",
    "print(np.asarray(acc).mean(), np.asarray(f1).mean())\n",
    "print(cm_summed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = y_test.argmax(1)\n",
    "predictions = [list(map(lambda x: x, model.predict_on_batch(np.asarray([x]))))[0] \\\n",
    "        for x in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.59220779220779218, 0.5288816693467856, 162, 385)\n",
      "(42.077922077922075, '% - ', 12)\n",
      "\n",
      "\n",
      "('Rejected good ones: ', 24, '/', 53)\n",
      "('Accepted wrong ones:', 133, '/', 332)\n",
      "\n",
      "\n",
      "('Rejected wrong ones: ', 199, '/', 332)\n",
      "('Accepted good ones:', 29, '/', 53)\n"
     ]
    }
   ],
   "source": [
    "y_predicted_proba_np = np.asarray(predictions)\n",
    "#y_predicted = (y_predicted_proba_np[:,1] > 0.001)\n",
    "y_predicted = (y_predicted_proba_np[:,1] > 0.01)\n",
    "\n",
    "acc = accuracy_score(y_predicted, ground_truth)\n",
    "f1 = f1_score(y_predicted, ground_truth, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*30.0/len(y_predicted)))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected good ones: \", len(X_test_df[(y_predicted != ground_truth) & (y_predicted == False)]), \"/\", sum(ground_truth))\n",
    "print(\"Accepted wrong ones:\", len(X_test_df[(y_predicted != ground_truth) & (y_predicted == True)]), \"/\", len(ground_truth)-sum(ground_truth))\n",
    "print(\"\\n\")\n",
    "print(\"Rejected wrong ones: \", len(X_test_df[(y_predicted == ground_truth) & (y_predicted == False)]), \"/\", len(ground_truth)-sum(ground_truth))\n",
    "print(\"Accepted good ones:\", len(X_test_df[(y_predicted == ground_truth) & (y_predicted == True)]), \"/\", sum(ground_truth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# evaluate\n",
    "y_predicted = [list(map(lambda x: x, model_lstm.predict_on_batch(np.asarray([x])).argmax(1)))[0] \\\n",
    "               for x in x_test]\n",
    "y_test = y[limit:]\n",
    "y_test = to_categorical(y_test,2)\n",
    "y_test = y_test.argmax(1)\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted))\n",
    "\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Total good ones:\", sum(y_test))\n",
    "print(\"Rejected good ones: \", len(X_test_df[(y_predicted != y_test) & (np.asarray(y_predicted) == 0)]))\n",
    "print(\"Accepted wrong ones:\", len(X_test_df[(y_predicted != y_test) & (np.asarray(y_predicted) == 1)]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predicted_proba = [list(map(lambda x: x, model_lstm.predict_on_batch(np.asarray([x]))))[0] \\\n",
    "               for x in x_test]\n",
    "y_predicted_proba_np = np.asarray(y_predicted_proba)\n",
    "#y_predicted = (y_predicted_proba_np[:,1] > 0.001)\n",
    "y_predicted = (y_predicted_proba_np[:,1] > 0.2)\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)/len(y_predicted)*100.0,\"% - \", int(sum(y_predicted)/len(y_predicted)*30.0))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected good ones: \", len(X_test_df[(y_predicted != y_test) & (y_predicted == False)]), \"/\", sum(y_test))\n",
    "print(\"Accepted wrong ones:\", len(X_test_df[(y_predicted != y_test) & (y_predicted == True)]), \"/\", len(y_test)-sum(y_test))\n",
    "print(\"\\n\")\n",
    "print(\"Rejected wrong ones: \", len(X_test_df[(y_predicted == y_test) & (y_predicted == False)]), \"/\", len(y_test)-sum(y_test))\n",
    "print(\"Accepted good ones:\", len(X_test_df[(y_predicted == y_test) & (y_predicted == True)]), \"/\", sum(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "reload(runner)\n",
    "# Padding sequences\n",
    "x_train = pad_sequences(sequences_train, maxlen=hyperparameters['max_seq_len'])\n",
    "x_test = pad_sequences(sequences_test, maxlen=hyperparameters['max_seq_len'])\n",
    "\n",
    "dataset = x_train, y_train, x_test, y_test, embedding_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "result_cnn, model_cnn = runner.build_train_run(dataset, le, hyperparameters_cnn, save=False, return_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# evaluate\n",
    "import numpy as np\n",
    "y_predicted = [list(map(lambda x: x, model_cnn.predict_on_batch(np.asarray([x])).argmax(1)))[0] \\\n",
    "               for x in x_test]\n",
    "y_test = y[limit:]\n",
    "y_test = to_categorical(y_test,hyperparameters['nclasses'])\n",
    "y_test = y_test.argmax(1)\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted))\n",
    "\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Total good ones:\", sum(y_test))\n",
    "print(\"Rejected good ones: \", len(X_test_df[(y_predicted != y_test) & (np.asarray(y_predicted) == 0)]))\n",
    "print(\"Accepted wrong ones:\", len(X_test_df[(y_predicted != y_test) & (np.asarray(y_predicted) == 1)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predicted_proba = [list(map(lambda x: x, model_cnn.predict_on_batch(np.asarray([x]))))[0] \\\n",
    "               for x in x_test]\n",
    "y_predicted_proba_np = np.asarray(y_predicted_proba)\n",
    "\n",
    "#y_predicted = (y_predicted_proba_np[:,1] > 0.001)\n",
    "y_predicted = (y_predicted_proba_np[:,1] > 0.0005)\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)/len(y_predicted)*100.0,\"% - \", int(sum(y_predicted)/len(y_predicted)*30.0))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected good ones: \", len(X_test_df[(y_predicted != y_test) & (y_predicted == False)]), \"/\", sum(y_test))\n",
    "print(\"Accepted wrong ones:\", len(X_test_df[(y_predicted != y_test) & (y_predicted == True)]), \"/\", len(y_test)-sum(y_test))\n",
    "print(\"\\n\")\n",
    "print(\"Rejected wrong ones: \", len(X_test_df[(y_predicted == y_test) & (y_predicted == False)]), \"/\", len(y_test)-sum(y_test))\n",
    "print(\"Accepted good ones:\", len(X_test_df[(y_predicted == y_test) & (y_predicted == True)]), \"/\", sum(y_test))\n",
    "\n",
    "y_predicted_proba[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predicted_proba = [list(map(lambda x: x, model_lstm.predict_on_batch(np.asarray([x]))))[0] \\\n",
    "               for x in x_test]\n",
    "y_predicted_proba_np = np.asarray(y_predicted_proba)\n",
    "\n",
    "y_predicted_proba[0:20]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predicted_proba = [list(map(lambda x: x, model_lstm.predict_on_batch(np.asarray([x]))))[0] \\\n",
    "               for x in x_test]\n",
    "y_predicted_proba_np = np.asarray(y_predicted_proba)\n",
    "#y_predicted = (y_predicted_proba_np[:,1] > 0.001)\n",
    "y_predicted = (y_predicted_proba_np[:,1] > 0.2)\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)/len(y_predicted)*100.0,\"% - \", int(sum(y_predicted)/len(y_predicted)*30.0))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected good ones: \", len(X_test_df[(y_predicted != y_test) & (y_predicted == False)]), \"/\", sum(y_test))\n",
    "print(\"Accepted wrong ones:\", len(X_test_df[(y_predicted != y_test) & (y_predicted == True)]), \"/\", len(y_test)-sum(y_test))\n",
    "print(\"\\n\")\n",
    "print(\"Rejected wrong ones: \", len(X_test_df[(y_predicted == y_test) & (y_predicted == False)]), \"/\", len(y_test)-sum(y_test))\n",
    "print(\"Accepted good ones:\", len(X_test_df[(y_predicted == y_test) & (y_predicted == True)]), \"/\", sum(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
