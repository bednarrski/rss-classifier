{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from api import inoreader_api, inoreader_scraping\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape feeds starting from a concrete moment and store them in a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=2yqJclSC1n4Y\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=sJre0AtlHyQr\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=7Hd1_I_3T4Ad\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=XKIGnzlEfmdC\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=_6rdRtnyXou3\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=f_7fBDEKzxGn\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=LBKFB9iLz2UO\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=LrAjunuKX_ju\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=zDtccoaBcYcz\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=MH74ga3bAnui\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=I9gMb_Qhy0jY\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=P62pKLlE4mRy\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=u47R0m55LgYh\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=GM4GM7cCHDWC\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=dLTKLZzPuJfU\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=cbyPRyDQTJNF\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=QD3Gryk7Midm\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=wuFZ90bjdcyN\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=rnSxBjfj9ozT\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=BtUg0yzhBC2w\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=kGU6O2PQERT2\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=CusxfWPWjUfo\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=U09hdseiaQWt\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=nJq0rbqW_uD9\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=S_QbDDwwaNnp\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=L98RRWXq0Jpr\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=oigPmMaORtXJ\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=1YKt8kuzDTkg\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=2HNa7OemNQ9t\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=wdZMEtRI3FIK\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=lcNo9I6c5uJg\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=M5fDoz6PpC74\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=qBebMXuQr2M4\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=Ns3tZaG7pBp5\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=ETM2Plbor58u\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=cWLd6dCGLn0Y\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=e4AeWOpT9Tfz\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=HP8nna6jCnsL\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=j3pLSnwKiH9j\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=fcAeZcIf1lcy\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=K8USoHjMc9jK\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=ytoszNcXY7YM\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=HhyRzxZ0BUXf\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=i__t3WU3xD0U\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=Ds7yaxH5AfzC\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=swD6E0z_iRJH\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=b0S6NUyeaQAr\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=UiGpGiRSlCPf\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=GetqwW3La1dy\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=EDMmmn6FFmsg\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=GElXrb8qKlJI\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=YbNDMOlGKqty\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=fl_Q9H4TjAN0\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=n17Kp965WUmS\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=cy68ixgH901E\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=mdlAhpJj9q99\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=NLUs6mlyhFot\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=Ph3ZRlczLhDR\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=AadDua00q09y\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=LTQGg9A5YGXd\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=uQSCd2nd5yTm\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=mcHLA99gY6y0\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=Yzb4sagTpzNT\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=Xb8umUbCH4dB\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=TdPMLlEysfDU\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=sigoY1JgFF1Y\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=yCIBp_h9eo_9\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=ef_pkq2Up66W\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=DY6JHZnNKT4t\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=UqIxgZ4Ww3pK\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=pCrdcJX_8oDo\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=2f8TfobOjwe9\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=t77Krb9dZwFF\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=Bn7PpdqN4XaY\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=fedzQH3fz4oM\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=JjAaPt8HoHyh\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=fUzzII8Fdai_\n",
      "(200, 'OK')\n",
      "1540\n"
     ]
    }
   ],
   "source": [
    "start_time = 1508112001\n",
    "feed = 'user/-/label/arXiv'\n",
    "file_name = 'articles_raw.json'\n",
    "\n",
    "number_scraped = inoreader_scraping.scrape(feed, start_time, file_name)\n",
    "print(number_scraped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the feeds from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open(file_name, 'r')\n",
    "json_string = f.read()\n",
    "f.close\n",
    "\n",
    "json_object = json.loads(json_string)\n",
    "all_articles = json_object['all_articles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_abstract_string(abs_dict):\n",
    "    abs_string = abs_dict['content']\n",
    "    abs_string = re.search('<p>(.*)</p>', abs_string, flags=re.DOTALL)\n",
    "    return abs_string.group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_canonical_string(canonical_list):\n",
    "    url_dict = canonical_list[0]\n",
    "    url = url_dict['href']\n",
    "    return url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create preprocessed and cleaned DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piotr.bednarski/ml-env-27-gpu/lib/python2.7/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/piotr.bednarski/ml-env-27-gpu/lib/python2.7/site-packages/ipykernel/__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/piotr.bednarski/ml-env-27-gpu/lib/python2.7/site-packages/ipykernel/__main__.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/piotr.bednarski/ml-env-27-gpu/lib/python2.7/site-packages/ipykernel/__main__.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "all_articles_pd = pd.DataFrame(all_articles)\n",
    "all_articles_pd = all_articles_pd[['canonical', 'author', 'categories', 'published', 'title', 'summary']]\n",
    "\n",
    "for i in range(len(all_articles_pd)):\n",
    "    all_articles_pd['summary'][i] = get_abstract_string(all_articles_pd['summary'][i])\n",
    "    all_articles_pd['canonical'][i] = get_canonical_string(all_articles_pd['canonical'][i])\n",
    "    \n",
    "all_articles_pd['read'] = False\n",
    "all_articles_pd['liked'] = False\n",
    "\n",
    "for i in range(len(all_articles_pd)):\n",
    "    if 'user/1005689817/state/com.google/read' in all_articles_pd['categories'][i]:\n",
    "        all_articles_pd['read'][i] = True\n",
    "    if 'user/1005689817/state/com.google/like' in all_articles_pd['categories'][i]:\n",
    "        all_articles_pd['liked'][i] = True\n",
    "\n",
    "del all_articles_pd['categories']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#all_articles_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tagged_articles_pd = all_articles_pd[all_articles_pd['read'] == True]\n",
    "\n",
    "with open('old_articles_proto2.pickle', 'rb') as f:\n",
    "    # Pickle the 'data' dictionary using the highest protocol available.\n",
    "    old_tagged_articles_pd = pickle.load(f)\n",
    "    \n",
    "tagged_articles_pd = pd.concat([tagged_articles_pd, old_tagged_articles_pd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tagged_articles_unique_pd = tagged_articles_pd.sort_values(by=['canonical', 'liked'], ascending=False).reset_index(drop=True)\n",
    "to_drop = tagged_articles_unique_pd.duplicated(subset = ['canonical'], keep='first')\n",
    "to_drop = list(to_drop[to_drop == False].index.values)\n",
    "\n",
    "tagged_articles_unique_pd = tagged_articles_unique_pd[tagged_articles_unique_pd.index.isin(to_drop)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2487\n",
      "2293\n"
     ]
    }
   ],
   "source": [
    "print(len(tagged_articles_pd))\n",
    "print(len(tagged_articles_unique_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_ = list(tagged_articles_unique_pd['author']+' '+tagged_articles_unique_pd['title']+' '+tagged_articles_unique_pd['summary'])\n",
    "y_ = list(tagged_articles_unique_pd['liked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index_shuffled = [i for i in range(len(X_))]\n",
    "random.shuffle(index_shuffled)\n",
    "X = []\n",
    "y = []\n",
    "for i in index_shuffled:\n",
    "    X.append(X_[i])\n",
    "    y.append(y_[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras.preprocessing.text\n",
    "from string import maketrans\n",
    "\n",
    "def text_to_word_sequence(text,\n",
    "                          filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "                          lower=True, split=\" \"):\n",
    "    if lower: text = text.lower()\n",
    "    if type(text) == unicode:\n",
    "        translate_table = {ord(c): ord(t) for c,t in zip(filters, split*len(filters)) }\n",
    "    else:\n",
    "        translate_table = maketrans(filters, split * len(filters))\n",
    "    text = text.translate(translate_table)\n",
    "    seq = text.split(split)\n",
    "    return [i for i in seq if i]\n",
    "    \n",
    "keras.preprocessing.text.text_to_word_sequence = text_to_word_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('stopwords/english') as f:\n",
    "    stopwords = [line.strip() for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1376\n",
      "1083\n"
     ]
    }
   ],
   "source": [
    "print(len(X[4]))\n",
    "\n",
    "for i in range(len(X)):\n",
    "    seq = text_to_word_sequence(X[i])\n",
    "    clean_seq = [word for word in seq if word not in stopwords]\n",
    "    X[i] = ' '.join(clean_seq)\n",
    "    \n",
    "print(len(X[4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF -> NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piotr.bednarski/ml-env-27-gpu/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/piotr.bednarski/ml-env-27-gpu/lib/python2.7/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.88017429193899777, 0.93626882966396296)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "\n",
    "\n",
    "model_nb_tfidf = Pipeline([\n",
    "    (\"tfidf_vectorizer\", TfidfVectorizer()),\\\n",
    "    (\"nb\", BernoulliNB())\n",
    "])\n",
    "\n",
    "limit = int(0.8*len(X))\n",
    "\n",
    "X_train = X[:limit]\n",
    "X_test = X[limit:]\n",
    "\n",
    "y_train = y[:limit]\n",
    "y_test = y[limit:]\n",
    "\n",
    "model_nb_tfidf.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = model_nb_tfidf.predict(X_test)\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "acc, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.88017429193899777, 0.93626882966396296, 0, 459)\n",
      "(0.0, '% - ', 0)\n",
      "\n",
      "\n",
      "('Rejected good ones: ', 55, '/', 55)\n",
      "('Accepted wrong ones:', 0, '/', 404)\n",
      "\n",
      "\n",
      "('Rejected wrong ones: ', 404, '/', 404)\n",
      "('Accepted good ones:', 0, '/', 55)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  1.00000000e+00,   4.62135003e-29],\n",
       "       [  1.00000000e+00,   3.74338992e-30],\n",
       "       [  1.00000000e+00,   1.13139133e-20],\n",
       "       [  1.00000000e+00,   5.59203978e-27],\n",
       "       [  1.00000000e+00,   2.20903331e-22],\n",
       "       [  1.00000000e+00,   1.82545968e-20],\n",
       "       [  1.00000000e+00,   6.84679136e-19],\n",
       "       [  1.00000000e+00,   4.09661825e-32],\n",
       "       [  1.00000000e+00,   9.08068507e-25],\n",
       "       [  1.00000000e+00,   2.16518454e-26],\n",
       "       [  1.00000000e+00,   7.55703430e-19],\n",
       "       [  1.00000000e+00,   1.52992374e-25],\n",
       "       [  1.00000000e+00,   6.14278827e-23],\n",
       "       [  1.00000000e+00,   6.70248034e-23],\n",
       "       [  1.00000000e+00,   3.99907456e-32],\n",
       "       [  1.00000000e+00,   2.52761869e-28],\n",
       "       [  1.00000000e+00,   4.85280390e-32],\n",
       "       [  1.00000000e+00,   5.27399622e-23],\n",
       "       [  1.00000000e+00,   5.80877144e-25],\n",
       "       [  1.00000000e+00,   5.56402178e-15]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted_proba = model_nb_tfidf.predict_proba(X_test)\n",
    "#y_predicted = (y_predicted_proba[:,1] > 0.15)\n",
    "y_predicted = (y_predicted_proba[:,1] > 0.10)\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)/len(y_predicted)*100.0,\"% - \", int(sum(y_predicted)/len(y_predicted)*50.0))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected good ones: \", len(X_test_df[(y_predicted != y_test) & (y_predicted == False)]), \"/\", sum(y_test))\n",
    "print(\"Accepted wrong ones:\", len(X_test_df[(y_predicted != y_test) & (y_predicted == True)]), \"/\", len(y_test)-sum(y_test))\n",
    "print(\"\\n\")\n",
    "print(\"Rejected wrong ones: \", len(X_test_df[(y_predicted == y_test) & (y_predicted == False)]), \"/\", len(y_test)-sum(y_test))\n",
    "print(\"Accepted good ones:\", len(X_test_df[(y_predicted == y_test) & (y_predicted == True)]), \"/\", sum(y_test))\n",
    "\n",
    "y_predicted_proba[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CountVect -> NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.88017429193899777, 0.93626882966396296)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "\n",
    "\n",
    "model_nb = Pipeline([\n",
    "    #('vect', CountVectorizer(ngram_range=(1,3),stop_words='english')),\\\n",
    "    (\"count_vectorizer\", CountVectorizer(analyzer=lambda x: x)),\\\n",
    "    (\"nb\", BernoulliNB())\n",
    "])\n",
    "\n",
    "limit = int(0.8*len(X))\n",
    "\n",
    "X_train = X[:limit]\n",
    "X_test = X[limit:]\n",
    "\n",
    "y_train = y[:limit]\n",
    "y_test = y[limit:]\n",
    "\n",
    "model_nb.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = model_nb.predict(X_test)\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "acc, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.514161220044 0.432158000345 230 459\n",
      "50.1089324619 % -  25\n",
      "\n",
      "\n",
      "('Rejected good ones: ', 24, '/', 55)\n",
      "('Accepted wrong ones:', 199, '/', 404)\n",
      "\n",
      "\n",
      "('Rejected wrong ones: ', 205, '/', 404)\n",
      "('Accepted good ones:', 31, '/', 55)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.89297741,  0.10702259],\n",
       "       [ 0.87208127,  0.12791873],\n",
       "       [ 0.89475893,  0.10524107],\n",
       "       [ 0.82584317,  0.17415683],\n",
       "       [ 0.89052774,  0.10947226]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted_proba = model_nb.predict_proba(X_test)\n",
    "#y_predicted = (y_predicted_proba[:,1] > 0.1296)\n",
    "y_predicted = (y_predicted_proba[:,1] > 0.1325)\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print acc, f1, sum(y_predicted), len(y_predicted)\n",
    "print sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected good ones: \", len(X_test_df[(y_predicted != y_test) & (y_predicted == False)]), \"/\", sum(y_test))\n",
    "print(\"Accepted wrong ones:\", len(X_test_df[(y_predicted != y_test) & (y_predicted == True)]), \"/\", len(y_test)-sum(y_test))\n",
    "print(\"\\n\")\n",
    "print(\"Rejected wrong ones: \", len(X_test_df[(y_predicted == y_test) & (y_predicted == False)]), \"/\", len(y_test)-sum(y_test))\n",
    "print(\"Accepted good ones:\", len(X_test_df[(y_predicted == y_test) & (y_predicted == True)]), \"/\", sum(y_test))\n",
    "\n",
    "y_predicted_proba[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF -> SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.87799564270152508, 0.91551341454683066)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "\n",
    "model_svc_tfidf = Pipeline([\n",
    "    ('vect', CountVectorizer(ngram_range=(1,3), min_df=1, max_df=1.0,stop_words='english')),\n",
    "    #('vect', CountVectorizer(ngram_range=(3,6),analyzer='char_wb', min_df=10, max_df=0.95,stop_words='english')),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    (\"svc\", SVC(kernel='linear', probability=True, class_weight = 'balanced'))\n",
    "    #(\"svc\", SVC(kernel='linear', probability=True))\n",
    "])\n",
    "\n",
    "limit = int(0.8*len(X))\n",
    "\n",
    "X_train = X[:limit]\n",
    "X_test = X[limit:]\n",
    "\n",
    "y_train = y[:limit]\n",
    "y_test = y[limit:]\n",
    "\n",
    "model_svc_tfidf.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = model_svc_tfidf.predict(X_test)\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "acc, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.53159041394335516, 0.45505794501162822, 244, 459)\n",
      "(53.15904139433551, '% - ', 26)\n",
      "\n",
      "\n",
      "('Rejected good ones: ', 13, '/', 55)\n",
      "('Accepted wrong ones:', 202, '/', 404)\n",
      "\n",
      "\n",
      "('Rejected wrong ones: ', 202, '/', 404)\n",
      "('Accepted good ones:', 42, '/', 55)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.85911252,  0.14088748],\n",
       "       [ 0.97299437,  0.02700563],\n",
       "       [ 0.79171778,  0.20828222],\n",
       "       [ 0.78248004,  0.21751996],\n",
       "       [ 0.95591919,  0.04408081]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted_proba = model_svc_tfidf.predict_proba(X_test)\n",
    "#y_predicted = (y_predicted_proba[:,1] > 0.12)\n",
    "y_predicted = (y_predicted_proba[:,1] > 0.103)\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected good ones: \", len(X_test_df[(y_predicted != y_test) & (y_predicted == False)]), \"/\", sum(y_test))\n",
    "print(\"Accepted wrong ones:\", len(X_test_df[(y_predicted != y_test) & (y_predicted == True)]), \"/\", len(y_test)-sum(y_test))\n",
    "print(\"\\n\")\n",
    "print(\"Rejected wrong ones: \", len(X_test_df[(y_predicted == y_test) & (y_predicted == False)]), \"/\", len(y_test)-sum(y_test))\n",
    "print(\"Accepted good ones:\", len(X_test_df[(y_predicted == y_test) & (y_predicted == True)]), \"/\", sum(y_test))\n",
    "\n",
    "y_predicted_proba[0:5]\n",
    "\n",
    "#(0.62077922077922076, 0.55417162908266104, 162, 385)\n",
    "#(42.077922077922075, '% - ', 21)\n",
    "#('Rejected good ones: ', 15, '/', 46)\n",
    "#('Accepted wrong ones:', 131, '/', 339)\n",
    "#('Rejected wrong ones: ', 208, '/', 339)\n",
    "#('Accepted good ones:', 31, '/', 46)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.77124183006535951, 0.74794154583580086)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "\n",
    "model_svc_tfidf = Pipeline([\n",
    "    #('vect', CountVectorizer(ngram_range=(1,3), min_df=1, max_df=1.0,stop_words='english')),\n",
    "    ('vect', CountVectorizer(ngram_range=(3,6),analyzer='char_wb', min_df=10, max_df=0.95,stop_words='english')),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    (\"svc\", SVC(kernel='linear', probability=True, class_weight = 'balanced'))\n",
    "    #(\"svc\", SVC(kernel='linear', probability=True))\n",
    "])\n",
    "\n",
    "limit = int(0.8*len(X))\n",
    "\n",
    "X_train = X[:limit]\n",
    "X_test = X[limit:]\n",
    "\n",
    "y_train = y[:limit]\n",
    "y_test = y[limit:]\n",
    "\n",
    "model_svc_tfidf.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = model_svc_tfidf.predict(X_test)\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "acc, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.53812636165577343, 0.46246068031022758, 243, 459)\n",
      "(52.941176470588232, '% - ', 26)\n",
      "\n",
      "\n",
      "('Rejected good ones: ', 12, '/', 55)\n",
      "('Accepted wrong ones:', 200, '/', 404)\n",
      "\n",
      "\n",
      "('Rejected wrong ones: ', 204, '/', 404)\n",
      "('Accepted good ones:', 43, '/', 55)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.87489565,  0.12510435],\n",
       "       [ 0.93463575,  0.06536425],\n",
       "       [ 0.80568488,  0.19431512],\n",
       "       [ 0.89238852,  0.10761148],\n",
       "       [ 0.86164755,  0.13835245]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted_proba = model_svc_tfidf.predict_proba(X_test)\n",
    "#y_predicted = (y_predicted_proba[:,1] > 0.12)\n",
    "y_predicted = (y_predicted_proba[:,1] > 0.111)\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected good ones: \", len(X_test_df[(y_predicted != y_test) & (y_predicted == False)]), \"/\", sum(y_test))\n",
    "print(\"Accepted wrong ones:\", len(X_test_df[(y_predicted != y_test) & (y_predicted == True)]), \"/\", len(y_test)-sum(y_test))\n",
    "print(\"\\n\")\n",
    "print(\"Rejected wrong ones: \", len(X_test_df[(y_predicted == y_test) & (y_predicted == False)]), \"/\", len(y_test)-sum(y_test))\n",
    "print(\"Accepted good ones:\", len(X_test_df[(y_predicted == y_test) & (y_predicted == True)]), \"/\", sum(y_test))\n",
    "\n",
    "y_predicted_proba[0:5]\n",
    "\n",
    "#(0.62077922077922076, 0.55417162908266104, 162, 385)\n",
    "#(42.077922077922075, '% - ', 21)\n",
    "#('Rejected good ones: ', 15, '/', 46)\n",
    "#('Accepted wrong ones:', 131, '/', 339)\n",
    "#('Rejected wrong ones: ', 208, '/', 339)\n",
    "#('Accepted good ones:', 31, '/', 46)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count -> SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.87363834422657949, 0.92260716770520701)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "\n",
    "model_svc = Pipeline([\n",
    "    #('vect', CountVectorizer()),\n",
    "    ('vect', CountVectorizer(ngram_range=(1,3), min_df=1, max_df=1.0,stop_words='english')),\n",
    "    #('vect', CountVectorizer(ngram_range=(3,6),analyzer='char_wb', min_df=10, max_df=0.95,stop_words='english')),\n",
    "    #('tfidf', TfidfTransformer()),\n",
    "    (\"svc\", SVC(kernel='linear', probability=True, class_weight = 'balanced'))\n",
    "    #(\"svc\", SVC(kernel='linear', probability=True))\n",
    "])\n",
    "\n",
    "limit = int(0.8*len(X))\n",
    "\n",
    "X_train = X[:limit]\n",
    "X_test = X[limit:]\n",
    "\n",
    "y_train = y[:limit]\n",
    "y_test = y[limit:]\n",
    "\n",
    "model_svc.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = model_svc.predict(X_test)\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "acc, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.52723311546840956, 0.44958058370959769, 242, 459)\n",
      "(52.723311546840961, '% - ', 26)\n",
      "\n",
      "\n",
      "('Rejected good ones: ', 15, '/', 55)\n",
      "('Accepted wrong ones:', 202, '/', 404)\n",
      "\n",
      "\n",
      "('Rejected wrong ones: ', 202, '/', 404)\n",
      "('Accepted good ones:', 40, '/', 55)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.8024909 ,  0.1975091 ],\n",
       "       [ 0.95157312,  0.04842688],\n",
       "       [ 0.85450218,  0.14549782],\n",
       "       [ 0.76319154,  0.23680846],\n",
       "       [ 0.92887599,  0.07112401]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted_proba = model_svc.predict_proba(X_test)\n",
    "#y_predicted = (y_predicted_proba[:,1] > 0.12)\n",
    "y_predicted = (y_predicted_proba[:,1] > 0.11)\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected good ones: \", len(X_test_df[(y_predicted != y_test) & (y_predicted == False)]), \"/\", sum(y_test))\n",
    "print(\"Accepted wrong ones:\", len(X_test_df[(y_predicted != y_test) & (y_predicted == True)]), \"/\", len(y_test)-sum(y_test))\n",
    "print(\"\\n\")\n",
    "print(\"Rejected wrong ones: \", len(X_test_df[(y_predicted == y_test) & (y_predicted == False)]), \"/\", len(y_test)-sum(y_test))\n",
    "print(\"Accepted good ones:\", len(X_test_df[(y_predicted == y_test) & (y_predicted == True)]), \"/\", sum(y_test))\n",
    "\n",
    "y_predicted_proba[0:5]\n",
    "\n",
    "#(0.62077922077922076, 0.55417162908266104, 162, 385)\n",
    "#(42.077922077922075, '% - ', 21)\n",
    "#('Rejected good ones: ', 15, '/', 46)\n",
    "#('Accepted wrong ones:', 131, '/', 339)\n",
    "#('Rejected wrong ones: ', 208, '/', 339)\n",
    "#('Accepted good ones:', 31, '/', 46)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embeddings preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import (Input, Embedding, SimpleRNN, Dense, Activation, TimeDistributed, Bidirectional, LSTM, GaussianNoise)\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model\n",
    "from keras.utils import plot_model #Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATASETS_DIR = '../ml-research/datasets/'\n",
    "GLOVE_DIR = DATASETS_DIR+'glove.6B/'\n",
    "WIKI_EN_DIR = DATASETS_DIR+'wiki.en/'\n",
    "#embeddings_file = os.path.join(GLOVE_DIR, 'glove.6B.300d.txt')\n",
    "embeddings_file = os.path.join(WIKI_EN_DIR, 'wiki.en.vec')\n",
    "\n",
    "# Word embeddings' constraints\n",
    "MAX_NB_WORDS = 20000  # Number of most common words for tokenizer\n",
    "EMBEDDING_DIM = 300   # Embeddings dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras.preprocessing.text\n",
    "from string import maketrans\n",
    "\n",
    "def text_to_word_sequence(text,\n",
    "                          filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "                          lower=True, split=\" \"):\n",
    "    if lower: text = text.lower()\n",
    "    if type(text) == unicode:\n",
    "        translate_table = {ord(c): ord(t) for c,t in zip(filters, split*len(filters)) }\n",
    "    else:\n",
    "        translate_table = maketrans(filters, split * len(filters))\n",
    "    text = text.translate(translate_table)\n",
    "    seq = text.split(split)\n",
    "    return [i for i in seq if i]\n",
    "    \n",
    "keras.preprocessing.text.text_to_word_sequence = text_to_word_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24837 unique tokens.\n",
      "78\n",
      "24836\n"
     ]
    }
   ],
   "source": [
    "# Tokenizing and creating word index\n",
    "\n",
    "additional_words = ['unk', 'num']\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(X+additional_words)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "# inversing the word_index.\n",
    "index_word = dict((k,v) for v,k in word_index.items())\n",
    "\n",
    "# example\n",
    "print(word_index['adversarial'])\n",
    "print(word_index['unk'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing word vectors.\n",
      "Found 2519371 word vectors.\n",
      "Creating Word Embeddings matrix...\n",
      "Word Embeddings matrix was successfuly created.\n"
     ]
    }
   ],
   "source": [
    "import models.embedding_matrix as embedding\n",
    "\n",
    "embedding_matrix = embedding.create_embedding_matrix(embeddings_file, MAX_NB_WORDS, EMBEDDING_DIM, word_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import (Input, Embedding, SimpleRNN, Dense, Activation, TimeDistributed, Bidirectional,\n",
    "                          LSTM, GaussianNoise,Conv1D, MaxPooling1D, Flatten, Dropout)\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    'conv_units': 128,\n",
    "    'hidden_units_1': 128,\n",
    "    'hidden_units_2': 64,\n",
    "    'dropout': 0.5,\n",
    "    'pooling' : 5,\n",
    "    'gauss_stddev' : 0.0002,\n",
    "    'epochs' : 15,\n",
    "    'folds' : 5,\n",
    "    'nclasses' : 2,\n",
    "    'max_seq_len' : 300,\n",
    "    'learning_rate' : 0.001,\n",
    "    'stopwords' : True\n",
    "}\n",
    "\n",
    "hyperparameters = {\n",
    "    'conv_units': 64,\n",
    "    'hidden_units_1': 64,\n",
    "    'hidden_units_2': 32,\n",
    "    'dropout': 0.5,\n",
    "    'pooling' : 5,\n",
    "    'gauss_stddev' : 0.0002,\n",
    "    'epochs' : 15,\n",
    "    'folds' : 5,\n",
    "    'nclasses' : 2,\n",
    "    'max_seq_len' : 300,\n",
    "    'learning_rate' : 0.001,\n",
    "    'stopwords' : True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb97c8ecd90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X_sequences = tokenizer.texts_to_sequences(X)\n",
    "X_sequences_len = []\n",
    "for item in X_sequences:\n",
    "    X_sequences_len.append(\n",
    "                            min( len(item), 1000\n",
    "                               ))\n",
    "    \n",
    "X_sequences_padded = pad_sequences(X_sequences, maxlen=hyperparameters['max_seq_len'])\n",
    "\n",
    "plt.hist(X_sequences_len, 50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn import preprocessing\n",
    "\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "label_encoder.fit(y)\n",
    "\n",
    "y_num = label_encoder.transform(y)\n",
    "y_matrix = to_categorical(y_num,hyperparameters['nclasses'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1834 samples, validate on 459 samples\n",
      "Epoch 1/15\n",
      "1834/1834 [==============================] - 6s - loss: 1.1983 - categorical_accuracy: 0.7492 - val_loss: 0.6521 - val_categorical_accuracy: 0.8715\n",
      "Epoch 2/15\n",
      "1834/1834 [==============================] - 6s - loss: 1.1963 - categorical_accuracy: 0.6489 - val_loss: 0.6870 - val_categorical_accuracy: 0.5948\n",
      "Epoch 3/15\n",
      "1834/1834 [==============================] - 6s - loss: 1.1860 - categorical_accuracy: 0.6532 - val_loss: 0.5960 - val_categorical_accuracy: 0.8693\n",
      "Epoch 4/15\n",
      "1834/1834 [==============================] - 6s - loss: 1.1633 - categorical_accuracy: 0.7197 - val_loss: 0.5565 - val_categorical_accuracy: 0.7647\n",
      "Epoch 5/15\n",
      "1834/1834 [==============================] - 6s - loss: 1.1384 - categorical_accuracy: 0.5785 - val_loss: 0.7064 - val_categorical_accuracy: 0.4205\n",
      "Epoch 6/15\n",
      "1834/1834 [==============================] - 6s - loss: 1.0825 - categorical_accuracy: 0.5594 - val_loss: 0.4949 - val_categorical_accuracy: 0.7473\n",
      "Epoch 7/15\n",
      "1834/1834 [==============================] - 6s - loss: 0.9963 - categorical_accuracy: 0.6652 - val_loss: 0.5597 - val_categorical_accuracy: 0.6950\n",
      "Epoch 8/15\n",
      "1834/1834 [==============================] - 6s - loss: 0.9060 - categorical_accuracy: 0.7159 - val_loss: 0.4337 - val_categorical_accuracy: 0.7996\n",
      "Epoch 9/15\n",
      "1834/1834 [==============================] - 6s - loss: 0.7357 - categorical_accuracy: 0.8157 - val_loss: 0.8697 - val_categorical_accuracy: 0.5425\n",
      "Epoch 10/15\n",
      "1834/1834 [==============================] - 6s - loss: 0.5617 - categorical_accuracy: 0.8326 - val_loss: 0.7082 - val_categorical_accuracy: 0.6688\n",
      "Epoch 11/15\n",
      "1834/1834 [==============================] - 6s - loss: 0.3614 - categorical_accuracy: 0.9029 - val_loss: 0.4782 - val_categorical_accuracy: 0.8519\n",
      "Epoch 12/15\n",
      "1834/1834 [==============================] - 6s - loss: 0.2499 - categorical_accuracy: 0.9427 - val_loss: 0.6651 - val_categorical_accuracy: 0.7342\n",
      "Epoch 13/15\n",
      "1834/1834 [==============================] - 6s - loss: 0.1473 - categorical_accuracy: 0.9695 - val_loss: 0.5485 - val_categorical_accuracy: 0.8562\n",
      "Epoch 14/15\n",
      "1834/1834 [==============================] - 6s - loss: 0.0704 - categorical_accuracy: 0.9880 - val_loss: 0.6477 - val_categorical_accuracy: 0.8649\n",
      "Epoch 15/15\n",
      "1834/1834 [==============================] - 6s - loss: 0.0709 - categorical_accuracy: 0.9847 - val_loss: 0.8117 - val_categorical_accuracy: 0.8802\n",
      "(0.88017429193899777, 0.84493269356592982)\n",
      "[[395   4]\n",
      " [ 51   9]]\n",
      "Train on 1834 samples, validate on 459 samples\n",
      "Epoch 1/15\n",
      "1834/1834 [==============================] - 6s - loss: 1.2017 - categorical_accuracy: 0.2846 - val_loss: 0.7038 - val_categorical_accuracy: 0.1264\n",
      "Epoch 2/15\n",
      "1834/1834 [==============================] - 6s - loss: 1.1980 - categorical_accuracy: 0.2323 - val_loss: 0.7050 - val_categorical_accuracy: 0.2505\n",
      "Epoch 3/15\n",
      "1834/1834 [==============================] - 6s - loss: 1.1919 - categorical_accuracy: 0.3893 - val_loss: 0.7049 - val_categorical_accuracy: 0.4052\n",
      "Epoch 4/15\n",
      "1834/1834 [==============================] - 6s - loss: 1.1535 - categorical_accuracy: 0.5229 - val_loss: 0.7010 - val_categorical_accuracy: 0.5120\n",
      "Epoch 5/15\n",
      "1834/1834 [==============================] - 6s - loss: 1.0903 - categorical_accuracy: 0.6150 - val_loss: 0.5699 - val_categorical_accuracy: 0.7342\n",
      "Epoch 6/15\n",
      "1834/1834 [==============================] - 6s - loss: 1.0010 - categorical_accuracy: 0.7285 - val_loss: 0.6169 - val_categorical_accuracy: 0.6776\n",
      "Epoch 7/15\n",
      "1834/1834 [==============================] - 6s - loss: 0.7681 - categorical_accuracy: 0.8108 - val_loss: 0.3408 - val_categorical_accuracy: 0.8715\n",
      "Epoch 8/15\n",
      "1834/1834 [==============================] - 6s - loss: 0.5889 - categorical_accuracy: 0.8582 - val_loss: 0.3472 - val_categorical_accuracy: 0.8715\n",
      "Epoch 9/15\n",
      "1834/1834 [==============================] - 6s - loss: 0.4974 - categorical_accuracy: 0.8664 - val_loss: 0.4338 - val_categorical_accuracy: 0.8780\n",
      "Epoch 10/15\n",
      "1834/1834 [==============================] - 6s - loss: 0.4644 - categorical_accuracy: 0.8969 - val_loss: 0.4496 - val_categorical_accuracy: 0.7865\n",
      "Epoch 11/15\n",
      "1834/1834 [==============================] - 6s - loss: 0.2119 - categorical_accuracy: 0.9624 - val_loss: 0.4476 - val_categorical_accuracy: 0.8649\n",
      "Epoch 12/15\n",
      "1834/1834 [==============================] - 6s - loss: 0.0860 - categorical_accuracy: 0.9885 - val_loss: 0.6144 - val_categorical_accuracy: 0.7887\n",
      "Epoch 13/15\n",
      "1834/1834 [==============================] - 6s - loss: 0.0850 - categorical_accuracy: 0.9804 - val_loss: 0.5111 - val_categorical_accuracy: 0.8453\n",
      "Epoch 14/15\n",
      "1834/1834 [==============================] - 6s - loss: 0.1522 - categorical_accuracy: 0.9635 - val_loss: 0.5619 - val_categorical_accuracy: 0.8780\n",
      "Epoch 15/15\n",
      "1834/1834 [==============================] - 6s - loss: 0.0750 - categorical_accuracy: 0.9858 - val_loss: 0.4860 - val_categorical_accuracy: 0.8388\n",
      "(0.83877995642701531, 0.8399447029282523)\n",
      "[[363  38]\n",
      " [ 36  22]]\n",
      "Train on 1834 samples, validate on 459 samples\n",
      "Epoch 1/15\n",
      "1834/1834 [==============================] - 6s - loss: 1.1808 - categorical_accuracy: 0.2923 - val_loss: 0.6843 - val_categorical_accuracy: 0.6950\n",
      "Epoch 2/15\n",
      "1834/1834 [==============================] - 6s - loss: 1.1756 - categorical_accuracy: 0.6778 - val_loss: 0.7167 - val_categorical_accuracy: 0.2789\n",
      "Epoch 3/15\n",
      "1834/1834 [==============================] - 6s - loss: 1.1592 - categorical_accuracy: 0.5458 - val_loss: 0.6282 - val_categorical_accuracy: 0.7603\n",
      "Epoch 4/15\n",
      "1834/1834 [==============================] - 6s - loss: 1.1287 - categorical_accuracy: 0.6156 - val_loss: 0.6051 - val_categorical_accuracy: 0.7560\n",
      "Epoch 5/15\n",
      "1834/1834 [==============================] - 6s - loss: 1.0623 - categorical_accuracy: 0.6947 - val_loss: 0.7068 - val_categorical_accuracy: 0.5534\n",
      "Epoch 6/15\n",
      "1834/1834 [==============================] - 6s - loss: 0.9589 - categorical_accuracy: 0.7334 - val_loss: 0.6348 - val_categorical_accuracy: 0.6427\n",
      "Epoch 7/15\n",
      "1834/1834 [==============================] - 6s - loss: 0.8500 - categorical_accuracy: 0.7595 - val_loss: 0.5338 - val_categorical_accuracy: 0.7364\n",
      "Epoch 8/15\n",
      "1834/1834 [==============================] - 6s - loss: 0.7093 - categorical_accuracy: 0.8228 - val_loss: 0.4973 - val_categorical_accuracy: 0.7647\n",
      "Epoch 9/15\n",
      "1834/1834 [==============================] - 6s - loss: 0.5611 - categorical_accuracy: 0.8806 - val_loss: 0.9842 - val_categorical_accuracy: 0.5686\n",
      "Epoch 10/15\n",
      "1834/1834 [==============================] - 6s - loss: 0.4982 - categorical_accuracy: 0.8702 - val_loss: 0.4421 - val_categorical_accuracy: 0.8148\n",
      "Epoch 11/15\n",
      "1834/1834 [==============================] - 6s - loss: 0.3429 - categorical_accuracy: 0.9373 - val_loss: 0.7134 - val_categorical_accuracy: 0.6993\n",
      "Epoch 12/15\n",
      "1834/1834 [==============================] - 6s - loss: 0.1957 - categorical_accuracy: 0.9629 - val_loss: 0.8851 - val_categorical_accuracy: 0.6754\n",
      "Epoch 13/15\n",
      "1834/1834 [==============================] - 6s - loss: 0.1631 - categorical_accuracy: 0.9684 - val_loss: 0.6474 - val_categorical_accuracy: 0.7865\n",
      "Epoch 14/15\n",
      "1834/1834 [==============================] - 6s - loss: 0.0595 - categorical_accuracy: 0.9896 - val_loss: 0.7068 - val_categorical_accuracy: 0.8192\n",
      "Epoch 15/15\n",
      "1834/1834 [==============================] - 6s - loss: 0.0262 - categorical_accuracy: 0.9945 - val_loss: 0.8366 - val_categorical_accuracy: 0.8497\n",
      "(0.84967320261437906, 0.8102248160976494)\n",
      "[[381   9]\n",
      " [ 60   9]]\n",
      "Train on 1835 samples, validate on 458 samples\n",
      "Epoch 1/15\n",
      "1835/1835 [==============================] - 6s - loss: 1.1778 - categorical_accuracy: 0.5319 - val_loss: 0.6778 - val_categorical_accuracy: 0.8450\n",
      "Epoch 2/15\n",
      "1835/1835 [==============================] - 6s - loss: 1.1707 - categorical_accuracy: 0.6725 - val_loss: 0.6162 - val_categorical_accuracy: 0.8450\n",
      "Epoch 3/15\n",
      "1835/1835 [==============================] - 6s - loss: 1.1562 - categorical_accuracy: 0.7471 - val_loss: 0.5601 - val_categorical_accuracy: 0.8341\n",
      "Epoch 4/15\n",
      "1835/1835 [==============================] - 6s - loss: 1.1465 - categorical_accuracy: 0.6589 - val_loss: 0.5597 - val_categorical_accuracy: 0.7838\n",
      "Epoch 5/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1835/1835 [==============================] - 6s - loss: 1.0923 - categorical_accuracy: 0.6098 - val_loss: 0.4597 - val_categorical_accuracy: 0.8231\n",
      "Epoch 6/15\n",
      "1835/1835 [==============================] - 6s - loss: 1.0189 - categorical_accuracy: 0.6785 - val_loss: 0.5992 - val_categorical_accuracy: 0.6397\n",
      "Epoch 7/15\n",
      "1835/1835 [==============================] - 6s - loss: 0.9518 - categorical_accuracy: 0.7411 - val_loss: 0.7219 - val_categorical_accuracy: 0.5415\n",
      "Epoch 8/15\n",
      "1835/1835 [==============================] - 6s - loss: 0.8379 - categorical_accuracy: 0.7591 - val_loss: 0.5003 - val_categorical_accuracy: 0.7555\n",
      "Epoch 9/15\n",
      "1835/1835 [==============================] - 6s - loss: 0.6672 - categorical_accuracy: 0.8278 - val_loss: 0.5841 - val_categorical_accuracy: 0.7118\n",
      "Epoch 10/15\n",
      "1835/1835 [==============================] - 6s - loss: 0.4600 - categorical_accuracy: 0.9008 - val_loss: 0.5480 - val_categorical_accuracy: 0.7795\n",
      "Epoch 11/15\n",
      "1835/1835 [==============================] - 6s - loss: 0.3192 - categorical_accuracy: 0.9297 - val_loss: 0.5998 - val_categorical_accuracy: 0.8079\n",
      "Epoch 12/15\n",
      "1835/1835 [==============================] - 6s - loss: 0.1467 - categorical_accuracy: 0.9700 - val_loss: 0.6572 - val_categorical_accuracy: 0.8188\n",
      "Epoch 13/15\n",
      "1835/1835 [==============================] - 6s - loss: 0.0934 - categorical_accuracy: 0.9815 - val_loss: 0.7992 - val_categorical_accuracy: 0.8406\n",
      "Epoch 14/15\n",
      "1835/1835 [==============================] - 6s - loss: 0.0570 - categorical_accuracy: 0.9907 - val_loss: 0.9270 - val_categorical_accuracy: 0.8493\n",
      "Epoch 15/15\n",
      "1835/1835 [==============================] - 6s - loss: 0.0344 - categorical_accuracy: 0.9956 - val_loss: 0.8671 - val_categorical_accuracy: 0.8428\n",
      "(0.84279475982532748, 0.81382738248137687)\n",
      "[[372  15]\n",
      " [ 57  14]]\n",
      "Train on 1835 samples, validate on 458 samples\n",
      "Epoch 1/15\n",
      "1835/1835 [==============================] - 6s - loss: 1.1820 - categorical_accuracy: 0.3074 - val_loss: 0.6910 - val_categorical_accuracy: 0.6463\n",
      "Epoch 2/15\n",
      "1835/1835 [==============================] - 6s - loss: 1.1782 - categorical_accuracy: 0.4916 - val_loss: 0.6969 - val_categorical_accuracy: 0.5240\n",
      "Epoch 3/15\n",
      "1835/1835 [==============================] - 6s - loss: 1.1682 - categorical_accuracy: 0.3172 - val_loss: 0.7309 - val_categorical_accuracy: 0.3275\n",
      "Epoch 4/15\n",
      "1835/1835 [==============================] - 6s - loss: 1.1588 - categorical_accuracy: 0.3984 - val_loss: 0.6666 - val_categorical_accuracy: 0.7358\n",
      "Epoch 5/15\n",
      "1835/1835 [==============================] - 6s - loss: 1.1369 - categorical_accuracy: 0.6196 - val_loss: 0.6393 - val_categorical_accuracy: 0.7314\n",
      "Epoch 6/15\n",
      "1835/1835 [==============================] - 6s - loss: 1.0511 - categorical_accuracy: 0.7095 - val_loss: 0.6390 - val_categorical_accuracy: 0.6528\n",
      "Epoch 7/15\n",
      "1835/1835 [==============================] - 6s - loss: 0.9681 - categorical_accuracy: 0.7591 - val_loss: 0.6334 - val_categorical_accuracy: 0.6725\n",
      "Epoch 8/15\n",
      "1835/1835 [==============================] - 6s - loss: 0.7886 - categorical_accuracy: 0.8229 - val_loss: 0.4233 - val_categorical_accuracy: 0.8384\n",
      "Epoch 9/15\n",
      "1835/1835 [==============================] - 6s - loss: 0.6055 - categorical_accuracy: 0.8948 - val_loss: 0.6239 - val_categorical_accuracy: 0.7183\n",
      "Epoch 10/15\n",
      "1835/1835 [==============================] - 6s - loss: 0.3844 - categorical_accuracy: 0.9259 - val_loss: 0.5495 - val_categorical_accuracy: 0.8515\n",
      "Epoch 11/15\n",
      "1835/1835 [==============================] - 6s - loss: 0.4398 - categorical_accuracy: 0.9106 - val_loss: 0.4641 - val_categorical_accuracy: 0.8275\n",
      "Epoch 12/15\n",
      "1835/1835 [==============================] - 6s - loss: 0.2972 - categorical_accuracy: 0.9515 - val_loss: 0.6279 - val_categorical_accuracy: 0.8035\n",
      "Epoch 13/15\n",
      "1835/1835 [==============================] - 6s - loss: 0.1261 - categorical_accuracy: 0.9831 - val_loss: 0.6714 - val_categorical_accuracy: 0.8231\n",
      "Epoch 14/15\n",
      "1835/1835 [==============================] - 6s - loss: 0.0781 - categorical_accuracy: 0.9886 - val_loss: 0.7980 - val_categorical_accuracy: 0.8428\n",
      "Epoch 15/15\n",
      "1835/1835 [==============================] - 6s - loss: 0.0430 - categorical_accuracy: 0.9973 - val_loss: 0.8800 - val_categorical_accuracy: 0.8428\n",
      "(0.84279475982532748, 0.79303817304276958)\n",
      "[[382   8]\n",
      " [ 64   4]]\n",
      "(0.84279475982532748, 0.79303817304276958)\n",
      "[[ 1893.    74.]\n",
      " [  268.    58.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "import utils.evaluation as evaluation\n",
    "from keras import metrics\n",
    "\n",
    "\n",
    "class_weight = {0 : 1.,\n",
    "    1: (len(y)-sum(y))/sum(y)}\n",
    "\n",
    "acc_list = []\n",
    "f1_list = []\n",
    "cm_summed = np.zeros((2,2))\n",
    "kf = KFold(n_splits=5, shuffle = True)\n",
    "for train_index, test_index in kf.split(X_sequences):\n",
    "    K.clear_session()\n",
    "    \n",
    "    X_sequences_padded = pad_sequences(X_sequences, maxlen=hyperparameters['max_seq_len'])\n",
    "\n",
    "    num_words = embedding_matrix.shape[0]\n",
    "    embedding_dim = embedding_matrix.shape[1]\n",
    "\n",
    "    embedding_layer = Embedding(num_words,\n",
    "                                embedding_dim,\n",
    "                                weights=[embedding_matrix],\n",
    "                                input_length=hyperparameters['max_seq_len'],\n",
    "                                trainable=False)\n",
    "\n",
    "    # train a 1D convnet with global maxpooling\n",
    "    sequence_input = Input(shape=(hyperparameters['max_seq_len'],), dtype='int32')\n",
    "    embedded_sequences = embedding_layer(sequence_input)\n",
    "\n",
    "    #x = GaussianNoise(hyperparameters['gauss_stddev'])(embedded_sequences)\n",
    "    x = embedded_sequences\n",
    "    x = Conv1D(2*hyperparameters['conv_units'], 5, activation='relu')(x)\n",
    "    x = MaxPooling1D(5)(x)\n",
    "    x = Conv1D(hyperparameters['conv_units'], 5, activation='relu')(x)\n",
    "    x = MaxPooling1D(5)(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(hyperparameters['hidden_units_1'], activation='relu')(x)\n",
    "    x = Dropout(hyperparameters['dropout'])(x)\n",
    "    x = Dense(hyperparameters['hidden_units_2'], activation='relu')(x)\n",
    "    preds = Dense(hyperparameters['nclasses'], activation='softmax')(x)\n",
    "\n",
    "    model_cnn = Model(sequence_input, preds)\n",
    "    model_cnn.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=[metrics.categorical_accuracy])\n",
    "\n",
    "    \n",
    "    X_train, X_test = X_sequences_padded[train_index], X_sequences_padded[test_index]\n",
    "    y_train, y_test = y_matrix[train_index], y_matrix[test_index]\n",
    "\n",
    "    # train\n",
    "    model_cnn.fit(X_train, y_train,\n",
    "              batch_size=128,\n",
    "              epochs=hyperparameters['epochs'],\n",
    "              class_weight=class_weight,\n",
    "              validation_data=(X_test, y_test))\n",
    "\n",
    "    # run\n",
    "    ground_truth = y_test.argmax(1)\n",
    "    predictions = [list(map(lambda x: x, model_cnn.predict_on_batch(np.asarray([x])).argmax(1)))[0] \\\n",
    "            for x in X_test]\n",
    "    \n",
    "    \n",
    "    acc = evaluation.accuracy(ground_truth, predictions)\n",
    "    f1 = evaluation.eval_f1_score(ground_truth, predictions)    \n",
    "    cm = evaluation.cm_matrix(ground_truth, predictions)\n",
    "    acc_list.append(acc)\n",
    "    f1_list.append(f1)\n",
    "    cm_summed = cm_summed + cm\n",
    "    print(acc, f1)\n",
    "    print(cm)\n",
    "    \n",
    "print(np.asarray(acc).mean(), np.asarray(f1).mean())\n",
    "print(cm_summed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ground_truth = y_test.argmax(1)\n",
    "predictions = [list(map(lambda x: x, model_cnn.predict_on_batch(np.asarray([x]))))[0] \\\n",
    "        for x in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.84279475982532748, 0.89255134660788515, 12, 458)\n",
      "(2.6200873362445414, '% - ', 1)\n",
      "\n",
      "\n",
      "('Rejected good ones: ', 64, '/', 68)\n",
      "('Accepted wrong ones:', 8, '/', 390)\n",
      "\n",
      "\n",
      "('Rejected wrong ones: ', 382, '/', 390)\n",
      "('Accepted good ones:', 4, '/', 68)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  9.96629894e-01,   3.37007153e-03],\n",
       "       [  9.09401417e-01,   9.05985981e-02],\n",
       "       [  9.99828100e-01,   1.71905442e-04],\n",
       "       [  4.43538904e-01,   5.56461036e-01],\n",
       "       [  9.99375641e-01,   6.24337583e-04]], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted_proba_np = np.asarray(predictions)\n",
    "#y_predicted = (y_predicted_proba_np[:,1] > 0.001)\n",
    "y_predicted = (y_predicted_proba_np[:,1] > 0.4791)\n",
    "\n",
    "acc = accuracy_score(y_predicted, ground_truth)\n",
    "f1 = f1_score(y_predicted, ground_truth, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected good ones: \", len(X_test_df[(y_predicted != ground_truth) & (y_predicted == False)]), \"/\", sum(ground_truth))\n",
    "print(\"Accepted wrong ones:\", len(X_test_df[(y_predicted != ground_truth) & (y_predicted == True)]), \"/\", len(ground_truth)-sum(ground_truth))\n",
    "print(\"\\n\")\n",
    "print(\"Rejected wrong ones: \", len(X_test_df[(y_predicted == ground_truth) & (y_predicted == False)]), \"/\", len(ground_truth)-sum(ground_truth))\n",
    "print(\"Accepted good ones:\", len(X_test_df[(y_predicted == ground_truth) & (y_predicted == True)]), \"/\", sum(ground_truth))\n",
    "\n",
    "# 15% bezbolesnie odrzucic - 0.000008\n",
    "\n",
    "y_predicted_proba_np[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    'conv_units': 128,\n",
    "    'hidden_units_1': 128,\n",
    "    'hidden_units_2': 64,\n",
    "    'dropout': 0.5,\n",
    "    'pooling' : 5,\n",
    "    'gauss_stddev' : 0.0002,\n",
    "    'epochs' : 15,\n",
    "    'folds' : 5,\n",
    "    'nclasses' : 2,\n",
    "    'max_seq_len' : 300,\n",
    "    'learning_rate' : 0.001,\n",
    "    'stopwords' : True\n",
    "}\n",
    "\n",
    "hyperparameters = {\n",
    "    'conv_units': 64,\n",
    "    'hidden_units_1': 64,\n",
    "    'hidden_units_2': 0,\n",
    "    'dropout': 0.5,\n",
    "    'pooling' : 5,\n",
    "    'gauss_stddev' : 0.0002,\n",
    "    'epochs' : 5,\n",
    "    'folds' : 5,\n",
    "    'nclasses' : 2,\n",
    "    'max_seq_len' : 300,\n",
    "    'learning_rate' : 0.001,\n",
    "    'stopwords' : True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW BEST: epoch 0 valid F1 =  0.771380892783 in 82.126418829 (sec)                               \n",
      "[learning] epoch 1 >> 0.11% completed in 0.08 (sec)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piotr.bednarski/ml-env-27-gpu/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.84313725490196079, 0.77138089278264499) 76.44 (sec)\n",
      "[[387   0]\n",
      " [ 72   0]]\n",
      "NEW BEST: epoch 0 valid F1 =  0.768307743873 in 81.5669898987 (sec)                               \n",
      "(0.84095860566448799, 0.76830774387335465) 75.82 (sec)\n",
      "[[386   0]\n",
      " [ 73   0]]\n",
      "NEW BEST: epoch 0 valid F1 =  0.824079754214 in 81.8548219204 (sec)                               \n",
      "(0.88017429193899777, 0.82407975421403268) 75.90 (sec)\n",
      "[[404   0]\n",
      " [ 55   0]]\n",
      "NEW BEST: epoch 0 valid F1 =  0.792537933795 in 81.1007399559 (sec)                               \n",
      "(0.85807860262008728, 0.7925379337948163)n 75.58 (sec)\n",
      "[[393   0]\n",
      " [ 65   0]]\n",
      "NEW BEST: epoch 0 valid F1 =  0.804969483388 in 80.8233170509 (sec)                               \n",
      "(0.86681222707423577, 0.80496948338823771) 75.07 (sec)\n",
      "[[397   0]\n",
      " [ 61   0]]\n",
      "(0.86681222707423577, 0.80496948338823771)\n",
      "[[ 1967.     0.]\n",
      " [  326.     0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "import utils.evaluation as evaluation\n",
    "from keras import metrics\n",
    "import time\n",
    "import sys\n",
    "\n",
    "\n",
    "class_weight = {0 : 1.,\n",
    "    1: (len(y)-sum(y))/sum(y)}\n",
    "\n",
    "acc_list = []\n",
    "f1_list = []\n",
    "cm_summed = np.zeros((2,2))\n",
    "kf = KFold(n_splits=5, shuffle = True)\n",
    "for train_index, test_index in kf.split(X_sequences):\n",
    "    K.clear_session()\n",
    "\n",
    "    num_words = embedding_matrix.shape[0]\n",
    "    embedding_dim = embedding_matrix.shape[1]\n",
    "    \n",
    "    model_lstm = Sequential()\n",
    "    model_lstm.add(Embedding(num_words,\n",
    "                                embedding_dim,\n",
    "                                weights=[embedding_matrix],\n",
    "                                trainable=False))\n",
    "\n",
    "    model_lstm.add(Bidirectional(LSTM(hyperparameters['conv_units'], activation='sigmoid', return_sequences=False)))\n",
    "    model_lstm.add(GaussianNoise(hyperparameters['gauss_stddev']))\n",
    "    model_lstm.add(Dropout(hyperparameters['dropout']))\n",
    "    model_lstm.add(Dense(units=hyperparameters['hidden_units_1']))\n",
    "    if hyperparameters['hidden_units_2'] > 0:\n",
    "        model_lstm.add(Dense(units=hyperparameters['hidden_units_2']))\n",
    "    model_lstm.add(Dense(units=hyperparameters['nclasses']))\n",
    "    model_lstm.add(Activation(\"softmax\"))\n",
    "\n",
    "    optimizer = RMSprop(lr=hyperparameters['learning_rate'])\n",
    "    model_lstm.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  #optimizer='adadelta',\n",
    "                  metrics=['acc'])\n",
    "\n",
    "    #print(model.summary())\n",
    "    \n",
    "    X_train, X_test = np.asarray(X_sequences)[train_index], np.asarray(X_sequences)[test_index]\n",
    "    y_train, y_test = y_matrix[train_index], y_matrix[test_index]\n",
    "\n",
    "    # train\n",
    "    nsentences = len(X_train)\n",
    "    best_f1 = -np.inf\n",
    "    for epoch in xrange(hyperparameters['epochs']):\n",
    "        # Shuffle datasets\n",
    "        #shuffle([x_train, y_train], 42)\n",
    "        tic = time.time()\n",
    "        for i in xrange(nsentences):\n",
    "            X_lstm = np.asarray([X_train[i]])\n",
    "            Y_lstm = y_train[i].reshape((1,hyperparameters['nclasses']))\n",
    "            if X_lstm.shape[1] == 1:\n",
    "                continue # Bug with X, Y of len 1\n",
    "            model_lstm.train_on_batch(X_lstm, Y_lstm)\n",
    "            print '[learning] epoch %i >> %2.2f%%'%(epoch,(i+1)*100./nsentences)+\\\n",
    "                    ' completed in %.2f (sec)\\r'%(time.time()-tic),\n",
    "            sys.stdout.flush()\n",
    "\n",
    "        # Evaluation // back into the real world : idx -> words\n",
    "        predictions = [map(lambda x: x, model_lstm.predict_on_batch(np.asarray([x])).argmax(1))[0] \\\n",
    "            for x in X_test]\n",
    "        ground_truth = y_test.argmax(1)\n",
    "\n",
    "        f1_valid = evaluation.eval_f1_score(ground_truth, predictions)\n",
    "\n",
    "        if f1_valid > best_f1:\n",
    "            best_f1 = f1_valid\n",
    "            model_lstm.save_weights('best_model_lstm.h5', overwrite=True)\n",
    "            print 'NEW BEST: epoch', epoch, 'valid F1 = ', f1_valid, 'in', str(time.time()-tic), '(sec)',' '*30\n",
    "\n",
    "        # load best performing model\n",
    "        model_lstm.load_weights('best_model_lstm.h5')\n",
    "\n",
    "    # eval\n",
    "    ground_truth = y_test.argmax(1)\n",
    "    predictions = [list(map(lambda x: x, model_lstm.predict_on_batch(np.asarray([x])).argmax(1)))[0] \\\n",
    "            for x in X_test]\n",
    "    \n",
    "    \n",
    "    acc = evaluation.accuracy(ground_truth, predictions)\n",
    "    f1 = evaluation.eval_f1_score(ground_truth, predictions)    \n",
    "    cm = evaluation.cm_matrix(ground_truth, predictions)\n",
    "    acc_list.append(acc)\n",
    "    f1_list.append(f1)\n",
    "    cm_summed = cm_summed + cm\n",
    "    print(acc, f1)\n",
    "    print(cm)\n",
    "    \n",
    "    #break\n",
    "    #del model\n",
    "    #K.clear_session()\n",
    "    \n",
    "print(np.asarray(acc).mean(), np.asarray(f1).mean())\n",
    "print(cm_summed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ground_truth = y_test.argmax(1)\n",
    "predictions = [list(map(lambda x: x, model_lstm.predict_on_batch(np.asarray([x]))))[0] \\\n",
    "        for x in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.86681222707423577, 0.92865497076023384, 0, 458)\n",
      "(0.0, '% - ', 0)\n",
      "\n",
      "\n",
      "('Rejected good ones: ', 61, '/', 61)\n",
      "('Accepted wrong ones:', 0, '/', 397)\n",
      "\n",
      "\n",
      "('Rejected wrong ones: ', 397, '/', 397)\n",
      "('Accepted good ones:', 0, '/', 61)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.90840906,  0.09159097],\n",
       "       [ 0.88821292,  0.11178701],\n",
       "       [ 0.89566678,  0.10433322],\n",
       "       [ 0.89800155,  0.10199841],\n",
       "       [ 0.89574528,  0.10425469]], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted_proba_np = np.asarray(predictions)\n",
    "#y_predicted = (y_predicted_proba_np[:,1] > 0.001)\n",
    "y_predicted = (y_predicted_proba_np[:,1] > 0.4791)\n",
    "\n",
    "acc = accuracy_score(y_predicted, ground_truth)\n",
    "f1 = f1_score(y_predicted, ground_truth, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected good ones: \", len(X_test_df[(y_predicted != ground_truth) & (y_predicted == False)]), \"/\", sum(ground_truth))\n",
    "print(\"Accepted wrong ones:\", len(X_test_df[(y_predicted != ground_truth) & (y_predicted == True)]), \"/\", len(ground_truth)-sum(ground_truth))\n",
    "print(\"\\n\")\n",
    "print(\"Rejected wrong ones: \", len(X_test_df[(y_predicted == ground_truth) & (y_predicted == False)]), \"/\", len(ground_truth)-sum(ground_truth))\n",
    "print(\"Accepted good ones:\", len(X_test_df[(y_predicted == ground_truth) & (y_predicted == True)]), \"/\", sum(ground_truth))\n",
    "\n",
    "# 15% bezbolesnie odrzucic - 0.000008\n",
    "\n",
    "y_predicted_proba_np[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extree - pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing word vectors.\n",
      "Found 1032578 word vectors.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "import models.embedding_matrix as embedding\n",
    "reload(embedding)\n",
    "\n",
    "DATASETS_DIR = '../ml-research/datasets/'\n",
    "WIKI_DIR = DATASETS_DIR+'wiki.pl/'\n",
    "embeddings_file = WIKI_DIR+'wiki.pl.vec'\n",
    "\n",
    "word2vec_pretrained = embedding.create_embedding_dictionary(embeddings_file)\n",
    "\n",
    "# train word2vec on all the texts - both training and test set\n",
    "# we're not using test labels, just texts so this is fine\n",
    "model = Word2Vec(X, size=100, window=5, min_count=5, workers=2)\n",
    "w2v_custom = {w: vec for w, vec in zip(model.wv.index2word, model.wv.syn0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "class MeanEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        self.dim = len(word2vec.itervalues().next())\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        return self \n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "            np.mean([self.word2vec[w] for w in words if w in self.word2vec] \n",
    "                    or [np.zeros(self.dim)], axis=0)\n",
    "            for words in X\n",
    "        ])\n",
    "    \n",
    "# and a tf-idf version of the same\n",
    "\n",
    "class TfidfEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        self.word2weight = None\n",
    "        self.dim = len(word2vec.itervalues().next())\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        tfidf = TfidfVectorizer(analyzer=lambda x: x)\n",
    "        tfidf.fit(X)\n",
    "        # if a word was never seen - it must be at least as infrequent\n",
    "        # as any of the known words - so the default idf is the max of \n",
    "        # known idf's\n",
    "        max_idf = max(tfidf.idf_)\n",
    "        self.word2weight = defaultdict(\n",
    "            lambda: max_idf, \n",
    "            [(w, tfidf.idf_[i]) for w, i in tfidf.vocabulary_.items()])\n",
    "    \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "                np.mean([self.word2vec[w] * self.word2weight[w]\n",
    "                         for w in words if w in self.word2vec] or\n",
    "                        [np.zeros(self.dim)], axis=0)\n",
    "                for words in X\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extra Trees classifier is almost universally great, let's stack it with our embeddings\n",
    "\n",
    "etree_w2v = Pipeline([(\"word2vec vectorizer\", MeanEmbeddingVectorizer(word2vec_pretrained)), \n",
    "                        (\"extra trees\", ExtraTreesClassifier(n_estimators=50))])\n",
    "etree_w2v_tfidf = Pipeline([(\"word2vec vectorizer\", TfidfEmbeddingVectorizer(word2vec_pretrained)), \n",
    "                        (\"svc\", ExtraTreesClassifier(n_estimators=50))])\n",
    "svc_w2v = Pipeline([(\"word2vec vectorizer\", MeanEmbeddingVectorizer(word2vec_pretrained)), \n",
    "                        (\"extra trees\", SVC(kernel=\"linear\", probability=True))])\n",
    "svc_w2v_tfidf = Pipeline([(\"word2vec vectorizer\", TfidfEmbeddingVectorizer(word2vec_pretrained)), \n",
    "                        (\"svc\", SVC(kernel=\"linear\", probability=True))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.51416122004357301, 0.43283218084765002, 234, 459)\n",
      "(50.980392156862742, '% - ', 25)\n",
      "\n",
      "\n",
      "('Rejected good ones: ', 22, '/', 55)\n",
      "('Accepted wrong ones:', 201, '/', 404)\n",
      "\n",
      "\n",
      "('Rejected wrong ones: ', 203, '/', 404)\n",
      "('Accepted good ones:', 33, '/', 55)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.82,  0.18],\n",
       "       [ 0.9 ,  0.1 ],\n",
       "       [ 0.86,  0.14],\n",
       "       [ 0.92,  0.08],\n",
       "       [ 0.92,  0.08]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "limit = int(0.8*len(X))\n",
    "\n",
    "X_train = X[:limit]\n",
    "X_test = X[limit:]\n",
    "\n",
    "y_train = y[:limit]\n",
    "y_test = y[limit:]\n",
    "\n",
    "etree_w2v.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = etree_w2v.predict(X_test)\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "\n",
    "y_predicted_proba = etree_w2v.predict_proba(X_test)\n",
    "#y_predicted = (y_predicted_proba[:,1] > 0.12)\n",
    "y_predicted = (y_predicted_proba[:,1] > 0.14)\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected good ones: \", len(X_test_df[(y_predicted != y_test) & (y_predicted == False)]), \"/\", sum(y_test))\n",
    "print(\"Accepted wrong ones:\", len(X_test_df[(y_predicted != y_test) & (y_predicted == True)]), \"/\", len(y_test)-sum(y_test))\n",
    "print(\"\\n\")\n",
    "print(\"Rejected wrong ones: \", len(X_test_df[(y_predicted == y_test) & (y_predicted == False)]), \"/\", len(y_test)-sum(y_test))\n",
    "print(\"Accepted good ones:\", len(X_test_df[(y_predicted == y_test) & (y_predicted == True)]), \"/\", sum(y_test))\n",
    "\n",
    "y_predicted_proba[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.48148148148148145, 0.39896782027929573, 253, 459)\n",
      "(55.119825708061001, '% - ', 27)\n",
      "\n",
      "\n",
      "('Rejected good ones: ', 20, '/', 55)\n",
      "('Accepted wrong ones:', 218, '/', 404)\n",
      "\n",
      "\n",
      "('Rejected wrong ones: ', 186, '/', 404)\n",
      "('Accepted good ones:', 35, '/', 55)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.72,  0.28],\n",
       "       [ 0.92,  0.08],\n",
       "       [ 0.88,  0.12],\n",
       "       [ 0.94,  0.06],\n",
       "       [ 0.94,  0.06]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "limit = int(0.8*len(X))\n",
    "\n",
    "X_train = X[:limit]\n",
    "X_test = X[limit:]\n",
    "\n",
    "y_train = y[:limit]\n",
    "y_test = y[limit:]\n",
    "\n",
    "etree_w2v_tfidf.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = etree_w2v_tfidf.predict(X_test)\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "\n",
    "y_predicted_proba = etree_w2v_tfidf.predict_proba(X_test)\n",
    "#y_predicted = (y_predicted_proba[:,1] > 0.12)\n",
    "y_predicted = (y_predicted_proba[:,1] > 0.137)\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected good ones: \", len(X_test_df[(y_predicted != y_test) & (y_predicted == False)]), \"/\", sum(y_test))\n",
    "print(\"Accepted wrong ones:\", len(X_test_df[(y_predicted != y_test) & (y_predicted == True)]), \"/\", len(y_test)-sum(y_test))\n",
    "print(\"\\n\")\n",
    "print(\"Rejected wrong ones: \", len(X_test_df[(y_predicted == y_test) & (y_predicted == False)]), \"/\", len(y_test)-sum(y_test))\n",
    "print(\"Accepted good ones:\", len(X_test_df[(y_predicted == y_test) & (y_predicted == True)]), \"/\", sum(y_test))\n",
    "\n",
    "y_predicted_proba[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.32897603485838778, 0.26313888279912756, 331, 459)\n",
      "(72.113289760348579, '% - ', 36)\n",
      "\n",
      "\n",
      "('Rejected good ones: ', 16, '/', 55)\n",
      "('Accepted wrong ones:', 292, '/', 404)\n",
      "\n",
      "\n",
      "('Rejected wrong ones: ', 112, '/', 404)\n",
      "('Accepted good ones:', 39, '/', 55)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.87352436,  0.12647564],\n",
       "       [ 0.87447085,  0.12552915],\n",
       "       [ 0.88665125,  0.11334875],\n",
       "       [ 0.83110076,  0.16889924],\n",
       "       [ 0.85441572,  0.14558428]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "limit = int(0.8*len(X))\n",
    "\n",
    "X_train = X[:limit]\n",
    "X_test = X[limit:]\n",
    "\n",
    "y_train = y[:limit]\n",
    "y_test = y[limit:]\n",
    "\n",
    "svc_w2v.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = svc_w2v.predict(X_test)\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "\n",
    "y_predicted_proba = svc_w2v.predict_proba(X_test)\n",
    "#y_predicted = (y_predicted_proba[:,1] > 0.12)\n",
    "y_predicted = (y_predicted_proba[:,1] > 0.135)\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected good ones: \", len(X_test_df[(y_predicted != y_test) & (y_predicted == False)]), \"/\", sum(y_test))\n",
    "print(\"Accepted wrong ones:\", len(X_test_df[(y_predicted != y_test) & (y_predicted == True)]), \"/\", len(y_test)-sum(y_test))\n",
    "print(\"\\n\")\n",
    "print(\"Rejected wrong ones: \", len(X_test_df[(y_predicted == y_test) & (y_predicted == False)]), \"/\", len(y_test)-sum(y_test))\n",
    "print(\"Accepted good ones:\", len(X_test_df[(y_predicted == y_test) & (y_predicted == True)]), \"/\", sum(y_test))\n",
    "\n",
    "y_predicted_proba[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.4662309368191721, 0.38512818744562033, 266, 459)\n",
      "(57.952069716775597, '% - ', 28)\n",
      "\n",
      "\n",
      "('Rejected good ones: ', 17, '/', 55)\n",
      "('Accepted wrong ones:', 228, '/', 404)\n",
      "\n",
      "\n",
      "('Rejected wrong ones: ', 176, '/', 404)\n",
      "('Accepted good ones:', 38, '/', 55)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.85302655,  0.14697345],\n",
       "       [ 0.85690779,  0.14309221],\n",
       "       [ 0.90907751,  0.09092249],\n",
       "       [ 0.8051091 ,  0.1948909 ],\n",
       "       [ 0.87100243,  0.12899757]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "limit = int(0.8*len(X))\n",
    "\n",
    "X_train = X[:limit]\n",
    "X_test = X[limit:]\n",
    "\n",
    "y_train = y[:limit]\n",
    "y_test = y[limit:]\n",
    "\n",
    "svc_w2v_tfidf.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = svc_w2v_tfidf.predict(X_test)\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "\n",
    "y_predicted_proba = svc_w2v_tfidf.predict_proba(X_test)\n",
    "#y_predicted = (y_predicted_proba[:,1] > 0.12)\n",
    "y_predicted = (y_predicted_proba[:,1] > 0.145)\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected good ones: \", len(X_test_df[(y_predicted != y_test) & (y_predicted == False)]), \"/\", sum(y_test))\n",
    "print(\"Accepted wrong ones:\", len(X_test_df[(y_predicted != y_test) & (y_predicted == True)]), \"/\", len(y_test)-sum(y_test))\n",
    "print(\"\\n\")\n",
    "print(\"Rejected wrong ones: \", len(X_test_df[(y_predicted == y_test) & (y_predicted == False)]), \"/\", len(y_test)-sum(y_test))\n",
    "print(\"Accepted good ones:\", len(X_test_df[(y_predicted == y_test) & (y_predicted == True)]), \"/\", sum(y_test))\n",
    "\n",
    "y_predicted_proba[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extree - Custom embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extra Trees classifier is almost universally great, let's stack it with our embeddings\n",
    "\n",
    "etree_w2v_custom = Pipeline([(\"word2vec vectorizer\", MeanEmbeddingVectorizer(w2v_custom)), \n",
    "                        (\"extra trees\", ExtraTreesClassifier(n_estimators=50))])\n",
    "etree_w2v_tfidf_custom = Pipeline([(\"word2vec vectorizer\", TfidfEmbeddingVectorizer(w2v_custom)), \n",
    "                        (\"svc\", ExtraTreesClassifier(n_estimators=50))])\n",
    "svc_w2v_custom = Pipeline([(\"word2vec vectorizer\", MeanEmbeddingVectorizer(w2v_custom)), \n",
    "                        (\"extra trees\", SVC(kernel=\"linear\", probability=True))])\n",
    "svc_w2v_tfidf_custom = Pipeline([(\"word2vec vectorizer\", TfidfEmbeddingVectorizer(w2v_custom)), \n",
    "                        (\"svc\", SVC(kernel=\"linear\", probability=True))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.54030501089324623, 0.46335242223701412, 234, 459)\n",
      "(50.980392156862742, '% - ', 25)\n",
      "\n",
      "\n",
      "('Rejected good ones: ', 16, '/', 55)\n",
      "('Accepted wrong ones:', 195, '/', 404)\n",
      "\n",
      "\n",
      "('Rejected wrong ones: ', 209, '/', 404)\n",
      "('Accepted good ones:', 39, '/', 55)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.74,  0.26],\n",
       "       [ 0.94,  0.06],\n",
       "       [ 0.82,  0.18],\n",
       "       [ 0.86,  0.14],\n",
       "       [ 0.88,  0.12]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "limit = int(0.8*len(X))\n",
    "\n",
    "X_train = X[:limit]\n",
    "X_test = X[limit:]\n",
    "\n",
    "y_train = y[:limit]\n",
    "y_test = y[limit:]\n",
    "\n",
    "etree_w2v_custom.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = etree_w2v_custom.predict(X_test)\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "\n",
    "y_predicted_proba = etree_w2v_custom.predict_proba(X_test)\n",
    "#y_predicted = (y_predicted_proba[:,1] > 0.12)\n",
    "y_predicted = (y_predicted_proba[:,1] > 0.14)\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected good ones: \", len(X_test_df[(y_predicted != y_test) & (y_predicted == False)]), \"/\", sum(y_test))\n",
    "print(\"Accepted wrong ones:\", len(X_test_df[(y_predicted != y_test) & (y_predicted == True)]), \"/\", len(y_test)-sum(y_test))\n",
    "print(\"\\n\")\n",
    "print(\"Rejected wrong ones: \", len(X_test_df[(y_predicted == y_test) & (y_predicted == False)]), \"/\", len(y_test)-sum(y_test))\n",
    "print(\"Accepted good ones:\", len(X_test_df[(y_predicted == y_test) & (y_predicted == True)]), \"/\", sum(y_test))\n",
    "\n",
    "y_predicted_proba[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.4989106753812636, 0.4196849651009244, 255, 459)\n",
      "(55.555555555555557, '% - ', 27)\n",
      "\n",
      "\n",
      "('Rejected good ones: ', 15, '/', 55)\n",
      "('Accepted wrong ones:', 215, '/', 404)\n",
      "\n",
      "\n",
      "('Rejected wrong ones: ', 189, '/', 404)\n",
      "('Accepted good ones:', 40, '/', 55)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.7 ,  0.3 ],\n",
       "       [ 0.86,  0.14],\n",
       "       [ 0.92,  0.08],\n",
       "       [ 0.9 ,  0.1 ],\n",
       "       [ 0.82,  0.18]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "limit = int(0.8*len(X))\n",
    "\n",
    "X_train = X[:limit]\n",
    "X_test = X[limit:]\n",
    "\n",
    "y_train = y[:limit]\n",
    "y_test = y[limit:]\n",
    "\n",
    "etree_w2v_tfidf_custom.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = etree_w2v_tfidf_custom.predict(X_test)\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "\n",
    "y_predicted_proba = etree_w2v_tfidf_custom.predict_proba(X_test)\n",
    "#y_predicted = (y_predicted_proba[:,1] > 0.12)\n",
    "y_predicted = (y_predicted_proba[:,1] > 0.137)\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected good ones: \", len(X_test_df[(y_predicted != y_test) & (y_predicted == False)]), \"/\", sum(y_test))\n",
    "print(\"Accepted wrong ones:\", len(X_test_df[(y_predicted != y_test) & (y_predicted == True)]), \"/\", len(y_test)-sum(y_test))\n",
    "print(\"\\n\")\n",
    "print(\"Rejected wrong ones: \", len(X_test_df[(y_predicted == y_test) & (y_predicted == False)]), \"/\", len(y_test)-sum(y_test))\n",
    "print(\"Accepted good ones:\", len(X_test_df[(y_predicted == y_test) & (y_predicted == True)]), \"/\", sum(y_test))\n",
    "\n",
    "y_predicted_proba[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.18300653594771241, 0.19126781002699925, 410, 459)\n",
      "(89.324618736383442, '% - ', 44)\n",
      "\n",
      "\n",
      "('Rejected good ones: ', 10, '/', 55)\n",
      "('Accepted wrong ones:', 365, '/', 404)\n",
      "\n",
      "\n",
      "('Rejected wrong ones: ', 39, '/', 404)\n",
      "('Accepted good ones:', 45, '/', 55)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.85814773,  0.14185227],\n",
       "       [ 0.83613767,  0.16386233],\n",
       "       [ 0.86272365,  0.13727635],\n",
       "       [ 0.83288082,  0.16711918],\n",
       "       [ 0.85589108,  0.14410892]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "limit = int(0.8*len(X))\n",
    "\n",
    "X_train = X[:limit]\n",
    "X_test = X[limit:]\n",
    "\n",
    "y_train = y[:limit]\n",
    "y_test = y[limit:]\n",
    "\n",
    "svc_w2v_custom.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = svc_w2v_custom.predict(X_test)\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "\n",
    "y_predicted_proba = svc_w2v_custom.predict_proba(X_test)\n",
    "#y_predicted = (y_predicted_proba[:,1] > 0.12)\n",
    "y_predicted = (y_predicted_proba[:,1] > 0.135)\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected good ones: \", len(X_test_df[(y_predicted != y_test) & (y_predicted == False)]), \"/\", sum(y_test))\n",
    "print(\"Accepted wrong ones:\", len(X_test_df[(y_predicted != y_test) & (y_predicted == True)]), \"/\", len(y_test)-sum(y_test))\n",
    "print(\"\\n\")\n",
    "print(\"Rejected wrong ones: \", len(X_test_df[(y_predicted == y_test) & (y_predicted == False)]), \"/\", len(y_test)-sum(y_test))\n",
    "print(\"Accepted good ones:\", len(X_test_df[(y_predicted == y_test) & (y_predicted == True)]), \"/\", sum(y_test))\n",
    "\n",
    "y_predicted_proba[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.37037037037037035, 0.29010137398299413, 300, 459)\n",
      "(65.359477124183002, '% - ', 32)\n",
      "\n",
      "\n",
      "('Rejected good ones: ', 22, '/', 55)\n",
      "('Accepted wrong ones:', 267, '/', 404)\n",
      "\n",
      "\n",
      "('Rejected wrong ones: ', 137, '/', 404)\n",
      "('Accepted good ones:', 33, '/', 55)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.86169592,  0.13830408],\n",
       "       [ 0.81362768,  0.18637232],\n",
       "       [ 0.86764605,  0.13235395],\n",
       "       [ 0.82867217,  0.17132783],\n",
       "       [ 0.83682704,  0.16317296]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "limit = int(0.8*len(X))\n",
    "\n",
    "X_train = X[:limit]\n",
    "X_test = X[limit:]\n",
    "\n",
    "y_train = y[:limit]\n",
    "y_test = y[limit:]\n",
    "\n",
    "svc_w2v_tfidf_custom.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = svc_w2v_tfidf_custom.predict(X_test)\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "\n",
    "y_predicted_proba = svc_w2v_tfidf_custom.predict_proba(X_test)\n",
    "#y_predicted = (y_predicted_proba[:,1] > 0.12)\n",
    "y_predicted = (y_predicted_proba[:,1] > 0.145)\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected good ones: \", len(X_test_df[(y_predicted != y_test) & (y_predicted == False)]), \"/\", sum(y_test))\n",
    "print(\"Accepted wrong ones:\", len(X_test_df[(y_predicted != y_test) & (y_predicted == True)]), \"/\", len(y_test)-sum(y_test))\n",
    "print(\"\\n\")\n",
    "print(\"Rejected wrong ones: \", len(X_test_df[(y_predicted == y_test) & (y_predicted == False)]), \"/\", len(y_test)-sum(y_test))\n",
    "print(\"Accepted good ones:\", len(X_test_df[(y_predicted == y_test) & (y_predicted == True)]), \"/\", sum(y_test))\n",
    "\n",
    "y_predicted_proba[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
