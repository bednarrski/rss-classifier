{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from api import inoreader_api, inoreader_scraping\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "percentile = 33.3\n",
    "workers_split = 0.8\n",
    "manager_split = 0.8\n",
    "\n",
    "\n",
    "def rewrite(x):\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape feeds starting from a concrete moment and store them in a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv\n",
      "200 OK\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "start_time = 1517463300 #1508112001\n",
    "feed = 'user/-/label/arXiv'\n",
    "file_name = 'articles_raw.json'\n",
    "\n",
    "number_scraped = inoreader_scraping.scrape(feed, start_time, file_name)\n",
    "print(number_scraped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the feeds from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open(file_name, 'r')\n",
    "json_string = f.read()\n",
    "f.close\n",
    "\n",
    "json_object = json.loads(json_string)\n",
    "all_articles = json_object['all_articles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_abstract_string(abs_dict):\n",
    "    abs_string = abs_dict['content']\n",
    "    abs_string = re.search('<p>(.*)</p>', abs_string, flags=re.DOTALL)\n",
    "    return abs_string.group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_canonical_string(canonical_list):\n",
    "    url_dict = canonical_list[0]\n",
    "    url = url_dict['href']\n",
    "    return url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create preprocessed and cleaned DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piotr.bednarski/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/piotr.bednarski/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/piotr.bednarski/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/piotr.bednarski/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "all_articles_pd = pd.DataFrame(all_articles)\n",
    "all_articles_pd = all_articles_pd[['canonical', 'author', 'categories', 'published', 'title', 'summary']]\n",
    "\n",
    "for i in range(len(all_articles_pd)):\n",
    "    all_articles_pd['summary'][i] = get_abstract_string(all_articles_pd['summary'][i])\n",
    "    all_articles_pd['canonical'][i] = get_canonical_string(all_articles_pd['canonical'][i])\n",
    "    \n",
    "all_articles_pd['read'] = False\n",
    "all_articles_pd['liked'] = False\n",
    "\n",
    "for i in range(len(all_articles_pd)):\n",
    "    if 'user/1005689817/state/com.google/read' in all_articles_pd['categories'][i]:\n",
    "        all_articles_pd['read'][i] = True\n",
    "    if 'user/1005689817/state/com.google/like' in all_articles_pd['categories'][i]:\n",
    "        all_articles_pd['liked'][i] = True\n",
    "\n",
    "del all_articles_pd['categories']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#all_articles_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "2826\n"
     ]
    }
   ],
   "source": [
    "tagged_articles_pd = all_articles_pd[all_articles_pd['read'] == True]\n",
    "\n",
    "with open('old_articles_good_and_bad.pickle', 'rb') as f:\n",
    "    # Pickle the 'data' dictionary using the highest protocol available.\n",
    "    old_tagged_articles_pd = pickle.load(f)\n",
    "    \n",
    "print(len(tagged_articles_pd))\n",
    "print(len(old_tagged_articles_pd))\n",
    "    \n",
    "tagged_articles_pd = pd.concat([tagged_articles_pd, old_tagged_articles_pd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tagged_articles_unique_pd = tagged_articles_pd.sort_values(by=['canonical', 'liked'], ascending=False).reset_index(drop=True)\n",
    "to_drop = tagged_articles_unique_pd.duplicated(subset = ['canonical'], keep='first')\n",
    "to_drop = list(to_drop[to_drop == False].index.values)\n",
    "\n",
    "tagged_articles_unique_pd = tagged_articles_unique_pd[tagged_articles_unique_pd.index.isin(to_drop)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2846\n",
      "2826\n"
     ]
    }
   ],
   "source": [
    "print(len(tagged_articles_pd))\n",
    "print(len(tagged_articles_unique_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Do you want to save new dataset?\n",
    "if True:\n",
    "    with open('old_articles_good_and_bad.pickle', 'wb') as f:\n",
    "        # Pickle the 'data' dictionary using the highest protocol available.\n",
    "        pickle.dump(tagged_articles_unique_pd, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    del tagged_articles_unique_pd\n",
    "\n",
    "    with open('old_articles_good_and_bad.pickle', 'rb') as f:\n",
    "        # Pickle the 'data' dictionary using the highest protocol available.\n",
    "        tagged_articles_unique_pd = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_ = list(tagged_articles_unique_pd['author']+' '+tagged_articles_unique_pd['title']+' '+tagged_articles_unique_pd['summary'])\n",
    "y_ = list(tagged_articles_unique_pd['liked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index_shuffled = [i for i in range(len(X_))]\n",
    "random.shuffle(index_shuffled)\n",
    "X = []\n",
    "y = []\n",
    "for i in index_shuffled:\n",
    "    X.append(X_[i])\n",
    "    y.append(y_[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('stopwords/english') as f:\n",
    "    stopwords = [line.strip() for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "883\n",
      "717\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def text_to_word_sequence(text,\n",
    "                          filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "                          lower=True, split=\" \"):\n",
    "    if lower: text = text.lower()\n",
    "    if type(text) == str:\n",
    "        translate_table = {ord(c): ord(t) for c,t in zip(filters, split*len(filters)) }\n",
    "    else:\n",
    "        translate_table = maketrans(filters, split * len(filters))\n",
    "    text = text.translate(translate_table)\n",
    "    seq = text.split(split)\n",
    "    return [i for i in seq if i]\n",
    "\n",
    "print(len(X[4]))\n",
    "\n",
    "for i in range(len(X)):\n",
    "    seq = text_to_word_sequence(X[i])\n",
    "    clean_seq = [word for word in seq if word not in stopwords]\n",
    "    X[i] = ' '.join(clean_seq)\n",
    "    \n",
    "print(len(X[4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving or loading the data and LE and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2260\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "data_dict = {\n",
    "    'X' : X,\n",
    "    'y' : y\n",
    "}\n",
    "pickle.dump(data_dict,open(\"data.pickle\", \"wb\" ) )\n",
    "\n",
    "\n",
    "limit = int(0.8*len(X))\n",
    "print(limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2260\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "data_dict = pickle.load(open( \"data.pickle\", \"rb\" ) )\n",
    "X = data_dict['X']\n",
    "y = data_dict['y']\n",
    "limit = int(workers_split*len(X))\n",
    "print(limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_ = X\n",
    "y_ = y\n",
    "index_shuffled = [i for i in range(len(X_))]\n",
    "random.shuffle(index_shuffled)\n",
    "X = []\n",
    "y = []\n",
    "for i in index_shuffled:\n",
    "    X.append(X_[i])\n",
    "    y.append(y_[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF -> NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piotr.bednarski/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/piotr.bednarski/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8568904593639576, 0.9211958168277945)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "\n",
    "\n",
    "model_nb_tfidf = Pipeline([\n",
    "    (\"tfidf_vectorizer\", TfidfVectorizer()),\\\n",
    "    (\"nb\", BernoulliNB())\n",
    "])\n",
    "\n",
    "\n",
    "X_train = X[:limit]\n",
    "X_test = X[limit:]\n",
    "\n",
    "y_train = y[:limit]\n",
    "y_test = y[limit:]\n",
    "\n",
    "model_nb_tfidf.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = model_nb_tfidf.predict(X_test)\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "acc, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6696113074204947 0.6249163501226127 189 566\n",
      "33.39222614840989 % -  16\n",
      "\n",
      "\n",
      "Rejected 69.63% of wrong ones\n",
      "Accepted 51.22% of good ones\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piotr.bednarski/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+00, 1.20365054e-11],\n",
       "       [1.00000000e+00, 1.09298861e-25],\n",
       "       [1.00000000e+00, 1.83262803e-16],\n",
       "       [1.00000000e+00, 1.68716184e-25],\n",
       "       [1.00000000e+00, 8.51393034e-24]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted_proba = model_nb_tfidf.predict_proba(X_test)\n",
    "#y_predicted = (y_predicted_proba[:,1] > 0.15)\n",
    "y_predicted = (y_predicted_proba[:,1] > np.percentile(y_predicted_proba[:,1],100-percentile))\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)/len(y_predicted)*100.0,\"% - \", int(sum(y_predicted)/len(y_predicted)*50.0))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected %.2f%% of wrong ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == False)])*100.0/(len(y_test)-sum(y_test))))\n",
    "print(\"Accepted %.2f%% of good ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == True)])*100.0/sum(y_test)))\n",
    "\n",
    "y_predicted_proba[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CountVect -> NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piotr.bednarski/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8551236749116607, 0.9219047619047619)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "\n",
    "\n",
    "model_nb = Pipeline([\n",
    "    #('vect', CountVectorizer(ngram_range=(1,3),stop_words='english')),\\\n",
    "    (\"count_vectorizer\", CountVectorizer(analyzer=rewrite)),\\\n",
    "    (\"nb\", BernoulliNB())\n",
    "])\n",
    "\n",
    "X_train = X[:limit]\n",
    "X_test = X[limit:]\n",
    "\n",
    "y_train = y[:limit]\n",
    "y_test = y[limit:]\n",
    "\n",
    "model_nb.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = model_nb.predict(X_test)\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "acc, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6342756183745583 0.5848004517400045 189 566\n",
      "33.3922261484099 % -  16\n",
      "\n",
      "\n",
      "Rejected 67.56% of wrong ones\n",
      "Accepted 39.02% of good ones\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.8651149 , 0.1348851 ],\n",
       "       [0.8580219 , 0.1419781 ],\n",
       "       [0.87645224, 0.12354776],\n",
       "       [0.88077268, 0.11922732],\n",
       "       [0.89556866, 0.10443134]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted_proba = model_nb.predict_proba(X_test)\n",
    "#y_predicted = (y_predicted_proba[:,1] > 0.1296)\n",
    "y_predicted = (y_predicted_proba[:,1] > np.percentile(y_predicted_proba[:,1],100-percentile))\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected %.2f%% of wrong ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == False)])*100.0/(len(y_test)-sum(y_test))))\n",
    "print(\"Accepted %.2f%% of good ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == True)])*100.0/sum(y_test)))\n",
    "\n",
    "y_predicted_proba[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF -> SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piotr.bednarski/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8551236749116607, 0.8947943594742093)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "\n",
    "model_svc_tfidf = Pipeline([\n",
    "    ('vect', CountVectorizer(ngram_range=(1,3), min_df=1, max_df=1.0,stop_words='english')),\n",
    "    #('vect', CountVectorizer(ngram_range=(3,6),analyzer='char_wb', min_df=10, max_df=0.95,stop_words='english')),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    (\"svc\", SVC(kernel='linear', probability=True, class_weight = 'balanced'))\n",
    "    #(\"svc\", SVC(kernel='linear', probability=True))\n",
    "])\n",
    "\n",
    "X_train = X[:limit]\n",
    "X_test = X[limit:]\n",
    "\n",
    "y_train = y[:limit]\n",
    "y_test = y[limit:]\n",
    "\n",
    "model_svc_tfidf.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = model_svc_tfidf.predict(X_test)\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "acc, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piotr.bednarski/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6837455830388692 0.6409627094756561 189 566\n",
      "33.3922261484099 % -  16\n",
      "\n",
      "\n",
      "Rejected 70.45% of wrong ones\n",
      "Accepted 56.10% of good ones\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.30401739, 0.69598261],\n",
       "       [0.93064309, 0.06935691],\n",
       "       [0.26261182, 0.73738818],\n",
       "       [0.94961737, 0.05038263],\n",
       "       [0.64480508, 0.35519492]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted_proba = model_svc_tfidf.predict_proba(X_test)\n",
    "#y_predicted = (y_predicted_proba[:,1] > 0.12)\n",
    "y_predicted = (y_predicted_proba[:,1] > np.percentile(y_predicted_proba[:,1],100-percentile))\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected %.2f%% of wrong ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == False)])*100.0/(len(y_test)-sum(y_test))))\n",
    "print(\"Accepted %.2f%% of good ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == True)])*100.0/sum(y_test)))\n",
    "\n",
    "y_predicted_proba[0:5]\n",
    "\n",
    "#(0.62077922077922076, 0.55417162908266104, 162, 385)\n",
    "#(42.077922077922075, '% - ', 21)\n",
    "#('Rejected good ones: ', 15, '/', 46)\n",
    "#('Accepted wrong ones:', 131, '/', 339)\n",
    "#('Rejected wrong ones: ', 208, '/', 339)\n",
    "#('Accepted good ones:', 31, '/', 46)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-21.752650176678443"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(X_test_df[(y_predicted == y_test) & (y_predicted == False)])*100.0/len(y_test)-sum(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piotr.bednarski/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7685512367491166, 0.7511766555672601)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "\n",
    "model_svc_tfidf = Pipeline([\n",
    "    #('vect', CountVectorizer(ngram_range=(1,3), min_df=1, max_df=1.0,stop_words='english')),\n",
    "    ('vect', CountVectorizer(ngram_range=(3,6),analyzer='char_wb', min_df=10, max_df=0.95,stop_words='english')),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    (\"svc\", SVC(kernel='linear', probability=True, class_weight = 'balanced'))\n",
    "    #(\"svc\", SVC(kernel='linear', probability=True))\n",
    "])\n",
    "\n",
    "X_train = X[:limit]\n",
    "X_test = X[limit:]\n",
    "\n",
    "y_train = y[:limit]\n",
    "y_test = y[limit:]\n",
    "\n",
    "model_svc_tfidf.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = model_svc_tfidf.predict(X_test)\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "acc, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piotr.bednarski/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6731448763250883 0.6289279399608737 189 566\n",
      "33.3922261484099 % -  16\n",
      "\n",
      "\n",
      "Rejected 69.83% of wrong ones\n",
      "Accepted 52.44% of good ones\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.61847531, 0.38152469],\n",
       "       [0.9401417 , 0.0598583 ],\n",
       "       [0.62974138, 0.37025862],\n",
       "       [0.94740495, 0.05259505],\n",
       "       [0.85043041, 0.14956959]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted_proba = model_svc_tfidf.predict_proba(X_test)\n",
    "#y_predicted = (y_predicted_proba[:,1] > 0.12)\n",
    "y_predicted = (y_predicted_proba[:,1] > np.percentile(y_predicted_proba[:,1],100-percentile))\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected %.2f%% of wrong ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == False)])*100.0/(len(y_test)-sum(y_test))))\n",
    "print(\"Accepted %.2f%% of good ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == True)])*100.0/sum(y_test)))\n",
    "\n",
    "y_predicted_proba[0:5]\n",
    "\n",
    "#(0.62077922077922076, 0.55417162908266104, 162, 385)\n",
    "#(42.077922077922075, '% - ', 21)\n",
    "#('Rejected good ones: ', 15, '/', 46)\n",
    "#('Accepted wrong ones:', 131, '/', 339)\n",
    "#('Rejected wrong ones: ', 208, '/', 339)\n",
    "#('Accepted good ones:', 31, '/', 46)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count -> SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8462897526501767, 0.8997122043122288)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "\n",
    "model_svc = Pipeline([\n",
    "    #('vect', CountVectorizer()),\n",
    "    ('vect', CountVectorizer(ngram_range=(1,3), min_df=1, max_df=1.0,stop_words='english')),\n",
    "    #('vect', CountVectorizer(ngram_range=(3,6),analyzer='char_wb', min_df=10, max_df=0.95,stop_words='english')),\n",
    "    #('tfidf', TfidfTransformer()),\n",
    "    (\"svc\", SVC(kernel='linear', probability=True, class_weight = 'balanced'))\n",
    "    #(\"svc\", SVC(kernel='linear', probability=True))\n",
    "])\n",
    "\n",
    "X_train = X[:limit]\n",
    "X_test = X[limit:]\n",
    "\n",
    "y_train = y[:limit]\n",
    "y_test = y[limit:]\n",
    "\n",
    "model_svc.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = model_svc.predict(X_test)\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "acc, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6731448763250883 0.6289279399608737 189 566\n",
      "33.3922261484099 % -  16\n",
      "\n",
      "\n",
      "Rejected 69.83% of wrong ones\n",
      "Accepted 52.44% of good ones\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.66019501, 0.33980499],\n",
       "       [0.87670942, 0.12329058],\n",
       "       [0.70794005, 0.29205995],\n",
       "       [0.91087068, 0.08912932],\n",
       "       [0.82596868, 0.17403132]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted_proba = model_svc.predict_proba(X_test)\n",
    "#y_predicted = (y_predicted_proba[:,1] > 0.12)\n",
    "y_predicted = (y_predicted_proba[:,1] > np.percentile(y_predicted_proba[:,1],100-percentile))\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected %.2f%% of wrong ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == False)])*100.0/(len(y_test)-sum(y_test))))\n",
    "print(\"Accepted %.2f%% of good ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == True)])*100.0/sum(y_test)))\n",
    "\n",
    "y_predicted_proba[0:5]\n",
    "\n",
    "#(0.62077922077922076, 0.55417162908266104, 162, 385)\n",
    "#(42.077922077922075, '% - ', 21)\n",
    "#('Rejected good ones: ', 15, '/', 46)\n",
    "#('Accepted wrong ones:', 131, '/', 339)\n",
    "#('Rejected wrong ones: ', 208, '/', 339)\n",
    "#('Accepted good ones:', 31, '/', 46)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extree - pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'raz'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = ['raz']\n",
    "'_'.join(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing word vectors.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import models.embedding_matrix as embedding\n",
    "#reload(embedding)\n",
    "\n",
    "DATASETS_DIR = '../ml-research/datasets/'\n",
    "WIKI_DIR = DATASETS_DIR+'wiki.pl/'\n",
    "embeddings_file = WIKI_DIR+'wiki.pl.vec'\n",
    "\n",
    "print('Indexing word vectors.')\n",
    "\n",
    "word2vec_pretrained = {}\n",
    "f = open(embeddings_file, encoding='utf-8')\n",
    "\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = '_'.join(values[:-300])\n",
    "    coefs = np.asarray(values[-300:], dtype='float32')\n",
    "    word2vec_pretrained[word] = coefs\n",
    "f.close()\n",
    "\n",
    "# train word2vec on all the texts - both training and test set\n",
    "# we're not using test labels, just texts so this is fine\n",
    "model = Word2Vec(X, size=100, window=5, min_count=5, workers=2)\n",
    "w2v_custom = {w: vec for w, vec in zip(model.wv.index2word, model.wv.syn0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "class MeanEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        self.dim = len(next(iter(word2vec.items())))\n",
    "        \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        return self \n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "            np.mean([self.word2vec[w] for w in words if w in self.word2vec] \n",
    "                    or [np.zeros(self.dim)], axis=0)\n",
    "            for words in X\n",
    "        ])\n",
    "    \n",
    "# and a tf-idf version of the same\n",
    "\n",
    "class TfidfEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        self.word2weight = None\n",
    "        self.dim = len(next(iter(word2vec.items())))\n",
    "        \n",
    "    def max_idf_func():\n",
    "        return self.max_idf\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        #tfidf = TfidfVectorizer(analyzer=lambda x: x)\n",
    "        tfidf = TfidfVectorizer(analyzer=rewrite)\n",
    "        tfidf.fit(X)\n",
    "        # if a word was never seen - it must be at least as infrequent\n",
    "        # as any of the known words - so the default idf is the max of \n",
    "        # known idf's\n",
    "        self.max_idf = max(tfidf.idf_)\n",
    "        self.word2weight = defaultdict(\n",
    "            #lambda: max_idf, \n",
    "            self.max_idf_func, \n",
    "            [(w, tfidf.idf_[i]) for w, i in tfidf.vocabulary_.items()])\n",
    "    \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "                np.mean([self.word2vec[w] * self.word2weight[w]\n",
    "                         for w in words if w in self.word2vec] or\n",
    "                        [np.zeros(self.dim)], axis=0)\n",
    "                for words in X\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extra Trees classifier is almost universally great, let's stack it with our embeddings\n",
    "\n",
    "etree_w2v = Pipeline([(\"word2vec vectorizer\", MeanEmbeddingVectorizer(word2vec_pretrained)), \n",
    "                        (\"extra trees\", ExtraTreesClassifier(n_estimators=50))])\n",
    "etree_w2v_tfidf = Pipeline([(\"word2vec vectorizer\", TfidfEmbeddingVectorizer(word2vec_pretrained)), \n",
    "                        (\"svc\", ExtraTreesClassifier(n_estimators=50))])\n",
    "svc_w2v = Pipeline([(\"word2vec vectorizer\", MeanEmbeddingVectorizer(word2vec_pretrained)), \n",
    "                        (\"extra trees\", SVC(kernel=\"linear\", probability=True))])\n",
    "svc_w2v_tfidf = Pipeline([(\"word2vec vectorizer\", TfidfEmbeddingVectorizer(word2vec_pretrained)), \n",
    "                        (\"svc\", SVC(kernel=\"linear\", probability=True))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6607773851590106 0.62044741839679 162 566\n",
      "28.62190812720848 % -  14\n",
      "\n",
      "\n",
      "Rejected 71.90% of wrong ones\n",
      "Accepted 31.71% of good ones\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.88, 0.12],\n",
       "       [0.72, 0.28],\n",
       "       [0.6 , 0.4 ],\n",
       "       [0.98, 0.02],\n",
       "       [0.92, 0.08]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "X_train = X[:limit]\n",
    "X_test = X[limit:]\n",
    "\n",
    "y_train = y[:limit]\n",
    "y_test = y[limit:]\n",
    "\n",
    "etree_w2v.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = etree_w2v.predict(X_test)\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "\n",
    "y_predicted_proba = etree_w2v.predict_proba(X_test)\n",
    "#y_predicted = (y_predicted_proba[:,1] > 0.12)\n",
    "y_predicted = (y_predicted_proba[:,1] > np.percentile(y_predicted_proba[:,1],100-percentile))\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected %.2f%% of wrong ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == False)])*100.0/(len(y_test)-sum(y_test))))\n",
    "print(\"Accepted %.2f%% of good ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == True)])*100.0/sum(y_test)))\n",
    "\n",
    "y_predicted_proba[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6378091872791519 0.590673446028085 179 566\n",
      "31.625441696113075 % -  15\n",
      "\n",
      "\n",
      "Rejected 68.80% of wrong ones\n",
      "Accepted 34.15% of good ones\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.84, 0.16],\n",
       "       [0.74, 0.26],\n",
       "       [0.72, 0.28],\n",
       "       [0.92, 0.08],\n",
       "       [0.8 , 0.2 ]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X[:limit]\n",
    "X_test = X[limit:]\n",
    "\n",
    "y_train = y[:limit]\n",
    "y_test = y[limit:]\n",
    "\n",
    "etree_w2v_tfidf.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = etree_w2v_tfidf.predict(X_test)\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "\n",
    "y_predicted_proba = etree_w2v_tfidf.predict_proba(X_test)\n",
    "#y_predicted = (y_predicted_proba[:,1] > 0.12)\n",
    "y_predicted = (y_predicted_proba[:,1] > np.percentile(y_predicted_proba[:,1],100-percentile))\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected %.2f%% of wrong ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == False)])*100.0/(len(y_test)-sum(y_test))))\n",
    "print(\"Accepted %.2f%% of good ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == True)])*100.0/sum(y_test)))\n",
    "\n",
    "y_predicted_proba[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piotr.bednarski/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6130742049469965 0.5607309127104396 189 566\n",
      "33.3922261484099 % -  16\n",
      "\n",
      "\n",
      "Rejected 66.32% of wrong ones\n",
      "Accepted 31.71% of good ones\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.86076473, 0.13923527],\n",
       "       [0.8489032 , 0.1510968 ],\n",
       "       [0.84389459, 0.15610541],\n",
       "       [0.87988403, 0.12011597],\n",
       "       [0.8377424 , 0.1622576 ]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X[:limit]\n",
    "X_test = X[limit:]\n",
    "\n",
    "y_train = y[:limit]\n",
    "y_test = y[limit:]\n",
    "\n",
    "svc_w2v.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = svc_w2v.predict(X_test)\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "\n",
    "y_predicted_proba = svc_w2v.predict_proba(X_test)\n",
    "#y_predicted = (y_predicted_proba[:,1] > 0.12)\n",
    "y_predicted = (y_predicted_proba[:,1] > np.percentile(y_predicted_proba[:,1],100-percentile))\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected %.2f%% of wrong ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == False)])*100.0/(len(y_test)-sum(y_test))))\n",
    "print(\"Accepted %.2f%% of good ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == True)])*100.0/sum(y_test)))\n",
    "\n",
    "y_predicted_proba[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piotr.bednarski/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6307420494699647 0.5807888619017436 189 566\n",
      "33.3922261484099 % -  16\n",
      "\n",
      "\n",
      "Rejected 67.36% of wrong ones\n",
      "Accepted 37.80% of good ones\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.85473874, 0.14526126],\n",
       "       [0.87237684, 0.12762316],\n",
       "       [0.85107407, 0.14892593],\n",
       "       [0.87847818, 0.12152182],\n",
       "       [0.82977453, 0.17022547]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X[:limit]\n",
    "X_test = X[limit:]\n",
    "\n",
    "y_train = y[:limit]\n",
    "y_test = y[limit:]\n",
    "\n",
    "svc_w2v_tfidf.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = svc_w2v_tfidf.predict(X_test)\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "\n",
    "y_predicted_proba = svc_w2v_tfidf.predict_proba(X_test)\n",
    "#y_predicted = (y_predicted_proba[:,1] > 0.12)\n",
    "y_predicted = (y_predicted_proba[:,1] > np.percentile(y_predicted_proba[:,1],100-percentile))\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected %.2f%% of wrong ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == False)])*100.0/(len(y_test)-sum(y_test))))\n",
    "print(\"Accepted %.2f%% of good ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == True)])*100.0/sum(y_test)))\n",
    "\n",
    "y_predicted_proba[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extree - Custom embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extra Trees classifier is almost universally great, let's stack it with our embeddings\n",
    "\n",
    "etree_w2v_custom = Pipeline([(\"word2vec vectorizer\", MeanEmbeddingVectorizer(w2v_custom)), \n",
    "                        (\"extra trees\", ExtraTreesClassifier(n_estimators=50))])\n",
    "etree_w2v_tfidf_custom = Pipeline([(\"word2vec vectorizer\", TfidfEmbeddingVectorizer(w2v_custom)), \n",
    "                        (\"svc\", ExtraTreesClassifier(n_estimators=50))])\n",
    "svc_w2v_custom = Pipeline([(\"word2vec vectorizer\", MeanEmbeddingVectorizer(w2v_custom)), \n",
    "                        (\"extra trees\", SVC(kernel=\"linear\", probability=True))])\n",
    "svc_w2v_tfidf_custom = Pipeline([(\"word2vec vectorizer\", TfidfEmbeddingVectorizer(w2v_custom)), \n",
    "                        (\"svc\", SVC(kernel=\"linear\", probability=True))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6678445229681979 0.625197487281678 176 566\n",
      "31.09540636042403 % -  15\n",
      "\n",
      "\n",
      "Rejected 70.87% of wrong ones\n",
      "Accepted 42.68% of good ones\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.94, 0.06],\n",
       "       [0.74, 0.26],\n",
       "       [0.84, 0.16],\n",
       "       [0.98, 0.02],\n",
       "       [0.94, 0.06]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X[:limit]\n",
    "X_test = X[limit:]\n",
    "\n",
    "y_train = y[:limit]\n",
    "y_test = y[limit:]\n",
    "\n",
    "etree_w2v_custom.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = etree_w2v_custom.predict(X_test)\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "\n",
    "y_predicted_proba = etree_w2v_custom.predict_proba(X_test)\n",
    "#y_predicted = (y_predicted_proba[:,1] > 0.12)\n",
    "y_predicted = (y_predicted_proba[:,1] > np.percentile(y_predicted_proba[:,1],100-percentile))\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected %.2f%% of wrong ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == False)])*100.0/(len(y_test)-sum(y_test))))\n",
    "print(\"Accepted %.2f%% of good ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == True)])*100.0/sum(y_test)))\n",
    "\n",
    "y_predicted_proba[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.676678445229682 0.6384878666766575 161 566\n",
      "28.445229681978798 % -  14\n",
      "\n",
      "\n",
      "Rejected 72.93% of wrong ones\n",
      "Accepted 36.59% of good ones\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.94, 0.06],\n",
       "       [0.76, 0.24],\n",
       "       [0.86, 0.14],\n",
       "       [0.94, 0.06],\n",
       "       [0.96, 0.04]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X[:limit]\n",
    "X_test = X[limit:]\n",
    "\n",
    "y_train = y[:limit]\n",
    "y_test = y[limit:]\n",
    "\n",
    "etree_w2v_tfidf_custom.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = etree_w2v_tfidf_custom.predict(X_test)\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "\n",
    "y_predicted_proba = etree_w2v_tfidf_custom.predict_proba(X_test)\n",
    "#y_predicted = (y_predicted_proba[:,1] > 0.12)\n",
    "y_predicted = (y_predicted_proba[:,1] > np.percentile(y_predicted_proba[:,1],100-percentile))\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected %.2f%% of wrong ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == False)])*100.0/(len(y_test)-sum(y_test))))\n",
    "print(\"Accepted %.2f%% of good ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == True)])*100.0/sum(y_test)))\n",
    "\n",
    "y_predicted_proba[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piotr.bednarski/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6060070671378092 0.552707733033918 189 566\n",
      "33.3922261484099 % -  16\n",
      "\n",
      "\n",
      "Rejected 65.91% of wrong ones\n",
      "Accepted 29.27% of good ones\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.85987574, 0.14012426],\n",
       "       [0.85734273, 0.14265727],\n",
       "       [0.86075493, 0.13924507],\n",
       "       [0.86187167, 0.13812833],\n",
       "       [0.85373754, 0.14626246]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X[:limit]\n",
    "X_test = X[limit:]\n",
    "\n",
    "y_train = y[:limit]\n",
    "y_test = y[limit:]\n",
    "\n",
    "svc_w2v_custom.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = svc_w2v_custom.predict(X_test)\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "\n",
    "y_predicted_proba = svc_w2v_custom.predict_proba(X_test)\n",
    "#y_predicted = (y_predicted_proba[:,1] > 0.12)\n",
    "y_predicted = (y_predicted_proba[:,1] > np.percentile(y_predicted_proba[:,1],100-percentile))\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected %.2f%% of wrong ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == False)])*100.0/(len(y_test)-sum(y_test))))\n",
    "print(\"Accepted %.2f%% of good ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == True)])*100.0/sum(y_test)))\n",
    "\n",
    "y_predicted_proba[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piotr.bednarski/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6378091872791519 0.5888120415782652 189 566\n",
      "33.3922261484099 % -  16\n",
      "\n",
      "\n",
      "Rejected 67.77% of wrong ones\n",
      "Accepted 40.24% of good ones\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.85129995, 0.14870005],\n",
       "       [0.85682874, 0.14317126],\n",
       "       [0.85241667, 0.14758333],\n",
       "       [0.86856864, 0.13143136],\n",
       "       [0.86313104, 0.13686896]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X[:limit]\n",
    "X_test = X[limit:]\n",
    "\n",
    "y_train = y[:limit]\n",
    "y_test = y[limit:]\n",
    "\n",
    "svc_w2v_tfidf_custom.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = svc_w2v_tfidf_custom.predict(X_test)\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "\n",
    "y_predicted_proba = svc_w2v_tfidf_custom.predict_proba(X_test)\n",
    "#y_predicted = (y_predicted_proba[:,1] > 0.12)\n",
    "y_predicted = (y_predicted_proba[:,1] > np.percentile(y_predicted_proba[:,1],100-percentile))\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected %.2f%% of wrong ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == False)])*100.0/(len(y_test)-sum(y_test))))\n",
    "print(\"Accepted %.2f%% of good ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == True)])*100.0/sum(y_test)))\n",
    "\n",
    "y_predicted_proba[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression and SGD - both on embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "\n",
    "logistic_w2v = Pipeline([(\"word2vec vectorizer\", MeanEmbeddingVectorizer(word2vec_pretrained)), \n",
    "                        (\"logistic\", LogisticRegression())])\n",
    "logistic_w2v_tfidf = Pipeline([(\"word2vec vectorizer\", TfidfEmbeddingVectorizer(word2vec_pretrained)), \n",
    "                        (\"logistic\", LogisticRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piotr.bednarski/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6554770318021201 0.6088699907695696 189 566\n",
      "33.3922261484099 % -  16\n",
      "\n",
      "\n",
      "Rejected 68.80% of wrong ones\n",
      "Accepted 46.34% of good ones\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.84211101, 0.15788899],\n",
       "       [0.84991373, 0.15008627],\n",
       "       [0.76536361, 0.23463639],\n",
       "       [0.8894035 , 0.1105965 ],\n",
       "       [0.85846224, 0.14153776]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X[:limit]\n",
    "X_test = X[limit:]\n",
    "\n",
    "y_train = y[:limit]\n",
    "y_test = y[limit:]\n",
    "\n",
    "logistic_w2v.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = logistic_w2v.predict(X_test)\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "\n",
    "y_predicted_proba = logistic_w2v.predict_proba(X_test)\n",
    "#y_predicted = (y_predicted_proba[:,1] > 0.12)\n",
    "y_predicted = (y_predicted_proba[:,1] > np.percentile(y_predicted_proba[:,1],100-percentile))\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected %.2f%% of wrong ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == False)])*100.0/(len(y_test)-sum(y_test))))\n",
    "print(\"Accepted %.2f%% of good ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == True)])*100.0/sum(y_test)))\n",
    "\n",
    "y_predicted_proba[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piotr.bednarski/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6554770318021201 0.6088699907695696 189 566\n",
      "33.3922261484099 % -  16\n",
      "\n",
      "\n",
      "Rejected 68.80% of wrong ones\n",
      "Accepted 46.34% of good ones\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.84258132, 0.15741868],\n",
       "       [0.85088588, 0.14911412],\n",
       "       [0.76661231, 0.23338769],\n",
       "       [0.88918848, 0.11081152],\n",
       "       [0.85845565, 0.14154435]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X[:limit]\n",
    "X_test = X[limit:]\n",
    "\n",
    "y_train = y[:limit]\n",
    "y_test = y[limit:]\n",
    "\n",
    "logistic_w2v_tfidf.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = logistic_w2v_tfidf.predict(X_test)\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "\n",
    "y_predicted_proba = logistic_w2v_tfidf.predict_proba(X_test)\n",
    "#y_predicted = (y_predicted_proba[:,1] > 0.12)\n",
    "y_predicted = (y_predicted_proba[:,1] > np.percentile(y_predicted_proba[:,1],100-percentile))\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected %.2f%% of wrong ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == False)])*100.0/(len(y_test)-sum(y_test))))\n",
    "print(\"Accepted %.2f%% of good ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == True)])*100.0/sum(y_test)))\n",
    "\n",
    "y_predicted_proba[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "\n",
    "sgd_w2v = Pipeline([(\"word2vec vectorizer\", MeanEmbeddingVectorizer(word2vec_pretrained)), \n",
    "                        (\"logistic\", SGDClassifier(loss = 'log'))])\n",
    "sgd_w2v_tfidf = Pipeline([(\"word2vec vectorizer\", TfidfEmbeddingVectorizer(word2vec_pretrained)), \n",
    "                        (\"logistic\", SGDClassifier(loss = 'log'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piotr.bednarski/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6484098939929329 0.6008468110930478 189 566\n",
      "33.3922261484099 % -  16\n",
      "\n",
      "\n",
      "Rejected 68.39% of wrong ones\n",
      "Accepted 43.90% of good ones\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[9.98736672e-01, 1.26332764e-03],\n",
       "       [9.99171406e-01, 8.28594454e-04],\n",
       "       [9.80813612e-01, 1.91863879e-02],\n",
       "       [9.99875906e-01, 1.24093738e-04],\n",
       "       [9.99356692e-01, 6.43307560e-04]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X[:limit]\n",
    "X_test = X[limit:]\n",
    "\n",
    "y_train = y[:limit]\n",
    "y_test = y[limit:]\n",
    "\n",
    "sgd_w2v.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = sgd_w2v.predict(X_test)\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "\n",
    "y_predicted_proba = sgd_w2v.predict_proba(X_test)\n",
    "#y_predicted = (y_predicted_proba[:,1] > 0.12)\n",
    "y_predicted = (y_predicted_proba[:,1] > np.percentile(y_predicted_proba[:,1],100-percentile))\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected %.2f%% of wrong ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == False)])*100.0/(len(y_test)-sum(y_test))))\n",
    "print(\"Accepted %.2f%% of good ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == True)])*100.0/sum(y_test)))\n",
    "\n",
    "y_predicted_proba[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6448763250883393 0.5968352212547869 189 566\n",
      "33.3922261484099 % -  16\n",
      "\n",
      "\n",
      "Rejected 68.18% of wrong ones\n",
      "Accepted 42.68% of good ones\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.93485347, 0.06514653],\n",
       "       [0.95274659, 0.04725341],\n",
       "       [0.41316528, 0.58683472],\n",
       "       [0.9887392 , 0.0112608 ],\n",
       "       [0.96209921, 0.03790079]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X[:limit]\n",
    "X_test = X[limit:]\n",
    "\n",
    "y_train = y[:limit]\n",
    "y_test = y[limit:]\n",
    "\n",
    "sgd_w2v_tfidf.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = sgd_w2v_tfidf.predict(X_test)\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "\n",
    "y_predicted_proba = sgd_w2v_tfidf.predict_proba(X_test)\n",
    "#y_predicted = (y_predicted_proba[:,1] > 0.12)\n",
    "y_predicted = (y_predicted_proba[:,1] > np.percentile(y_predicted_proba[:,1],100-percentile))\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected %.2f%% of wrong ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == False)])*100.0/(len(y_test)-sum(y_test))))\n",
    "print(\"Accepted %.2f%% of good ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == True)])*100.0/sum(y_test)))\n",
    "\n",
    "y_predicted_proba[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Saving/loading models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "def datetime_string():\n",
    "    localtime = time.localtime(time.time())\n",
    "    datetime_str = str(localtime.tm_year)\n",
    "    if(localtime.tm_mon < 10):\n",
    "        datetime_str += '0'\n",
    "    datetime_str += str(localtime.tm_mon)\n",
    "    if(localtime.tm_mday < 10):\n",
    "        datetime_str += '0'\n",
    "    datetime_str += str(localtime.tm_mday) + '_'\n",
    "    if(localtime.tm_hour < 10):\n",
    "        datetime_str += '0'\n",
    "    datetime_str += str(localtime.tm_hour)\n",
    "    if(localtime.tm_min < 10):\n",
    "        datetime_str += '0'\n",
    "    datetime_str += str(localtime.tm_min) + '_'\n",
    "    \n",
    "    return datetime_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "contents_dict = {\n",
    "    'model_svc_sklearn' : model_svc,\n",
    "    'model_svc_tfidf_sklearn' : model_svc_tfidf,\n",
    "    \n",
    "    'model_nb_sklearn' : model_nb,\n",
    "    'model_nb_tfidf_sklearn' : model_nb_tfidf,\n",
    "    \n",
    "    'etree_w2v_sklearn' : etree_w2v,\n",
    "    'etree_w2v_tfidf_sklearn' : etree_w2v_tfidf,\n",
    "    \n",
    "    'svc_w2v_sklearn' : svc_w2v,\n",
    "    'svc_w2v_tfidf_sklearn' : svc_w2v_tfidf,\n",
    "    \n",
    "    'etree_w2v_custom_sklearn' : etree_w2v_custom,\n",
    "    'etree_w2v_tfidf_custom_sklearn' : etree_w2v_tfidf_custom,\n",
    "    \n",
    "    'svc_w2v_custom_sklearn' : svc_w2v_custom,\n",
    "    'svc_w2v_tfidf_custom_sklearn' : svc_w2v_tfidf_custom,\n",
    "    \n",
    "    'logistic_w2v_sklearn' : logistic_w2v,\n",
    "    'logistic_w2v_tfidf_sklearn' : logistic_w2v_tfidf,\n",
    "    \n",
    "    'sgd_w2v_sklearn' : sgd_w2v,\n",
    "    'sgd_w2v_tfidf_sklearn' : sgd_w2v_tfidf\n",
    "}\n",
    "\n",
    "dat_str = datetime_string()\n",
    "with open(\"models/\"+dat_str+\"ensemble_models.pickle\", 'wb') as f:\n",
    "    pickle.dump(contents_dict, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('models/'+dat_str+'ensemble_models.pickle', 'rb') as f:\n",
    "    contents_dict = pickle.load(f)\n",
    "\n",
    "model_svc = contents_dict['model_svc_sklearn']\n",
    "model_svc_tfidf = contents_dict['model_svc_tfidf_sklearn']\n",
    "\n",
    "model_nb = contents_dict['model_nb_sklearn']\n",
    "model_nb_tfidf = contents_dict['model_nb_tfidf_sklearn']\n",
    "\n",
    "etree_w2v = contents_dict['etree_w2v_sklearn']\n",
    "etree_w2v_tfidf = contents_dict['etree_w2v_tfidf_sklearn']\n",
    "\n",
    "svc_w2v = contents_dict['svc_w2v_sklearn']\n",
    "svc_w2v_tfidf = contents_dict['svc_w2v_tfidf_sklearn']\n",
    "\n",
    "etree_w2v_custom = contents_dict['etree_w2v_custom_sklearn']\n",
    "etree_w2v_tfidf_custom = contents_dict['etree_w2v_tfidf_custom_sklearn']\n",
    "\n",
    "svc_w2v_custom = contents_dict['svc_w2v_custom_sklearn']\n",
    "svc_w2v_tfidf_custom = contents_dict['svc_w2v_tfidf_custom_sklearn']\n",
    "\n",
    "logistic_w2v = contents_dict['logistic_w2v_sklearn']\n",
    "logistic_w2v_tfidf = contents_dict['logistic_w2v_tfidf_sklearn']\n",
    "\n",
    "sgd_w2v = contents_dict['sgd_w2v_sklearn']\n",
    "sgd_w2v_tfidf = contents_dict['sgd_w2v_tfidf_sklearn']\n",
    "\n",
    "#hyperparameters_cnn = contents_dict['hyperparameters_cnn']\n",
    "#hyperparameters_lstm = contents_dict['hyperparameters_lstm']\n",
    "\n",
    "#label_encoder = contents_dict['label_encoder']\n",
    "#tokenize = contents_dict['tokenizer']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building an ensembler - Without data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "XE = X[limit:]\n",
    "yE = y[limit:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piotr.bednarski/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3.39804988e-01, 3.81524689e-01, 1.34885101e-01, ...,\n",
       "        1.57418678e-01, 1.26332764e-03, 6.51465254e-02],\n",
       "       [1.23290579e-01, 5.98582988e-02, 1.41978101e-01, ...,\n",
       "        1.49114125e-01, 8.28594454e-04, 4.72534144e-02],\n",
       "       [2.92059950e-01, 3.70258616e-01, 1.23547755e-01, ...,\n",
       "        2.33387687e-01, 1.91863879e-02, 5.86834719e-01],\n",
       "       ...,\n",
       "       [8.47294064e-02, 6.25996674e-02, 1.41224648e-01, ...,\n",
       "        8.57452225e-02, 1.57450276e-05, 3.47356746e-03],\n",
       "       [8.68772941e-02, 5.14922112e-02, 2.05290429e-01, ...,\n",
       "        1.76177557e-01, 2.21993740e-03, 1.13807602e-01],\n",
       "       [5.77106553e-02, 4.75357888e-02, 8.37646632e-02, ...,\n",
       "        8.45256167e-02, 3.40050064e-05, 1.60447352e-03]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "XE_intermediate = np.column_stack((\n",
    "        model_svc.predict_proba(XE)[:,1],\n",
    "        model_svc_tfidf.predict_proba(XE)[:,1],\n",
    "    \n",
    "        model_nb.predict_proba(XE)[:,1],\n",
    "        model_nb_tfidf.predict_proba(XE)[:,1],\n",
    "\n",
    "        etree_w2v.predict_proba(XE)[:,1],\n",
    "        etree_w2v_tfidf.predict_proba(XE)[:,1],\n",
    "\n",
    "        svc_w2v.predict_proba(XE)[:,1],\n",
    "        svc_w2v_tfidf.predict_proba(XE)[:,1],\n",
    "\n",
    "        etree_w2v_custom.predict_proba(XE)[:,1],\n",
    "        etree_w2v_tfidf_custom.predict_proba(XE)[:,1],\n",
    "\n",
    "        svc_w2v_custom.predict_proba(XE)[:,1],\n",
    "        svc_w2v_tfidf_custom.predict_proba(XE)[:,1],\n",
    "\n",
    "        logistic_w2v.predict_proba(XE)[:,1],\n",
    "        logistic_w2v_tfidf.predict_proba(XE)[:,1],\n",
    "\n",
    "        sgd_w2v.predict_proba(XE)[:,1],\n",
    "        sgd_w2v_tfidf.predict_proba(XE)[:,1]\n",
    "    ))\n",
    "XE_intermediate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "452\n"
     ]
    }
   ],
   "source": [
    "limitE = int(manager_split*len(XE_intermediate))\n",
    "print(limitE)\n",
    "\n",
    "X_train = XE_intermediate[:limitE]\n",
    "X_test = XE_intermediate[limitE:]\n",
    "\n",
    "y_train = yE[:limitE]\n",
    "y_test = yE[limitE:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666 0.6124708624708625 38 114\n",
      "33.333333333333336 % -  16\n",
      "\n",
      "\n",
      "Rejected 69.00% of wrong ones\n",
      "Accepted 50.00% of good ones\n",
      "Median: 0.139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piotr.bednarski/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.88491249, 0.11508751],\n",
       "       [0.85235219, 0.14764781],\n",
       "       [0.80749649, 0.19250351],\n",
       "       [0.85671897, 0.14328103],\n",
       "       [0.84576315, 0.15423685]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "logi = LogisticRegression()\n",
    "logi.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = logi.predict(X_test)\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "\n",
    "y_predicted_proba = logi.predict_proba(X_test)\n",
    "y_predicted = (y_predicted_proba[:,1] > np.percentile(y_predicted_proba[:,1],100-percentile))\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected %.2f%% of wrong ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == False)])*100.0/(len(y_test)-sum(y_test))))\n",
    "print(\"Accepted %.2f%% of good ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == True)])*100.0/sum(y_test)))\n",
    "print(\"Median: %.3f\" % np.median(y_predicted_proba[:,1]))\n",
    "\n",
    "y_predicted_proba[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best ratings:\n",
    "Rejected 53.94% of wrong ones\n",
    "\n",
    "Accepted 77.05% of good ones\n",
    "\n",
    "Median: 0.043"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piotr.bednarski/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1059: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  if hasattr(X, 'dtype') and np.issubdtype(X.dtype, np.float):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "max_rej = 20.0\n",
    "max_acc = 20.0\n",
    "\n",
    "XE_intermediate_full = np.column_stack((\n",
    "        model_svc.predict_proba(XE)[:,1],\n",
    "        model_svc_tfidf.predict_proba(XE)[:,1],\n",
    "\n",
    "        model_nb.predict_proba(XE)[:,1],\n",
    "        model_nb_tfidf.predict_proba(XE)[:,1], #----------\n",
    "\n",
    "        etree_w2v.predict_proba(XE)[:,1],\n",
    "        etree_w2v_tfidf.predict_proba(XE)[:,1],\n",
    "\n",
    "        svc_w2v.predict_proba(XE)[:,1],\n",
    "        svc_w2v_tfidf.predict_proba(XE)[:,1], #----------\n",
    "\n",
    "        etree_w2v_custom.predict_proba(XE)[:,1],\n",
    "        etree_w2v_tfidf_custom.predict_proba(XE)[:,1],\n",
    "\n",
    "        svc_w2v_custom.predict_proba(XE)[:,1],\n",
    "        svc_w2v_tfidf_custom.predict_proba(XE)[:,1], #----------\n",
    "\n",
    "        logistic_w2v.predict_proba(XE)[:,1],\n",
    "        logistic_w2v_tfidf.predict_proba(XE)[:,1],\n",
    "\n",
    "        sgd_w2v.predict_proba(XE)[:,1],\n",
    "        sgd_w2v_tfidf.predict_proba(XE)[:,1]\n",
    "    ))\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1]\n",
      "1\n",
      "Rejected 69.00% of wrong ones\n",
      "Accepted 50.00% of good ones\n",
      "Median: 0.151\n",
      "\n",
      "\n",
      "[1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1]\n",
      "2\n",
      "Rejected 69.00% of wrong ones\n",
      "Accepted 50.00% of good ones\n",
      "Median: 0.152\n",
      "\n",
      "\n",
      "[1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0]\n",
      "3\n",
      "Rejected 70.00% of wrong ones\n",
      "Accepted 57.14% of good ones\n",
      "Median: 0.154\n",
      "\n",
      "\n",
      "[0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0]\n",
      "4\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.154\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piotr.bednarski/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
      "5\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.155\n",
      "\n",
      "\n",
      "[1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "6\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.158\n",
      "\n",
      "\n",
      "[1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0]\n",
      "7\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.160\n",
      "\n",
      "\n",
      "[1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0]\n",
      "8\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.158\n",
      "\n",
      "\n",
      "[1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0]\n",
      "9\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.156\n",
      "\n",
      "\n",
      "[1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "10\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.158\n",
      "\n",
      "\n",
      "[1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0]\n",
      "11\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.156\n",
      "\n",
      "\n",
      "[1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0]\n",
      "12\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.158\n",
      "\n",
      "\n",
      "[1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "13\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.155\n",
      "\n",
      "\n",
      "[1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0]\n",
      "14\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.158\n",
      "\n",
      "\n",
      "[1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0]\n",
      "15\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.156\n",
      "\n",
      "\n",
      "[1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0]\n",
      "16\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.158\n",
      "\n",
      "\n",
      "[1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0]\n",
      "17\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.159\n",
      "\n",
      "\n",
      "[1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0]\n",
      "18\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.154\n",
      "\n",
      "\n",
      "[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "19\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.157\n",
      "\n",
      "\n",
      "[1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "20\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.157\n",
      "\n",
      "\n",
      "[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "21\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.157\n",
      "\n",
      "\n",
      "[1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "22\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.155\n",
      "\n",
      "\n",
      "[1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0]\n",
      "23\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.158\n",
      "\n",
      "\n",
      "[1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0]\n",
      "24\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.158\n",
      "\n",
      "\n",
      "[1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0]\n",
      "25\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.159\n",
      "\n",
      "\n",
      "[1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0]\n",
      "26\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.159\n",
      "\n",
      "\n",
      "[1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0]\n",
      "27\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.158\n",
      "\n",
      "\n",
      "[1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "28\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.155\n",
      "\n",
      "\n",
      "[1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0]\n",
      "29\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.159\n",
      "\n",
      "\n",
      "[1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0]\n",
      "30\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.155\n",
      "\n",
      "\n",
      "[1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0]\n",
      "31\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.158\n",
      "\n",
      "\n",
      "[1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0]\n",
      "32\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.158\n",
      "\n",
      "\n",
      "[1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]\n",
      "33\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.159\n",
      "\n",
      "\n",
      "[1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "34\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.159\n",
      "\n",
      "\n",
      "[1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0]\n",
      "35\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.158\n",
      "\n",
      "\n",
      "[1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0]\n",
      "36\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.158\n",
      "\n",
      "\n",
      "[1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "37\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.155\n",
      "\n",
      "\n",
      "[1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0]\n",
      "38\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.158\n",
      "\n",
      "\n",
      "[1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "39\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.158\n",
      "\n",
      "\n",
      "[1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0]\n",
      "40\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.157\n",
      "\n",
      "\n",
      "[1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0]\n",
      "41\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.158\n",
      "\n",
      "\n",
      "[1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0]\n",
      "42\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.156\n",
      "\n",
      "\n",
      "[1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0]\n",
      "43\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.158\n",
      "\n",
      "\n",
      "[1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0]\n",
      "44\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.158\n",
      "\n",
      "\n",
      "[1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0]\n",
      "45\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.157\n",
      "\n",
      "\n",
      "[0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "46\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.156\n",
      "\n",
      "\n",
      "[1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
      "47\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.155\n",
      "\n",
      "\n",
      "[1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "48\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.158\n",
      "\n",
      "\n",
      "[1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0]\n",
      "49\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.156\n",
      "\n",
      "\n",
      "[1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0]\n",
      "50\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.156\n",
      "\n",
      "\n",
      "[1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0]\n",
      "51\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.158\n",
      "\n",
      "\n",
      "[1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0]\n",
      "52\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.157\n",
      "\n",
      "\n",
      "[1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0]\n",
      "53\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.158\n",
      "\n",
      "\n",
      "[1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "54\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.155\n",
      "\n",
      "\n",
      "[1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "55\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.155\n",
      "\n",
      "\n",
      "[1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0]\n",
      "56\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.159\n",
      "\n",
      "\n",
      "[0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0]\n",
      "57\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.154\n",
      "\n",
      "\n",
      "[1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "58\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.158\n",
      "\n",
      "\n",
      "[1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0]\n",
      "59\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.158\n",
      "\n",
      "\n",
      "[1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0]\n",
      "60\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.158\n",
      "\n",
      "\n",
      "[1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
      "61\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.156\n",
      "\n",
      "\n",
      "[1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "62\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.158\n",
      "\n",
      "\n",
      "[1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0]\n",
      "63\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.158\n",
      "\n",
      "\n",
      "[1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0]\n",
      "64\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.159\n",
      "\n",
      "\n",
      "[1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
      "65\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.157\n",
      "\n",
      "\n",
      "[1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "66\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.156\n",
      "\n",
      "\n",
      "[1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0]\n",
      "67\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.158\n",
      "\n",
      "\n",
      "[1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0]\n",
      "68\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.159\n",
      "\n",
      "\n",
      "[1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0]\n",
      "69\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.159\n",
      "\n",
      "\n",
      "[1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0]\n",
      "70\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.157\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0]\n",
      "71\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.157\n",
      "\n",
      "\n",
      "[1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0]\n",
      "72\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.158\n",
      "\n",
      "\n",
      "[1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0]\n",
      "73\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.158\n",
      "\n",
      "\n",
      "[1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0]\n",
      "74\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.159\n",
      "\n",
      "\n",
      "[1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0]\n",
      "75\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.159\n",
      "\n",
      "\n",
      "[1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0]\n",
      "76\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.158\n",
      "\n",
      "\n",
      "[1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0]\n",
      "77\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.156\n",
      "\n",
      "\n",
      "[0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0]\n",
      "78\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.155\n",
      "\n",
      "\n",
      "[1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0]\n",
      "79\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.160\n",
      "\n",
      "\n",
      "[1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0]\n",
      "80\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.158\n",
      "\n",
      "\n",
      "[1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0]\n",
      "81\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.155\n",
      "\n",
      "\n",
      "[1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0]\n",
      "82\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.159\n",
      "\n",
      "\n",
      "[1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0]\n",
      "83\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.159\n",
      "\n",
      "\n",
      "[1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0]\n",
      "84\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.158\n",
      "\n",
      "\n",
      "[1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "85\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.156\n",
      "\n",
      "\n",
      "[1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0]\n",
      "86\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.158\n",
      "\n",
      "\n",
      "[1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0]\n",
      "87\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.159\n",
      "\n",
      "\n",
      "[1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0]\n",
      "88\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.158\n",
      "\n",
      "\n",
      "[1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0]\n",
      "89\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.154\n",
      "\n",
      "\n",
      "[0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0]\n",
      "90\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.154\n",
      "\n",
      "\n",
      "[1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "91\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.154\n",
      "\n",
      "\n",
      "[1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "92\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.157\n",
      "\n",
      "\n",
      "[1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0]\n",
      "93\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.157\n",
      "\n",
      "\n",
      "[1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0]\n",
      "94\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.159\n",
      "\n",
      "\n",
      "[1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0]\n",
      "95\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.158\n",
      "\n",
      "\n",
      "[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
      "96\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.157\n",
      "\n",
      "\n",
      "[1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0]\n",
      "97\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.155\n",
      "\n",
      "\n",
      "[1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0]\n",
      "98\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.158\n",
      "\n",
      "\n",
      "[1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0]\n",
      "99\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.159\n",
      "\n",
      "\n",
      "[1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0]\n",
      "100\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.158\n",
      "\n",
      "\n",
      "[1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "101\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.159\n",
      "\n",
      "\n",
      "[1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "102\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.155\n",
      "\n",
      "\n",
      "[1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0]\n",
      "103\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.155\n",
      "\n",
      "\n",
      "[1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
      "104\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.155\n",
      "\n",
      "\n",
      "[1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "105\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.156\n",
      "\n",
      "\n",
      "[1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0]\n",
      "106\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.155\n",
      "\n",
      "\n",
      "[1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0]\n",
      "107\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.158\n",
      "\n",
      "\n",
      "[1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0]\n",
      "108\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.159\n",
      "\n",
      "\n",
      "[1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "109\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.156\n",
      "\n",
      "\n",
      "[1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0]\n",
      "110\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.155\n",
      "\n",
      "\n",
      "[1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0]\n",
      "111\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.158\n",
      "\n",
      "\n",
      "[1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0]\n",
      "112\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.156\n",
      "\n",
      "\n",
      "[1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0]\n",
      "113\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.155\n",
      "\n",
      "\n",
      "[1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
      "114\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.156\n",
      "\n",
      "\n",
      "[1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "115\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.155\n",
      "\n",
      "\n",
      "[1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0]\n",
      "116\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.160\n",
      "\n",
      "\n",
      "[1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0]\n",
      "117\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.158\n",
      "\n",
      "\n",
      "[1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0]\n",
      "118\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.158\n",
      "\n",
      "\n",
      "[1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0]\n",
      "119\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.158\n",
      "\n",
      "\n",
      "[1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0]\n",
      "120\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.159\n",
      "\n",
      "\n",
      "[1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0]\n",
      "121\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.158\n",
      "\n",
      "\n",
      "[1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0]\n",
      "122\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.156\n",
      "\n",
      "\n",
      "[1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0]\n",
      "123\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.159\n",
      "\n",
      "\n",
      "[1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]\n",
      "124\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.158\n",
      "\n",
      "\n",
      "[1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "125\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.159\n",
      "\n",
      "\n",
      "[1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "126\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.156\n",
      "\n",
      "\n",
      "[1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "127\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.158\n",
      "\n",
      "\n",
      "[1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "128\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.158\n",
      "\n",
      "\n",
      "[1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0]\n",
      "129\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.158\n",
      "\n",
      "\n",
      "[1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0]\n",
      "130\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.158\n",
      "\n",
      "\n",
      "[1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0]\n",
      "131\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.156\n",
      "\n",
      "\n",
      "[1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0]\n",
      "132\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.158\n",
      "\n",
      "\n",
      "[1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "133\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.158\n",
      "\n",
      "\n",
      "[1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0]\n",
      "134\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.158\n",
      "\n",
      "\n",
      "[1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0]\n",
      "135\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.158\n",
      "\n",
      "\n",
      "[1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0]\n",
      "136\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.158\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "137\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.155\n",
      "\n",
      "\n",
      "[1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0]\n",
      "138\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.159\n",
      "\n",
      "\n",
      "[0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "139\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.154\n",
      "\n",
      "\n",
      "[1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0]\n",
      "140\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.156\n",
      "\n",
      "\n",
      "[1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0]\n",
      "141\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.158\n",
      "\n",
      "\n",
      "[1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0]\n",
      "142\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.155\n",
      "\n",
      "\n",
      "[1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "143\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.155\n",
      "\n",
      "\n",
      "[1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0]\n",
      "144\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.158\n",
      "\n",
      "\n",
      "[1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0]\n",
      "145\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.158\n",
      "\n",
      "\n",
      "[1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0]\n",
      "146\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.160\n",
      "\n",
      "\n",
      "[1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0]\n",
      "147\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.158\n",
      "\n",
      "\n",
      "[0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0]\n",
      "148\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.155\n",
      "\n",
      "\n",
      "[1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0]\n",
      "149\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.159\n",
      "\n",
      "\n",
      "[1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "150\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.158\n",
      "\n",
      "\n",
      "[1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0]\n",
      "151\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.159\n",
      "\n",
      "\n",
      "[1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0]\n",
      "152\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.158\n",
      "\n",
      "\n",
      "[1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0]\n",
      "153\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.155\n",
      "\n",
      "\n",
      "[1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "154\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.158\n",
      "\n",
      "\n",
      "[1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0]\n",
      "155\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.156\n",
      "\n",
      "\n",
      "[1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0]\n",
      "156\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.158\n",
      "\n",
      "\n",
      "[1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "157\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.155\n",
      "\n",
      "\n",
      "[1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0]\n",
      "158\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.159\n",
      "\n",
      "\n",
      "[1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0]\n",
      "159\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.158\n",
      "\n",
      "\n",
      "[1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0]\n",
      "160\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.158\n",
      "\n",
      "\n",
      "[1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]\n",
      "161\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.158\n",
      "\n",
      "\n",
      "[1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]\n",
      "162\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.160\n",
      "\n",
      "\n",
      "[1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0]\n",
      "163\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.158\n",
      "\n",
      "\n",
      "[1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0]\n",
      "164\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.157\n",
      "\n",
      "\n",
      "[1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0]\n",
      "165\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.158\n",
      "\n",
      "\n",
      "[1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "166\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.157\n",
      "\n",
      "\n",
      "[0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0]\n",
      "167\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.154\n",
      "\n",
      "\n",
      "[1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0]\n",
      "168\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.158\n",
      "\n",
      "\n",
      "[1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0]\n",
      "169\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.158\n",
      "\n",
      "\n",
      "[1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0]\n",
      "170\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.158\n",
      "\n",
      "\n",
      "[1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "171\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.158\n",
      "\n",
      "\n",
      "[1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0]\n",
      "172\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.155\n",
      "\n",
      "\n",
      "[1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]\n",
      "173\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.160\n",
      "\n",
      "\n",
      "[1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0]\n",
      "174\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.158\n",
      "\n",
      "\n",
      "[1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0]\n",
      "175\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.159\n",
      "\n",
      "\n",
      "[1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0]\n",
      "176\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.158\n",
      "\n",
      "\n",
      "[1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0]\n",
      "177\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.158\n",
      "\n",
      "\n",
      "[1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
      "178\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.156\n",
      "\n",
      "\n",
      "[1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0]\n",
      "179\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.157\n",
      "\n",
      "\n",
      "[1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0]\n",
      "180\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.158\n",
      "\n",
      "\n",
      "[1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "181\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.155\n",
      "\n",
      "\n",
      "[1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "182\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.156\n",
      "\n",
      "\n",
      "[1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0]\n",
      "183\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.157\n",
      "\n",
      "\n",
      "[1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0]\n",
      "184\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.159\n",
      "\n",
      "\n",
      "[0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0]\n",
      "185\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.154\n",
      "\n",
      "\n",
      "[1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0]\n",
      "186\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.158\n",
      "\n",
      "\n",
      "[1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "187\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.156\n",
      "\n",
      "\n",
      "[1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0]\n",
      "188\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.158\n",
      "\n",
      "\n",
      "[1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0]\n",
      "189\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.160\n",
      "\n",
      "\n",
      "[1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0]\n",
      "190\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.158\n",
      "\n",
      "\n",
      "[1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0]\n",
      "191\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.158\n",
      "\n",
      "\n",
      "[1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
      "192\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.155\n",
      "\n",
      "\n",
      "[1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0]\n",
      "193\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.158\n",
      "\n",
      "\n",
      "[1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0]\n",
      "194\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.157\n",
      "\n",
      "\n",
      "[1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0]\n",
      "195\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.158\n",
      "\n",
      "\n",
      "[1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0]\n",
      "196\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.158\n",
      "\n",
      "\n",
      "[1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0]\n",
      "197\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.160\n",
      "\n",
      "\n",
      "[1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0]\n",
      "198\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.160\n",
      "\n",
      "\n",
      "[1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0]\n",
      "199\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.158\n",
      "\n",
      "\n",
      "[1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0]\n",
      "200\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.158\n",
      "\n",
      "\n",
      "[1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0]\n",
      "201\n",
      "Rejected 72.00% of wrong ones\n",
      "Accepted 71.43% of good ones\n",
      "Median: 0.160\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.0\n",
    "mask_list = []\n",
    "while(True):\n",
    "    threshold = threshold + 0.1\n",
    "    rand_vect = np.random.rand(16) > threshold\n",
    "    XE_intermediate = XE_intermediate_full[:,rand_vect]\n",
    "    if threshold > 0.85:\n",
    "        threshold = 0.0\n",
    "    if XE_intermediate.shape[1] < 1:\n",
    "        continue\n",
    "        \n",
    "    rand_vect_int = []\n",
    "    for i in range(len(rand_vect)):\n",
    "        if rand_vect[i] == True:\n",
    "            rand_vect_int.append(1)\n",
    "        else:\n",
    "            rand_vect_int.append(0)\n",
    "    if rand_vect_int in mask_list:\n",
    "        continue\n",
    "\n",
    "    limitE = int(manager_split*len(XE_intermediate))\n",
    "    #print(limitE)\n",
    "\n",
    "    X_train = XE_intermediate[:limitE]\n",
    "    X_test = XE_intermediate[limitE:]\n",
    "\n",
    "    y_train = yE[:limitE]\n",
    "    y_test = yE[limitE:]\n",
    "\n",
    "    from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "    from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "    logi = LogisticRegression()\n",
    "    logi.fit(X_train, y_train)\n",
    "\n",
    "    y_predicted = logi.predict(X_test)\n",
    "    acc = accuracy_score(y_predicted, y_test)\n",
    "    f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "\n",
    "    y_predicted_proba = logi.predict_proba(X_test)\n",
    "    #y_predicted = (y_predicted_proba[:,1] > np.percentile(y_predicted_proba[:,1],100-28.5))\n",
    "    y_predicted = (y_predicted_proba[:,1] > np.percentile(y_predicted_proba[:,1],100-percentile))\n",
    "\n",
    "    acc = accuracy_score(y_predicted, y_test)\n",
    "    f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "    #print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "    #print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "    #print(\"\\n\")\n",
    "    \n",
    "    rej = len(X_test_df[(y_predicted == y_test) & (y_predicted == False)])*100.0/(len(y_test)-sum(y_test))\n",
    "    acc = len(X_test_df[(y_predicted == y_test) & (y_predicted == True)])*100.0/sum(y_test)\n",
    "    \n",
    "    X_test_df = pd.DataFrame(X_test)\n",
    "    if (rej >= max_rej and acc >= max_acc):\n",
    "        max_rej = rej \n",
    "        max_acc = acc\n",
    "        mask_list.append(rand_vect_int)\n",
    "        print(rand_vect_int)\n",
    "        print(len(mask_list))\n",
    "        print(\"Rejected %.2f%% of wrong ones\" % rej)\n",
    "        print(\"Accepted %.2f%% of good ones\" % acc)\n",
    "        print(\"Median: %.3f\\n\\n\" % np.percentile(y_predicted_proba[:,1],100-percentile))\n",
    "        if len(mask_list) > 200:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "[0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0]\n",
    "41\n",
    "Rejected 72.32% of wrong ones\n",
    "Accepted 78.57% of good ones\n",
    "Median: 0.169\n",
    "\n",
    "\n",
    "[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1]\n",
    "42\n",
    "Rejected 72.32% of wrong ones\n",
    "Accepted 78.57% of good ones\n",
    "Median: 0.169\n",
    "\n",
    "percentile 33%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.95522388, 0.14427861, 0.43781095, 0.47263682, 0.50248756,\n",
       "       0.46766169, 0.60199005, 0.3880597 , 0.56218905, 0.34825871,\n",
       "       0.31840796, 0.3880597 , 0.26368159, 0.2238806 , 0.47263682,\n",
       "       0.00995025])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_list_np = np.array([np.array(xi) for xi in mask_list])\n",
    "\n",
    "mask_list_np.sum(axis=0)/len(mask_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ndElqhIUuSY2w0CWpERa6JDXCQpekRvw/7+eDqOlvgHsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f56c7fe2dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = mask_list_np.sum(axis=1)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(a, bins=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16])  # arguments are passed to np.histogram\n",
    "plt.title(\"Histogram\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indices = a.argsort()\n",
    "smallest_mask = mask_list[indices[10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "rand_vect = mask_list[-15]\n",
    "rand_vect = smallest_mask\n",
    "print(rand_vect)\n",
    "XE_intermediate = XE_intermediate_full[:,rand_vect]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "452\n"
     ]
    }
   ],
   "source": [
    "limitE = int(manager_split*len(XE_intermediate))\n",
    "print(limitE)\n",
    "\n",
    "X_train = XE_intermediate[:limitE]\n",
    "X_test = XE_intermediate[limitE:]\n",
    "\n",
    "y_train = yE[:limitE]\n",
    "y_test = yE[limitE:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7017543859649122 0.6532634032634033 38 114\n",
      "33.333333333333336 % -  16\n",
      "\n",
      "\n",
      "Rejected 71.00% of wrong ones\n",
      "Accepted 64.29% of good ones\n",
      "Median: 0.153456826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piotr.bednarski/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.89167651, 0.10832349],\n",
       "       [0.85530552, 0.14469448],\n",
       "       [0.80928826, 0.19071174],\n",
       "       [0.87220355, 0.12779645],\n",
       "       [0.85551154, 0.14448846]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "logi = LogisticRegression()\n",
    "logi.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = logi.predict(X_test)\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "\n",
    "y_predicted_proba = logi.predict_proba(X_test)\n",
    "y_predicted = (y_predicted_proba[:,1] > np.percentile(y_predicted_proba[:,1],100-percentile))\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected %.2f%% of wrong ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == False)])*100.0/(len(y_test)-sum(y_test))))\n",
    "print(\"Accepted %.2f%% of good ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == True)])*100.0/sum(y_test)))\n",
    "print(\"Median: %.9f\" % np.percentile(y_predicted_proba[:,1],100-percentile))\n",
    "\n",
    "y_predicted_proba[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "contents_dict = {\n",
    "    'model_svc_sklearn' : model_svc,\n",
    "    'model_svc_tfidf_sklearn' : model_svc_tfidf,\n",
    "    \n",
    "    'model_nb_sklearn' : model_nb,\n",
    "    'model_nb_tfidf_sklearn' : model_nb_tfidf,\n",
    "    \n",
    "    'etree_w2v_sklearn' : etree_w2v,\n",
    "    'etree_w2v_tfidf_sklearn' : etree_w2v_tfidf,\n",
    "    \n",
    "    'svc_w2v_sklearn' : svc_w2v,\n",
    "    'svc_w2v_tfidf_sklearn' : svc_w2v_tfidf,\n",
    "    \n",
    "    'etree_w2v_custom_sklearn' : etree_w2v_custom,\n",
    "    'etree_w2v_tfidf_custom_sklearn' : etree_w2v_tfidf_custom,\n",
    "    \n",
    "    'svc_w2v_custom_sklearn' : svc_w2v_custom,\n",
    "    'svc_w2v_tfidf_custom_sklearn' : svc_w2v_tfidf_custom,\n",
    "    \n",
    "    'logistic_w2v_sklearn' : logistic_w2v,\n",
    "    'logistic_w2v_tfidf_sklearn' : logistic_w2v_tfidf,\n",
    "    \n",
    "    'sgd_w2v_sklearn' : sgd_w2v,\n",
    "    'sgd_w2v_tfidf_sklearn' : sgd_w2v_tfidf,\n",
    "    \n",
    "    'mask_list' : mask_list,\n",
    "    'ensempler' : logi\n",
    "}\n",
    "\n",
    "with open(\"models/\"+dat_str+\"ensemble_models_with_manager.pickle\", 'wb') as f:\n",
    "    pickle.dump(contents_dict, f, pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
