{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from api import inoreader_api, inoreader_scraping\n",
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import keras.preprocessing.text\n",
    "from string import maketrans\n",
    "\n",
    "def text_to_word_sequence(text,\n",
    "                          filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "                          lower=True, split=\" \"):\n",
    "    if lower: text = text.lower()\n",
    "    if type(text) == unicode:\n",
    "        translate_table = {ord(c): ord(t) for c,t in zip(filters, split*len(filters)) }\n",
    "    else:\n",
    "        translate_table = maketrans(filters, split * len(filters))\n",
    "    text = text.translate(translate_table)\n",
    "    seq = text.split(split)\n",
    "    return [i for i in seq if i]\n",
    "    \n",
    "keras.preprocessing.text.text_to_word_sequence = text_to_word_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape feeds starting from a concrete moment and store them in a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=UiylFfp7lMJd\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=6ZjcoTSC77uo\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=bCduBEiJQAjM\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=dJkhUx2XcxQG\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=xwWsDyaRkFCt\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=5sG9BPD0cm_u\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=Dos6QoFcnh3t\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=7T3ZHI_8xabA\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=jREf5YoL8RRQ\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=wQdFF_8S1miG\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=7OeuD9ctUor5\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=7FOl8S9213cN\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=XXmKfaD2Ef8J\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=y2AUQ7W0tPuw\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=mO3IF_ltBPBJ\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=Q3dxea7_F4U_\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=n62MNj3E5fKc\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=9gFsSOwnBYmJ\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=T2UKW8ZP46Dt\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=0uBjuppZ63F4\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=kBDwOhSKo3I6\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=D7QqXaD2wqA_\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=NfaQYpMTyuxX\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=I4KXxDWEwhWc\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=N9kFnn5rYJNX\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=2CoJlGHAZzgA\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=5bqeUxuQitoB\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=6qKI_F_5kaGB\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=QybYqknfPAKZ\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=ByCJptqH1A8B\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=uONlKy5chRSa\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=sj7AKMPGEtS9\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=8142R3QbL6Gi\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=Gke_4GzfeyWt\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=huqN_Kd0K9dQ\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=a9gIarXIDgd7\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=mhnXXaj9Y7TZ\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=n1Ygtefr_4wF\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=OQtmR7KYPoJo\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=jj8ZYQhOuR0Y\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=FdbyFcKL3WGJ\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=edy4Uk8ecwhA\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=3nhF5fLGkh8S\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=_wFRXFgtew57\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=eSoFlWajf8XX\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=RrPS5ZalWmcS\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=megdLUHMwgB2\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=YrP4XXkwZcfS\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=itg48magOy3Y\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=44S8JGlrk4Bg\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=NBQl0tzxCy0O\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=FFxCTEO9K_e0\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=jcPdb6jUFaMK\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=fiFAO93E0fth\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=HznwHraaKZSP\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=1KT3Scg5xlcC\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=u63Dh4oddg74\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=X2Ab76CmnFTz\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=jXhpnfKXTy6R\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=YUUDd8J0G3us\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=PHeuXrFCFoS2\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=aHqmpK1Wx0dd\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=U9Wzi9K6WX0U\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=wSMM1Mk6R6k3\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=46_uDlTYiDN1\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=3fiEj3LeAGNx\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=GC2gcGurNchj\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=BUex5eLdcp8M\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=0JA4H35FsUSo\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=LoxOk3wTE7Zd\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=Jdo5ceWuEY0C\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=52tfHTiLMDUL\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=JhPS4kDRdS1Z\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=wFwj7K3_JyP6\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=iOjLaarxCt3x\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=JR47ATEoyf73\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=swBroZBP35Gw\n",
      "(200, 'OK')\n",
      "\n",
      "Requesting: stream/contents/user/-/label/arXiv?c=wGZZDBL5mAHL\n",
      "(200, 'OK')\n",
      "1560\n"
     ]
    }
   ],
   "source": [
    "start_time = 1508112001\n",
    "feed = 'user/-/label/arXiv'\n",
    "file_name = 'articles_raw.json'\n",
    "\n",
    "number_scraped = inoreader_scraping.scrape(feed, start_time, file_name)\n",
    "print(number_scraped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the feeds from disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open(file_name, 'r')\n",
    "json_string = f.read()\n",
    "f.close\n",
    "\n",
    "json_object = json.loads(json_string)\n",
    "all_articles = json_object['all_articles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_abstract_string(abs_dict):\n",
    "    abs_string = abs_dict['content']\n",
    "    abs_string = re.search('<p>(.*)</p>', abs_string, flags=re.DOTALL)\n",
    "    return abs_string.group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_canonical_string(canonical_list):\n",
    "    url_dict = canonical_list[0]\n",
    "    url = url_dict['href']\n",
    "    return url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create preprocessed and cleaned DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piotr.bednarski/ml-env-27-gpu/lib/python2.7/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/piotr.bednarski/ml-env-27-gpu/lib/python2.7/site-packages/ipykernel/__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/piotr.bednarski/ml-env-27-gpu/lib/python2.7/site-packages/ipykernel/__main__.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/piotr.bednarski/ml-env-27-gpu/lib/python2.7/site-packages/ipykernel/__main__.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "all_articles_pd = pd.DataFrame(all_articles)\n",
    "all_articles_pd = all_articles_pd[['canonical', 'author', 'categories', 'published', 'title', 'summary']]\n",
    "\n",
    "for i in range(len(all_articles_pd)):\n",
    "    all_articles_pd['summary'][i] = get_abstract_string(all_articles_pd['summary'][i])\n",
    "    all_articles_pd['canonical'][i] = get_canonical_string(all_articles_pd['canonical'][i])\n",
    "    \n",
    "all_articles_pd['read'] = False\n",
    "all_articles_pd['liked'] = False\n",
    "\n",
    "for i in range(len(all_articles_pd)):\n",
    "    if 'user/1005689817/state/com.google/read' in all_articles_pd['categories'][i]:\n",
    "        all_articles_pd['read'][i] = True\n",
    "    if 'user/1005689817/state/com.google/like' in all_articles_pd['categories'][i]:\n",
    "        all_articles_pd['liked'][i] = True\n",
    "\n",
    "del all_articles_pd['categories']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#all_articles_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tagged_articles_pd = all_articles_pd[all_articles_pd['read'] == True]\n",
    "\n",
    "with open('old_articles_proto2.pickle', 'rb') as f:\n",
    "    # Pickle the 'data' dictionary using the highest protocol available.\n",
    "    old_tagged_articles_pd = pickle.load(f)\n",
    "    \n",
    "tagged_articles_pd = pd.concat([tagged_articles_pd, old_tagged_articles_pd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tagged_articles_unique_pd = tagged_articles_pd.sort_values(by=['canonical', 'liked'], ascending=False).reset_index(drop=True)\n",
    "to_drop = tagged_articles_unique_pd.duplicated(subset = ['canonical'], keep='first')\n",
    "to_drop = list(to_drop[to_drop == False].index.values)\n",
    "\n",
    "tagged_articles_unique_pd = tagged_articles_unique_pd[tagged_articles_unique_pd.index.isin(to_drop)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2652\n",
      "2446\n"
     ]
    }
   ],
   "source": [
    "print(len(tagged_articles_pd))\n",
    "print(len(tagged_articles_unique_pd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_ = list(tagged_articles_unique_pd['author']+' '+tagged_articles_unique_pd['title']+' '+tagged_articles_unique_pd['summary'])\n",
    "y_ = list(tagged_articles_unique_pd['liked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index_shuffled = [i for i in range(len(X_))]\n",
    "random.shuffle(index_shuffled)\n",
    "X = []\n",
    "y = []\n",
    "for i in index_shuffled:\n",
    "    X.append(X_[i])\n",
    "    y.append(y_[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('stopwords/english') as f:\n",
    "    stopwords = [line.strip() for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1206\n",
      "1012\n"
     ]
    }
   ],
   "source": [
    "print(len(X[4]))\n",
    "\n",
    "for i in range(len(X)):\n",
    "    seq = text_to_word_sequence(X[i])\n",
    "    clean_seq = [word for word in seq if word not in stopwords]\n",
    "    X[i] = ' '.join(clean_seq)\n",
    "    \n",
    "print(len(X[4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving or loading the data and LE and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1834\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "data_dict = {\n",
    "    'X' : X,\n",
    "    'y' : y\n",
    "}\n",
    "pickle.dump(data_dict,open(\"data.pickle\", \"wb\" ) )\n",
    "\n",
    "\n",
    "limit = int(0.75*len(X))\n",
    "print(limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1834\n"
     ]
    }
   ],
   "source": [
    "data_dict = pickle.load(open( \"data.pickle\", \"r\" ) )\n",
    "X = data_dict['X']\n",
    "y = data_dict['y']\n",
    "limit = int(0.75*len(X))\n",
    "print(limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF -> NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piotr.bednarski/ml-env-27-gpu/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.85620915032679734, 0.92092771264884565)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "\n",
    "\n",
    "model_nb_tfidf = Pipeline([\n",
    "    (\"tfidf_vectorizer\", TfidfVectorizer()),\\\n",
    "    (\"nb\", BernoulliNB())\n",
    "])\n",
    "\n",
    "\n",
    "X_train = X[:limit]\n",
    "X_test = X[limit:]\n",
    "\n",
    "y_train = y[:limit]\n",
    "y_test = y[limit:]\n",
    "\n",
    "model_nb_tfidf.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = model_nb_tfidf.predict(X_test)\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "acc, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.85620915032679734, 0.92092771264884565, 1, 612)\n",
      "(0.0, '% - ', 0)\n",
      "\n",
      "\n",
      "Rejected 100.00% of wrong ones\n",
      "Accepted 1.12% of good ones\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  1.00000000e+00,   5.78768398e-20],\n",
       "       [  1.00000000e+00,   1.46682056e-27],\n",
       "       [  1.00000000e+00,   1.60864192e-24],\n",
       "       [  1.00000000e+00,   2.27455926e-24],\n",
       "       [  1.00000000e+00,   5.25138436e-20]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted_proba = model_nb_tfidf.predict_proba(X_test)\n",
    "#y_predicted = (y_predicted_proba[:,1] > 0.15)\n",
    "y_predicted = (y_predicted_proba[:,1] > 0.10)\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)/len(y_predicted)*100.0,\"% - \", int(sum(y_predicted)/len(y_predicted)*50.0))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected %.2f%% of wrong ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == False)])*100.0/(len(y_test)-sum(y_test))))\n",
    "print(\"Accepted %.2f%% of good ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == True)])*100.0/sum(y_test)))\n",
    "\n",
    "y_predicted_proba[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CountVect -> NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piotr.bednarski/ml-env-27-gpu/lib/python2.7/site-packages/sklearn/metrics/classification.py:1115: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.85457516339869277, 0.92158590308370025)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "\n",
    "\n",
    "model_nb = Pipeline([\n",
    "    #('vect', CountVectorizer(ngram_range=(1,3),stop_words='english')),\\\n",
    "    (\"count_vectorizer\", CountVectorizer(analyzer=lambda x: x)),\\\n",
    "    (\"nb\", BernoulliNB())\n",
    "])\n",
    "\n",
    "X_train = X[:limit]\n",
    "X_test = X[limit:]\n",
    "\n",
    "y_train = y[:limit]\n",
    "y_test = y[limit:]\n",
    "\n",
    "model_nb.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = model_nb.predict(X_test)\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "acc, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.555555555556 0.490015360983 267 612\n",
      "43.6274509804 % -  21\n",
      "\n",
      "\n",
      "Rejected 56.98% of wrong ones\n",
      "Accepted 47.19% of good ones\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.87876577,  0.12123423],\n",
       "       [ 0.91535951,  0.08464049],\n",
       "       [ 0.81684456,  0.18315544],\n",
       "       [ 0.83247632,  0.16752368],\n",
       "       [ 0.90410823,  0.09589177]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted_proba = model_nb.predict_proba(X_test)\n",
    "#y_predicted = (y_predicted_proba[:,1] > 0.1296)\n",
    "y_predicted = (y_predicted_proba[:,1] > 0.1325)\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print acc, f1, sum(y_predicted), len(y_predicted)\n",
    "print sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected %.2f%% of wrong ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == False)])*100.0/(len(y_test)-sum(y_test))))\n",
    "print(\"Accepted %.2f%% of good ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == True)])*100.0/sum(y_test)))\n",
    "\n",
    "y_predicted_proba[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF -> SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.85620915032679734, 0.90261527687998266)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "\n",
    "model_svc_tfidf = Pipeline([\n",
    "    ('vect', CountVectorizer(ngram_range=(1,3), min_df=1, max_df=1.0,stop_words='english')),\n",
    "    #('vect', CountVectorizer(ngram_range=(3,6),analyzer='char_wb', min_df=10, max_df=0.95,stop_words='english')),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    (\"svc\", SVC(kernel='linear', probability=True, class_weight = 'balanced'))\n",
    "    #(\"svc\", SVC(kernel='linear', probability=True))\n",
    "])\n",
    "\n",
    "X_train = X[:limit]\n",
    "X_test = X[limit:]\n",
    "\n",
    "y_train = y[:limit]\n",
    "y_test = y[limit:]\n",
    "\n",
    "model_svc_tfidf.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = model_svc_tfidf.predict(X_test)\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "acc, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.55882352941176472, 0.49734773136307658, 325, 612)\n",
      "(53.104575163398692, '% - ', 26)\n",
      "\n",
      "\n",
      "Rejected 51.63% of wrong ones\n",
      "Accepted 80.90% of good ones\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.38262675,  0.61737325],\n",
       "       [ 0.93613274,  0.06386726],\n",
       "       [ 0.57142515,  0.42857485],\n",
       "       [ 0.87220903,  0.12779097],\n",
       "       [ 0.23406676,  0.76593324]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted_proba = model_svc_tfidf.predict_proba(X_test)\n",
    "#y_predicted = (y_predicted_proba[:,1] > 0.12)\n",
    "y_predicted = (y_predicted_proba[:,1] > 0.103)\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected %.2f%% of wrong ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == False)])*100.0/(len(y_test)-sum(y_test))))\n",
    "print(\"Accepted %.2f%% of good ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == True)])*100.0/sum(y_test)))\n",
    "\n",
    "y_predicted_proba[0:5]\n",
    "\n",
    "#(0.62077922077922076, 0.55417162908266104, 162, 385)\n",
    "#(42.077922077922075, '% - ', 21)\n",
    "#('Rejected good ones: ', 15, '/', 46)\n",
    "#('Accepted wrong ones:', 131, '/', 339)\n",
    "#('Rejected wrong ones: ', 208, '/', 339)\n",
    "#('Accepted good ones:', 31, '/', 46)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-44.88235294117647"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(X_test_df[(y_predicted == y_test) & (y_predicted == False)])*100.0/len(y_test)-sum(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7663398692810458, 0.75559793274823439)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "\n",
    "model_svc_tfidf = Pipeline([\n",
    "    #('vect', CountVectorizer(ngram_range=(1,3), min_df=1, max_df=1.0,stop_words='english')),\n",
    "    ('vect', CountVectorizer(ngram_range=(3,6),analyzer='char_wb', min_df=10, max_df=0.95,stop_words='english')),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    (\"svc\", SVC(kernel='linear', probability=True, class_weight = 'balanced'))\n",
    "    #(\"svc\", SVC(kernel='linear', probability=True))\n",
    "])\n",
    "\n",
    "X_train = X[:limit]\n",
    "X_test = X[limit:]\n",
    "\n",
    "y_train = y[:limit]\n",
    "y_test = y[limit:]\n",
    "\n",
    "model_svc_tfidf.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = model_svc_tfidf.predict(X_test)\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "acc, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.53104575163398693, 0.46556999777486274, 324, 612)\n",
      "(52.941176470588232, '% - ', 26)\n",
      "\n",
      "\n",
      "Rejected 50.10% of wrong ones\n",
      "Accepted 70.79% of good ones\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.70827366,  0.29172634],\n",
       "       [ 0.92089631,  0.07910369],\n",
       "       [ 0.8263935 ,  0.1736065 ],\n",
       "       [ 0.83135261,  0.16864739],\n",
       "       [ 0.5263346 ,  0.4736654 ]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted_proba = model_svc_tfidf.predict_proba(X_test)\n",
    "#y_predicted = (y_predicted_proba[:,1] > 0.12)\n",
    "y_predicted = (y_predicted_proba[:,1] > 0.111)\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected %.2f%% of wrong ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == False)])*100.0/(len(y_test)-sum(y_test))))\n",
    "print(\"Accepted %.2f%% of good ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == True)])*100.0/sum(y_test)))\n",
    "\n",
    "y_predicted_proba[0:5]\n",
    "\n",
    "#(0.62077922077922076, 0.55417162908266104, 162, 385)\n",
    "#(42.077922077922075, '% - ', 21)\n",
    "#('Rejected good ones: ', 15, '/', 46)\n",
    "#('Accepted wrong ones:', 131, '/', 339)\n",
    "#('Rejected wrong ones: ', 208, '/', 339)\n",
    "#('Accepted good ones:', 31, '/', 46)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count -> SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.85784313725490191, 0.91208872612245262)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "\n",
    "model_svc = Pipeline([\n",
    "    #('vect', CountVectorizer()),\n",
    "    ('vect', CountVectorizer(ngram_range=(1,3), min_df=1, max_df=1.0,stop_words='english')),\n",
    "    #('vect', CountVectorizer(ngram_range=(3,6),analyzer='char_wb', min_df=10, max_df=0.95,stop_words='english')),\n",
    "    #('tfidf', TfidfTransformer()),\n",
    "    (\"svc\", SVC(kernel='linear', probability=True, class_weight = 'balanced'))\n",
    "    #(\"svc\", SVC(kernel='linear', probability=True))\n",
    "])\n",
    "\n",
    "X_train = X[:limit]\n",
    "X_test = X[limit:]\n",
    "\n",
    "y_train = y[:limit]\n",
    "y_test = y[limit:]\n",
    "\n",
    "model_svc.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = model_svc.predict(X_test)\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "acc, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.52614379084967322, 0.46351612254209495, 347, 612)\n",
      "(56.699346405228759, '% - ', 28)\n",
      "\n",
      "\n",
      "Rejected 47.61% of wrong ones\n",
      "Accepted 82.02% of good ones\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.75110111,  0.24889889],\n",
       "       [ 0.88304561,  0.11695439],\n",
       "       [ 0.7525934 ,  0.2474066 ],\n",
       "       [ 0.89636819,  0.10363181],\n",
       "       [ 0.63111198,  0.36888802]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted_proba = model_svc.predict_proba(X_test)\n",
    "#y_predicted = (y_predicted_proba[:,1] > 0.12)\n",
    "y_predicted = (y_predicted_proba[:,1] > 0.11)\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected %.2f%% of wrong ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == False)])*100.0/(len(y_test)-sum(y_test))))\n",
    "print(\"Accepted %.2f%% of good ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == True)])*100.0/sum(y_test)))\n",
    "\n",
    "y_predicted_proba[0:5]\n",
    "\n",
    "#(0.62077922077922076, 0.55417162908266104, 162, 385)\n",
    "#(42.077922077922075, '% - ', 21)\n",
    "#('Rejected good ones: ', 15, '/', 46)\n",
    "#('Accepted wrong ones:', 131, '/', 339)\n",
    "#('Rejected wrong ones: ', 208, '/', 339)\n",
    "#('Accepted good ones:', 31, '/', 46)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extree - pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing word vectors.\n",
      "Found 1032578 word vectors.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "import models.embedding_matrix as embedding\n",
    "reload(embedding)\n",
    "\n",
    "DATASETS_DIR = '../ml-research/datasets/'\n",
    "WIKI_DIR = DATASETS_DIR+'wiki.pl/'\n",
    "embeddings_file = WIKI_DIR+'wiki.pl.vec'\n",
    "\n",
    "word2vec_pretrained = embedding.create_embedding_dictionary(embeddings_file)\n",
    "\n",
    "# train word2vec on all the texts - both training and test set\n",
    "# we're not using test labels, just texts so this is fine\n",
    "model = Word2Vec(X, size=100, window=5, min_count=5, workers=2)\n",
    "w2v_custom = {w: vec for w, vec in zip(model.wv.index2word, model.wv.syn0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "class MeanEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        self.dim = len(word2vec.itervalues().next())\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        return self \n",
    "\n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "            np.mean([self.word2vec[w] for w in words if w in self.word2vec] \n",
    "                    or [np.zeros(self.dim)], axis=0)\n",
    "            for words in X\n",
    "        ])\n",
    "    \n",
    "# and a tf-idf version of the same\n",
    "\n",
    "class TfidfEmbeddingVectorizer(object):\n",
    "    def __init__(self, word2vec):\n",
    "        self.word2vec = word2vec\n",
    "        self.word2weight = None\n",
    "        self.dim = len(word2vec.itervalues().next())\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        tfidf = TfidfVectorizer(analyzer=lambda x: x)\n",
    "        tfidf.fit(X)\n",
    "        # if a word was never seen - it must be at least as infrequent\n",
    "        # as any of the known words - so the default idf is the max of \n",
    "        # known idf's\n",
    "        max_idf = max(tfidf.idf_)\n",
    "        self.word2weight = defaultdict(\n",
    "            lambda: max_idf, \n",
    "            [(w, tfidf.idf_[i]) for w, i in tfidf.vocabulary_.items()])\n",
    "    \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return np.array([\n",
    "                np.mean([self.word2vec[w] * self.word2weight[w]\n",
    "                         for w in words if w in self.word2vec] or\n",
    "                        [np.zeros(self.dim)], axis=0)\n",
    "                for words in X\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extra Trees classifier is almost universally great, let's stack it with our embeddings\n",
    "\n",
    "etree_w2v = Pipeline([(\"word2vec vectorizer\", MeanEmbeddingVectorizer(word2vec_pretrained)), \n",
    "                        (\"extra trees\", ExtraTreesClassifier(n_estimators=50))])\n",
    "etree_w2v_tfidf = Pipeline([(\"word2vec vectorizer\", TfidfEmbeddingVectorizer(word2vec_pretrained)), \n",
    "                        (\"svc\", ExtraTreesClassifier(n_estimators=50))])\n",
    "svc_w2v = Pipeline([(\"word2vec vectorizer\", MeanEmbeddingVectorizer(word2vec_pretrained)), \n",
    "                        (\"extra trees\", SVC(kernel=\"linear\", probability=True))])\n",
    "svc_w2v_tfidf = Pipeline([(\"word2vec vectorizer\", TfidfEmbeddingVectorizer(word2vec_pretrained)), \n",
    "                        (\"svc\", SVC(kernel=\"linear\", probability=True))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.5702614379084967, 0.50690202565224629, 272, 612)\n",
      "(44.444444444444443, '% - ', 22)\n",
      "\n",
      "\n",
      "Rejected 57.36% of wrong ones\n",
      "Accepted 55.06% of good ones\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.86,  0.14],\n",
       "       [ 1.  ,  0.  ],\n",
       "       [ 0.76,  0.24],\n",
       "       [ 0.92,  0.08],\n",
       "       [ 0.66,  0.34]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "X_train = X[:limit]\n",
    "X_test = X[limit:]\n",
    "\n",
    "y_train = y[:limit]\n",
    "y_test = y[limit:]\n",
    "\n",
    "etree_w2v.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = etree_w2v.predict(X_test)\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "\n",
    "y_predicted_proba = etree_w2v.predict_proba(X_test)\n",
    "#y_predicted = (y_predicted_proba[:,1] > 0.12)\n",
    "y_predicted = (y_predicted_proba[:,1] > 0.14)\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected %.2f%% of wrong ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == False)])*100.0/(len(y_test)-sum(y_test))))\n",
    "print(\"Accepted %.2f%% of good ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == True)])*100.0/sum(y_test)))\n",
    "\n",
    "y_predicted_proba[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.53104575163398693, 0.46531780188275618, 322, 612)\n",
      "(52.614379084967318, '% - ', 26)\n",
      "\n",
      "\n",
      "Rejected 50.29% of wrong ones\n",
      "Accepted 69.66% of good ones\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.84,  0.16],\n",
       "       [ 0.94,  0.06],\n",
       "       [ 0.82,  0.18],\n",
       "       [ 0.9 ,  0.1 ],\n",
       "       [ 0.76,  0.24]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X[:limit]\n",
    "X_test = X[limit:]\n",
    "\n",
    "y_train = y[:limit]\n",
    "y_test = y[limit:]\n",
    "\n",
    "etree_w2v_tfidf.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = etree_w2v_tfidf.predict(X_test)\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "\n",
    "y_predicted_proba = etree_w2v_tfidf.predict_proba(X_test)\n",
    "#y_predicted = (y_predicted_proba[:,1] > 0.12)\n",
    "y_predicted = (y_predicted_proba[:,1] > 0.137)\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected %.2f%% of wrong ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == False)])*100.0/(len(y_test)-sum(y_test))))\n",
    "print(\"Accepted %.2f%% of good ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == True)])*100.0/sum(y_test)))\n",
    "\n",
    "y_predicted_proba[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.1437908496732026, 0.25101774042950509, 611, 612)\n",
      "(99.83660130718954, '% - ', 49)\n",
      "\n",
      "\n",
      "Rejected 0.00% of wrong ones\n",
      "Accepted 98.88% of good ones\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.85804242,  0.14195758],\n",
       "       [ 0.85837028,  0.14162972],\n",
       "       [ 0.85789585,  0.14210415],\n",
       "       [ 0.85648581,  0.14351419],\n",
       "       [ 0.85828106,  0.14171894]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X[:limit]\n",
    "X_test = X[limit:]\n",
    "\n",
    "y_train = y[:limit]\n",
    "y_test = y[limit:]\n",
    "\n",
    "svc_w2v.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = svc_w2v.predict(X_test)\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "\n",
    "y_predicted_proba = svc_w2v.predict_proba(X_test)\n",
    "#y_predicted = (y_predicted_proba[:,1] > 0.12)\n",
    "y_predicted = (y_predicted_proba[:,1] > 0.135)\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected %.2f%% of wrong ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == False)])*100.0/(len(y_test)-sum(y_test))))\n",
    "print(\"Accepted %.2f%% of good ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == True)])*100.0/sum(y_test)))\n",
    "\n",
    "y_predicted_proba[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.46895424836601307, 0.39857055244340356, 346, 612)\n",
      "(56.535947712418299, '% - ', 28)\n",
      "\n",
      "\n",
      "Rejected 44.36% of wrong ones\n",
      "Accepted 61.80% of good ones\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.79362731,  0.20637269],\n",
       "       [ 0.88048159,  0.11951841],\n",
       "       [ 0.85134198,  0.14865802],\n",
       "       [ 0.86675399,  0.13324601],\n",
       "       [ 0.86220898,  0.13779102]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X[:limit]\n",
    "X_test = X[limit:]\n",
    "\n",
    "y_train = y[:limit]\n",
    "y_test = y[limit:]\n",
    "\n",
    "svc_w2v_tfidf.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = svc_w2v_tfidf.predict(X_test)\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "\n",
    "y_predicted_proba = svc_w2v_tfidf.predict_proba(X_test)\n",
    "#y_predicted = (y_predicted_proba[:,1] > 0.12)\n",
    "y_predicted = (y_predicted_proba[:,1] > 0.145)\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected %.2f%% of wrong ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == False)])*100.0/(len(y_test)-sum(y_test))))\n",
    "print(\"Accepted %.2f%% of good ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == True)])*100.0/sum(y_test)))\n",
    "\n",
    "y_predicted_proba[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extree - Custom embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extra Trees classifier is almost universally great, let's stack it with our embeddings\n",
    "\n",
    "etree_w2v_custom = Pipeline([(\"word2vec vectorizer\", MeanEmbeddingVectorizer(w2v_custom)), \n",
    "                        (\"extra trees\", ExtraTreesClassifier(n_estimators=50))])\n",
    "etree_w2v_tfidf_custom = Pipeline([(\"word2vec vectorizer\", TfidfEmbeddingVectorizer(w2v_custom)), \n",
    "                        (\"svc\", ExtraTreesClassifier(n_estimators=50))])\n",
    "svc_w2v_custom = Pipeline([(\"word2vec vectorizer\", MeanEmbeddingVectorizer(w2v_custom)), \n",
    "                        (\"extra trees\", SVC(kernel=\"linear\", probability=True))])\n",
    "svc_w2v_tfidf_custom = Pipeline([(\"word2vec vectorizer\", TfidfEmbeddingVectorizer(w2v_custom)), \n",
    "                        (\"svc\", SVC(kernel=\"linear\", probability=True))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.61928104575163401, 0.56321203705933187, 260, 612)\n",
      "(42.483660130718953, '% - ', 21)\n",
      "\n",
      "\n",
      "Rejected 61.38% of wrong ones\n",
      "Accepted 65.17% of good ones\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.94,  0.06],\n",
       "       [ 0.88,  0.12],\n",
       "       [ 0.8 ,  0.2 ],\n",
       "       [ 0.94,  0.06],\n",
       "       [ 0.84,  0.16]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X[:limit]\n",
    "X_test = X[limit:]\n",
    "\n",
    "y_train = y[:limit]\n",
    "y_test = y[limit:]\n",
    "\n",
    "etree_w2v_custom.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = etree_w2v_custom.predict(X_test)\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "\n",
    "y_predicted_proba = etree_w2v_custom.predict_proba(X_test)\n",
    "#y_predicted = (y_predicted_proba[:,1] > 0.12)\n",
    "y_predicted = (y_predicted_proba[:,1] > 0.14)\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected %.2f%% of wrong ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == False)])*100.0/(len(y_test)-sum(y_test))))\n",
    "print(\"Accepted %.2f%% of good ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == True)])*100.0/sum(y_test)))\n",
    "\n",
    "y_predicted_proba[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.5326797385620915, 0.46730541340517906, 323, 612)\n",
      "(52.777777777777779, '% - ', 26)\n",
      "\n",
      "\n",
      "Rejected 50.29% of wrong ones\n",
      "Accepted 70.79% of good ones\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.8 ,  0.2 ],\n",
       "       [ 0.82,  0.18],\n",
       "       [ 0.76,  0.24],\n",
       "       [ 0.94,  0.06],\n",
       "       [ 0.88,  0.12]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X[:limit]\n",
    "X_test = X[limit:]\n",
    "\n",
    "y_train = y[:limit]\n",
    "y_test = y[limit:]\n",
    "\n",
    "etree_w2v_tfidf_custom.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = etree_w2v_tfidf_custom.predict(X_test)\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "\n",
    "y_predicted_proba = etree_w2v_tfidf_custom.predict_proba(X_test)\n",
    "#y_predicted = (y_predicted_proba[:,1] > 0.12)\n",
    "y_predicted = (y_predicted_proba[:,1] > 0.137)\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected %.2f%% of wrong ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == False)])*100.0/(len(y_test)-sum(y_test))))\n",
    "print(\"Accepted %.2f%% of good ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == True)])*100.0/sum(y_test)))\n",
    "\n",
    "y_predicted_proba[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.33823529411764708, 0.29877691611270707, 464, 612)\n",
      "(75.816993464052288, '% - ', 37)\n",
      "\n",
      "\n",
      "Rejected 25.43% of wrong ones\n",
      "Accepted 83.15% of good ones\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.83763728,  0.16236272],\n",
       "       [ 0.87275726,  0.12724274],\n",
       "       [ 0.83770015,  0.16229985],\n",
       "       [ 0.87757687,  0.12242313],\n",
       "       [ 0.83207554,  0.16792446]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X[:limit]\n",
    "X_test = X[limit:]\n",
    "\n",
    "y_train = y[:limit]\n",
    "y_test = y[limit:]\n",
    "\n",
    "svc_w2v_custom.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = svc_w2v_custom.predict(X_test)\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "\n",
    "y_predicted_proba = svc_w2v_custom.predict_proba(X_test)\n",
    "#y_predicted = (y_predicted_proba[:,1] > 0.12)\n",
    "y_predicted = (y_predicted_proba[:,1] > 0.135)\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected %.2f%% of wrong ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == False)])*100.0/(len(y_test)-sum(y_test))))\n",
    "print(\"Accepted %.2f%% of good ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == True)])*100.0/sum(y_test)))\n",
    "\n",
    "y_predicted_proba[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.52287581699346408, 0.45383759357521525, 301, 612)\n",
      "(49.183006535947712, '% - ', 24)\n",
      "\n",
      "\n",
      "Rejected 51.82% of wrong ones\n",
      "Accepted 55.06% of good ones\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.82352702,  0.17647298],\n",
       "       [ 0.83245524,  0.16754476],\n",
       "       [ 0.86507693,  0.13492307],\n",
       "       [ 0.85071184,  0.14928816],\n",
       "       [ 0.84901055,  0.15098945]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X[:limit]\n",
    "X_test = X[limit:]\n",
    "\n",
    "y_train = y[:limit]\n",
    "y_test = y[limit:]\n",
    "\n",
    "svc_w2v_tfidf_custom.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = svc_w2v_tfidf_custom.predict(X_test)\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "\n",
    "y_predicted_proba = svc_w2v_tfidf_custom.predict_proba(X_test)\n",
    "#y_predicted = (y_predicted_proba[:,1] > 0.12)\n",
    "y_predicted = (y_predicted_proba[:,1] > 0.145)\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected %.2f%% of wrong ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == False)])*100.0/(len(y_test)-sum(y_test))))\n",
    "print(\"Accepted %.2f%% of good ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == True)])*100.0/sum(y_test)))\n",
    "\n",
    "y_predicted_proba[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression and SGD - both on embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "\n",
    "logistic_w2v = Pipeline([(\"word2vec vectorizer\", MeanEmbeddingVectorizer(word2vec_pretrained)), \n",
    "                        (\"logistic\", LogisticRegression())])\n",
    "logistic_w2v_tfidf = Pipeline([(\"word2vec vectorizer\", TfidfEmbeddingVectorizer(word2vec_pretrained)), \n",
    "                        (\"logistic\", LogisticRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.55718954248366015, 0.49233893526720379, 288, 612)\n",
      "(47.058823529411768, '% - ', 23)\n",
      "\n",
      "\n",
      "Rejected 55.07% of wrong ones\n",
      "Accepted 59.55% of good ones\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.86661682,  0.13338318],\n",
       "       [ 0.90337903,  0.09662097],\n",
       "       [ 0.83128492,  0.16871508],\n",
       "       [ 0.84420314,  0.15579686],\n",
       "       [ 0.80742756,  0.19257244]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X[:limit]\n",
    "X_test = X[limit:]\n",
    "\n",
    "y_train = y[:limit]\n",
    "y_test = y[limit:]\n",
    "\n",
    "logistic_w2v.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = logistic_w2v.predict(X_test)\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "\n",
    "y_predicted_proba = logistic_w2v.predict_proba(X_test)\n",
    "#y_predicted = (y_predicted_proba[:,1] > 0.12)\n",
    "y_predicted = (y_predicted_proba[:,1] > 0.14)\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected %.2f%% of wrong ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == False)])*100.0/(len(y_test)-sum(y_test))))\n",
    "print(\"Accepted %.2f%% of good ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == True)])*100.0/sum(y_test)))\n",
    "\n",
    "y_predicted_proba[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.55718954248366015, 0.49233893526720379, 288, 612)\n",
      "(47.058823529411768, '% - ', 23)\n",
      "\n",
      "\n",
      "Rejected 55.07% of wrong ones\n",
      "Accepted 59.55% of good ones\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.86640739,  0.13359261],\n",
       "       [ 0.90346221,  0.09653779],\n",
       "       [ 0.83137045,  0.16862955],\n",
       "       [ 0.84536149,  0.15463851],\n",
       "       [ 0.80771324,  0.19228676]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X[:limit]\n",
    "X_test = X[limit:]\n",
    "\n",
    "y_train = y[:limit]\n",
    "y_test = y[limit:]\n",
    "\n",
    "logistic_w2v_tfidf.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = logistic_w2v_tfidf.predict(X_test)\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "\n",
    "y_predicted_proba = logistic_w2v_tfidf.predict_proba(X_test)\n",
    "#y_predicted = (y_predicted_proba[:,1] > 0.12)\n",
    "y_predicted = (y_predicted_proba[:,1] > 0.14)\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected %.2f%% of wrong ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == False)])*100.0/(len(y_test)-sum(y_test))))\n",
    "print(\"Accepted %.2f%% of good ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == True)])*100.0/sum(y_test)))\n",
    "\n",
    "y_predicted_proba[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "\n",
    "sgd_w2v = Pipeline([(\"word2vec vectorizer\", MeanEmbeddingVectorizer(word2vec_pretrained)), \n",
    "                        (\"logistic\", SGDClassifier(loss = 'log'))])\n",
    "sgd_w2v_tfidf = Pipeline([(\"word2vec vectorizer\", TfidfEmbeddingVectorizer(word2vec_pretrained)), \n",
    "                        (\"logistic\", SGDClassifier(loss = 'log'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.84477124183006536, 0.90125569419687079, 10, 612)\n",
      "(1.6339869281045751, '% - ', 0)\n",
      "\n",
      "\n",
      "Rejected 98.47% of wrong ones\n",
      "Accepted 2.25% of good ones\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  9.97375276e-01,   2.62472409e-03],\n",
       "       [  9.99657836e-01,   3.42164062e-04],\n",
       "       [  9.84727369e-01,   1.52726310e-02],\n",
       "       [  9.91213470e-01,   8.78653007e-03],\n",
       "       [  9.65991370e-01,   3.40086302e-02]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X[:limit]\n",
    "X_test = X[limit:]\n",
    "\n",
    "y_train = y[:limit]\n",
    "y_test = y[limit:]\n",
    "\n",
    "sgd_w2v.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = sgd_w2v.predict(X_test)\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "\n",
    "y_predicted_proba = sgd_w2v.predict_proba(X_test)\n",
    "#y_predicted = (y_predicted_proba[:,1] > 0.12)\n",
    "y_predicted = (y_predicted_proba[:,1] > 0.14)\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected %.2f%% of wrong ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == False)])*100.0/(len(y_test)-sum(y_test))))\n",
    "print(\"Accepted %.2f%% of good ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == True)])*100.0/sum(y_test)))\n",
    "\n",
    "y_predicted_proba[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.73692810457516345, 0.72064111322500513, 122, 612)\n",
      "(19.934640522875817, '% - ', 9)\n",
      "\n",
      "\n",
      "Rejected 81.45% of wrong ones\n",
      "Accepted 28.09% of good ones\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.97117963,  0.02882037],\n",
       "       [ 0.99618042,  0.00381958],\n",
       "       [ 0.83095958,  0.16904042],\n",
       "       [ 0.90258141,  0.09741859],\n",
       "       [ 0.68663379,  0.31336621]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X[:limit]\n",
    "X_test = X[limit:]\n",
    "\n",
    "y_train = y[:limit]\n",
    "y_test = y[limit:]\n",
    "\n",
    "sgd_w2v_tfidf.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = sgd_w2v_tfidf.predict(X_test)\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "\n",
    "y_predicted_proba = sgd_w2v_tfidf.predict_proba(X_test)\n",
    "#y_predicted = (y_predicted_proba[:,1] > 0.12)\n",
    "y_predicted = (y_predicted_proba[:,1] > 0.14)\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected %.2f%% of wrong ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == False)])*100.0/(len(y_test)-sum(y_test))))\n",
    "print(\"Accepted %.2f%% of good ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == True)])*100.0/sum(y_test)))\n",
    "\n",
    "y_predicted_proba[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Saving/loading models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "def datetime_string():\n",
    "    localtime = time.localtime(time.time())\n",
    "    datetime_str = str(localtime.tm_year)\n",
    "    if(localtime.tm_mon < 10):\n",
    "        datetime_str += '0'\n",
    "    datetime_str += str(localtime.tm_mon)\n",
    "    if(localtime.tm_mday < 10):\n",
    "        datetime_str += '0'\n",
    "    datetime_str += str(localtime.tm_mday) + '_'\n",
    "    if(localtime.tm_hour < 10):\n",
    "        datetime_str += '0'\n",
    "    datetime_str += str(localtime.tm_hour)\n",
    "    if(localtime.tm_min < 10):\n",
    "        datetime_str += '0'\n",
    "    datetime_str += str(localtime.tm_min) + '_'\n",
    "    \n",
    "    return datetime_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import dill\n",
    "\n",
    "contents_dict = {\n",
    "    #'model_cnn_keras' : model_cnn,\n",
    "    #'model_lstm_keras' : model_lstm,\n",
    "    \n",
    "    'model_svc_sklearn' : model_svc,\n",
    "    'model_svc_tfidf_sklearn' : model_svc_tfidf,\n",
    "    \n",
    "    'model_nb_sklearn' : model_nb,\n",
    "    'model_nb_tfidf_sklearn' : model_nb_tfidf,\n",
    "    \n",
    "    'etree_w2v_sklearn' : etree_w2v,\n",
    "    'etree_w2v_tfidf_sklearn' : etree_w2v_tfidf,\n",
    "    \n",
    "    'svc_w2v_sklearn' : svc_w2v,\n",
    "    'svc_w2v_tfidf_sklearn' : svc_w2v_tfidf,\n",
    "    \n",
    "    'etree_w2v_custom_sklearn' : etree_w2v_custom,\n",
    "    'etree_w2v_tfidf_custom_sklearn' : etree_w2v_tfidf_custom,\n",
    "    \n",
    "    'svc_w2v_custom_sklearn' : svc_w2v_custom,\n",
    "    'svc_w2v_tfidf_custom_sklearn' : svc_w2v_tfidf_custom,\n",
    "    \n",
    "    'logistic_w2v_sklearn' : logistic_w2v,\n",
    "    'logistic_w2v_tfidf_sklearn' : logistic_w2v_tfidf,\n",
    "    \n",
    "    'sgd_w2v_sklearn' : sgd_w2v,\n",
    "    'sgd_w2v_tfidf_sklearn' : sgd_w2v_tfidf,\n",
    "    \n",
    "    #'hyperparameters_cnn' : hyperparameters_cnn,\n",
    "    #'hyperparameters_lstm' : hyperparameters_lstm,\n",
    "    \n",
    "   # 'label_encoder' : label_encoder,\n",
    "   # 'tokenizer' : tokenizer\n",
    "}\n",
    "   \n",
    "pickle.dump(contents_dict,open( \"models/\"+datetime_string()+\"ensemble_models.pickle\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents_dict = pickle.load(open( \"models/20180125_1302_ensemble_models.pickle\", \"r\" ) )\n",
    "\n",
    "model_svc = contents_dict['model_svc_sklearn']\n",
    "model_svc_tfidf = contents_dict['model_svc_tfidf_sklearn']\n",
    "\n",
    "model_nb = contents_dict['model_nb_sklearn']\n",
    "model_nb_tfidf = contents_dict['model_nb_tfidf_sklearn']\n",
    "\n",
    "etree_w2v = contents_dict['etree_w2v_sklearn']\n",
    "etree_w2v_tfidf = contents_dict['etree_w2v_tfidf_sklearn']\n",
    "\n",
    "svc_w2v = contents_dict['svc_w2v_sklearn']\n",
    "svc_w2v_tfidf = contents_dict['svc_w2v_tfidf_sklearn']\n",
    "\n",
    "etree_w2v_custom = contents_dict['etree_w2v_custom_sklearn']\n",
    "etree_w2v_tfidf_custom = contents_dict['etree_w2v_tfidf_custom_sklearn']\n",
    "\n",
    "svc_w2v_custom = contents_dict['svc_w2v_custom_sklearn']\n",
    "svc_w2v_tfidf_custom = contents_dict['svc_w2v_tfidf_custom_sklearn']\n",
    "\n",
    "logistic_w2v = contents_dict['logistic_w2v_sklearn']\n",
    "logistic_w2v_tfidf = contents_dict['logistic_w2v_tfidf_sklearn']\n",
    "\n",
    "sgd_w2v = contents_dict['sgd_w2v_sklearn']\n",
    "sgd_w2v_tfidf = contents_dict['sgd_w2v_tfidf_sklearn']\n",
    "\n",
    "#hyperparameters_cnn = contents_dict['hyperparameters_cnn']\n",
    "#hyperparameters_lstm = contents_dict['hyperparameters_lstm']\n",
    "\n",
    "#label_encoder = contents_dict['label_encoder']\n",
    "#tokenize = contents_dict['tokenizer']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word embeddings preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import (Input, Embedding, SimpleRNN, Dense, Activation, TimeDistributed, Bidirectional, LSTM, GaussianNoise)\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model\n",
    "from keras.utils import plot_model #Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import types\n",
    "import tempfile\n",
    "import keras.models\n",
    "\n",
    "def make_keras_picklable():\n",
    "    def __getstate__(self):\n",
    "        model_str = \"\"\n",
    "        with tempfile.NamedTemporaryFile(suffix='.hdf5', delete=True) as fd:\n",
    "            keras.models.save_model(self, fd.name, overwrite=True)\n",
    "            model_str = fd.read()\n",
    "        d = { 'model_str': model_str }\n",
    "        return d\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        with tempfile.NamedTemporaryFile(suffix='.hdf5', delete=True) as fd:\n",
    "            fd.write(state['model_str'])\n",
    "            fd.flush()\n",
    "            model = keras.models.load_model(fd.name)\n",
    "        self.__dict__ = model.__dict__\n",
    "\n",
    "\n",
    "    cls = keras.models.Model\n",
    "    cls.__getstate__ = __getstate__\n",
    "    cls.__setstate__ = __setstate__\n",
    "    \n",
    "\n",
    "make_keras_picklable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATASETS_DIR = '../ml-research/datasets/'\n",
    "GLOVE_DIR = DATASETS_DIR+'glove.6B/'\n",
    "WIKI_EN_DIR = DATASETS_DIR+'wiki.en/'\n",
    "#embeddings_file = os.path.join(GLOVE_DIR, 'glove.6B.300d.txt')\n",
    "embeddings_file = os.path.join(WIKI_EN_DIR, 'wiki.en.vec')\n",
    "\n",
    "# Word embeddings' constraints\n",
    "MAX_NB_WORDS = 20000  # Number of most common words for tokenizer\n",
    "EMBEDDING_DIM = 300   # Embeddings dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras.preprocessing.text\n",
    "from string import maketrans\n",
    "\n",
    "def text_to_word_sequence(text,\n",
    "                          filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "                          lower=True, split=\" \"):\n",
    "    if lower: text = text.lower()\n",
    "    if type(text) == unicode:\n",
    "        translate_table = {ord(c): ord(t) for c,t in zip(filters, split*len(filters)) }\n",
    "    else:\n",
    "        translate_table = maketrans(filters, split * len(filters))\n",
    "    text = text.translate(translate_table)\n",
    "    seq = text.split(split)\n",
    "    return [i for i in seq if i]\n",
    "    \n",
    "keras.preprocessing.text.text_to_word_sequence = text_to_word_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25779 unique tokens.\n",
      "80\n",
      "25778\n"
     ]
    }
   ],
   "source": [
    "# Tokenizing and creating word index\n",
    "\n",
    "additional_words = ['unk', 'num']\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(X+additional_words)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "# inversing the word_index.\n",
    "index_word = dict((k,v) for v,k in word_index.items())\n",
    "\n",
    "# example\n",
    "print(word_index['adversarial'])\n",
    "print(word_index['unk'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing word vectors.\n",
      "Found 2519371 word vectors.\n",
      "Creating Word Embeddings matrix...\n",
      "Word Embeddings matrix was successfuly created.\n"
     ]
    }
   ],
   "source": [
    "import models.embedding_matrix as embedding\n",
    "\n",
    "embedding_matrix = embedding.create_embedding_matrix(embeddings_file, MAX_NB_WORDS, EMBEDDING_DIM, word_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import (Input, Embedding, SimpleRNN, Dense, Activation, TimeDistributed, Bidirectional,\n",
    "                          LSTM, GaussianNoise,Conv1D, MaxPooling1D, Flatten, Dropout)\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hyperparameters_cnn = {\n",
    "    'conv_units': 128,\n",
    "    'hidden_units_1': 128,\n",
    "    'hidden_units_2': 64,\n",
    "    'dropout': 0.5,\n",
    "    'pooling' : 5,\n",
    "    'gauss_stddev' : 0.0002,\n",
    "    'epochs' : 15,\n",
    "    'folds' : 5,\n",
    "    'nclasses' : 2,\n",
    "    'max_seq_len' : 300,\n",
    "    'learning_rate' : 0.001,\n",
    "    'stopwords' : True\n",
    "}\n",
    "\n",
    "hyperparameters_cnn = {\n",
    "    'conv_units': 64,\n",
    "    'hidden_units_1': 64,\n",
    "    'hidden_units_2': 32,\n",
    "    'dropout': 0.5,\n",
    "    'pooling' : 5,\n",
    "    'gauss_stddev' : 0.0002,\n",
    "    'epochs' : 15,\n",
    "    'folds' : 5,\n",
    "    'nclasses' : 2,\n",
    "    'max_seq_len' : 300,\n",
    "    'learning_rate' : 0.001,\n",
    "    'stopwords' : True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff746391150>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "hyperparameters = hyperparameters_cnn\n",
    "\n",
    "\n",
    "X_sequences = tokenizer.texts_to_sequences(X)\n",
    "X_sequences_len = []\n",
    "for item in X_sequences:\n",
    "    X_sequences_len.append(\n",
    "                            min( len(item), 1000\n",
    "                               ))\n",
    "    \n",
    "X_sequences_padded = pad_sequences(X_sequences, maxlen=hyperparameters['max_seq_len'])\n",
    "\n",
    "plt.hist(X_sequences_len, 50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn import preprocessing\n",
    "\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "label_encoder.fit(y)\n",
    "\n",
    "y_num = label_encoder.transform(y)\n",
    "y_matrix = to_categorical(y_num,hyperparameters['nclasses'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1956 samples, validate on 490 samples\n",
      "Epoch 1/15\n",
      "1956/1956 [==============================] - 7s - loss: 1.1975 - categorical_accuracy: 0.5552 - val_loss: 0.6381 - val_categorical_accuracy: 0.8673\n",
      "Epoch 2/15\n",
      "1956/1956 [==============================] - 6s - loss: 1.1980 - categorical_accuracy: 0.6109 - val_loss: 0.6876 - val_categorical_accuracy: 0.5959\n",
      "Epoch 3/15\n",
      "1956/1956 [==============================] - 6s - loss: 1.1910 - categorical_accuracy: 0.4335 - val_loss: 0.6070 - val_categorical_accuracy: 0.8571\n",
      "Epoch 4/15\n",
      "1956/1956 [==============================] - 6s - loss: 1.1749 - categorical_accuracy: 0.5660 - val_loss: 0.6832 - val_categorical_accuracy: 0.5755\n",
      "Epoch 5/15\n",
      "1956/1956 [==============================] - 6s - loss: 1.1325 - categorical_accuracy: 0.5716 - val_loss: 0.8055 - val_categorical_accuracy: 0.3735\n",
      "Epoch 6/15\n",
      "1956/1956 [==============================] - 6s - loss: 1.0877 - categorical_accuracy: 0.5895 - val_loss: 0.5565 - val_categorical_accuracy: 0.7347\n",
      "Epoch 7/15\n",
      "1956/1956 [==============================] - 6s - loss: 0.9886 - categorical_accuracy: 0.6820 - val_loss: 0.4604 - val_categorical_accuracy: 0.8245\n",
      "Epoch 8/15\n",
      "1956/1956 [==============================] - 6s - loss: 0.8995 - categorical_accuracy: 0.7618 - val_loss: 0.7720 - val_categorical_accuracy: 0.5959\n",
      "Epoch 9/15\n",
      "1956/1956 [==============================] - 6s - loss: 0.7512 - categorical_accuracy: 0.7889 - val_loss: 0.6290 - val_categorical_accuracy: 0.6857\n",
      "Epoch 10/15\n",
      "1956/1956 [==============================] - 6s - loss: 0.5657 - categorical_accuracy: 0.8584 - val_loss: 0.4713 - val_categorical_accuracy: 0.7918\n",
      "Epoch 11/15\n",
      "1956/1956 [==============================] - 6s - loss: 0.3403 - categorical_accuracy: 0.9228 - val_loss: 0.5220 - val_categorical_accuracy: 0.8102\n",
      "Epoch 12/15\n",
      "1956/1956 [==============================] - 6s - loss: 0.2008 - categorical_accuracy: 0.9586 - val_loss: 1.3461 - val_categorical_accuracy: 0.5735\n",
      "Epoch 13/15\n",
      "1956/1956 [==============================] - 6s - loss: 0.5151 - categorical_accuracy: 0.8599 - val_loss: 0.4333 - val_categorical_accuracy: 0.8449\n",
      "Epoch 14/15\n",
      "1956/1956 [==============================] - 6s - loss: 0.2012 - categorical_accuracy: 0.9749 - val_loss: 0.5669 - val_categorical_accuracy: 0.8306\n",
      "Epoch 15/15\n",
      "1956/1956 [==============================] - 6s - loss: 0.0599 - categorical_accuracy: 0.9913 - val_loss: 0.8288 - val_categorical_accuracy: 0.7837\n",
      "(0.78367346938775506, 0.79486500341763489)\n",
      "[[365  62]\n",
      " [ 44  19]]\n",
      "Train on 1957 samples, validate on 489 samples\n",
      "Epoch 1/15\n",
      "1957/1957 [==============================] - 7s - loss: 1.1950 - categorical_accuracy: 0.5376 - val_loss: 0.7035 - val_categorical_accuracy: 0.1391\n",
      "Epoch 2/15\n",
      "1957/1957 [==============================] - 6s - loss: 1.1896 - categorical_accuracy: 0.3516 - val_loss: 0.6596 - val_categorical_accuracy: 0.8630\n",
      "Epoch 3/15\n",
      "1957/1957 [==============================] - 6s - loss: 1.1779 - categorical_accuracy: 0.6949 - val_loss: 0.6533 - val_categorical_accuracy: 0.5337\n",
      "Epoch 4/15\n",
      "1957/1957 [==============================] - 6s - loss: 1.1703 - categorical_accuracy: 0.6658 - val_loss: 0.6275 - val_categorical_accuracy: 0.5746\n",
      "Epoch 5/15\n",
      "1957/1957 [==============================] - 6s - loss: 1.1388 - categorical_accuracy: 0.6341 - val_loss: 0.6280 - val_categorical_accuracy: 0.5317\n",
      "Epoch 6/15\n",
      "1957/1957 [==============================] - 6s - loss: 1.0980 - categorical_accuracy: 0.5851 - val_loss: 0.6994 - val_categorical_accuracy: 0.4601\n",
      "Epoch 7/15\n",
      "1957/1957 [==============================] - 6s - loss: 1.0357 - categorical_accuracy: 0.6265 - val_loss: 0.5176 - val_categorical_accuracy: 0.7157\n",
      "Epoch 8/15\n",
      "1957/1957 [==============================] - 7s - loss: 0.9157 - categorical_accuracy: 0.7425 - val_loss: 0.8193 - val_categorical_accuracy: 0.4806\n",
      "Epoch 9/15\n",
      "1957/1957 [==============================] - 7s - loss: 0.7606 - categorical_accuracy: 0.7782 - val_loss: 0.8216 - val_categorical_accuracy: 0.5215\n",
      "Epoch 10/15\n",
      "1957/1957 [==============================] - 7s - loss: 0.7309 - categorical_accuracy: 0.7547 - val_loss: 0.4911 - val_categorical_accuracy: 0.7669\n",
      "Epoch 11/15\n",
      "1957/1957 [==============================] - 6s - loss: 0.4722 - categorical_accuracy: 0.8733 - val_loss: 0.6343 - val_categorical_accuracy: 0.7280\n",
      "Epoch 12/15\n",
      "1957/1957 [==============================] - 6s - loss: 0.3264 - categorical_accuracy: 0.9090 - val_loss: 0.6195 - val_categorical_accuracy: 0.7423\n",
      "Epoch 13/15\n",
      "1957/1957 [==============================] - 6s - loss: 0.2063 - categorical_accuracy: 0.9515 - val_loss: 0.6843 - val_categorical_accuracy: 0.8323\n",
      "Epoch 14/15\n",
      "1957/1957 [==============================] - 6s - loss: 0.1330 - categorical_accuracy: 0.9729 - val_loss: 0.7576 - val_categorical_accuracy: 0.8344\n",
      "Epoch 15/15\n",
      "1957/1957 [==============================] - 6s - loss: 0.0885 - categorical_accuracy: 0.9867 - val_loss: 0.8059 - val_categorical_accuracy: 0.7955\n",
      "(0.79550102249488752, 0.80331545202177379)\n",
      "[[364  57]\n",
      " [ 43  25]]\n",
      "Train on 1957 samples, validate on 489 samples\n",
      "Epoch 1/15\n",
      "1957/1957 [==============================] - 7s - loss: 1.1988 - categorical_accuracy: 0.7041 - val_loss: 0.6887 - val_categorical_accuracy: 0.6646\n",
      "Epoch 2/15\n",
      "1957/1957 [==============================] - 6s - loss: 1.1959 - categorical_accuracy: 0.3240 - val_loss: 0.6822 - val_categorical_accuracy: 0.3742\n",
      "Epoch 3/15\n",
      "1957/1957 [==============================] - 6s - loss: 1.1898 - categorical_accuracy: 0.6142 - val_loss: 0.6332 - val_categorical_accuracy: 0.6748\n",
      "Epoch 4/15\n",
      "1957/1957 [==============================] - 7s - loss: 1.1640 - categorical_accuracy: 0.7087 - val_loss: 0.6535 - val_categorical_accuracy: 0.5481\n",
      "Epoch 5/15\n",
      "1957/1957 [==============================] - 6s - loss: 1.1383 - categorical_accuracy: 0.5912 - val_loss: 0.6108 - val_categorical_accuracy: 0.6074\n",
      "Epoch 6/15\n",
      "1957/1957 [==============================] - 6s - loss: 1.0837 - categorical_accuracy: 0.6275 - val_loss: 0.6760 - val_categorical_accuracy: 0.5337\n",
      "Epoch 7/15\n",
      "1957/1957 [==============================] - 7s - loss: 1.0228 - categorical_accuracy: 0.6321 - val_loss: 0.6923 - val_categorical_accuracy: 0.5297\n",
      "Epoch 8/15\n",
      "1957/1957 [==============================] - 7s - loss: 0.8617 - categorical_accuracy: 0.7557 - val_loss: 0.4505 - val_categorical_accuracy: 0.8016\n",
      "Epoch 9/15\n",
      "1957/1957 [==============================] - 7s - loss: 0.6363 - categorical_accuracy: 0.8201 - val_loss: 0.4207 - val_categorical_accuracy: 0.8200\n",
      "Epoch 10/15\n",
      "1957/1957 [==============================] - 7s - loss: 0.4204 - categorical_accuracy: 0.8912 - val_loss: 0.6327 - val_categorical_accuracy: 0.7035\n",
      "Epoch 11/15\n",
      "1957/1957 [==============================] - 6s - loss: 0.3850 - categorical_accuracy: 0.9004 - val_loss: 0.5029 - val_categorical_accuracy: 0.7955\n",
      "Epoch 12/15\n",
      "1957/1957 [==============================] - 6s - loss: 0.4964 - categorical_accuracy: 0.8544 - val_loss: 0.4848 - val_categorical_accuracy: 0.7914\n",
      "Epoch 13/15\n",
      "1957/1957 [==============================] - 6s - loss: 0.2294 - categorical_accuracy: 0.9647 - val_loss: 0.5424 - val_categorical_accuracy: 0.8180\n",
      "Epoch 14/15\n",
      "1957/1957 [==============================] - 6s - loss: 0.1042 - categorical_accuracy: 0.9821 - val_loss: 0.6327 - val_categorical_accuracy: 0.8221\n",
      "Epoch 15/15\n",
      "1957/1957 [==============================] - 6s - loss: 0.0504 - categorical_accuracy: 0.9908 - val_loss: 0.6851 - val_categorical_accuracy: 0.8446\n",
      "(0.84458077709611457, 0.82149696961265761)\n",
      "[[403  22]\n",
      " [ 54  10]]\n",
      "Train on 1957 samples, validate on 489 samples\n",
      "Epoch 1/15\n",
      "1957/1957 [==============================] - 6s - loss: 1.1886 - categorical_accuracy: 0.5514 - val_loss: 0.6753 - val_categorical_accuracy: 0.8405\n",
      "Epoch 2/15\n",
      "1957/1957 [==============================] - 6s - loss: 1.1834 - categorical_accuracy: 0.5713 - val_loss: 0.6865 - val_categorical_accuracy: 0.7423\n",
      "Epoch 3/15\n",
      "1957/1957 [==============================] - 6s - loss: 1.1759 - categorical_accuracy: 0.5820 - val_loss: 0.6544 - val_categorical_accuracy: 0.7996\n",
      "Epoch 4/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1957/1957 [==============================] - 6s - loss: 1.1705 - categorical_accuracy: 0.6239 - val_loss: 0.6475 - val_categorical_accuracy: 0.7157\n",
      "Epoch 5/15\n",
      "1957/1957 [==============================] - 6s - loss: 1.1373 - categorical_accuracy: 0.6346 - val_loss: 0.6088 - val_categorical_accuracy: 0.7014\n",
      "Epoch 6/15\n",
      "1957/1957 [==============================] - 6s - loss: 1.0548 - categorical_accuracy: 0.6694 - val_loss: 0.6815 - val_categorical_accuracy: 0.5542\n",
      "Epoch 7/15\n",
      "1957/1957 [==============================] - 6s - loss: 0.9154 - categorical_accuracy: 0.7179 - val_loss: 0.8344 - val_categorical_accuracy: 0.5072\n",
      "Epoch 8/15\n",
      "1957/1957 [==============================] - 6s - loss: 0.7204 - categorical_accuracy: 0.7900 - val_loss: 0.4031 - val_categorical_accuracy: 0.8344\n",
      "Epoch 9/15\n",
      "1957/1957 [==============================] - 6s - loss: 0.5367 - categorical_accuracy: 0.8743 - val_loss: 0.5333 - val_categorical_accuracy: 0.7485\n",
      "Epoch 10/15\n",
      "1957/1957 [==============================] - 6s - loss: 0.2582 - categorical_accuracy: 0.9479 - val_loss: 0.5767 - val_categorical_accuracy: 0.8282\n",
      "Epoch 11/15\n",
      "1957/1957 [==============================] - 6s - loss: 0.1412 - categorical_accuracy: 0.9745 - val_loss: 0.6072 - val_categorical_accuracy: 0.8364\n",
      "Epoch 12/15\n",
      "1957/1957 [==============================] - 6s - loss: 0.0626 - categorical_accuracy: 0.9903 - val_loss: 0.6710 - val_categorical_accuracy: 0.8323\n",
      "Epoch 13/15\n",
      "1957/1957 [==============================] - 6s - loss: 0.0422 - categorical_accuracy: 0.9918 - val_loss: 0.7954 - val_categorical_accuracy: 0.8405\n",
      "Epoch 14/15\n",
      "1957/1957 [==============================] - 6s - loss: 0.0467 - categorical_accuracy: 0.9949 - val_loss: 0.7380 - val_categorical_accuracy: 0.7955\n",
      "Epoch 15/15\n",
      "1957/1957 [==============================] - 6s - loss: 0.0375 - categorical_accuracy: 0.9949 - val_loss: 0.7642 - val_categorical_accuracy: 0.8303\n",
      "(0.8302658486707567, 0.82041529834554827)\n",
      "[[385  33]\n",
      " [ 50  21]]\n",
      "Train on 1957 samples, validate on 489 samples\n",
      "Epoch 1/15\n",
      "1957/1957 [==============================] - 7s - loss: 1.1647 - categorical_accuracy: 0.6142 - val_loss: 0.6661 - val_categorical_accuracy: 0.8303\n",
      "Epoch 2/15\n",
      "1957/1957 [==============================] - 6s - loss: 1.1624 - categorical_accuracy: 0.8171 - val_loss: 0.6707 - val_categorical_accuracy: 0.8303\n",
      "Epoch 3/15\n",
      "1957/1957 [==============================] - 6s - loss: 1.1544 - categorical_accuracy: 0.8242 - val_loss: 0.6676 - val_categorical_accuracy: 0.6299\n",
      "Epoch 4/15\n",
      "1957/1957 [==============================] - 6s - loss: 1.1249 - categorical_accuracy: 0.7399 - val_loss: 0.7091 - val_categorical_accuracy: 0.4581\n",
      "Epoch 5/15\n",
      "1957/1957 [==============================] - 6s - loss: 1.0698 - categorical_accuracy: 0.6311 - val_loss: 0.5391 - val_categorical_accuracy: 0.7485\n",
      "Epoch 6/15\n",
      "1957/1957 [==============================] - 6s - loss: 1.0682 - categorical_accuracy: 0.6285 - val_loss: 0.6667 - val_categorical_accuracy: 0.5644\n",
      "Epoch 7/15\n",
      "1957/1957 [==============================] - 6s - loss: 0.9689 - categorical_accuracy: 0.7220 - val_loss: 0.5497 - val_categorical_accuracy: 0.6953\n",
      "Epoch 8/15\n",
      "1957/1957 [==============================] - 6s - loss: 0.8504 - categorical_accuracy: 0.7537 - val_loss: 0.4575 - val_categorical_accuracy: 0.7996\n",
      "Epoch 9/15\n",
      "1957/1957 [==============================] - 6s - loss: 0.7075 - categorical_accuracy: 0.8109 - val_loss: 0.4596 - val_categorical_accuracy: 0.8078\n",
      "Epoch 10/15\n",
      "1957/1957 [==============================] - 6s - loss: 0.4658 - categorical_accuracy: 0.8850 - val_loss: 0.5115 - val_categorical_accuracy: 0.8221\n",
      "Epoch 11/15\n",
      "1957/1957 [==============================] - 6s - loss: 0.2822 - categorical_accuracy: 0.9463 - val_loss: 0.6573 - val_categorical_accuracy: 0.7894\n",
      "Epoch 12/15\n",
      "1957/1957 [==============================] - 6s - loss: 0.1305 - categorical_accuracy: 0.9709 - val_loss: 1.2883 - val_categorical_accuracy: 0.8323\n",
      "Epoch 13/15\n",
      "1957/1957 [==============================] - 6s - loss: 0.1818 - categorical_accuracy: 0.9699 - val_loss: 0.6711 - val_categorical_accuracy: 0.8200\n",
      "Epoch 14/15\n",
      "1957/1957 [==============================] - 6s - loss: 0.0880 - categorical_accuracy: 0.9872 - val_loss: 0.8105 - val_categorical_accuracy: 0.7791\n",
      "Epoch 15/15\n",
      "1957/1957 [==============================] - 6s - loss: 0.0317 - categorical_accuracy: 0.9974 - val_loss: 0.9946 - val_categorical_accuracy: 0.8221\n",
      "(0.82208588957055218, 0.79718375419846221)\n",
      "[[383  23]\n",
      " [ 64  19]]\n",
      "(0.82208588957055218, 0.79718375419846221)\n",
      "[[ 1900.   197.]\n",
      " [  255.    94.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "import utils.evaluation as evaluation\n",
    "from keras import metrics\n",
    "\n",
    "class_weight = {0 : 1.,\n",
    "    1: (len(y)-sum(y))/sum(y)}\n",
    "\n",
    "acc_list = []\n",
    "f1_list = []\n",
    "cm_summed = np.zeros((2,2))\n",
    "kf = KFold(n_splits=5, shuffle = True)\n",
    "for train_index, test_index in kf.split(X_sequences):\n",
    "    K.clear_session()\n",
    "    \n",
    "    X_sequences_padded = pad_sequences(X_sequences, maxlen=hyperparameters['max_seq_len'])\n",
    "\n",
    "    num_words = embedding_matrix.shape[0]\n",
    "    embedding_dim = embedding_matrix.shape[1]\n",
    "\n",
    "    embedding_layer = Embedding(num_words,\n",
    "                                embedding_dim,\n",
    "                                weights=[embedding_matrix],\n",
    "                                input_length=hyperparameters['max_seq_len'],\n",
    "                                trainable=False)\n",
    "\n",
    "    # train a 1D convnet with global maxpooling\n",
    "    sequence_input = Input(shape=(hyperparameters['max_seq_len'],), dtype='int32')\n",
    "    embedded_sequences = embedding_layer(sequence_input)\n",
    "\n",
    "    #x = GaussianNoise(hyperparameters['gauss_stddev'])(embedded_sequences)\n",
    "    x = embedded_sequences\n",
    "    x = Conv1D(2*hyperparameters['conv_units'], 5, activation='relu')(x)\n",
    "    x = MaxPooling1D(5)(x)\n",
    "    x = Conv1D(hyperparameters['conv_units'], 5, activation='relu')(x)\n",
    "    x = MaxPooling1D(5)(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(hyperparameters['hidden_units_1'], activation='relu')(x)\n",
    "    x = Dropout(hyperparameters['dropout'])(x)\n",
    "    x = Dense(hyperparameters['hidden_units_2'], activation='relu')(x)\n",
    "    preds = Dense(hyperparameters['nclasses'], activation='softmax')(x)\n",
    "\n",
    "    model_cnn = Model(sequence_input, preds)\n",
    "    model_cnn.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=[metrics.categorical_accuracy])\n",
    "\n",
    "    \n",
    "    X_train, X_test = X_sequences_padded[train_index], X_sequences_padded[test_index]\n",
    "    y_train, y_test = y_matrix[train_index], y_matrix[test_index]\n",
    "\n",
    "    # train\n",
    "    model_cnn.fit(X_train, y_train,\n",
    "              batch_size=128,\n",
    "              epochs=hyperparameters['epochs'],\n",
    "              class_weight=class_weight,\n",
    "              validation_data=(X_test, y_test))\n",
    "\n",
    "    # run\n",
    "    ground_truth = y_test.argmax(1)\n",
    "    predictions = [list(map(lambda x: x, model_cnn.predict_on_batch(np.asarray([x])).argmax(1)))[0] \\\n",
    "            for x in X_test]\n",
    "    \n",
    "    \n",
    "    acc = evaluation.accuracy(ground_truth, predictions)\n",
    "    f1 = evaluation.eval_f1_score(ground_truth, predictions)    \n",
    "    cm = evaluation.cm_matrix(ground_truth, predictions)\n",
    "    acc_list.append(acc)\n",
    "    f1_list.append(f1)\n",
    "    cm_summed = cm_summed + cm\n",
    "    print(acc, f1)\n",
    "    print(cm)\n",
    "    \n",
    "print(np.asarray(acc).mean(), np.asarray(f1).mean())\n",
    "print(cm_summed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ground_truth = y_test.argmax(1)\n",
    "predictions = [list(map(lambda x: x, model_cnn.predict_on_batch(np.asarray([x]))))[0] \\\n",
    "        for x in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.6073619631901841, 0.55845915827602488, 225, 489)\n",
      "(46.012269938650306, '% - ', 23)\n",
      "\n",
      "\n",
      "Rejected 30.12% of wrong ones\n",
      "Accepted 41.13% of good ones\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  9.99953508e-01,   4.64564946e-05],\n",
       "       [  1.00000000e+00,   1.67152194e-08],\n",
       "       [  9.99977708e-01,   2.23164752e-05],\n",
       "       [  9.99998808e-01,   1.22565393e-06],\n",
       "       [  9.99924541e-01,   7.54324938e-05]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "y_predicted_proba_np = np.asarray(predictions)\n",
    "#y_predicted = (y_predicted_proba_np[:,1] > 0.001)\n",
    "y_predicted = (y_predicted_proba_np[:,1] > 0.001)\n",
    "\n",
    "acc = accuracy_score(y_predicted, ground_truth)\n",
    "f1 = f1_score(y_predicted, ground_truth, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected %.2f%% of wrong ones\" % (len(X_test_df[(y_predicted == y_test[:,0]) & (y_predicted == False)])*100.0/(len(y_test)-sum(y_test)[0])))\n",
    "print(\"Accepted %.2f%% of good ones\" % (len(X_test_df[(y_predicted == y_test[:,0]) & (y_predicted == True)])*100.0/sum(y_test)[0]))\n",
    "\n",
    "# 15% bezbolesnie odrzucic - 0.000008\n",
    "\n",
    "y_predicted_proba_np[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hyperparameters_lstm = {\n",
    "    'conv_units': 128,\n",
    "    'hidden_units_1': 128,\n",
    "    'hidden_units_2': 64,\n",
    "    'dropout': 0.5,\n",
    "    'pooling' : 5,\n",
    "    'gauss_stddev' : 0.0002,\n",
    "    'epochs' : 15,\n",
    "    'folds' : 5,\n",
    "    'nclasses' : 2,\n",
    "    'max_seq_len' : 300,\n",
    "    'learning_rate' : 0.001,\n",
    "    'stopwords' : True\n",
    "}\n",
    "\n",
    "hyperparameters_lstm = {\n",
    "    'conv_units': 64,\n",
    "    'hidden_units_1': 64,\n",
    "    'hidden_units_2': 0,\n",
    "    'dropout': 0.5,\n",
    "    'pooling' : 5,\n",
    "    'gauss_stddev' : 0.0002,\n",
    "    'epochs' : 2,\n",
    "    'folds' : 5,\n",
    "    'nclasses' : 2,\n",
    "    'max_seq_len' : 300,\n",
    "    'learning_rate' : 0.001,\n",
    "    'stopwords' : True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW BEST: epoch 0 valid F1 =  0.770985603544 in 88.6433889866 (sec)                               \n",
      "[learning] epoch 1 >> 0.05% completed in 0.04 (sec)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/piotr.bednarski/ml-env-27-gpu/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.84285714285714286, 0.77098560354374301) 82.40 (sec)\n",
      "[[413   0]\n",
      " [ 77   0]]\n",
      "NEW BEST: epoch 0 valid F1 =  0.782094476268 in 88.783285141 (sec)                               \n",
      "(0.8507157464212679, 0.78209447626795003)n 82.70 (sec)\n",
      "[[416   0]\n",
      " [ 73   0]]\n",
      "NEW BEST: epoch 0 valid F1 =  0.799516924479 in 88.6081900597 (sec)                               \n",
      "(0.86298568507157469, 0.79951692447904399) 82.62 (sec)\n",
      "[[422   0]\n",
      " [ 67   0]]\n",
      "NEW BEST: epoch 0 valid F1 =  0.793699001802 in 90.2043309212 (sec)                               \n",
      "(0.85889570552147243, 0.7936990018020208)n 84.06 (sec)\n",
      "[[420   0]\n",
      " [ 69   0]]\n",
      "[learning] epoch 0 >> 77.77% completed in 67.58 (sec)\r"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "import utils.evaluation as evaluation\n",
    "from keras import metrics\n",
    "import time\n",
    "import sys\n",
    "\n",
    "hyperparameters = hyperparameters_lstm\n",
    "class_weight = {0 : 1.,\n",
    "    1: (len(y)-sum(y))/sum(y)}\n",
    "\n",
    "acc_list = []\n",
    "f1_list = []\n",
    "cm_summed = np.zeros((2,2))\n",
    "kf = KFold(n_splits=5, shuffle = True)\n",
    "for train_index, test_index in kf.split(X_sequences):\n",
    "    K.clear_session()\n",
    "\n",
    "    num_words = embedding_matrix.shape[0]\n",
    "    embedding_dim = embedding_matrix.shape[1]\n",
    "    \n",
    "    model_lstm = Sequential()\n",
    "    model_lstm.add(Embedding(num_words,\n",
    "                                embedding_dim,\n",
    "                                weights=[embedding_matrix],\n",
    "                                trainable=False))\n",
    "\n",
    "    model_lstm.add(Bidirectional(LSTM(hyperparameters['conv_units'], activation='sigmoid', return_sequences=False)))\n",
    "    model_lstm.add(GaussianNoise(hyperparameters['gauss_stddev']))\n",
    "    model_lstm.add(Dropout(hyperparameters['dropout']))\n",
    "    model_lstm.add(Dense(units=hyperparameters['hidden_units_1']))\n",
    "    if hyperparameters['hidden_units_2'] > 0:\n",
    "        model_lstm.add(Dense(units=hyperparameters['hidden_units_2']))\n",
    "    model_lstm.add(Dense(units=hyperparameters['nclasses']))\n",
    "    model_lstm.add(Activation(\"softmax\"))\n",
    "\n",
    "    optimizer = RMSprop(lr=hyperparameters['learning_rate'])\n",
    "    model_lstm.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  #optimizer='adadelta',\n",
    "                  metrics=['acc'])\n",
    "\n",
    "    #print(model.summary())\n",
    "    \n",
    "    X_train, X_test = np.asarray(X_sequences)[train_index], np.asarray(X_sequences)[test_index]\n",
    "    y_train, y_test = y_matrix[train_index], y_matrix[test_index]\n",
    "\n",
    "    # train\n",
    "    nsentences = len(X_train)\n",
    "    best_f1 = -np.inf\n",
    "    for epoch in xrange(hyperparameters['epochs']):\n",
    "        # Shuffle datasets\n",
    "        #shuffle([x_train, y_train], 42)\n",
    "        tic = time.time()\n",
    "        for i in xrange(nsentences):\n",
    "            X_lstm = np.asarray([X_train[i]])\n",
    "            Y_lstm = y_train[i].reshape((1,hyperparameters['nclasses']))\n",
    "            if X_lstm.shape[1] == 1:\n",
    "                continue # Bug with X, Y of len 1\n",
    "            model_lstm.train_on_batch(X_lstm, Y_lstm)\n",
    "            print '[learning] epoch %i >> %2.2f%%'%(epoch,(i+1)*100./nsentences)+\\\n",
    "                    ' completed in %.2f (sec)\\r'%(time.time()-tic),\n",
    "            sys.stdout.flush()\n",
    "\n",
    "        # Evaluation // back into the real world : idx -> words\n",
    "        predictions = [map(lambda x: x, model_lstm.predict_on_batch(np.asarray([x])).argmax(1))[0] \\\n",
    "            for x in X_test]\n",
    "        ground_truth = y_test.argmax(1)\n",
    "\n",
    "        f1_valid = evaluation.eval_f1_score(ground_truth, predictions)\n",
    "\n",
    "        if f1_valid > best_f1:\n",
    "            best_f1 = f1_valid\n",
    "            model_lstm.save_weights('best_model_lstm.h5', overwrite=True)\n",
    "            print 'NEW BEST: epoch', epoch, 'valid F1 = ', f1_valid, 'in', str(time.time()-tic), '(sec)',' '*30\n",
    "\n",
    "        # load best performing model\n",
    "        model_lstm.load_weights('best_model_lstm.h5')\n",
    "\n",
    "    # eval\n",
    "    ground_truth = y_test.argmax(1)\n",
    "    predictions = [list(map(lambda x: x, model_lstm.predict_on_batch(np.asarray([x])).argmax(1)))[0] \\\n",
    "            for x in X_test]\n",
    "    \n",
    "    \n",
    "    acc = evaluation.accuracy(ground_truth, predictions)\n",
    "    f1 = evaluation.eval_f1_score(ground_truth, predictions)    \n",
    "    cm = evaluation.cm_matrix(ground_truth, predictions)\n",
    "    acc_list.append(acc)\n",
    "    f1_list.append(f1)\n",
    "    cm_summed = cm_summed + cm\n",
    "    print(acc, f1)\n",
    "    print(cm)\n",
    "    \n",
    "    #break\n",
    "    #del model\n",
    "    #K.clear_session()\n",
    "    \n",
    "print(np.asarray(acc).mean(), np.asarray(f1).mean())\n",
    "print(cm_summed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ground_truth = y_test.argmax(1)\n",
    "predictions = [list(map(lambda x: x, model_lstm.predict_on_batch(np.asarray([x]))))[0] \\\n",
    "        for x in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predicted_proba_np = np.asarray(predictions)\n",
    "#y_predicted = (y_predicted_proba_np[:,1] > 0.001)\n",
    "y_predicted = (y_predicted_proba_np[:,1] > 0.4791)\n",
    "\n",
    "acc = accuracy_score(y_predicted, ground_truth)\n",
    "f1 = f1_score(y_predicted, ground_truth, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "\n",
    "print(\"Rejected %.2f%% of wrong ones\" % (len(X_test_df[(y_predicted == y_test[:,0]) & (y_predicted == False)])*100.0/(len(y_test)-sum(y_test)[0])))\n",
    "print(\"Accepted %.2f%% of good ones\" % (len(X_test_df[(y_predicted == y_test[:,0]) & (y_predicted == True)])*100.0/sum(y_test)[0]))\n",
    "\n",
    "# 15% bezbolesnie odrzucic - 0.000008\n",
    "\n",
    "y_predicted_proba_np[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building an ensembler - Without data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "XE = X[limit:]\n",
    "yE = y[limit:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "XE_intermediate = np.column_stack((\n",
    "        model_svc.predict_proba(XE)[:,1],\n",
    "        model_svc_tfidf.predict_proba(XE)[:,1],\n",
    "    \n",
    "        model_nb.predict_proba(XE)[:,1],\n",
    "        model_nb_tfidf.predict_proba(XE)[:,1],\n",
    "\n",
    "        etree_w2v.predict_proba(XE)[:,1],\n",
    "        etree_w2v_tfidf.predict_proba(XE)[:,1],\n",
    "\n",
    "        svc_w2v.predict_proba(XE)[:,1],\n",
    "        svc_w2v_tfidf.predict_proba(XE)[:,1],\n",
    "\n",
    "        etree_w2v_custom.predict_proba(XE)[:,1],\n",
    "        etree_w2v_tfidf_custom.predict_proba(XE)[:,1],\n",
    "\n",
    "        svc_w2v_custom.predict_proba(XE)[:,1],\n",
    "        svc_w2v_tfidf_custom.predict_proba(XE)[:,1],\n",
    "\n",
    "        logistic_w2v.predict_proba(XE)[:,1],\n",
    "        logistic_w2v_tfidf.predict_proba(XE)[:,1],\n",
    "\n",
    "        sgd_w2v.predict_proba(XE)[:,1],\n",
    "        sgd_w2v_tfidf.predict_proba(XE)[:,1]\n",
    "    ))\n",
    "XE_intermediate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "limitE = int(0.8*len(XE_intermediate))\n",
    "print(limitE)\n",
    "\n",
    "X_train = XE_intermediate[:limitE]\n",
    "X_test = XE_intermediate[limitE:]\n",
    "\n",
    "y_train = yE[:limitE]\n",
    "y_test = yE[limitE:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "logi = LogisticRegression()\n",
    "logi.fit(X_train, y_train)\n",
    "\n",
    "y_predicted = logi.predict(X_test)\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "\n",
    "y_predicted_proba = logi.predict_proba(X_test)\n",
    "y_predicted = (y_predicted_proba[:,1] > np.median(y_predicted_proba[:,1]))\n",
    "\n",
    "acc = accuracy_score(y_predicted, y_test)\n",
    "f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "print(\"\\n\")\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "print(\"Rejected %.2f%% of wrong ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == False)])*100.0/(len(y_test)-sum(y_test))))\n",
    "print(\"Accepted %.2f%% of good ones\" % (len(X_test_df[(y_predicted == y_test) & (y_predicted == True)])*100.0/sum(y_test)))\n",
    "print(\"Median: %.3f\" % np.median(y_predicted_proba[:,1]))\n",
    "\n",
    "y_predicted_proba[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best ratings:\n",
    "Rejected 53.94% of wrong ones\n",
    "\n",
    "Accepted 77.05% of good ones\n",
    "\n",
    "Median: 0.043"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "max_rej = 53.0\n",
    "max_acc = 75.0\n",
    "\n",
    "XE_intermediate_full = np.column_stack((\n",
    "        model_svc.predict_proba(XE)[:,1],\n",
    "        model_svc_tfidf.predict_proba(XE)[:,1],\n",
    "\n",
    "        model_nb.predict_proba(XE)[:,1],\n",
    "        model_nb_tfidf.predict_proba(XE)[:,1],\n",
    "\n",
    "        etree_w2v.predict_proba(XE)[:,1],\n",
    "        etree_w2v_tfidf.predict_proba(XE)[:,1],\n",
    "\n",
    "        svc_w2v.predict_proba(XE)[:,1],\n",
    "        svc_w2v_tfidf.predict_proba(XE)[:,1],\n",
    "\n",
    "        etree_w2v_custom.predict_proba(XE)[:,1],\n",
    "        etree_w2v_tfidf_custom.predict_proba(XE)[:,1],\n",
    "\n",
    "        svc_w2v_custom.predict_proba(XE)[:,1],\n",
    "        svc_w2v_tfidf_custom.predict_proba(XE)[:,1],\n",
    "\n",
    "        logistic_w2v.predict_proba(XE)[:,1],\n",
    "        logistic_w2v_tfidf.predict_proba(XE)[:,1],\n",
    "\n",
    "        sgd_w2v.predict_proba(XE)[:,1],\n",
    "        sgd_w2v_tfidf.predict_proba(XE)[:,1]\n",
    "    ))\n",
    "\n",
    "while(True):\n",
    "    rand_vect = np.random.rand(18) > 0.25\n",
    "    XE_intermediate = XE_intermediate_full[~np.array(rand_vect)]\n",
    "\n",
    "\n",
    "    limitE = int(0.8*len(XE_intermediate))\n",
    "    #print(limitE)\n",
    "\n",
    "    X_train = XE_intermediate[:limitE]\n",
    "    X_test = XE_intermediate[limitE:]\n",
    "\n",
    "    y_train = yE[:limitE]\n",
    "    y_test = yE[limitE:]\n",
    "\n",
    "    from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "    from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "    logi = LogisticRegression()\n",
    "    logi.fit(X_train, y_train)\n",
    "\n",
    "    y_predicted = logi.predict(X_test)\n",
    "    acc = accuracy_score(y_predicted, y_test)\n",
    "    f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "\n",
    "    y_predicted_proba = logi.predict_proba(X_test)\n",
    "    y_predicted = (y_predicted_proba[:,1] > np.median(y_predicted_proba[:,1]))\n",
    "\n",
    "    acc = accuracy_score(y_predicted, y_test)\n",
    "    f1 = f1_score(y_predicted, y_test, average='weighted')\n",
    "    #print(acc, f1, sum(y_predicted), len(y_predicted))\n",
    "    #print(sum(y_predicted)*100.0/len(y_predicted),\"% - \", int(sum(y_predicted)*50.0/len(y_predicted)))\n",
    "    #print(\"\\n\")\n",
    "    \n",
    "    rej = len(X_test_df[(y_predicted == y_test) & (y_predicted == False)])*100.0/(len(y_test)-sum(y_test))\n",
    "    acc = len(X_test_df[(y_predicted == y_test) & (y_predicted == True)])*100.0/sum(y_test)\n",
    "    \n",
    "    X_test_df = pd.DataFrame(X_test)\n",
    "    if (rej > max_rej and acc > max_acc):\n",
    "        max_rej = rej\n",
    "        max_acc = acc\n",
    "        print(rand_vect)\n",
    "        print(\"Rejected %.2f%% of wrong ones\" % rej)\n",
    "        print(\"Accepted %.2f%% of good ones\" % acc)\n",
    "        print(\"Median: %.3f\\n\\n\" % np.median(y_predicted_proba[:,1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
