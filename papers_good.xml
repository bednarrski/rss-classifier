<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Good papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Good Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-02-14T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04924"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.10451"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04818"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04821"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04942"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05219"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1607.08723"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1707.06203"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.05706"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.00694"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.09547"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04009"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04865"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04868"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04874"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04889"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05196"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1706.01566"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1707.08561"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.01768"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.02029"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.04432"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04431"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.00497"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1802.04924">
<title>Exploring Hidden Dimensions in Parallelizing Convolutional Neural Networks. (arXiv:1802.04924v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.04924</link>
<description rdf:parseType="Literal">&lt;p&gt;The past few years have witnessed growth in the size and computational
requirements for training deep convolutional neural networks. Current
approaches parallelize the training process onto multiple devices by applying a
single parallelization strategy (e.g., data or model parallelism) to all layers
in a network. Although easy to reason about, this design results in suboptimal
runtime performance in large-scale distributed training, since different layers
in a network may prefer different parallelization strategies. In this paper, we
propose layer-wise parallelism that allows each layer in a network to use an
individual parallelization strategy. We jointly optimize how each layer is
parallelized by solving a graph search problem. Our experiments show that
layer-wise parallelism outperforms current parallelization approaches by
increasing training speed, reducing communication costs, achieving better
scalability to multiple GPUs, while maintaining the same network accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jia_Z/0/1/0/all/0/1&quot;&gt;Zhihao Jia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_S/0/1/0/all/0/1&quot;&gt;Sina Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qi_C/0/1/0/all/0/1&quot;&gt;Charles R. Qi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aiken_A/0/1/0/all/0/1&quot;&gt;Alex Aiken&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.10451">
<title>Sample-level CNN Architectures for Music Auto-tagging Using Raw Waveforms. (arXiv:1710.10451v2 [cs.SD] UPDATED)</title>
<link>http://arxiv.org/abs/1710.10451</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent work has shown that the end-to-end approach using convolutional neural
network (CNN) is effective in various types of machine learning tasks. For
audio signals, the approach takes raw waveforms as input using an 1-D
convolution layer. In this paper, we improve the 1-D CNN architecture for music
auto-tagging by adopting building blocks from state-of-the-art image
classification models, ResNets and SENets, and adding multi-level feature
aggregation to it. We compare different combinations of the modules in building
CNN architectures. The results show that they achieve significant improvements
over previous state-of-the-art models on the MagnaTagATune dataset and
comparable results on Million Song Dataset. Furthermore, we analyze and
visualize our model to show how the 1-D CNN operates.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_T/0/1/0/all/0/1&quot;&gt;Taejun Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1&quot;&gt;Jongpil Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nam_J/0/1/0/all/0/1&quot;&gt;Juhan Nam&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04818">
<title>Story Generation and Aviation Incident Representation. (arXiv:1802.04818v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.04818</link>
<description rdf:parseType="Literal">&lt;p&gt;This working note discusses the topic of story generation, with a view to
identifying the knowledge required to understand aviation incident narratives
(which have structural similarities to stories), following the premise that to
understand aviation incidents, one should at least be able to generate examples
of them. We give a brief overview of aviation incidents and their relation to
stories, and then describe two of our earlier attempts (using `scripts&apos; and
`story grammars&apos;) at incident generation which did not evolve promisingly.
Following this, we describe a simple incident generator which did work (at a
`toy&apos; level), using a `world simulation&apos; approach. This generator is based on
Meehan&apos;s TALE-SPIN story generator (1977). We conclude with a critique of the
approach.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Clark_P/0/1/0/all/0/1&quot;&gt;Peter Clark&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04821">
<title>Evolved Policy Gradients. (arXiv:1802.04821v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.04821</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a meta-learning approach for learning gradient-based reinforcement
learning (RL) algorithms. The idea is to evolve a differentiable loss function,
such that an agent, which optimizes its policy to minimize this loss, will
achieve high rewards. The loss is parametrized via temporal convolutions over
the agent&apos;s experience. Because this loss is highly flexible in its ability to
take into account the agent&apos;s history, it enables fast task learning and
eliminates the need for reward shaping at test time. Empirical results show
that our evolved policy gradient algorithm achieves faster learning on several
randomized environments compared to an off-the-shelf policy gradient method.
Moreover, at test time, our learner optimizes only its learned loss function,
and requires no explicit reward signal. In effect, the agent internalizes the
reward structure, suggesting a direction toward agents that learn to solve new
tasks simply from intrinsic motivation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Houthooft_R/0/1/0/all/0/1&quot;&gt;Rein Houthooft&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_R/0/1/0/all/0/1&quot;&gt;Richard Y. Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Isola_P/0/1/0/all/0/1&quot;&gt;Phillip Isola&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stadie_B/0/1/0/all/0/1&quot;&gt;Bradly C. Stadie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wolski_F/0/1/0/all/0/1&quot;&gt;Filip Wolski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ho_J/0/1/0/all/0/1&quot;&gt;Jonathan Ho&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1&quot;&gt;Pieter Abbeel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04942">
<title>Isolating Sources of Disentanglement in Variational Autoencoders. (arXiv:1802.04942v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.04942</link>
<description rdf:parseType="Literal">&lt;p&gt;We decompose the evidence lower bound to show the existence of a term
measuring the total correlation between latent variables. We use this to
motivate our $\beta$-TCVAE (Total Correlation Variational Autoencoder), a
refinement of the state-of-the-art $\beta$-VAE objective for learning
disentangled representations, requiring no additional hyperparameters during
training. We further propose a principled classifier-free measure of
disentanglement called the mutual information gap (MIG). We perform extensive
quantitative and qualitative experiments, in both restricted and non-restricted
settings, and show a strong relation between total correlation and
disentanglement, when the latent variables model is trained using our
framework.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1&quot;&gt;Tian Qi Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xuechen Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grosse_R/0/1/0/all/0/1&quot;&gt;Roger Grosse&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Duvenaud_D/0/1/0/all/0/1&quot;&gt;David Duvenaud&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05219">
<title>Who Killed Albert Einstein? From Open Data to Murder Mystery Games. (arXiv:1802.05219v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.05219</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents a framework for generating adventure games from open
data. Focusing on the murder mystery type of adventure games, the generator is
able to transform open data from Wikipedia articles, OpenStreetMap and images
from Wikimedia Commons into WikiMysteries. Every WikiMystery game revolves
around the murder of a person with a Wikipedia article and populates the game
with suspects who must be arrested by the player if guilty of the murder or
absolved if innocent. Starting from only one person as the victim, an extensive
generative pipeline finds suspects, their alibis, and paths connecting them
from open data, transforms open data into cities, buildings, non-player
characters, locks and keys and dialog options. The paper describes in detail
each generative step, provides a specific playthrough of one WikiMystery where
Albert Einstein is murdered, and evaluates the outcomes of games generated for
the 100 most influential people of the 20th century.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barros_G/0/1/0/all/0/1&quot;&gt;Gabriella A. B. Barros&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Green_M/0/1/0/all/0/1&quot;&gt;Michael Cerny Green&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liapis_A/0/1/0/all/0/1&quot;&gt;Antonios Liapis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Togelius_J/0/1/0/all/0/1&quot;&gt;Julian Togelius&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1607.08723">
<title>Cognitive Science in the era of Artificial Intelligence: A roadmap for reverse-engineering the infant language-learner. (arXiv:1607.08723v4 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1607.08723</link>
<description rdf:parseType="Literal">&lt;p&gt;During their first years of life, infants learn the language(s) of their
environment at an amazing speed despite large cross cultural variations in
amount and complexity of the available language input. Understanding this
simple fact still escapes current cognitive and linguistic theories. Recently,
spectacular progress in the engineering science, notably, machine learning and
wearable technology, offer the promise of revolutionizing the study of
cognitive development. Machine learning offers powerful learning algorithms
that can achieve human-like performance on many linguistic tasks. Wearable
sensors can capture vast amounts of data, which enable the reconstruction of
the sensory experience of infants in their natural environment. The project of
&apos;reverse engineering&apos; language development, i.e., of building an effective
system that mimics infant&apos;s achievements appears therefore to be within reach.
Here, we analyze the conditions under which such a project can contribute to
our scientific understanding of early language development. We argue that
instead of defining a sub-problem or simplifying the data, computational models
should address the full complexity of the learning situation, and take as input
the raw sensory signals available to infants. This implies that (1) accessible
but privacy-preserving repositories of home data be setup and widely shared,
and (2) models be evaluated at different linguistic levels through a benchmark
of psycholinguist tests that can be passed by machines and humans alike, (3)
linguistically and psychologically plausible learning architectures be scaled
up to real data using probabilistic/optimization principles from machine
learning. We discuss the feasibility of this approach and present preliminary
results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dupoux_E/0/1/0/all/0/1&quot;&gt;Emmanuel Dupoux&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1707.06203">
<title>Imagination-Augmented Agents for Deep Reinforcement Learning. (arXiv:1707.06203v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1707.06203</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce Imagination-Augmented Agents (I2As), a novel architecture for
deep reinforcement learning combining model-free and model-based aspects. In
contrast to most existing model-based reinforcement learning and planning
methods, which prescribe how a model should be used to arrive at a policy, I2As
learn to interpret predictions from a learned environment model to construct
implicit plans in arbitrary ways, by using the predictions as additional
context in deep policy networks. I2As show improved data efficiency,
performance, and robustness to model misspecification compared to several
baselines.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Weber_T/0/1/0/all/0/1&quot;&gt;Th&amp;#xe9;ophane Weber&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Racaniere_S/0/1/0/all/0/1&quot;&gt;S&amp;#xe9;bastien Racani&amp;#xe8;re&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Reichert_D/0/1/0/all/0/1&quot;&gt;David P. Reichert&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Buesing_L/0/1/0/all/0/1&quot;&gt;Lars Buesing&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guez_A/0/1/0/all/0/1&quot;&gt;Arthur Guez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rezende_D/0/1/0/all/0/1&quot;&gt;Danilo Jimenez Rezende&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Badia_A/0/1/0/all/0/1&quot;&gt;Adria Puigdom&amp;#xe8;nech Badia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vinyals_O/0/1/0/all/0/1&quot;&gt;Oriol Vinyals&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Heess_N/0/1/0/all/0/1&quot;&gt;Nicolas Heess&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yujia Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pascanu_R/0/1/0/all/0/1&quot;&gt;Razvan Pascanu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Battaglia_P/0/1/0/all/0/1&quot;&gt;Peter Battaglia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hassabis_D/0/1/0/all/0/1&quot;&gt;Demis Hassabis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Silver_D/0/1/0/all/0/1&quot;&gt;David Silver&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wierstra_D/0/1/0/all/0/1&quot;&gt;Daan Wierstra&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.05706">
<title>Memory Augmented Control Networks. (arXiv:1709.05706v6 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1709.05706</link>
<description rdf:parseType="Literal">&lt;p&gt;Planning problems in partially observable environments cannot be solved
directly with convolutional networks and require some form of memory. But, even
memory networks with sophisticated addressing schemes are unable to learn
intelligent reasoning satisfactorily due to the complexity of simultaneously
learning to access memory and plan. To mitigate these challenges we introduce
the Memory Augmented Control Network (MACN). The proposed network architecture
consists of three main parts. The first part uses convolutions to extract
features and the second part uses a neural network-based planning module to
pre-plan in the environment. The third part uses a network controller that
learns to store those specific instances of past information that are necessary
for planning. The performance of the network is evaluated in discrete grid
world environments for path planning in the presence of simple and complex
obstacles. We show that our network learns to plan and can generalize to new
environments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khan_A/0/1/0/all/0/1&quot;&gt;Arbaaz Khan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1&quot;&gt;Clark Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Atanasov_N/0/1/0/all/0/1&quot;&gt;Nikolay Atanasov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Karydis_K/0/1/0/all/0/1&quot;&gt;Konstantinos Karydis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kumar_V/0/1/0/all/0/1&quot;&gt;Vijay Kumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1&quot;&gt;Daniel D. Lee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.00694">
<title>Interpretable and Pedagogical Examples. (arXiv:1711.00694v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1711.00694</link>
<description rdf:parseType="Literal">&lt;p&gt;Teachers intentionally pick the most informative examples to show their
students. However, if the teacher and student are neural networks, the examples
that the teacher network learns to give, although effective at teaching the
student, are typically uninterpretable. We show that training the student and
teacher iteratively, rather than jointly, can produce interpretable teaching
strategies. We evaluate interpretability by (1) measuring the similarity of the
teacher&apos;s emergent strategies to intuitive strategies in each domain and (2)
conducting human experiments to evaluate how effective the teacher&apos;s strategies
are at teaching humans. We show that the teacher network learns to select or
generate interpretable, pedagogical examples to teach rule-based,
probabilistic, boolean, and hierarchical concepts.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Milli_S/0/1/0/all/0/1&quot;&gt;Smitha Milli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1&quot;&gt;Pieter Abbeel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mordatch_I/0/1/0/all/0/1&quot;&gt;Igor Mordatch&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.09547">
<title>An Improved Tabu Search Heuristic for Static Dial-A-Ride Problem. (arXiv:1801.09547v5 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1801.09547</link>
<description rdf:parseType="Literal">&lt;p&gt;Multi-vehicle routing has become increasingly important with the rapid
development of autonomous vehicle technology. Dial-a-ride problem, a variant of
vehicle routing problem (VRP), deals with the allocation of customer requests
to vehicles, scheduling the pick-up and drop-off times and the sequence of
serving those requests by ensuring high customer satisfaction with minimized
travel cost. In this paper, we propose an improved tabu search (ITS) heuristic
for static dial-a-ride problem (DARP) with the objective of obtaining
high-quality solutions in short time. Two new techniques, initialization
heuristic, and time window adjustment are proposed to achieve faster
convergence to the global optimum. Various numerical experiments are conducted
for the proposed solution methodology using DARP test instances from the
literature and the convergence speed up is validated.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ho_S/0/1/0/all/0/1&quot;&gt;Songguang Ho&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nagavarapu_S/0/1/0/all/0/1&quot;&gt;Sarat Chandra Nagavarapu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pandi_R/0/1/0/all/0/1&quot;&gt;Ramesh Ramasamy Pandi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dauwels_J/0/1/0/all/0/1&quot;&gt;Justin Dauwels&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04009">
<title>Distinguishing Question Subjectivity from Difficulty for Improved Crowdsourcing. (arXiv:1802.04009v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1802.04009</link>
<description rdf:parseType="Literal">&lt;p&gt;The questions in a crowdsourcing task typically exhibit varying degrees of
difficulty and subjectivity. Their joint effects give rise to the variation in
responses to the same question by different crowd-workers. This variation is
low when the question is easy to answer and objective, and high when it is
difficult and subjective. Unfortunately, current quality control methods for
crowdsourcing consider only the question difficulty to account for the
variation. As a result,these methods cannot distinguish workers personal
preferences for different correct answers of a partially subjective question
from their ability/expertise to avoid objectively wrong answers for that
question. To address this issue, we present a probabilistic model which (i)
explicitly encodes question difficulty as a model parameter and (ii) implicitly
encodes question subjectivity via latent preference factors for crowd-workers.
We show that question subjectivity induces grouping of crowd-workers, revealed
through clustering of their latent preferences. Moreover, we develop a
quantitative measure of the subjectivity of a question. Experiments show that
our model(1) improves the performance of both quality control for crowd-sourced
answers and next answer prediction for crowd-workers,and (2) can potentially
provide coherent rankings of questions in terms of their difficulty and
subjectivity, so that task providers can refine their designs of the
crowdsourcing tasks, e.g. by removing highly subjective questions or
inappropriately difficult questions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jin_Y/0/1/0/all/0/1&quot;&gt;Yuan Jin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Carman_M/0/1/0/all/0/1&quot;&gt;Mark Carman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1&quot;&gt;Ye Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Buntine_W/0/1/0/all/0/1&quot;&gt;Wray Buntine&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04865">
<title>Learning Confidence for Out-of-Distribution Detection in Neural Networks. (arXiv:1802.04865v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.04865</link>
<description rdf:parseType="Literal">&lt;p&gt;Modern neural networks are very powerful predictive models, but they are
often incapable of recognizing when their predictions may be wrong. Closely
related to this is the task of out-of-distribution detection, where a network
must determine whether or not an input is outside of the set on which it is
expected to safely perform. To jointly address these issues, we propose a
method of learning confidence estimates for neural networks that is simple to
implement and produces intuitively interpretable outputs. We demonstrate that
on the task of out-of-distribution detection, our technique surpasses recently
proposed techniques which construct confidence based on the network&apos;s output
distribution, without requiring any additional labels or access to
out-of-distribution examples. Additionally, we address the problem of
calibrating out-of-distribution detectors, where we demonstrate that
misclassified in-distribution examples can be used as a proxy for
out-of-distribution examples.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+DeVries_T/0/1/0/all/0/1&quot;&gt;Terrance DeVries&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Taylor_G/0/1/0/all/0/1&quot;&gt;Graham W. Taylor&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04868">
<title>SimplE Embedding for Link Prediction in Knowledge Graphs. (arXiv:1802.04868v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.04868</link>
<description rdf:parseType="Literal">&lt;p&gt;The aim of knowledge graphs is to gather knowledge about the world and
provide a structured representation of this knowledge. Current knowledge graphs
are far from complete. To address the incompleteness of the knowledge graphs,
link prediction approaches have been developed which make probabilistic
predictions about new links in a knowledge graph given the existing links.
Tensor factorization approaches have proven promising for such link prediction
problems. In this paper, we develop a simple tensor factorization model called
SimplE, through a slight modification of the Polyadic Decomposition model from
1927. The complexity of SimplE grows linearly with the size of embeddings. The
embeddings learned through SimplE are interpretable, and certain types of
expert knowledge in terms of logical rules can be incorporated into these
embeddings through weight tying. We prove SimplE is fully-expressive and derive
a bound on the size of its embeddings for full expressivity. We show
empirically that, despite its simplicity, SimplE outperforms several
state-of-the-art tensor factorization techniques.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kazemi_S/0/1/0/all/0/1&quot;&gt;Seyed Mehran Kazemi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Poole_D/0/1/0/all/0/1&quot;&gt;David Poole&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04874">
<title>GILBO: One Metric to Measure Them All. (arXiv:1802.04874v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.04874</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a simple, tractable lower bound on the mutual information
contained in the joint generative density of any latent variable generative
model: the GILBO (Generative Information Lower BOund). It offers a data
independent measure of the complexity of the learned latent variable
description, giving the log of the effective description length. It is
well-defined for both VAEs and GANs. We compute the GILBO for 800 GANs and VAEs
trained on MNIST and discuss the results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Alemi_A/0/1/0/all/0/1&quot;&gt;Alexander A. Alemi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Fischer_I/0/1/0/all/0/1&quot;&gt;Ian Fischer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04889">
<title>Understanding Membership Inferences on Well-Generalized Learning Models. (arXiv:1802.04889v1 [cs.CR])</title>
<link>http://arxiv.org/abs/1802.04889</link>
<description rdf:parseType="Literal">&lt;p&gt;Membership Inference Attack (MIA) determines the presence of a record in a
machine learning model&apos;s training data by querying the model. Prior work has
shown that the attack is feasible when the model is overfitted to its training
data or when the adversary controls the training algorithm. However, when the
model is not overfitted and the adversary does not control the training
algorithm, the threat is not well understood. In this paper, we report a study
that discovers overfitting to be a sufficient but not a necessary condition for
an MIA to succeed. More specifically, we demonstrate that even a
well-generalized model contains vulnerable instances subject to a new
generalized MIA (GMIA). In GMIA, we use novel techniques for selecting
vulnerable instances and detecting their subtle influences ignored by
overfitting metrics. Specifically, we successfully identify individual records
with high precision in real-world datasets by querying black-box machine
learning models. Further we show that a vulnerable record can even be
indirectly attacked by querying other related records and existing
generalization techniques are found to be less effective in protecting the
vulnerable instances. Our findings sharpen the understanding of the fundamental
cause of the problem: the unique influences the training instance may have on
the model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Long_Y/0/1/0/all/0/1&quot;&gt;Yunhui Long&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bindschaedler_V/0/1/0/all/0/1&quot;&gt;Vincent Bindschaedler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1&quot;&gt;Lei Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bu_D/0/1/0/all/0/1&quot;&gt;Diyue Bu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;Xiaofeng Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_H/0/1/0/all/0/1&quot;&gt;Haixu Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gunter_C/0/1/0/all/0/1&quot;&gt;Carl A. Gunter&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1&quot;&gt;Kai Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05196">
<title>Generative Models for Spear Phishing Posts on Social Media. (arXiv:1802.05196v1 [cs.CR])</title>
<link>http://arxiv.org/abs/1802.05196</link>
<description rdf:parseType="Literal">&lt;p&gt;Historically, machine learning in computer security has prioritized defense:
think intrusion detection systems, malware classification, and botnet traffic
identification. Offense can benefit from data just as well. Social networks,
with their access to extensive personal data, bot-friendly APIs, colloquial
syntax, and prevalence of shortened links, are the perfect venues for spreading
machine-generated malicious content. We aim to discover what capabilities an
adversary might utilize in such a domain. We present a long short-term memory
(LSTM) neural network that learns to socially engineer specific users into
clicking on deceptive URLs. The model is trained with word vector
representations of social media posts, and in order to make a click-through
more likely, it is dynamically seeded with topics extracted from the target&apos;s
timeline. We augment the model with clustering to triage high value targets
based on their level of social engagement, and measure success of the LSTM&apos;s
phishing expedition using click-rates of IP-tracked links. We achieve state of
the art success rates, tripling those of historic email attack campaigns, and
outperform humans manually performing the same task.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Seymour_J/0/1/0/all/0/1&quot;&gt;John Seymour&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tully_P/0/1/0/all/0/1&quot;&gt;Philip Tully&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1706.01566">
<title>Open Loop Hyperparameter Optimization and Determinantal Point Processes. (arXiv:1706.01566v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1706.01566</link>
<description rdf:parseType="Literal">&lt;p&gt;Driven by the need for parallelizable hyperparameter optimization methods,
this paper studies \emph{open loop} search methods: sequences that are
predetermined and can be generated before a single configuration is evaluated.
Examples include grid search, uniform random search, low discrepancy sequences,
and other sampling distributions. In particular, we propose the use of
$k$-determinantal point processes in hyperparameter optimization via random
search. Compared to conventional uniform random search where hyperparameter
settings are sampled independently, a $k$-DPP promotes diversity. We describe
an approach that transforms hyperparameter search spaces for efficient use with
a $k$-DPP. In addition, we introduce a novel Metropolis-Hastings algorithm
which can sample from $k$-DPPs defined over any space from which uniform
samples can be drawn, including spaces with a mixture of discrete and
continuous dimensions or tree structure. Our experiments show significant
benefits in realistic scenarios with a limited budget for training supervised
learners, whether in serial or parallel.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Dodge_J/0/1/0/all/0/1&quot;&gt;Jesse Dodge&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Jamieson_K/0/1/0/all/0/1&quot;&gt;Kevin Jamieson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Smith_N/0/1/0/all/0/1&quot;&gt;Noah A. Smith&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1707.08561">
<title>Quantum machine learning: a classical perspective. (arXiv:1707.08561v3 [quant-ph] UPDATED)</title>
<link>http://arxiv.org/abs/1707.08561</link>
<description rdf:parseType="Literal">&lt;p&gt;Recently, increased computational power and data availability, as well as
algorithmic advances, have led machine learning techniques to impressive
results in regression, classification, data-generation and reinforcement
learning tasks. Despite these successes, the proximity to the physical limits
of chip fabrication alongside the increasing size of datasets are motivating a
growing number of researchers to explore the possibility of harnessing the
power of quantum computation to speed-up classical machine learning algorithms.
Here we review the literature in quantum machine learning and discuss
perspectives for a mixed readership of classical machine learning and quantum
computation experts. Particular emphasis will be placed on clarifying the
limitations of quantum algorithms, how they compare with their best classical
counterparts and why quantum resources are expected to provide advantages for
learning problems. Learning in the presence of noise and certain
computationally hard problems in machine learning are identified as promising
directions for the field. Practical questions, like how to upload classical
data into quantum form, will also be addressed.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Ciliberto_C/0/1/0/all/0/1&quot;&gt;Carlo Ciliberto&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Herbster_M/0/1/0/all/0/1&quot;&gt;Mark Herbster&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Ialongo_A/0/1/0/all/0/1&quot;&gt;Alessandro Davide Ialongo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Pontil_M/0/1/0/all/0/1&quot;&gt;Massimiliano Pontil&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Rocchetto_A/0/1/0/all/0/1&quot;&gt;Andrea Rocchetto&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Severini_S/0/1/0/all/0/1&quot;&gt;Simone Severini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Wossnig_L/0/1/0/all/0/1&quot;&gt;Leonard Wossnig&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.01768">
<title>Towards Reverse-Engineering Black-Box Neural Networks. (arXiv:1711.01768v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1711.01768</link>
<description rdf:parseType="Literal">&lt;p&gt;Many deployed learned models are black boxes: given input, returns output.
Internal information about the model, such as the architecture, optimisation
procedure, or training data, is not disclosed explicitly as it might contain
proprietary information or make the system more vulnerable. This work shows
that such attributes of neural networks can be exposed from a sequence of
queries. This has multiple implications. On the one hand, our work exposes the
vulnerability of black-box neural networks to different types of attacks -- we
show that the revealed internal information helps generate more effective
adversarial examples against the black box model. On the other hand, this
technique can be used for better protection of private content from automatic
recognition models using adversarial examples. Our paper suggests that it is
actually hard to draw a line between white box and black box models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Oh_S/0/1/0/all/0/1&quot;&gt;Seong Joon Oh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Augustin_M/0/1/0/all/0/1&quot;&gt;Max Augustin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Schiele_B/0/1/0/all/0/1&quot;&gt;Bernt Schiele&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Fritz_M/0/1/0/all/0/1&quot;&gt;Mario Fritz&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.02029">
<title>AdaBatch: Adaptive Batch Sizes for Training Deep Neural Networks. (arXiv:1712.02029v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1712.02029</link>
<description rdf:parseType="Literal">&lt;p&gt;Training deep neural networks with Stochastic Gradient Descent, or its
variants, requires careful choice of both learning rate and batch size. While
smaller batch sizes generally converge in fewer training epochs, larger batch
sizes offer more parallelism and hence better computational efficiency. We have
developed a new training approach that, rather than statically choosing a
single batch size for all epochs, adaptively increases the batch size during
the training process. Our method delivers the convergence rate of small batch
sizes while achieving performance similar to large batch sizes. We analyse our
approach using the standard AlexNet, ResNet, and VGG networks operating on the
popular CIFAR-10, CIFAR-100, and ImageNet datasets. Our results demonstrate
that learning with adaptive batch sizes can improve performance by factors of
up to 6.25 on 4 NVIDIA Tesla P100 GPUs while changing accuracy by less than 1%
relative to training with fixed batch sizes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Devarakonda_A/0/1/0/all/0/1&quot;&gt;Aditya Devarakonda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Naumov_M/0/1/0/all/0/1&quot;&gt;Maxim Naumov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garland_M/0/1/0/all/0/1&quot;&gt;Michael Garland&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.04432">
<title>Integrated Model, Batch and Domain Parallelism in Training Neural Networks. (arXiv:1712.04432v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1712.04432</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a new integrated method of exploiting model, batch and domain
parallelism for the training of deep neural networks (DNNs) on large
distributed-memory computers using minibatch stochastic gradient descent (SGD).
Our goal is to find an efficient parallelization strategy for a fixed batch
size using $P$ processes. Our method is inspired by the communication-avoiding
algorithms in numerical linear algebra. We see $P$ processes as logically
divided into a $P_r \times P_c$ grid where the $P_r$ dimension is implicitly
responsible for model/domain parallelism and the $P_c$ dimension is implicitly
responsible for batch parallelism. In practice, the integrated matrix-based
parallel algorithm encapsulates these types of parallelism automatically. We
analyze the communication complexity and analytically demonstrate that the
lowest communication costs are often achieved neither with pure model nor with
pure data parallelism. We also show how the domain parallel approach can help
in extending the the theoretical scaling limit of the typical batch parallel
method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gholami_A/0/1/0/all/0/1&quot;&gt;Amir Gholami&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Azad_A/0/1/0/all/0/1&quot;&gt;Ariful Azad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jin_P/0/1/0/all/0/1&quot;&gt;Peter Jin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Keutzer_K/0/1/0/all/0/1&quot;&gt;Kurt Keutzer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Buluc_A/0/1/0/all/0/1&quot;&gt;Aydin Buluc&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04431">
<title>Detecting Spacecraft Anomalies Using LSTMs and Nonparametric Dynamic Thresholding. (arXiv:1802.04431v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1802.04431</link>
<description rdf:parseType="Literal">&lt;p&gt;As spacecraft send back increasing amounts of telemetry data, improved
anomaly detection systems are needed to lessen the monitoring burden placed on
operations engineers and reduce operational risk. Current spacecraft monitoring
systems only target a subset of anomaly types and often require costly expert
knowledge to develop and maintain due to challenges involving scale and
complexity. We demonstrate the effectiveness of Long Short-Term Memory (LSTMs)
networks, a type of Recurrent Neural Network (RNN), in overcoming these issues
using expert-labeled telemetry anomaly data from the Soil Moisture Active
Passive (SMAP) satellite and the Mars Science Laboratory (MSL) rover,
Curiosity. We also propose a complementary unsupervised and nonparametric
anomaly thresholding approach developed during a pilot implementation of an
anomaly detection system for SMAP, and offer false positive mitigation
strategies along with other key improvements and lessons learned during
development.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hundman_K/0/1/0/all/0/1&quot;&gt;Kyle Hundman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Constantinou_V/0/1/0/all/0/1&quot;&gt;Valentino Constantinou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Laporte_C/0/1/0/all/0/1&quot;&gt;Christopher Laporte&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Colwell_I/0/1/0/all/0/1&quot;&gt;Ian Colwell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Soderstrom_T/0/1/0/all/0/1&quot;&gt;Tom Soderstrom&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.00497">
<title>Propagating Uncertainty in Multi-Stage Bayesian Convolutional Neural Networks with Application to Pulmonary Nodule Detection. (arXiv:1712.00497v1 [cs.CV] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1712.00497</link>
<description rdf:parseType="Literal">&lt;p&gt;Motivated by the problem of computer-aided detection (CAD) of pulmonary
nodules, we introduce methods to propagate and fuse uncertainty information in
a multi-stage Bayesian convolutional neural network (CNN) architecture. The
question we seek to answer is &quot;can we take advantage of the model uncertainty
provided by one deep learning model to improve the performance of the
subsequent deep learning models and ultimately of the overall performance in a
multi-stage Bayesian deep learning architecture?&quot;. Our experiments show that
propagating uncertainty through the pipeline enables us to improve the overall
performance in terms of both final prediction accuracy and model confidence.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ozdemir_O/0/1/0/all/0/1&quot;&gt;Onur Ozdemir&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Woodward_B/0/1/0/all/0/1&quot;&gt;Benjamin Woodward&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Berlin_A/0/1/0/all/0/1&quot;&gt;Andrew A. Berlin&lt;/a&gt;</dc:creator>
</item></rdf:RDF>