<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Good papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Good Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-09-10T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.02731"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.02836"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.03242"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1708.06019"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05978"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.00368"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.02637"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.02649"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.02657"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.02719"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.02735"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.02786"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.02790"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.02904"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.02906"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.02992"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.03051"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.03125"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.03194"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.03260"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.03272"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.03327"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.03406"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.03449"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.04307"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.04520"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.01186"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09657"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.00734"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.03586"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.01341"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.01997"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.02670"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.02709"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.02727"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.02740"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.02744"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.02861"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.03019"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.03137"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.03207"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.03214"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.03267"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.03316"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.03368"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.03474"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1706.02216"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07674"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.08108"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.02061"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.04730"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.06645"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.07216"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.01887"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1809.02731">
<title>Exploiting Invertible Decoders for Unsupervised Sentence Representation Learning. (arXiv:1809.02731v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1809.02731</link>
<description rdf:parseType="Literal">&lt;p&gt;The encoder-decoder models for unsupervised sentence representation learning
tend to discard the decoder after being trained on a large unlabelled corpus,
since only the encoder is needed to map the input sentence into a vector
representation. However, parameters learnt in the decoder also contain useful
information about language. In order to utilise the decoder after learning, we
present two types of decoding functions whose inverse can be easily derived
without expensive inverse calculation. Therefore, the inverse of the decoding
function serves as another encoder that produces sentence representations. We
show that, with careful design of the decoding functions, the model learns good
sentence representations, and the ensemble of the representations produced from
the encoder and the inverse of the decoder demonstrate even better
generalisation ability and solid transferability.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_S/0/1/0/all/0/1&quot;&gt;Shuai Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sa_V/0/1/0/all/0/1&quot;&gt;Virginia R. de Sa&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.02836">
<title>Context-Free Transductions with Neural Stacks. (arXiv:1809.02836v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1809.02836</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper analyzes the behavior of stack-augmented recurrent neural network
(RNN) models. Due to the architectural similarity between stack RNNs and
pushdown transducers, we train stack RNN models on a number of tasks, including
string reversal, context-free language modelling, and cumulative XOR
evaluation. Examining the behavior of our networks, we show that
stack-augmented RNNs can discover intuitive stack-based strategies for solving
our tasks. However, stack RNNs are more difficult to train than classical
architectures such as LSTMs. Rather than employ stack-based strategies, more
complex networks often find approximate solutions by using the stack as
unstructured memory.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hao_Y/0/1/0/all/0/1&quot;&gt;Yiding Hao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Merrill_W/0/1/0/all/0/1&quot;&gt;William Merrill&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Angluin_D/0/1/0/all/0/1&quot;&gt;Dana Angluin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Frank_R/0/1/0/all/0/1&quot;&gt;Robert Frank&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Amsel_N/0/1/0/all/0/1&quot;&gt;Noah Amsel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Benz_A/0/1/0/all/0/1&quot;&gt;Andrew Benz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mendelsohn_S/0/1/0/all/0/1&quot;&gt;Simon Mendelsohn&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.03242">
<title>Finding Better Topologies for Deep Convolutional Neural Networks by Evolution. (arXiv:1809.03242v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1809.03242</link>
<description rdf:parseType="Literal">&lt;p&gt;Due to the nonlinearity of artificial neural networks, designing topologies
for deep convolutional neural networks (CNN) is a challenging task and often
only heuristic approach, such as trial and error, can be applied. An
evolutionary algorithm can solve optimization problems where the fitness
landscape is unknown. However, evolutionary algorithms are computing resource
intensive, which makes it difficult for problems when deep CNNs are involved.
In this paper, we propose an evolutionary strategy to find better topologies
for deep CNNs. Incorporating the concept of knowledge inheritance and knowledge
learning, our evolutionary algorithm can be executed with limited computing
resources. We applied the proposed algorithm in finding effective topologies of
deep CNNs for the image classification task using CIFAR-10 dataset. After the
evolution, we analyzed the topologies that performed well for this task. Our
studies verify the techniques that have been commonly used in human designed
deep CNNs. We also discovered that some of the graph properties greatly affect
the system performance. We applied the guidelines learned from the evolution
and designed new network topologies that outperform Residual Net with less
layers on CIFAR-10, CIFAR-100, and SVHN dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1&quot;&gt;Honglei Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kiranyaz_S/0/1/0/all/0/1&quot;&gt;Serkan Kiranyaz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gabbouj_M/0/1/0/all/0/1&quot;&gt;Moncef Gabbouj&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1708.06019">
<title>A Capacity Scaling Law for Artificial Neural Networks. (arXiv:1708.06019v3 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1708.06019</link>
<description rdf:parseType="Literal">&lt;p&gt;We derive the calculation of two critical numbers predicting the behavior of
perceptron networks. First, we derive the calculation of what we call the
lossless memory (LM) dimension. The LM dimension is a generalization of the
Vapnik--Chervonenkis (VC) dimension that avoids structured data and therefore
provides an upper bound for perfectly fitting almost any training data. Second,
we derive what we call the MacKay (MK) dimension. This limit indicates a 50%
chance of not being able to train a given function. Our derivations are
performed by embedding a neural network into Shannon&apos;s communication model
which allows to interpret the two points as capacities measured in bits. We
present a proof and practical experiments that validate our upper bounds with
repeatable experiments using different network configurations, diverse
implementations, varying activation functions, and several learning algorithms.
The bottom line is that the two capacity points scale strictly linear with the
number of weights. Among other practical applications, our result allows to
compare and benchmark different neural network implementations independent of a
concrete learning task. Our results provide insight into the capabilities and
limits of neural networks and generate valuable know how for experimental
design decisions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Friedland_G/0/1/0/all/0/1&quot;&gt;Gerald Friedland&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Krell_M/0/1/0/all/0/1&quot;&gt;Mario Krell&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05978">
<title>Bayesian Convolutional Neural Networks. (arXiv:1806.05978v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1806.05978</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce Bayesian Convolutional Neural Networks (BayesCNNs), a variant of
Convolutional Neural Networks (CNNs) which is built upon Bayes by Backprop. We
demonstrate how this novel reliable variational inference method can serve as a
fundamental construct for various network architectures. On multiple datasets
in supervised learning settings (MNIST, CIFAR-10, CIFAR-100, and STL-10), our
proposed variational inference method achieves performances equivalent to
frequentist inference in identical architectures, while a measurement for
uncertainties and a regularisation are incorporated naturally. In the past,
Bayes by Backprop has been successfully implemented in feedforward and
recurrent neural networks, but not in convolutional ones. This work symbolises
the extension of Bayesian neural networks which encompasses all three
aforementioned types of network architectures now.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shridhar_K/0/1/0/all/0/1&quot;&gt;Kumar Shridhar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Laumann_F/0/1/0/all/0/1&quot;&gt;Felix Laumann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Maurin_A/0/1/0/all/0/1&quot;&gt;Adrian Llopart Maurin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liwicki_M/0/1/0/all/0/1&quot;&gt;Marcus Liwicki&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.00368">
<title>On overcoming the Curse of Dimensionality in Neural Networks. (arXiv:1809.00368v2 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1809.00368</link>
<description rdf:parseType="Literal">&lt;p&gt;Let $H$ be a reproducing Kernel Hilbert space. For $i=1,\cdots,N$, let
$x_i\in\mathbb{R}^{d}$ and $y_i\in\mathbb{R}^{m}$ comprise our dataset. Let
$f^*\in H$ be the unique global minimiser of the functional \begin{equation*}
J(f) = \frac{1}{2}\Vert f\Vert_{H}^{2} +
\frac{1}{N}\sum_{i=1}^{N}\frac{1}{2}\vert f(x_i)-y_i\vert^{2}. \end{equation*}
&lt;/p&gt;
&lt;p&gt;In this paper we show that for each $n\in\mathbb{N}$ there exists a two layer
network where the first layer has $nm$ number of basis functions
$\Phi_{x_{i_k},j}$ for $i_1,\cdots,i_n\in\{1,\cdots,N\}$, $j=1,\cdots,m$ and
the second layer takes a weighted summation of the first layer, such that the
functions $f_n$ realised by these networks satisfy \begin{equation*} \Vert
f_{n}-f^*\Vert_{H}\leq O(\frac{1}{\sqrt{n}})\enspace \text{for all}\enspace
n\in\mathbb{N}. \end{equation*}
&lt;/p&gt;
&lt;p&gt;Thus the error rate is independent of input dimension $d$, output dimension
$m$ and data size $N$.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yeressian_K/0/1/0/all/0/1&quot;&gt;Karen Yeressian&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.02637">
<title>Neural Generation of Diverse Questions using Answer Focus, Contextual and Linguistic Features. (arXiv:1809.02637v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1809.02637</link>
<description rdf:parseType="Literal">&lt;p&gt;Question Generation is the task of automatically creating questions from
textual input. In this work we present a new Attentional Encoder--Decoder
Recurrent Neural Network model for automatic question generation. Our model
incorporates linguistic features and an additional sentence embedding to
capture meaning at both sentence and word levels. The linguistic features are
designed to capture information related to named entity recognition, word case,
and entity coreference resolution. In addition our model uses a copying
mechanism and a special answer signal that enables generation of numerous
diverse questions on a given sentence. Our model achieves state of the art
results of 19.98 Bleu_4 on a benchmark Question Generation dataset,
outperforming all previously published results by a significant margin. A human
evaluation also shows that these added features improve the quality of the
generated questions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Harrison_V/0/1/0/all/0/1&quot;&gt;Vrindavan Harrison&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Walker_M/0/1/0/all/0/1&quot;&gt;Marilyn Walker&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.02649">
<title>A Transfer-Learnable Natural Language Interface for Databases. (arXiv:1809.02649v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1809.02649</link>
<description rdf:parseType="Literal">&lt;p&gt;Relational database management systems (RDBMSs) are powerful because they are
able to optimize and answer queries against any relational database. A natural
language interface (NLI) for a database, on the other hand, is tailored to
support that specific database. In this work, we introduce a general purpose
transfer-learnable NLI with the goal of learning one model that can be used as
NLI for any relational database. We adopt the data management principle of
separating data and its schema, but with the additional support for the
idiosyncrasy and complexity of natural languages. Specifically, we introduce an
automatic annotation mechanism that separates the schema and the data, where
the schema also covers knowledge about natural language. Furthermore, we
propose a customized sequence model that translates annotated natural language
queries to SQL statements. We show in experiments that our approach outperforms
previous NLI methods on the WikiSQL dataset and the model we learned can be
applied to another benchmark dataset OVERNIGHT without retraining.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1&quot;&gt;Wenlu Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1&quot;&gt;Yingtao Tian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiong_H/0/1/0/all/0/1&quot;&gt;Hongyu Xiong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1&quot;&gt;Haixun Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ku_W/0/1/0/all/0/1&quot;&gt;Wei-Shinn Ku&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.02657">
<title>dyngraph2vec: Capturing Network Dynamics using Dynamic Graph Representation Learning. (arXiv:1809.02657v1 [cs.SI])</title>
<link>http://arxiv.org/abs/1809.02657</link>
<description rdf:parseType="Literal">&lt;p&gt;Learning graph representations is a fundamental task aimed at capturing
various properties of graphs in vector space. The most recent methods learn
such representations for static networks. However, real world networks evolve
over time and have varying dynamics. Capturing such evolution is key to
predicting the properties of unseen networks. To understand how the network
dynamics affect the prediction performance, we propose an embedding approach
which learns the structure of evolution in dynamic graphs and can predict
unseen links with higher precision. Our model, dyngraph2vec, learns the
temporal transitions in the network using a deep architecture composed of dense
and recurrent layers. We motivate the need of capturing dynamics for prediction
on a toy data set created using stochastic block models. We then demonstrate
the efficacy of dyngraph2vec over existing state-of-the-art methods on two real
world data sets. We observe that learning dynamics can improve the quality of
embedding and yield better performance in link prediction.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goyal_P/0/1/0/all/0/1&quot;&gt;Palash Goyal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chhetri_S/0/1/0/all/0/1&quot;&gt;Sujit Rokka Chhetri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Canedo_A/0/1/0/all/0/1&quot;&gt;Arquimedes Canedo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.02719">
<title>What If We Simply Swap the Two Text Fragments? A Straightforward yet Effective Way to Test the Robustness of Methods to Confounding Signals in Nature Language Inference Tasks. (arXiv:1809.02719v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1809.02719</link>
<description rdf:parseType="Literal">&lt;p&gt;Nature language inference (NLI) task is a predictive task of determining the
inference relationship of a pair of natural language sentences. With the
increasing popularity of NLI, many state-of-the-art predictive models have been
proposed with impressive performances. However, several works have noticed the
statistical irregularities in the collected NLI data set that may result in an
over-estimated performance of these models and proposed remedies. In this
paper, we further investigate the statistical irregularities, what we refer as
confounding factors, of the NLI data sets. With the belief that some NLI labels
should preserve under swapping operations, we propose a simple yet effective
way (swapping the two text fragments) of evaluating the NLI predictive models
that naturally mitigate the observed problems. Further, we continue to train
the predictive models with our swapping manner and propose to use the deviation
of the model&apos;s evaluation performances under different percentages of training
text fragments to be swapped to describe the robustness of a predictive model.
Our evaluation metrics leads to some interesting understandings of recent
published NLI methods. Finally, we also apply the swapping operation on NLI
models to see the effectiveness of this straightforward method in mitigating
the confounding factor problems in training generic sentence embeddings for
other NLP transfer tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1&quot;&gt;Haohan Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_D/0/1/0/all/0/1&quot;&gt;Da Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xing_E/0/1/0/all/0/1&quot;&gt;Eric P. Xing&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.02735">
<title>Operations Guided Neural Networks for High Fidelity Data-To-Text Generation. (arXiv:1809.02735v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1809.02735</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent neural models for data-to-text generation are mostly based on
data-driven end-to-end training over encoder-decoder networks. Even though the
generated texts are mostly fluent and informative, they often generate
descriptions that are not consistent with the input structured data. This is a
critical issue especially in domains that require inference or calculations
over raw data. In this paper, we attempt to improve the fidelity of neural
data-to-text generation by utilizing pre-executed symbolic operations. We
propose a framework called Operation-guided Attention-based
sequence-to-sequence network (OpAtt), with a specifically designed gating
mechanism as well as a quantization module for operation results to utilize
information from pre-executed operations. Experiments on two sports datasets
show our proposed method clearly improves the fidelity of the generated texts
to the input structured data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nie_F/0/1/0/all/0/1&quot;&gt;Feng Nie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jinpeng Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yao_J/0/1/0/all/0/1&quot;&gt;Jin-Ge Yao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pan_R/0/1/0/all/0/1&quot;&gt;Rong Pan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1&quot;&gt;Chin-Yew Lin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.02786">
<title>Structure-Preserving Transformation: Generating Diverse and Transferable Adversarial Examples. (arXiv:1809.02786v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1809.02786</link>
<description rdf:parseType="Literal">&lt;p&gt;Adversarial examples are perturbed inputs designed to fool machine learning
models. Most recent works on adversarial examples for image classification
focus on directly modifying pixels with minor perturbations. A common
requirement in all these works is that the malicious perturbations should be
small enough (measured by an $L_p$ norm for some $p$) so that they are
imperceptible to humans. However, small perturbations can be unnecessarily
restrictive and limit the diversity of adversarial examples generated. Further,
an $L_p$ norm based distance metric ignores important structure patterns hidden
in images that are important to human perception. Consequently, even the minor
perturbation introduced in recent works often makes the adversarial examples
less natural to humans. More importantly, they often do not transfer well and
are therefore less effective when attacking black-box models especially for
those protected by a defense mechanism. In this paper, we propose a
structure-preserving transformation (SPT) for generating natural and diverse
adversarial examples with extremely high transferability. The key idea of our
approach is to allow perceptible deviation in adversarial examples while
keeping structure patterns that are central to a human classifier. Empirical
results on the MNIST and the fashion-MNIST datasets show that adversarial
examples generated by our approach can easily bypass strong adversarial
training. Further, they transfer well to other target models with no loss or
little loss of successful attack rate.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peng_D/0/1/0/all/0/1&quot;&gt;Dan Peng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_Z/0/1/0/all/0/1&quot;&gt;Zizhan Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xiaofeng Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.02790">
<title>Simplified Hierarchical Recurrent Encoder-Decoder for Building End-To-End Dialogue Systems. (arXiv:1809.02790v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1809.02790</link>
<description rdf:parseType="Literal">&lt;p&gt;As a generative model for building end-to-end dialogue systems, Hierarchical
Recurrent Encoder-Decoder (HRED) consists of three layers of Gated Recurrent
Unit (GRU), which from bottom to top are separately used as the word-level
encoder, the sentence-level encoder, and the decoder. Despite performing well
on dialogue corpora, HRED is computationally expensive to train due to its
complexity. To improve the training efficiency of HRED, we propose a new model,
which is named as Simplified HRED (SHRED), by making each layer of HRED except
the top one simpler than its upper layer. On the one hand, we propose Scalar
Gated Unit (SGU), which is a simplified variant of GRU, and use it as the
sentence-level encoder. On the other hand, we use Fixed-size
Ordinally-Forgetting Encoding (FOFE), which has no trainable parameter at all,
as the word-level encoder. The experimental results show that compared with
HRED under the same word embedding size and the same hidden state size for each
layer, SHRED reduces the number of trainable parameters by 25\%--35\%, and the
training time by more than 50\%, but still achieves slightly better
performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1&quot;&gt;Chao Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1&quot;&gt;Hui Jiang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.02904">
<title>A Continuous Information Gain Measure to Find the Most Discriminatory Problems for AI Benchmarking. (arXiv:1809.02904v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1809.02904</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper introduces an information-theoretic method for selecting a small
subset of problems which gives us the most information about a group of
problem-solving algorithms. This method was tested on the games in the General
Video Game AI (GVGAI) framework, allowing us to identify a smaller set of games
that still gives a large amount of information about the game-playing agents.
This approach can be used to make agent testing more efficient in the future.
We can achieve almost as good discriminatory accuracy when testing on only a
handful of games as when testing on more than a hundred games, something which
is often computationally infeasible. Furthermore, this method can be extended
to study the dimensions of effective variance in game design between these
games, allowing us to identify which games differentiate between agents in the
most complementary ways. As a side effect of this investigation, we provide an
up-to-date comparison on agent performance for all GVGAI games, and an analysis
of correlations between scores and win-rates across both games and agents.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stephenson_M/0/1/0/all/0/1&quot;&gt;Matthew Stephenson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Anderson_D/0/1/0/all/0/1&quot;&gt;Damien Anderson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khalifa_A/0/1/0/all/0/1&quot;&gt;Ahmed Khalifa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Togelius_J/0/1/0/all/0/1&quot;&gt;Julian Togelius&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Salge_C/0/1/0/all/0/1&quot;&gt;Christoph Salge&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Renz_J/0/1/0/all/0/1&quot;&gt;Jochen Renz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Levine_J/0/1/0/all/0/1&quot;&gt;John Levine&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.02906">
<title>End-to-end Language Identification using NetFV and NetVLAD. (arXiv:1809.02906v1 [eess.AS])</title>
<link>http://arxiv.org/abs/1809.02906</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we apply the NetFV and NetVLAD layers for the end-to-end
language identification task. NetFV and NetVLAD layers are the differentiable
implementations of the standard Fisher Vector and Vector of Locally Aggregated
Descriptors (VLAD) methods, respectively. Both of them can encode a sequence of
feature vectors into a fixed dimensional vector which is very important to
process those variable-length utterances. We first present the relevances and
differences between the classical i-vector and the aforementioned encoding
schemes. Then, we construct a flexible end-to-end framework including a
convolutional neural network (CNN) architecture and an encoding layer (NetFV or
NetVLAD) for the language identification task. Experimental results on the NIST
LRE 2007 close-set task show that the proposed system achieves significant EER
reductions against the conventional i-vector baseline and the CNN temporal
average pooling system, respectively.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Chen_J/0/1/0/all/0/1&quot;&gt;Jinkun Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Cai_W/0/1/0/all/0/1&quot;&gt;Weicheng Cai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Cai_D/0/1/0/all/0/1&quot;&gt;Danwei Cai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Cai_Z/0/1/0/all/0/1&quot;&gt;Zexin Cai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Zhong_H/0/1/0/all/0/1&quot;&gt;Haibin Zhong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Li_M/0/1/0/all/0/1&quot;&gt;Ming Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.02992">
<title>Speeding Up Neural Machine Translation Decoding by Cube Pruning. (arXiv:1809.02992v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1809.02992</link>
<description rdf:parseType="Literal">&lt;p&gt;Although neural machine translation has achieved promising results, it
suffers from slow translation speed. The direct consequence is that a trade-off
has to be made between translation quality and speed, thus its performance can
not come into full play. We apply cube pruning, a popular technique to speed up
dynamic programming, into neural machine translation to speed up the
translation. To construct the equivalence class, similar target hidden states
are combined, leading to less RNN expansion operations on the target side and
less \$\mathrm{softmax}\$ operations over the large target vocabulary. The
experiments show that, at the same or even better translation quality, our
method can translate faster compared with naive beam search by \$3.3\times\$ on
GPUs and \$3.5\times\$ on CPUs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1&quot;&gt;Wen Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1&quot;&gt;Liang Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1&quot;&gt;Yang Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_L/0/1/0/all/0/1&quot;&gt;Lei Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1&quot;&gt;Qun Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.03051">
<title>Attentional Multi-Reading Sarcasm Detection. (arXiv:1809.03051v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1809.03051</link>
<description rdf:parseType="Literal">&lt;p&gt;Recognizing sarcasm often requires a deep understanding of multiple sources
of information, including the utterance, the conversational context, and real
world facts. Most of the current sarcasm detection systems consider only the
utterance in isolation. There are some limited attempts toward taking into
account the conversational context. In this paper, we propose an interpretable
end-to-end model that combines information from both the utterance and the
conversational context to detect sarcasm, and demonstrate its effectiveness
through empirical evaluations. We also study the behavior of the proposed model
to provide explanations for the model&apos;s decisions. Importantly, our model is
capable of determining the impact of utterance and conversational context on
the model&apos;s decisions. Finally, we provide an ablation study to illustrate the
impact of different components of the proposed model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghaeini_R/0/1/0/all/0/1&quot;&gt;Reza Ghaeini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fern_X/0/1/0/all/0/1&quot;&gt;Xiaoli Z. Fern&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tadepalli_P/0/1/0/all/0/1&quot;&gt;Prasad Tadepalli&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.03125">
<title>The LKPY Package for Recommender Systems Experiments: Next-Generation Tools and Lessons Learned from the LensKit Project. (arXiv:1809.03125v1 [cs.IR])</title>
<link>http://arxiv.org/abs/1809.03125</link>
<description rdf:parseType="Literal">&lt;p&gt;Since 2010, we have built and maintained LensKit, an open-source toolkit for
building, researching, and learning about recommender systems. We have
successfully used the software in a wide range of recommender systems
experiments, to support education in traditional classroom and online settings,
and as the algorithmic backend for user-facing recommendation services in
movies and books. This experience, along with community feedback, has surfaced
a number of challenges with LensKit&apos;s design and environmental choices. In
response to these challenges, we are developing a new set of tools that
leverage the PyData stack to enable the kinds of research experiments and
educational experiences that we have been able to deliver with LensKit, along
with new experimental structures that the existing code makes difficult. The
result is a set of research tools that should significantly increase research
velocity and provide much smoother integration with other software such as
Keras while maintaining the same level of reproducibility as a LensKit
experiment. In this paper, we reflect on the LensKit project, particularly on
our experience using it for offline evaluation experiments, and describe the
next-generation LKPY tools for enabling new offline evaluations and experiments
with flexible, open-ended designs and well-tested evaluation primitives.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ekstrand_M/0/1/0/all/0/1&quot;&gt;Michael D. Ekstrand&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.03194">
<title>Improving Response Selection in Multi-turn Dialogue Systems. (arXiv:1809.03194v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1809.03194</link>
<description rdf:parseType="Literal">&lt;p&gt;Building systems that can communicate with humans is a core problem in
Artificial Intelligence. This work proposes a novel neural network architecture
for response selection in an end-to-end multi-turn conversational dialogue
setting. The architecture applies context level attention and incorporates
additional external knowledge provided by descriptions of domain-specific
words. It uses a bi-directional Gated Recurrent Unit (GRU) for encoding context
and responses and learns to attend over the context words given the latent
response representation and vice versa.In addition, it incorporates external
domain specific information using another GRU for encoding the domain keyword
descriptions. This allows better representation of domain-specific keywords in
responses and hence improves the overall performance. Experimental results show
that our model outperforms all other state-of-the-art methods for response
selection in multi-turn conversations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chaudhuri_D/0/1/0/all/0/1&quot;&gt;Debanjan Chaudhuri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kristiadi_A/0/1/0/all/0/1&quot;&gt;Agustinus Kristiadi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lehmann_J/0/1/0/all/0/1&quot;&gt;Jens Lehmann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fischer_A/0/1/0/all/0/1&quot;&gt;Asja Fischer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.03260">
<title>Automated Test Generation to Detect Individual Discrimination in AI Models. (arXiv:1809.03260v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1809.03260</link>
<description rdf:parseType="Literal">&lt;p&gt;Dependability on AI models is of utmost importance to ensure full acceptance
of the AI systems. One of the key aspects of the dependable AI system is to
ensure that all its decisions are fair and not biased towards any individual.
In this paper, we address the problem of detecting whether a model has an
individual discrimination. Such a discrimination exists when two individuals
who differ only in the values of their protected attributes (such as,
gender/race) while the values of their non-protected ones are exactly the same,
get different decisions. Measuring individual discrimination requires an
exhaustive testing, which is infeasible for a non-trivial system. In this
paper, we present an automated technique to generate test inputs, which is
geared towards finding individual discrimination. Our technique combines the
well-known technique called symbolic execution along with the local
explainability for generation of effective test cases. Our experimental results
clearly demonstrate that our technique produces 3.72 times more successful test
cases than the existing state-of-the-art across all our chosen benchmarks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Agarwal_A/0/1/0/all/0/1&quot;&gt;Aniya Agarwal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lohia_P/0/1/0/all/0/1&quot;&gt;Pranay Lohia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nagar_S/0/1/0/all/0/1&quot;&gt;Seema Nagar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dey_K/0/1/0/all/0/1&quot;&gt;Kuntal Dey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saha_D/0/1/0/all/0/1&quot;&gt;Diptikalyan Saha&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.03272">
<title>Privacy-Preserving Deep Learning for any Activation Function. (arXiv:1809.03272v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1809.03272</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper considers the scenario that multiple data owners wish to apply a
machine learning method over the combined dataset of all owners to obtain the
best possible learning output but do not want to share the local datasets owing
to privacy concerns. We design systems for the scenario that the stochastic
gradient descent (SGD) algorithm is used as the machine learning method because
SGD (or its variants) is at the heart of recent deep learning techniques over
neural networks. Our systems differ from existing systems in the following
features: {\bf (1)} any activation function can be used, meaning that no
privacy-preserving-friendly approximation is required; {\bf (2)} gradients
computed by SGD are not shared but the weight parameters are shared instead;
and {\bf (3)} robustness against colluding parties even in the extreme case
that only one honest party exists. We prove that our systems, while
privacy-preserving, achieve the same learning accuracy as SGD and hence retain
the merit of deep learning with respect to accuracy. Finally, we conduct
several experiments using benchmark datasets, and show that our systems
outperform previous system in terms of learning accuracies.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Phong_L/0/1/0/all/0/1&quot;&gt;Le Trieu Phong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Phuong_T/0/1/0/all/0/1&quot;&gt;Tran Thi Phuong&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.03327">
<title>YouTube-VOS: A Large-Scale Video Object Segmentation Benchmark. (arXiv:1809.03327v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1809.03327</link>
<description rdf:parseType="Literal">&lt;p&gt;Learning long-term spatial-temporal features are critical for many video
analysis tasks. However, existing video segmentation methods predominantly rely
on static image segmentation techniques, and methods capturing temporal
dependency for segmentation have to depend on pretrained optical flow models,
leading to suboptimal solutions for the problem. End-to-end sequential learning
to explore spatialtemporal features for video segmentation is largely limited
by the scale of available video segmentation datasets, i.e., even the largest
video segmentation dataset only contains 90 short video clips. To solve this
problem, we build a new large-scale video object segmentation dataset called
YouTube Video Object Segmentation dataset (YouTube-VOS). Our dataset contains
4,453 YouTube video clips and 94 object categories. This is by far the largest
video object segmentation dataset to our knowledge and has been released at
&lt;a href=&quot;http://youtube-vos.org.&quot;&gt;this http URL&lt;/a&gt; We further evaluate several existing state-of-the-art
video object segmentation algorithms on this dataset which aims to establish
baselines for the development of new algorithms in the future.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_N/0/1/0/all/0/1&quot;&gt;Ning Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1&quot;&gt;Linjie Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fan_Y/0/1/0/all/0/1&quot;&gt;Yuchen Fan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yue_D/0/1/0/all/0/1&quot;&gt;Dingcheng Yue&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1&quot;&gt;Yuchen Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1&quot;&gt;Jianchao Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_T/0/1/0/all/0/1&quot;&gt;Thomas Huang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.03406">
<title>Keep it stupid simple. (arXiv:1809.03406v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1809.03406</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep reinforcement learning can match and exceed human performance, but if
even minor changes are introduced to the environment artificial networks often
can&apos;t adapt. Humans meanwhile are quite adaptable. We hypothesize that this is
partly because of how humans use heuristics, and partly because humans can
imagine new and more challenging environments to learn from. We&apos;ve developed a
model of hierarchical reinforcement learning that combines both these elements
into a stumbler-strategist network. We test transfer performance of this
network using Wythoff&apos;s game, a gridworld environment with a known optimal
strategy. We show that combining imagined play with a heuristic--labeling each
position as &quot;good&quot; or &quot;bad&quot;&apos;--both accelerates learning and promotes transfer
to novel games, while also improving model interpretability.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peterson_E/0/1/0/all/0/1&quot;&gt;Erik J Peterson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Muyesser_N/0/1/0/all/0/1&quot;&gt;Necati Alp M&amp;#xfc;yesser&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Verstynen_T/0/1/0/all/0/1&quot;&gt;Timothy Verstynen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dunovan_K/0/1/0/all/0/1&quot;&gt;Kyle Dunovan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.03449">
<title>Exploring Machine Reading Comprehension with Explicit Knowledge. (arXiv:1809.03449v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1809.03449</link>
<description rdf:parseType="Literal">&lt;p&gt;To apply general knowledge to machine reading comprehension (MRC), we propose
an innovative MRC approach, which consists of a WordNet-based data enrichment
method and an MRC model named as Knowledge Aided Reader (KAR). The data
enrichment method uses the semantic relations of WordNet to extract semantic
level inter-word connections from each passage-question pair in the MRC
dataset, and allows us to control the amount of the extraction results by
setting a hyper-parameter. KAR uses the extraction results of the data
enrichment method as explicit knowledge to assist the prediction of answer
spans. According to the experimental results, the single model of KAR achieves
an Exact Match (EM) of $72.4$ and an F1 Score of $81.1$ on the development set
of SQuAD, and more importantly, by applying different settings in the data
enrichment method to change the amount of the extraction results, there is a
$2\%$ variation in the resulting performance of KAR, which implies that the
explicit knowledge provided by the data enrichment method plays an effective
role in the training of KAR.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1&quot;&gt;Chao Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1&quot;&gt;Hui Jiang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.04307">
<title>AI Safety and Reproducibility: Establishing Robust Foundations for the Neuropsychology of Human Values. (arXiv:1712.04307v3 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1712.04307</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose the creation of a systematic effort to identify and replicate key
findings in neuropsychology and allied fields related to understanding human
values. Our aim is to ensure that research underpinning the value alignment
problem of artificial intelligence has been sufficiently validated to play a
role in the design of AI systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sarma_G/0/1/0/all/0/1&quot;&gt;Gopal P. Sarma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hay_N/0/1/0/all/0/1&quot;&gt;Nick J. Hay&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Safron_A/0/1/0/all/0/1&quot;&gt;Adam Safron&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.04520">
<title>Non-Parametric Transformation Networks. (arXiv:1801.04520v6 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1801.04520</link>
<description rdf:parseType="Literal">&lt;p&gt;ConvNets, through their architecture, only enforce invariance to translation.
In this paper, we introduce a new class of deep convolutional architectures
called Non-Parametric Transformation Networks (NPTNs) which can learn
\textit{general} invariances and symmetries directly from data. NPTNs are a
natural generalization of ConvNets and can be optimized directly using gradient
descent. Unlike almost all previous works in deep architectures, they make no
assumption regarding the structure of the invariances present in the data and
in that aspect are flexible and powerful. We also model ConvNets and NPTNs
under a unified framework called Transformation Networks (TN), which yields a
better understanding of the connection between the two. We demonstrate the
efficacy of NPTNs on data such as MNIST with extreme transformations and
CIFAR10 where they outperform baselines, and further outperform several recent
algorithms on ETH-80. They do so while having the same number of parameters. We
also show that they are more effective than ConvNets in modelling symmetries
and invariances from data, without the explicit knowledge of the added
arbitrary nuisance transformations. Finally, we replace ConvNets with NPTNs
within Capsule Networks and show that this enables Capsule Nets to perform even
better.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pal_D/0/1/0/all/0/1&quot;&gt;Dipan K. Pal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Savvides_M/0/1/0/all/0/1&quot;&gt;Marios Savvides&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.01186">
<title>Neural-Guided Deductive Search for Real-Time Program Synthesis from Examples. (arXiv:1804.01186v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1804.01186</link>
<description rdf:parseType="Literal">&lt;p&gt;Synthesizing user-intended programs from a small number of input-output
examples is a challenging problem with several important applications like
spreadsheet manipulation, data wrangling and code refactoring. Existing
synthesis systems either completely rely on deductive logic techniques that are
extensively hand-engineered or on purely statistical models that need massive
amounts of data, and in general fail to provide real-time synthesis on
challenging benchmarks. In this work, we propose Neural Guided Deductive Search
(NGDS), a hybrid synthesis technique that combines the best of both symbolic
logic techniques and statistical models. Thus, it produces programs that
satisfy the provided specifications by construction and generalize well on
unseen examples, similar to data-driven systems. Our technique effectively
utilizes the deductive search framework to reduce the learning problem of the
neural component to a simple supervised learning setup. Further, this allows us
to both train on sparingly available real-world data and still leverage
powerful recurrent neural network encoders. We demonstrate the effectiveness of
our method by evaluating on real-world customer scenarios by synthesizing
accurate programs with up to 12x speed-up compared to state-of-the-art systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kalyan_A/0/1/0/all/0/1&quot;&gt;Ashwin Kalyan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mohta_A/0/1/0/all/0/1&quot;&gt;Abhishek Mohta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Polozov_O/0/1/0/all/0/1&quot;&gt;Oleksandr Polozov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Batra_D/0/1/0/all/0/1&quot;&gt;Dhruv Batra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jain_P/0/1/0/all/0/1&quot;&gt;Prateek Jain&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gulwani_S/0/1/0/all/0/1&quot;&gt;Sumit Gulwani&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09657">
<title>Learning compositionally through attentive guidance. (arXiv:1805.09657v3 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1805.09657</link>
<description rdf:parseType="Literal">&lt;p&gt;While neural network models have been successfully applied to domains that
require substantial generalisation skills, recent studies have implied that
they struggle when solving the task they are trained on requires inferring its
underlying compositional structure. In this paper, we introduce Attentive
Guidance, a mechanism to direct a sequence to sequence model equipped with
attention to find more compositional solutions. We test it on two tasks,
devised precisely to assess the compositional capabilities of neural models,
and we show that vanilla sequence to sequence models with attention overfit the
training distribution, while the guided versions come up with compositional
solutions that fit the training and testing distributions almost equally well.
Moreover, the learned solutions generalise even in cases where the training and
testing distributions strongly diverge. In this way, we demonstrate that
sequence to sequence models are capable of finding compositional solutions
without requiring extra components. These results helps to disentangle the
causes for the lack of systematic compositionality in neural networks, which
can in turn fuel future work.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hupkes_D/0/1/0/all/0/1&quot;&gt;Dieuwke Hupkes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1&quot;&gt;Anand Singh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Korrel_K/0/1/0/all/0/1&quot;&gt;Kris Korrel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kruszewski_G/0/1/0/all/0/1&quot;&gt;German Kruszewski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bruni_E/0/1/0/all/0/1&quot;&gt;Elia Bruni&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.00734">
<title>The relativistic discriminator: a key element missing from standard GAN. (arXiv:1807.00734v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1807.00734</link>
<description rdf:parseType="Literal">&lt;p&gt;In standard generative adversarial network (SGAN), the discriminator
estimates the probability that the input data is real. The generator is trained
to increase the probability that fake data is real. We argue that it should
also simultaneously decrease the probability that real data is real because 1)
this would account for a priori knowledge that half of the data in the
mini-batch is fake, 2) this would be observed with divergence minimization, and
3) in optimal settings, SGAN would be equivalent to integral probability metric
(IPM) GANs.
&lt;/p&gt;
&lt;p&gt;We show that this property can be induced by using a relativistic
discriminator which estimate the probability that the given real data is more
realistic than a randomly sampled fake data. We also present a variant in which
the discriminator estimate the probability that the given real data is more
realistic than fake data, on average. We generalize both approaches to
non-standard GAN loss functions and we refer to them respectively as
Relativistic GANs (RGANs) and Relativistic average GANs (RaGANs). We show that
IPM-based GANs are a subset of RGANs which use the identity function.
&lt;/p&gt;
&lt;p&gt;Empirically, we observe that 1) RGANs and RaGANs are significantly more
stable and generate higher quality data samples than their non-relativistic
counterparts, 2) Standard RaGAN with gradient penalty generate data of better
quality than WGAN-GP while only requiring a single discriminator update per
generator update (reducing the time taken for reaching the state-of-the-art by
400%), and 3) RaGANs are able to generate plausible high resolutions images
(256x256) from a very small sample (N=2011), while GAN and LSGAN cannot; these
images are of significantly better quality than the ones generated by WGAN-GP
and SGAN with spectral normalization.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jolicoeur_Martineau_A/0/1/0/all/0/1&quot;&gt;Alexia Jolicoeur-Martineau&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.03586">
<title>Difficulty-controllable Question Generation for Reading Comprehension. (arXiv:1807.03586v3 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1807.03586</link>
<description rdf:parseType="Literal">&lt;p&gt;We investigate the difficulty levels of questions, and propose a new setting
called Difficulty-controllable Question Generation (DQG). Taking as input a
reading comprehension paragraph and some text fragments (i.e. answers) in the
paragraph that we want to ask questions about, a DQG method needs to generate
questions each of which has a given text fragment as its answer, and meanwhile
the generation is under the control of specified difficulty labels---the output
questions should satisfy the specified difficulty as much as possible. To solve
this task, we propose an end-to-end framework to generate questions of
designated difficulty levels. Specifically, we explore a few intuitions: (i) In
the input sentences, the nearer a word is to the answer fragment, the more
likely it is used in the question; (ii) The easier a question is, the nearer
its words are to the answer fragment in the sentence; (iii) Performing
difficulty control could be regarded as a problem of sentence generation
towards a specified attribute or style, namely difficulty level. For
evaluation, we prepared the first dataset of reading comprehension questions
with difficulty labels. The results show that our framework not only generates
questions of better quality under the metrics like BLEU, but also has the
capability to generate questions complying with the specified difficulty
labels.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1&quot;&gt;Yifan Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bing_L/0/1/0/all/0/1&quot;&gt;Lidong Bing&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1&quot;&gt;Wang Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jianan Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+King_I/0/1/0/all/0/1&quot;&gt;Irwin King&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lyu_M/0/1/0/all/0/1&quot;&gt;Michael R. Lyu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.01341">
<title>Embedding Multimodal Relational Data for Knowledge Base Completion. (arXiv:1809.01341v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1809.01341</link>
<description rdf:parseType="Literal">&lt;p&gt;Representing entities and relations in an embedding space is a well-studied
approach for machine learning on relational data. Existing approaches, however,
primarily focus on simple link structure between a finite set of entities,
ignoring the variety of data types that are often used in knowledge bases, such
as text, images, and numerical values. In this paper, we propose multimodal
knowledge base embeddings (MKBE) that use different neural encoders for this
variety of observed data, and combine them with existing relational models to
learn embeddings of the entities and multimodal data. Further, using these
learned embedings and different neural decoders, we introduce a novel
multimodal imputation model to generate missing multimodal values, like text
and images, from information in the knowledge base. We enrich existing
relational datasets to create two novel benchmarks that contain additional
information such as textual descriptions and images of the original entities.
We demonstrate that our models utilize this additional information effectively
to provide more accurate link prediction, achieving state-of-the-art results
with a considerable gap of 5-7% over existing methods. Further, we evaluate the
quality of our generated multimodal values via a user study. We have release
the datasets and the open-source implementation of our models at
https://github.com/pouyapez/mkbe
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pezeshkpour_P/0/1/0/all/0/1&quot;&gt;Pouya Pezeshkpour&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1&quot;&gt;Liyan Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1&quot;&gt;Sameer Singh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.01997">
<title>Dual Ask-Answer Network for Machine Reading Comprehension. (arXiv:1809.01997v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1809.01997</link>
<description rdf:parseType="Literal">&lt;p&gt;There are three modalities in the reading comprehension setting: question,
answer and context. The task of question answering or question generation aims
to infer an answer or a question when given the counterpart based on context.
We present a novel two-way neural sequence transduction model that connects
three modalities, allowing it to learn two tasks simultaneously and mutually
benefit one another. During training, the model receives
question-context-answer triplets as input and captures the cross-modal
interaction via a hierarchical attention process. Unlike previous joint
learning paradigms that leverage the duality of question generation and
question answering at data level, we solve such dual tasks at the architecture
level by mirroring the network structure and partially sharing components at
different layers. This enables the knowledge to be transferred from one task to
another, helping the model to find a general representation for each modality.
The evaluation on four public datasets shows that our dual-learning model
outperforms the mono-learning counterpart as well as the state-of-the-art joint
models on both question answering and question generation tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiao_H/0/1/0/all/0/1&quot;&gt;Han Xiao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1&quot;&gt;Feng Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1&quot;&gt;Jianfeng Yan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_J/0/1/0/all/0/1&quot;&gt;Jingyao Zheng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.02670">
<title>RetGK: Graph Kernels based on Return Probabilities of Random Walks. (arXiv:1809.02670v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1809.02670</link>
<description rdf:parseType="Literal">&lt;p&gt;Graph-structured data arise in wide applications, such as computer vision,
bioinformatics, and social networks. Quantifying similarities among graphs is a
fundamental problem. In this paper, we develop a framework for computing graph
kernels, based on return probabilities of random walks. The advantages of our
proposed kernels are that they can effectively exploit various node attributes,
while being scalable to large datasets. We conduct extensive graph
classification experiments to evaluate our graph kernels. The experimental
results show that our graph kernels significantly outperform existing
state-of-the-art approaches in both accuracy and computational efficiency.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhang_Z/0/1/0/all/0/1&quot;&gt;Zhen Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wang_M/0/1/0/all/0/1&quot;&gt;Mianzhi Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Xiang_Y/0/1/0/all/0/1&quot;&gt;Yijian Xiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Huang_Y/0/1/0/all/0/1&quot;&gt;Yan Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Nehorai_A/0/1/0/all/0/1&quot;&gt;Arye Nehorai&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.02709">
<title>Adaptive Edge Features Guided Graph Attention Networks. (arXiv:1809.02709v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1809.02709</link>
<description rdf:parseType="Literal">&lt;p&gt;Edge features contain important information about graphs. However, current
state-of-the-art neural network models designed for graph learning do not
consider incorporating edge features, especially multi-dimensional edge
features. In this paper, we propose an attention mechanism which combines both
node features and edge features. Guided by the edge features, the attention
mechanism on a pair of graph nodes will not only depend on node contents, but
also ajust automatically with respect to the properties of the edge connecting
these two nodes. Moreover, the edge features are adjusted by the attention
function and fed to the next layer, which means our edge features are adaptive
across network layers. As a result, our proposed adaptive edge features guided
graph attention model can consolidate a rich source of graph information that
current state-of-the-art graph learning methods cannot. We apply our proposed
model to graph node classification, and experimental results on three citaion
network datasets and a biological network dataset show that out method
outperforms the current state-of-the-art methods, testifying to the
discriminative capability of edge features and the effectiveness of our
adaptive edge features guided attention model. Additional ablation experimental
study further shows that both the edge features and adaptiveness components
contribute to our model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gong_L/0/1/0/all/0/1&quot;&gt;Liyu Gong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_Q/0/1/0/all/0/1&quot;&gt;Qiang Cheng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.02727">
<title>Decentralized Differentially Private Without-Replacement Stochastic Gradient Descent. (arXiv:1809.02727v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1809.02727</link>
<description rdf:parseType="Literal">&lt;p&gt;While machine learning has achieved remarkable results in a wide variety of
domains, the training of models often requires large datasets that may need to
be collected from different individuals. As sensitive information may be
contained in the individual&apos;s dataset, sharing training data may lead to severe
privacy concerns. One effective approach to build the privacy-aware machine
learning methods is to leverage the generic framework of differential privacy.
Considering that stochastic gradient descent (SGD) is one of the mostly adopted
methods for large-scale machine learning problems, two decentralized
differentially private SGD algorithms are proposed in this work. Particularly,
we focus on SGD without replacement due to its favorable structure for
practical implementation. In addition, both privacy and convergence analysis
are provided for the proposed algorithms. Finally, extensive experiments are
performed to verify the theoretical results and demonstrate the effectiveness
of the proposed algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jin_R/0/1/0/all/0/1&quot;&gt;Richeng Jin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1&quot;&gt;Xiaofan He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dai_H/0/1/0/all/0/1&quot;&gt;Huaiyu Dai&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.02740">
<title>Ensembles of Nested Dichotomies with Multiple Subset Evaluation. (arXiv:1809.02740v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1809.02740</link>
<description rdf:parseType="Literal">&lt;p&gt;A system of nested dichotomies is a method of decomposing a multi-class
problem into a collection of binary problems. Such a system recursively applies
binary splits to divide the set of classes into two subsets, and trains a
binary classifier for each split. Many methods have been proposed to perform
this split, each with various advantages and disadvantages. In this paper, we
present a simple, general method for improving the predictive performance of
nested dichotomies produced by any subset selection techniques that employ
randomness to construct the subsets. We provide a theoretical expectation for
performance improvements, as well as empirical results showing that our method
improves the root mean squared error of nested dichotomies, regardless of
whether they are employed as an individual model or in an ensemble setting.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leathart_T/0/1/0/all/0/1&quot;&gt;Tim Leathart&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Frank_E/0/1/0/all/0/1&quot;&gt;Eibe Frank&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pfahringer_B/0/1/0/all/0/1&quot;&gt;Bernhard Pfahringer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Holmes_G/0/1/0/all/0/1&quot;&gt;Geoffrey Holmes&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.02744">
<title>On the Calibration of Nested Dichotomies for Large Multiclass Tasks. (arXiv:1809.02744v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1809.02744</link>
<description rdf:parseType="Literal">&lt;p&gt;Nested dichotomies are used as a method of transforming a multiclass
classification problem into a series of binary problems. A tree structure is
induced that recursively splits the set of classes into subsets, and a binary
classification model learns to discriminate between the two subsets of classes
at each node. In this paper, we demonstrate that these nested dichotomies
typically exhibit poor probability calibration, even when the base binary
models are well calibrated. We also show that this problem is exacerbated when
the binary models are poorly calibrated. We discuss the effectiveness of
different calibration strategies and show that accuracy and log-loss can be
significantly improved by calibrating both the internal base models and the
full nested dichotomy structure, especially when the number of classes is high.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leathart_T/0/1/0/all/0/1&quot;&gt;Tim Leathart&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Frank_E/0/1/0/all/0/1&quot;&gt;Eibe Frank&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pfahringer_B/0/1/0/all/0/1&quot;&gt;Bernhard Pfahringer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Holmes_G/0/1/0/all/0/1&quot;&gt;Geoffrey Holmes&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.02861">
<title>On the Intriguing Connections of Regularization, Input Gradients and Transferability of Evasion and Poisoning Attacks. (arXiv:1809.02861v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1809.02861</link>
<description rdf:parseType="Literal">&lt;p&gt;Transferability captures the ability of an attack against a machine-learning
model to be effective against a different, potentially unknown, model. Studying
transferability of attacks has gained interest in the last years due to the
deployment of cyber-attack detection services based on machine learning. For
these applications of machine learning, service providers avoid disclosing
information about their machine-learning algorithms. As a result, attackers
trying to bypass detection are forced to craft their attacks against a
surrogate model instead of the actual target model used by the service. While
previous work has shown that finding test-time transferable attack samples is
possible, it is not well understood how an attacker may construct adversarial
examples that are likely to transfer against different models, in particular in
the case of training-time poisoning attacks. In this paper, we present the
first empirical analysis aimed to investigate the transferability of both
test-time evasion and training-time poisoning attacks. We provide a unifying,
formal definition of transferability of such attacks and show how it relates to
the input gradients of the surrogate and of the target classification models.
We assess to which extent some of the most well-known machine-learning systems
are vulnerable to transfer attacks, and explain why such attacks succeed (or
not) across different models. To this end, we leverage some interesting
connections highlighted in this work among the adversarial vulnerability of
machine-learning models, their regularization hyperparameters and input
gradients.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Demontis_A/0/1/0/all/0/1&quot;&gt;Ambra Demontis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Melis_M/0/1/0/all/0/1&quot;&gt;Marco Melis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pintor_M/0/1/0/all/0/1&quot;&gt;Maura Pintor&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jagielski_M/0/1/0/all/0/1&quot;&gt;Matthew Jagielski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Biggio_B/0/1/0/all/0/1&quot;&gt;Battista Biggio&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oprea_A/0/1/0/all/0/1&quot;&gt;Alina Oprea&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nita_Rotaru_C/0/1/0/all/0/1&quot;&gt;Cristina Nita-Rotaru&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roli_F/0/1/0/all/0/1&quot;&gt;Fabio Roli&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.03019">
<title>Stochastic Gradient Descent Learns State Equations with Nonlinear Activations. (arXiv:1809.03019v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1809.03019</link>
<description rdf:parseType="Literal">&lt;p&gt;We study discrete time dynamical systems governed by the state equation
$h_{t+1}=\phi(Ah_t+Bu_t)$. Here $A,B$ are weight matrices, $\phi$ is an
activation function, and $u_t$ is the input data. This relation is the backbone
of recurrent neural networks (e.g. LSTMs) which have broad applications in
sequential learning tasks. We utilize stochastic gradient descent to learn the
weight matrices from a finite input/state trajectory $(u_t,h_t)_{t=0}^N$. We
prove that SGD estimate linearly converges to the ground truth weights while
using near-optimal sample size. Our results apply to increasing activations
whose derivatives are bounded away from zero. The analysis is based on i) a
novel SGD convergence result with nonlinear activations and ii) careful
statistical characterization of the state vector. Numerical experiments verify
the fast convergence of SGD on ReLU and leaky ReLU in consistence with our
theory.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oymak_S/0/1/0/all/0/1&quot;&gt;Samet Oymak&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.03137">
<title>Tracking by Animation: Unsupervised Learning of Multi-Object Attentive Trackers. (arXiv:1809.03137v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1809.03137</link>
<description rdf:parseType="Literal">&lt;p&gt;Online Multi-Object Tracking (MOT) from videos is a challenging computer
vision task which has been extensively studied for decades. Most of the
existing MOT algorithms are based on the Tracking-by-Detection (TBD) paradigm
combined with popular machine learning approaches which largely reduce the
human effort to tune algorithm parameters. However, the commonly used
supervised learning approaches require the labeled data (e.g., bounding boxes),
which is expensive for videos. Also, the TBD framework is usually suboptimal
since it is not end-to-end, i.e., it considers the task as detection and
tracking, but not jointly. To achieve both label-free and end-to-end learning
of MOT, we propose a Tracking-by-Animation framework, where a differentiable
neural model first tracks objects from input frames and then animates these
objects into reconstructed frames. Learning is then driven by the
reconstruction error through backpropagation. We further propose a
Reprioritized Attentive Tracking to improve the robustness of data association.
Experiments conducted on both synthetic and real video datasets show the
potential of the proposed model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_Z/0/1/0/all/0/1&quot;&gt;Zhen He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jian Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_D/0/1/0/all/0/1&quot;&gt;Daxue Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_H/0/1/0/all/0/1&quot;&gt;Hangen He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barber_D/0/1/0/all/0/1&quot;&gt;David Barber&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.03207">
<title>Beyond the Selected Completely At Random Assumption for Learning from Positive and Unlabeled Data. (arXiv:1809.03207v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1809.03207</link>
<description rdf:parseType="Literal">&lt;p&gt;Most positive and unlabeled data is subject to selection biases. The labeled
examples can, for example, be selected from the positive set because they are
easier to obtain or more obviously positive. This paper investigates how
learning can be enabled in this setting. We propose and theoretically analyze
an empirical-risk-based method for incorporating the labeling mechanism.
Additionally, we investigate under which assumptions learning is possible when
the labeling mechanism is not fully understood and propose a practical method
to enable this. Our empirical analysis supports the theoretical results and
shows that taking into account the possibility of a selection bias, even when
the labeling mechanism is unknown, improves the trained classifiers.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bekker_J/0/1/0/all/0/1&quot;&gt;Jessa Bekker&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Davis_J/0/1/0/all/0/1&quot;&gt;Jesse Davis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.03214">
<title>Adaptive Behavior Generation for Autonomous Driving using Deep Reinforcement Learning with Compact Semantic States. (arXiv:1809.03214v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1809.03214</link>
<description rdf:parseType="Literal">&lt;p&gt;Making the right decision in traffic is a challenging task that is highly
dependent on individual preferences as well as the surrounding environment.
Therefore it is hard to model solely based on expert knowledge. In this work we
use Deep Reinforcement Learning to learn maneuver decisions based on a compact
semantic state representation. This ensures a consistent model of the
environment across scenarios as well as a behavior adaptation function,
enabling on-line changes of desired behaviors without re-training. The input
for the neural network is a simulated object list similar to that of Radar or
Lidar sensors, superimposed by a relational semantic scene description. The
state as well as the reward are extended by a behavior adaptation function and
a parameterization respectively. With little expert knowledge and a set of
mid-level actions, it can be seen that the agent is capable to adhere to
traffic rules and learns to drive safely in a variety of situations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wolf_P/0/1/0/all/0/1&quot;&gt;Peter Wolf&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kurzer_K/0/1/0/all/0/1&quot;&gt;Karl Kurzer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wingert_T/0/1/0/all/0/1&quot;&gt;Tobias Wingert&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kuhnt_F/0/1/0/all/0/1&quot;&gt;Florian Kuhnt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zollner_J/0/1/0/all/0/1&quot;&gt;J. Marius Z&amp;#xf6;llner&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.03267">
<title>Feature Learning for Meta-Paths in Knowledge Graphs. (arXiv:1809.03267v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1809.03267</link>
<description rdf:parseType="Literal">&lt;p&gt;In this thesis, we study the problem of feature learning on heterogeneous
knowledge graphs. These features can be used to perform tasks such as link
prediction, classification and clustering on graphs. Knowledge graphs provide
rich semantics encoded in the edge and node types. Meta-paths consist of these
types and abstract paths in the graph. Until now, meta-paths can only be used
as categorical features with high redundancy and are therefore unsuitable for
machine learning models. We propose meta-path embeddings to solve this problem
by learning semantical and compact vector representations of them. Current
graph embedding methods only embed nodes and edge types and therefore miss
semantics encoded in the combination of them. Our method embeds meta-paths
using the skipgram model with an extension to deal with the redundancy and high
amount of meta-paths in big knowledge graphs. We critically evaluate our
embedding approach by predicting links on Wikidata. The experiments indicate
that we learn a sensible embedding of the meta-paths but can improve it
further.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bischoff_S/0/1/0/all/0/1&quot;&gt;Sebastian Bischoff&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.03316">
<title>Hierarchical Video Understanding. (arXiv:1809.03316v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1809.03316</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce a hierarchical architecture for video understanding that
exploits the structure of real world actions by capturing targets at different
levels of granularity. We design the model such that it first learns simpler
coarse-grained tasks, and then moves on to learn more fine-grained targets. The
model is trained with a joint loss on different granularity levels. We
demonstrate empirical results on the recent release of Something-Something
dataset, which provides a hierarchy of targets, namely coarse-grained action
groups, fine-grained action categories, and captions. Experiments suggest that
models that exploit targets at different levels of granularity achieve better
performance on all levels.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mahdisoltani_F/0/1/0/all/0/1&quot;&gt;Farzaneh Mahdisoltani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Memisevic_R/0/1/0/all/0/1&quot;&gt;Roland Memisevic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fleet_D/0/1/0/all/0/1&quot;&gt;David Fleet&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.03368">
<title>Probabilistic Binary Neural Networks. (arXiv:1809.03368v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1809.03368</link>
<description rdf:parseType="Literal">&lt;p&gt;Low bit-width weights and activations are an effective way of combating the
increasing need for both memory and compute power of Deep Neural Networks. In
this work, we present a probabilistic training method for Neural Network with
both binary weights and activations, called BLRNet. By embracing stochasticity
during training, we circumvent the need to approximate the gradient of
non-differentiable functions such as sign(), while still obtaining a fully
Binary Neural Network at test time. Moreover, it allows for anytime ensemble
predictions for improved performance and uncertainty estimates by sampling from
the weight distribution. Since all operations in a layer of the BLRNet operate
on random variables, we introduce stochastic versions of Batch Normalization
and max pooling, which transfer well to a deterministic network at test time.
We evaluate the BLRNet on multiple standardized benchmarks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peters_J/0/1/0/all/0/1&quot;&gt;Jorn W.T. Peters&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Welling_M/0/1/0/all/0/1&quot;&gt;Max Welling&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.03474">
<title>Multi-party Poisoning through Generalized $p$-Tampering. (arXiv:1809.03474v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1809.03474</link>
<description rdf:parseType="Literal">&lt;p&gt;In a poisoning attack against a learning algorithm, an adversary tampers with
a fraction of the training data $T$ with the goal of increasing the
classification error of the constructed hypothesis/model over the final test
distribution. In the distributed setting, $T$ might be gathered gradually from
$m$ data providers $P_1,\dots,P_m$ who generate and submit their shares of $T$
in an online way. In this work, we initiate a formal study of $(k,p)$-poisoning
attacks in which an adversary controls $k\in[n]$ of the parties, and even for
each corrupted party $P_i$, the adversary submits some poisoned data $T&apos;_i$ on
behalf of $P_i$ that is still &quot;$(1-p)$-close&quot; to the correct data $T_i$ (e.g.,
$1-p$ fraction of $T&apos;_i$ is still honestly generated). For $k=m$, this model
becomes the traditional notion of poisoning, and for $p=1$ it coincides with
the standard notion of corruption in multi-party computation. We prove that if
there is an initial constant error for the generated hypothesis $h$, there is
always a $(k,p)$-poisoning attacker who can decrease the confidence of $h$ (to
have a small error), or alternatively increase the error of $h$, by $\Omega(p
\cdot k/m)$. Our attacks can be implemented in polynomial time given samples
from the correct data, and they use no wrong labels if the original
distributions are not noisy. At a technical level, we prove a general lemma
about biasing bounded functions $f(x_1,\dots,x_n)\in[0,1]$ through an attack
model in which each block $x_i$ might be controlled by an adversary with
marginal probability $p$ in an online way. When the probabilities are
independent, this coincides with the model of $p$-tampering attacks, thus we
call our model generalized $p$-tampering. We prove the power of such attacks by
incorporating ideas from the context of coin-flipping attacks into the
$p$-tampering model and generalize the results in both of these areas.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mahloujifar_S/0/1/0/all/0/1&quot;&gt;Saeed Mahloujifar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mahmoody_M/0/1/0/all/0/1&quot;&gt;Mohammad Mahmoody&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mohammed_A/0/1/0/all/0/1&quot;&gt;Ameer Mohammed&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1706.02216">
<title>Inductive Representation Learning on Large Graphs. (arXiv:1706.02216v4 [cs.SI] UPDATED)</title>
<link>http://arxiv.org/abs/1706.02216</link>
<description rdf:parseType="Literal">&lt;p&gt;Low-dimensional embeddings of nodes in large graphs have proved extremely
useful in a variety of prediction tasks, from content recommendation to
identifying protein functions. However, most existing approaches require that
all nodes in the graph are present during training of the embeddings; these
previous approaches are inherently transductive and do not naturally generalize
to unseen nodes. Here we present GraphSAGE, a general, inductive framework that
leverages node feature information (e.g., text attributes) to efficiently
generate node embeddings for previously unseen data. Instead of training
individual embeddings for each node, we learn a function that generates
embeddings by sampling and aggregating features from a node&apos;s local
neighborhood. Our algorithm outperforms strong baselines on three inductive
node-classification benchmarks: we classify the category of unseen nodes in
evolving information graphs based on citation and Reddit post data, and we show
that our algorithm generalizes to completely unseen graphs using a multi-graph
dataset of protein-protein interactions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hamilton_W/0/1/0/all/0/1&quot;&gt;William L. Hamilton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ying_R/0/1/0/all/0/1&quot;&gt;Rex Ying&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leskovec_J/0/1/0/all/0/1&quot;&gt;Jure Leskovec&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07674">
<title>BourGAN: Generative Networks with Metric Embeddings. (arXiv:1805.07674v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1805.07674</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper addresses the mode collapse for generative adversarial networks
(GANs). We view modes as a geometric structure of data distribution in a metric
space. Under this geometric lens, we embed subsamples of the dataset from an
arbitrary metric space into the l2 space, while preserving their pairwise
distance distribution. Not only does this metric embedding determine the
dimensionality of the latent space automatically, it also enables us to
construct a mixture of Gaussians to draw latent space random vectors. We use
the Gaussian mixture model in tandem with a simple augmentation of the
objective function to train GANs. Every major step of our method is supported
by theoretical analysis, and our experiments on real and synthetic data confirm
that the generator is able to produce samples spreading over most of the modes
while avoiding unwanted samples, outperforming several recent GAN variants on a
number of metrics and offering new features.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Xiao_C/0/1/0/all/0/1&quot;&gt;Chang Xiao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhong_P/0/1/0/all/0/1&quot;&gt;Peilin Zhong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zheng_C/0/1/0/all/0/1&quot;&gt;Changxi Zheng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.08108">
<title>Simultaneous Adversarial Training - Learn from Others Mistakes. (arXiv:1807.08108v3 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1807.08108</link>
<description rdf:parseType="Literal">&lt;p&gt;Adversarial examples are maliciously tweaked images that can easily fool
machine learning techniques, such as neural networks, but they are normally not
visually distinguishable for human beings. One of the main approaches to solve
this problem is to retrain the networks using those adversarial examples,
namely adversarial training. However, standard adversarial training might not
actually change the decision boundaries but cause the problem of gradient
masking, resulting in a weaker ability to generate adversarial examples.
Therefore, it cannot alleviate the problem of black-box attacks, where
adversarial examples generated from other networks can transfer to the targeted
one. In order to reduce the problem of black-box attacks, we propose a novel
method that allows two networks to learn from each others&apos; adversarial examples
and become resilient to black-box attacks. We also combine this method with a
simple domain adaptation to further improve the performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liao_Z/0/1/0/all/0/1&quot;&gt;Zukang Liao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.02061">
<title>Semblance: A Rank-Based Kernel on Probability Spaces for Niche Detection. (arXiv:1808.02061v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1808.02061</link>
<description rdf:parseType="Literal">&lt;p&gt;Kernel methods provide a principled approach for detecting nonlinear
relations using well understood linear algorithms. In exploratory data analyses
when the underlying structure of the data&apos;s probability space is unclear, the
choice of kernel is often arbitrary. Here, we present a novel kernel,
Semblance, on a probability feature space. The advantage of Semblance lies in
its distribution free formulation and its ability to detect niche features by
placing greater emphasis on similarity between observation pairs that fall at
the tail ends of a distribution, as opposed to those that fall towards the
mean. We prove that Semblance is a valid Mercer kernel and illustrate its
applicability through simulations and real world examples.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Agarwal_D/0/1/0/all/0/1&quot;&gt;Divyansh Agarwal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhang_N/0/1/0/all/0/1&quot;&gt;Nancy Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.04730">
<title>Analyzing Inverse Problems with Invertible Neural Networks. (arXiv:1808.04730v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1808.04730</link>
<description rdf:parseType="Literal">&lt;p&gt;In many tasks, in particular in natural science, the goal is to determine
hidden system parameters from a set of measurements. Often, the forward process
from parameter- to measurement-space is a well-defined function, whereas the
inverse problem is ambiguous: one measurement may map to multiple different
sets of parameters. In this setting, the posterior parameter distribution,
conditioned on an input measurement, has to be determined. We argue that a
particular class of neural networks is well suited for this task -- so-called
Invertible Neural Networks (INNs). Although INNs are not new, they have, so
far, received little attention in literature. While classical neural networks
attempt to solve the ambiguous inverse problem directly, INNs are able to learn
it jointly with the well-defined forward process, using additional latent
output variables to capture the information otherwise lost. Given a specific
measurement and sampled latent variables, the inverse pass of the INN provides
a full distribution over parameter space. We verify experimentally, on
artificial data and real-world problems from astrophysics and medicine, that
INNs are a powerful analysis tool to find multi-modalities in parameter space,
to uncover parameter correlations, and to identify unrecoverable parameters.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ardizzone_L/0/1/0/all/0/1&quot;&gt;Lynton Ardizzone&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kruse_J/0/1/0/all/0/1&quot;&gt;Jakob Kruse&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wirkert_S/0/1/0/all/0/1&quot;&gt;Sebastian Wirkert&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rahner_D/0/1/0/all/0/1&quot;&gt;Daniel Rahner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pellegrini_E/0/1/0/all/0/1&quot;&gt;Eric W. Pellegrini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Klessen_R/0/1/0/all/0/1&quot;&gt;Ralf S. Klessen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Maier_Hein_L/0/1/0/all/0/1&quot;&gt;Lena Maier-Hein&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rother_C/0/1/0/all/0/1&quot;&gt;Carsten Rother&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kothe_U/0/1/0/all/0/1&quot;&gt;Ullrich K&amp;#xf6;the&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.06645">
<title>Stochastic Combinatorial Ensembles for Defending Against Adversarial Examples. (arXiv:1808.06645v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1808.06645</link>
<description rdf:parseType="Literal">&lt;p&gt;Many deep learning algorithms can be easily fooled with simple adversarial
examples. To address the limitations of existing defenses, we devised a
probabilistic framework that can generate an exponentially large ensemble of
models from a single model with just a linear cost. This framework takes
advantage of neural network depth and stochastically decides whether or not to
insert noise removal operators such as VAEs between layers. We show empirically
the important role that model gradients have when it comes to determining
transferability of adversarial examples, and take advantage of this result to
demonstrate that it is possible to train models with limited adversarial attack
transferability. Additionally, we propose a detection method based on metric
learning in order to detect adversarial examples that have no hope of being
cleaned of maliciously engineered noise.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Adam_G/0/1/0/all/0/1&quot;&gt;George A. Adam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Smirnov_P/0/1/0/all/0/1&quot;&gt;Petr Smirnov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Duvenaud_D/0/1/0/all/0/1&quot;&gt;David Duvenaud&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Haibe_Kains_B/0/1/0/all/0/1&quot;&gt;Benjamin Haibe-Kains&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goldenberg_A/0/1/0/all/0/1&quot;&gt;Anna Goldenberg&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.07216">
<title>Model Interpretation: A Unified Derivative-based Framework for Nonparametric Regression and Supervised Machine Learning. (arXiv:1808.07216v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1808.07216</link>
<description rdf:parseType="Literal">&lt;p&gt;Interpreting a nonparametric regression model with many predictors is known
to be a challenging problem. There has been renewed interest in this topic due
to the extensive use of machine learning algorithms and the difficulty in
understanding and explaining their input-output relationships. This paper
develops a unified framework using a derivative-based approach for existing
tools in the literature, including the partial-dependence plots, marginal plots
and accumulated effects plots. It proposes a new interpretation technique
called the accumulated total derivative effects plot and demonstrates how its
components can be used to develop extensive insights in complex regression
models with correlated predictors. The techniques are illustrated through
simulation results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Liu_X/0/1/0/all/0/1&quot;&gt;Xiaoyu Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chen_J/0/1/0/all/0/1&quot;&gt;Jie Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Vaughan_J/0/1/0/all/0/1&quot;&gt;Joel Vaughan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Nair_V/0/1/0/all/0/1&quot;&gt;Vijayan Nair&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sudjianto_A/0/1/0/all/0/1&quot;&gt;Agus Sudjianto&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.01887">
<title>Travel Speed Prediction with a Hierarchical Convolutional Neural Network and Long Short-Term Memory Model Framework. (arXiv:1809.01887v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1809.01887</link>
<description rdf:parseType="Literal">&lt;p&gt;Advanced travel information and warning, if provided accurately, can help
road users avoid traffic congestion through dynamic route planning and behavior
change. It also enables traffic control centres mitigate the impact of
congestion by activating Intelligent Transport System (ITS) proactively. Deep
learning has become increasingly popular in recent years, following a surge of
innovative GPU technology, high-resolution, big datasets and thriving machine
learning algorithms. However, there are few examples exploiting this emerging
technology to develop applications for traffic prediction. This is largely due
to the difficulty in capturing random, seasonal, non-linear, and
spatio-temporal correlated nature of traffic data. In this paper, we propose a
data-driven modelling approach with a novel hierarchical D-CLSTM-t deep
learning model for short-term traffic speed prediction, a framework combined
with convolutional neural network (CNN) and long short-term memory (LSTM)
models. A deep CNN model is employed to learn the spatio-temporal traffic
patterns of the input graphs, which are then fed into a deep LSTM model for
sequence learning. To capture traffic seasonal variations, time of the day and
day of the week indicators are fused with trained features. The model is
trained end-to-end to predict travel speed in 15 to 90 minutes in the future.
We compare the model performance against other baseline models including CNN,
LGBM, LSTM, and traditional speed-flow curves. Experiment results show that the
D-CLSTM-t outperforms other models considerably. Model tests show that speed
upstream also responds sensibly to a sudden accident occurring downstream. Our
D-CLSTM-t model framework is also highly scalable for future extension such as
for network-wide traffic prediction, which can also be improved by including
additional features such as weather, long term seasonality and accident
information.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1&quot;&gt;Wei Wang&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xucheng Li&lt;/a&gt; (2) ((1) Atkins (SNC-Lavalin), UK, (2) Shenzhen Urban Transport Planning Center Co. Ltd, China)</dc:creator>
</item></rdf:RDF>