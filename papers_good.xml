<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Good papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Good Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2017-12-12T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.04118"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.04170"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.04185"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.04195"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.04248"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.04254"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1703.09902"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.11160"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.07966"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.01208"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.02779"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.04008"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.04020"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.04065"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.04076"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.04143"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.04155"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.04159"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.04172"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.04182"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.04301"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.04306"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.04307"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.04323"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.04363"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.04386"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.04402"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.04415"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1610.04213"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1705.08690"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1708.06374"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.10445"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.07735"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.07425"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.08345"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.03890"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.03999"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.04046"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.04086"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.04120"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.04129"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.04135"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.04144"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.04145"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.04146"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.04165"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.04221"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.04276"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.04332"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.04350"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.04356"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.04407"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.04432"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1606.07636"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1703.01785"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1705.00919"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1705.04312"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1705.07881"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1707.04659"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1708.05978"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.04412"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.02971"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.11469"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.00837"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.07476"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.07693"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.09522"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.09889"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.03660"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.03878"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1712.04118">
<title>Neural Component Analysis for Fault Detection. (arXiv:1712.04118v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1712.04118</link>
<description rdf:parseType="Literal">&lt;p&gt;Principal component analysis (PCA) is largely adopted for chemical process
monitoring and numerous PCA-based systems have been developed to solve various
fault detection and diagnosis problems. Since PCA-based methods assume that the
monitored process is linear, nonlinear PCA models, such as autoencoder models
and kernel principal component analysis (KPCA), has been proposed and applied
to nonlinear process monitoring. However, KPCA-based methods need to perform
eigen-decomposition (ED) on the kernel Gram matrix whose dimensions depend on
the number of training data. Moreover, prefixed kernel parameters cannot be
most effective for different faults which may need different parameters to
maximize their respective detection performances. Autoencoder models lack the
consideration of orthogonal constraints which is crucial for PCA-based
algorithms. To address these problems, this paper proposes a novel nonlinear
method, called neural component analysis (NCA), which intends to train a
feedforward neural work with orthogonal constraints such as those used in PCA.
NCA can adaptively learn its parameters through backpropagation and the
dimensionality of the nonlinear features has no relationship with the number of
training samples. Extensive experimental results on the Tennessee Eastman (TE)
benchmark process show the superiority of NCA in terms of missed detection rate
(MDR) and false alarm rate (FAR). The source code of NCA can be found in
https://github.com/haitaozhao/Neural-Component-Analysis.git.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1&quot;&gt;Haitao Zhao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.04170">
<title>Interpretable Policies for Reinforcement Learning by Genetic Programming. (arXiv:1712.04170v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1712.04170</link>
<description rdf:parseType="Literal">&lt;p&gt;The search for interpretable reinforcement learning policies is of high
academic and industrial interest. Especially for industrial systems, domain
experts are more likely to deploy autonomously learned controllers if they are
understandable and convenient to evaluate. Basic algebraic equations are
supposed to meet these requirements, as long as they are restricted to an
adequate complexity. Here we introduce the genetic programming for
reinforcement learning (GPRL) approach based on model-based batch reinforcement
learning and genetic programming, which autonomously learns policy equations
from pre-existing default state-action trajectory samples. GPRL is compared to
a straight-forward method which utilizes genetic programming for symbolic
regression, yielding policies imitating an existing well-performing, but
non-interpretable policy. Experiments on three reinforcement learning
benchmarks, i.e., mountain car, cart-pole balancing, and industrial benchmark,
demonstrate the superiority of our GPRL approach compared to the symbolic
regression method. GPRL is capable of producing well-performing interpretable
reinforcement learning policies from pre-existing default trajectory data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hein_D/0/1/0/all/0/1&quot;&gt;Daniel Hein&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Udluft_S/0/1/0/all/0/1&quot;&gt;Steffen Udluft&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Runkler_T/0/1/0/all/0/1&quot;&gt;Thomas A. Runkler&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.04185">
<title>Backpropagation generalized for output derivatives. (arXiv:1712.04185v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1712.04185</link>
<description rdf:parseType="Literal">&lt;p&gt;Backpropagation algorithm is the cornerstone for neural network analysis.
Paper extends it for training any derivatives of neural network&apos;s output with
respect to its input. By the dint of it feedforward networks can be used to
solve or verify solutions of partial or simple, linear or nonlinear
differential equations. This method vastly differs from traditional ones like
finite differences on a mesh. It contains no approximations, but rather an
exact form of differential operators. Algorithm is built to train a feed
forward network with any number of hidden layers and any kind of sufficiently
smooth activation functions. It&apos;s presented in a form of matrix-vector products
so highly parallel implementation is readily possible. First part derives the
method for 2D case with first and second order derivatives, second part extends
it to N-dimensional case with any derivatives. All necessary expressions for
using this method to solve most applied PDE can be found in Appendix D.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Avrutskiy_V/0/1/0/all/0/1&quot;&gt;V.I. Avrutskiy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.04195">
<title>Concept Formation and Dynamics of Repeated Inference in Deep Generative Models. (arXiv:1712.04195v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1712.04195</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep generative models are reported to be useful in broad applications
including image generation. Repeated inference between data space and latent
space in these models can denoise cluttered images and improve the quality of
inferred results. However, previous studies only qualitatively evaluated image
outputs in data space, and the mechanism behind the inference has not been
investigated. The purpose of the current study is to numerically analyze
changes in activity patterns of neurons in the latent space of a deep
generative model called a &quot;variational auto-encoder&quot; (VAE). What kinds of
inference dynamics the VAE demonstrates when noise is added to the input data
are identified. The VAE embeds a dataset with clear cluster structures in the
latent space and the center of each cluster of multiple correlated data points
(memories) is referred as the concept. Our study demonstrated that transient
dynamics of inference first approaches a concept, and then moves close to a
memory. Moreover, the VAE revealed that the inference dynamics approaches a
more abstract concept to the extent that the uncertainty of input data
increases due to noise. It was demonstrated that by increasing the number of
the latent variables, the trend of the inference dynamics to approach a concept
can be enhanced, and the generalization ability of the VAE can be improved.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Nagano_Y/0/1/0/all/0/1&quot;&gt;Yoshihiro Nagano&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Karakida_R/0/1/0/all/0/1&quot;&gt;Ryo Karakida&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Okada_M/0/1/0/all/0/1&quot;&gt;Masato Okada&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.04248">
<title>Decision-Based Adversarial Attacks: Reliable Attacks Against Black-Box Machine Learning Models. (arXiv:1712.04248v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1712.04248</link>
<description rdf:parseType="Literal">&lt;p&gt;Many machine learning algorithms are vulnerable to almost imperceptible
perturbations of their inputs. So far it was unclear how much risk adversarial
perturbations carry for the safety of real-world machine learning applications
because most methods used to generate such perturbations rely either on
detailed model information (gradient-based attacks) or on confidence scores
such as class probabilities (score-based attacks), neither of which are
available in most real-world scenarios. In many such cases one currently needs
to retreat to transfer-based attacks which rely on cumbersome substitute
models, need access to the training data and can be defended against. Here we
emphasise the importance of attacks which solely rely on the final model
decision. Such decision-based attacks are (1) applicable to real-world
black-box models such as autonomous cars, (2) need less knowledge and are
easier to apply than transfer-based attacks and (3) are more robust to simple
defences than gradient- or score-based attacks. Previous attacks in this
category were limited to simple models or simple datasets. Here we introduce
the Boundary Attack, a decision-based attack that starts from a large
adversarial perturbation and then seeks to reduce the perturbation while
staying adversarial. The attack is conceptually simple, requires close to no
hyperparameter tuning, does not rely on substitute models and is competitive
with the best gradient-based attacks in standard computer vision tasks like
ImageNet. We apply the attack on two black-box algorithms from Clarifai.com.
The Boundary Attack in particular and the class of decision-based attacks in
general open new avenues to study the robustness of machine learning models and
raise new questions regarding the safety of deployed machine learning systems.
An implementation of the attack is available as part of Foolbox at
https://github.com/bethgelab/foolbox .
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Brendel_W/0/1/0/all/0/1&quot;&gt;Wieland Brendel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rauber_J/0/1/0/all/0/1&quot;&gt;Jonas Rauber&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bethge_M/0/1/0/all/0/1&quot;&gt;Matthias Bethge&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.04254">
<title>Robustness, Evolvability and Phenotypic Complexity: Insights from Evolving Digital Circuits. (arXiv:1712.04254v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1712.04254</link>
<description rdf:parseType="Literal">&lt;p&gt;We show how the characteristics of the evolutionary algorithm influence the
evolvability of candidate solutions, i.e. the propensity of evolving
individuals to generate better solutions as a result of genetic variation. More
specifically, (1+{\lambda}) evolutionary strategies largely outperform
({\mu}+1) evolutionary strategies in the context of the evolution of digital
circuits --- a domain characterized by a high level of neutrality. This
difference is due to the fact that the competition for robustness to mutations
among the circuits evolved with ({\mu}+1) evolutionary strategies leads to the
selection of phenotypically simple but low evolvable circuits. These circuits
achieve robustness by minimizing the number of functional genes rather than by
relying on redundancy or degeneracy to buffer the effects of mutations. The
analysis of these factors enabled us to design a new evolutionary algorithm,
named Parallel Stochastic Hill Climber (PSHC), which outperforms the other two
methods considered.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Milano_N/0/1/0/all/0/1&quot;&gt;Nicola Milano&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pagliuca_P/0/1/0/all/0/1&quot;&gt;Paolo Pagliuca&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nolfi_S/0/1/0/all/0/1&quot;&gt;Stefano Nolfi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1703.09902">
<title>Survey of the State of the Art in Natural Language Generation: Core tasks, applications and evaluation. (arXiv:1703.09902v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1703.09902</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper surveys the current state of the art in Natural Language
Generation (NLG), defined as the task of generating text or speech from
non-linguistic input. A survey of NLG is timely in view of the changes that the
field has undergone over the past decade or so, especially in relation to new
(usually data-driven) methods, as well as new applications of NLG technology.
This survey therefore aims to (a) give an up-to-date synthesis of research on
the core tasks in NLG and the architectures adopted in which such tasks are
organised; (b) highlight a number of relatively recent research topics that
have arisen partly as a result of growing synergies between NLG and other areas
of artificial intelligence; (c) draw attention to the challenges in NLG
evaluation, relating them to similar challenges faced in other areas of Natural
Language Processing, with an emphasis on different evaluation methods and the
relationships between them.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gatt_A/0/1/0/all/0/1&quot;&gt;Albert Gatt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Krahmer_E/0/1/0/all/0/1&quot;&gt;Emiel Krahmer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.11160">
<title>Super-polynomial and exponential improvements for quantum-enhanced reinforcement learning. (arXiv:1710.11160v2 [quant-ph] UPDATED)</title>
<link>http://arxiv.org/abs/1710.11160</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent work on quantum machine learning has demonstrated that quantum
computers can offer dramatic improvements over classical devices for data
mining, prediction and classification. However, less is known about the
advantages using quantum computers may bring in the more general setting of
reinforcement learning, where learning is achieved via interaction with a task
environment that provides occasional rewards. Reinforcement learning can
incorporate data-analysis-oriented learning settings as special cases, but also
includes more complex situations where, e.g., reinforcing feedback is delayed.
In a few recent works, Grover-type amplification has been utilized to construct
quantum agents that achieve up-to-quadratic improvements in learning
efficiency. These encouraging results have left open the key question of
whether super-polynomial improvements in learning times are possible for
genuine reinforcement learning problems, that is problems that go beyond the
other more restricted learning paradigms. In this work, we provide a family of
such genuine reinforcement learning tasks. We construct quantum-enhanced
learners which learn super-polynomially, and even exponentially faster than any
classical reinforcement learning model, and we discuss the potential impact our
results may have on future technologies.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Dunjko_V/0/1/0/all/0/1&quot;&gt;Vedran Dunjko&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yi-Kai Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Wu_X/0/1/0/all/0/1&quot;&gt;Xingyao Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Taylor_J/0/1/0/all/0/1&quot;&gt;Jacob M. Taylor&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.07966">
<title>Deep Learning for Real-time Gravitational Wave Detection and Parameter Estimation with LIGO Data. (arXiv:1711.07966v2 [gr-qc] UPDATED)</title>
<link>http://arxiv.org/abs/1711.07966</link>
<description rdf:parseType="Literal">&lt;p&gt;The recent Nobel-prize-winning detections of gravitational waves from merging
black holes and the subsequent detection of the collision of two neutron stars
in coincidence with electromagnetic observations have inaugurated a new era of
multimessenger astrophysics. To enhance the scope of this emergent science, we
proposed the use of deep convolutional neural networks for the detection and
characterization of gravitational wave signals in real-time. This method, Deep
Filtering, was initially demonstrated using simulated LIGO noise. In this
article, we present the extension of Deep Filtering using real data from the
first observing run of LIGO, for both detection and parameter estimation of
gravitational waves from binary black hole mergers with continuous data streams
from multiple LIGO detectors. We show for the first time that machine learning
can detect and estimate the true parameters of a real GW event observed by
LIGO. Our comparisons show that Deep Filtering is far more computationally
efficient than matched-filtering, while retaining similar sensitivity and lower
errors, allowing real-time processing of weak time-series signals in
non-stationary non-Gaussian noise, with minimal resources, and also enables the
detection of new classes of gravitational wave sources that may go unnoticed
with existing detection algorithms. This approach is uniquely suited to enable
coincident detection campaigns of gravitational waves and their multimessenger
counterparts in real-time.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/gr-qc/1/au:+George_D/0/1/0/all/0/1&quot;&gt;Daniel George&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/gr-qc/1/au:+Huerta_E/0/1/0/all/0/1&quot;&gt;E. A. Huerta&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.01208">
<title>The Case for Learned Index Structures. (arXiv:1712.01208v2 [cs.DB] UPDATED)</title>
<link>http://arxiv.org/abs/1712.01208</link>
<description rdf:parseType="Literal">&lt;p&gt;Indexes are models: a B-Tree-Index can be seen as a model to map a key to the
position of a record within a sorted array, a Hash-Index as a model to map a
key to a position of a record within an unsorted array, and a BitMap-Index as a
model to indicate if a data record exists or not. In this exploratory research
paper, we start from this premise and posit that all existing index structures
can be replaced with other types of models, including deep-learning models,
which we term learned indexes. The key idea is that a model can learn the sort
order or structure of lookup keys and use this signal to effectively predict
the position or existence of records. We theoretically analyze under which
conditions learned indexes outperform traditional index structures and describe
the main challenges in designing learned index structures. Our initial results
show, that by using neural nets we are able to outperform cache-optimized
B-Trees by up to 70% in speed while saving an order-of-magnitude in memory over
several real-world data sets. More importantly though, we believe that the idea
of replacing core components of a data management system through learned models
has far reaching implications for future systems designs and that this work
just provides a glimpse of what might be possible.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kraska_T/0/1/0/all/0/1&quot;&gt;Tim Kraska&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Beutel_A/0/1/0/all/0/1&quot;&gt;Alex Beutel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chi_E/0/1/0/all/0/1&quot;&gt;Ed H. Chi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dean_J/0/1/0/all/0/1&quot;&gt;Jeffrey Dean&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Polyzotis_N/0/1/0/all/0/1&quot;&gt;Neoklis Polyzotis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.02779">
<title>A Rotation and a Translation Suffice: Fooling CNNs with Simple Transformations. (arXiv:1712.02779v2 [cs.LG] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1712.02779</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent work has shown that neural network-based vision classifiers exhibit a
significant vulnerability to misclassifications caused by imperceptible but
adversarial perturbations of their inputs. These perturbations, however, are
purely pixel-wise and built out of loss function gradients of either the
attacked model or its surrogate. As a result, they tend to be contrived and
look pretty artificial. This might suggest that such vulnerability to slight
input perturbations can only arise in a truly adversarial setting and thus is
unlikely to be an issue in more &quot;natural&quot; contexts.
&lt;/p&gt;
&lt;p&gt;In this paper, we provide evidence that such belief might be incorrect. We
demonstrate that significantly simpler, and more likely to occur naturally,
transformations of the input - namely, rotations and translations alone,
suffice to significantly degrade the classification performance of neural
network-based vision models across a spectrum of datasets. This remains to be
the case even when these models are trained using appropriate data
augmentation. Finding such &quot;fooling&quot; transformations does not require having
any special access to the model - just trying out a small number of random
rotation and translation combinations already has a significant effect. These
findings suggest that our current neural network-based vision models might not
be as reliable as we tend to assume.
&lt;/p&gt;
&lt;p&gt;Finally, we consider a new class of perturbations that combines rotations and
translations with the standard pixel-wise attacks. We observe that these two
types of input transformations are, in a sense, orthogonal to each other. Their
effect on the performance of the model seems to be additive, while robustness
to one type does not seem to affect the robustness to the other type. This
suggests that this combined class of transformations is a more complete notion
of similarity in the context of adversarial robustness of vision models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Engstrom_L/0/1/0/all/0/1&quot;&gt;Logan Engstrom&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tsipras_D/0/1/0/all/0/1&quot;&gt;Dimitris Tsipras&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schmidt_L/0/1/0/all/0/1&quot;&gt;Ludwig Schmidt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Madry_A/0/1/0/all/0/1&quot;&gt;Aleksander Madry&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.04008">
<title>Investigation on How Data Volume Affects Transfer Learning Performances in Business Applications. (arXiv:1712.04008v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1712.04008</link>
<description rdf:parseType="Literal">&lt;p&gt;Transfer Learning helps to build a system to recognize and apply knowledge
and experience learned in previous tasks (source task) to new tasks or new
domains (target task), which share some commonality. The two important factors
that impact the performance of transfer learning models are: (a) the size of
the target dataset and (b) the similarity in distribution between source and
target domains. Thus far there has been little investigation into just how
important these factors are. In this paper, we investigated the impact of
target dataset size and source/target domain similarity on model performance
through a series of experiments. We found that more data is always beneficial,
and that model performance improved linearly with the log of data size, until
we were out of data. As source/target domains differ, more data is required and
fine tuning will render better performance than feature extraction. When
source/target domains are similar and data size is small, fine tuning and
feature extraction renders equivalent performance. We hope that our study
inspires further work in transfer learning, which continues to be a very
important technique for developing practical machine learning applications in
business domains.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bernico_M/0/1/0/all/0/1&quot;&gt;Michael Bernico&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yuntao Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1&quot;&gt;Dingchao Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.04020">
<title>Detecting Qualia in Natural and Artificial Agents. (arXiv:1712.04020v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1712.04020</link>
<description rdf:parseType="Literal">&lt;p&gt;The Hard Problem of consciousness has been dismissed as an illusion. By
showing that computers are capable of experiencing, we show that they are at
least rudimentarily conscious with potential to eventually reach
superconsciousness. The main contribution of the paper is a test for confirming
certain subjective experiences in a tested agent. We follow with analysis of
benefits and problems with conscious machines and implications of such
capability on future of computing, machine rights and artificial intelligence
safety.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yampolskiy_R/0/1/0/all/0/1&quot;&gt;Roman V. Yampolskiy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.04065">
<title>The Eigenoption-Critic Framework. (arXiv:1712.04065v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1712.04065</link>
<description rdf:parseType="Literal">&lt;p&gt;Eigenoptions (EOs) have been recently introduced as a promising idea for
generating a diverse set of options through the graph Laplacian, having been
shown to allow efficient exploration. Despite its initial promising results, a
couple of issues in current algorithms limit its application, namely: (1) EO
methods require two separate steps (eigenoption discovery and reward
maximization) to learn a control policy, which can incur a significant amount
of storage and computation; (2) EOs are only defined for problems with discrete
state-spaces and; (3) it is not easy to take the environment&apos;s reward function
into consideration when discovering EOs. To addresses these issues, we
introduce an algorithm termed eigenoption-critic (EOC) based on the
Option-critic (OC) framework [Bacon17], a general hierarchical reinforcement
learning (RL) algorithm that allows learning the intra-option policies
simultaneously with the policy over options. We also propose a generalization
of EOC to problems with continuous state-spaces through the Nystr\&quot;om
approximation. EOC can also be seen as extending OC to nonstationary settings,
where the discovered options are not tailored for a single task.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1&quot;&gt;Miao Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Machado_M/0/1/0/all/0/1&quot;&gt;Marlos C. Machado&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tesauro_G/0/1/0/all/0/1&quot;&gt;Gerald Tesauro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Campbell_M/0/1/0/all/0/1&quot;&gt;Murray Campbell&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.04076">
<title>In a Nutshell: Sequential Parameter Optimization. (arXiv:1712.04076v1 [cs.MS])</title>
<link>http://arxiv.org/abs/1712.04076</link>
<description rdf:parseType="Literal">&lt;p&gt;The performance of optimization algorithms relies crucially on their
parameterizations. Finding good parameter settings is called algorithm tuning.
Using a simple simulated annealing algorithm, we will demonstrate how
optimization algorithms can be tuned using the sequential parameter
optimization toolbox (SPOT). SPOT provides several tools for automated and
interactive tuning. The underling concepts of the SPOT approach are explained.
This includes key techniques such as exploratory fitness landscape analysis and
response surface methodology. Many examples illustrate how SPOT can be used for
understanding the performance of algorithms and gaining insight into
algorithm&apos;s behavior. Furthermore, we demonstrate how SPOT can be used as an
optimizer and how a sophisticated ensemble approach is able to combine several
meta models via stacking.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bartz_Beielstein_T/0/1/0/all/0/1&quot;&gt;Thomas Bartz-Beielstein&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gentile_L/0/1/0/all/0/1&quot;&gt;Lorenzo Gentile&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zaefferer_M/0/1/0/all/0/1&quot;&gt;Martin Zaefferer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.04143">
<title>RESIDE: A Benchmark for Single Image Dehazing. (arXiv:1712.04143v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1712.04143</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we present a comprehensive study and evaluation of existing
single image dehazing algorithms, using a new large-scale benchmark consisting
of both synthetic and real-world hazy images, called REalistic Single Image
DEhazing (RESIDE). RESIDE highlights diverse data sources and image contents,
and is divided into five subsets, each serving different training or evaluation
purposes. We further provide a rich variety of criteria for dehazing algorithm
evaluation, ranging from full-reference metrics, to no-reference metrics, to
subjective evaluation and the novel task-driven evaluation. Experiments on
RESIDE sheds light on the comparisons and limitations of state-of-the-art
dehazing algorithms, and suggest promising future directions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1&quot;&gt;Boyi Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ren_W/0/1/0/all/0/1&quot;&gt;Wenqi Ren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fu_D/0/1/0/all/0/1&quot;&gt;Dengpan Fu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1&quot;&gt;Dacheng Tao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feng_D/0/1/0/all/0/1&quot;&gt;Dan Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zeng_W/0/1/0/all/0/1&quot;&gt;Wenjun Zeng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zhangyang Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.04155">
<title>Toward `verifying&apos; a Water Treatment System. (arXiv:1712.04155v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1712.04155</link>
<description rdf:parseType="Literal">&lt;p&gt;Modeling and verifying real-world cyber-physical systems are challenging,
especially so for complex systems where manually modeling is infeasible. In
this work, we report our experience on combining model learning and abstraction
refinement to analyze a challenging system, i.e., a real-world Secure Water
Treatment (SWaT) system. Given a set of safety requirements, the objective is
to either show that the system is safe with a high probability (so that a
system shutdown is rarely triggered due to safety violation) or otherwise. As
the system is too complicated to be manually modelled, we apply latest
automatic model learning techniques to construct a set of Markov chains through
abstraction and refinement, based on two long system execution logs (one for
training and the other for testing). For each probabilistic property, we either
report it does not hold with a certain level of probabilistic confidence, or
report that it holds by showing the evidence in the form of an abstract Markov
chain. The Markov chains can subsequently be implemented as runtime monitors in
SWaT. This is the first case study of applying model learning techniques to a
real-world system as far as we know.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jingyi Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1&quot;&gt;Jun Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jia_Y/0/1/0/all/0/1&quot;&gt;Yifan Jia&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.04159">
<title>Mining Non-Redundant Sets of Generalizing Patterns from Sequence Databases. (arXiv:1712.04159v1 [cs.DS])</title>
<link>http://arxiv.org/abs/1712.04159</link>
<description rdf:parseType="Literal">&lt;p&gt;Sequential pattern mining techniques extract patterns corresponding to
frequent subsequences from a sequence database. A practical limitation of these
techniques is that they overload the user with too many patterns. Local Process
Model (LPM) mining is an alternative approach coming from the field of process
mining. While in traditional sequential pattern mining, a pattern describes one
subsequence, an LPM captures a set of subsequences. Also, while traditional
sequential patterns only match subsequences that are observed in the sequence
database, an LPM may capture subsequences that are not explicitly observed, but
that are related to observed subsequences. In other words, LPMs generalize the
behavior observed in the sequence database. These properties make it possible
for a set of LPMs to cover the behavior of a much larger set of sequential
patterns. Yet, existing LPM mining techniques still suffer from the pattern
explosion problem because they produce sets of redundant LPMs. In this paper,
we propose several heuristics to mine a set of non-redundant LPMs either from a
set of redundant LPMs or from a set of sequential patterns. We empirically
compare the proposed heuristics between them and against existing (local)
process mining techniques in terms of coverage, precision, and complexity of
the produced sets of LPMs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tax_N/0/1/0/all/0/1&quot;&gt;Niek Tax&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dumas_M/0/1/0/all/0/1&quot;&gt;Marlon Dumas&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.04172">
<title>A Low-Cost Ethics Shaping Approach for Designing Reinforcement Learning Agents. (arXiv:1712.04172v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1712.04172</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper proposes a low-cost, easily realizable strategy to equip a
reinforcement learning (RL) agent the capability of behaving ethically. Our
model allows the designers of RL agents to solely focus on the task to achieve,
without having to worry about the implementation of multiple trivial ethical
patterns to follow. Based on the assumption that the majority of human
behavior, regardless which goals they are achieving, is ethical, our design
integrates human policy with the RL policy to achieve the target objective with
less chance of violating the ethical code that human beings normally obey.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1&quot;&gt;Yueh-Hua Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_S/0/1/0/all/0/1&quot;&gt;Shou-De Lin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.04182">
<title>Contradiction-Centricity: A Uniform Model for Formation of Swarm Intelligence and its Simulations. (arXiv:1712.04182v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1712.04182</link>
<description rdf:parseType="Literal">&lt;p&gt;It is a grand challenge to model the emergence of swarm intelligence and many
principles or models had been proposed. However, existing models do not catch
the nature of swarm intelligence and they are not generic enough to describe
various types of emergence phenomena. In this work, we propose a
contradiction-centric model for emergence of swarm intelligence, in which
individuals&apos; contradictions dominate their appearances whilst they are
associated and interacting to update their contradictions. This model
hypothesizes that 1) the emergence of swarm intelligence is rooted in the
development of contradictions of individuals and the interactions among
associated individuals and 2) swarm intelligence is essentially a combinative
reflection of the configurations of contradictions inside individuals and the
distributions of contradictions among individuals. To verify the feasibility of
the model, we simulate four types of swarm intelligence. As the simulations
show, our model is truly generic and can describe the emergence of a variety of
swarm intelligence, and it is also very simple and can be easily applied to
demonstrate the emergence of swarm intelligence without needing complicated
computations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiao_W/0/1/0/all/0/1&quot;&gt;Wenpin Jiao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.04301">
<title>Deep Learning for IoT Big Data and Streaming Analytics: A Survey. (arXiv:1712.04301v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1712.04301</link>
<description rdf:parseType="Literal">&lt;p&gt;In the era of the Internet of Things (IoT), an enormous amount of sensing
devices collect and/or generate various sensory data over time for a wide range
of fields and applications. Based on the nature of the application, these
devices will result in big or fast/real-time data streams. Applying analytics
over such data streams to discover new information, predict future insights,
and make control decisions is a crucial process that makes IoT a worthy
paradigm for businesses and a quality-of-life improving technology. In this
paper, we provide a thorough overview on using a class of advanced machine
learning techniques, namely Deep Learning (DL), to facilitate the analytics and
learning in the IoT domain. We start by articulating IoT data characteristics
and identifying two major treatments for IoT data from a machine learning
perspective, namely IoT big data analytics and IoT streaming data analytics. We
also discuss why DL is a promising approach to achieve the desired analytics in
these types of data and applications. The potential of using emerging DL
techniques for IoT data analytics are then discussed, and its promises and
challenges are introduced. We present a comprehensive background on different
DL architectures and algorithms. We also analyze and summarize major reported
research attempts that leveraged DL in the IoT domain. The smart IoT devices
that have incorporated DL in their intelligence background are also discussed.
DL implementation approaches on the fog and cloud centers in support of IoT
applications are also surveyed. Finally, we shed light on some challenges and
potential directions for future research. At the end of each section, we
highlight the lessons learned based on our experiments and review of the recent
literature.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mohammadi_M/0/1/0/all/0/1&quot;&gt;Mehdi Mohammadi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Al_Fuqaha_A/0/1/0/all/0/1&quot;&gt;Ala Al-Fuqaha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sorour_S/0/1/0/all/0/1&quot;&gt;Sameh Sorour&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guizani_M/0/1/0/all/0/1&quot;&gt;Mohsen Guizani&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.04306">
<title>In folly ripe. In reason rotten. Putting machine theology to rest. (arXiv:1712.04306v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1712.04306</link>
<description rdf:parseType="Literal">&lt;p&gt;Computation has changed the world more than any previous expressions of
knowledge. In its particular algorithmic embodiment, it offers a perspective,
within which the digital computer (one of many possible) exercises a role
reminiscent of theology. Since it is closed to meaning, algorithmic digital
computation can at most mimic the creative aspects of life. AI, in the
perspective of time, proved to be less an acronym for artificial intelligence
and more of automating tasks associated with intelligence. The entire
development led to the hypostatized role of the machine: outputting nothing
else but reality, including that of the humanity that made the machine happen.
The convergence machine called deep learning is only the latest form through
which the deterministic theology of the machine claims more than what extremely
effective data processing actually is. A new understanding of complexity, as
well as the need to distinguish between the reactive nature of the artificial
and the anticipatory nature of the living are suggested as practical responses
to the challenges posed by machine theology.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nadin_M/0/1/0/all/0/1&quot;&gt;Mihai Nadin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.04307">
<title>AI Safety and Reproducibility: Establishing Robust Foundations for the Neuroscience of Human Values. (arXiv:1712.04307v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1712.04307</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose the creation of a systematic effort to identify and replicate key
findings in neuroscience and allied fields related to understanding human
values. Our aim is to ensure that research underpinning the value alignment
problem of artificial intelligence has been sufficiently validated to play a
role in the design of AI systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sarma_G/0/1/0/all/0/1&quot;&gt;Gopal P. Sarma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hay_N/0/1/0/all/0/1&quot;&gt;Nick J. Hay&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Safron_A/0/1/0/all/0/1&quot;&gt;Adam Safron&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.04323">
<title>Deep Echo State Network (DeepESN): A Brief Survey. (arXiv:1712.04323v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1712.04323</link>
<description rdf:parseType="Literal">&lt;p&gt;The study of deep recurrent neural networks (RNNs) and, in particular, of
deep Reservoir Computing (RC) is gaining an increasing research attention in
the neural networks community. The recently introduced deep Echo State Network
(deepESN) model opened the way to an extremely efficient approach for designing
deep neural networks for temporal data. At the same time, the study of deepESNs
allowed to shed light on the intrinsic properties of state dynamics developed
by hierarchical compositions of recurrent layers, i.e. on the bias of depth in
RNNs architectural design. In this paper, we summarize the advancements in the
development, analysis and applications of deepESNs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gallicchio_C/0/1/0/all/0/1&quot;&gt;Claudio Gallicchio&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Micheli_A/0/1/0/all/0/1&quot;&gt;Alessio Micheli&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.04363">
<title>Simulated Autonomous Driving on Realistic Road Networks using Deep Reinforcement Learning. (arXiv:1712.04363v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1712.04363</link>
<description rdf:parseType="Literal">&lt;p&gt;Using Deep Reinforcement Learning (DRL) can be a promising approach to handle
tasks in the field of (simulated) autonomous driving, whereby recent
publications only consider learning in unusual driving environments. This paper
outlines a developed software, which instead can be used for evaluating DRL
algorithms based on realistic road networks and therefore in more usual driving
environments. Furthermore, we identify difficulties when DRL algorithms are
applied to tasks, in which it is not only important to reach a goal, but also
how this goal is reached. We conclude this paper by presenting the results of
an application of a new DRL algorithm, which can partly solve these problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Klose_P/0/1/0/all/0/1&quot;&gt;Patrick Klose&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mester_R/0/1/0/all/0/1&quot;&gt;Rudolf Mester&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.04386">
<title>Hawkes Processes for Invasive Species Modeling and Management. (arXiv:1712.04386v1 [q-bio.PE])</title>
<link>http://arxiv.org/abs/1712.04386</link>
<description rdf:parseType="Literal">&lt;p&gt;The spread of invasive species to new areas threatens the stability of
ecosystems and causes major economic losses in agriculture and forestry. We
propose a novel approach to minimizing the spread of an invasive species given
a limited intervention budget. We first model invasive species propagation
using Hawkes processes, and then derive closed-form expressions for
characterizing the effect of an intervention action on the invasion process. We
use this to obtain an optimal intervention plan based on an integer programming
formulation, and compare the optimal plan against several
ecologically-motivated heuristic strategies used in practice. We present an
empirical study of two variants of the invasive control problem: minimizing the
final rate of invasions, and minimizing the number of invasions at the end of a
given time horizon. Our results show that the optimized intervention achieves
nearly the same level of control that would be attained by completely
eradicating the species, with a 20% cost saving. Additionally, we design a
heuristic intervention strategy based on a combination of the density and life
stage of the invasive individuals, and find that it comes surprisingly close to
the optimized strategy, suggesting that this could serve as a good rule of
thumb in invasive species management.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Gupta_A/0/1/0/all/0/1&quot;&gt;Amrita Gupta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Farajtabar_M/0/1/0/all/0/1&quot;&gt;Mehrdad Farajtabar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Dilkina_B/0/1/0/all/0/1&quot;&gt;Bistra Dilkina&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Zha_H/0/1/0/all/0/1&quot;&gt;Hongyuan Zha&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.04402">
<title>Android Malware Characterization using Metadata and Machine Learning Techniques. (arXiv:1712.04402v1 [cs.CR])</title>
<link>http://arxiv.org/abs/1712.04402</link>
<description rdf:parseType="Literal">&lt;p&gt;Android Malware has emerged as a consequence of the increasing popularity of
smartphones and tablets. While most previous work focuses on inherent
characteristics of Android apps to detect malware, this study analyses indirect
features and meta-data to identify patterns in malware applications. Our
experiments show that: (1) the permissions used by an application offer only
moderate performance results; (2) other features publicly available at Android
Markets are more relevant in detecting malware, such as the application
developer and certificate issuer, and (3) compact and efficient classifiers can
be constructed for the early detection of malware applications prior to code
inspection or sandboxing.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Martin_I/0/1/0/all/0/1&quot;&gt;Ignacio Mart&amp;#xed;n&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hernandez_J/0/1/0/all/0/1&quot;&gt;Jos&amp;#xe9; Alberto Hern&amp;#xe1;ndez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Munoz_A/0/1/0/all/0/1&quot;&gt;Alfonso Mu&amp;#xf1;oz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guzman_A/0/1/0/all/0/1&quot;&gt;Antonio Guzm&amp;#xe1;n&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.04415">
<title>Deception Detection in Videos. (arXiv:1712.04415v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1712.04415</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a system for covert automated deception detection in real-life
courtroom trial videos. We study the importance of different modalities like
vision, audio and text for this task. On the vision side, our system uses
classifiers trained on low level video features which predict human
micro-expressions. We show that predictions of high-level micro-expressions can
be used as features for deception prediction. Surprisingly, IDT (Improved Dense
Trajectory) features which have been widely used for action recognition, are
also very good at predicting deception in videos. We fuse the score of
classifiers trained on IDT features and high-level micro-expressions to improve
performance. MFCC (Mel-frequency Cepstral Coefficients) features from the audio
domain also provide a significant boost in performance, while information from
transcripts is not very beneficial for our system. Using various classifiers,
our automated system obtains an AUC of 0.877 (10-fold cross-validation) when
evaluated on subjects which were not part of the training set. Even though
state-of-the-art methods use human annotations of micro-expressions for
deception detection, our fully automated approach outperforms them by 5%. When
combined with human annotations of micro-expressions, our AUC improves to
0.922. We also present results of a user-study to analyze how well do average
humans perform on this task, what modalities they use for deception detection
and how they perform if only one modality is accessible. Our project page can
be found at \url{https://doubaibai.github.io/DARE/}.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1&quot;&gt;Zhe Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singh_B/0/1/0/all/0/1&quot;&gt;Bharat Singh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Davis_L/0/1/0/all/0/1&quot;&gt;Larry S. Davis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Subrahmanian_V/0/1/0/all/0/1&quot;&gt;V. S. Subrahmanian&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1610.04213">
<title>Reset-free Trial-and-Error Learning for Robot Damage Recovery. (arXiv:1610.04213v4 [cs.RO] UPDATED)</title>
<link>http://arxiv.org/abs/1610.04213</link>
<description rdf:parseType="Literal">&lt;p&gt;The high probability of hardware failures prevents many advanced robots
(e.g., legged robots) from being confidently deployed in real-world situations
(e.g., post-disaster rescue). Instead of attempting to diagnose the failures,
robots could adapt by trial-and-error in order to be able to complete their
tasks. In this situation, damage recovery can be seen as a Reinforcement
Learning (RL) problem. However, the best RL algorithms for robotics require the
robot and the environment to be reset to an initial state after each episode,
that is, the robot is not learning autonomously. In addition, most of the RL
methods for robotics do not scale well with complex robots (e.g., walking
robots) and either cannot be used at all or take too long to converge to a
solution (e.g., hours of learning). In this paper, we introduce a novel
learning algorithm called &quot;Reset-free Trial-and-Error&quot; (RTE) that (1) breaks
the complexity by pre-generating hundreds of possible behaviors with a dynamics
simulator of the intact robot, and (2) allows complex robots to quickly recover
from damage while completing their tasks and taking the environment into
account. We evaluate our algorithm on a simulated wheeled robot, a simulated
six-legged robot, and a real six-legged walking robot that are damaged in
several ways (e.g., a missing leg, a shortened leg, faulty motor, etc.) and
whose objective is to reach a sequence of targets in an arena. Our experiments
show that the robots can recover most of their locomotion abilities in an
environment with obstacles, and without any human intervention.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chatzilygeroudis_K/0/1/0/all/0/1&quot;&gt;Konstantinos Chatzilygeroudis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vassiliades_V/0/1/0/all/0/1&quot;&gt;Vassilis Vassiliades&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mouret_J/0/1/0/all/0/1&quot;&gt;Jean-Baptiste Mouret&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1705.08690">
<title>Continual Learning with Deep Generative Replay. (arXiv:1705.08690v3 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1705.08690</link>
<description rdf:parseType="Literal">&lt;p&gt;Attempts to train a comprehensive artificial intelligence capable of solving
multiple tasks have been impeded by a chronic problem called catastrophic
forgetting. Although simply replaying all previous data alleviates the problem,
it requires large memory and even worse, often infeasible in real world
applications where the access to past data is limited. Inspired by the
generative nature of hippocampus as a short-term memory system in primate
brain, we propose the Deep Generative Replay, a novel framework with a
cooperative dual model architecture consisting of a deep generative model
(&quot;generator&quot;) and a task solving model (&quot;solver&quot;). With only these two models,
training data for previous tasks can easily be sampled and interleaved with
those for a new task. We test our methods in several sequential learning
settings involving image classification tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shin_H/0/1/0/all/0/1&quot;&gt;Hanul Shin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1&quot;&gt;Jung Kwon Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1&quot;&gt;Jaehong Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1&quot;&gt;Jiwon Kim&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1708.06374">
<title>On a Formal Model of Safe and Scalable Self-driving Cars. (arXiv:1708.06374v3 [cs.RO] UPDATED)</title>
<link>http://arxiv.org/abs/1708.06374</link>
<description rdf:parseType="Literal">&lt;p&gt;In recent years, car makers and tech companies have been racing towards self
driving cars. It seems that the main parameter in this race is who will have
the first car on the road. The goal of this paper is to add to the equation two
additional crucial parameters. The first is standardization of safety assurance
--- what are the minimal requirements that every self-driving car must satisfy,
and how can we verify these requirements. The second parameter is scalability
--- engineering solutions that lead to unleashed costs will not scale to
millions of cars, which will push interest in this field into a niche academic
corner, and drive the entire field into a &quot;winter of autonomous driving&quot;. In
the first part of the paper we propose a white-box, interpretable, mathematical
model for safety assurance, which we call Responsibility-Sensitive Safety
(RSS). In the second part we describe a design of a system that adheres to our
safety assurance requirements and is scalable to millions of cars.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shalev_Shwartz_S/0/1/0/all/0/1&quot;&gt;Shai Shalev-Shwartz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shammah_S/0/1/0/all/0/1&quot;&gt;Shaked Shammah&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shashua_A/0/1/0/all/0/1&quot;&gt;Amnon Shashua&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.10445">
<title>Synonym Discovery with Etymology-based Word Embeddings. (arXiv:1709.10445v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1709.10445</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a novel approach to learn word embeddings based on an extended
version of the distributional hypothesis. Our model derives word embedding
vectors using the etymological composition of words, rather than the context in
which they appear. It has the strength of not requiring a large text corpus,
but instead it requires reliable access to etymological roots of words, making
it specially fit for languages with logographic writing systems. The model
consists on three steps: (1) building an etymological graph, which is a
bipartite network of words and etymological roots, (2) obtaining the
biadjacency matrix of the etymological graph and reducing its dimensionality,
(3) using columns/rows of the resulting matrices as embedding vectors. We test
our model in the Chinese and Sino-Korean vocabularies. Our graphs are formed by
a set of 117,000 Chinese words, and a set of 135,000 Sino-Korean words. In both
cases we show that our model performs well in the task of synonym discovery.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yoon_S/0/1/0/all/0/1&quot;&gt;Seunghyun Yoon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Estrada_P/0/1/0/all/0/1&quot;&gt;Pablo Estrada&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jung_K/0/1/0/all/0/1&quot;&gt;Kyomin Jung&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.07735">
<title>ADA: A Game-Theoretic Perspective on Data Augmentation for Object Detection. (arXiv:1710.07735v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1710.07735</link>
<description rdf:parseType="Literal">&lt;p&gt;The use of random perturbations of ground truth data, such as random
translation or scaling of bounding boxes, is a common heuristic used for data
augmentation that has been shown to prevent overfitting and improve
generalization. Since the design of data augmentation is largely guided by
reported best practices, it is difficult to understand if those design choices
are optimal. To provide a more principled perspective, we develop a
game-theoretic interpretation of data augmentation in the context of object
detection. We aim to find an optimal adversarial perturbations of the ground
truth data (i.e., the worst case perturbations) that forces the object bounding
box predictor to learn from the hardest distribution of perturbed examples for
better test-time performance. We establish that the game theoretic solution,
the Nash equilibrium, provides both an optimal predictor and optimal data
augmentation distribution. We show that our adversarial method of training a
predictor can significantly improve test time performance for the task of
object detection. On the ImageNet object detection task, our adversarial
approach improves performance by over 16\% compared to the best performing data
augmentation method
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Behpour_S/0/1/0/all/0/1&quot;&gt;Sima Behpour&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kitani_K/0/1/0/all/0/1&quot;&gt;Kris M. Kitani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ziebart_B/0/1/0/all/0/1&quot;&gt;Brian D. Ziebart&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.07425">
<title>Modular Continual Learning in a Unified Visual Environment. (arXiv:1711.07425v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1711.07425</link>
<description rdf:parseType="Literal">&lt;p&gt;A core aspect of human intelligence is the ability to learn new tasks quickly
and switch between them flexibly. Here, we describe a modular continual
reinforcement learning paradigm inspired by these abilities. We first introduce
a visual interaction environment that allows many types of tasks to be unified
in a single framework. We then describe a reward map prediction scheme that
learns new tasks robustly in the very large state and action spaces required by
such an environment. We investigate how properties of module architecture
influence efficiency of task learning, showing that a module motif
incorporating specific design principles (e.g. early bottlenecks, low-order
polynomial nonlinearities, and symmetry) significantly outperforms more
standard neural network motifs, needing fewer training examples and fewer
neurons to achieve high levels of performance. Finally, we present a
meta-controller architecture for task switching based on a dynamic neural
voting scheme, which allows new modules to use information learned from
previously-seen tasks to substantially improve their own learning efficiency.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feigelis_K/0/1/0/all/0/1&quot;&gt;Kevin T. Feigelis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sheffer_B/0/1/0/all/0/1&quot;&gt;Blue Sheffer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yamins_D/0/1/0/all/0/1&quot;&gt;Daniel L. K. Yamins&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.08345">
<title>Allocation Problems in Ride-Sharing Platforms: Online Matching with Offline Reusable Resources. (arXiv:1711.08345v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1711.08345</link>
<description rdf:parseType="Literal">&lt;p&gt;Bipartite matching markets pair agents on one side of a market with agents,
items, or contracts on the opposing side. Prior work addresses online bipartite
matching markets, where agents arrive over time and are dynamically matched to
a known set of disposable resources. In this paper, we propose a new model,
Online Matching with (offline) Reusable Resources under Known Adversarial
Distributions (OM-RR-KAD), in which resources on the offline side are reusable
instead of disposable; that is, once matched, resources become available again
at some point in the future. We show that our model is tractable by presenting
an LP-based adaptive algorithm that achieves an online competitive ratio of 1/2
- eps for any given eps greater than 0. We also show that no non-adaptive
algorithm can achieve a ratio of 1/2 + o(1) based on the same benchmark LP.
Through a data-driven analysis on a massive openly-available dataset, we show
our model is robust enough to capture the application of taxi dispatching
services and ride-sharing systems. We also present heuristics that perform well
in practice.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dickerson_J/0/1/0/all/0/1&quot;&gt;John P Dickerson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sankararaman_K/0/1/0/all/0/1&quot;&gt;Karthik A Sankararaman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Srinivasan_A/0/1/0/all/0/1&quot;&gt;Aravind Srinivasan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_P/0/1/0/all/0/1&quot;&gt;Pan Xu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.03890">
<title>DeepConfig: Automating Data Center Network Topologies Management with Machine Learning. (arXiv:1712.03890v1 [cs.NI] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1712.03890</link>
<description rdf:parseType="Literal">&lt;p&gt;In recent years, many techniques have been developed to improve the
performance and efficiency of data center networks. While these techniques
provide high accuracy, they are often designed using heuristics that leverage
domain-specific properties of the workload or hardware.
&lt;/p&gt;
&lt;p&gt;In this vision paper, we argue that many data center networking techniques,
e.g., routing, topology augmentation, energy savings, with diverse goals
actually share design and architectural similarity. We present a design for
developing general intermediate representations of network topologies using
deep learning that is amenable to solving classes of data center problems. We
develop a framework, DeepConfig, that simplifies the processing of configuring
and training deep learning agents that use the intermediate representation to
learns different tasks. To illustrate the strength of our approach, we
configured, implemented, and evaluated a DeepConfig-Agent that tackles the data
center topology augmentation problem. Our initial results are promising ---
DeepConfig performs comparably to the optimal.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Streiffer_C/0/1/0/all/0/1&quot;&gt;Christopher Streiffer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1&quot;&gt;Huan Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Benson_T/0/1/0/all/0/1&quot;&gt;Theophilus Benson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kadav_A/0/1/0/all/0/1&quot;&gt;Asim Kadav&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.03999">
<title>Eye In-Painting with Exemplar Generative Adversarial Networks. (arXiv:1712.03999v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1712.03999</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper introduces a novel approach to in-painting where the identity of
the object to remove or change is preserved and accounted for at inference
time: Exemplar GANs (ExGANs). ExGANs are a type of conditional GAN that utilize
exemplar information to produce high-quality, personalized in painting results.
We propose using exemplar information in the form of a reference image of the
region to in-paint, or a perceptual code describing that object. Unlike
previous conditional GAN formulations, this extra information can be inserted
at multiple points within the adversarial network, thus increasing its
descriptive power. We show that ExGANs can produce photo-realistic personalized
in-painting results that are both perceptually and semantically plausible by
applying them to the task of closed to-open eye in-painting in natural
pictures. A new benchmark dataset is also introduced for the task of eye
in-painting for future comparisons.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dolhansky_B/0/1/0/all/0/1&quot;&gt;Brian Dolhansky&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ferrer_C/0/1/0/all/0/1&quot;&gt;Cristian Canton Ferrer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.04046">
<title>Attention networks for image-to-text. (arXiv:1712.04046v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1712.04046</link>
<description rdf:parseType="Literal">&lt;p&gt;The paper approaches the problem of image-to-text with attention-based
encoder-decoder networks that are trained to handle sequences of characters
rather than words. We experiment on lines of text from a popular handwriting
database with different attention mechanisms for the decoder. The model trained
with softmax attention achieves the lowest test error, outperforming several
other RNN-based models. Our results show that softmax attention is able to
learn a linear alignment whereas the alignment generated by sigmoid attention
is linear but much less precise.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Poulos_J/0/1/0/all/0/1&quot;&gt;Jason Poulos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Valle_R/0/1/0/all/0/1&quot;&gt;Rafael Valle&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.04086">
<title>PacGAN: The power of two samples in generative adversarial networks. (arXiv:1712.04086v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1712.04086</link>
<description rdf:parseType="Literal">&lt;p&gt;Generative adversarial networks (GANs) are innovative techniques for learning
generative models of complex data distributions from samples. Despite
remarkable recent improvements in generating realistic images, one of their
major shortcomings is the fact that in practice, they tend to produce samples
with little diversity, even when trained on diverse datasets. This phenomenon,
known as mode collapse, has been the main focus of several recent advances in
GANs. Yet there is little understanding of why mode collapse happens and why
existing approaches are able to mitigate mode collapse. We propose a principled
approach to handling mode collapse, which we call packing. The main idea is to
modify the discriminator to make decisions based on multiple samples from the
same class, either real or artificially generated. We borrow analysis tools
from binary hypothesis testing---in particular the seminal result of Blackwell
[Bla53]---to prove a fundamental connection between packing and mode collapse.
We show that packing naturally penalizes generators with mode collapse, thereby
favoring generator distributions with less mode collapse during the training
process. Numerical experiments on benchmark datasets suggests that packing
provides significant improvements in practice as well.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1&quot;&gt;Zinan Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khetan_A/0/1/0/all/0/1&quot;&gt;Ashish Khetan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fanti_G/0/1/0/all/0/1&quot;&gt;Giulia Fanti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oh_S/0/1/0/all/0/1&quot;&gt;Sewoong Oh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.04120">
<title>GibbsNet: Iterative Adversarial Inference for Deep Graphical Models. (arXiv:1712.04120v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1712.04120</link>
<description rdf:parseType="Literal">&lt;p&gt;Directed latent variable models that formulate the joint distribution as
$p(x,z) = p(z) p(x \mid z)$ have the advantage of fast and exact sampling.
However, these models have the weakness of needing to specify $p(z)$, often
with a simple fixed prior that limits the expressiveness of the model.
Undirected latent variable models discard the requirement that $p(z)$ be
specified with a prior, yet sampling from them generally requires an iterative
procedure such as blocked Gibbs-sampling that may require many steps to draw
samples from the joint distribution $p(x, z)$. We propose a novel approach to
learning the joint distribution between the data and a latent code which uses
an adversarially learned iterative procedure to gradually refine the joint
distribution, $p(x, z)$, to better match with the data distribution on each
step. GibbsNet is the best of both worlds both in theory and in practice.
Achieving the speed and simplicity of a directed latent variable model, it is
guaranteed (assuming the adversarial game reaches the virtual training criteria
global minimum) to produce samples from $p(x, z)$ with only a few sampling
iterations. Achieving the expressiveness and flexibility of an undirected
latent variable model, GibbsNet does away with the need for an explicit $p(z)$
and has the ability to do attribute prediction, class-conditional generation,
and joint image-attribute modeling in a single model which is not trained for
any of these specific tasks. We show empirically that GibbsNet is able to learn
a more complex $p(z)$ and show that this leads to improved inpainting and
iterative refinement of $p(x, z)$ for dozens of steps and stable generation
without collapse for thousands of steps, despite being trained on only a few
steps.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lamb_A/0/1/0/all/0/1&quot;&gt;Alex Lamb&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hjelm_D/0/1/0/all/0/1&quot;&gt;Devon Hjelm&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ganin_Y/0/1/0/all/0/1&quot;&gt;Yaroslav Ganin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Cohen_J/0/1/0/all/0/1&quot;&gt;Joseph Paul Cohen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Courville_A/0/1/0/all/0/1&quot;&gt;Aaron Courville&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bengio_Y/0/1/0/all/0/1&quot;&gt;Yoshua Bengio&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.04129">
<title>Outlier Detection by Consistent Data Selection Method. (arXiv:1712.04129v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1712.04129</link>
<description rdf:parseType="Literal">&lt;p&gt;Often the challenge associated with tasks like fraud and spam detection[1] is
the lack of all likely patterns needed to train suitable supervised learning
models. In order to overcome this limitation, such tasks are attempted as
outlier or anomaly detection tasks. We also hypothesize that out- liers have
behavioral patterns that change over time. Limited data and continuously
changing patterns makes learning significantly difficult. In this work we are
proposing an approach that detects outliers in large data sets by relying on
data points that are consistent. The primary contribution of this work is that
it will quickly help retrieve samples for both consistent and non-outlier data
sets and is also mindful of new outlier patterns. No prior knowledge of each
set is required to extract the samples. The method consists of two phases, in
the first phase, consistent data points (non- outliers) are retrieved by an
ensemble method of unsupervised clustering techniques and in the second phase a
one class classifier trained on the consistent data point set is ap- plied on
the remaining sample set to identify the outliers. The approach is tested on
three publicly available data sets and the performance scores are competitive.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Porwal_U/0/1/0/all/0/1&quot;&gt;Utkarsh Porwal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mukund_S/0/1/0/all/0/1&quot;&gt;Smruthi Mukund&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.04135">
<title>Deep Learning for Reliable Mobile Edge Analytics in Intelligent Transportation Systems. (arXiv:1712.04135v1 [cs.IT])</title>
<link>http://arxiv.org/abs/1712.04135</link>
<description rdf:parseType="Literal">&lt;p&gt;Intelligent transportation systems (ITSs) will be a major component of
tomorrow&apos;s smart cities. However, realizing the true potential of ITSs requires
ultra-low latency and reliable data analytics solutions that can combine, in
real-time, a heterogeneous mix of data stemming from the ITS network and its
environment. Such data analytics capabilities cannot be provided by
conventional cloud-centric data processing techniques whose communication and
computing latency can be high. Instead, edge-centric solutions that are
tailored to the unique ITS environment must be developed. In this paper, an
edge analytics architecture for ITSs is introduced in which data is processed
at the vehicle or roadside smart sensor level in order to overcome the ITS
latency and reliability challenges. With a higher capability of passengers&apos;
mobile devices and intra-vehicle processors, such a distributed edge computing
architecture can leverage deep learning techniques for reliable mobile sensing
in ITSs. In this context, the ITS mobile edge analytics challenges pertaining
to heterogeneous data, autonomous control, vehicular platoon control, and
cyber-physical security are investigated. Then, different deep learning
solutions for such challenges are proposed. The proposed deep learning
solutions will enable ITS edge analytics by endowing the ITS devices with
powerful computer vision and signal processing functions. Preliminary results
show that the proposed edge analytics architecture, coupled with the power of
deep learning algorithms, can provide a reliable, secure, and truly smart
transportation environment.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ferdowsi_A/0/1/0/all/0/1&quot;&gt;Aidin Ferdowsi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Challita_U/0/1/0/all/0/1&quot;&gt;Ursula Challita&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saad_W/0/1/0/all/0/1&quot;&gt;Walid Saad&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.04144">
<title>Information Perspective to Probabilistic Modeling: Boltzmann Machines versus Born Machines. (arXiv:1712.04144v1 [physics.data-an])</title>
<link>http://arxiv.org/abs/1712.04144</link>
<description rdf:parseType="Literal">&lt;p&gt;We compare and contrast the statistical physics and quantum physics inspired
approaches for unsupervised generative modeling of classical data. The two
approaches represent probabilities of observed data using energy-based models
and quantum states respectively.Classical and quantum information patterns of
the target datasets therefore provide principled guidelines for structural
design and learning in these two approaches. Taking the restricted Boltzmann
machines (RBM) as an example, we analyze the information theoretical bounds of
the two approaches. We verify our reasonings by comparing the performance of
RBMs of various architectures on the standard MNIST datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Cheng_S/0/1/0/all/0/1&quot;&gt;Song Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Chen_J/0/1/0/all/0/1&quot;&gt;Jing Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Wang_L/0/1/0/all/0/1&quot;&gt;Lei Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.04145">
<title>Transportation analysis of denoising autoencoders: a novel method for analyzing deep neural networks. (arXiv:1712.04145v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1712.04145</link>
<description rdf:parseType="Literal">&lt;p&gt;The feature map obtained from the denoising autoencoder (DAE) is investigated
by determining transportation dynamics of the DAE, which is a cornerstone for
deep learning. Despite the rapid development in its application, deep neural
networks remain analytically unexplained, because the feature maps are nested
and parameters are not faithful. In this paper, we address the problem of the
formulation of nested complex of parameters by regarding the feature map as a
transport map. Even when a feature map has different dimensions between input
and output, we can regard it as a transportation map by considering that both
the input and output spaces are embedded in a common high-dimensional space. In
addition, the trajectory is a geometric object and thus, is independent of
parameterization. In this manner, transportation can be regarded as a universal
character of deep neural networks. By determining and analyzing the
transportation dynamics, we can understand the behavior of a deep neural
network. In this paper, we investigate a fundamental case of deep neural
networks: the DAE. We derive the transport map of the DAE, and reveal that the
infinitely deep DAE transports mass to decrease a certain quantity, such as
entropy, of the data distribution. These results though analytically simple,
shed light on the correspondence between deep neural networks and the
Wasserstein gradient flows.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sonoda_S/0/1/0/all/0/1&quot;&gt;Sho Sonoda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Murata_N/0/1/0/all/0/1&quot;&gt;Noboru Murata&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.04146">
<title>A Random Sample Partition Data Model for Big Data Analysis. (arXiv:1712.04146v1 [cs.DC])</title>
<link>http://arxiv.org/abs/1712.04146</link>
<description rdf:parseType="Literal">&lt;p&gt;Big data sets must be carefully partitioned into statistically similar data
subsets that can be used as representative samples for big data analysis tasks.
In this paper, we propose the random sample partition (RSP) to represent a big
data set as a set of non-overlapping data subsets, i.e. RSP data blocks, where
each RSP data block has the same probability distribution with the whole big
data set. Then, the block-based sampling is used to directly select
representative samples for a variety of data analysis tasks. We show how RSP
data blocks can be employed to estimate statistics and build models which are
equivalent (or approximate) to those from the whole big data set.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Salloum_S/0/1/0/all/0/1&quot;&gt;Salman Salloum&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1&quot;&gt;Yulin He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1&quot;&gt;Joshua Zhexue Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xiaoliang Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Emara_T/0/1/0/all/0/1&quot;&gt;Tamer Z. Emara&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.04165">
<title>Temporal Stability in Predictive Process Monitoring. (arXiv:1712.04165v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1712.04165</link>
<description rdf:parseType="Literal">&lt;p&gt;Predictive business process monitoring is concerned with the analysis of
events produced during the execution of a business process in order to predict
as early as possible the final outcome of an ongoing case. Traditionally,
predictive process monitoring methods are optimized with respect to accuracy.
However, in environments where users make decisions and take actions in
response to the predictions they receive, it is equally important to optimize
the stability of the successive predictions made for each case. To this end,
this paper defines a notion of temporal stability for predictive process
monitoring and evaluates existing methods with respect to both temporal
stability and accuracy. We find that methods based on XGBoost and LSTM neural
networks exhibit the highest temporal stability. We then show that temporal
stability can be enhanced by hyperparameter-optimizing random forests and
XGBoost classifiers with respect to inter-run stability. Finally, we show that
time series smoothing techniques can further enhance temporal stability at the
expense of slightly lower accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Teinemaa_I/0/1/0/all/0/1&quot;&gt;Irene Teinemaa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dumas_M/0/1/0/all/0/1&quot;&gt;Marlon Dumas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leontjeva_A/0/1/0/all/0/1&quot;&gt;Anna Leontjeva&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Maggi_F/0/1/0/all/0/1&quot;&gt;Fabrizio Maria Maggi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.04221">
<title>Causal Patterns: Extraction of multiple causal relationships by Mixture of Probabilistic Partial Canonical Correlation Analysis. (arXiv:1712.04221v1 [stat.ME])</title>
<link>http://arxiv.org/abs/1712.04221</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we propose a mixture of probabilistic partial canonical
correlation analysis (MPPCCA) that extracts the Causal Patterns from two
multivariate time series. Causal patterns refer to the signal patterns within
interactions of two elements having multiple types of mutually causal
relationships, rather than a mixture of simultaneous correlations or the
absence of presence of a causal relationship between the elements. In
multivariate statistics, partial canonical correlation analysis (PCCA)
evaluates the correlation between two multivariates after subtracting the
effect of the third multivariate. PCCA can calculate the Granger Causal- ity
Index (which tests whether a time-series can be predicted from an- other
time-series), but is not applicable to data containing multiple partial
canonical correlations. After introducing the MPPCCA, we propose an
expectation-maxmization (EM) algorithm that estimates the parameters and latent
variables of the MPPCCA. The MPPCCA is expected to ex- tract multiple partial
canonical correlations from data series without any supervised signals to split
the data as clusters. The method was then eval- uated in synthetic data
experiments. In the synthetic dataset, our method estimated the multiple
partial canonical correlations more accurately than the existing method. To
determine the types of patterns detectable by the method, experiments were also
conducted on real datasets. The method estimated the communication patterns In
motion-capture data. The MP- PCCA is applicable to various type of signals such
as brain signals, human communication and nonlinear complex multibody systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mori_H/0/1/0/all/0/1&quot;&gt;Hiroki Mori&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kawano_K/0/1/0/all/0/1&quot;&gt;Keisuke Kawano&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yokoyama_H/0/1/0/all/0/1&quot;&gt;Hiroki Yokoyama&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.04276">
<title>Multi-Speaker Localization Using Convolutional Neural Network Trained with Noise. (arXiv:1712.04276v1 [cs.SD])</title>
<link>http://arxiv.org/abs/1712.04276</link>
<description rdf:parseType="Literal">&lt;p&gt;The problem of multi-speaker localization is formulated as a multi-class
multi-label classification problem, which is solved using a convolutional
neural network (CNN) based source localization method. Utilizing the common
assumption of disjoint speaker activities, we propose a novel method to train
the CNN using synthesized noise signals. The proposed localization method is
evaluated for two speakers and compared to a well-known steered response power
method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chakrabarty_S/0/1/0/all/0/1&quot;&gt;Soumitro Chakrabarty&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Habets_E/0/1/0/all/0/1&quot;&gt;Emanu&amp;#xeb;l A. P. Habets&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.04332">
<title>Scaling Limit: Exact and Tractable Analysis of Online Learning Algorithms with Applications to Regularized Regression and PCA. (arXiv:1712.04332v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1712.04332</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a framework for analyzing the exact dynamics of a class of online
learning algorithms in the high-dimensional scaling limit. Our results are
applied to two concrete examples: online regularized linear regression and
principal component analysis. As the ambient dimension tends to infinity, and
with proper time scaling, we show that the time-varying joint empirical
measures of the target feature vector and its estimates provided by the
algorithms will converge weakly to a deterministic measured-valued process that
can be characterized as the unique solution of a nonlinear PDE. Numerical
solutions of this PDE can be efficiently obtained. These solutions lead to
precise predictions of the performance of the algorithms, as many practical
performance metrics are linear functionals of the joint empirical measures. In
addition to characterizing the dynamic performance of online learning
algorithms, our asymptotic analysis also provides useful insights. In
particular, in the high-dimensional limit, and due to exchangeability, the
original coupled dynamics associated with the algorithms will be asymptotically
&quot;decoupled&quot;, with each coordinate independently solving a 1-D effective
minimization problem via stochastic gradient descent. Exploiting this insight
for nonconvex optimization problems may prove an interesting line of future
research.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1&quot;&gt;Chuang Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mattingly_J/0/1/0/all/0/1&quot;&gt;Jonathan Mattingly&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1&quot;&gt;Yue M. Lu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.04350">
<title>Predicting Yelp Star Reviews Based on Network Structure with Deep Learning. (arXiv:1712.04350v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1712.04350</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we tackle the real-world problem of predicting Yelp
star-review rating based on business features (such as images, descriptions),
user features (average previous ratings), and, of particular interest, network
properties (which businesses has a user rated before). We compare multiple
models on different sets of features -- from simple linear regression on
network features only to deep learning models on network and item features.
&lt;/p&gt;
&lt;p&gt;In recent years, breakthroughs in deep learning have led to increased
accuracy in common supervised learning tasks, such as image classification,
captioning, and language understanding. However, the idea of combining deep
learning with network feature and structure appears to be novel. While the
problem of predicting future interactions in a network has been studied at
length, these approaches have often ignored either node-specific data or global
structure.
&lt;/p&gt;
&lt;p&gt;We demonstrate that taking a mixed approach combining both node-level
features and network information can effectively be used to predict Yelp-review
star ratings. We evaluate on the Yelp dataset by splitting our data along the
time dimension (as would naturally occur in the real-world) and comparing our
model against others which do no take advantage of the network structure and/or
deep learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Perez_L/0/1/0/all/0/1&quot;&gt;Luis Perez&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.04356">
<title>CUSBoost: Cluster-based Under-sampling with Boosting for Imbalanced Classification. (arXiv:1712.04356v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1712.04356</link>
<description rdf:parseType="Literal">&lt;p&gt;Class imbalance classification is a challenging research problem in data
mining and machine learning, as most of the real-life datasets are often
imbalanced in nature. Existing learning algorithms maximise the classification
accuracy by correctly classifying the majority class, but misclassify the
minority class. However, the minority class instances are representing the
concept with greater interest than the majority class instances in real-life
applications. Recently, several techniques based on sampling methods
(under-sampling of the majority class and over-sampling the minority class),
cost-sensitive learning methods, and ensemble learning have been used in the
literature for classifying imbalanced datasets. In this paper, we introduce a
new clustering-based under-sampling approach with boosting (AdaBoost)
algorithm, called CUSBoost, for effective imbalanced classification. The
proposed algorithm provides an alternative to RUSBoost (random under-sampling
with AdaBoost) and SMOTEBoost (synthetic minority over-sampling with AdaBoost)
algorithms. We evaluated the performance of CUSBoost algorithm with the
state-of-the-art methods based on ensemble learning like AdaBoost, RUSBoost,
SMOTEBoost on 13 imbalance binary and multi-class datasets with various
imbalance ratios. The experimental results show that the CUSBoost is a
promising and effective approach for dealing with highly imbalanced datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rayhan_F/0/1/0/all/0/1&quot;&gt;Farshid Rayhan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ahmed_S/0/1/0/all/0/1&quot;&gt;Sajid Ahmed&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mahbub_A/0/1/0/all/0/1&quot;&gt;Asif Mahbub&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jani_M/0/1/0/all/0/1&quot;&gt;Md. Rafsan Jani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shatabda_S/0/1/0/all/0/1&quot;&gt;Swakkhar Shatabda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Farid_D/0/1/0/all/0/1&quot;&gt;Dewan Md. Farid&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.04407">
<title>Logo Synthesis and Manipulation with Clustered Generative Adversarial Networks. (arXiv:1712.04407v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1712.04407</link>
<description rdf:parseType="Literal">&lt;p&gt;Designing a logo for a new brand is a lengthy and tedious back-and-forth
process between a designer and a client. In this paper we explore to what
extent machine learning can solve the creative task of the designer. For this,
we build a dataset -- LLD -- of 600k+ logos crawled from the world wide web.
Training Generative Adversarial Networks (GANs) for logo synthesis on such
multi-modal data is not straightforward and results in mode collapse for some
state-of-the-art methods. We propose the use of synthetic labels obtained
through clustering to disentangle and stabilize GAN training. We are able to
generate a high diversity of plausible logos and we demonstrate latent space
exploration techniques to ease the logo design task in an interactive manner.
Moreover, we validate the proposed clustered GAN training on CIFAR 10,
achieving state-of-the-art Inception scores when using synthetic labels
obtained via clustering the features of an ImageNet classifier. GANs can cope
with multi-modal data by means of synthetic labels achieved through clustering,
and our results show the creative potential of such techniques for logo
synthesis and manipulation. Our dataset and models will be made publicly
available at https://data.vision.ee.ethz.ch/cvl/lld/.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sage_A/0/1/0/all/0/1&quot;&gt;Alexander Sage&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Agustsson_E/0/1/0/all/0/1&quot;&gt;Eirikur Agustsson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Timofte_R/0/1/0/all/0/1&quot;&gt;Radu Timofte&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gool_L/0/1/0/all/0/1&quot;&gt;Luc Van Gool&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.04432">
<title>Integrated Model and Data Parallelism in Training Neural Networks. (arXiv:1712.04432v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1712.04432</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a new integrated method of exploiting both model and data
parallelism for the training of deep neural networks (DNNs) on large
distributed-memory computers using mini-batch stochastic gradient descent
(SGD). Our goal is to find an efficient parallelization strategy for a fixed
batch size using $P$ processes. Our method is inspired by the
communication-avoiding algorithms in numerical linear algebra. We see $P$
processes as logically divided into a $P_r \times P_c$ grid where the $P_r$
dimension is implicitly responsible for model parallelism and the $P_c$
dimension is implicitly responsible for data parallelism. In practice, the
integrated matrix-based parallel algorithm encapsulates both types of
parallelism automatically. We analyze the communication complexity and
analytically demonstrate that the lowest communication costs are often achieved
neither with pure model parallelism nor with pure data parallelism. We also
show the positive effect of our approach in the computational performance of
SGD based DNN training where the reduced number of processes responsible for
data parallelism result in &quot;fatter&quot; matrices that enable higher-throughput
matrix multiplication.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gholami_A/0/1/0/all/0/1&quot;&gt;Amir Gholami&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Azad_A/0/1/0/all/0/1&quot;&gt;Ariful Azad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Keutzer_K/0/1/0/all/0/1&quot;&gt;Kurt Keutzer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Buluc_A/0/1/0/all/0/1&quot;&gt;Aydin Buluc&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1606.07636">
<title>Is the Bellman residual a bad proxy?. (arXiv:1606.07636v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1606.07636</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper aims at theoretically and empirically comparing two standard
optimization criteria for Reinforcement Learning: i) maximization of the mean
value and ii) minimization of the Bellman residual. For that purpose, we place
ourselves in the framework of policy search algorithms, that are usually
designed to maximize the mean value, and derive a method that minimizes the
residual $\|T_* v_\pi - v_\pi\|_{1,\nu}$ over policies. A theoretical analysis
shows how good this proxy is to policy optimization, and notably that it is
better than its value-based counterpart. We also propose experiments on
randomly generated generic Markov decision processes, specifically designed for
studying the influence of the involved concentrability coefficient. They show
that the Bellman residual is generally a bad proxy to policy optimization and
that directly maximizing the mean value is much better, despite the current
lack of deep theoretical analysis. This might seem obvious, as directly
addressing the problem of interest is usually better, but given the prevalence
of (projected) Bellman residual minimization in value-based reinforcement
learning, we believe that this question is worth to be considered.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Geist_M/0/1/0/all/0/1&quot;&gt;Matthieu Geist&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Piot_B/0/1/0/all/0/1&quot;&gt;Bilal Piot&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pietquin_O/0/1/0/all/0/1&quot;&gt;Olivier Pietquin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1703.01785">
<title>Forward and Reverse Gradient-Based Hyperparameter Optimization. (arXiv:1703.01785v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1703.01785</link>
<description rdf:parseType="Literal">&lt;p&gt;We study two procedures (reverse-mode and forward-mode) for computing the
gradient of the validation error with respect to the hyperparameters of any
iterative learning algorithm such as stochastic gradient descent. These
procedures mirror two methods of computing gradients for recurrent neural
networks and have different trade-offs in terms of running time and space
requirements. Our formulation of the reverse-mode procedure is linked to
previous work by Maclaurin et al. [2015] but does not require reversible
dynamics. The forward-mode procedure is suitable for real-time hyperparameter
updates, which may significantly speed up hyperparameter optimization on large
datasets. We present experiments on data cleaning and on learning task
interactions. We also present one large-scale experiment where the use of
previous gradient-based methods would be prohibitive.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Franceschi_L/0/1/0/all/0/1&quot;&gt;Luca Franceschi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Donini_M/0/1/0/all/0/1&quot;&gt;Michele Donini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Frasconi_P/0/1/0/all/0/1&quot;&gt;Paolo Frasconi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pontil_M/0/1/0/all/0/1&quot;&gt;Massimiliano Pontil&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1705.00919">
<title>Broadband DOA estimation using Convolutional neural networks trained with noise signals. (arXiv:1705.00919v2 [cs.SD] UPDATED)</title>
<link>http://arxiv.org/abs/1705.00919</link>
<description rdf:parseType="Literal">&lt;p&gt;A convolution neural network (CNN) based classification method for broadband
DOA estimation is proposed, where the phase component of the short-time Fourier
transform coefficients of the received microphone signals are directly fed into
the CNN and the features required for DOA estimation are learnt during
training. Since only the phase component of the input is used, the CNN can be
trained with synthesized noise signals, thereby making the preparation of the
training data set easier compared to using speech signals. Through experimental
evaluation, the ability of the proposed noise trained CNN framework to
generalize to speech sources is demonstrated. In addition, the robustness of
the system to noise, small perturbations in microphone positions, as well as
its ability to adapt to different acoustic conditions is investigated using
experiments with simulated and real data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chakrabarty_S/0/1/0/all/0/1&quot;&gt;Soumitro Chakrabarty&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Habets_E/0/1/0/all/0/1&quot;&gt;Emanu&amp;#xeb;l. A. P. Habets&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1705.04312">
<title>FDR-Corrected Sparse Canonical Correlation Analysis with Applications to Imaging Genomics. (arXiv:1705.04312v3 [stat.ME] UPDATED)</title>
<link>http://arxiv.org/abs/1705.04312</link>
<description rdf:parseType="Literal">&lt;p&gt;Reducing the number of false positive discoveries is presently one of the
most pressing issues in the life sciences. It is of especially great importance
for many applications in neuroimaging and genomics, where datasets are
typically high-dimensional, which means that the number of explanatory
variables exceeds the sample size. The false discovery rate (FDR) is a
criterion that can be employed to address that issue. Thus it has gained great
popularity as a tool for testing multiple hypotheses. Canonical correlation
analysis (CCA) is a statistical technique that is used to make sense of the
cross-correlation of two sets of measurements collected on the same set of
samples (e.g., brain imaging and genomic data for the same mental illness
patients), and sparse CCA extends the classical method to high-dimensional
settings. Here we propose a way of applying the FDR concept to sparse CCA, and
a method to control the FDR. The proposed FDR correction directly influences
the sparsity of the solution, adapting it to the unknown true sparsity level.
Theoretical derivation as well as simulation studies show that our procedure
indeed keeps the FDR of the canonical vectors below a user-specified target
level. We apply the proposed method to an imaging genomics dataset from the
Philadelphia Neurodevelopmental Cohort. Our results link the brain connectivity
profiles derived from brain activity during an emotion identification task, as
measured by functional magnetic resonance imaging (fMRI), to the corresponding
subjects&apos; genomic data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gossmann_A/0/1/0/all/0/1&quot;&gt;Alexej Gossmann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zille_P/0/1/0/all/0/1&quot;&gt;Pascal Zille&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Calhoun_V/0/1/0/all/0/1&quot;&gt;Vince Calhoun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yu-Ping Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1705.07881">
<title>Online Factorization and Partition of Complex Networks From Random Walks. (arXiv:1705.07881v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1705.07881</link>
<description rdf:parseType="Literal">&lt;p&gt;Finding the reduced-dimensional structure is critical to understanding
complex networks. Existing approaches such as spectral clustering are
applicable only when the full network is explicitly observed. In this paper, we
focus on the online factorization and partition of implicit large-scale
networks based on observations from an associated random walk. We formulate
this into a nonconvex stochastic factorization problem and propose an efficient
and scalable stochastic generalized Hebbian algorithm. The algorithm is able to
process dependent state-transition data dynamically generated by the underlying
network and learn a low-dimensional representation for each vertex. By applying
a diffusion approximation analysis, we show that the continuous-time limiting
process of the stochastic algorithm converges globally to the &quot;principal
components&quot; of the Markov chain and achieves a nearly optimal sample
complexity. Once given the learned low-dimensional representations, we further
apply clustering techniques to recover the network partition. We show that when
the associated Markov process is lumpable, one can recover the partition
exactly with high probability. We apply the proposed approach to model the
traffic flow of Manhattan as city-wide random walks. By using our algorithm to
analyze the taxi trip data, we discover a latent partition of the Manhattan
city that closely matches the traffic dynamics.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1&quot;&gt;Lin F. Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Braverman_V/0/1/0/all/0/1&quot;&gt;Vladimir Braverman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_T/0/1/0/all/0/1&quot;&gt;Tuo Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1&quot;&gt;Mengdi Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1707.04659">
<title>Variational approach for learning Markov processes from time series data. (arXiv:1707.04659v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1707.04659</link>
<description rdf:parseType="Literal">&lt;p&gt;Inference, prediction and control of complex dynamical systems from time
series is important in many areas, including financial markets, power grid
management, climate and weather modeling, or molecular dynamics. The analysis
of such highly nonlinear dynamical systems is facilitated by the fact that we
can often find a (generally nonlinear) transformation of the system coordinates
to features in which the dynamics can be excellently approximated by a linear
Markovian model. Moreover, the large number of system variables often change
collectively on large time- and length-scales, facilitating a low-dimensional
analysis in feature space. In this paper, we introduce a variational approach
for Markov processes (VAMP) that allows us to find optimal feature mappings and
optimal Markovian models of the dynamics from given time series data. The key
insight is that the best linear model can be obtained from the top singular
components of the Koopman operator. This leads to the definition of a family of
score functions called VAMP-r which can be calculated from data, and can be
employed to optimize a Markovian model. In addition, based on the relationship
between the variational scores and approximation errors of Koopman operators,
we propose a new VAMP-E score, which can be applied to cross-validation for
hyper-parameter optimization and model selection in VAMP. VAMP is valid for
both reversible and nonreversible processes and for stationary and
non-stationary processes or realizations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wu_H/0/1/0/all/0/1&quot;&gt;Hao Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Noe_F/0/1/0/all/0/1&quot;&gt;Frank No&amp;#xe9;&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1708.05978">
<title>Stochastic Primal-Dual Proximal ExtraGradient Descent for Compositely Regularized Optimization. (arXiv:1708.05978v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1708.05978</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider a wide range of regularized stochastic minimization problems with
two regularization terms, one of which is composed with a linear function. This
optimization model abstracts a number of important applications in artificial
intelligence and machine learning, such as fused Lasso, fused logistic
regression, and a class of graph-guided regularized minimization. The
computational challenges of this model are in two folds. On one hand, the
closed-form solution of the proximal mapping associated with the composed
regularization term or the expected objective function is not available. On the
other hand, the calculation of the full gradient of the expectation in the
objective is very expensive when the number of input data samples is
considerably large. To address these issues, we propose a stochastic variant of
extra-gradient type methods, namely \textsf{Stochastic Primal-Dual Proximal
ExtraGradient descent (SPDPEG)}, and analyze its convergence property for both
convex and strongly convex objectives. For general convex objectives, the
uniformly average iterates generated by \textsf{SPDPEG} converge in expectation
with $O(1/\sqrt{t})$ rate. While for strongly convex objectives, the uniformly
and non-uniformly average iterates generated by \textsf{SPDPEG} converge with
$O(\log(t)/t)$ and $O(1/t)$ rates, respectively. The order of the rate of the
proposed algorithm is known to match the best convergence rate for first-order
stochastic algorithms. Experiments on fused logistic regression and
graph-guided regularized logistic regression problems show that the proposed
algorithm performs very efficiently and consistently outperforms other
competing algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_T/0/1/0/all/0/1&quot;&gt;Tianyi Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qiao_L/0/1/0/all/0/1&quot;&gt;Linbo Qiao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1&quot;&gt;Teng Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1&quot;&gt;Jiashi Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1&quot;&gt;Bofeng Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.04412">
<title>The Merging Path Plot: adaptive fusing of k-groups with likelihood-based model selection. (arXiv:1709.04412v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1709.04412</link>
<description rdf:parseType="Literal">&lt;p&gt;There are many statistical tests that verify the null hypothesis: the
variable of interest has the same distribution among k-groups. But once the
null hypothesis is rejected, how to present the structure of dissimilarity
between groups? In this article, we introduce The Merging Path Plot - a
methodology, and factorMerger - an R package, for exploration and visualization
of k-group dissimilarities. Comparison of k-groups is one of the most important
issues in exploratory analyses and it has zillions of applications. The
classical solution is to test a~null hypothesis that observations from all
groups come from the same distribution. If the global null hypothesis is
rejected, a~more detailed analysis of differences among pairs of groups is
performed. The traditional approach is to use pairwise post hoc tests in order
to verify which groups differ significantly. However, this approach fails with
a large number of groups in both interpretation and visualization layer.
The~Merging Path Plot methodology solves this problem by using an
easy-to-understand description of dissimilarity among groups based on
Likelihood Ratio Test (LRT) statistic.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sitko_A/0/1/0/all/0/1&quot;&gt;Agnieszka Sitko&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Biecek_P/0/1/0/all/0/1&quot;&gt;Przemyslaw Biecek&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.02971">
<title>Network Embedding as Matrix Factorization: Unifying DeepWalk, LINE, PTE, and node2vec. (arXiv:1710.02971v3 [cs.SI] UPDATED)</title>
<link>http://arxiv.org/abs/1710.02971</link>
<description rdf:parseType="Literal">&lt;p&gt;Since the invention of word2vec, the skip-gram model has significantly
advanced the research of network embedding, such as the recent emergence of the
DeepWalk, LINE, PTE, and node2vec approaches. In this work, we show that all of
the aforementioned models with negative sampling can be unified into the matrix
factorization framework with closed forms. Our analysis and proofs reveal that:
(1) DeepWalk empirically produces a low-rank transformation of a network&apos;s
normalized Laplacian matrix; (2) LINE, in theory, is a special case of DeepWalk
when the size of vertices&apos; context is set to one; (3) As an extension of LINE,
PTE can be viewed as the joint factorization of multiple networks&apos; Laplacians;
(4) node2vec is factorizing a matrix related to the stationary distribution and
transition probability tensor of a 2nd-order random walk. We further provide
the theoretical connections between skip-gram based network embedding
algorithms and the theory of graph Laplacian. Finally, we present the NetMF
method as well as its approximation algorithm for computing network embedding.
Our method offers significant improvements over DeepWalk and LINE for
conventional network mining tasks. This work lays the theoretical foundation
for skip-gram based network embedding methods, leading to a better
understanding of latent network representation learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qiu_J/0/1/0/all/0/1&quot;&gt;Jiezhong Qiu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1&quot;&gt;Yuxiao Dong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_H/0/1/0/all/0/1&quot;&gt;Hao Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jian Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1&quot;&gt;Kuansan Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1&quot;&gt;Jie Tang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.11469">
<title>Grouping-By-ID: Guarding Against Adversarial Domain Shifts. (arXiv:1710.11469v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1710.11469</link>
<description rdf:parseType="Literal">&lt;p&gt;When training a deep network for image classification, one can broadly
distinguish between two types of latent features that will drive the
classification. Following Gong et al. (2016), we can divide features into (i)
&quot;core&quot; features $X^{ci}$ whose distribution $P(X^{ci} | Y)$ does not change
substantially across domains and (ii) &quot;style&quot; or &quot;orthogonal&quot; features
$X^\perp$ whose distribution $P(X^\perp | Y)$ can change substantially across
domains. These latter orthogonal features would generally include features such
as position or brightness but also more complex ones like hair color or posture
for images of persons. We try to guard against future adversarial domain shifts
by ideally just using the &quot;core&quot; features for classification. In contrast to
previous work, we assume that the domain itself is not observed and hence a
latent variable, i.e. we cannot directly see the distributional change of
features across different domains. We do assume, however, that we can sometimes
observe a so-called ID variable. E.g. we might know that two images show the
same person, with ID referring to the identity of the person. The method
requires only a small fraction of images to have an ID variable. We provide a
causal framework for the problem by adding the ID variable to the model of Gong
et al. (2016). If two or more samples share the same class and identifier, then
we treat those samples as counterfactuals under different interventions on the
orthogonal features. Using this grouping-by-ID approach, we regularize the
network to provide near constant output across samples that share the same ID
by penalizing with an appropriate graph Laplacian. This substantially improves
performance in settings where domains change in terms of image quality,
brightness, color or posture and movement. We show links to questions of
interpretability, fairness, transfer learning and adversarial examples.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Heinze_Deml_C/0/1/0/all/0/1&quot;&gt;Christina Heinze-Deml&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Meinshausen_N/0/1/0/all/0/1&quot;&gt;Nicolai Meinshausen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.00837">
<title>Oversampling for Imbalanced Learning Based on K-Means and SMOTE. (arXiv:1711.00837v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1711.00837</link>
<description rdf:parseType="Literal">&lt;p&gt;Learning from class-imbalanced data continues to be a common and challenging
problem in supervised learning as standard classification algorithms are
designed to handle balanced class distributions. While different strategies
exist to tackle this problem, methods which generate artificial data to achieve
a balanced class distribution are more versatile than modifications to the
classification algorithm. Such techniques, called oversamplers, modify the
training data, allowing any classifier to be used with class-imbalanced
datasets. Many algorithms have been proposed for this task, but most are
complex and tend to generate unnecessary noise. This work presents a simple and
effective oversampling method based on k-means clustering and SMOTE
oversampling, which avoids the generation of noise and effectively overcomes
imbalances between and within classes. Empirical results of extensive
experiments with 71 datasets show that training data oversampled with the
proposed method improves classification results. Moreover, k-means SMOTE
consistently outperforms other popular oversampling methods. An implementation
is made available in the python programming language.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Last_F/0/1/0/all/0/1&quot;&gt;Felix Last&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Douzas_G/0/1/0/all/0/1&quot;&gt;Georgios Douzas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bacao_F/0/1/0/all/0/1&quot;&gt;Fernando Bacao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.07476">
<title>Virtual Adversarial Ladder Networks For Semi-supervised Learning. (arXiv:1711.07476v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1711.07476</link>
<description rdf:parseType="Literal">&lt;p&gt;Semi-supervised learning (SSL) partially circumvents the high cost of
labeling data by augmenting a small labeled dataset with a large and relatively
cheap unlabeled dataset drawn from the same distribution. This paper offers a
novel interpretation of two deep learning-based SSL approaches, ladder networks
and virtual adversarial training (VAT), as applying distributional smoothing to
their respective latent spaces. We propose a class of models that fuse these
approaches. We achieve near-supervised accuracy with high consistency on the
MNIST dataset using just 5 labels per class: our best model, ladder with
layer-wise virtual adversarial noise (LVAN-LW), achieves 1.42% +/- 0.12 average
error rate on the MNIST test set, in comparison with 1.62% +/- 0.65 reported
for the ladder network. On adversarial examples generated with L2-normalized
fast gradient method, LVAN-LW trained with 5 examples per class achieves
average error rate 2.4% +/- 0.3 compared to 68.6% +/- 6.5 for the ladder
network and 9.9% +/- 7.5 for VAT.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shinoda_S/0/1/0/all/0/1&quot;&gt;Saki Shinoda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Worrall_D/0/1/0/all/0/1&quot;&gt;Daniel E. Worrall&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brostow_G/0/1/0/all/0/1&quot;&gt;Gabriel J. Brostow&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.07693">
<title>Regret Analysis for Continuous Dueling Bandit. (arXiv:1711.07693v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1711.07693</link>
<description rdf:parseType="Literal">&lt;p&gt;The dueling bandit is a learning framework wherein the feedback information
in the learning process is restricted to a noisy comparison between a pair of
actions. In this research, we address a dueling bandit problem based on a cost
function over a continuous space. We propose a stochastic mirror descent
algorithm and show that the algorithm achieves an $O(\sqrt{T\log T})$-regret
bound under strong convexity and smoothness assumptions for the cost function.
Subsequently, we clarify the equivalence between regret minimization in dueling
bandit and convex optimization for the cost function. Moreover, when
considering a lower bound in convex optimization, our algorithm is shown to
achieve the optimal convergence rate in convex optimization and the optimal
regret in dueling bandit except for a logarithmic factor.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kumagai_W/0/1/0/all/0/1&quot;&gt;Wataru Kumagai&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.09522">
<title>Proceedings of NIPS 2017 Workshop on Machine Learning for the Developing World. (arXiv:1711.09522v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1711.09522</link>
<description rdf:parseType="Literal">&lt;p&gt;This is the Proceedings of NIPS 2017 Workshop on Machine Learning for the
Developing World, held in Long Beach, California, USA on December 8, 2017
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+De_Arteaga_M/0/1/0/all/0/1&quot;&gt;Maria De-Arteaga&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Herlands_W/0/1/0/all/0/1&quot;&gt;William Herlands&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.09889">
<title>Proceedings of NIPS 2017 Symposium on Interpretable Machine Learning. (arXiv:1711.09889v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1711.09889</link>
<description rdf:parseType="Literal">&lt;p&gt;This is the Proceedings of NIPS 2017 Symposium on Interpretable Machine
Learning, held in Long Beach, California, USA on December 7, 2017
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wilson_A/0/1/0/all/0/1&quot;&gt;Andrew Gordon Wilson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yosinski_J/0/1/0/all/0/1&quot;&gt;Jason Yosinski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Simard_P/0/1/0/all/0/1&quot;&gt;Patrice Simard&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Caruana_R/0/1/0/all/0/1&quot;&gt;Rich Caruana&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Herlands_W/0/1/0/all/0/1&quot;&gt;William Herlands&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.03660">
<title>Distributed Mapper. (arXiv:1712.03660v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1712.03660</link>
<description rdf:parseType="Literal">&lt;p&gt;The construction of Mapper has emerged in the last decade as a powerful and
effective topological data analysis tool that approximates and generalizes
other topological summaries, such as the Reeb graph, the contour tree, split,
and joint trees. In this paper we study the parallel analysis of the
construction of Mapper. We give a provably correct algorithm to distribute
Mapper on a set of processors and discuss the performance results that compare
our approach to a reference sequential Mapper implementation. We report the
performance experiments that demonstrate the efficiency of our method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hajij_M/0/1/0/all/0/1&quot;&gt;Mustafa Hajij&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Assiri_B/0/1/0/all/0/1&quot;&gt;Basem Assiri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rosen_P/0/1/0/all/0/1&quot;&gt;Paul Rosen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.03878">
<title>Generalized Zero-Shot Learning via Synthesized Examples. (arXiv:1712.03878v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1712.03878</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a generative framework for generalized zero-shot learning where
the training and test classes are not necessarily disjoint. Built upon a
variational autoencoder based architecture, consisting of a probabilistic
encoder and a probabilistic conditional decoder, our model can generate novel
exemplars from seen/unseen classes, given their respective class attributes.
These exemplars can subsequently be used to train any off-the-shelf
classification model. One of the key aspects of our encoder-decoder
architecture is a feedback-driven mechanism in which a discriminator (a
multivariate regressor) learns to map the generated exemplars to the
corresponding class attribute vectors, leading to an improved generator. Our
model&apos;s ability to generate and leverage examples from unseen classes to train
the classification model naturally helps to mitigate the bias towards
predicting seen classes in generalized zero-shot learning settings. Through a
comprehensive set of experiments, we show that our model outperforms several
state-of-the-art methods, on several benchmark datasets, for both standard as
well as generalized zero-shot learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Arora_G/0/1/0/all/0/1&quot;&gt;Gundeep Arora&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Verma_V/0/1/0/all/0/1&quot;&gt;Vinay Kumar Verma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mishra_A/0/1/0/all/0/1&quot;&gt;Ashish Mishra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rai_P/0/1/0/all/0/1&quot;&gt;Piyush Rai&lt;/a&gt;</dc:creator>
</item></rdf:RDF>