<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Good papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Good Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-04-11T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.03758"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.03799"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.03984"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.03994"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.04095"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1704.06259"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1706.01320"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.05360"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.06922"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.00293"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.03720"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.03958"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.03987"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.04058"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1209.0367"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1702.01000"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1707.07012"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.02929"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1804.03758">
<title>Universal Successor Representations for Transfer Reinforcement Learning. (arXiv:1804.03758v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1804.03758</link>
<description rdf:parseType="Literal">&lt;p&gt;The objective of transfer reinforcement learning is to generalize from a set
of previous tasks to unseen new tasks. In this work, we focus on the transfer
scenario where the dynamics among tasks are the same, but their goals differ.
Although general value function (Sutton et al., 2011) has been shown to be
useful for knowledge transfer, learning a universal value function can be
challenging in practice. To attack this, we propose (1) to use universal
successor representations (USR) to represent the transferable knowledge and (2)
a USR approximator (USRA) that can be trained by interacting with the
environment. Our experiments show that USR can be effectively applied to new
tasks, and the agent initialized by the trained USRA can achieve the goal
considerably faster than random initialization.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_C/0/1/0/all/0/1&quot;&gt;Chen Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wen_J/0/1/0/all/0/1&quot;&gt;Junfeng Wen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bengio_Y/0/1/0/all/0/1&quot;&gt;Yoshua Bengio&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.03799">
<title>Achieving Fluency and Coherency in Task-oriented Dialog. (arXiv:1804.03799v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1804.03799</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider real world task-oriented dialog settings, where agents need to
generate both fluent natural language responses and correct external actions
like database queries and updates. We demonstrate that, when applied to
customer support chat transcripts, Sequence to Sequence (Seq2Seq) models often
generate short, incoherent and ungrammatical natural language responses that
are dominated by words that occur with high frequency in the training data.
These phenomena do not arise in synthetic datasets such as bAbI, where we show
Seq2Seq models are nearly perfect. We develop techniques to learn embeddings
that succinctly capture relevant information from the dialog history, and
demonstrate that nearest neighbor based approaches in this learned neural
embedding space generate more fluent responses. However, we see that these
methods are not able to accurately predict when to execute an external action.
We show how to combine nearest neighbor and Seq2Seq methods in a hybrid model,
where nearest neighbor is used to generate fluent responses and Seq2Seq type
models ensure dialog coherency and generate accurate external actions. We show
that this approach is well suited for customer support scenarios, where agents&apos;
responses are typically script-driven, and correct external actions are
critically important. The hybrid model on the customer support data achieves a
78% relative improvement in fluency scores, and a 130% improvement in accuracy
of external calls.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gangadharaiah_R/0/1/0/all/0/1&quot;&gt;Rashmi Gangadharaiah&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Narayanaswamy_B/0/1/0/all/0/1&quot;&gt;Balakrishnan Narayanaswamy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Elkan_C/0/1/0/all/0/1&quot;&gt;Charles Elkan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.03984">
<title>Emergence of Linguistic Communication from Referential Games with Symbolic and Pixel Input. (arXiv:1804.03984v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1804.03984</link>
<description rdf:parseType="Literal">&lt;p&gt;The ability of algorithms to evolve or learn (compositional) communication
protocols has traditionally been studied in the language evolution literature
through the use of emergent communication tasks. Here we scale up this research
by using contemporary deep learning methods and by training
reinforcement-learning neural network agents on referential communication
games. We extend previous work, in which agents were trained in symbolic
environments, by developing agents which are able to learn from raw pixel data,
a more challenging and realistic input representation. We find that the degree
of structure found in the input data affects the nature of the emerged
protocols, and thereby corroborate the hypothesis that structured compositional
language is most likely to emerge when agents perceive the world as being
structured.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lazaridou_A/0/1/0/all/0/1&quot;&gt;Angeliki Lazaridou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hermann_K/0/1/0/all/0/1&quot;&gt;Karl Moritz Hermann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tuyls_K/0/1/0/all/0/1&quot;&gt;Karl Tuyls&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Clark_S/0/1/0/all/0/1&quot;&gt;Stephen Clark&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.03994">
<title>An Estimation of Favorite Value in Emotion Generating Calculation by Fuzzy Petri Net. (arXiv:1804.03994v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1804.03994</link>
<description rdf:parseType="Literal">&lt;p&gt;Emotion Generating Calculations (EGC) method based on the Emotion Eliciting
Condition Theory can decide whether an event arouses pleasure or not and
quantify the degree under the event. An event in the form of Case Frame
representation is classified into 12 types of calculations. However, the weak
point in EGC is Favorite Value (FV) as the personal taste information. In order
to improve the problem, this paper challenges to establish a learning method to
learn speaker&apos;s taste information from dialog. Especially, the learning method
employs Fuzzy Petri Net to find an appropriate FV to a word which has the
unknown FV. This paper discusses the effective learning method to improve a
weak point of EGC when a missing value of FV exists.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ichimura_T/0/1/0/all/0/1&quot;&gt;Takumi Ichimura&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tanabe_K/0/1/0/all/0/1&quot;&gt;Kousuke Tanabe&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.04095">
<title>Predicting Twitter User Socioeconomic Attributes with Network and Language Information. (arXiv:1804.04095v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1804.04095</link>
<description rdf:parseType="Literal">&lt;p&gt;Inferring socioeconomic attributes of social media users such as occupation
and income is an important problem in computational social science. Automated
inference of such characteristics has applications in personalised recommender
systems, targeted computational advertising and online political campaigning.
While previous work has shown that language features can reliably predict
socioeconomic attributes on Twitter, employing information coming from users&apos;
social networks has not yet been explored for such complex user
characteristics. In this paper, we describe a method for predicting the
occupational class and the income of Twitter users given information extracted
from their extended networks by learning a low-dimensional vector
representation of users, i.e. graph embeddings. We use this representation to
train predictive models for occupational class and income. Results on two
publicly available datasets show that our method consistently outperforms the
state-of-the-art methods in both tasks. We also obtain further significant
improvements when we combine graph embeddings with textual features,
demonstrating that social network and language information are complementary.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aletras_N/0/1/0/all/0/1&quot;&gt;Nikolaos Aletras&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chamberlain_B/0/1/0/all/0/1&quot;&gt;Benjamin Paul Chamberlain&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1704.06259">
<title>A Semantic QA-Based Approach for Text Summarization Evaluation. (arXiv:1704.06259v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1704.06259</link>
<description rdf:parseType="Literal">&lt;p&gt;Many Natural Language Processing and Computational Linguistics applications
involves the generation of new texts based on some existing texts, such as
summarization, text simplification and machine translation. However, there has
been a serious problem haunting these applications for decades, that is, how to
automatically and accurately assess quality of these applications. In this
paper, we will present some preliminary results on one especially useful and
challenging problem in NLP system evaluation: how to pinpoint content
differences of two text passages (especially for large pas-sages such as
articles and books). Our idea is intuitive and very different from existing
approaches. We treat one text passage as a small knowledge base, and ask it a
large number of questions to exhaustively identify all content points in it. By
comparing the correctly answered questions from two text passages, we will be
able to compare their content precisely. The experiment using 2007 DUC
summarization corpus clearly shows promising results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_P/0/1/0/all/0/1&quot;&gt;Ping Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1&quot;&gt;Fei Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1&quot;&gt;Tong Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ding_W/0/1/0/all/0/1&quot;&gt;Wei Ding&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1706.01320">
<title>3D Pathfinding and Collision Avoidance Using Uneven Search-space Quantization and Visual Cone Search. (arXiv:1706.01320v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1706.01320</link>
<description rdf:parseType="Literal">&lt;p&gt;Pathfinding is a very popular area in computer game development. While
two-dimensional (2D) pathfinding is widely applied in most of the popular game
engines, little implementation of real three-dimensional (3D) pathfinding can
be found. This research presents a dynamic search space optimization algorithm
which can be applied to tessellate 3D search space unevenly, significantly
reducing the total number of resulting nodes. The algorithm can be used with
popular pathfinding algorithms in 3D game engines. Furthermore, a simplified
standalone 3D pathfinding algorithm is proposed in this paper. The proposed
algorithm relies on ray-casting or line vision to generate a feasible path
during runtime without requiring division of the search space into a 3D grid.
Both of the proposed algorithms are simulated on Unreal Engine to show
innerworkings and resultant path comparison with A*. The advantages and
shortcomings of the proposed algorithms are also discussed along with future
directions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pandit_D/0/1/0/all/0/1&quot;&gt;Diptangshu Pandit&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.05360">
<title>Embedding Deep Networks into Visual Explanations. (arXiv:1709.05360v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1709.05360</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we propose a novel explanation module to explain the
predictions made by a deep network. The explanation module works by embedding a
high-dimensional deep network layer nonlinearly into a low-dimensional
explanation space while retaining faithfulness, so that the original deep
learning predictions can be constructed from the few concepts extracted by the
explanation module. We then visualize such concepts for human to learn about
the high-level concepts that deep learning is using to make decisions. We
propose an algorithm called Sparse Reconstruction Autoencoder (SRAE) for
learning the embedding to the explanation space. SRAE aims to reconstruct part
of the original feature space while retaining faithfulness. A pull-away term is
applied to SRAE to make the explanation space more orthogonal. A visualization
system is then introduced for human understanding of the features in the
explanation space. The proposed method is applied to explain CNN models in
image classification tasks, and several novel metrics are introduced to
evaluate the performance of explanations quantitatively without human
involvement. Experiments show that the proposed approach generates interesting
explanations of the mechanisms CNN use for making predictions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qi_Z/0/1/0/all/0/1&quot;&gt;Zhongang Qi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khorram_S/0/1/0/all/0/1&quot;&gt;Saeed Khorram&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_F/0/1/0/all/0/1&quot;&gt;Fuxin Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.06922">
<title>Emergent Translation in Multi-Agent Communication. (arXiv:1710.06922v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1710.06922</link>
<description rdf:parseType="Literal">&lt;p&gt;While most machine translation systems to date are trained on large parallel
corpora, humans learn language in a different way: by being grounded in an
environment and interacting with other humans. In this work, we propose a
communication game where two agents, native speakers of their own respective
languages, jointly learn to solve a visual referential task. We find that the
ability to understand and translate a foreign language emerges as a means to
achieve shared goals. The emergent translation is interactive and multimodal,
and crucially does not require parallel corpora, but only monolingual,
independent text and corresponding images. Our proposed translation model
achieves this by grounding the source and target languages into a shared visual
modality, and outperforms several baselines on both word-level and
sentence-level translation tasks. Furthermore, we show that agents in a
multilingual community learn to translate better and faster than in a bilingual
communication setting.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1&quot;&gt;Jason Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cho_K/0/1/0/all/0/1&quot;&gt;Kyunghyun Cho&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Weston_J/0/1/0/all/0/1&quot;&gt;Jason Weston&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kiela_D/0/1/0/all/0/1&quot;&gt;Douwe Kiela&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.00293">
<title>Attentional Multilabel Learning over Graphs: A Message Passing Approach. (arXiv:1804.00293v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1804.00293</link>
<description rdf:parseType="Literal">&lt;p&gt;We address a largely open problem of multilabel classification over graphs.
Unlike traditional vector input, a graph has rich variable-size substructures
which are related to the labels in some ways. We believe that uncovering these
relations might hold the key to classification performance and explainability.
We introduce GAML (Graph Attentional Multi-Label learning), a novel graph
neural network that can handle this problem effectively. GAML regards labels as
auxiliary nodes and models them in conjunction with the input graph. By
applying message passing and attention mechanisms to both the label nodes and
the input nodes iteratively, GAML can capture the relations between the labels
and the input subgraphs at various resolution scales. Moreover, our model can
take advantage of explicit label dependencies. It also scales linearly with the
number of labels and graph size thanks to our proposed hierarchical attention.
We evaluate GAML on an extensive set of experiments with both graph-structured
inputs and classical unstructured inputs. The results show that GAML
significantly outperforms other competing methods. Importantly, GAML enables
intuitive visualizations for better understanding of the label-substructure
relations and explanation of the model behaviors.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Do_K/0/1/0/all/0/1&quot;&gt;Kien Do&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tran_T/0/1/0/all/0/1&quot;&gt;Truyen Tran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1&quot;&gt;Thin Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Venkatesh_S/0/1/0/all/0/1&quot;&gt;Svetha Venkatesh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.03720">
<title>Gotta Learn Fast: A New Benchmark for Generalization in RL. (arXiv:1804.03720v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1804.03720</link>
<description rdf:parseType="Literal">&lt;p&gt;In this report, we present a new reinforcement learning (RL) benchmark based
on the Sonic the Hedgehog (TM) video game franchise. This benchmark is intended
to measure the performance of transfer learning and few-shot learning
algorithms in the RL domain. We also present and evaluate some baseline
algorithms on the new benchmark.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nichol_A/0/1/0/all/0/1&quot;&gt;Alex Nichol&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pfau_V/0/1/0/all/0/1&quot;&gt;Vicki Pfau&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hesse_C/0/1/0/all/0/1&quot;&gt;Christopher Hesse&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Klimov_O/0/1/0/all/0/1&quot;&gt;Oleg Klimov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schulman_J/0/1/0/all/0/1&quot;&gt;John Schulman&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.03958">
<title>Interdependent Gibbs Samplers. (arXiv:1804.03958v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1804.03958</link>
<description rdf:parseType="Literal">&lt;p&gt;Gibbs sampling, as a model learning method, is known to produce the most
accurate results available in a variety of domains, and is a de facto standard
in these domains. Yet, it is also well known that Gibbs random walks usually
have bottlenecks, sometimes termed &quot;local maxima&quot;, and thus samplers often
return suboptimal solutions. In this paper we introduce a variation of the
Gibbs sampler which yields high likelihood solutions significantly more often
than the regular Gibbs sampler.
&lt;/p&gt;
&lt;p&gt;Specifically, we show that combining multiple samplers, with certain
dependence (coupling) between them, results in higher likelihood solutions.
This side-steps the well known issue of identifiability, which has been the
obstacle to combining samplers in previous work. We evaluate the approach on a
Latent Dirichlet Allocation model, and also on HMM&apos;s, where precise computation
of likelihoods and comparisons to the standard EM algorithm are possible.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kozdoba_M/0/1/0/all/0/1&quot;&gt;Mark Kozdoba&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mannor_S/0/1/0/all/0/1&quot;&gt;Shie Mannor&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.03987">
<title>Analysis on the Nonlinear Dynamics of Deep Neural Networks: Topological Entropy and Chaos. (arXiv:1804.03987v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1804.03987</link>
<description rdf:parseType="Literal">&lt;p&gt;The theoretical explanation for deep neural network (DNN) is still an open
problem. In this paper DNN is considered as a discrete-time dynamical system
due to its layered structure. The complexity provided by the nonlinearity in
the dynamics is analyzed in terms of topological entropy and chaos
characterized by Lyapunov exponents. The properties revealed for the dynamics
of DNN are applied to analyze the corresponding capabilities of classification
and generalization.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1&quot;&gt;Husheng Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.04058">
<title>Analyzing Self-Driving Cars on Twitter. (arXiv:1804.04058v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1804.04058</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper studies users&apos; perception regarding a controversial product,
namely self-driving (autonomous) cars. To find people&apos;s opinion regarding this
new technology, we used an annotated Twitter dataset, and extracted the topics
in positive and negative tweets using an unsupervised, probabilistic model
known as topic modeling. We later used the topics, as well as linguist and
Twitter specific features to classify the sentiment of the tweets. Regarding
the opinions, the result of our analysis shows that people are optimistic and
excited about the future technology, but at the same time they find it
dangerous and not reliable. For the classification task, we found Twitter
specific features, such as hashtags as well as linguistic features such as
emphatic words among top attributes in classifying the sentiment of the tweets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sadiq_R/0/1/0/all/0/1&quot;&gt;Rizwan Sadiq&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khan_M/0/1/0/all/0/1&quot;&gt;Mohsin Khan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1209.0367">
<title>Seeded Graph Matching. (arXiv:1209.0367v4 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1209.0367</link>
<description rdf:parseType="Literal">&lt;p&gt;Given two graphs, the graph matching problem is to align the two vertex sets
so as to minimize the number of adjacency disagreements between the two graphs.
The seeded graph matching problem is the graph matching problem when we are
first given a partial alignment that we are tasked with completing. In this
paper, we modify the state-of-the-art approximate graph matching algorithm
&quot;FAQ&quot; of Vogelstein et al. (2015) to make it a fast approximate seeded graph
matching algorithm, adapt its applicability to include graphs with differently
sized vertex sets, and extend the algorithm so as to provide, for each
individual vertex, a nomination list of likely matches. We demonstrate the
effectiveness of our algorithm via simulation and real data experiments;
indeed, knowledge of even a few seeds can be extremely effective when our
seeded graph matching algorithm is used to recover a naturally existing
alignment that is only partially observed.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Fishkind_D/0/1/0/all/0/1&quot;&gt;Donniell E. Fishkind&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Adali_S/0/1/0/all/0/1&quot;&gt;Sancar Adali&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Patsolic_H/0/1/0/all/0/1&quot;&gt;Heather G. Patsolic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Meng_L/0/1/0/all/0/1&quot;&gt;Lingyao Meng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Singh_D/0/1/0/all/0/1&quot;&gt;Digvijay Singh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lyzinski_V/0/1/0/all/0/1&quot;&gt;Vince Lyzinski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Priebe_C/0/1/0/all/0/1&quot;&gt;Carey E. Priebe&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1702.01000">
<title>Sharp Convergence Rates for Forward Regression in High-Dimensional Sparse Linear Models. (arXiv:1702.01000v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1702.01000</link>
<description rdf:parseType="Literal">&lt;p&gt;Forward regression is a statistical model selection and estimation procedure
which inductively selects covariates that add predictive power into a working
statistical regression model. Once a model is selected, unknown regression
parameters are estimated by least squares. This paper analyzes forward
regression in high-dimensional sparse linear models. Probabilistic bounds for
prediction error norm and number of selected covariates are proved. The
analysis in this paper gives sharp rates and does not require beta-min or
irrepresentability conditions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kozbur_D/0/1/0/all/0/1&quot;&gt;Damian Kozbur&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1707.07012">
<title>Learning Transferable Architectures for Scalable Image Recognition. (arXiv:1707.07012v4 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1707.07012</link>
<description rdf:parseType="Literal">&lt;p&gt;Developing neural network image classification models often requires
significant architecture engineering. In this paper, we study a method to learn
the model architectures directly on the dataset of interest. As this approach
is expensive when the dataset is large, we propose to search for an
architectural building block on a small dataset and then transfer the block to
a larger dataset. The key contribution of this work is the design of a new
search space (the &quot;NASNet search space&quot;) which enables transferability. In our
experiments, we search for the best convolutional layer (or &quot;cell&quot;) on the
CIFAR-10 dataset and then apply this cell to the ImageNet dataset by stacking
together more copies of this cell, each with their own parameters to design a
convolutional architecture, named &quot;NASNet architecture&quot;. We also introduce a
new regularization technique called ScheduledDropPath that significantly
improves generalization in the NASNet models. On CIFAR-10 itself, NASNet
achieves 2.4% error rate, which is state-of-the-art. On ImageNet, NASNet
achieves, among the published works, state-of-the-art accuracy of 82.7% top-1
and 96.2% top-5 on ImageNet. Our model is 1.2% better in top-1 accuracy than
the best human-invented architectures while having 9 billion fewer FLOPS - a
reduction of 28% in computational demand from the previous state-of-the-art
model. When evaluated at different levels of computational cost, accuracies of
NASNets exceed those of the state-of-the-art human-designed models. For
instance, a small version of NASNet also achieves 74% top-1 accuracy, which is
3.1% better than equivalently-sized, state-of-the-art models for mobile
platforms. Finally, the learned features by NASNet used with the Faster-RCNN
framework surpass state-of-the-art by 4.0% achieving 43.1% mAP on the COCO
dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zoph_B/0/1/0/all/0/1&quot;&gt;Barret Zoph&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vasudevan_V/0/1/0/all/0/1&quot;&gt;Vijay Vasudevan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shlens_J/0/1/0/all/0/1&quot;&gt;Jonathon Shlens&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Le_Q/0/1/0/all/0/1&quot;&gt;Quoc V. Le&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.02929">
<title>Data Augmentation by Pairing Samples for Images Classification. (arXiv:1801.02929v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1801.02929</link>
<description rdf:parseType="Literal">&lt;p&gt;Data augmentation is a widely used technique in many machine learning tasks,
such as image classification, to virtually enlarge the training dataset size
and avoid overfitting. Traditional data augmentation techniques for image
classification tasks create new samples from the original training data by, for
example, flipping, distorting, adding a small amount of noise to, or cropping a
patch from an original image. In this paper, we introduce a simple but
surprisingly effective data augmentation technique for image classification
tasks. With our technique, named SamplePairing, we synthesize a new sample from
one image by overlaying another image randomly chosen from the training data
(i.e., taking an average of two images for each pixel). By using two images
randomly selected from the training set, we can generate $N^2$ new samples from
$N$ training samples. This simple data augmentation technique significantly
improved classification accuracy for all the tested datasets; for example, the
top-1 error rate was reduced from 33.5% to 29.0% for the ILSVRC 2012 dataset
with GoogLeNet and from 8.22% to 6.93% in the CIFAR-10 dataset. We also show
that our SamplePairing technique largely improved accuracy when the number of
samples in the training set was very small. Therefore, our technique is more
valuable for tasks with a limited amount of training data, such as medical
imaging tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Inoue_H/0/1/0/all/0/1&quot;&gt;Hiroshi Inoue&lt;/a&gt;</dc:creator>
</item></rdf:RDF>