<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Good papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Good Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2017-11-30T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.11059"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.11240"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.11486"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1703.01780"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.11068"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.11124"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.11135"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.11157"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.11175"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.11180"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.11200"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.11225"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.11231"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.11289"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.11383"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.11443"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.11508"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.11543"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.11565"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1608.07685"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1703.00441"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1704.01161"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1706.09076"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1707.00183"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1707.06633"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1707.08783"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.07654"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1612.01895"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.11034"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.11053"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.11057"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.11139"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.11189"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.11216"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.11279"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.11294"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.11386"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.11394"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.11408"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.11423"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.11510"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.11511"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.11527"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.11542"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.11561"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.11581"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.11586"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1602.03943"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1707.00372"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.10571"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.06719"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.06798"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.08018"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.09889"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.10173"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.10337"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.10635"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.10925"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.10907"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1711.11059">
<title>Gaussian Process Neurons Learn Stochastic Activation Functions. (arXiv:1711.11059v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1711.11059</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose stochastic, non-parametric activation functions that are fully
learnable and individual to each neuron. Complexity and the risk of overfitting
are controlled by placing a Gaussian process prior over these functions. The
result is the Gaussian process neuron, a probabilistic unit that can be used as
the basic building block for probabilistic graphical models that resemble the
structure of neural networks. The proposed model can intrinsically handle
uncertainties in its inputs and self-estimate the confidence of its
predictions. Using variational Bayesian inference and the central limit
theorem, a fully deterministic loss function is derived, allowing it to be
trained as efficiently as a conventional neural network using mini-batch
gradient descent. The posterior distribution of activation functions is
inferred from the training data alongside the weights of the network.
&lt;/p&gt;
&lt;p&gt;The proposed model favorably compares to deep Gaussian processes, both in
model complexity and efficiency of inference. It can be directly applied to
recurrent or convolutional network structures, allowing its use in audio and
image processing tasks.
&lt;/p&gt;
&lt;p&gt;As an preliminary empirical evaluation we present experiments on regression
and classification tasks, in which our model achieves performance comparable to
or better than a Dropout regularized neural network with a fixed activation
function. Experiments are ongoing and results will be added as they become
available.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Urban_S/0/1/0/all/0/1&quot;&gt;Sebastian Urban&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Basalla_M/0/1/0/all/0/1&quot;&gt;Marcus Basalla&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Smagt_P/0/1/0/all/0/1&quot;&gt;Patrick van der Smagt&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.11240">
<title>Quantum Neuron: an elementary building block for machine learning on quantum computers. (arXiv:1711.11240v1 [quant-ph])</title>
<link>http://arxiv.org/abs/1711.11240</link>
<description rdf:parseType="Literal">&lt;p&gt;Even the most sophisticated artificial neural networks are built by
aggregating substantially identical units called neurons. A neuron receives
multiple signals, internally combines them, and applies a non-linear function
to the resulting weighted sum. Several attempts to generalize neurons to the
quantum regime have been proposed, but all proposals collided with the
difficulty of implementing non-linear activation functions, which is essential
for classical neurons, due to the linear nature of quantum mechanics. Here we
propose a solution to this roadblock in the form of a small quantum circuit
that naturally simulates neurons with threshold activation. Our quantum circuit
defines a building block, the &quot;quantum neuron&quot;, that can reproduce a variety of
classical neural network constructions while maintaining the ability to process
superpositions of inputs and preserve quantum coherence and entanglement. In
the construction of feedforward networks of quantum neurons, we provide
numerical evidence that the network not only can learn a function when trained
with superposition of inputs and the corresponding output, but that this
training suffices to learn the function on all individual inputs separately.
When arranged to mimic Hopfield networks, quantum neural networks exhibit
properties of associative memory. Patterns are encoded using the simple Hebbian
rule for the weights and we demonstrate attractor dynamics from corrupted
inputs. Finally, the fact that our quantum model closely captures (traditional)
neural network dynamics implies that the vast body of literature and results on
neural networks becomes directly relevant in the context of quantum machine
learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Cao_Y/0/1/0/all/0/1&quot;&gt;Yudong Cao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Guerreschi_G/0/1/0/all/0/1&quot;&gt;Gian Giacomo Guerreschi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Aspuru_Guzik_A/0/1/0/all/0/1&quot;&gt;Al&amp;#xe1;n Aspuru-Guzik&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.11486">
<title>Uncertainty Estimates for Efficient Neural Network-based Dialogue Policy Optimisation. (arXiv:1711.11486v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1711.11486</link>
<description rdf:parseType="Literal">&lt;p&gt;In statistical dialogue management, the dialogue manager learns a policy that
maps a belief state to an action for the system to perform. Efficient
exploration is key to successful policy optimisation. Current deep
reinforcement learning methods are very promising but rely on epsilon-greedy
exploration, thus subjecting the user to a random choice of action during
learning. Alternative approaches such as Gaussian Process SARSA (GPSARSA)
estimate uncertainties and are sample efficient, leading to better user
experience, but on the expense of a greater computational complexity. This
paper examines approaches to extract uncertainty estimates from deep Q-networks
(DQN) in the context of dialogue management. We perform an extensive benchmark
of deep Bayesian methods to extract uncertainty estimates, namely
Bayes-By-Backprop, dropout, its concrete variation, bootstrapped ensemble and
alpha-divergences, combining it with DQN algorithm.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tegho_C/0/1/0/all/0/1&quot;&gt;Christopher Tegho&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Budzianowski_P/0/1/0/all/0/1&quot;&gt;Pawe&amp;#x142; Budzianowski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gasic_M/0/1/0/all/0/1&quot;&gt;Milica Ga&amp;#x161;i&amp;#x107;&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1703.01780">
<title>Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results. (arXiv:1703.01780v3 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1703.01780</link>
<description rdf:parseType="Literal">&lt;p&gt;The recently proposed Temporal Ensembling has achieved state-of-the-art
results in several semi-supervised learning benchmarks. It maintains an
exponential moving average of label predictions on each training example, and
penalizes predictions that are inconsistent with this target. However, because
the targets change only once per epoch, Temporal Ensembling becomes unwieldy
when learning large datasets. To overcome this problem, we propose Mean
Teacher, a method that averages model weights instead of label predictions. As
an additional benefit, Mean Teacher improves test accuracy and enables training
with fewer labels than Temporal Ensembling. Without changing the network
architecture, Mean Teacher achieves an error rate of 4.35% on SVHN with 250
labels, outperforming Temporal Ensembling trained with 1000 labels. We also
show that a good network architecture is crucial to performance. Combining Mean
Teacher and Residual Networks, we improve the state of the art on CIFAR-10 with
4000 labels from 10.55% to 6.28%, and on ImageNet 2012 with 10% of the labels
from 35.24% to 9.11%.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tarvainen_A/0/1/0/all/0/1&quot;&gt;Antti Tarvainen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Valpola_H/0/1/0/all/0/1&quot;&gt;Harri Valpola&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.11068">
<title>Happiness Pursuit: Personality Learning in a Society of Agents. (arXiv:1711.11068v1 [cs.MA])</title>
<link>http://arxiv.org/abs/1711.11068</link>
<description rdf:parseType="Literal">&lt;p&gt;Modeling personality is a challenging problem with applications spanning
computer games, virtual assistants, online shopping and education. Many
techniques have been tried, ranging from neural networks to computational
cognitive architectures. However, most approaches rely on examples with
hand-crafted features and scenarios. Here, we approach learning a personality
by training agents using a Deep Q-Network (DQN) model on rewards based on
psychoanalysis, against hand-coded AI in the game of Pong. As a result, we
obtain 4 agents, each with its own personality. Then, we define happiness of an
agent, which can be seen as a measure of alignment with agent&apos;s objective
function, and study it when agents play both against hand-coded AI, and against
each other. We find that the agents that achieve higher happiness during
testing against hand-coded AI, have lower happiness when competing against each
other. This suggests that higher happiness in testing is a sign of overfitting
in learning to interact with hand-coded AI, and leads to worse performance
against agents with different personalities.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Muszynski_R/0/1/0/all/0/1&quot;&gt;Rafa&amp;#x142; Muszy&amp;#x144;ski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jun Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.11124">
<title>Improving Latent User Models in Online Social Media. (arXiv:1711.11124v1 [cs.SI])</title>
<link>http://arxiv.org/abs/1711.11124</link>
<description rdf:parseType="Literal">&lt;p&gt;Modern social platforms are characterized by the presence of rich
user-behavior data associated with the publication, sharing and consumption of
textual content. Users interact with content and with each other in a complex
and dynamic social environment while simultaneously evolving over time. In
order to effectively characterize users and predict their future behavior in
such a setting, it is necessary to overcome several challenges. Content
heterogeneity and temporal inconsistency of behavior data result in severe
sparsity at the user level. In this paper, we propose a novel
mutual-enhancement framework to simultaneously partition and learn latent
activity profiles of users. We propose a flexible user partitioning approach to
effectively discover rare behaviors and tackle user-level sparsity. We
extensively evaluate the proposed framework on massive datasets from real-world
platforms including Q&amp;amp;A networks and interactive online courses (MOOCs). Our
results indicate significant gains over state-of-the-art behavior models ( 15%
avg ) in a varied range of tasks and our gains are further magnified for users
with limited interaction data. The proposed algorithms are amenable to
parallelization, scale linearly in the size of datasets, and provide
flexibility to model diverse facets of user behavior.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Krishnan_A/0/1/0/all/0/1&quot;&gt;Adit Krishnan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1&quot;&gt;Ashish Sharma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sundaram_H/0/1/0/all/0/1&quot;&gt;Hari Sundaram&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.11135">
<title>Video Captioning via Hierarchical Reinforcement Learning. (arXiv:1711.11135v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1711.11135</link>
<description rdf:parseType="Literal">&lt;p&gt;Video captioning is the task of automatically generating a textual
description of the actions in a video. Although previous work (e.g.
sequence-to-sequence model) has shown promising results in abstracting a coarse
description of a short video, it is still very challenging to caption a video
containing multiple fine-grained actions with a detailed description. This
paper aims to address the challenge by proposing a novel hierarchical
reinforcement learning framework for video captioning, where a high-level
Manager module learns to design sub-goals and a low-level Worker module
recognizes the primitive actions to fulfill the sub-goal. With this
compositional framework to reinforce video captioning at different levels, our
approach significantly outperforms all the baseline methods on a newly
introduced large-scale dataset for fine-grained video captioning. Furthermore,
our non-ensemble model has already achieved the state-of-the-art results on the
widely-used MSR-VTT dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;Xin Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1&quot;&gt;Wenhu Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1&quot;&gt;Jiawei Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yuan-Fang Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1&quot;&gt;William Yang Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.11157">
<title>A Semantic Loss Function for Deep Learning with Symbolic Knowledge. (arXiv:1711.11157v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1711.11157</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper develops a novel methodology for using symbolic knowledge in deep
learning. From first principles, we derive a semantic loss function that
bridges between neural output vectors and logical constraints. This loss
function captures how close the neural network is to satisfying the constraints
on its output. An experimental evaluation shows that our semantic loss function
effectively guides the learner to achieve (near-)state-of-the-art results on
semi-supervised multi-class classification. Moreover, it significantly
increases the ability of the neural network to predict structured objects, such
as rankings and paths. These discrete concepts are tremendously difficult to
learn, and benefit from a tight integration of deep learning and symbolic
reasoning methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1&quot;&gt;Jingyi Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1&quot;&gt;Zilu Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Friedman_T/0/1/0/all/0/1&quot;&gt;Tal Friedman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1&quot;&gt;Yitao Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Broeck_G/0/1/0/all/0/1&quot;&gt;Guy Van den Broeck&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.11175">
<title>Towards Data Quality Assessment in Online Advertising. (arXiv:1711.11175v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1711.11175</link>
<description rdf:parseType="Literal">&lt;p&gt;In online advertising, our aim is to match the advertisers with the most
relevant users to optimize the campaign performance. In the pursuit of
achieving this goal, multiple data sources provided by the advertisers or
third-party data providers are utilized to choose the set of users according to
the advertisers&apos; targeting criteria. In this paper, we present a framework that
can be applied to assess the quality of such data sources in large scale. This
framework efficiently evaluates the similarity of a specific data source
categorization to that of the ground truth, especially for those cases when the
ground truth is accessible only in aggregate, and the user-level information is
anonymized or unavailable due to privacy reasons. We propose multiple
methodologies within this framework, present some preliminary assessment
results, and evaluate how the methodologies compare to each other. We also
present two use cases where we can utilize the data quality assessment results:
the first use case is targeting specific user categories, and the second one is
forecasting the desirable audiences we can reach for an online advertising
campaign with pre-set targeting criteria.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Geyik_S/0/1/0/all/0/1&quot;&gt;Sahin Cem Geyik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_J/0/1/0/all/0/1&quot;&gt;Jianqiang Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shariat_S/0/1/0/all/0/1&quot;&gt;Shahriar Shariat&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dasdan_A/0/1/0/all/0/1&quot;&gt;Ali Dasdan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kolay_S/0/1/0/all/0/1&quot;&gt;Santanu Kolay&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.11180">
<title>Improved Learning in Evolution Strategies via Sparser Inter-Agent Network Topologies. (arXiv:1711.11180v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1711.11180</link>
<description rdf:parseType="Literal">&lt;p&gt;We draw upon a previously largely untapped literature on human collective
intelligence as a source of inspiration for improving deep learning. Implicit
in many algorithms that attempt to solve Deep Reinforcement Learning (DRL)
tasks is the network of processors along which parameter values are shared. So
far, existing approaches have implicitly utilized fully-connected networks, in
which all processors are connected. However, the scientific literature on human
collective intelligence suggests that complete networks may not always be the
most effective information network structures for distributed search through
complex spaces. Here we show that alternative topologies can improve deep
neural network training: we find that sparser networks learn higher rewards
faster, leading to learning improvements at lower communication costs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Adjodah_D/0/1/0/all/0/1&quot;&gt;Dhaval Adjodah&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Calacci_D/0/1/0/all/0/1&quot;&gt;Dan Calacci&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leng_Y/0/1/0/all/0/1&quot;&gt;Yan Leng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Krafft_P/0/1/0/all/0/1&quot;&gt;Peter Krafft&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moro_E/0/1/0/all/0/1&quot;&gt;Esteban Moro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pentland_A/0/1/0/all/0/1&quot;&gt;Alex Pentland&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.11200">
<title>Embedded Real-Time Fall Detection Using Deep Learning For Elderly Care. (arXiv:1711.11200v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1711.11200</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper proposes a real-time embedded fall detection system using a
DVS(Dynamic Vision Sensor) that has never been used for traditional fall
detection, a dataset for fall detection using that, and a DVS-TN(DVS-Temporal
Network). The first contribution is building a DVS Falls Dataset, which made
our network to recognize a much greater variety of falls than the existing
datasets that existed before and solved privacy issues using the DVS. Secondly,
we introduce the DVS-TN : optimized deep learning network to detect falls using
DVS. Finally, we implemented a fall detection system which can run on
low-computing H/W with real-time, and tested on DVS Falls Dataset that takes
into account various falls situations. Our approach achieved 95.5% on the
F1-score and operates at 31.25 FPS on NVIDIA Jetson TX1 board.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lee_H/0/1/0/all/0/1&quot;&gt;Hyunwoo Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kim_J/0/1/0/all/0/1&quot;&gt;Jooyoung Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yang_D/0/1/0/all/0/1&quot;&gt;Dojun Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kim_J/0/1/0/all/0/1&quot;&gt;Joon-Ho Kim&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.11225">
<title>Variational Deep Q Network. (arXiv:1711.11225v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1711.11225</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a framework that directly tackles the probability distribution of
the value function parameters in Deep Q Network (DQN), with powerful
variational inference subroutines to approximate the posterior of the
parameters. We will establish the equivalence between our proposed surrogate
objective and variational inference loss. Our new algorithm achieves efficient
exploration and performs well on large scale chain Markov Decision Process
(MDP).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_Y/0/1/0/all/0/1&quot;&gt;Yunhao Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kucukelbir_A/0/1/0/all/0/1&quot;&gt;Alp Kucukelbir&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.11231">
<title>Knowledge Graph Embedding with Iterative Guidance from Soft Rules. (arXiv:1711.11231v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1711.11231</link>
<description rdf:parseType="Literal">&lt;p&gt;Embedding knowledge graphs (KGs) into continuous vector spaces is a focus of
current research. Combining such an embedding model with logic rules has
recently attracted increasing attention. Most previous attempts made a one-time
injection of logic rules, ignoring the interactive nature between embedding
learning and logical inference. And they focused only on hard rules, which
always hold with no exception and usually require extensive manual effort to
create or validate. In this paper, we propose Rule-Guided Embedding (RUGE), a
novel paradigm of KG embedding with iterative guidance from soft rules. RUGE
enables an embedding model to learn simultaneously from 1) labeled triples that
have been directly observed in a given KG, 2) unlabeled triples whose labels
are going to be predicted iteratively, and 3) soft rules with various
confidence levels extracted automatically from the KG. In the learning process,
RUGE iteratively queries rules to obtain soft labels for unlabeled triples, and
integrates such newly labeled triples to update the embedding model. Through
this iterative procedure, knowledge embodied in logic rules may be better
transferred into the learned embeddings. We evaluate RUGE in link prediction on
Freebase and YAGO. Experimental results show that: 1) with rule knowledge
injected iteratively, RUGE achieves significant and consistent improvements
over state-of-the-art baselines; and 2) despite their uncertainties,
automatically extracted soft rules are highly beneficial to KG embedding, even
those with moderate confidence levels. The code and data used for this paper
can be obtained from https://github.com/iieir-km/RUGE.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_S/0/1/0/all/0/1&quot;&gt;Shu Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1&quot;&gt;Quan Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1&quot;&gt;Lihong Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1&quot;&gt;Bin Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_L/0/1/0/all/0/1&quot;&gt;Li Guo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.11289">
<title>Learning to Compose Skills. (arXiv:1711.11289v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1711.11289</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a differentiable framework capable of learning a wide variety of
compositions of simple policies that we call skills. By recursively composing
skills with themselves, we can create hierarchies that display complex
behavior. Skill networks are trained to generate skill-state embeddings that
are provided as inputs to a trainable composition function, which in turn
outputs a policy for the overall task. Our experiments on an environment
consisting of multiple collect and evade tasks show that this architecture is
able to quickly build complex skills from simpler ones. Furthermore, the
learned composition function displays some transfer to unseen combinations of
skills, allowing for zero-shot generalizations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sahni_H/0/1/0/all/0/1&quot;&gt;Himanshu Sahni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1&quot;&gt;Saurabh Kumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tejani_F/0/1/0/all/0/1&quot;&gt;Farhan Tejani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Isbell_C/0/1/0/all/0/1&quot;&gt;Charles Isbell&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.11383">
<title>Learning to Learn from Weak Supervision by Full Supervision. (arXiv:1711.11383v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1711.11383</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we propose a method for training neural networks when we have
a large set of data with weak labels and a small amount of data with true
labels. In our proposed model, we train two neural networks: a target network,
the learner and a confidence network, the meta-learner. The target network is
optimized to perform a given task and is trained using a large set of unlabeled
data that are weakly annotated. We propose to control the magnitude of the
gradient updates to the target network using the scores provided by the second
confidence network, which is trained on a small amount of supervised data. Thus
we avoid that the weight updates computed from noisy labels harm the quality of
the target network model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Dehghani_M/0/1/0/all/0/1&quot;&gt;Mostafa Dehghani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Severyn_A/0/1/0/all/0/1&quot;&gt;Aliaksei Severyn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rothe_S/0/1/0/all/0/1&quot;&gt;Sascha Rothe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kamps_J/0/1/0/all/0/1&quot;&gt;Jaap Kamps&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.11443">
<title>ConvNets and ImageNet Beyond Accuracy: Explanations, Bias Detection, Adversarial Examples and Model Criticism. (arXiv:1711.11443v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1711.11443</link>
<description rdf:parseType="Literal">&lt;p&gt;ConvNets and Imagenet have driven the recent success of deep learning for
image classification. However, the marked slowdown in performance improvement,
the recent studies on the lack of robustness of neural networks to adversarial
examples and their tendency to exhibit undesirable biases (e.g racial biases)
questioned the reliability and the sustained development of these methods. This
work investigates these questions from the perspective of the end-user by using
human subject studies and explanations. We experimentally demonstrate that the
accuracy and robustness of ConvNets measured on Imagenet are underestimated. We
show that explanations can mitigate the impact of misclassified adversarial
examples from the perspective of the end-user and we introduce a novel tool for
uncovering the undesirable biases learned by a model. These contributions also
show that explanations are a promising tool for improving our understanding of
ConvNets&apos; predictions and for designing more reliable models
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stock_P/0/1/0/all/0/1&quot;&gt;Pierre Stock&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cisse_M/0/1/0/all/0/1&quot;&gt;Moustapha Cisse&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.11508">
<title>Calculating Semantic Similarity between Academic Articles using Topic Event and Ontology. (arXiv:1711.11508v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1711.11508</link>
<description rdf:parseType="Literal">&lt;p&gt;Determining semantic similarity between academic documents is crucial to many
tasks such as plagiarism detection, automatic technical survey and semantic
search. Current studies mostly focus on semantic similarity between concepts,
sentences and short text fragments. However, document-level semantic matching
is still based on statistical information in surface level, neglecting article
structures and global semantic meanings, which may cause the deviation in
document understanding. In this paper, we focus on the document-level semantic
similarity issue for academic literatures with a novel method. We represent
academic articles with topic events that utilize multiple information profiles,
such as research purposes, methodologies and domains to integrally describe the
research work, and calculate the similarity between topic events based on the
domain ontology to acquire the semantic similarity between articles.
Experiments show that our approach achieves significant performance compared to
state-of-the-art methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1&quot;&gt;Ming Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lang_B/0/1/0/all/0/1&quot;&gt;Bo Lang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gu_Z/0/1/0/all/0/1&quot;&gt;Zepeng Gu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.11543">
<title>Embodied Question Answering. (arXiv:1711.11543v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1711.11543</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a new AI task -- Embodied Question Answering (EmbodiedQA) -- where
an agent is spawned at a random location in a 3D environment and asked a
natural language question (&quot;What color is the car?&quot;). In order to answer, the
agent must first intelligently navigate to explore the environment, gather
information through first-person (egocentric) vision, and then answer the
question (&quot;orange&quot;).
&lt;/p&gt;
&lt;p&gt;This challenging task requires a range of AI skills -- active perception,
language understanding, goal-driven navigation, commonsense reasoning, and
grounding of language into actions. In this work, we develop the environments,
end-to-end-trained reinforcement learning agents, and evaluation protocols for
EmbodiedQA.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Das_A/0/1/0/all/0/1&quot;&gt;Abhishek Das&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Datta_S/0/1/0/all/0/1&quot;&gt;Samyak Datta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gkioxari_G/0/1/0/all/0/1&quot;&gt;Georgia Gkioxari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1&quot;&gt;Stefan Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Parikh_D/0/1/0/all/0/1&quot;&gt;Devi Parikh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Batra_D/0/1/0/all/0/1&quot;&gt;Dhruv Batra&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.11565">
<title>Deep Neural Networks for Multiple Speaker Detection and Localization. (arXiv:1711.11565v1 [cs.SD])</title>
<link>http://arxiv.org/abs/1711.11565</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose to use neural networks (NNs) for simultaneous detection and
localization of multiple sound sources in Human-Robot Interaction (HRI). Unlike
conventional signal processing techniques, NN-based Sound Source Localization
(SSL) methods are relatively straightforward and require no or fewer
assumptions that hardly hold in real HRI scenarios. Previously, NN-based
methods have been successfully applied to single SSL problems, which do not
extend to multiple sources in terms of detection and localization. In this
paper, we thus propose a likelihood-based encoding of the network output, which
naturally allows the detection of an arbitrary number of sources. In addition,
we investigate the use of sub-band cross-correlation information as features
for better localization in sound mixtures, as well as three different NN
architectures based on different processing motivations. Experiments on real
data recorded from the robot show that our NN-based methods significantly
outperform the popular spatial spectrum-based approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_W/0/1/0/all/0/1&quot;&gt;Weipeng He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Motlicek_P/0/1/0/all/0/1&quot;&gt;Petr Motlicek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Odobez_J/0/1/0/all/0/1&quot;&gt;Jean-Marc Odobez&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1608.07685">
<title>KSR: A Semantic Representation of Knowledge Graph within a Novel Unsupervised Paradigm. (arXiv:1608.07685v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1608.07685</link>
<description rdf:parseType="Literal">&lt;p&gt;Knowledge representation is a long-history topic in AI, which is very
important. A variety of models have been proposed for knowledge graph
embedding, which projects symbolic entities and relations into continuous
vector space. However, most related methods merely focus on the data-fitting of
knowledge graph, and ignore the interpretable semantic expression. Thus,
traditional embedding methods are not friendly for applications that require
semantic analysis, such as question answering and entity retrieval. To this
end, this paper proposes a semantic representation method for knowledge graph
\textbf{(KSR)}, which imposes a two-level hierarchical generative process that
globally extracts many aspects and then locally assigns a specific category in
each aspect for every triple. Since both aspects and categories are
semantics-relevant, the collection of categories in each aspect is treated as
the semantic representation of this triple. Extensive experiments show that our
model outperforms other state-of-the-art baselines substantially.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiao_H/0/1/0/all/0/1&quot;&gt;Han Xiao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_M/0/1/0/all/0/1&quot;&gt;Minlie Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1&quot;&gt;Xiaoyan Zhu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1703.00441">
<title>Learning to Optimize Neural Nets. (arXiv:1703.00441v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1703.00441</link>
<description rdf:parseType="Literal">&lt;p&gt;Learning to Optimize is a recently proposed framework for learning
optimization algorithms using reinforcement learning. In this paper, we explore
learning an optimization algorithm for training shallow neural nets. Such
high-dimensional stochastic optimization problems present interesting
challenges for existing reinforcement learning algorithms. We develop an
extension that is suited to learning optimization algorithms in this setting
and demonstrate that the learned optimization algorithm consistently
outperforms other known optimization algorithms even on unseen tasks and is
robust to changes in stochasticity of gradients and the neural net
architecture. More specifically, we show that an optimization algorithm trained
with the proposed method on the problem of training a neural net on MNIST
generalizes to the problems of training neural nets on the Toronto Faces
Dataset, CIFAR-10 and CIFAR-100.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_K/0/1/0/all/0/1&quot;&gt;Ke Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Malik_J/0/1/0/all/0/1&quot;&gt;Jitendra Malik&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1704.01161">
<title>Finite Sample Analyses for TD(0) with Function Approximation. (arXiv:1704.01161v3 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1704.01161</link>
<description rdf:parseType="Literal">&lt;p&gt;TD(0) is one of the most commonly used algorithms in reinforcement learning.
Despite this, there is no existing finite sample analysis for TD(0) with
function approximation, even for the linear case. Our work is the first to
provide such results. Existing convergence rates for Temporal Difference (TD)
methods apply only to somewhat modified versions, e.g., projected variants or
ones where stepsizes depend on unknown problem parameters. Our analyses obviate
these artificial alterations by exploiting strong properties of TD(0). We
provide convergence rates both in expectation and with high-probability. The
two are obtained via different approaches that use relatively unknown, recently
developed stochastic approximation techniques.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dalal_G/0/1/0/all/0/1&quot;&gt;Gal Dalal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Szorenyi_B/0/1/0/all/0/1&quot;&gt;Bal&amp;#xe1;zs Sz&amp;#xf6;r&amp;#xe9;nyi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Thoppe_G/0/1/0/all/0/1&quot;&gt;Gugan Thoppe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mannor_S/0/1/0/all/0/1&quot;&gt;Shie Mannor&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1706.09076">
<title>A Pig, an Angel and a Cactus Walk Into a Blender: A Descriptive Approach to Visual Blending. (arXiv:1706.09076v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1706.09076</link>
<description rdf:parseType="Literal">&lt;p&gt;A descriptive approach for automatic generation of visual blends is
presented. The implemented system, the Blender, is composed of two components:
the Mapper and the Visual Blender. The approach uses structured visual
representations along with sets of visual relations which describe how the
elements (in which the visual representation can be decomposed) relate among
each other. Our system is a hybrid blender, as the blending process starts at
the Mapper (conceptual level) and ends at the Visual Blender (visual
representation level). The experimental results show that the Blender is able
to create analogies from input mental spaces and produce well-composed blends,
which follow the rules imposed by its base-analogy and its relations. The
resulting blends are visually interesting and some can be considered as
unexpected.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cunha_J/0/1/0/all/0/1&quot;&gt;Jo&amp;#xe3;o M. Cunha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goncalves_J/0/1/0/all/0/1&quot;&gt;Jo&amp;#xe3;o Gon&amp;#xe7;alves&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Martins_P/0/1/0/all/0/1&quot;&gt;Pedro Martins&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Machado_P/0/1/0/all/0/1&quot;&gt;Penousal Machado&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cardoso_A/0/1/0/all/0/1&quot;&gt;Am&amp;#xed;lcar Cardoso&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1707.00183">
<title>Teacher-Student Curriculum Learning. (arXiv:1707.00183v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1707.00183</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose Teacher-Student Curriculum Learning (TSCL), a framework for
automatic curriculum learning, where the Student tries to learn a complex task
and the Teacher automatically chooses subtasks from a given set for the Student
to train on. We describe a family of Teacher algorithms that rely on the
intuition that the Student should practice more those tasks on which it makes
the fastest progress, i.e. where the slope of the learning curve is highest. In
addition, the Teacher algorithms address the problem of forgetting by also
choosing tasks where the Student&apos;s performance is getting worse. We demonstrate
that TSCL matches or surpasses the results of carefully hand-crafted curricula
in two tasks: addition of decimal numbers with LSTM and navigation in
Minecraft. Using our automatically generated curriculum enabled to solve a
Minecraft maze that could not be solved at all when training directly on
solving the maze, and the learning was an order of magnitude faster than
uniform sampling of subtasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Matiisen_T/0/1/0/all/0/1&quot;&gt;Tambet Matiisen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oliver_A/0/1/0/all/0/1&quot;&gt;Avital Oliver&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cohen_T/0/1/0/all/0/1&quot;&gt;Taco Cohen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schulman_J/0/1/0/all/0/1&quot;&gt;John Schulman&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1707.06633">
<title>Acting Thoughts: Towards a Mobile Robotic Service Assistant for Users with Limited Communication Skills. (arXiv:1707.06633v3 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1707.06633</link>
<description rdf:parseType="Literal">&lt;p&gt;As autonomous service robots become more affordable and thus available also
for the general public, there is a growing need for user friendly interfaces to
control the robotic system. Currently available control modalities typically
expect users to be able to express their desire through either touch, speech or
gesture commands. While this requirement is fulfilled for the majority of
users, paralyzed users may not be able to use such systems. In this paper, we
present a novel framework, that allows these users to interact with a robotic
service assistant in a closed-loop fashion, using only thoughts. The
brain-computer interface (BCI) system is composed of several interacting
components, i.e., non-invasive neuronal signal recording and decoding,
high-level task planning, motion and manipulation planning as well as
environment perception. In various experiments, we demonstrate its
applicability and robustness in real world scenarios, considering
fetch-and-carry tasks and tasks involving human-robot interaction. As our
results demonstrate, our system is capable of adapting to frequent changes in
the environment and reliably completing given tasks within a reasonable amount
of time. Combined with high-level planning and autonomous robotic systems,
interesting new perspectives open up for non-invasive BCI-based human-robot
interactions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Burget_F/0/1/0/all/0/1&quot;&gt;Felix Burget&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fiederer_L/0/1/0/all/0/1&quot;&gt;Lukas Dominique Josef Fiederer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kuhner_D/0/1/0/all/0/1&quot;&gt;Daniel Kuhner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Volker_M/0/1/0/all/0/1&quot;&gt;Martin V&amp;#xf6;lker&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aldinger_J/0/1/0/all/0/1&quot;&gt;Johannes Aldinger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schirrmeister_R/0/1/0/all/0/1&quot;&gt;Robin Tibor Schirrmeister&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Do_C/0/1/0/all/0/1&quot;&gt;Chau Do&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Boedecker_J/0/1/0/all/0/1&quot;&gt;Joschka Boedecker&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nebel_B/0/1/0/all/0/1&quot;&gt;Bernhard Nebel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ball_T/0/1/0/all/0/1&quot;&gt;Tonio Ball&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Burgard_W/0/1/0/all/0/1&quot;&gt;Wolfram Burgard&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1707.08783">
<title>Analysis of Italian Word Embeddings. (arXiv:1707.08783v4 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1707.08783</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work we analyze the performances of two of the most used word
embeddings algorithms, skip-gram and continuous bag of words on Italian
language. These algorithms have many hyper-parameter that have to be carefully
tuned in order to obtain accurate word representation in vectorial space. We
provide an accurate analysis and an evaluation, showing what are the best
configuration of parameters for specific tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tripodi_R/0/1/0/all/0/1&quot;&gt;Rocco Tripodi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pira_S/0/1/0/all/0/1&quot;&gt;Stefano Li Pira&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.07654">
<title>Deep Voice 3: 2000-Speaker Neural Text-to-Speech. (arXiv:1710.07654v2 [cs.SD] UPDATED)</title>
<link>http://arxiv.org/abs/1710.07654</link>
<description rdf:parseType="Literal">&lt;p&gt;We present Deep Voice 3, a fully-convolutional attention-based neural
text-to-speech (TTS) system. Deep Voice 3 matches state-of-the-art neural
speech synthesis systems in naturalness while training ten times faster. We
scale Deep Voice 3 to data set sizes unprecedented for TTS, training on more
than eight hundred hours of audio from over two thousand speakers. In addition,
we identify common error modes of attention-based speech synthesis networks,
demonstrate how to mitigate them, and compare several different waveform
synthesis methods. We also describe how to scale inference to ten million
queries per day on one single-GPU server.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ping_W/0/1/0/all/0/1&quot;&gt;Wei Ping&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peng_K/0/1/0/all/0/1&quot;&gt;Kainan Peng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gibiansky_A/0/1/0/all/0/1&quot;&gt;Andrew Gibiansky&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Arik_S/0/1/0/all/0/1&quot;&gt;Sercan O. Arik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kannan_A/0/1/0/all/0/1&quot;&gt;Ajay Kannan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Narang_S/0/1/0/all/0/1&quot;&gt;Sharan Narang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Raiman_J/0/1/0/all/0/1&quot;&gt;Jonathan Raiman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Miller_J/0/1/0/all/0/1&quot;&gt;John Miller&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1612.01895">
<title>Multimodal Transfer: A Hierarchical Deep Convolutional Neural Network for Fast Artistic Style Transfer. (arXiv:1612.01895v2 [cs.CV] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1612.01895</link>
<description rdf:parseType="Literal">&lt;p&gt;Transferring artistic styles onto everyday photographs has become an
extremely popular task in both academia and industry. Recently, offline
training has replaced on-line iterative optimization, enabling nearly real-time
stylization. When those stylization networks are applied directly to
high-resolution images, however, the style of localized regions often appears
less similar to the desired artistic style. This is because the transfer
process fails to capture small, intricate textures and maintain correct texture
scales of the artworks. Here we propose a multimodal convolutional neural
network that takes into consideration faithful representations of both color
and luminance channels, and performs stylization hierarchically with multiple
losses of increasing scales. Compared to state-of-the-art networks, our network
can also perform style transfer in nearly real-time by conducting much more
sophisticated training offline. By properly handling style and texture cues at
multiple scales using several modalities, we can transfer not just large-scale,
obvious style cues but also subtle, exquisite ones. That is, our scheme can
generate results that are visually pleasing and more similar to multiple
desired artistic styles with color and texture cues at multiple scales.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;Xin Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oxholm_G/0/1/0/all/0/1&quot;&gt;Geoffrey Oxholm&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1&quot;&gt;Da Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yuan-Fang Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.11034">
<title>Wisdom of the crowd from unsupervised dimension reduction. (arXiv:1711.11034v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1711.11034</link>
<description rdf:parseType="Literal">&lt;p&gt;Wisdom of the crowd, the collective intelligence derived from responses of
multiple human or machine individuals to the same questions, can be more
accurate than each individual, and improve social decision-making and
prediction accuracy. This can also integrate multiple programs or datasets,
each as an individual, for the same predictive questions. Crowd wisdom
estimates each individual&apos;s independent error level arising from their limited
knowledge, and finds the crowd consensus that minimizes the overall error.
However, previous studies have merely built isolated, problem-specific models
with limited generalizability, and mainly for binary (yes/no) responses. Here
we show with simulation and real-world data that the crowd wisdom problem is
analogous to one-dimensional unsupervised dimension reduction in machine
learning. This provides a natural class of crowd wisdom solutions, such as
principal component analysis and Isomap, which can handle binary and also
continuous responses, like confidence levels, and consequently can be more
accurate than existing solutions. They can even outperform
supervised-learning-based collective intelligence that is calibrated on
historical performance of individuals, e.g. penalized linear regression and
random forest. This study unifies crowd wisdom and unsupervised dimension
reduction, and thereupon introduces a broad range of highly-performing and
widely-applicable crowd wisdom methods. As the costs for data acquisition and
processing rapidly decrease, this study will promote and guide crowd wisdom
applications in the social and natural sciences, including data fusion,
meta-analysis, crowd-sourcing, and committee decision making.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wang_L/0/1/0/all/0/1&quot;&gt;Lingfei Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Michoel_T/0/1/0/all/0/1&quot;&gt;Tom Michoel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.11053">
<title>A Multi-Horizon Quantile Recurrent Forecaster. (arXiv:1711.11053v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1711.11053</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a framework for general probabilistic multi-step time series
regression. Specifically, we exploit the expressiveness and temporal nature of
Recurrent Neural Networks, the nonparametric nature of Quantile Regression and
the efficiency of Direct Multi-Horizon Forecasting. A new training scheme for
recurrent nets is designed to boost stability and performance. We show that the
approach accommodates both temporal and static covariates, learning across
multiple related series, shifting seasonality, future planned event spikes and
cold-starts in real life large-scale forecasting. The performance of the
framework is demonstrated in an application to predict the future demand of
items sold on Amazon.com, and in a public probabilistic forecasting competition
to predict electricity price and load.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wen_R/0/1/0/all/0/1&quot;&gt;Ruofeng Wen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Torkkola_K/0/1/0/all/0/1&quot;&gt;Kari Torkkola&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Narayanaswamy_B/0/1/0/all/0/1&quot;&gt;Balakrishnan Narayanaswamy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.11057">
<title>On the use of bootstrap with variational inference: Theory, interpretation, and a two-sample test example. (arXiv:1711.11057v1 [stat.ME])</title>
<link>http://arxiv.org/abs/1711.11057</link>
<description rdf:parseType="Literal">&lt;p&gt;Variational inference is a general approach for approximating complex density
functions, such as those arising in latent variable models, popular in machine
learning. It has been applied to approximate the maximum likelihood estimator
and to carry out Bayesian inference, however, quantification of uncertainty
with variational inference remains challenging from both theoretical and
practical perspectives. This paper is concerned with developing uncertainty
measures for variational inference by using bootstrap procedures. We first
develop two general bootstrap approaches for assessing the uncertainty of a
variational estimate and the study the underlying bootstrap theory in both
fixed- and increasing-dimension settings. We then use the bootstrap approach
and our theoretical results in the context of mixed membership modeling with
multivariate binary data on functional disability from the National Long Term
Care Survey. We carry out a two-sample approach to test for changes in the
repeated measures of functional disability for the subset of individuals
present in 1984 and 1994 waves.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yen-Chi Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Y. Samuel Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Erosheva_E/0/1/0/all/0/1&quot;&gt;Elena A. Erosheva&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.11139">
<title>GANs for LIFE: Generative Adversarial Networks for Likelihood Free Inference. (arXiv:1711.11139v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1711.11139</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce a framework using Generative Adversarial Networks (GANs) for
likelihood--free inference (LFI) and Approximate Bayesian Computation (ABC).
Our approach addresses both the key problems in likelihood--free inference,
namely how to compare distributions and how to efficiently explore the
parameter space. Our framework allows one to use the simulator model as a black
box and leverage the power of deep networks to generate a rich set of features
in a data driven fashion (as opposed to previous ad hoc approaches). Thereby it
is a step towards a powerful alternative approach to LFI and ABC. On benchmark
data sets, our approach improves on others with respect to scalability, ability
to handle high dimensional data and complex probability distributions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jethava_V/0/1/0/all/0/1&quot;&gt;Vinay Jethava&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dubhashi_D/0/1/0/all/0/1&quot;&gt;Devdatt Dubhashi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.11189">
<title>Phase Transitions in Approximate Ranking. (arXiv:1711.11189v1 [math.ST])</title>
<link>http://arxiv.org/abs/1711.11189</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the problem of approximate ranking from observations of pairwise
interactions. The goal is to estimate the underlying ranks of $n$ objects from
data through interactions of comparison or collaboration. Under a general
framework of approximate ranking models, we characterize the exact optimal
statistical error rates of estimating the underlying ranks. We discover
important phase transition boundaries of the optimal error rates. Depending on
the value of the signal-to-noise ratio (SNR) parameter, the optimal rate, as a
function of SNR, is either trivial, polynomial, exponential or zero. The four
corresponding regimes thus have completely different error behaviors. To the
best of our knowledge, this phenomenon, especially the phase transition between
the polynomial and the exponential rates, has not been discovered before.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Gao_C/0/1/0/all/0/1&quot;&gt;Chao Gao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.11216">
<title>Riemannian Stein Variational Gradient Descent for Bayesian Inference. (arXiv:1711.11216v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1711.11216</link>
<description rdf:parseType="Literal">&lt;p&gt;We develop Riemannian Stein Variational Gradient Descent (RSVGD), a Bayesian
inference method that generalizes Stein Variational Gradient Descent (SVGD) to
Riemann manifold. The benefits are two-folds: (i) for inference tasks in
Euclidean spaces, RSVGD has the advantage over SVGD of utilizing information
geometry, and (ii) for inference tasks on Riemann manifolds, RSVGD brings the
unique advantages of SVGD to the Riemannian world. To appropriately transfer to
Riemann manifolds, we conceive novel and non-trivial techniques for RSVGD,
which are required by the intrinsically different characteristics of general
Riemann manifolds from Euclidean spaces. We also discover Riemannian Stein&apos;s
Identity and Riemannian Kernelized Stein Discrepancy. Experimental results show
the advantages over SVGD of exploring distribution geometry and the advantages
of particle-efficiency, iteration-effectiveness and approximation flexibility
over other inference methods on Riemann manifolds.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Liu_C/0/1/0/all/0/1&quot;&gt;Chang Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhu_J/0/1/0/all/0/1&quot;&gt;Jun Zhu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.11279">
<title>TCAV: Relative concept importance testing with Linear Concept Activation Vectors. (arXiv:1711.11279v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1711.11279</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural networks commonly offer high utility but remain difficult to
interpret. Developing methods to explain their decisions is challenging due to
their large size, complex structure, and inscrutable internal representations.
This work argues that the language of explanations should be expanded from that
of input features (e.g., assigning importance weightings to pixels) to include
that of higher-level, human-friendly concepts. For example, an understandable
explanation of why an image classifier outputs the label &quot;zebra&quot; would ideally
relate to concepts such as &quot;stripes&quot; rather than a set of particular pixel
values. This paper introduces the &quot;concept activation vector&quot; (CAV) which
allows quantitative analysis of a concept&apos;s relative importance to
classification, with a user-provided set of input data examples defining the
concept. CAVs may be easily used by non-experts, who need only provide
examples, and with CAVs the high-dimensional structure of neural networks turns
into an aid to interpretation, rather than an obstacle. Using the domain of
image classification as a testing ground, we describe how CAVs may be used to
test hypotheses about classifiers and also generate insights into the
deficiencies and correlations in training data. CAVs also provide us a directed
approach to choose the combinations of neurons to visualize with the DeepDream
technique, which traditionally has chosen neurons or linear combinations of
neurons at random to visualize.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kim_B/0/1/0/all/0/1&quot;&gt;Been Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gilmer_J/0/1/0/all/0/1&quot;&gt;Justin Gilmer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Viegas_F/0/1/0/all/0/1&quot;&gt;Fernanda Viegas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Erlingsson_U/0/1/0/all/0/1&quot;&gt;Ulfar Erlingsson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wattenberg_M/0/1/0/all/0/1&quot;&gt;Martin Wattenberg&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.11294">
<title>Towards Accurate Binary Convolutional Neural Network. (arXiv:1711.11294v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1711.11294</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce a novel scheme to train binary convolutional neural networks
(CNNs) -- CNNs with weights and activations constrained to {-1,+1} at run-time.
It has been known that using binary weights and activations drastically reduce
memory size and accesses, and can replace arithmetic operations with more
efficient bitwise operations, leading to much faster test-time inference and
lower power consumption. However, previous works on binarizing CNNs usually
result in severe prediction accuracy degradation. In this paper, we address
this issue with two major innovations: (1) approximating full-precision weights
with the linear combination of multiple binary weight bases; (2) employing
multiple binary activations to alleviate information loss. The implementation
of the resulting binary CNN, denoted as ABC-Net, is shown to achieve much
closer performance to its full-precision counterpart, and even reach the
comparable prediction accuracy on ImageNet and forest trail datasets, given
adequate binary weight bases and activations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_X/0/1/0/all/0/1&quot;&gt;Xiaofan Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_C/0/1/0/all/0/1&quot;&gt;Cong Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pan_W/0/1/0/all/0/1&quot;&gt;Wei Pan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.11386">
<title>MR image reconstruction using the learned data distribution as prior. (arXiv:1711.11386v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1711.11386</link>
<description rdf:parseType="Literal">&lt;p&gt;MR image reconstruction from undersampled data exploits priors to compensate
for missing k-space data. This has previously been achieved by using
regularization methods, such as TV and wavelets, or data adaptive methods, such
as dictionary learning. We propose to explicitly learn the probability
distribution of MR image patches and to constrain patches to have a high
probability according to this distribution in reconstruction, effectively
employing it as the prior.
&lt;/p&gt;
&lt;p&gt;We use variational autoencoders (VAE) to learn the distribution of MR image
patches. This high dimensional distribution is modelled by a latent parameter
model of lower dimensions in a non-linear fashion. We develop a reconstruction
algorithm that uses the learned prior in a Maximum-A-Posteriori estimation
formulation. We evaluate the proposed method with T1 weighted images and
compare it to existing alternatives. We also apply our method on images with
white matter lesions.
&lt;/p&gt;
&lt;p&gt;Visual evaluation of the samples drawn from the learned model showed that the
VAE algorithm was able to approximate the distribution of MR image patches.
Furthermore, the reconstruction algorithm using the approximate distribution
produced qualitatively better results. The proposed technique achieved RMSE,
CNR and CN values of 2.77\%, 0.43, 0.11 and 4.29\%, 0.43, 0.11 for
undersampling ratios of 2 and 3, respectively. It outperformed other evaluated
methods in terms of used metrics. In the experiments on images with white
matter lesions, the method faithfully reconstructed the lesions.
&lt;/p&gt;
&lt;p&gt;We introduced a novel method for MR reconstruction, which takes a new
perspective on regularization by learning priors. Results suggest the method
compares favorably against TV and dictionary based methods as well as the
neural-network based ADMM-Net in terms of the RMSE, CNR and CN and perceptual
image quality and can reconstruct lesions as well.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tezcan_K/0/1/0/all/0/1&quot;&gt;Kerem C. Tezcan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Baumgartner_C/0/1/0/all/0/1&quot;&gt;Christian F. Baumgartner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Konukoglu_E/0/1/0/all/0/1&quot;&gt;Ender Konukoglu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.11394">
<title>Who wins the Miss Contest for Imputation Methods? Our Vote for Miss BooPF. (arXiv:1711.11394v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1711.11394</link>
<description rdf:parseType="Literal">&lt;p&gt;Missing data is an expected issue when large amounts of data is collected,
and several imputation techniques have been proposed to tackle this problem.
Beneath classical approaches such as MICE, the application of Machine Learning
techniques is tempting. Here, the recently proposed missForest imputation
method has shown high imputation accuracy under the Missing (Completely) at
Random scheme with various missing rates. In its core, it is based on a random
forest for classification and regression, respectively. In this paper we study
whether this approach can even be enhanced by other methods such as the
stochastic gradient tree boosting method, the C5.0 algorithm or modified random
forest procedures. In particular, other resampling strategies within the random
forest protocol are suggested. In an extensive simulation study, we analyze
their performances for continuous, categorical as well as mixed-type data.
Therein, MissBooPF, a combination of the stochastic gradient tree boosting
method together with the parametrically bootstrapped random forest method,
appeared to be promising. Finally, an empirical analysis focusing on credit
information and Facebook data is conducted.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ramosaj_B/0/1/0/all/0/1&quot;&gt;Burim Ramosaj&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pauly_M/0/1/0/all/0/1&quot;&gt;Markus Pauly&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.11408">
<title>The identity of information: how deterministic dependencies constrain information synergy and redundancy. (arXiv:1711.11408v1 [q-bio.NC])</title>
<link>http://arxiv.org/abs/1711.11408</link>
<description rdf:parseType="Literal">&lt;p&gt;Understanding how different information sources together transmit information
is crucial in many domains. For example, understanding the neural code requires
characterizing how different neurons contribute unique, redundant, or
synergistic pieces of information about sensory or behavioral variables.
Williams and Beer (2010) proposed a partial information decomposition (PID)
which separates the mutual information that a set of sources contains about a
set of targets into nonnegative terms interpretable as these pieces.
Quantifying redundancy requires assigning an identity to different information
pieces, to assess when information is common across sources. Harder et al.
(2013) proposed an identity axiom stating that there cannot be redundancy
between two independent sources about a copy of themselves. However,
Bertschinger et al. (2012) showed that with a deterministically related
sources-target copy this axiom is incompatible with ensuring PID nonnegativity.
Here we study systematically the effect of deterministic target-sources
dependencies. We introduce two synergy stochasticity axioms that generalize the
identity axiom, and we derive general expressions separating stochastic and
deterministic PID components. Our analysis identifies how negative terms can
originate from deterministic dependencies and shows how different assumptions
on information identity, implicit in the stochasticity and identity axioms,
determine the PID structure. The implications for studying neural coding are
discussed.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Chicharro_D/0/1/0/all/0/1&quot;&gt;Daniel Chicharro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Pica_G/0/1/0/all/0/1&quot;&gt;Giuseppe Pica&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Panzeri_S/0/1/0/all/0/1&quot;&gt;Stefano Panzeri&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.11423">
<title>On reducing the communication cost of the diffusion LMS algorithm. (arXiv:1711.11423v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1711.11423</link>
<description rdf:parseType="Literal">&lt;p&gt;The rise of digital and mobile communications has recently made the world
more connected and networked, resulting in an unprecedented volume of data
flowing between sources, data centers, or processes. While these data may be
processed in a centralized manner, it is often more suitable to consider
distributed strategies such as diffusion as they are scalable and can handle
large amounts of data by distributing tasks over networked agents. Although it
is relatively simple to implement diffusion strategies over a cluster, it
appears to be challenging to deploy them in an ad-hoc network with limited
energy budget for communication. In this paper, we introduce a diffusion LMS
strategy that significantly reduces communication costs without compromising
the performance. Then, we analyze the proposed algorithm in the mean and
mean-square sense. Next, we conduct numerical experiments to confirm the
theoretical findings. Finally, we perform large scale simulations to test the
algorithm efficiency in a scenario where energy is limited.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Harrane_I/0/1/0/all/0/1&quot;&gt;Ibrahim El Khalil Harrane&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Flamary_R/0/1/0/all/0/1&quot;&gt;R&amp;#xe9;mi Flamary&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Richard_C/0/1/0/all/0/1&quot;&gt;C&amp;#xe9;dric Richard&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.11510">
<title>The Channel Multivariate Entropy Triangle and Balance Equation. (arXiv:1711.11510v1 [cs.IT])</title>
<link>http://arxiv.org/abs/1711.11510</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper we use information-theoretic measures to provide a theory and
tools to analyze the flow of information from a discrete, multivariate source
of information $\overline X$ to a discrete, multivariate sink of information
$\overline Y$ joined by a distribution $P_{\overline X \overline Y}$. The first
contribution is a decomposition of the maximal potential entropy of $(\overline
X, \overline Y)$ that we call a balance equation, that can also be split into
decompositions for the entropies of $\overline X$ and $\overline Y$
respectively. Such balance equations accept normalizations that allow them to
be represented in de Finetti entropy diagrams, our second contribution. The
most important of these, the aggregate Channel Multivariate Entropy Triangle
CMET is an exploratory tool to assess the efficiency of multivariate channels.
We also present a practical contribution in the application of these balance
equations and diagrams to the assessment of information transfer efficiency for
PCA and ICA as feature transformation and selection procedures in machine
learning applications.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Valverde_Albacete_F/0/1/0/all/0/1&quot;&gt;Francisco J. Valverde-Albacete&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pelaez_Moreno_C/0/1/0/all/0/1&quot;&gt;Carmen Pel&amp;#xe1;ez-Moreno&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.11511">
<title>Thermostat-assisted Continuous-tempered Hamiltonian Monte Carlo for Multimodal Posterior Sampling on Large Datasets. (arXiv:1711.11511v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1711.11511</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we propose a new sampling method named as the
thermostat-assisted continuous-tempered Hamiltonian Monte Carlo for multimodal
posterior sampling on large datasets. It simulates a noisy system, which is
augmented by a coupling tempering variable as well as a set of Nos\&apos;e-Hoover
thermostats. This augmentation is devised to address two main issues of
concern: the first is to effectively generate i.i.d. samples from complex
multimodal posterior distributions; the second is to adaptively control the
system dynamics in the presence of unknown noise that arises from the use of
mini-batches. The experiment on synthetic distributions has been performed; the
result demonstrates the effectiveness of the proposed method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Luo_R/0/1/0/all/0/1&quot;&gt;Rui Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yang_Y/0/1/0/all/0/1&quot;&gt;Yaodong Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jun Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yuanyuan Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.11527">
<title>Improved Linear Embeddings via Lagrange Duality. (arXiv:1711.11527v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1711.11527</link>
<description rdf:parseType="Literal">&lt;p&gt;Near isometric orthonormal embeddings to lower dimensions are a fundamental
tool in data science and machine learning. We present a construction of such
embeddings that minimizes the maximum distortion for a given set of points. We
formulate the problem as a non convex constrained optimization problem. We
first construct a primal relaxation and then using the theory of Lagrange
duality, we construct dual relaxations. We also give a polynomial time
algorithm based on convex optimization to solve the dual relaxation provably.
We experimentally demonstrate the superiority of our algorithm compared to
baselines in terms scalability and the ability to achieve lower distortion.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sheth_K/0/1/0/all/0/1&quot;&gt;Kshiteej Sheth&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Garg_D/0/1/0/all/0/1&quot;&gt;Dinesh Garg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Dasgupta_A/0/1/0/all/0/1&quot;&gt;Anirban Dasgupta&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.11542">
<title>Learning to Adapt by Minimizing Discrepancy. (arXiv:1711.11542v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1711.11542</link>
<description rdf:parseType="Literal">&lt;p&gt;We explore whether useful temporal neural generative models can be learned
from sequential data without back-propagation through time. We investigate the
viability of a more neurocognitively-grounded approach in the context of
unsupervised generative modeling of sequences. Specifically, we build on the
concept of predictive coding, which has gained influence in cognitive science,
in a neural framework. To do so we develop a novel architecture, the Temporal
Neural Coding Network, and its learning algorithm, Discrepancy Reduction. The
underlying directed generative model is fully recurrent, meaning that it
employs structural feedback connections and temporal feedback connections,
yielding information propagation cycles that create local learning signals.
This facilitates a unified bottom-up and top-down approach for information
transfer inside the architecture. Our proposed algorithm shows promise on the
bouncing balls generative modeling problem. Further experiments could be
conducted to explore the strengths and weaknesses of our approach.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ororbia_A/0/1/0/all/0/1&quot;&gt;Alexander G. Ororbia II&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Haffner_P/0/1/0/all/0/1&quot;&gt;Patrick Haffner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Reitter_D/0/1/0/all/0/1&quot;&gt;David Reitter&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Giles_C/0/1/0/all/0/1&quot;&gt;C. Lee Giles&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.11561">
<title>Measuring the tendency of CNNs to Learn Surface Statistical Regularities. (arXiv:1711.11561v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1711.11561</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep CNNs are known to exhibit the following peculiarity: on the one hand
they generalize extremely well to a test set, while on the other hand they are
extremely sensitive to so-called adversarial perturbations. The extreme
sensitivity of high performance CNNs to adversarial examples casts serious
doubt that these networks are learning high level abstractions in the dataset.
We are concerned with the following question: How can a deep CNN that does not
learn any high level semantics of the dataset manage to generalize so well? The
goal of this article is to measure the tendency of CNNs to learn surface
statistical regularities of the dataset. To this end, we use Fourier filtering
to construct datasets which share the exact same high level abstractions but
exhibit qualitatively different surface statistical regularities. For the SVHN
and CIFAR-10 datasets, we present two Fourier filtered variants: a low
frequency variant and a randomly filtered variant. Each of the Fourier
filtering schemes is tuned to preserve the recognizability of the objects. Our
main finding is that CNNs exhibit a tendency to latch onto the Fourier image
statistics of the training dataset, sometimes exhibiting up to a 28%
generalization gap across the various test sets. Moreover, we observe that
significantly increasing the depth of a network has a very marginal impact on
closing the aforementioned generalization gap. Thus we provide quantitative
evidence supporting the hypothesis that deep CNNs tend to learn surface
statistical regularities in the dataset rather than higher-level abstract
concepts.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jo_J/0/1/0/all/0/1&quot;&gt;Jason Jo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bengio_Y/0/1/0/all/0/1&quot;&gt;Yoshua Bengio&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.11581">
<title>Outlier-robust moment-estimation via sum-of-squares. (arXiv:1711.11581v1 [cs.DS])</title>
<link>http://arxiv.org/abs/1711.11581</link>
<description rdf:parseType="Literal">&lt;p&gt;We develop efficient algorithms for estimating low-degree moments of unknown
distributions in the presence of adversarial outliers. The guarantees of our
algorithms improve in many cases significantly over the best previous ones,
obtained in recent works of Diakonikolas et al, Lai et al, and Charikar et al.
We also show that the guarantees of our algorithms match information-theoretic
lower-bounds for the class of distributions we consider. These improved
guarantees allow us to give improved algorithms for independent component
analysis and learning mixtures of Gaussians in the presence of outliers.
&lt;/p&gt;
&lt;p&gt;Our algorithms are based on a standard sum-of-squares relaxation of the
following conceptually-simple optimization problem: Among all distributions
whose moments are bounded in the same way as for the unknown distribution, find
the one that is closest in statistical distance to the empirical distribution
of the adversarially-corrupted sample.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kothari_P/0/1/0/all/0/1&quot;&gt;Pravesh K. Kothari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Steurer_D/0/1/0/all/0/1&quot;&gt;David Steurer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.11586">
<title>Toward Multimodal Image-to-Image Translation. (arXiv:1711.11586v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1711.11586</link>
<description rdf:parseType="Literal">&lt;p&gt;Many image-to-image translation problems are ambiguous, as a single input
image may correspond to multiple possible outputs. In this work, we aim to
model a \emph{distribution} of possible outputs in a conditional generative
modeling setting. The ambiguity of the mapping is distilled in a
low-dimensional latent vector, which can be randomly sampled at test time. A
generator learns to map the given input, combined with this latent code, to the
output. We explicitly encourage the connection between output and the latent
code to be invertible. This helps prevent a many-to-one mapping from the latent
code to the output during training, also known as the problem of mode collapse,
and produces more diverse results. We explore several variants of this approach
by employing different training objectives, network architectures, and methods
of injecting the latent code. Our proposed method encourages bijective
consistency between the latent encoding and output modes. We present a
systematic comparison of our method and other variants on both perceptual
realism and diversity.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1&quot;&gt;Jun-Yan Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1&quot;&gt;Richard Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pathak_D/0/1/0/all/0/1&quot;&gt;Deepak Pathak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Darrell_T/0/1/0/all/0/1&quot;&gt;Trevor Darrell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Efros_A/0/1/0/all/0/1&quot;&gt;Alexei A. Efros&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_O/0/1/0/all/0/1&quot;&gt;Oliver Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shechtman_E/0/1/0/all/0/1&quot;&gt;Eli Shechtman&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1602.03943">
<title>Second-Order Stochastic Optimization for Machine Learning in Linear Time. (arXiv:1602.03943v5 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1602.03943</link>
<description rdf:parseType="Literal">&lt;p&gt;First-order stochastic methods are the state-of-the-art in large-scale
machine learning optimization owing to efficient per-iteration complexity.
Second-order methods, while able to provide faster convergence, have been much
less explored due to the high cost of computing the second-order information.
In this paper we develop second-order stochastic methods for optimization
problems in machine learning that match the per-iteration cost of gradient
based methods, and in certain settings improve upon the overall running time
over popular first-order methods. Furthermore, our algorithm has the desirable
property of being implementable in time linear in the sparsity of the input
data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Agarwal_N/0/1/0/all/0/1&quot;&gt;Naman Agarwal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bullins_B/0/1/0/all/0/1&quot;&gt;Brian Bullins&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hazan_E/0/1/0/all/0/1&quot;&gt;Elad Hazan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1707.00372">
<title>Deep Convolutional Framelets: A General Deep Learning Framework for Inverse Problems. (arXiv:1707.00372v4 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1707.00372</link>
<description rdf:parseType="Literal">&lt;p&gt;Recently, deep learning approaches have achieved significant performance
improvement in various imaging problems. However, it is still unclear why these
deep learning architectures work. Moreover, the link between the deep learning
and the classical signal processing approaches such as wavelet, non-local
processing, compressed sensing, etc, is still not well understood. To address
these issues, here we show that the long-searched-for missing link is the
convolutional framelets for representing a signal by convolving local and
non-local bases. The convolutional framelets was originally developed to
generalize the recent theory of low-rank Hankel matrix approaches, and this
paper significantly extends the idea to derive a deep neural network using
multi-layer convolutional framelets with perfect reconstruction (PR) under
rectified linear unit (ReLU). Our analysis also shows that the popular deep
network components such as residual block, redundant filter channels, and
concatenated ReLU (CReLU) indeed help to achieve the PR, while the pooling and
unpooling layers should be augmented with multi-resolution convolutional
framelets to achieve PR condition. This discovery reveals the limitations of
many existing deep learning architectures for inverse problems, and leads us to
propose a novel deep convolutional framelets neural network. Using numerical
experiments with sparse view x-ray computed tomography (CT), we demonstrated
that our deep convolution framelets network shows consistent improvement. This
discovery suggests that the success of deep learning is not from a magical
power of a black-box, but rather comes from the power of a novel signal
representation using non-local basis combined with data-driven local basis,
which is indeed a natural extension of classical signal processing theory.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ye_J/0/1/0/all/0/1&quot;&gt;Jong Chul Ye&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Han_Y/0/1/0/all/0/1&quot;&gt;Yoseob Han&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Cha_E/0/1/0/all/0/1&quot;&gt;Eunju Cha&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.10571">
<title>Certifiable Distributional Robustness with Principled Adversarial Training. (arXiv:1710.10571v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1710.10571</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural networks are vulnerable to adversarial examples and researchers have
proposed many heuristic attack and defense mechanisms. We take the principled
view of distributionally robust optimization, which guarantees performance
under adversarial input perturbations. By considering a Lagrangian penalty
formulation of perturbation of the underlying data distribution in a
Wasserstein ball, we provide a training procedure that augments model parameter
updates with worst-case perturbations of training data. For smooth losses, our
procedure provably achieves moderate levels of robustness with little
computational or statistical cost relative to empirical risk minimization.
Furthermore, our statistical guarantees allow us to efficiently certify
robustness for the population loss. We match or outperform heuristic approaches
on supervised and reinforcement learning tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sinha_A/0/1/0/all/0/1&quot;&gt;Aman Sinha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Namkoong_H/0/1/0/all/0/1&quot;&gt;Hongseok Namkoong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Duchi_J/0/1/0/all/0/1&quot;&gt;John Duchi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.06719">
<title>Techniques for proving Asynchronous Convergence results for Markov Chain Monte Carlo methods. (arXiv:1711.06719v4 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1711.06719</link>
<description rdf:parseType="Literal">&lt;p&gt;Markov Chain Monte Carlo (MCMC) methods such as Gibbs sampling are finding
widespread use in applied statistics and machine learning. These often lead to
difficult computational problems, which are increasingly being solved on
parallel and distributed systems such as compute clusters. Recent work has
proposed running iterative algorithms such as gradient descent and MCMC in
parallel asynchronously for increased performance, with good empirical results
in certain problems. Unfortunately, for MCMC this parallelization technique
requires new convergence theory, as it has been explicitly demonstrated to lead
to divergence on some examples. Recent theory on Asynchronous Gibbs sampling
describes why these algorithms can fail, and provides a way to alter them to
make them converge. In this article, we describe how to apply this theory in a
generic setting, to understand the asynchronous behavior of any MCMC algorithm,
including those implemented using parameter servers, and those not based on
Gibbs sampling.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Terenin_A/0/1/0/all/0/1&quot;&gt;Alexander Terenin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Xing_E/0/1/0/all/0/1&quot;&gt;Eric P. Xing&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.06798">
<title>MorphNet: Fast &amp; Simple Resource-Constrained Structure Learning of Deep Networks. (arXiv:1711.06798v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1711.06798</link>
<description rdf:parseType="Literal">&lt;p&gt;We present MorphNet, an approach to automate the design of neural network
structures. MorphNet iteratively shrinks and expands a network, shrinking via a
resource-weighted sparsifying regularizer on activations and expanding via a
uniform multiplicative factor on all layers. In contrast to previous
approaches, our method is scalable to large networks, adaptable to specific
resource constraints (e.g. the number of floating-point operations per
inference), and capable of increasing the network&apos;s performance. When applied
to standard network architectures on a wide variety of datasets, our approach
discovers novel structures in each domain, obtaining higher performance while
respecting the resource constraint.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gordon_A/0/1/0/all/0/1&quot;&gt;Ariel Gordon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Eban_E/0/1/0/all/0/1&quot;&gt;Elad Eban&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nachum_O/0/1/0/all/0/1&quot;&gt;Ofir Nachum&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1&quot;&gt;Bo Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_T/0/1/0/all/0/1&quot;&gt;Tien-Ju Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Choi_E/0/1/0/all/0/1&quot;&gt;Edward Choi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.08018">
<title>Disagreement-based combinatorial pure exploration: Efficient algorithms and an analysis with localization. (arXiv:1711.08018v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1711.08018</link>
<description rdf:parseType="Literal">&lt;p&gt;We design new algorithms for the combinatorial pure exploration problem in
the multi-arm bandit framework. In this problem, we are given K distributions
and a collection of subsets $\mathcal{V} \subset 2^K$ of these distributions,
and we would like to find the subset $v \in \mathcal{V}$ that has largest
cumulative mean, while collecting, in a sequential fashion, as few samples from
the distributions as possible. We study both the fixed budget and fixed
confidence settings, and our algorithms essentially achieve state-of-the-art
performance in all settings, improving on previous guarantees for structures
like matchings and submatrices that have large augmenting sets. Moreover, our
algorithms can be implemented efficiently whenever the decision set V admits
linear optimization. Our analysis involves precise concentration-of-measure
arguments and a new algorithm for linear programming with exponentially many
constraints.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Cao_T/0/1/0/all/0/1&quot;&gt;Tongyi Cao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Krishnamurthy_A/0/1/0/all/0/1&quot;&gt;Akshay Krishnamurthy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.09889">
<title>Proceedings of NIPS 2017 Symposium on Interpretable Machine Learning. (arXiv:1711.09889v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1711.09889</link>
<description rdf:parseType="Literal">&lt;p&gt;This is the Proceedings of NIPS 2017 Symposium on Interpretable Machine
Learning, held in Long Beach, California, USA on December 7, 2017
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wilson_A/0/1/0/all/0/1&quot;&gt;Andrew Gordon Wilson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yosinski_J/0/1/0/all/0/1&quot;&gt;Jason Yosinski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Simard_P/0/1/0/all/0/1&quot;&gt;Patrice Simard&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Caruana_R/0/1/0/all/0/1&quot;&gt;Rich Caruana&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Herlands_W/0/1/0/all/0/1&quot;&gt;William Herlands&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.10173">
<title>Hierarchical Policy Search via Return-Weighted Density Estimation. (arXiv:1711.10173v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1711.10173</link>
<description rdf:parseType="Literal">&lt;p&gt;Learning an optimal policy from a multi-modal reward function is a
challenging problem in reinforcement learning (RL). Hierarchical RL (HRL)
tackles this problem by learning a hierarchical policy, where multiple option
policies are in charge of different strategies corresponding to modes of a
reward function and a gating policy selects the best option for a given
context. Although HRL has been demonstrated to be promising, current
state-of-the-art methods cannot still perform well in complex real-world
problems due to the difficulty of identifying modes of the reward function. In
this paper, we propose a novel method called hierarchical policy search via
return-weighted density estimation (HPSDE), which can efficiently identify the
modes through density estimation with return-weighted importance sampling. Our
proposed method finds option policies corresponding to the modes of the return
function and automatically determines the number and the location of option
policies, which significantly reduces the burden of hyper-parameters tuning.
Through experiments, we demonstrate that the proposed HPSDE successfully learns
option policies corresponding to modes of the return function and that it can
be successfully applied to a challenging motion planning problem of a redundant
robotic manipulator.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Osa_T/0/1/0/all/0/1&quot;&gt;Takayuki Osa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sugiyama_M/0/1/0/all/0/1&quot;&gt;Masashi Sugiyama&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.10337">
<title>Are GANs Created Equal? A Large-Scale Study. (arXiv:1711.10337v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1711.10337</link>
<description rdf:parseType="Literal">&lt;p&gt;Generative adversarial networks (GAN) are a powerful subclass of generative
models. Despite a very rich research activity leading to numerous interesting
GAN algorithms, it is still very hard to assess which algorithm(s) perform
better than others. We conduct a neutral, multi-faceted large-scale empirical
study on state-of-the art models and evaluation measures. We find that most
models can reach similar scores with enough hyperparameter optimization and
random restarts. This suggests that improvements can arise from a higher
computational budget and tuning more than fundamental algorithmic changes. To
overcome some limitations of the current metrics, we also propose several data
sets on which precision and recall can be computed. Our experimental results
suggest that future GAN research should be based on more systematic and
objective evaluation procedures. Finally, we did not find evidence that any of
the tested algorithms consistently outperforms the original one.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lucic_M/0/1/0/all/0/1&quot;&gt;Mario Lucic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kurach_K/0/1/0/all/0/1&quot;&gt;Karol Kurach&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Michalski_M/0/1/0/all/0/1&quot;&gt;Marcin Michalski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gelly_S/0/1/0/all/0/1&quot;&gt;Sylvain Gelly&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bousquet_O/0/1/0/all/0/1&quot;&gt;Olivier Bousquet&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.10635">
<title>Valid Inference Corrected for Outlier Removal. (arXiv:1711.10635v2 [stat.ME] UPDATED)</title>
<link>http://arxiv.org/abs/1711.10635</link>
<description rdf:parseType="Literal">&lt;p&gt;Ordinary least square (OLS) estimation of a linear regression model is
well-known to be highly sensitive to outliers. It is common practice to first
identify and remove outliers by looking at the data then to fit OLS and form
confidence intervals and p-values on the remaining data as if this were the
original data collected. We show in this paper that this &quot;detect-and-forget&quot;
approach can lead to invalid inference, and we propose a framework that
properly accounts for outlier detection and removal to provide valid confidence
intervals and hypothesis tests. Our inferential procedures apply to any outlier
removal procedure that can be characterized by a set of quadratic constraints
on the response vector, and we show that several of the most commonly used
outlier detection procedures are of this form. Our methodology is built upon
recent advances in selective inference (Taylor &amp;amp; Tibshirani 2015), which are
focused on inference corrected for variable selection. We conduct simulations
to corroborate the theoretical results, and we apply our method to two classic
data sets considered in the outlier detection literature to illustrate how our
inferential results can differ from the traditional detect-and-forget strategy.
A companion R package, outference, implements these new procedures with an
interface that matches the functions commonly used for inference with lm in R.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chen_S/0/1/0/all/0/1&quot;&gt;Shuxiao Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bien_J/0/1/0/all/0/1&quot;&gt;Jacob Bien&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.10925">
<title>Deep Image Prior. (arXiv:1711.10925v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1711.10925</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep convolutional networks have become a popular tool for image generation
and restoration. Generally, their excellent performance is imputed to their
ability to learn realistic image priors from a large number of example images.
In this paper, we show that, on the contrary, the structure of a generator
network is sufficient to capture a great deal of low-level image statistics
prior to any learning. In order to do so, we show that a randomly-initialized
neural network can be used as a handcrafted prior with excellent results in
standard inverse problems such as denoising, super-resolution, and inpainting.
Furthermore, the same prior can be used to invert deep neural representations
to diagnose them, and to restore images based on flash-no flash input pairs.
&lt;/p&gt;
&lt;p&gt;Apart from its diverse applications, our approach highlights the inductive
bias captured by standard generator network architectures. It also bridges the
gap between two very popular families of image restoration methods:
learning-based methods using deep convolutional networks and learning-free
methods based on handcrafted image priors such as self-similarity. Code and
supplementary material are available at
https://dmitryulyanov.github.io/deep_image_prior .
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ulyanov_D/0/1/0/all/0/1&quot;&gt;Dmitry Ulyanov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vedaldi_A/0/1/0/all/0/1&quot;&gt;Andrea Vedaldi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lempitsky_V/0/1/0/all/0/1&quot;&gt;Victor Lempitsky&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.10907">
<title>Deep Reinforcement Learning for De-Novo Drug Design. (arXiv:1711.10907v1 [cs.AI] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1711.10907</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a novel computational strategy based on deep and reinforcement
learning techniques for de-novo design of molecules with desired properties.
This strategy integrates two deep neural networks -generative and predictive -
that are trained separately but employed jointly to generate novel chemical
structures with the desired properties. Generative models are trained to
produce chemically feasible SMILES, and predictive models are derived to
forecast the desired compound properties. In the first phase of the method,
generative and predictive models are separately trained with supervised
learning algorithms. In the second phase, both models are trained jointly with
reinforcement learning approach to bias newly generated chemical structures
towards those with desired physical and biological properties. In this
proof-of-concept study, we have employed this integrative strategy to design
chemical libraries biased toward compounds with either maximal, minimal, or
specific range of physical properties, such as melting point and
hydrophobicity, as well as to develop novel putative inhibitors of JAK2. This
new approach can find a general use for generating targeted chemical libraries
optimized for a single desired property or multiple properties.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Popova_M/0/1/0/all/0/1&quot;&gt;Mariya Popova&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Isayev_O/0/1/0/all/0/1&quot;&gt;Olexandr Isayev&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tropsha_A/0/1/0/all/0/1&quot;&gt;Alexander Tropsha&lt;/a&gt;</dc:creator>
</item></rdf:RDF>