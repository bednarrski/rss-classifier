<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Good papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Good Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-02-25T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08375"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08465"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08530"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08535"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08567"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1708.08694"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.05468"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.01078"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.00930"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08311"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08314"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08352"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08445"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08454"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08534"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.03641"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06070"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08250"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08526"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1612.02707"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1707.01926"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.01401"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.09203"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1802.08375">
<title>Reusing Weights in Subword-aware Neural Language Models. (arXiv:1802.08375v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1802.08375</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose several ways of reusing subword embeddings and other weights in
subword-aware neural language models. The proposed techniques do not benefit a
competitive character-aware model, but some of them improve the performance of
syllable- and morpheme-aware models while showing significant reductions in
model sizes. We discover a simple hands-on principle: in a multi-layer input
embedding model, layers should be tied consecutively bottom-up if reused at
output. Our best morpheme-aware model with properly reused weights beats the
competitive word-level model by a large margin across multiple languages and
has 20%-87% fewer parameters.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Assylbekov_Z/0/1/0/all/0/1&quot;&gt;Zhenisbek Assylbekov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Takhanov_R/0/1/0/all/0/1&quot;&gt;Rustem Takhanov&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08465">
<title>AEkNN: An AutoEncoder kNN-based classifier with built-in dimensionality reduction. (arXiv:1802.08465v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.08465</link>
<description rdf:parseType="Literal">&lt;p&gt;High dimensionality, i.e. data having a large number of variables, tends to
be a challenge for most machine learning tasks, including classification. A
classifier usually builds a model representing how a set of inputs explain the
outputs. The larger is the set of inputs and/or outputs, the more complex would
be that model. There is a family of classification algorithms, known as lazy
learning methods, which does not build a model. One of the best known members
of this family is the kNN algorithm. Its strategy relies on searching a set of
nearest neighbors, using the input variables as position vectors and computing
distances among them. These distances loss significance in high-dimensional
spaces. Therefore kNN, as many other classifiers, tends to worse its
performance as the number of input variables grows.
&lt;/p&gt;
&lt;p&gt;In this work AEkNN, a new kNN-based algorithm with built-in dimensionality
reduction, is presented. Aiming to obtain a new representation of the data,
having a lower dimensionality but with more informational features, AEkNN
internally uses autoencoders. From this new feature vectors the computed
distances should be more significant, thus providing a way to choose better
neighbors. A experimental evaluation of the new proposal is conducted,
analyzing several configurations and comparing them against the classical kNN
algorithm. The obtained conclusions demonstrate that AEkNN offers better
results in predictive and runtime performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pulgar_F/0/1/0/all/0/1&quot;&gt;Francisco J. Pulgar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Charte_F/0/1/0/all/0/1&quot;&gt;Francisco Charte&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rivera_A/0/1/0/all/0/1&quot;&gt;Antonio J. Rivera&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jesus_M/0/1/0/all/0/1&quot;&gt;Mar&amp;#xed;a J. del Jesus&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08530">
<title>Training wide residual networks for deployment using a single bit for each weight. (arXiv:1802.08530v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.08530</link>
<description rdf:parseType="Literal">&lt;p&gt;For fast and energy-efficient deployment of trained deep neural networks on
resource-constrained embedded hardware, each learned weight parameter should
ideally be represented and stored using a single bit. Error-rates usually
increase when this requirement is imposed. Here, we report large improvements
in error rates on multiple datasets, for deep convolutional neural networks
deployed with 1-bit-per-weight. Using wide residual networks as our main
baseline, our approach simplifies existing methods that binarize weights by
applying the sign function in training; we apply scaling factors for each layer
with constant unlearned values equal to the layer-specific standard deviations
used for initialization. For CIFAR-10, CIFAR-100 and ImageNet, and models with
1-bit-per-weight requiring less than 10 MB of parameter memory, we achieve
error rates of 3.9%, 18.5% and 26.0% / 8.5% (Top-1 / Top-5) respectively. We
also considered MNIST, SVHN and ImageNet32, achieving 1-bit-per-weight test
results of 0.27%, 1.9%, and 41.3% / 19.1% respectively. For CIFAR, our error
rates halve previously reported values, and are within about 1% of our
error-rates for the same network with full-precision weights. For networks that
overfit, we also show significant improvements in error rate by not learning
batch normalization scale and offset parameters. This applies to both full
precision and 1-bit-per-weight networks. Using a warm-restart learning-rate
schedule, we found that training for 1-bit-per-weight is just as fast as
full-precision networks, with better accuracy than standard schedules, and
achieved about 98%-99% of peak performance in just 62 training epochs for
CIFAR-10/100. For full training code and trained models in MATLAB, Keras and
PyTorch see https://github.com/McDonnell-Lab/1-bit-per-weight/ .
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+McDonnell_M/0/1/0/all/0/1&quot;&gt;Mark D. McDonnell&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08535">
<title>Can Neural Networks Understand Logical Entailment?. (arXiv:1802.08535v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1802.08535</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce a new dataset of logical entailments for the purpose of
measuring models&apos; ability to capture and exploit the structure of logical
expressions against an entailment prediction task. We use this task to compare
a series of architectures which are ubiquitous in the sequence-processing
literature, in addition to a new model class---PossibleWorldNets---which
computes entailment as a &quot;convolution over possible worlds&quot;. Results show that
convolutional networks present the wrong inductive bias for this class of
problems relative to LSTM RNNs, tree-structured neural networks outperform LSTM
RNNs due to their enhanced ability to exploit the syntax of logic, and
PossibleWorldNets outperform all benchmarks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Evans_R/0/1/0/all/0/1&quot;&gt;Richard Evans&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saxton_D/0/1/0/all/0/1&quot;&gt;David Saxton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Amos_D/0/1/0/all/0/1&quot;&gt;David Amos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kohli_P/0/1/0/all/0/1&quot;&gt;Pushmeet Kohli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grefenstette_E/0/1/0/all/0/1&quot;&gt;Edward Grefenstette&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08567">
<title>Adversarial Training for Probabilistic Spiking Neural Networks. (arXiv:1802.08567v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.08567</link>
<description rdf:parseType="Literal">&lt;p&gt;Classifiers trained using conventional empirical risk minimization or maximum
likelihood methods are known to suffer dramatic performance degradations when
tested over examples adversarially selected based on knowledge of the
classifier&apos;s decision rule. Due to the prominence of Artificial Neural Networks
(ANNs) as classifiers, their sensitivity to adversarial examples, as well as
robust training schemes, have been recently the subject of intense
investigation. In this paper, for the first time, the sensitivity of spiking
neural networks (SNNs), or third-generation neural networks, to adversarial
examples is studied. The study considers rate and time encoding, as well as
rate and first-to-spike decoding. Furthermore, a robust training mechanism is
proposed that is demonstrated to enhance the performance of SNNs under
white-box attacks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bagheri_A/0/1/0/all/0/1&quot;&gt;Alireza Bagheri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Simeone_O/0/1/0/all/0/1&quot;&gt;Osvaldo Simeone&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rajendran_B/0/1/0/all/0/1&quot;&gt;Bipin Rajendran&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1708.08694">
<title>Natasha 2: Faster Non-Convex Optimization Than SGD. (arXiv:1708.08694v3 [math.OC] UPDATED)</title>
<link>http://arxiv.org/abs/1708.08694</link>
<description rdf:parseType="Literal">&lt;p&gt;We design a stochastic algorithm to train any smooth neural network to
$\varepsilon$-approximate local minima, using $O(\varepsilon^{-3.25})$
backpropagations. The best result was essentially $O(\varepsilon^{-4})$ by SGD.
&lt;/p&gt;
&lt;p&gt;More broadly, it finds $\varepsilon$-approximate local minima of any smooth
nonconvex function in rate $O(\varepsilon^{-3.25})$, with only oracle access to
stochastic gradients.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Allen_Zhu_Z/0/1/0/all/0/1&quot;&gt;Zeyuan Allen-Zhu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.05468">
<title>Generalization in Deep Learning. (arXiv:1710.05468v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1710.05468</link>
<description rdf:parseType="Literal">&lt;p&gt;With a direct analysis of neural networks, this paper presents a
mathematically tight generalization theory to partially address an open problem
regarding the generalization of deep learning. Unlike previous bound-based
theory, our main theory is quantitatively as tight as possible for every
dataset individually, while producing qualitative insights competitively. Our
results give insight into why and how deep learning can generalize well,
despite its large capacity, complexity, possible algorithmic instability,
nonrobustness, and sharp minima, answering to an open question in the
literature. We also discuss limitations of our results and propose additional
open problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kawaguchi_K/0/1/0/all/0/1&quot;&gt;Kenji Kawaguchi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kaelbling_L/0/1/0/all/0/1&quot;&gt;Leslie Pack Kaelbling&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bengio_Y/0/1/0/all/0/1&quot;&gt;Yoshua Bengio&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.01078">
<title>Recent Advances in Recurrent Neural Networks. (arXiv:1801.01078v3 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1801.01078</link>
<description rdf:parseType="Literal">&lt;p&gt;Recurrent neural networks (RNNs) are capable of learning features and long
term dependencies from sequential and time-series data. The RNNs have a stack
of non-linear units where at least one connection between units forms a
directed cycle. A well-trained RNN can model any dynamical system; however,
training RNNs is mostly plagued by issues in learning long-term dependencies.
In this paper, we present a survey on RNNs and several new advances for
newcomers and professionals in the field. The fundamentals and recent advances
are explained and the research challenges are introduced.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Salehinejad_H/0/1/0/all/0/1&quot;&gt;Hojjat Salehinejad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sankar_S/0/1/0/all/0/1&quot;&gt;Sharan Sankar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barfett_J/0/1/0/all/0/1&quot;&gt;Joseph Barfett&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Colak_E/0/1/0/all/0/1&quot;&gt;Errol Colak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Valaee_S/0/1/0/all/0/1&quot;&gt;Shahrokh Valaee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.00930">
<title>Mixed Precision Training of Convolutional Neural Networks using Integer Operations. (arXiv:1802.00930v2 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1802.00930</link>
<description rdf:parseType="Literal">&lt;p&gt;The state-of-the-art (SOTA) for mixed precision training is dominated by
variants of low precision floating point operations, and in particular, FP16
accumulating into FP32 Micikevicius et al. (2017). On the other hand, while a
lot of research has also happened in the domain of low and mixed-precision
Integer training, these works either present results for non-SOTA networks (for
instance only AlexNet for ImageNet-1K), or relatively small datasets (like
CIFAR-10). In this work, we train state-of-the-art visual understanding neural
networks on the ImageNet-1K dataset, with Integer operations on General Purpose
(GP) hardware. In particular, we focus on Integer Fused-Multiply-and-Accumulate
(FMA) operations which take two pairs of INT16 operands and accumulate results
into an INT32 output.We propose a shared exponent representation of tensors and
develop a Dynamic Fixed Point (DFP) scheme suitable for common neural network
operations. The nuances of developing an efficient integer convolution kernel
is examined, including methods to handle overflow of the INT32 accumulator. We
implement CNN training for ResNet-50, GoogLeNet-v1, VGG-16 and AlexNet; and
these networks achieve or exceed SOTA accuracy within the same number of
iterations as their FP32 counterparts without any change in hyper-parameters
and with a 1.8X improvement in end-to-end training throughput. To the best of
our knowledge these results represent the first INT16 training results on GP
hardware for ImageNet-1K dataset using SOTA CNNs and achieve highest reported
accuracy using half-precision
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Das_D/0/1/0/all/0/1&quot;&gt;Dipankar Das&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mellempudi_N/0/1/0/all/0/1&quot;&gt;Naveen Mellempudi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mudigere_D/0/1/0/all/0/1&quot;&gt;Dheevatsa Mudigere&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kalamkar_D/0/1/0/all/0/1&quot;&gt;Dhiraj Kalamkar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Avancha_S/0/1/0/all/0/1&quot;&gt;Sasikanth Avancha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Banerjee_K/0/1/0/all/0/1&quot;&gt;Kunal Banerjee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sridharan_S/0/1/0/all/0/1&quot;&gt;Srinivas Sridharan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vaidyanathan_K/0/1/0/all/0/1&quot;&gt;Karthik Vaidyanathan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kaul_B/0/1/0/all/0/1&quot;&gt;Bharat Kaul&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Georganas_E/0/1/0/all/0/1&quot;&gt;Evangelos Georganas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Heinecke_A/0/1/0/all/0/1&quot;&gt;Alexander Heinecke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dubey_P/0/1/0/all/0/1&quot;&gt;Pradeep Dubey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Corbal_J/0/1/0/all/0/1&quot;&gt;Jesus Corbal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shustrov_N/0/1/0/all/0/1&quot;&gt;Nikita Shustrov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dubtsov_R/0/1/0/all/0/1&quot;&gt;Roma Dubtsov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fomenko_E/0/1/0/all/0/1&quot;&gt;Evarist Fomenko&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pirogov_V/0/1/0/all/0/1&quot;&gt;Vadim Pirogov&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08311">
<title>Structured Control Nets for Deep Reinforcement Learning. (arXiv:1802.08311v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.08311</link>
<description rdf:parseType="Literal">&lt;p&gt;In recent years, Deep Reinforcement Learning has made impressive advances in
solving several important benchmark problems for sequential decision making.
Many control applications use a generic multilayer perceptron (MLP) for
non-vision parts of the policy network. In this work, we propose a new neural
network architecture for the policy network representation that is simple yet
effective. The proposed Structured Control Net (SCN) splits the generic MLP
into two separate sub-modules: a nonlinear control module and a linear control
module. Intuitively, the nonlinear control is for forward-looking and global
control, while the linear control stabilizes the local dynamics around the
residual of global control. We hypothesize that this will bring together the
benefits of both linear and nonlinear policies: improve training sample
efficiency, final episodic reward, and generalization of learned policy, while
requiring a smaller network and being generally applicable to different
training methods. We validated our hypothesis with competitive results on
simulations from OpenAI MuJoCo, Roboschool, Atari, and a custom 2D urban
driving environment, with various ablation and generalization tests, trained
with multiple black-box and policy gradient training methods. The proposed
architecture has the potential to improve upon broader control tasks by
incorporating problem specific priors into the architecture. As a case study,
we demonstrate much improved performance for locomotion tasks by emulating the
biological central pattern generators (CPGs) as the nonlinear part of the
architecture.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Srouji_M/0/1/0/all/0/1&quot;&gt;Mario Srouji&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Jian Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Salakhutdinov_R/0/1/0/all/0/1&quot;&gt;Ruslan Salakhutdinov&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08314">
<title>High Order Recurrent Neural Networks for Acoustic Modelling. (arXiv:1802.08314v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1802.08314</link>
<description rdf:parseType="Literal">&lt;p&gt;Vanishing long-term gradients are a major issue in training standard
recurrent neural networks (RNNs), which can be alleviated by long short-term
memory (LSTM) models with memory cells. However, the extra parameters
associated with the memory cells mean an LSTM layer has four times as many
parameters as an RNN with the same hidden vector size. This paper addresses the
vanishing gradient problem using a high order RNN (HORNN) which has additional
connections from multiple previous time steps. Speech recognition experiments
using British English multi-genre broadcast (MGB3) data showed that the
proposed HORNN architectures for rectified linear unit and sigmoid activation
functions reduced word error rates (WER) by 4.2% and 6.3% over the
corresponding RNNs, and gave similar WERs to a (projected) LSTM while using
only 20%--50% of the recurrent layer parameters and computation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1&quot;&gt;Chao Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Woodland_P/0/1/0/all/0/1&quot;&gt;Philip Woodland&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08352">
<title>Learning to Make Predictions on Graphs with Autoencoders. (arXiv:1802.08352v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1802.08352</link>
<description rdf:parseType="Literal">&lt;p&gt;We examine two fundamental tasks associated with graph representation
learning: link prediction and semi-supervised node classification. We present a
densely connected autoencoder architecture capable of learning a joint
representation of both local graph structure and available external node
features for the multi-task learning of link prediction and node
classification. To the best of our knowledge, this is the first architecture
that can be efficiently trained end-to-end in a single learning stage to
simultaneously perform link prediction and node classification. We provide
comprehensive empirical evaluation of our models on a range of challenging
benchmark graph-structured datasets, and demonstrate significant improvement in
accuracy over related methods for graph representation learning. Code
implementation is available at
https://github.com/vuptran/graph-representation-learning
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tran_P/0/1/0/all/0/1&quot;&gt;Phi Vu Tran&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08445">
<title>A Matrix Approach for Weighted Argumentation Frameworks: a Preliminary Report. (arXiv:1802.08445v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.08445</link>
<description rdf:parseType="Literal">&lt;p&gt;The assignment of weights to attacks in a classical Argumentation Framework
allows to compute semantics by taking into account the different importance of
each argument. We represent a Weighted Argumentation Framework by a non-binary
matrix, and we characterize the basic extensions (such as w-admissible, w-
stable, w-complete) by analysing sub-blocks of this matrix. Also, we show how
to reduce the matrix into another one of smaller size, that is equivalent to
the original one for the determination of extensions. Furthermore, we provide
two algorithms that allow to build incrementally w-grounded and w-preferred
extensions starting from a w-admissible extension.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bistarelli_S/0/1/0/all/0/1&quot;&gt;Stefano Bistarelli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tappini_A/0/1/0/all/0/1&quot;&gt;Alessandra Tappini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Taticchi_C/0/1/0/all/0/1&quot;&gt;Carlo Taticchi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08454">
<title>Faithful Semantical Embedding of a Dyadic Deontic Logic in HOL. (arXiv:1802.08454v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.08454</link>
<description rdf:parseType="Literal">&lt;p&gt;A shallow semantical embedding of a dyadic deontic logic by Carmo and Jones
in classical higher-order logic is presented. This embedding is proven sound
and complete, that is, faithful.
&lt;/p&gt;
&lt;p&gt;The work presented here provides the theoretical foundation for the
implementation and automation of dyadic deontic logic within off-the-shelf
higher-order theorem provers and proof assistants.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Benzmuller_C/0/1/0/all/0/1&quot;&gt;Christoph Benzm&amp;#xfc;ller&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Farjami_A/0/1/0/all/0/1&quot;&gt;Ali Farjami&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Parent_X/0/1/0/all/0/1&quot;&gt;Xavier Parent&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08534">
<title>Weighted Double Deep Multiagent Reinforcement Learning in Stochastic Cooperative Environments. (arXiv:1802.08534v1 [cs.MA])</title>
<link>http://arxiv.org/abs/1802.08534</link>
<description rdf:parseType="Literal">&lt;p&gt;Despite single agent deep reinforcement learning has achieved significant
success due to the experience replay mechanism, Concerns should be reconsidered
in multiagent environments. This work focus on the stochastic cooperative
environment. We apply a specific adaptation to one recently proposed weighted
double estimator and propose a multiagent deep reinforcement learning
framework, named Weighted Double Deep Q-Network (WDDQN). To achieve efficient
cooperation, \textit{Lenient Reward Network} and \textit{Mixture Replay
Strategy} are introduced. By utilizing the deep neural network and the weighted
double estimator, WDDQN can not only reduce the bias effectively but also be
extended to many deep RL scenarios with only raw pixel images as input.
Empirically, the WDDQN outperforms the existing DRL algorithm (double DQN) and
multiagent RL algorithm (lenient Q-learning) in terms of performance and
convergence within stochastic cooperative environments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1&quot;&gt;Yan Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hao_J/0/1/0/all/0/1&quot;&gt;Jianye Hao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1&quot;&gt;Zongzhang Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.03641">
<title>Continuous Adaptation via Meta-Learning in Nonstationary and Competitive Environments. (arXiv:1710.03641v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1710.03641</link>
<description rdf:parseType="Literal">&lt;p&gt;Ability to continuously learn and adapt from limited experience in
nonstationary environments is an important milestone on the path towards
general intelligence. In this paper, we cast the problem of continuous
adaptation into the learning-to-learn framework. We develop a simple
gradient-based meta-learning algorithm suitable for adaptation in dynamically
changing and adversarial scenarios. Additionally, we design a new multi-agent
competitive environment, RoboSumo, and define iterated adaptation games for
testing various aspects of continuous adaptation strategies. We demonstrate
that meta-learning enables significantly more efficient adaptation than
reactive baselines in the few-shot regime. Our experiments with a population of
agents that learn and compete suggest that meta-learners are the fittest.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Al_Shedivat_M/0/1/0/all/0/1&quot;&gt;Maruan Al-Shedivat&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bansal_T/0/1/0/all/0/1&quot;&gt;Trapit Bansal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Burda_Y/0/1/0/all/0/1&quot;&gt;Yuri Burda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sutskever_I/0/1/0/all/0/1&quot;&gt;Ilya Sutskever&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mordatch_I/0/1/0/all/0/1&quot;&gt;Igor Mordatch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1&quot;&gt;Pieter Abbeel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06070">
<title>Diversity is All You Need: Learning Skills without a Reward Function. (arXiv:1802.06070v3 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1802.06070</link>
<description rdf:parseType="Literal">&lt;p&gt;Intelligent creatures can explore their environments and learn useful skills
without supervision. In this paper, we propose DIAYN (&quot;Diversity is All You
Need&quot;), a method for learning useful skills without a reward function. Our
proposed method learns skills by maximizing an information theoretic objective
using a maximum entropy policy. On a variety of simulated robotic tasks, we
show that this simple objective results in the unsupervised emergence of
diverse skills, such as walking and jumping. In a number of reinforcement
learning benchmark environments, our method is able to learn a skill that
solves the benchmark task despite never receiving the true task reward. In
these environments, some of the learned skills correspond to solving the task,
and each skill that solves the task does so in a distinct manner. Our results
suggest that unsupervised discovery of skills can serve as an effective
pretraining mechanism for overcoming challenges of exploration and data
efficiency in reinforcement learning
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Eysenbach_B/0/1/0/all/0/1&quot;&gt;Benjamin Eysenbach&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1&quot;&gt;Abhishek Gupta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ibarz_J/0/1/0/all/0/1&quot;&gt;Julian Ibarz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1&quot;&gt;Sergey Levine&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08250">
<title>Overcoming Catastrophic Forgetting in Convolutional Neural Networks by Selective Network Augmentation. (arXiv:1802.08250v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.08250</link>
<description rdf:parseType="Literal">&lt;p&gt;Lifelong learning aims to develop machine learning systems that can learn new
tasks while preserving the performance on previous tasks. This approach can be
applied, for example, to prevent accident on autonomous vehicles by applying
the knowledge learned on previous situations. In this paper we present a method
to overcomes catastrophic forgetting that learns new tasks and preserves the
performance on old tasks without accessing the data of the original model, by
selective network augmentation, using convolutional neural networks for image
classification. The experiment results showed that our method, in some
scenarios outperforms the state-of-art Learning without Forgetting algorithm.
Results also showed that in some situations is better to use our model instead
of training a neural network using isolated learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zacarias_A/0/1/0/all/0/1&quot;&gt;Abel S. Zacarias&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alexandre_L/0/1/0/all/0/1&quot;&gt;Lu&amp;#xed;s A. Alexandre&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08526">
<title>The Weighted Kendall and High-order Kernels for Permutations. (arXiv:1802.08526v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.08526</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose new positive definite kernels for permutations. First we introduce
a weighted version of the Kendall kernel, which allows to weight unequally the
contributions of different item pairs in the permutations depending on their
ranks. Like the Kendall kernel, we show that the weighted version is invariant
to relabeling of items and can be computed efficiently in $O(n \ln(n))$
operations, where $n$ is the number of items in the permutation. Second, we
propose a supervised approach to learn the weights by jointly optimizing them
with the function estimated by a kernel machine. Third, while the Kendall
kernel considers pairwise comparison between items, we extend it by considering
higher-order comparisons among tuples of items and show that the supervised
approach of learning the weights can be systematically generalized to
higher-order permutation kernels.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Jiao_Y/0/1/0/all/0/1&quot;&gt;Yunlong Jiao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Vert_J/0/1/0/all/0/1&quot;&gt;Jean-Philippe Vert&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1612.02707">
<title>CrowdMI: Multiple Imputation via Crowdsourcing. (arXiv:1612.02707v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1612.02707</link>
<description rdf:parseType="Literal">&lt;p&gt;Can humans impute missing data with similar proficiency as machines? This is
the question we aim to answer in this paper. We present a novel idea of
converting observations with missing data in to a survey questionnaire, which
is presented to crowdworkers for completion. We replicate a multiple imputation
framework by having multiple unique crowdworkers complete our questionnaire.
Experimental results demonstrate that using our method, it is possible to
generate valid imputations for qualitative and quantitative missing data, with
results comparable to imputations generated by complex statistical models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gondara_L/0/1/0/all/0/1&quot;&gt;Lovedeep Gondara&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1707.01926">
<title>Diffusion Convolutional Recurrent Neural Network: Data-Driven Traffic Forecasting. (arXiv:1707.01926v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1707.01926</link>
<description rdf:parseType="Literal">&lt;p&gt;Spatiotemporal forecasting has various applications in neuroscience, climate
and transportation domain. Traffic forecasting is one canonical example of such
learning task. The task is challenging due to (1) complex spatial dependency on
road networks, (2) non-linear temporal dynamics with changing road conditions
and (3) inherent difficulty of long-term forecasting. To address these
challenges, we propose to model the traffic flow as a diffusion process on a
directed graph and introduce Diffusion Convolutional Recurrent Neural Network
(DCRNN), a deep learning framework for traffic forecasting that incorporates
both spatial and temporal dependency in the traffic flow. Specifically, DCRNN
captures the spatial dependency using bidirectional random walks on the graph,
and the temporal dependency using the encoder-decoder architecture with
scheduled sampling. We evaluate the framework on two real-world large scale
road network traffic datasets and observe consistent improvement of 12% - 15%
over state-of-the-art baselines.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yaguang Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_R/0/1/0/all/0/1&quot;&gt;Rose Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shahabi_C/0/1/0/all/0/1&quot;&gt;Cyrus Shahabi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yan Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.01401">
<title>Demystifying MMD GANs. (arXiv:1801.01401v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1801.01401</link>
<description rdf:parseType="Literal">&lt;p&gt;We investigate the training and performance of generative adversarial
networks using the Maximum Mean Discrepancy (MMD) as critic, termed MMD GANs.
As our main theoretical contribution, we clarify the situation with bias in GAN
loss functions raised by recent work: we show that gradient estimators used in
the optimization process for both MMD GANs and Wasserstein GANs are unbiased,
but learning a discriminator based on samples leads to biased gradients for the
generator parameters. We also discuss the issue of kernel choice for the MMD
critic, and characterize the kernel corresponding to the energy distance used
for the Cramer GAN critic. Being an integral probability metric, the MMD
benefits from training strategies recently developed for Wasserstein GANs. In
experiments, the MMD GAN is able to employ a smaller critic network than the
Wasserstein GAN, resulting in a simpler and faster-training algorithm with
matching performance. We also propose an improved measure of GAN convergence,
the Kernel Inception Distance, and show how to use it to dynamically adapt
learning rates during GAN training.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Binkowski_M/0/1/0/all/0/1&quot;&gt;Miko&amp;#x142;aj Bi&amp;#x144;kowski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sutherland_D/0/1/0/all/0/1&quot;&gt;Dougal J. Sutherland&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Arbel_M/0/1/0/all/0/1&quot;&gt;Michael Arbel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gretton_A/0/1/0/all/0/1&quot;&gt;Arthur Gretton&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.09203">
<title>Algorithmic Regularization in Over-parameterized Matrix Sensing and Neural Networks with Quadratic Activations. (arXiv:1712.09203v3 [cs.LG] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1712.09203</link>
<description rdf:parseType="Literal">&lt;p&gt;We show that the (stochastic) gradient descent algorithm provides an implicit
regularization effect in the learning of over-parameterized matrix
factorization models and one-hidden-layer neural networks with quadratic
activations. Concretely, we show that given $\tilde{O}(dr^{2})$ random linear
measurements of a rank $r$ positive semidefinite matrix $X^{\star}$, we can
recover $X^{\star}$ by parameterizing it by $UU^\top$ with $U\in
\mathbb{R}^{d\times d}$ and minimizing the squared loss, even if $r \ll d$. We
prove that starting from a small initialization, gradient descent recovers
$X^{\star}$ in $\tilde{O}(\sqrt{r})$ iterations approximately. The results
solve the conjecture of Gunasekar et al.&apos;17 under the restricted isometry
property. The technique can be applied to analyzing neural networks with
quadratic activations with some technical modifications.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yuanzhi Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_T/0/1/0/all/0/1&quot;&gt;Tengyu Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1&quot;&gt;Hongyang Zhang&lt;/a&gt;</dc:creator>
</item></rdf:RDF>