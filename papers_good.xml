<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Good papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Good Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-09-11T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.05849"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.03559"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.03916"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.03956"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.04040"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.00138"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.01239"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07340"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11154"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11648"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.00412"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.04343"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.02904"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.02383"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.03627"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.03672"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.03702"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.03832"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.03868"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.04019"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.02780"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07813"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.02740"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.02744"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1803.05849">
<title>XNORBIN: A 95 TOp/s/W Hardware Accelerator for Binary Convolutional Neural Networks. (arXiv:1803.05849v1 [cs.CV] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1803.05849</link>
<description rdf:parseType="Literal">&lt;p&gt;Deploying state-of-the-art CNNs requires power-hungry processors and off-chip
memory. This precludes the implementation of CNNs in low-power embedded
systems. Recent research shows CNNs sustain extreme quantization, binarizing
their weights and intermediate feature maps, thereby saving 8-32\x memory and
collapsing energy-intensive sum-of-products into XNOR-and-popcount operations.
&lt;/p&gt;
&lt;p&gt;We present XNORBIN, an accelerator for binary CNNs with computation tightly
coupled to memory for aggressive data reuse. Implemented in UMC 65nm technology
XNORBIN achieves an energy efficiency of 95 TOp/s/W and an area efficiency of
2.0 TOp/s/MGE at 0.8 V.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bahou_A/0/1/0/all/0/1&quot;&gt;Andrawes Al Bahou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Karunaratne_G/0/1/0/all/0/1&quot;&gt;Geethan Karunaratne&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Andri_R/0/1/0/all/0/1&quot;&gt;Renzo Andri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cavigelli_L/0/1/0/all/0/1&quot;&gt;Lukas Cavigelli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Benini_L/0/1/0/all/0/1&quot;&gt;Luca Benini&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.03559">
<title>Deep Learning Towards Mobile Applications. (arXiv:1809.03559v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1809.03559</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent years have witnessed an explosive growth of mobile devices. Mobile
devices are permeating every aspect of our daily lives. With the increasing
usage of mobile devices and intelligent applications, there is a soaring demand
for mobile applications with machine learning services. Inspired by the
tremendous success achieved by deep learning in many machine learning tasks, it
becomes a natural trend to push deep learning towards mobile applications.
However, there exist many challenges to realize deep learning in mobile
applications, including the contradiction between the miniature nature of
mobile devices and the resource requirement of deep neural networks, the
privacy and security concerns about individuals&apos; data, and so on. To resolve
these challenges, during the past few years, great leaps have been made in this
area. In this paper, we provide an overview of the current challenges and
representative achievements about pushing deep learning on mobile devices from
three aspects: training with mobile data, efficient inference on mobile
devices, and applications of mobile deep learning. The former two aspects cover
the primary tasks of deep learning. Then, we go through our two recent
applications that apply the data collected by mobile devices to inferring mood
disturbance and user identification. Finally, we conclude this paper with the
discussion of the future of this area.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Ji Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cao_B/0/1/0/all/0/1&quot;&gt;Bokai Cao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1&quot;&gt;Philip S. Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1&quot;&gt;Lichao Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bao_W/0/1/0/all/0/1&quot;&gt;Weidong Bao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1&quot;&gt;Xiaomin Zhu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.03916">
<title>Detecting Intentions of Vulnerable Road Users Based on Collective Intelligence. (arXiv:1809.03916v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1809.03916</link>
<description rdf:parseType="Literal">&lt;p&gt;Vulnerable road users (VRUs, i.e. cyclists and pedestrians) will play an
important role in future traffic. To avoid accidents and achieve a highly
efficient traffic flow, it is important to detect VRUs and to predict their
intentions. In this article a holistic approach for detecting intentions of
VRUs by cooperative methods is presented. The intention detection consists of
basic movement primitive prediction, e.g. standing, moving, turning, and a
forecast of the future trajectory. Vehicles equipped with sensors, data
processing systems and communication abilities, referred to as intelligent
vehicles, acquire and maintain a local model of their surrounding traffic
environment, e.g. crossing cyclists. Heterogeneous, open sets of agents
(cooperating and interacting vehicles, infrastructure, e.g. cameras and laser
scanners, and VRUs equipped with smart devices and body-worn sensors) exchange
information forming a multi-modal sensor system with the goal to reliably and
robustly detect VRUs and their intentions under consideration of real time
requirements and uncertainties. The resulting model allows to extend the
perceptual horizon of the individual agent beyond their own sensory
capabilities, enabling a longer forecast horizon. Concealments,
implausibilities and inconsistencies are resolved by the collective
intelligence of cooperating agents. Novel techniques of signal processing and
modelling in combination with analytical and learning based approaches of
pattern and activity recognition are used for detection, as well as intention
prediction of VRUs. Cooperation, by means of probabilistic sensor and knowledge
fusion, takes place on the level of perception and intention recognition. Based
on the requirements of the cooperative approach for the communication a new
strategy for an ad hoc network is proposed.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bieshaar_M/0/1/0/all/0/1&quot;&gt;Maarten Bieshaar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Reitberger_G/0/1/0/all/0/1&quot;&gt;G&amp;#xfc;nther Reitberger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zernetsch_S/0/1/0/all/0/1&quot;&gt;Stefan Zernetsch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sick_B/0/1/0/all/0/1&quot;&gt;Bernhard Sick&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fuchs_E/0/1/0/all/0/1&quot;&gt;Erich Fuchs&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Doll_K/0/1/0/all/0/1&quot;&gt;Konrad Doll&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.03956">
<title>Abstraction Learning. (arXiv:1809.03956v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1809.03956</link>
<description rdf:parseType="Literal">&lt;p&gt;There has been a gap between artificial intelligence and human intelligence.
In this paper, we identify three key elements forming human intelligence, and
suggest that abstraction learning combines these elements and is thus a way to
bridge the gap. Prior researches in artificial intelligence either specify
abstraction by human experts, or take abstraction as a qualitative explanation
for the model. This paper aims to learn abstraction directly. We tackle three
main challenges: representation, objective function, and learning algorithm.
Specifically, we propose a partition structure that contains pre-allocated
abstraction neurons; we formulate abstraction learning as a constrained
optimization problem, which integrates abstraction properties; we develop a
network evolution algorithm to solve this problem. This complete framework is
named ONE (Optimization via Network Evolution). In our experiments on MNIST,
ONE shows elementary human-like intelligence, including low energy consumption,
knowledge sharing, and lifelong learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deng_F/0/1/0/all/0/1&quot;&gt;Fei Deng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ren_J/0/1/0/all/0/1&quot;&gt;Jinsheng Ren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_F/0/1/0/all/0/1&quot;&gt;Feng Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.04040">
<title>Solving Imperfect-Information Games via Discounted Regret Minimization. (arXiv:1809.04040v1 [cs.GT])</title>
<link>http://arxiv.org/abs/1809.04040</link>
<description rdf:parseType="Literal">&lt;p&gt;Counterfactual regret minimization (CFR) is a family of iterative algorithms
that are the most popular and, in practice, fastest approach to approximately
solving large imperfect-information games. In this paper we introduce novel CFR
variants that 1) discount regrets from earlier iterations in various ways (in
some cases differently for positive and negative regrets), 2) reweight
iterations in various ways to obtain the output strategies, 3) use a
non-standard regret minimizer and/or 4) leverage &quot;optimistic regret matching&quot;.
They lead to dramatically improved performance in many settings. For one, we
introduce a variant that outperforms CFR+, the prior state-of-the-art
algorithm, in every game tested, including large-scale realistic settings. CFR+
is a formidable benchmark: no other algorithm has been able to outperform it.
Finally, we show that, unlike CFR+, many of the important new variants are
compatible with modern imperfect-information-game pruning techniques and one is
also compatible with sampling in the game tree.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brown_N/0/1/0/all/0/1&quot;&gt;Noam Brown&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sandholm_T/0/1/0/all/0/1&quot;&gt;Tuomas Sandholm&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.00138">
<title>Visualizing and Understanding Atari Agents. (arXiv:1711.00138v5 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1711.00138</link>
<description rdf:parseType="Literal">&lt;p&gt;While deep reinforcement learning (deep RL) agents are effective at
maximizing rewards, it is often unclear what strategies they use to do so. In
this paper, we take a step toward explaining deep RL agents through a case
study using Atari 2600 environments. In particular, we focus on using saliency
maps to understand how an agent learns and executes a policy. We introduce a
method for generating useful saliency maps and use it to show 1) what strong
agents attend to, 2) whether agents are making decisions for the right or wrong
reasons, and 3) how agents evolve during learning. We also test our method on
non-expert human subjects and find that it improves their ability to reason
about these agents. Overall, our results show that saliency information can
provide significant insight into an RL agent&apos;s decisions and learning behavior.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Greydanus_S/0/1/0/all/0/1&quot;&gt;Sam Greydanus&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koul_A/0/1/0/all/0/1&quot;&gt;Anurag Koul&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dodge_J/0/1/0/all/0/1&quot;&gt;Jonathan Dodge&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fern_A/0/1/0/all/0/1&quot;&gt;Alan Fern&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.01239">
<title>Counting and Sampling from Markov Equivalent DAGs Using Clique Trees. (arXiv:1802.01239v2 [cs.DS] UPDATED)</title>
<link>http://arxiv.org/abs/1802.01239</link>
<description rdf:parseType="Literal">&lt;p&gt;A directed acyclic graph (DAG) is the most common graphical model for
representing causal relationships among a set of variables. When restricted to
using only observational data, the structure of the ground truth DAG is
identifiable only up to Markov equivalence, based on conditional independence
relations among the variables. Therefore, the number of DAGs equivalent to the
ground truth DAG is an indicator of the causal complexity of the underlying
structure--roughly speaking, it shows how many interventions or how much
additional information is further needed to recover the underlying DAG. In this
paper, we propose a new technique for counting the number of DAGs in a Markov
equivalence class. Our approach is based on the clique tree representation of
chordal graphs. We show that in the case of bounded degree graphs, the proposed
algorithm is polynomial time. We further demonstrate that this technique can be
utilized for uniform sampling from a Markov equivalence class, which provides a
stochastic way to enumerate DAGs in the equivalence class and may be needed for
finding the best DAG or for causal inference given the equivalence class as
input. We also extend our counting and sampling method to the case where prior
knowledge about the underlying DAG is available, and present applications of
this extension in causal experiment design and estimating the causal effect of
joint interventions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghassami_A/0/1/0/all/0/1&quot;&gt;AmirEmad Ghassami&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Salehkaleybar_S/0/1/0/all/0/1&quot;&gt;Saber Salehkaleybar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kiyavash_N/0/1/0/all/0/1&quot;&gt;Negar Kiyavash&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1&quot;&gt;Kun Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07340">
<title>Improved Sentence Modeling using Suffix Bidirectional LSTM. (arXiv:1805.07340v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.07340</link>
<description rdf:parseType="Literal">&lt;p&gt;Recurrent neural networks have become ubiquitous in computing representations
of sequential data, especially textual data in natural language processing. In
particular, Bidirectional LSTMs are at the heart of several neural models
achieving state-of-the-art performance in a wide variety of tasks in NLP.
However, BiLSTMs are known to suffer from sequential bias - the contextual
representation of a token is heavily influenced by tokens close to it in a
sentence. We propose a general and effective improvement to the BiLSTM model
which encodes each suffix and prefix of a sequence of tokens in both forward
and reverse directions. We call our model Suffix Bidirectional LSTM or
SuBiLSTM. This introduces an alternate bias that favors long range
dependencies. We apply SuBiLSTMs to several tasks that require sentence
modeling. We demonstrate that using SuBiLSTM instead of a BiLSTM in existing
models leads to improvements in performance in learning general sentence
representations, text classification, textual entailment and paraphrase
detection. Using SuBiLSTM we achieve new state-of-the-art results for
fine-grained sentiment classification and question classification.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brahma_S/0/1/0/all/0/1&quot;&gt;Siddhartha Brahma&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11154">
<title>Refining Source Representations with Relation Networks for Neural Machine Translation. (arXiv:1805.11154v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1805.11154</link>
<description rdf:parseType="Literal">&lt;p&gt;Although neural machine translation with the encoder-decoder framework has
achieved great success recently, it still suffers drawbacks of forgetting
distant information, which is an inherent disadvantage of recurrent neural
network structure, and disregarding relationship between source words during
encoding step. Whereas in practice, the former information and relationship are
often useful in current step. We target on solving these problems and thus
introduce relation networks to learn better representations of the source. The
relation networks are able to facilitate memorization capability of recurrent
neural network via associating source words with each other, this would also
help retain their relationships. Then the source representations and all the
relations are fed into the attention component together while decoding, with
the main encoder-decoder framework unchanged. Experiments on several datasets
show that our method can improve the translation performance significantly over
the conventional encoder-decoder model and even outperform the approach
involving supervised syntactic knowledge.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1&quot;&gt;Wen Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_J/0/1/0/all/0/1&quot;&gt;Jiawei Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1&quot;&gt;Yang Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1&quot;&gt;Qun Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11648">
<title>Teaching Meaningful Explanations. (arXiv:1805.11648v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1805.11648</link>
<description rdf:parseType="Literal">&lt;p&gt;The adoption of machine learning in high-stakes applications such as
healthcare and law has lagged in part because predictions are not accompanied
by explanations comprehensible to the domain user, who often holds the ultimate
responsibility for decisions and outcomes. In this paper, we propose an
approach to generate such explanations in which training data is augmented to
include, in addition to features and labels, explanations elicited from domain
users. A joint model is then learned to produce both labels and explanations
from the input features. This simple idea ensures that explanations are
tailored to the complexity expectations and domain knowledge of the consumer.
Evaluation spans multiple modeling techniques on a game dataset, a (visual)
aesthetics dataset, a chemical odor dataset and a Melanoma dataset showing that
our approach is generalizable across domains and algorithms. Results
demonstrate that meaningful explanations can be reliably taught to machine
learning algorithms, and in some cases, also improve modeling accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Codella_N/0/1/0/all/0/1&quot;&gt;Noel C. F. Codella&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hind_M/0/1/0/all/0/1&quot;&gt;Michael Hind&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ramamurthy_K/0/1/0/all/0/1&quot;&gt;Karthikeyan Natesan Ramamurthy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Campbell_M/0/1/0/all/0/1&quot;&gt;Murray Campbell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dhurandhar_A/0/1/0/all/0/1&quot;&gt;Amit Dhurandhar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Varshney_K/0/1/0/all/0/1&quot;&gt;Kush R. Varshney&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wei_D/0/1/0/all/0/1&quot;&gt;Dennis Wei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mojsilovic_A/0/1/0/all/0/1&quot;&gt;Aleksandra Mojsilovic&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.00412">
<title>Learning to Drive in a Day. (arXiv:1807.00412v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1807.00412</link>
<description rdf:parseType="Literal">&lt;p&gt;We demonstrate the first application of deep reinforcement learning to
autonomous driving. From randomly initialised parameters, our model is able to
learn a policy for lane following in a handful of training episodes using a
single monocular image as input. We provide a general and easy to obtain
reward: the distance travelled by the vehicle without the safety driver taking
control. We use a continuous, model-free deep reinforcement learning algorithm,
with all exploration and optimisation performed on-vehicle. This demonstrates a
new framework for autonomous driving which moves away from reliance on defined
logical rules, mapping, and direct supervision. We discuss the challenges and
opportunities to scale this approach to a broader range of autonomous driving
tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kendall_A/0/1/0/all/0/1&quot;&gt;Alex Kendall&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hawke_J/0/1/0/all/0/1&quot;&gt;Jeffrey Hawke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Janz_D/0/1/0/all/0/1&quot;&gt;David Janz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mazur_P/0/1/0/all/0/1&quot;&gt;Przemyslaw Mazur&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Reda_D/0/1/0/all/0/1&quot;&gt;Daniele Reda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Allen_J/0/1/0/all/0/1&quot;&gt;John-Mark Allen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lam_V/0/1/0/all/0/1&quot;&gt;Vinh-Dieu Lam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bewley_A/0/1/0/all/0/1&quot;&gt;Alex Bewley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shah_A/0/1/0/all/0/1&quot;&gt;Amar Shah&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.04343">
<title>REGMAPR - Text Matching Made Easy. (arXiv:1808.04343v3 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1808.04343</link>
<description rdf:parseType="Literal">&lt;p&gt;Text matching is a fundamental problem in natural language processing. Neural
models using bidirectional LSTMs for sentence encoding and inter-sentence
attention mechanisms perform remarkably well on several benchmark datasets. We
propose REGMAPR - a simple and general architecture for text matching that does
not use inter-sentence attention. Starting from a Siamese architecture, we
augment the embeddings of the words with two features based on exact and para-
phrase match between words in the two sentences. We train the model using three
types of regularization on datasets for textual entailment, paraphrase
detection and semantic related- ness. REGMAPR performs comparably or better
than more complex neural models or models using a large number of handcrafted
features. REGMAPR achieves state-of-the-art results for paraphrase detection on
the SICK dataset and for textual entailment on the SNLI dataset among models
that do not use inter-sentence attention.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brahma_S/0/1/0/all/0/1&quot;&gt;Siddhartha Brahma&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.02904">
<title>A Continuous Information Gain Measure to Find the Most Discriminatory Problems for AI Benchmarking. (arXiv:1809.02904v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1809.02904</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper introduces an information-theoretic method for selecting a small
subset of problems which gives us the most information about a group of
problem-solving algorithms. This method was tested on the games in the General
Video Game AI (GVGAI) framework, allowing us to identify a smaller set of games
that still gives a large amount of information about the game-playing agents.
This approach can be used to make agent testing more efficient in the future.
We can achieve almost as good discriminatory accuracy when testing on only a
handful of games as when testing on more than a hundred games, something which
is often computationally infeasible. Furthermore, this method can be extended
to study the dimensions of effective variance in game design between these
games, allowing us to identify which games differentiate between agents in the
most complementary ways. As a side effect of this investigation, we provide an
up-to-date comparison on agent performance for all GVGAI games, and an analysis
of correlations between scores and win-rates across both games and agents.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stephenson_M/0/1/0/all/0/1&quot;&gt;Matthew Stephenson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Anderson_D/0/1/0/all/0/1&quot;&gt;Damien Anderson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khalifa_A/0/1/0/all/0/1&quot;&gt;Ahmed Khalifa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Levine_J/0/1/0/all/0/1&quot;&gt;John Levine&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Renz_J/0/1/0/all/0/1&quot;&gt;Jochen Renz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Togelius_J/0/1/0/all/0/1&quot;&gt;Julian Togelius&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Salge_C/0/1/0/all/0/1&quot;&gt;Christoph Salge&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.02383">
<title>A simple probabilistic deep generative model for learning generalizable disentangled representations from grouped data. (arXiv:1809.02383v1 [cs.LG] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1809.02383</link>
<description rdf:parseType="Literal">&lt;p&gt;The disentangling problem is to discover multiple complex factors of
variations hidden in data. One recent approach is to take a dataset with
grouping structure and separately estimate a factor common within a group
(content) and a factor specific to each group member (transformation). Notably,
this approach can learn to represent a continuous space of contents, which
allows for generalization to data with unseen contents. In this study, we aim
at cultivating this approach within probabilistic deep generative models.
Motivated by technical complication in existing group-based methods, we propose
a simpler probabilistic method, called group-contrastive variational
autoencoders. Despite its simplicity, our approach achieves reasonable
disentanglement with generalizability for three grouped datasets of 3D object
images. In comparison with a previous model, although conventional qualitative
evaluation shows little difference, our qualitative evaluation using few-shot
classification exhibits superior performances for some datasets. We analyze the
content representations from different methods and discuss their
transformation-dependency and potential performance impacts.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hosoya_H/0/1/0/all/0/1&quot;&gt;Haruo Hosoya&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.03627">
<title>ClusterGAN : Latent Space Clustering in Generative Adversarial Networks. (arXiv:1809.03627v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1809.03627</link>
<description rdf:parseType="Literal">&lt;p&gt;Generative Adversarial networks (GANs) have obtained remarkable success in
many unsupervised learning tasks and unarguably, clustering is an important
unsupervised learning problem. While one can potentially exploit the
latent-space back-projection in GANs to cluster, we demonstrate that the
cluster structure is not retained in the GAN latent space.
&lt;/p&gt;
&lt;p&gt;In this paper, we propose ClusterGAN as a new mechanism for clustering using
GANs. By sampling latent variables from a mixture of one-hot encoded variables
and continuous latent variables, coupled with an inverse network (which
projects the data to the latent space) trained jointly with a clustering
specific loss, we are able to achieve clustering in the latent space. Our
results show a remarkable phenomenon that GANs can preserve latent space
interpolation across categories, even though the discriminator is never exposed
to such vectors. We compare our results with various clustering baselines and
demonstrate superior performance on both synthetic and real datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mukherjee_S/0/1/0/all/0/1&quot;&gt;Sudipto Mukherjee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Asnani_H/0/1/0/all/0/1&quot;&gt;Himanshu Asnani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_E/0/1/0/all/0/1&quot;&gt;Eugene Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kannan_S/0/1/0/all/0/1&quot;&gt;Sreeram Kannan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.03672">
<title>Deep Interest Evolution Network for Click-Through Rate Prediction. (arXiv:1809.03672v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1809.03672</link>
<description rdf:parseType="Literal">&lt;p&gt;Click-through rate~(CTR) prediction, whose goal is to estimate the
probability of the user clicks, has become one of the core tasks in advertising
systems. For CTR prediction model, it is necessary to capture the latent user
interest behind the user behavior data. Besides, considering the changing of
the external environment and the internal cognition, user interest evolves over
time dynamically. There are several CTR prediction methods for interest
modeling, while most of them regard the representation of behavior as the
interest directly, and lack specially modeling for latent interest behind the
concrete behavior. Moreover, few work consider the changing trend of interest.
In this paper, we propose a novel model, named Deep Interest Evolution
Network~(DIEN), for CTR prediction. Specifically, we design interest extractor
layer to capture temporal interests from history behavior sequence. At this
layer, we introduce an auxiliary loss to supervise interest extracting at each
step. As user interests are diverse, especially in the e-commerce system, we
propose interest evolving layer to capture interest evolving process that is
relative to the target item. At interest evolving layer, attention mechanism is
embedded into the sequential structure novelly, and the effects of relative
interests are strengthened during interest evolution. In the experiments on
both public and industrial datasets, DIEN significantly outperforms the
state-of-the-art solutions. Notably, DIEN has been deployed in the display
advertisement system of Taobao, and obtained 20.7\% improvement on CTR.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhou_G/0/1/0/all/0/1&quot;&gt;Guorui Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mou_N/0/1/0/all/0/1&quot;&gt;Na Mou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Fan_Y/0/1/0/all/0/1&quot;&gt;Ying Fan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pi_Q/0/1/0/all/0/1&quot;&gt;Qi Pi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bian_W/0/1/0/all/0/1&quot;&gt;Weijie Bian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhou_C/0/1/0/all/0/1&quot;&gt;Chang Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhu_X/0/1/0/all/0/1&quot;&gt;Xiaoqiang Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gai_K/0/1/0/all/0/1&quot;&gt;Kun Gai&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.03702">
<title>Sparse Attentive Backtracking: Temporal CreditAssignment Through Reminding. (arXiv:1809.03702v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1809.03702</link>
<description rdf:parseType="Literal">&lt;p&gt;Learning long-term dependencies in extended temporal sequences requires
credit assignment to events far back in the past. The most common method for
training recurrent neural networks, back-propagation through time (BPTT),
requires credit information to be propagated backwards through every single
step of the forward computation, potentially over thousands or millions of time
steps. This becomes computationally expensive or even infeasible when used with
long sequences. Importantly, biological brains are unlikely to perform such
detailed reverse replay over very long sequences of internal states (consider
days, months, or years.) However, humans are often reminded of past memories or
mental states which are associated with the current mental state. We consider
the hypothesis that such memory associations between past and present could be
used for credit assignment through arbitrarily long sequences, propagating the
credit assigned to the current state to the associated past state. Based on
this principle, we study a novel algorithm which only back-propagates through a
few of these temporal skip connections, realized by a learned attention
mechanism that associates current states with relevant past states. We
demonstrate in experiments that our method matches or outperforms regular BPTT
and truncated BPTT in tasks involving particularly long-term dependencies, but
without requiring the biologically implausible backward replay through the
whole history of states. Additionally, we demonstrate that the proposed method
transfers to longer sequences significantly better than LSTMs trained with BPTT
and LSTMs trained with full self-attention.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ke_N/0/1/0/all/0/1&quot;&gt;Nan Rosemary Ke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goyal_A/0/1/0/all/0/1&quot;&gt;Anirudh Goyal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bilaniuk_O/0/1/0/all/0/1&quot;&gt;Olexa Bilaniuk&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Binas_J/0/1/0/all/0/1&quot;&gt;Jonathan Binas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mozer_M/0/1/0/all/0/1&quot;&gt;Michael C. Mozer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pal_C/0/1/0/all/0/1&quot;&gt;Chris Pal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bengio_Y/0/1/0/all/0/1&quot;&gt;Yoshua Bengio&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.03832">
<title>Learning rate adaptation for differentially private stochastic gradient descent. (arXiv:1809.03832v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1809.03832</link>
<description rdf:parseType="Literal">&lt;p&gt;Differentially private learning has recently emerged as the leading approach
for privacy-preserving machine learning. Differential privacy can complicate
learning procedures because each access to the data needs to be carefully
designed and carries a privacy cost. For example, standard parameter tuning
with a validation set cannot be easily applied. In this paper, we propose a
differentially private algorithm for the adaptation of the learning rate for
differentially private stochastic gradient descent (SGD) that avoids the need
for validation set use. The idea for the adaptiveness comes from the technique
of extrapolation in classical numerical analysis: to get an estimate for the
error against the gradient flow which underlies SGD, we compare the result
obtained by one full step and two half-steps. We prove the privacy of the
method using the moments accountant mechanism. This allows us to compute tight
privacy bounds. Empirically we show that our method is competitive with
manually tuned commonly used optimisation methods for training deep neural
networks and differentially private variational inference.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Koskela_A/0/1/0/all/0/1&quot;&gt;Antti Koskela&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Honkela_A/0/1/0/all/0/1&quot;&gt;Antti Honkela&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.03868">
<title>Dual-label Deep LSTM Dereverberation For Speaker Verification. (arXiv:1809.03868v1 [eess.AS])</title>
<link>http://arxiv.org/abs/1809.03868</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we present a reverberation removal approach for speaker
verification, utilizing dual-label deep neural networks (DNNs). The networks
perform feature mapping between the spectral features of reverberant and clean
speech. Long short term memory recurrent neural networks (LSTMs) are trained to
map corrupted Mel filterbank (MFB) features to two sets of labels: i) the clean
MFB features, and ii) either estimated pitch tracks or the fast Fourier
transform (FFT) spectrogram of clean speech. The performance of reverberation
removal is evaluated by equal error rates (EERs) of speaker verification
experiments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Zhang_H/0/1/0/all/0/1&quot;&gt;Hao Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Zahorian_S/0/1/0/all/0/1&quot;&gt;Stephen Zahorian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Chen_X/0/1/0/all/0/1&quot;&gt;Xiao Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Guzewich_P/0/1/0/all/0/1&quot;&gt;Peter Guzewich&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Liu_X/0/1/0/all/0/1&quot;&gt;Xiaoyu Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.04019">
<title>Training and Prediction Data Discrepancies: Challenges of Text Classification with Noisy, Historical Data. (arXiv:1809.04019v1 [cs.IR])</title>
<link>http://arxiv.org/abs/1809.04019</link>
<description rdf:parseType="Literal">&lt;p&gt;Industry datasets used for text classification are rarely created for that
purpose. In most cases, the data and target predictions are a by-product of
accumulated historical data, typically fraught with noise, present in both the
text-based document, as well as in the targeted labels. In this work, we
address the question of how well performance metrics computed on noisy,
historical data reflect the performance on the intended future machine learning
model input. The results demonstrate the utility of dirty training datasets
used to build prediction models for cleaner (and different) prediction inputs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Apostolova_E/0/1/0/all/0/1&quot;&gt;Emilia Apostolova&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kreek_R/0/1/0/all/0/1&quot;&gt;R. Andrew Kreek&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.02780">
<title>Transfer Learning with Neural AutoML. (arXiv:1803.02780v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1803.02780</link>
<description rdf:parseType="Literal">&lt;p&gt;We reduce the computational cost of Neural AutoML with transfer learning.
AutoML relieves human effort by automating the design of ML algorithms. Neural
AutoML has become popular for the design of deep learning architectures,
however, this method has a high computation cost.To address this we propose
Transfer Neural AutoML that uses knowledge from prior tasks to speed up network
design. We extend RL-based architecture search methods to support parallel
training on multiple tasks and then transfer the search strategy to new tasks.
On language and image classification data, Transfer Neural AutoML reduces
convergence time over single-task training by over an order of magnitude on
many tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wong_C/0/1/0/all/0/1&quot;&gt;Catherine Wong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Houlsby_N/0/1/0/all/0/1&quot;&gt;Neil Houlsby&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1&quot;&gt;Yifeng Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gesmundo_A/0/1/0/all/0/1&quot;&gt;Andrea Gesmundo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07813">
<title>Learning Real-World Robot Policies by Dreaming. (arXiv:1805.07813v3 [cs.RO] UPDATED)</title>
<link>http://arxiv.org/abs/1805.07813</link>
<description rdf:parseType="Literal">&lt;p&gt;Learning to control robots directly based on images is a primary challenge in
robotics. However, many existing reinforcement learning approaches require
iteratively obtaining millions of samples to learn a policy which can take
significant time. In this paper, we focus on the problem of learning real-world
robot action policies solely based on a few random off-policy initial samples.
We learn a realistic dreaming model that can emulate samples equivalent to a
sequence of images from the actual environment, and make the agent learn action
policies by interacting with the dreaming model rather than the real-world. We
experimentally confirm that our dreaming model can learn realistic policies
that transfer to the real-world.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Piergiovanni_A/0/1/0/all/0/1&quot;&gt;AJ Piergiovanni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_A/0/1/0/all/0/1&quot;&gt;Alan Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ryoo_M/0/1/0/all/0/1&quot;&gt;Michael S. Ryoo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.02740">
<title>Ensembles of Nested Dichotomies with Multiple Subset Evaluation. (arXiv:1809.02740v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1809.02740</link>
<description rdf:parseType="Literal">&lt;p&gt;A system of nested dichotomies is a method of decomposing a multi-class
problem into a collection of binary problems. Such a system recursively applies
binary splits to divide the set of classes into two subsets, and trains a
binary classifier for each split. Many methods have been proposed to perform
this split, each with various advantages and disadvantages. In this paper, we
present a simple, general method for improving the predictive performance of
nested dichotomies produced by any subset selection techniques that employ
randomness to construct the subsets. We provide a theoretical expectation for
performance improvements, as well as empirical results showing that our method
improves the root mean squared error of nested dichotomies, regardless of
whether they are employed as an individual model or in an ensemble setting.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leathart_T/0/1/0/all/0/1&quot;&gt;Tim Leathart&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Frank_E/0/1/0/all/0/1&quot;&gt;Eibe Frank&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pfahringer_B/0/1/0/all/0/1&quot;&gt;Bernhard Pfahringer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Holmes_G/0/1/0/all/0/1&quot;&gt;Geoffrey Holmes&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.02744">
<title>On the Calibration of Nested Dichotomies for Large Multiclass Tasks. (arXiv:1809.02744v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1809.02744</link>
<description rdf:parseType="Literal">&lt;p&gt;Nested dichotomies are used as a method of transforming a multiclass
classification problem into a series of binary problems. A tree structure is
induced that recursively splits the set of classes into subsets, and a binary
classification model learns to discriminate between the two subsets of classes
at each node. In this paper, we demonstrate that these nested dichotomies
typically exhibit poor probability calibration, even when the base binary
models are well calibrated. We also show that this problem is exacerbated when
the binary models are poorly calibrated. We discuss the effectiveness of
different calibration strategies and show that accuracy and log-loss can be
significantly improved by calibrating both the internal base models and the
full nested dichotomy structure, especially when the number of classes is high.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leathart_T/0/1/0/all/0/1&quot;&gt;Tim Leathart&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Frank_E/0/1/0/all/0/1&quot;&gt;Eibe Frank&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pfahringer_B/0/1/0/all/0/1&quot;&gt;Bernhard Pfahringer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Holmes_G/0/1/0/all/0/1&quot;&gt;Geoffrey Holmes&lt;/a&gt;</dc:creator>
</item></rdf:RDF>