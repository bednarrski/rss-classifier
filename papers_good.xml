<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Good papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Good Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-01-17T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.06563"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.05457"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.05462"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.05500"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.05532"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.05609"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.05667"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1708.07149"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.05512"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.05558"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.07324"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.10082"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.05236"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1712.06563">
<title>Safe Mutations for Deep and Recurrent Neural Networks through Output Gradients. (arXiv:1712.06563v2 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1712.06563</link>
<description rdf:parseType="Literal">&lt;p&gt;While neuroevolution (evolving neural networks) has a successful track record
across a variety of domains from reinforcement learning to artificial life, it
is rarely applied to large, deep neural networks. A central reason is that
while random mutation generally works in low dimensions, a random perturbation
of thousands or millions of weights is likely to break existing functionality,
providing no learning signal even if some individual weight changes were
beneficial. This paper proposes a solution by introducing a family of safe
mutation (SM) operators that aim within the mutation operator itself to find a
degree of change that does not alter network behavior too much, but still
facilitates exploration. Importantly, these SM operators do not require any
additional interactions with the environment. The most effective SM variant
capitalizes on the intriguing opportunity to scale the degree of mutation of
each individual weight according to the sensitivity of the network&apos;s outputs to
that weight, which requires computing the gradient of outputs with respect to
the weights (instead of the gradient of error, as in conventional deep
learning). This safe mutation through gradients (SM-G) operator dramatically
increases the ability of a simple genetic algorithm-based neuroevolution method
to find solutions in high-dimensional domains that require deep and/or
recurrent neural networks (which tend to be particularly brittle to mutation),
including domains that require processing raw pixels. By improving our ability
to evolve deep neural networks, this new safer approach to mutation expands the
scope of domains amenable to neuroevolution.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lehman_J/0/1/0/all/0/1&quot;&gt;Joel Lehman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1&quot;&gt;Jay Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Clune_J/0/1/0/all/0/1&quot;&gt;Jeff Clune&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stanley_K/0/1/0/all/0/1&quot;&gt;Kenneth O. Stanley&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.05457">
<title>Solutions to problems with deep learning. (arXiv:1801.05457v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1801.05457</link>
<description rdf:parseType="Literal">&lt;p&gt;Despite the several successes of deep learning systems, there are concerns
about their limitations, discussed most recently by Gary Marcus. This paper
discusses Marcus&apos;s concerns and some others, together with solutions to several
of these problems provided by the &quot;P theory of intelligence&quot; and its
realisation in the &quot;SP computer model&quot;. The main advantages of the SP system
are: relatively small requirements for data and the ability to learn from a
single experience; the ability to model both hierarchical and non-hierarchical
structures; strengths in several kinds of reasoning, including `commonsense&apos;
reasoning; transparency in the representation of knowledge, and the provision
of an audit trail for all processing; the likelihood that the SP system could
not be fooled into bizarre or eccentric recognition of stimuli, as deep
learning systems can be; the SP system provides a robust solution to the
problem of `catastrophic forgetting&apos; in deep learning systems; the SP system
provides a theoretically-coherent solution to the problems of correcting over-
and under-generalisations in learning, and learning correct structures despite
errors in data; unlike most research on deep learning, the SP programme of
research draws extensively on research on human learning, perception, and
cognition; and the SP programme of research has an overarching theory,
supported by evidence, something that is largely missing from research on deep
learning. In general, the SP system provides a much firmer foundation than deep
learning for the development of artificial general intelligence.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wolff_J/0/1/0/all/0/1&quot;&gt;J Gerard Wolff&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.05462">
<title>The Role of Conditional Independence in the Evolution of Intelligent Systems. (arXiv:1801.05462v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1801.05462</link>
<description rdf:parseType="Literal">&lt;p&gt;Systems are typically made from simple components regardless of their
complexity. While the function of each part is easily understood, higher order
functions are emergent properties and are notoriously difficult to explain. In
networked systems, both digital and biological, each component receives inputs,
performs a simple computation, and creates an output. When these components
have multiple outputs, we intuitively assume that the outputs are causally
dependent on the inputs but are themselves independent of each other given the
state of their shared input. However, this intuition can be violated for
components with probabilistic logic, as these typically cannot be decomposed
into separate logic gates with one output each. This violation of conditional
independence on the past system state is equivalent to instantaneous
interaction --- the idea is that some information between the outputs is not
coming from the inputs and thus must have been created instantaneously. Here we
compare evolved artificial neural systems with and without instantaneous
interaction across several task environments. We show that systems without
instantaneous interactions evolve faster, to higher final levels of
performance, and require fewer logic components to create a densely connected
cognitive machinery.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schossau_J/0/1/0/all/0/1&quot;&gt;Jory Schossau&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Albantakis_L/0/1/0/all/0/1&quot;&gt;Larissa Albantakis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hintze_A/0/1/0/all/0/1&quot;&gt;Arend Hintze&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.05500">
<title>Cellular-Connected UAVs over 5G: Deep Reinforcement Learning for Interference Management. (arXiv:1801.05500v1 [cs.IT])</title>
<link>http://arxiv.org/abs/1801.05500</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, an interference-aware path planning scheme for a network of
cellular-connected unmanned aerial vehicles (UAVs) is proposed. In particular,
each UAV aims at achieving a tradeoff between maximizing energy efficiency and
minimizing both wireless latency and the interference level caused on the
ground network along its path. The problem is cast as a dynamic game among
UAVs. To solve this game, a deep reinforcement learning algorithm, based on
echo state network (ESN) cells, is proposed. The introduced deep ESN
architecture is trained to allow each UAV to map each observation of the
network state to an action, with the goal of minimizing a sequence of
time-dependent utility functions. Each UAV uses ESN to learn its optimal path,
transmission power level, and cell association vector at different locations
along its path. The proposed algorithm is shown to reach a subgame perfect Nash
equilibrium (SPNE) upon convergence. Moreover, an upper and lower bound for the
altitude of the UAVs is derived thus reducing the computational complexity of
the proposed algorithm. Simulation results show that the proposed scheme
achieves better wireless latency per UAV and rate per ground user (UE) while
requiring a number of steps that is comparable to a heuristic baseline that
considers moving via the shortest distance towards the corresponding
destinations. The results also show that the optimal altitude of the UAVs
varies based on the ground network density and the UE data rate requirements
and plays a vital role in minimizing the interference level on the ground UEs
as well as the wireless transmission delay of the UAV.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Challita_U/0/1/0/all/0/1&quot;&gt;Ursula Challita&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saad_W/0/1/0/all/0/1&quot;&gt;Walid Saad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bettstetter_C/0/1/0/all/0/1&quot;&gt;Christian Bettstetter&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.05532">
<title>Reinforcement Learning based Recommender System using Biclustering Technique. (arXiv:1801.05532v1 [cs.IR])</title>
<link>http://arxiv.org/abs/1801.05532</link>
<description rdf:parseType="Literal">&lt;p&gt;A recommender system aims to recommend items that a user is interested in
among many items. The need for the recommender system has been expanded by the
information explosion. Various approaches have been suggested for providing
meaningful recommendations to users. One of the proposed approaches is to
consider a recommender system as a Markov decision process (MDP) problem and
try to solve it using reinforcement learning (RL). However, existing RL-based
methods have an obvious drawback. To solve an MDP in a recommender system, they
encountered a problem with the large number of discrete actions that bring RL
to a larger class of problems. In this paper, we propose a novel RL-based
recommender system. We formulate a recommender system as a gridworld game by
using a biclustering technique that can reduce the state and action space
significantly. Using biclustering not only reduces space but also improves the
recommendation quality effectively handling the cold-start problem. In
addition, our approach can provide users with some explanation why the system
recommends certain items. Lastly, we examine the proposed algorithm on a
real-world dataset and achieve a better performance than the widely used
recommendation algorithm.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Choi_S/0/1/0/all/0/1&quot;&gt;Sungwoon Choi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ha_H/0/1/0/all/0/1&quot;&gt;Heonseok Ha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hwang_U/0/1/0/all/0/1&quot;&gt;Uiwon Hwang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_C/0/1/0/all/0/1&quot;&gt;Chanju Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ha_J/0/1/0/all/0/1&quot;&gt;Jung-Woo Ha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yoon_S/0/1/0/all/0/1&quot;&gt;Sungroh Yoon&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.05609">
<title>Unseen Class Discovery in Open-world Classification. (arXiv:1801.05609v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1801.05609</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper concerns open-world classification, where the classifier not only
needs to classify test examples into seen classes that have appeared in
training but also reject examples from unseen or novel classes that have not
appeared in training. Specifically, this paper focuses on discovering the
hidden unseen classes of the rejected examples. Clearly, without prior
knowledge this is difficult. However, we do have the data from the seen
training classes, which can tell us what kind of similarity/difference is
expected for examples from the same class or from different classes. It is
reasonable to assume that this knowledge can be transferred to the rejected
examples and used to discover the hidden unseen classes in them. This paper
aims to solve this problem. It first proposes a joint open classification model
with a sub-model for classifying whether a pair of examples belongs to the same
or different classes. This sub-model can serve as a distance function for
clustering to discover the hidden classes of the rejected examples.
Experimental results show that the proposed model is highly promising.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shu_L/0/1/0/all/0/1&quot;&gt;Lei Shu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1&quot;&gt;Hu Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1&quot;&gt;Bing Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.05667">
<title>Innateness, AlphaZero, and Artificial Intelligence. (arXiv:1801.05667v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1801.05667</link>
<description rdf:parseType="Literal">&lt;p&gt;The concept of innateness is rarely discussed in the context of artificial
intelligence. When it is discussed, or hinted at, it is often the context of
trying to reduce the amount of innate machinery in a given system. In this
paper, I consider as a test case a recent series of papers by Silver et al
(Silver et al., 2017a) on AlphaGo and its successors that have been presented
as an argument that a &quot;even in the most challenging of domains: it is possible
to train to superhuman level, without human examples or guidance&quot;, &quot;starting
tabula rasa.&quot;
&lt;/p&gt;
&lt;p&gt;I argue that these claims are overstated, for multiple reasons. I close by
arguing that artificial intelligence needs greater attention to innateness, and
I point to some proposals about what that innateness might look like.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Marcus_G/0/1/0/all/0/1&quot;&gt;Gary Marcus&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1708.07149">
<title>Towards an Automatic Turing Test: Learning to Evaluate Dialogue Responses. (arXiv:1708.07149v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1708.07149</link>
<description rdf:parseType="Literal">&lt;p&gt;Automatically evaluating the quality of dialogue responses for unstructured
domains is a challenging problem. Unfortunately, existing automatic evaluation
metrics are biased and correlate very poorly with human judgements of response
quality. Yet having an accurate automatic evaluation procedure is crucial for
dialogue research, as it allows rapid prototyping and testing of new models
with fewer expensive human evaluations. In response to this challenge, we
formulate automatic dialogue evaluation as a learning problem. We present an
evaluation model (ADEM) that learns to predict human-like scores to input
responses, using a new dataset of human response scores. We show that the ADEM
model&apos;s predictions correlate significantly, and at a level much higher than
word-overlap metrics such as BLEU, with human judgements at both the utterance
and system-level. We also show that ADEM can generalize to evaluating dialogue
models unseen during training, an important step for automatic dialogue
evaluation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lowe_R/0/1/0/all/0/1&quot;&gt;Ryan Lowe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Noseworthy_M/0/1/0/all/0/1&quot;&gt;Michael Noseworthy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Serban_I/0/1/0/all/0/1&quot;&gt;Iulian V. Serban&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Angelard_Gontier_N/0/1/0/all/0/1&quot;&gt;Nicolas Angelard-Gontier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bengio_Y/0/1/0/all/0/1&quot;&gt;Yoshua Bengio&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pineau_J/0/1/0/all/0/1&quot;&gt;Joelle Pineau&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.05512">
<title>Deep Neural Networks for Survival Analysis Based on a Multi-Task Framework. (arXiv:1801.05512v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1801.05512</link>
<description rdf:parseType="Literal">&lt;p&gt;Survival analysis/time-to-event models are extremely useful as they can help
companies predict when a customer will buy a product, churn or default on a
loan, and therefore help them improve their ROI. In this paper, we introduce a
new method to calculate survival functions using the Multi-Task Logistic
Regression (MTLR) model as its base and a deep learning architecture as its
core. Based on the Concordance index (C-index) and Brier score, this method
outperforms the MTLR in all the experiments disclosed in this paper as well as
the Cox Proportional Hazard (CoxPH) model when nonlinear dependencies are
found.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Fotso_S/0/1/0/all/0/1&quot;&gt;Stephane Fotso&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.05558">
<title>Meta-Learning with Adaptive Layerwise Metric and Subspace. (arXiv:1801.05558v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1801.05558</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent advances in meta-learning demonstrate that deep representations
combined with the gradient descent method have sufficient capacity to
approximate any learning algorithm. A promising approach is the model-agnostic
meta-learning (MAML) which embeds gradient descent into the meta-learner. It
optimizes for the initial parameters of the learner to warm-start the gradient
descent updates, such that new tasks can be solved using a small number of
examples. In this paper we elaborate the gradient-based meta-learning,
developing two new schemes. First, we present a feedforward neural network,
referred to as T-net, where the linear transformation between two adjacent
layers is decomposed as T W such that W is learned by task-specific learners
and the transformation T, which is shared across tasks, is meta-learned to
speed up the convergence of gradient updates for task-specific learners.
Second, we present MT-net where gradient updates in the T-net are guided by a
binary mask M that is meta-learned, restricting the updates to be performed in
a subspace. Empirical results demonstrate that our method is less sensitive to
the choice of initial learning rates than existing meta-learning methods, and
achieves the state-of-the-art or comparable performance on few-shot
classification and regression tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lee_Y/0/1/0/all/0/1&quot;&gt;Yoonho Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Choi_S/0/1/0/all/0/1&quot;&gt;Seungjin Choi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.07324">
<title>Scalable Gaussian Processes with Billions of Inducing Inputs via Tensor Train Decomposition. (arXiv:1710.07324v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1710.07324</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a method (TT-GP) for approximate inference in Gaussian Process
(GP) models. We build on previous scalable GP research including stochastic
variational inference based on inducing inputs, kernel interpolation, and
structure exploiting algebra. The key idea of our method is to use Tensor Train
decomposition for variational parameters, which allows us to train GPs with
billions of inducing inputs and achieve state-of-the-art results on several
benchmarks. Further, our approach allows for training kernels based on deep
neural networks without any modifications to the underlying GP model. A neural
network learns a multidimensional embedding for the data, which is used by the
GP to make the final prediction. We train GP and neural network parameters
end-to-end without pretraining, through maximization of GP marginal likelihood.
We show the efficiency of the proposed approach on several regression and
classification benchmark datasets including MNIST, CIFAR-10, and Airline.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Izmailov_P/0/1/0/all/0/1&quot;&gt;Pavel Izmailov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Novikov_A/0/1/0/all/0/1&quot;&gt;Alexander Novikov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kropotov_D/0/1/0/all/0/1&quot;&gt;Dmitry Kropotov&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.10082">
<title>Application of Convolutional Neural Network to Predict Airfoil Lift Coefficient. (arXiv:1712.10082v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1712.10082</link>
<description rdf:parseType="Literal">&lt;p&gt;The adaptability of the convolutional neural network (CNN) technique for
aerodynamic meta-modeling tasks is probed in this work. The primary objective
is to develop suitable CNN architecture for variable flow conditions and object
geometry, in addition to identifying a sufficient data preparation process.
Multiple CNN structures were trained to learn the lift coefficients of the
airfoils with a variety of shapes in multiple flow Mach numbers, Reynolds
numbers, and diverse angles of attack. This is conducted to illustrate the
concept of the technique. A multi-layered perceptron (MLP) is also used for the
training sets. The MLP results are compared with that of the CNN results. The
newly proposed meta-modeling concept has been found to be comparable with the
MLP in learning capability; and more importantly, our CNN model exhibits a
competitive prediction accuracy with minimal constraints in a geometric
representation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yao Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sung_W/0/1/0/all/0/1&quot;&gt;Woong-Je Sung&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mavris_D/0/1/0/all/0/1&quot;&gt;Dimitri Mavris&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.05236">
<title>MORF: A Framework for MOOC Predictive Modeling and Replication At Scale. (arXiv:1801.05236v2 [cs.SE] UPDATED)</title>
<link>http://arxiv.org/abs/1801.05236</link>
<description rdf:parseType="Literal">&lt;p&gt;The MOOC Replication Framework (MORF) is a novel software system for feature
extraction, model training/testing, and evaluation of predictive dropout models
in Massive Open Online Courses (MOOCs). MORF makes large-scale replication of
complex machine-learned models tractable and accessible for researchers, and
enables public research on privacy-protected data. It does so by focusing on
the high-level operations of an extract-train-test-evaluate workflow, and
enables researchers to encapsulate their implementations in portable, fully
reproducible software containers which are executed on data with a known
schema. MORF&apos;s workflow allows researchers to use data in analysis without
providing them access to the underlying data directly, preserving privacy and
data security. During execution, containers are sandboxed for security and data
leakage and parallelized for efficiency, allowing researchers to create and
test new models rapidly, on large-scale multi-institutional datasets that were
previously inaccessible to most researchers. MORF is provided both as a Python
API (the MORF Software), for institutions to use on their own MOOC data) or in
a platform-as-a-service (PaaS) model with a web API and a high-performance
computing environment (the MORF Platform).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gardner_J/0/1/0/all/0/1&quot;&gt;Josh Gardner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brooks_C/0/1/0/all/0/1&quot;&gt;Christopher Brooks&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Andres_J/0/1/0/all/0/1&quot;&gt;Juan Miguel L. Andres&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Baker_R/0/1/0/all/0/1&quot;&gt;Ryan Baker&lt;/a&gt;</dc:creator>
</item></rdf:RDF>