<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Good papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Good Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-06-07T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02448"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02583"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02375"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02508"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02566"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02639"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02794"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02817"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.00350"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06070"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.01709"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02091"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02371"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02389"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02426"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02460"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02499"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02507"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02643"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02682"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02782"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.01223"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.03567"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04431"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04591"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.06969"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.11258"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09370"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.01768"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1806.02448">
<title>Deep Reinforcement Learning for General Video Game AI. (arXiv:1806.02448v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.02448</link>
<description rdf:parseType="Literal">&lt;p&gt;The General Video Game AI (GVGAI) competition and its associated software
framework provides a way of benchmarking AI algorithms on a large number of
games written in a domain-specific description language. While the competition
has seen plenty of interest, it has so far focused on online planning,
providing a forward model that allows the use of algorithms such as Monte Carlo
Tree Search.
&lt;/p&gt;
&lt;p&gt;In this paper, we describe how we interface GVGAI to the OpenAI Gym
environment, a widely used way of connecting agents to reinforcement learning
problems. Using this interface, we characterize how widely used implementations
of several deep reinforcement learning algorithms fare on a number of GVGAI
games. We further analyze the results to provide a first indication of the
relative difficulty of these games relative to each other, and relative to
those in the Arcade Learning Environment under similar conditions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Torrado_R/0/1/0/all/0/1&quot;&gt;Ruben Rodriguez Torrado&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bontrager_P/0/1/0/all/0/1&quot;&gt;Philip Bontrager&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Togelius_J/0/1/0/all/0/1&quot;&gt;Julian Togelius&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Jialin Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Perez_Liebana_D/0/1/0/all/0/1&quot;&gt;Diego Perez-Liebana&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02583">
<title>Generative Adversarial Networks for Realistic Synthesis of Hyperspectral Samples. (arXiv:1806.02583v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1806.02583</link>
<description rdf:parseType="Literal">&lt;p&gt;This work addresses the scarcity of annotated hyperspectral data required to
train deep neural networks. Especially, we investigate generative adversarial
networks and their application to the synthesis of consistent labeled spectra.
By training such networks on public datasets, we show that these models are not
only able to capture the underlying distribution, but also to generate
genuine-looking and physically plausible spectra. Moreover, we experimentally
validate that the synthetic samples can be used as an effective data
augmentation strategy. We validate our approach on several public
hyper-spectral datasets using a variety of deep classifiers.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Audebert_N/0/1/0/all/0/1&quot;&gt;Nicolas Audebert&lt;/a&gt; (OBELIX, DTIS, ONERA, Universit&amp;#xe9; Paris Saclay), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saux_B/0/1/0/all/0/1&quot;&gt;Bertrand Le Saux&lt;/a&gt; (DTIS, ONERA, Universit&amp;#xe9; Paris Saclay), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lefevre_S/0/1/0/all/0/1&quot;&gt;S&amp;#xe9;bastien Lef&amp;#xe8;vre&lt;/a&gt; (OBELIX)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02375">
<title>Understanding Batch Normalization. (arXiv:1806.02375v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.02375</link>
<description rdf:parseType="Literal">&lt;p&gt;Batch normalization is a ubiquitous deep learning technique that normalizes
activations in intermediate layers. It is associated with improved accuracy and
faster learning, but despite its enormous success there is little consensus
regarding why it works. We aim to rectify this and take an empirical approach
to understanding batch normalization. Our primary observation is that the
higher learning rates that batch normalization enables have a regularizing
effect that dramatically improves generalization of normalized networks, which
is both demonstrated empirically and motivated theoretically. We show how
activations become large and how the convolutional channels become increasingly
ill-behaved for layers deep in unnormalized networks, and how this results in
larger input-independent gradients. Beyond just gradient scaling, we
demonstrate how the learning rate in unnormalized networks is further limited
by the magnitude of activations growing exponentially with network depth for
large parameter updates, a problem batch normalization trivially avoids.
Motivated by recent results in random matrix theory, we argue that
ill-conditioning of the activations is due to fluctuations in random
initialization, shedding new light on classical initialization schemes and
their consequences.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bjorck_J/0/1/0/all/0/1&quot;&gt;Johan Bjorck&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gomes_C/0/1/0/all/0/1&quot;&gt;Carla Gomes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Selman_B/0/1/0/all/0/1&quot;&gt;Bart Selman&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02508">
<title>Fast Distributed Deep Learning via Worker-adaptive Batch Sizing. (arXiv:1806.02508v1 [cs.DC])</title>
<link>http://arxiv.org/abs/1806.02508</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep neural network models are usually trained in cluster environments, where
the model parameters are iteratively refined by multiple worker machines in
parallel. One key challenge in this regard is the presence of stragglers, which
significantly degrades the learning performance. In this paper, we propose to
eliminate stragglers by adapting each worker&apos;s training load to its processing
capability; that is, slower workers receive a smaller batch of data to process.
&lt;/p&gt;
&lt;p&gt;Following this idea, we develop a new synchronization scheme called LB-BSP
(Load-balanced BSP). It works by coordinately setting the batch size of each
worker so that they can finish batch processing at around the same time. A
prerequisite for deciding the workers&apos; batch sizes is to know their processing
speeds before each iteration starts. For the best prediction accuracy, we adopt
NARX, an extended recurrent neural network that accounts for both the
historical speeds and the driving factors such as CPU and memory in prediction.
We have implemented LB-BSP for both TensorFlow and MXNet. EC2 experiments
against popular benchmarks show that LB-BSP can effectively accelerate the
training of deep models, with up to 2x speedup.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1&quot;&gt;Chen Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Weng_Q/0/1/0/all/0/1&quot;&gt;Qizhen Weng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1&quot;&gt;Wei Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1&quot;&gt;Baochun Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1&quot;&gt;Bo Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02566">
<title>AI-based Two-Stage Intrusion Detection for Software Defined IoT Networks. (arXiv:1806.02566v1 [cs.CR])</title>
<link>http://arxiv.org/abs/1806.02566</link>
<description rdf:parseType="Literal">&lt;p&gt;Software Defined Internet of Things (SD-IoT) Networks profits from
centralized management and interactive resource sharing which enhances the
efficiency and scalability of IoT applications. But with the rapid growth in
services and applications, it is vulnerable to possible attacks and faces
severe security challenges. Intrusion detection has been widely used to ensure
network security, but classical detection means are usually signature-based or
explicit-behavior-based and fail to detect unknown attacks intelligently, which
are hard to satisfy the requirements of SD-IoT Networks. In this paper, we
propose an AI-based two-stage intrusion detection empowered by software defined
technology. It flexibly captures network flows with a globle view and detects
attacks intelligently through applying AI algorithms. We firstly leverage Bat
algorithm with swarm division and Differential Mutation to select typical
features. Then, we exploit Random forest through adaptively altering the
weights of samples using weighted voting mechanism to classify flows.
Evaluation results prove that the modified intelligent algorithms select more
important features and achieve superior performance in flow classification. It
is also verified that intelligent intrusion detection shows better accuracy
with lower overhead comparied with existing solutions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jiaqi Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1&quot;&gt;Zhifeng Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1&quot;&gt;Rongpeng Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1&quot;&gt;Honggang Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02639">
<title>Path-Level Network Transformation for Efficient Architecture Search. (arXiv:1806.02639v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.02639</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce a new function-preserving transformation for efficient neural
architecture search. This network transformation allows reusing previously
trained networks and existing successful architectures that improves sample
efficiency. We aim to address the limitation of current network transformation
operations that can only perform layer-level architecture modifications, such
as adding (pruning) filters or inserting (removing) a layer, which fails to
change the topology of connection paths. Our proposed path-level transformation
operations enable the meta-controller to modify the path topology of the given
network while keeping the merits of reusing weights, and thus allow efficiently
designing effective structures with complex path topologies like Inception
models. We further propose a bidirectional tree-structured reinforcement
learning meta-controller to explore a simple yet highly expressive
tree-structured architecture space that can be viewed as a generalization of
multi-branch architectures. We experimented on the image classification
datasets with limited computational resources (about 200 GPU-hours), where we
observed improved parameter efficiency and better test results (97.70% test
accuracy on CIFAR-10 with 14.3M parameters and 74.6% top-1 accuracy on ImageNet
in the mobile setting), demonstrating the effectiveness and transferability of
our designed architectures.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cai_H/0/1/0/all/0/1&quot;&gt;Han Cai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1&quot;&gt;Jiacheng Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1&quot;&gt;Weinan Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1&quot;&gt;Song Han&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1&quot;&gt;Yong Yu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02794">
<title>Unbiased Estimation of the Value of an Optimized Policy. (arXiv:1806.02794v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.02794</link>
<description rdf:parseType="Literal">&lt;p&gt;Randomized trials, also known as A/B tests, are used to select between two
policies: a control and a treatment. Given a corresponding set of features, we
can ideally learn an optimized policy P that maps the A/B test data features to
action space and optimizes reward. However, although A/B testing provides an
unbiased estimator for the value of deploying B (i.e., switching from policy A
to B), direct application of those samples to learn the the optimized policy P
generally does not provide an unbiased estimator of the value of P as the
samples were observed when constructing P. In situations where the cost and
risks associated of deploying a policy are high, such an unbiased estimator is
highly desirable.
&lt;/p&gt;
&lt;p&gt;We present a procedure for learning optimized policies and getting unbiased
estimates for the value of deploying them. We wrap any policy learning
procedure with a bagging process and obtain out-of-bag policy inclusion
decisions for each sample. We then prove that inverse-propensity-weighting
effect estimator is unbiased when applied to the optimized subset. Likewise, we
apply the same idea to obtain out-of-bag unbiased per-sample value estimate of
the measurement that is independent of the randomized treatment, and use these
estimates to build an unbiased doubly-robust effect estimator. Lastly, we
empirically shown that even when the average treatment effect is negative we
can find a positive optimized policy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Portugaly_E/0/1/0/all/0/1&quot;&gt;Elon Portugaly&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pfeiffer_J/0/1/0/all/0/1&quot;&gt;Joseph J. Pfeiffer III&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02817">
<title>Probabilistic Model-Agnostic Meta-Learning. (arXiv:1806.02817v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.02817</link>
<description rdf:parseType="Literal">&lt;p&gt;Meta-learning for few-shot learning entails acquiring a prior over previous
tasks and experiences, such that new tasks be learned from small amounts of
data. However, a critical challenge in few-shot learning is task ambiguity:
even when a powerful prior can be meta-learned from a large number of prior
tasks, a small dataset for a new task can simply be too ambiguous to acquire a
single model (e.g., a classifier) for that task that is accurate. In this
paper, we propose a probabilistic meta-learning algorithm that can sample
models for a new task from a model distribution. Our approach extends
model-agnostic meta-learning, which adapts to new tasks via gradient descent,
to incorporate a parameter distribution that is trained via a variational lower
bound. At meta-test time, our algorithm adapts via a simple procedure that
injects noise into gradient descent, and at meta-training time, the model is
trained such that this stochastic adaptation procedure produces samples from
the approximate model posterior. Our experimental results show that our method
can sample plausible classifiers and regressors in ambiguous few-shot learning
problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Finn_C/0/1/0/all/0/1&quot;&gt;Chelsea Finn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_K/0/1/0/all/0/1&quot;&gt;Kelvin Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1&quot;&gt;Sergey Levine&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.00350">
<title>Generalization without systematicity: On the compositional skills of sequence-to-sequence recurrent networks. (arXiv:1711.00350v3 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1711.00350</link>
<description rdf:parseType="Literal">&lt;p&gt;Humans can understand and produce new utterances effortlessly, thanks to
their compositional skills. Once a person learns the meaning of a new verb
&quot;dax,&quot; he or she can immediately understand the meaning of &quot;dax twice&quot; or &quot;sing
and dax.&quot; In this paper, we introduce the SCAN domain, consisting of a set of
simple compositional navigation commands paired with the corresponding action
sequences. We then test the zero-shot generalization capabilities of a variety
of recurrent neural networks (RNNs) trained on SCAN with sequence-to-sequence
methods. We find that RNNs can make successful zero-shot generalizations when
the differences between training and test commands are small, so that they can
apply &quot;mix-and-match&quot; strategies to solve the task. However, when
generalization requires systematic compositional skills (as in the &quot;dax&quot;
example above), RNNs fail spectacularly. We conclude with a proof-of-concept
experiment in neural machine translation, suggesting that lack of systematicity
might be partially responsible for neural networks&apos; notorious training data
thirst.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lake_B/0/1/0/all/0/1&quot;&gt;Brenden M. Lake&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Baroni_M/0/1/0/all/0/1&quot;&gt;Marco Baroni&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06070">
<title>Diversity is All You Need: Learning Skills without a Reward Function. (arXiv:1802.06070v5 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1802.06070</link>
<description rdf:parseType="Literal">&lt;p&gt;Intelligent creatures can explore their environments and learn useful skills
without supervision. In this paper, we propose DIAYN (&apos;Diversity is All You
Need&apos;), a method for learning useful skills without a reward function. Our
proposed method learns skills by maximizing an information theoretic objective
using a maximum entropy policy. On a variety of simulated robotic tasks, we
show that this simple objective results in the unsupervised emergence of
diverse skills, such as walking and jumping. In a number of reinforcement
learning benchmark environments, our method is able to learn a skill that
solves the benchmark task despite never receiving the true task reward. We show
how pretrained skills can provide a good parameter initialization for
downstream tasks, and can be composed hierarchically to solve complex, sparse
reward tasks. Our results suggest that unsupervised discovery of skills can
serve as an effective pretraining mechanism for overcoming challenges of
exploration and data efficiency in reinforcement learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Eysenbach_B/0/1/0/all/0/1&quot;&gt;Benjamin Eysenbach&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1&quot;&gt;Abhishek Gupta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ibarz_J/0/1/0/all/0/1&quot;&gt;Julian Ibarz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1&quot;&gt;Sergey Levine&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.01709">
<title>Human-like generalization in a machine through predicate learning. (arXiv:1806.01709v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1806.01709</link>
<description rdf:parseType="Literal">&lt;p&gt;Humans readily generalize, applying prior knowledge to novel situations and
stimuli. Advances in machine learning and artificial intelligence have begun to
approximate and even surpass human performance, but machine systems reliably
struggle to generalize information to untrained situations. We describe a
neural network model that is trained to play one video game (Breakout) and
demonstrates one-shot generalization to a new game (Pong). The model
generalizes by learning representations that are functionally and formally
symbolic from training data, without feedback, and without requiring that
structured representations be specified a priori. The model uses unsupervised
comparison to discover which characteristics of the input are invariant, and to
learn relational predicates; it then applies these predicates to arguments in a
symbolic fashion, using oscillatory regularities in network firing to
dynamically bind predicates to arguments. We argue that models of human
cognition must account for far- reaching and flexible generalization, and that
in order to do so, models must be able to discover symbolic representations
from unstructured data, a process we call predicate learning. Only then can
models begin to adequately explain where human-like representations come from,
why human cognition is the way it is, and why it continues to differ from
machine intelligence in crucial ways.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Doumas_L/0/1/0/all/0/1&quot;&gt;Leonidas A. A. Doumas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Puebla_G/0/1/0/all/0/1&quot;&gt;Guillermo Puebla&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Martin_A/0/1/0/all/0/1&quot;&gt;Andrea E. Martin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02091">
<title>Can Machines Design? An Artificial General Intelligence Approach. (arXiv:1806.02091v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1806.02091</link>
<description rdf:parseType="Literal">&lt;p&gt;Can machines design? Can they come up with creative solutions to problems and
build tools and artifacts across a wide range of domains? Recent advances in
the field of computational creativity and formal Artificial General
Intelligence (AGI) provide frameworks for machines with the general ability to
design. In this paper we propose to integrate a formal computational creativity
framework into the G\&quot;odel machine framework. We call this machine a design
G\&quot;odel machine. Such a machine could solve a variety of design problems by
generating novel concepts. In addition, it could change the way these concepts
are generated by modifying itself. The design G\&quot;odel machine is able to
improve its initial design program, once it has proven that a modification
would increase its return on the utility function. Finally, we sketch out a
specific version of the design G\&quot;odel machine which specifically aims at the
design of complex software and hardware systems. Future work could be the
development of a more formal version of the Design G\&quot;odel machine and a
potential implementation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hein_A/0/1/0/all/0/1&quot;&gt;Andreas Makoto Hein&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Condat_H/0/1/0/all/0/1&quot;&gt;H&amp;#xe9;l&amp;#xe8;ne Condat&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02371">
<title>Adversarial Attack on Graph Structured Data. (arXiv:1806.02371v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.02371</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep learning on graph structures has shown exciting results in various
applications. However, few attentions have been paid to the robustness of such
models, in contrast to numerous research work for image or text adversarial
attack and defense. In this paper, we focus on the adversarial attacks that
fool the model by modifying the combinatorial structure of data. We first
propose a reinforcement learning based attack method that learns the
generalizable attack policy, while only requiring prediction labels from the
target classifier. Also, variants of genetic algorithms and gradient methods
are presented in the scenario where prediction confidence or gradients are
available. We use both synthetic and real-world data to show that, a family of
Graph Neural Network models are vulnerable to these attacks, in both
graph-level and node-level classification tasks. We also show such attacks can
be used to diagnose the learned classifiers.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dai_H/0/1/0/all/0/1&quot;&gt;Hanjun Dai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1&quot;&gt;Hui Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tian_T/0/1/0/all/0/1&quot;&gt;Tian Tian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1&quot;&gt;Xin Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1&quot;&gt;Lin Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1&quot;&gt;Jun Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_L/0/1/0/all/0/1&quot;&gt;Le Song&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02389">
<title>$d_{\mathcal{X}}$-Private Mechanisms for Linear Queries. (arXiv:1806.02389v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.02389</link>
<description rdf:parseType="Literal">&lt;p&gt;Differential Privacy is one of the strongest privacy guarantees, which allows
the release of useful information about any sensitive dataset. However, it
provides the same level of protection for all elements in the data universe. In
this paper, we consider $d_{\mathcal{X}}$-privacy, an instantiation of the
privacy notion introduced in \cite{chatzikokolakis2013broadening}, which allows
specifying a separate privacy budget for each pair of elements in the data
universe. We describe a systematic procedure to tailor any existing
differentially private mechanism into a $d_{\mathcal{X}}$-private variant for
the case of linear queries. For the resulting $d_{\mathcal{X}}$-private
mechanisms, we provide theoretical guarantees on the trade-off between utility
and privacy, and show that they always outperform their \emph{vanilla}
counterpart. We demonstrate the effectiveness of our procedure, by evaluating
the proposed $d_{\mathcal{X}}$-private Laplace mechanism on both synthetic and
real datasets using a set of randomly generated linear queries.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kamalaruban_P/0/1/0/all/0/1&quot;&gt;Parameswaran Kamalaruban&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Perrier_V/0/1/0/all/0/1&quot;&gt;Victor Perrier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Asghar_H/0/1/0/all/0/1&quot;&gt;Hassan Jameel Asghar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kaafar_M/0/1/0/all/0/1&quot;&gt;Mohamed Ali Kaafar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02426">
<title>Deep Variational Reinforcement Learning for POMDPs. (arXiv:1806.02426v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.02426</link>
<description rdf:parseType="Literal">&lt;p&gt;Many real-world sequential decision making problems are partially observable
by nature, and the environment model is typically unknown. Consequently, there
is great need for reinforcement learning methods that can tackle such problems
given only a stream of incomplete and noisy observations. In this paper, we
propose deep variational reinforcement learning (DVRL), which introduces an
inductive bias that allows an agent to learn a generative model of the
environment and perform inference in that model to effectively aggregate the
available information. We develop an n-step approximation to the evidence lower
bound (ELBO), allowing the model to be trained jointly with the policy. This
ensures that the latent state representation is suitable for the control task.
In experiments on Mountain Hike and flickering Atari we show that our method
outperforms previous approaches relying on recurrent neural networks to encode
the past.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Igl_M/0/1/0/all/0/1&quot;&gt;Maximilian Igl&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zintgraf_L/0/1/0/all/0/1&quot;&gt;Luisa Zintgraf&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Le_T/0/1/0/all/0/1&quot;&gt;Tuan Anh Le&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wood_F/0/1/0/all/0/1&quot;&gt;Frank Wood&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Whiteson_S/0/1/0/all/0/1&quot;&gt;Shimon Whiteson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02460">
<title>The effect of the choice of neural network depth and breadth on the size of its hypothesis space. (arXiv:1806.02460v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.02460</link>
<description rdf:parseType="Literal">&lt;p&gt;We show that the number of unique function mappings in a neural network
hypothesis space is inversely proportional to $\prod_lU_l!$, where $U_{l}$ is
the number of neurons in the hidden layer $l$.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Szymanski_L/0/1/0/all/0/1&quot;&gt;Lech Szymanski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+McCane_B/0/1/0/all/0/1&quot;&gt;Brendan McCane&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Albert_M/0/1/0/all/0/1&quot;&gt;Michael Albert&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02499">
<title>Conditional probability calculation using restricted Boltzmann machine with application to system identification. (arXiv:1806.02499v1 [cs.SY])</title>
<link>http://arxiv.org/abs/1806.02499</link>
<description rdf:parseType="Literal">&lt;p&gt;There are many advantages to use probability method for nonlinear system
identification, such as the noises and outliers in the data set do not affect
the probability models significantly; the input features can be extracted in
probability forms. The biggest obstacle of the probability model is the
probability distributions are not easy to be obtained. In this paper, we form
the nonlinear system identification into solving the conditional probability.
Then we modify the restricted Boltzmann machine (RBM), such that the joint
probability, input distribution, and the conditional probability can be
calculated by the RBM training. Binary encoding and continue valued methods are
discussed. The universal approximation analysis for the conditional probability
based modelling is proposed. We use two benchmark nonlinear systems to compare
our probability modelling method with the other black-box modeling methods. The
results show that this novel method is much better when there are big noises
and the system dynamics are complex.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rosa_E/0/1/0/all/0/1&quot;&gt;Erick de la Rosa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_W/0/1/0/all/0/1&quot;&gt;Wen Yu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02507">
<title>Large scale classification in deep neural network with Label Mapping. (arXiv:1806.02507v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.02507</link>
<description rdf:parseType="Literal">&lt;p&gt;In recent years, deep neural network is widely used in machine learning. The
multi-class classification problem is a class of important problem in machine
learning. However, in order to solve those types of multi-class classification
problems effectively, the required network size should have hyper-linear growth
with respect to the number of classes. Therefore, it is infeasible to solve the
multi-class classification problem using deep neural network when the number of
classes are huge. This paper presents a method, so called Label Mapping (LM),
to solve this problem by decomposing the original classification problem to
several smaller sub-problems which are solvable theoretically. Our method is an
ensemble method like error-correcting output codes (ECOC), but it allows base
learners to be multi-class classifiers with different number of class labels.
We propose two design principles for LM, one is to maximize the number of base
classifier which can separate two different classes, and the other is to keep
all base learners to be independent as possible in order to reduce the
redundant information. Based on these principles, two different LM algorithms
are derived using number theory and information theory. Since each base learner
can be trained independently, it is easy to scale our method into a large scale
training system. Experiments show that our proposed method outperforms the
standard one-hot encoding and ECOC significantly in terms of accuracy and model
complexity.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1&quot;&gt;Qizhi Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1&quot;&gt;Kuang-Chih Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bao_H/0/1/0/all/0/1&quot;&gt;Hongying Bao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+You_Y/0/1/0/all/0/1&quot;&gt;Yuan You&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1&quot;&gt;Wenjie Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_D/0/1/0/all/0/1&quot;&gt;Dongbai Guo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02643">
<title>Re-evaluating evaluation. (arXiv:1806.02643v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.02643</link>
<description rdf:parseType="Literal">&lt;p&gt;Progress in machine learning is measured by careful evaluation on problems of
outstanding common interest. However, the proliferation of benchmark suites and
environments, adversarial attacks, and other complications has diluted the
basic evaluation model by overwhelming researchers with choices. Deliberate or
accidental cherry picking is increasingly likely, and designing well-balanced
evaluation suites requires increasing effort. In this paper we take a step back
and propose Nash averaging. The approach builds on a detailed analysis of the
algebraic structure of evaluation in two basic scenarios: agent-vs-agent and
agent-vs-task. The key strength of Nash averaging is that it automatically
adapts to redundancies in evaluation data, so that results are not biased by
the incorporation of easy tasks or weak agents. Nash averaging thus encourages
maximally inclusive evaluation -- since there is no harm (computational cost
aside) from including all available tasks and agents.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Balduzzi_D/0/1/0/all/0/1&quot;&gt;David Balduzzi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tuyls_K/0/1/0/all/0/1&quot;&gt;Karl Tuyls&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Perolat_J/0/1/0/all/0/1&quot;&gt;Julien Perolat&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Graepel_T/0/1/0/all/0/1&quot;&gt;Thore Graepel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02682">
<title>Transfer Learning for Illustration Classification. (arXiv:1806.02682v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1806.02682</link>
<description rdf:parseType="Literal">&lt;p&gt;The field of image classification has shown an outstanding success thanks to
the development of deep learning techniques. Despite the great performance
obtained, most of the work has focused on natural images ignoring other domains
like artistic depictions. In this paper, we use transfer learning techniques to
propose a new classification network with better performance in illustration
images. Starting from the deep convolutional network VGG19, pre-trained with
natural images, we propose two novel models which learn object representations
in the new domain. Our optimized network will learn new low-level features of
the images (colours, edges, textures) while keeping the knowledge of the
objects and shapes that it already learned from the ImageNet dataset. Thus,
requiring much less data for the training. We propose a novel dataset of
illustration images labelled by content where our optimized architecture
achieves $\textbf{86.61\%}$ of top-1 and $\textbf{97.21\%}$ of top-5 precision.
We additionally demonstrate that our model is still able to recognize objects
in photographs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lagunas_M/0/1/0/all/0/1&quot;&gt;Manuel Lagunas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garces_E/0/1/0/all/0/1&quot;&gt;Elena Garces&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02782">
<title>Training Augmentation with Adversarial Examples for Robust Speech Recognition. (arXiv:1806.02782v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1806.02782</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper explores the use of adversarial examples in training speech
recognition systems to increase robustness of deep neural network acoustic
models. During training, the fast gradient sign method is used to generate
adversarial examples augmenting the original training data. Different from
conventional data augmentation based on data transformations, the examples are
dynamically generated based on current acoustic model parameters. We assess the
impact of adversarial data augmentation in experiments on the Aurora-4 and
CHiME-4 single-channel tasks, showing improved robustness against noise and
channel variation. Further improvement is obtained when combining adversarial
examples with teacher/student training, leading to a 23% relative word error
rate reduction on Aurora-4.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_S/0/1/0/all/0/1&quot;&gt;Sining Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yeh_C/0/1/0/all/0/1&quot;&gt;Ching-Feng Yeh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ostendorf_M/0/1/0/all/0/1&quot;&gt;Mari Ostendorf&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hwang_M/0/1/0/all/0/1&quot;&gt;Mei-Yuh Hwang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_L/0/1/0/all/0/1&quot;&gt;Lei Xie&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.01223">
<title>Learning Compact Neural Networks with Regularization. (arXiv:1802.01223v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1802.01223</link>
<description rdf:parseType="Literal">&lt;p&gt;Proper regularization is critical for speeding up training, improving
generalization performance, and learning compact models that are cost
efficient. We propose and analyze regularized gradient descent algorithms for
learning shallow neural networks. Our framework is general and covers
weight-sharing (convolutional networks), sparsity (network pruning), and
low-rank constraints among others. We first introduce covering dimension to
quantify the complexity of the constraint set and provide insights on the
generalization properties. Then, we show that proposed algorithms become
well-behaved and local linear convergence occurs once the amount of data
exceeds the covering dimension. Overall, our results demonstrate that
near-optimal sample complexity is sufficient for efficient learning and
illustrate how regularization can be beneficial to learn over-parameterized
networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oymak_S/0/1/0/all/0/1&quot;&gt;Samet Oymak&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.03567">
<title>Crit\`eres de qualit\&apos;e d&apos;un classifieur g\&apos;en\&apos;eraliste. (arXiv:1802.03567v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1802.03567</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper considers the problem of choosing a good classifier. For each
problem there exist an optimal classifier, but none are optimal, regarding the
error rate, in all cases. Because there exists a large number of classifiers, a
user would rather prefer an all-purpose classifier that is easy to adjust, in
the hope that it will do almost as good as the optimal. In this paper we
establish a list of criteria that a good generalist classifier should satisfy .
We first discuss data analytic, these criteria are presented. Six among the
most popular classifiers are selected and scored according to these criteria.
Tables allow to easily appreciate the relative values of each. In the end,
random forests turn out to be the best classifiers.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ducharme_G/0/1/0/all/0/1&quot;&gt;Gilles R. Ducharme&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04431">
<title>Detecting Spacecraft Anomalies Using LSTMs and Nonparametric Dynamic Thresholding. (arXiv:1802.04431v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1802.04431</link>
<description rdf:parseType="Literal">&lt;p&gt;As spacecraft send back increasing amounts of telemetry data, improved
anomaly detection systems are needed to lessen the monitoring burden placed on
operations engineers and reduce operational risk. Current spacecraft monitoring
systems only target a subset of anomaly types and often require costly expert
knowledge to develop and maintain due to challenges involving scale and
complexity. We demonstrate the effectiveness of Long Short-Term Memory (LSTMs)
networks, a type of Recurrent Neural Network (RNN), in overcoming these issues
using expert-labeled telemetry anomaly data from the Soil Moisture Active
Passive (SMAP) satellite and the Mars Science Laboratory (MSL) rover,
Curiosity. We also propose a complementary unsupervised and nonparametric
anomaly thresholding approach developed during a pilot implementation of an
anomaly detection system for SMAP, and offer false positive mitigation
strategies along with other key improvements and lessons learned during
development.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hundman_K/0/1/0/all/0/1&quot;&gt;Kyle Hundman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Constantinou_V/0/1/0/all/0/1&quot;&gt;Valentino Constantinou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Laporte_C/0/1/0/all/0/1&quot;&gt;Christopher Laporte&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Colwell_I/0/1/0/all/0/1&quot;&gt;Ian Colwell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Soderstrom_T/0/1/0/all/0/1&quot;&gt;Tom Soderstrom&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04591">
<title>First Order Generative Adversarial Networks. (arXiv:1802.04591v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1802.04591</link>
<description rdf:parseType="Literal">&lt;p&gt;GANs excel at learning high dimensional distributions, but they can update
generator parameters in directions that do not correspond to the steepest
descent direction of the objective. Prominent examples of problematic update
directions include those used in both Goodfellow&apos;s original GAN and the
WGAN-GP. To formally describe an optimal update direction, we introduce a
theoretical framework which allows the derivation of requirements on both the
divergence and corresponding method for determining an update direction, with
these requirements guaranteeing unbiased mini-batch updates in the direction of
steepest descent. We propose a novel divergence which approximates the
Wasserstein distance while regularizing the critic&apos;s first order information.
Together with an accompanying update direction, this divergence fulfills the
requirements for unbiased steepest descent updates. We verify our method, the
First Order GAN, with image generation on CelebA, LSUN and CIFAR-10 and set a
new state of the art on the One Billion Word language generation task. Code to
reproduce experiments is available.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Seward_C/0/1/0/all/0/1&quot;&gt;Calvin Seward&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Unterthiner_T/0/1/0/all/0/1&quot;&gt;Thomas Unterthiner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bergmann_U/0/1/0/all/0/1&quot;&gt;Urs Bergmann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jetchev_N/0/1/0/all/0/1&quot;&gt;Nikolay Jetchev&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hochreiter_S/0/1/0/all/0/1&quot;&gt;Sepp Hochreiter&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.06969">
<title>Comparing Dynamics: Deep Neural Networks versus Glassy Systems. (arXiv:1803.06969v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1803.06969</link>
<description rdf:parseType="Literal">&lt;p&gt;We analyze numerically the training dynamics of deep neural networks (DNN) by
using methods developed in statistical physics of glassy systems. The two main
issues we address are (1) the complexity of the loss landscape and of the
dynamics within it, and (2) to what extent DNNs share similarities with glassy
systems. Our findings, obtained for different architectures and datasets,
suggest that during the training process the dynamics slows down because of an
increasingly large number of flat directions. At large times, when the loss is
approaching zero, the system diffuses at the bottom of the landscape. Despite
some similarities with the dynamics of mean-field glassy systems, in
particular, the absence of barrier crossing, we find distinctive dynamical
behaviors in the two cases, showing that the statistical properties of the
corresponding loss and energy landscapes are different. In contrast, when the
network is under-parametrized we observe a typical glassy behavior, thus
suggesting the existence of different phases depending on whether the network
is under-parametrized or over-parametrized.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Baity_Jesi_M/0/1/0/all/0/1&quot;&gt;M. Baity-Jesi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sagun_L/0/1/0/all/0/1&quot;&gt;L. Sagun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Geiger_M/0/1/0/all/0/1&quot;&gt;M. Geiger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Spigler_S/0/1/0/all/0/1&quot;&gt;S. Spigler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Arous_G/0/1/0/all/0/1&quot;&gt;G. Ben Arous&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Cammarota_C/0/1/0/all/0/1&quot;&gt;C. Cammarota&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+LeCun_Y/0/1/0/all/0/1&quot;&gt;Y. LeCun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wyart_M/0/1/0/all/0/1&quot;&gt;M. Wyart&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Biroli_G/0/1/0/all/0/1&quot;&gt;G. Biroli&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.11258">
<title>Toward Diverse Text Generation with Inverse Reinforcement Learning. (arXiv:1804.11258v3 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1804.11258</link>
<description rdf:parseType="Literal">&lt;p&gt;Text generation is a crucial task in NLP. Recently, several adversarial
generative models have been proposed to improve the exposure bias problem in
text generation. Though these models gain great success, they still suffer from
the problems of reward sparsity and mode collapse. In order to address these
two problems, in this paper, we employ inverse reinforcement learning (IRL) for
text generation. Specifically, the IRL framework learns a reward function on
training data, and then an optimal policy to maximum the expected total reward.
Similar to the adversarial models, the reward and policy function in IRL are
optimized alternately. Our method has two advantages: (1) the reward function
can produce more dense reward signals. (2) the generation policy, trained by
&quot;entropy regularized&quot; policy gradient, encourages to generate more diversified
texts. Experiment results demonstrate that our proposed method can generate
higher quality texts than the previous methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_Z/0/1/0/all/0/1&quot;&gt;Zhan Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1&quot;&gt;Xinchi Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qiu_X/0/1/0/all/0/1&quot;&gt;Xipeng Qiu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1&quot;&gt;Xuanjing Huang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09370">
<title>Towards Robust Training of Neural Networks by Regularizing Adversarial Gradients. (arXiv:1805.09370v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.09370</link>
<description rdf:parseType="Literal">&lt;p&gt;In recent years, neural networks have demonstrated outstanding effectiveness
in a large amount of applications.However, recent works have shown that neural
networks are susceptible to adversarial examples, indicating possible flaws
intrinsic to the network structures. To address this problem and improve the
robustness of neural networks, we investigate the fundamental mechanisms behind
adversarial examples and propose a novel robust training method via regulating
adversarial gradients. The regulation effectively squeezes the adversarial
gradients of neural networks and significantly increases the difficulty of
adversarial example generation.Without any adversarial example involved, the
robust training method could generate naturally robust networks, which are
near-immune to various types of adversarial examples. Experiments show the
naturally robust networks can achieve optimal accuracy against Fast Gradient
Sign Method (FGSM) and C\&amp;amp;W attacks on MNIST, Cifar10, and Google Speech
Command dataset. Moreover, our proposed method also provides neural networks
with consistent robustness against transferable attacks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_F/0/1/0/all/0/1&quot;&gt;Fuxun Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1&quot;&gt;Zirui Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yanzhi Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1&quot;&gt;Chenchen Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1&quot;&gt;Xiang Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.01768">
<title>Evidential Deep Learning to Quantify Classification Uncertainty. (arXiv:1806.01768v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1806.01768</link>
<description rdf:parseType="Literal">&lt;p&gt;Deterministic neural nets have been shown to learn effective predictors on a
wide range of machine learning problems. However, as the standard approach is
to train the network to minimize a prediction loss, the resultant model remains
ignorant to its prediction confidence. Orthogonally to Bayesian neural nets
that indirectly infer prediction uncertainty through weight uncertainties, we
propose explicit modeling of the same using the theory of subjective logic. By
placing a Dirichlet prior on the softmax output, we treat predictions of a
neural net as subjective opinions and learn the function that collects the
evidence leading to these opinions by a deterministic neural net from data. The
resultant predictor for a multi-class classification problem is another
Dirichlet distribution whose parameters are set by the continuous output of a
neural net. We provide a preliminary analysis on how the peculiarities of our
new loss function drive improved uncertainty estimation. We observe that our
method achieves unprecedented success on detection of out-of-sample queries and
endurance against adversarial perturbations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sensoy_M/0/1/0/all/0/1&quot;&gt;Murat Sensoy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kandemir_M/0/1/0/all/0/1&quot;&gt;Melih Kandemir&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kaplan_L/0/1/0/all/0/1&quot;&gt;Lance Kaplan&lt;/a&gt;</dc:creator>
</item></rdf:RDF>