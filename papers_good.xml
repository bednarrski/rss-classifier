<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Good papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Good Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-03-29T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.10837"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.10813"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.10953"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.10995"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.11070"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.11115"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.01691"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.05402"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.07517"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.10768"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.10799"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.10927"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.11008"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.09677"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1803.10837">
<title>Probabilistic Knowledge Transfer for Deep Representation Learning. (arXiv:1803.10837v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1803.10837</link>
<description rdf:parseType="Literal">&lt;p&gt;Knowledge Transfer (KT) techniques tackle the problem of transferring the
knowledge from a large and complex neural network into a smaller and faster
one. However, existing KT methods are tailored towards classification tasks and
they cannot be used efficiently for other representation learning tasks. In
this paper a novel knowledge transfer technique, that is capable of training a
student model that maintains the same amount of mutual information between the
learned representation and a set of (possible unknown) labels as the teacher
model, is proposed. Apart from outperforming existing KT techniques, the
proposed method allows for overcoming several limitations of existing methods
providing new insight into KT as well as novel KT applications, ranging from
knowledge transfer from handcrafted feature extractors to {cross-modal} KT from
the textual modality into the representation extracted from the visual modality
of the data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Passalis_N/0/1/0/all/0/1&quot;&gt;Nikolaos Passalis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tefas_A/0/1/0/all/0/1&quot;&gt;Anastasios Tefas&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.10813">
<title>Artificial Intelligence and Robotics. (arXiv:1803.10813v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1803.10813</link>
<description rdf:parseType="Literal">&lt;p&gt;The recent successes of AI have captured the wildest imagination of both the
scientific communities and the general public. Robotics and AI amplify human
potentials, increase productivity and are moving from simple reasoning towards
human-like cognitive abilities. Current AI technologies are used in a set area
of applications, ranging from healthcare, manufacturing, transport, energy, to
financial services, banking, advertising, management consulting and government
agencies. The global AI market is around 260 billion USD in 2016 and it is
estimated to exceed 3 trillion by 2024. To understand the impact of AI, it is
important to draw lessons from it&apos;s past successes and failures and this white
paper provides a comprehensive explanation of the evolution of AI, its current
status and future directions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Perez_J/0/1/0/all/0/1&quot;&gt;Javier Andreu Perez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deligianni_F/0/1/0/all/0/1&quot;&gt;Fani Deligianni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ravi_D/0/1/0/all/0/1&quot;&gt;Daniele Ravi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_G/0/1/0/all/0/1&quot;&gt;Guang-Zhong Yang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.10953">
<title>Weakly Aggregative Modal Logic: Characterization and Interpolation. (arXiv:1803.10953v1 [cs.LO])</title>
<link>http://arxiv.org/abs/1803.10953</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we study the model theoretical aspects of Weakly Aggregative
Modal Logic (WAL), which is a collection of disguised polyadic modal logics
with $n$-ary modalities whose arguments are all the same. We give a
van-Benthem-Rosen characterization theorem of WAL based on an intuitive notion
of bisimulation, and show that WAL has Craig Interpolation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Jixin Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yanjing Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.10995">
<title>Protection against Cloning for Deep Learning. (arXiv:1803.10995v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1803.10995</link>
<description rdf:parseType="Literal">&lt;p&gt;The susceptibility of deep learning to adversarial attack can be understood
in the framework of the Renormalisation Group (RG) and the vulnerability of a
specific network may be diagnosed provided the weights in each layer are known.
An adversary with access to the inputs and outputs could train a second network
to clone these weights and, having identified a weakness, use them to compute
the perturbation of the input data which exploits it. However, the RG framework
also provides a means to poison the outputs of the network imperceptibly,
without affecting their legitimate use, so as to prevent such cloning of its
weights and thereby foil the generation of adversarial data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kenway_R/0/1/0/all/0/1&quot;&gt;Richard Kenway&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.11070">
<title>Actor-Critic based Training Framework for Abstractive Summarization. (arXiv:1803.11070v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1803.11070</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a training framework for neural abstractive summarization based on
actor-critic approaches from reinforcement learning. In the traditional neural
network based methods, the objective is only to maximize the likelihood of the
predicted summaries, no other assessment constraints are considered, which may
generate low-quality summaries or even incorrect sentences. To alleviate this
problem, we employ an actor-critic framework to enhance the training procedure.
For the actor, we employ the typical attention based sequence-to-sequence
(seq2seq) framework as the policy network for summary generation. For the
critic, we combine the maximum likelihood estimator with a well designed global
summary quality estimator which is a neural network based binary classifier
aiming to make the generated summaries indistinguishable from the human-written
ones. Policy gradient method is used to conduct the parameter learning. An
alternating training strategy is proposed to conduct the joint training of the
actor and critic models. Extensive experiments on some benchmark datasets in
different languages show that our framework achieves improvements over the
state-of-the-art methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1&quot;&gt;Piji Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bing_L/0/1/0/all/0/1&quot;&gt;Lidong Bing&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lam_W/0/1/0/all/0/1&quot;&gt;Wai Lam&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.11115">
<title>Deep Reinforcement Learning for Traffic Light Control in Vehicular Networks. (arXiv:1803.11115v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1803.11115</link>
<description rdf:parseType="Literal">&lt;p&gt;Existing inefficient traffic light control causes numerous problems, such as
long delay and waste of energy. To improve efficiency, taking real-time traffic
information as an input and dynamically adjusting the traffic light duration
accordingly is a must. In terms of how to dynamically adjust traffic signals&apos;
duration, existing works either split the traffic signal into equal duration or
extract limited traffic information from the real data. In this paper, we study
how to decide the traffic signals&apos; duration based on the collected data from
different sensors and vehicular networks. We propose a deep reinforcement
learning model to control the traffic light. In the model, we quantify the
complex traffic scenario as states by collecting data and dividing the whole
intersection into small grids. The timing changes of a traffic light are the
actions, which are modeled as a high-dimension Markov decision process. The
reward is the cumulative waiting time difference between two cycles. To solve
the model, a convolutional neural network is employed to map the states to
rewards. The proposed model is composed of several components to improve the
performance, such as dueling network, target network, double Q-learning
network, and prioritized experience replay. We evaluate our model via
simulation in the Simulation of Urban MObility (SUMO) in a vehicular network,
and the simulation results show the efficiency of our model in controlling
traffic lights.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_X/0/1/0/all/0/1&quot;&gt;Xiaoyuan Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Du_X/0/1/0/all/0/1&quot;&gt;Xunsheng Du&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1&quot;&gt;Guiling Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Han_Z/0/1/0/all/0/1&quot;&gt;Zhu Han&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.01691">
<title>Context Embedding Networks. (arXiv:1710.01691v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1710.01691</link>
<description rdf:parseType="Literal">&lt;p&gt;Low dimensional embeddings that capture the main variations of interest in
collections of data are important for many applications. One way to construct
these embeddings is to acquire estimates of similarity from the crowd. However,
similarity is a multi-dimensional concept that varies from individual to
individual. Existing models for learning embeddings from the crowd typically
make simplifying assumptions such as all individuals estimate similarity using
the same criteria, the list of criteria is known in advance, or that the crowd
workers are not influenced by the data that they see. To overcome these
limitations we introduce Context Embedding Networks (CENs). In addition to
learning interpretable embeddings from images, CENs also model worker biases
for different attributes along with the visual context i.e. the visual
attributes highlighted by a set of images. Experiments on two noisy crowd
annotated datasets show that modeling both worker bias and visual context
results in more interpretable embeddings compared to existing approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_K/0/1/0/all/0/1&quot;&gt;Kun Ho Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aodha_O/0/1/0/all/0/1&quot;&gt;Oisin Mac Aodha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Perona_P/0/1/0/all/0/1&quot;&gt;Pietro Perona&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.05402">
<title>Imitation Learning with Concurrent Actions in 3D Games. (arXiv:1803.05402v3 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1803.05402</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work we describe a novel deep reinforcement learning neural network
architecture that allows multiple actions to be selected at every time-step.
Multi-action policies allows complex behaviors to be learnt that are otherwise
hard to achieve when using single action selection techniques. This work
describes an algorithm that uses both imitation learning (IL) and temporal
difference (TD) reinforcement learning (RL) to provide a 4x improvement in
training time and 2.5x improvement in performance over single action selection
TD RL. We demonstrate the capabilities of this network using a complex in-house
3D game. Mimicking the behavior of the expert teacher significantly improves
world state exploration and allows the agents vision system to be trained more
rapidly than TD RL alone. This initial training technique kick-starts TD
learning and the agent quickly learns to surpass the capabilities of the
expert.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Harmer_J/0/1/0/all/0/1&quot;&gt;Jack Harmer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gisslen_L/0/1/0/all/0/1&quot;&gt;Linus Gissl&amp;#xe9;n&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Holst_H/0/1/0/all/0/1&quot;&gt;Henrik Holst&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bergdahl_J/0/1/0/all/0/1&quot;&gt;Joakim Bergdahl&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Olsson_T/0/1/0/all/0/1&quot;&gt;Tom Olsson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sjoo_K/0/1/0/all/0/1&quot;&gt;Kristoffer Sj&amp;#xf6;&amp;#xf6;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nordin_M/0/1/0/all/0/1&quot;&gt;Magnus Nordin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.07517">
<title>Explanation Methods in Deep Learning: Users, Values, Concerns and Challenges. (arXiv:1803.07517v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1803.07517</link>
<description rdf:parseType="Literal">&lt;p&gt;Issues regarding explainable AI involve four components: users, laws &amp;amp;
regulations, explanations and algorithms. Together these components provide a
context in which explanation methods can be evaluated regarding their adequacy.
The goal of this chapter is to bridge the gap between expert users and lay
users. Different kinds of users are identified and their concerns revealed,
relevant statements from the General Data Protection Regulation are analyzed in
the context of Deep Neural Networks (DNNs), a taxonomy for the classification
of existing explanation methods is introduced, and finally, the various classes
of explanation methods are analyzed to verify if user concerns are justified.
Overall, it is clear that (visual) explanations can be given about various
aspects of the influence of the input on the output. However, it is noted that
explanation methods or interfaces for lay users are missing and we speculate
which criteria these methods / interfaces should satisfy. Finally it is noted
that two important concerns are difficult to address with explanation methods:
the concern about bias in datasets that leads to biased DNNs, as well as the
suspicion about unfair outcomes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ras_G/0/1/0/all/0/1&quot;&gt;Gabrielle Ras&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gerven_M/0/1/0/all/0/1&quot;&gt;Marcel van Gerven&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Haselager_P/0/1/0/all/0/1&quot;&gt;Pim Haselager&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.10768">
<title>Unreasonable Effectivness of Deep Learning. (arXiv:1803.10768v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1803.10768</link>
<description rdf:parseType="Literal">&lt;p&gt;We show how well known rules of back propagation arise from a weighted
combination of finite automata. By redefining a finite automata as a predictor
we combine the set of all $k$-state finite automata using a weighted majority
algorithm. This aggregated prediction algorithm can be simplified using
symmetry, and we prove the equivalence of an algorithm that does this. We
demonstrate that this algorithm is equivalent to a form of a back propagation
acting in a completely connected $k$-node neural network. Thus the use of the
weighted majority algorithm allows a bound on the general performance of deep
learning approaches to prediction via known results from online statistics. The
presented framework opens more detailed questions about network topology; it is
a bridge to the well studied techniques of semigroup theory and applying these
techniques to answer what specific network topologies are capable of
predicting. This informs both the design of artificial networks and the
exploration of neuroscience models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Macleod_F/0/1/0/all/0/1&quot;&gt;Finn Macleod&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.10799">
<title>Modeling Customer Engagement from Partial Observations. (arXiv:1803.10799v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1803.10799</link>
<description rdf:parseType="Literal">&lt;p&gt;It is of high interest for a company to identify customers expected to bring
the largest profit in the upcoming period. Knowing as much as possible about
each customer is crucial for such predictions. However, their demographic data,
preferences, and other information that might be useful for building loyalty
programs is often missing. Additionally, modeling relations among different
customers as a network can be beneficial for predictions at an individual
level, as similar customers tend to have similar purchasing patterns. We
address this problem by proposing a robust framework for structured regression
on deficient data in evolving networks with a supervised representation
learning based on neural features embedding. The new method is compared to
several unstructured and structured alternatives for predicting customer
behavior (e.g. purchasing frequency and customer ticket) on user networks
generated from customer databases of two companies from different industries.
The obtained results show $4\%$ to $130\%$ improvement in accuracy over
alternatives when all customer information is known. Additionally, the
robustness of our method is demonstrated when up to $80\%$ of demographic
information was missing where it was up to several folds more accurate as
compared to alternatives that are either ignoring cases with missing values or
learn their feature representation in an unsupervised manner.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stojanovic_J/0/1/0/all/0/1&quot;&gt;Jelena Stojanovic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gligorijevic_D/0/1/0/all/0/1&quot;&gt;Djordje Gligorijevic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Obradovic_Z/0/1/0/all/0/1&quot;&gt;Zoran Obradovic&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.10927">
<title>An LP-based hyperparameter optimization model for language modeling. (arXiv:1803.10927v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1803.10927</link>
<description rdf:parseType="Literal">&lt;p&gt;In order to find hyperparameters for a machine learning model, algorithms
such as grid search or random search are used over the space of possible values
of the models hyperparameters. These search algorithms opt the solution that
minimizes a specific cost function. In language models, perplexity is one of
the most popular cost functions. In this study, we propose a fractional
nonlinear programming model that finds the optimal perplexity value. The
special structure of the model allows us to approximate it by a linear
programming model that can be solved using the well-known simplex algorithm. To
the best of our knowledge, this is the first attempt to use optimization
techniques to find perplexity values in the language modeling literature. We
apply our model to find hyperparameters of a language model and compare it to
the grid search algorithm. Furthermore, we illustrating that it results in
lower perplexity values. We perform this experiment on a real-world dataset
from SwiftKey to validate our proposed approach.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rahnama_A/0/1/0/all/0/1&quot;&gt;Amir Hossein Akhavan Rahnama&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Toloo_M/0/1/0/all/0/1&quot;&gt;Mehdi Toloo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zaidenberg_N/0/1/0/all/0/1&quot;&gt;Nezer Jacob Zaidenberg&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.11008">
<title>On Hyperparameter Search in Cluster Ensembles. (arXiv:1803.11008v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1803.11008</link>
<description rdf:parseType="Literal">&lt;p&gt;Quality assessments of models in unsupervised learning and clustering
verification in particular have been a long-standing problem in the machine
learning research. The lack of robust and universally applicable cluster
validity scores often makes the algorithm selection and hyperparameter
evaluation a tough guess. In this paper, we show that cluster ensemble
aggregation techniques such as consensus clustering may be used to evaluate
clusterings and their hyperparameter configurations. We use normalized mutual
information to compare individual objects of a clustering ensemble to the
constructed consensus of the whole ensemble and show, that the resulting score
can serve as an overall quality measure for clustering problems. This method is
capable of highlighting the standout clustering and hyperparameter
configuration in the ensemble even in the case of a distorted consensus. We
apply this very general framework to various data sets and give possible
directions for future research.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Helfmann_L/0/1/0/all/0/1&quot;&gt;Luzie Helfmann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lindheim_J/0/1/0/all/0/1&quot;&gt;Johannes von Lindheim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mollenhauer_M/0/1/0/all/0/1&quot;&gt;Mattes Mollenhauer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Banisch_R/0/1/0/all/0/1&quot;&gt;Ralf Banisch&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.09677">
<title>Momentum and Stochastic Momentum for Stochastic Gradient, Newton, Proximal Point and Subspace Descent Methods. (arXiv:1712.09677v2 [math.OC] UPDATED)</title>
<link>http://arxiv.org/abs/1712.09677</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper we study several classes of stochastic optimization algorithms
enriched with heavy ball momentum. Among the methods studied are: stochastic
gradient descent, stochastic Newton, stochastic proximal point and stochastic
dual subspace ascent. This is the first time momentum variants of several of
these methods are studied. We choose to perform our analysis in a setting in
which all of the above methods are equivalent. We prove global nonassymptotic
linear convergence rates for all methods and various measures of success,
including primal function values, primal iterates (in L2 sense), and dual
function values. We also show that the primal iterates converge at an
accelerated linear rate in the L1 sense. This is the first time a linear rate
is shown for the stochastic heavy ball method (i.e., stochastic gradient
descent method with momentum). Under somewhat weaker conditions, we establish a
sublinear convergence rate for Cesaro averages of primal iterates. Moreover, we
propose a novel concept, which we call stochastic momentum, aimed at decreasing
the cost of performing the momentum step. We prove linear convergence of
several stochastic methods with stochastic momentum, and show that in some
sparse data regimes and for sufficiently small momentum parameters, these
methods enjoy better overall complexity than methods with deterministic
momentum. Finally, we perform extensive numerical testing on artificial and
real datasets, including data coming from average consensus problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Loizou_N/0/1/0/all/0/1&quot;&gt;Nicolas Loizou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Richtarik_P/0/1/0/all/0/1&quot;&gt;Peter Richt&amp;#xe1;rik&lt;/a&gt;</dc:creator>
</item></rdf:RDF>