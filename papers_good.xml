<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Good papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Good Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-06-21T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.07912"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.07915"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.07917"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.07941"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.08047"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.08099"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.08216"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1508.02521"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1605.05296"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.03963"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00730"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.07937"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.07955"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.08055"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.08065"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.08122"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.08156"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.08340"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.08354"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.09990"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.07840"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.07908"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.07963"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.07978"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.08028"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.08079"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.08212"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.08240"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.08267"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.08297"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.01973"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.01532"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.01845"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1806.07912">
<title>Resource-Efficient Neural Architect. (arXiv:1806.07912v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1806.07912</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural Architecture Search (NAS) is a laborious process. Prior work on
automated NAS targets mainly on improving accuracy, but lacks consideration of
computational resource use. We propose the Resource-Efficient Neural Architect
(RENA), an efficient resource-constrained NAS using reinforcement learning with
network embedding. RENA uses a policy network to process the network embeddings
to generate new configurations. We demonstrate RENA on image recognition and
keyword spotting (KWS) problems. RENA can find novel architectures that achieve
high performance even with tight resource constraints. For CIFAR10, it achieves
2.95% test error when compute intensity is greater than 100 FLOPs/byte, and
3.87% test error when model size is less than 3M parameters. For Google Speech
Commands Dataset, RENA achieves the state-of-the-art accuracy without resource
constraints, and it outperforms the optimized architectures with tight resource
constraints.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1&quot;&gt;Yanqi Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ebrahimi_S/0/1/0/all/0/1&quot;&gt;Siavash Ebrahimi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Arik_S/0/1/0/all/0/1&quot;&gt;Sercan &amp;#xd6;. Ar&amp;#x131;k&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1&quot;&gt;Haonan Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1&quot;&gt;Hairong Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Diamos_G/0/1/0/all/0/1&quot;&gt;Greg Diamos&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.07915">
<title>An Efficient Scheduling for Security Constraint Unit Commitment Problem Via Modified Genetic Algorithm Based on Multicellular Organisms Mechanisms. (arXiv:1806.07915v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1806.07915</link>
<description rdf:parseType="Literal">&lt;p&gt;Security Constraint Unit commitment (SCUC) is one of the significant
challenges in operation of power grids which tries to regulate the status of
the generation units (ON or OFF) and providing an efficient power dispatch
within the grid. While many researches tried to address the SCUC challenges, it
is a mixed-integer optimization problem that is difficult to reach global
optimum. In this study, a novel modified genetic algorithm based on
Multicellular Organisms Mechanisms (GAMOM) is developed to find an optimal
solution for SCUC problem. The presentation of the GAMOM on the SCUC contain
two sections, the GA and modified GAMOM sections. Hence, a set of population is
considered for the SCUC problem. Next, an iterative process is used to obtain
the greatest SCUC population. Indeed, the best population is selected so that
the total operating cost is minimized and also all system and units constraints
are satisfied. The effectiveness of the proposed GAMOM algorithm is determined
by the simulation studies which demonstrate the convergence speed. Finally, the
proposed technique is compared with well-known existing approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yazdandoost_A/0/1/0/all/0/1&quot;&gt;Ali Yazdandoost&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khazaei_P/0/1/0/all/0/1&quot;&gt;Peyman Khazaei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kamali_R/0/1/0/all/0/1&quot;&gt;Rahim Kamali&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saadatian_S/0/1/0/all/0/1&quot;&gt;Salar Saadatian&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.07917">
<title>Meta Learning by the Baldwin Effect. (arXiv:1806.07917v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1806.07917</link>
<description rdf:parseType="Literal">&lt;p&gt;The scope of the Baldwin effect was recently called into question by two
papers that closely examined the seminal work of Hinton and Nowlan. To this
date there has been no demonstration of its necessity in empirically
challenging tasks. Here we show that the Baldwin effect is capable of evolving
few-shot supervised and reinforcement learning mechanisms, by shaping the
hyperparameters and the initial parameters of deep learning algorithms.
Furthermore it can genetically accommodate strong learning biases on the same
set of problems as a recent machine learning algorithm called MAML &quot;Model
Agnostic Meta-Learning&quot; which uses second-order gradients instead of evolution
to learn a set of reference parameters (initial weights) that can allow rapid
adaptation to tasks sampled from a distribution. Whilst in simple cases MAML is
more data efficient than the Baldwin effect, the Baldwin effect is more general
in that it does not require gradients to be backpropagated to the reference
parameters or hyperparameters, and permits effectively any number of gradient
updates in the inner loop. The Baldwin effect learns strong learning dependent
biases, rather than purely genetically accommodating fixed behaviours in a
learning independent manner.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fernando_C/0/1/0/all/0/1&quot;&gt;Chrisantha Thomas Fernando&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sygnowski_J/0/1/0/all/0/1&quot;&gt;Jakub Sygnowski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Osindero_S/0/1/0/all/0/1&quot;&gt;Simon Osindero&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jane Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schaul_T/0/1/0/all/0/1&quot;&gt;Tom Schaul&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Teplyashin_D/0/1/0/all/0/1&quot;&gt;Denis Teplyashin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sprechmann_P/0/1/0/all/0/1&quot;&gt;Pablo Sprechmann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pritzel_A/0/1/0/all/0/1&quot;&gt;Alexander Pritzel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rusu_A/0/1/0/all/0/1&quot;&gt;Andrei A. Rusu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.07941">
<title>Conditions for Major Transitions in Biological and Cultural Evolution. (arXiv:1806.07941v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1806.07941</link>
<description rdf:parseType="Literal">&lt;p&gt;Evolution by natural selection can be seen an algorithm for generating
creative solutions to difficult problems. More precisely, evolution by natural
selection is a class of algorithms that share a set of properties. The question
we address here is, what are the conditions that define this class of
algorithms? There is a standard answer to this question: Briefly, the
conditions are variation, heredity, and selection. We agree that these three
conditions are sufficient for a limited type of evolution, but they are not
sufficient for open-ended evolution. By open-ended evolution, we mean evolution
that generates a continuous stream of creative solutions, without stagnating.
We propose a set of conditions for open-ended evolution. The new conditions
build on the standard conditions by adding fission, fusion, and cooperation. We
test the proposed conditions by applying them to major transitions in the
evolution of life and culture. We find that the proposed conditions are able to
account for the major transitions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Turney_P/0/1/0/all/0/1&quot;&gt;Peter D. Turney&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.08047">
<title>Flexible Neural Representation for Physics Prediction. (arXiv:1806.08047v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1806.08047</link>
<description rdf:parseType="Literal">&lt;p&gt;Humans have a remarkable capacity to understand the physical dynamics of
objects in their environment, flexibly capturing complex structures and
interactions at multiple levels of detail. Inspired by this ability, we propose
a hierarchical particle-based object representation that covers a wide variety
of types of three-dimensional objects, including both arbitrary rigid
geometrical shapes and deformable materials. We then describe the Hierarchical
Relation Network (HRN), an end-to-end differentiable neural network based on
hierarchical graph convolution, that learns to predict physical dynamics in
this representation. Compared to other neural network baselines, the HRN
accurately handles complex collisions and nonrigid deformations, generating
plausible dynamics predictions at long time scales in novel settings, and
scaling to large scene configurations. These results demonstrate an
architecture with the potential to form the basis of next-generation physics
predictors for use in computer vision, robotics, and quantitative cognitive
science.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mrowca_D/0/1/0/all/0/1&quot;&gt;Damian Mrowca&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhuang_C/0/1/0/all/0/1&quot;&gt;Chengxu Zhuang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_E/0/1/0/all/0/1&quot;&gt;Elias Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Haber_N/0/1/0/all/0/1&quot;&gt;Nick Haber&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fei_Fei_L/0/1/0/all/0/1&quot;&gt;Li Fei-Fei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tenenbaum_J/0/1/0/all/0/1&quot;&gt;Joshua B. Tenenbaum&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yamins_D/0/1/0/all/0/1&quot;&gt;Daniel L. K. Yamins&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.08099">
<title>Lamarckian Evolution of Convolutional Neural Networks. (arXiv:1806.08099v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1806.08099</link>
<description rdf:parseType="Literal">&lt;p&gt;Convolutional neural networks belong to the most successul image classifiers,
but the adaptation of their network architecture to a particular problem is
computationally expensive. We show that an evolutionary algorithm saves
training time during the network architecture optimization, if learned network
weights are inherited over generations by Lamarckian evolution. Experiments on
typical image datasets show similar or significantly better test accuracies and
improved convergence speeds compared to two different baselines without weight
inheritance. On CIFAR-10 and CIFAR-100 a 75 % improvement in data efficiency is
observed.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Prellberg_J/0/1/0/all/0/1&quot;&gt;Jonas Prellberg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kramer_O/0/1/0/all/0/1&quot;&gt;Oliver Kramer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.08216">
<title>Autoencoders for Multi-Label Prostate MR Segmentation. (arXiv:1806.08216v1 [eess.IV])</title>
<link>http://arxiv.org/abs/1806.08216</link>
<description rdf:parseType="Literal">&lt;p&gt;Organ image segmentation can be improved by implementing prior knowledge
about the anatomy. One way of doing this is by training an autoencoder to learn
a lowdimensional representation of the segmentation. In this paper, this is
applied in multi-label prostate MR segmentation, with some positive results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Gelder_A/0/1/0/all/0/1&quot;&gt;Ard de Gelder&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Huisman_H/0/1/0/all/0/1&quot;&gt;Henkjan Huisman&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1508.02521">
<title>Topology Control of wireless sensor network using Quantum Inspired Genetic algorithm. (arXiv:1508.02521v3 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1508.02521</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work, an evolving Linked Quantum register has been introduced, which
are group vector of binary pair of genes, which in its local proximity
represent those nodes that will have high connectivity and keep the energy
consumption at low, and which are taken into account for topology control. The
register works in higher dimension. Here order-2 Quantum inspired genetic
algorithm has been used and also higher order can be used to achieve greater
versatility in topology control of nodes. Numerical result has been obtained,
analysis is done as how the result has previously been obtained with Quantum
genetic algorithm and results are compared too. For future work, factor is
hinted which would exploit the algorithm to work in more computational
intensive problem.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ullah_S/0/1/0/all/0/1&quot;&gt;Sajid Ullah&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wahid_M/0/1/0/all/0/1&quot;&gt;Mussarat Wahid&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1605.05296">
<title>Dataflow matrix machines as programmable, dynamically expandable, self-referential generalized recurrent neural networks. (arXiv:1605.05296v2 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1605.05296</link>
<description rdf:parseType="Literal">&lt;p&gt;Dataflow matrix machines are a powerful generalization of recurrent neural
networks. They work with multiple types of linear streams and multiple types of
neurons, including higher-order neurons which dynamically update the matrix
describing weights and topology of the network in question while the network is
running. It seems that the power of dataflow matrix machines is sufficient for
them to be a convenient general purpose programming platform. This paper
explores a number of useful programming idioms and constructions arising in
this context.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bukatin_M/0/1/0/all/0/1&quot;&gt;Michael Bukatin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Matthews_S/0/1/0/all/0/1&quot;&gt;Steve Matthews&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Radul_A/0/1/0/all/0/1&quot;&gt;Andrey Radul&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.03963">
<title>Monotone Learning with Rectified Wire Networks. (arXiv:1805.03963v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.03963</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce a new neural network model, together with a tractable and
monotone online learning algorithm. Our model describes feed-forward networks
for classification, with one output node for each class. The only nonlinear
operation is rectification using a ReLU function with a bias. However, there is
a rectifier on every edge rather than at the nodes of the network. There are
also weights, but these are positive, static, and associated with the nodes.
Our &quot;rectified wire&quot; networks are able to represent arbitrary Boolean
functions. Only the bias parameters, on the edges of the network, are learned.
Another departure in our approach, from standard neural networks, is that the
loss function is replaced by a constraint. This constraint is simply that the
value of the output node associated with the correct class should be zero. Our
model has the property that the exact norm-minimizing parameter update,
required to correctly classify a training item, is the solution to a quadratic
program that can be computed with a few passes through the network. We
demonstrate a training algorithm using this update, called sequential
deactivation (SDA), on MNIST and some synthetic datasets. Upon adopting a
natural choice for the nodal weights, SDA has no hyperparameters other than
those describing the network structure. Our experiments explore behavior with
respect to network size and depth in a family of sparse expander networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Elser_V/0/1/0/all/0/1&quot;&gt;Veit Elser&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schmidt_D/0/1/0/all/0/1&quot;&gt;Dan Schmidt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yedidia_J/0/1/0/all/0/1&quot;&gt;Jonathan Yedidia&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00730">
<title>Minnorm training: an algorithm for training over-parameterized deep neural networks. (arXiv:1806.00730v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1806.00730</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work, we propose a new training method for finding minimum weight
norm solutions in over-parameterized neural networks (NNs). This method seeks
to improve training speed and generalization performance by framing NN training
as a constrained optimization problem wherein the sum of the norm of the
weights in each layer of the network is minimized, under the constraint of
exactly fitting training data. It draws inspiration from support vector
machines (SVMs), which are able to generalize well, despite often having an
infinite number of free parameters in their primal form, and from recent
theoretical generalization bounds on NNs which suggest that lower norm
solutions generalize better. To solve this constrained optimization problem,
our method employs Lagrange multipliers that act as integrators of error over
training and identify `support vector&apos;-like examples. The method can be
implemented as a wrapper around gradient based methods and uses standard
back-propagation of gradients from the NN for both regression and
classification versions of the algorithm. We provide theoretical justifications
for the effectiveness of this algorithm in comparison to early stopping and
$L_2$-regularization using simple, analytically tractable settings. In
particular, we show faster convergence to the max-margin hyperplane in a
shallow network (compared to vanilla gradient descent); faster convergence to
the minimum-norm solution in a linear chain (compared to $L_2$-regularization);
and initialization-independent generalization performance in a deep linear
network. Finally, using the MNIST dataset, we demonstrate that this algorithm
can boost test accuracy and identify difficult examples in real-world datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bansal_Y/0/1/0/all/0/1&quot;&gt;Yamini Bansal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Advani_M/0/1/0/all/0/1&quot;&gt;Madhu Advani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Cox_D/0/1/0/all/0/1&quot;&gt;David D Cox&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Saxe_A/0/1/0/all/0/1&quot;&gt;Andrew M Saxe&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.07937">
<title>A Dissection of Overfitting and Generalization in Continuous Reinforcement Learning. (arXiv:1806.07937v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.07937</link>
<description rdf:parseType="Literal">&lt;p&gt;The risks and perils of overfitting in machine learning are well known.
However most of the treatment of this, including diagnostic tools and remedies,
was developed for the supervised learning case. In this work, we aim to offer
new perspectives on the characterization and prevention of overfitting in deep
Reinforcement Learning (RL) methods, with a particular focus on continuous
domains. We examine several aspects, such as how to define and diagnose
overfitting in MDPs, and how to reduce risks by injecting sufficient training
diversity. This work complements recent findings on the brittleness of deep RL
methods and offers practical observations for RL researchers and practitioners.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_A/0/1/0/all/0/1&quot;&gt;Amy Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ballas_N/0/1/0/all/0/1&quot;&gt;Nicolas Ballas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pineau_J/0/1/0/all/0/1&quot;&gt;Joelle Pineau&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.07955">
<title>Growing Better Graphs With Latent-Variable Probabilistic Graph Grammars. (arXiv:1806.07955v1 [cs.SI])</title>
<link>http://arxiv.org/abs/1806.07955</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent work in graph models has found that probabilistic hyperedge
replacement grammars (HRGs) can be extracted from graphs and used to generate
new random graphs with graph properties and substructures close to the
original. In this paper, we show how to add latent variables to the model,
trained using Expectation-Maximization, to generate still better graphs, that
is, ones that generalize better to the test data. We evaluate the new method by
separating training and test graphs, building the model on the former and
measuring the likelihood of the latter, as a more stringent test of how well
the model can generalize to new graphs. On this metric, we find that our
latent-variable HRGs consistently outperform several existing graph models and
provide interesting insights into the building blocks of real world networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;Xinyi Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aguinaga_S/0/1/0/all/0/1&quot;&gt;Salvador Aguinaga&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Weninger_T/0/1/0/all/0/1&quot;&gt;Tim Weninger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chiang_D/0/1/0/all/0/1&quot;&gt;David Chiang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.08055">
<title>Towards a Grounded Dialog Model for Explainable Artificial Intelligence. (arXiv:1806.08055v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1806.08055</link>
<description rdf:parseType="Literal">&lt;p&gt;To generate trust with their users, Explainable Artificial Intelligence (XAI)
systems need to include an explanation model that can communicate the internal
decisions, behaviours and actions to the interacting humans. Successful
explanation involves both cognitive and social processes. In this paper we
focus on the challenge of meaningful interaction between an explainer and an
explainee and investigate the structural aspects of an explanation in order to
propose a human explanation dialog model. We follow a bottom-up approach to
derive the model by analysing transcripts of 398 different explanation dialog
types. We use grounded theory to code and identify key components of which an
explanation dialog consists. We carry out further analysis to identify the
relationships between components and sequences and cycles that occur in a
dialog. We present a generalized state model obtained by the analysis and
compare it with an existing conceptual dialog model of explanation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Madumal_P/0/1/0/all/0/1&quot;&gt;Prashan Madumal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Miller_T/0/1/0/all/0/1&quot;&gt;Tim Miller&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vetere_F/0/1/0/all/0/1&quot;&gt;Frank Vetere&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sonenberg_L/0/1/0/all/0/1&quot;&gt;Liz Sonenberg&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.08065">
<title>Learning Cognitive Models using Neural Networks. (arXiv:1806.08065v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.08065</link>
<description rdf:parseType="Literal">&lt;p&gt;A cognitive model of human learning provides information about skills a
learner must acquire to perform accurately in a task domain. Cognitive models
of learning are not only of scientific interest, but are also valuable in
adaptive online tutoring systems. A more accurate model yields more effective
tutoring through better instructional decisions. Prior methods of automated
cognitive model discovery have typically focused on well-structured domains,
relied on student performance data or involved substantial human knowledge
engineering. In this paper, we propose Cognitive Representation Learner
(CogRL), a novel framework to learn accurate cognitive models in ill-structured
domains with no data and little to no human knowledge engineering. Our
contribution is two-fold: firstly, we show that representations learnt using
CogRL can be used for accurate automatic cognitive model discovery without
using any student performance data in several ill-structured domains: Rumble
Blocks, Chinese Character, and Article Selection. This is especially effective
and useful in domains where an accurate human-authored cognitive model is
unavailable or authoring a cognitive model is difficult. Secondly, for domains
where a cognitive model is available, we show that representations learned
through CogRL can be used to get accurate estimates of skill difficulty and
learning rate parameters without using any student performance data. These
estimates are shown to highly correlate with estimates using student
performance data on an Article Selection dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chaplot_D/0/1/0/all/0/1&quot;&gt;Devendra Singh Chaplot&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+MacLellan_C/0/1/0/all/0/1&quot;&gt;Christopher MacLellan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Salakhutdinov_R/0/1/0/all/0/1&quot;&gt;Ruslan Salakhutdinov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koedinger_K/0/1/0/all/0/1&quot;&gt;Kenneth Koedinger&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.08122">
<title>A New Approach for Resource Scheduling with Deep Reinforcement Learning. (arXiv:1806.08122v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1806.08122</link>
<description rdf:parseType="Literal">&lt;p&gt;With the rapid development of deep learning, deep reinforcement learning
(DRL) began to appear in the field of resource scheduling in recent years.
Based on the previous research on DRL in the literature, we introduce online
resource scheduling algorithm DeepRM2 and the offline resource scheduling
algorithm DeepRM_Off. Compared with the state-of-the-art DRL algorithm DeepRM
and heuristic algorithms, our proposed algorithms have faster convergence speed
and better scheduling efficiency with regarding to average slowdown time, job
completion time and rewards.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ye_Y/0/1/0/all/0/1&quot;&gt;Yufei Ye&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1&quot;&gt;Xiaoqin Ren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jin Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_L/0/1/0/all/0/1&quot;&gt;Lingxiao Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_W/0/1/0/all/0/1&quot;&gt;Wenxia Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1&quot;&gt;Wenqiang Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tian_W/0/1/0/all/0/1&quot;&gt;Wenhong Tian&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.08156">
<title>Identifiability of Gaussian Structural Equation Models with Dependent Errors Having Equal Variances. (arXiv:1806.08156v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.08156</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we prove that some Gaussian structural equation models with
dependent errors having equal variances are identifiable from their
corresponding Gaussian distributions. Specifically, we prove identifiability
for the Gaussian structural equation models that can be represented as
Andersson-Madigan-Perlman chain graphs (Andersson et al., 2001). These chain
graphs were originally developed to represent independence models. However,
they are also suitable for representing causal models with additive noise
(Pe\~{n}a, 2016. Our result implies then that these causal models can be
identified from observational data alone. Our result generalizes the result by
Peters and B\&quot;{u}hlmann (2014), who considered independent errors having equal
variances. The suitability of the equal error variances assumption should be
assessed on a per domain basis.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pena_J/0/1/0/all/0/1&quot;&gt;Jose M. Pe&amp;#xf1;a&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.08340">
<title>Interpretable Discovery in Large Image Data Sets. (arXiv:1806.08340v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.08340</link>
<description rdf:parseType="Literal">&lt;p&gt;Automated detection of new, interesting, unusual, or anomalous images within
large data sets has great value for applications from surveillance (e.g.,
airport security) to science (observations that don&apos;t fit a given theory can
lead to new discoveries). Many image data analysis systems are turning to
convolutional neural networks (CNNs) to represent image content due to their
success in achieving high classification accuracy rates. However, CNN
representations are notoriously difficult for humans to interpret. We describe
a new strategy that combines novelty detection with CNN image features to
achieve rapid discovery with interpretable explanations of novel image content.
We applied this technique to familiar images from ImageNet as well as to a
scientific image collection from planetary science.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wagstaff_K/0/1/0/all/0/1&quot;&gt;Kiri L. Wagstaff&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1&quot;&gt;Jake Lee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.08354">
<title>Learning Instance Segmentation by Interaction. (arXiv:1806.08354v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1806.08354</link>
<description rdf:parseType="Literal">&lt;p&gt;We present an approach for building an active agent that learns to segment
its visual observations into individual objects by interacting with its
environment in a completely self-supervised manner. The agent uses its current
segmentation model to infer pixels that constitute objects and refines the
segmentation model by interacting with these pixels. The model learned from
over 50K interactions generalizes to novel objects and backgrounds. To deal
with noisy training signal for segmenting objects obtained by self-supervised
interactions, we propose robust set loss. A dataset of robot&apos;s interactions
along-with a few human labeled examples is provided as a benchmark for future
research. We test the utility of the learned segmentation model by providing
results on a downstream vision-based control task of rearranging multiple
objects into target configurations from visual inputs alone. Videos, code, and
robotic interaction dataset are available at
https://pathak22.github.io/seg-by-interaction/
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pathak_D/0/1/0/all/0/1&quot;&gt;Deepak Pathak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shentu_Y/0/1/0/all/0/1&quot;&gt;Yide Shentu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1&quot;&gt;Dian Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Agrawal_P/0/1/0/all/0/1&quot;&gt;Pulkit Agrawal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Darrell_T/0/1/0/all/0/1&quot;&gt;Trevor Darrell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1&quot;&gt;Sergey Levine&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Malik_J/0/1/0/all/0/1&quot;&gt;Jitendra Malik&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.09990">
<title>Identification of Strong Edges in AMP Chain Graphs. (arXiv:1711.09990v2 [math.CO] UPDATED)</title>
<link>http://arxiv.org/abs/1711.09990</link>
<description rdf:parseType="Literal">&lt;p&gt;The essential graph is a distinguished member of a Markov equivalence class
of AMP chain graphs. However, the directed edges in the essential graph are not
necessarily strong or invariant, i.e. they may not be shared by every member of
the equivalence class. Likewise for the undirected edges. In this paper, we
develop a procedure for identifying which edges in an essential graph are
strong. We also show how this makes it possible to bound some causal effects
when the true chain graph is unknown.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Pena_J/0/1/0/all/0/1&quot;&gt;Jose M. Pe&amp;#xf1;a&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.07840">
<title>Edge Intelligence: On-Demand Deep Learning Model Co-Inference with Device-Edge Synergy. (arXiv:1806.07840v2 [cs.DC] UPDATED)</title>
<link>http://arxiv.org/abs/1806.07840</link>
<description rdf:parseType="Literal">&lt;p&gt;As the backbone technology of machine learning, deep neural networks (DNNs)
have have quickly ascended to the spotlight. Running DNNs on
resource-constrained mobile devices is, however, by no means trivial, since it
incurs high performance and energy overhead. While offloading DNNs to the cloud
for execution suffers unpredictable performance, due to the uncontrolled long
wide-area network latency. To address these challenges, in this paper, we
propose Edgent, a collaborative and on-demand DNN co-inference framework with
device-edge synergy. Edgent pursues two design knobs: (1) DNN partitioning that
adaptively partitions DNN computation between device and edge, in order to
leverage hybrid computation resources in proximity for real-time DNN inference.
(2) DNN right-sizing that accelerates DNN inference through early-exit at a
proper intermediate DNN layer to further reduce the computation latency. The
prototype implementation and extensive evaluations based on Raspberry Pi
demonstrate Edgent&apos;s effectiveness in enabling on-demand low-latency edge
intelligence.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_E/0/1/0/all/0/1&quot;&gt;En Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1&quot;&gt;Zhi Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1&quot;&gt;Xu Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.07908">
<title>Como funciona o Deep Learning. (arXiv:1806.07908v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.07908</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep Learning methods are currently the state-of-the-art in many problems
which can be tackled via machine learning, in particular classification
problems. However there is still lack of understanding on how those methods
work, why they work and what are the limitations involved in using them. In
this chapter we will describe in detail the transition from shallow to deep
networks, include examples of code on how to implement them, as well as the
main issues one faces when training a deep network. Afterwards, we introduce
some theoretical background behind the use of deep models, and discuss their
limitations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ponti_M/0/1/0/all/0/1&quot;&gt;Moacir Antonelli Ponti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Costa_G/0/1/0/all/0/1&quot;&gt;Gabriel B. Paranhos da Costa&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.07963">
<title>Latent heterogeneous multilayer community detection. (arXiv:1806.07963v1 [cs.SI])</title>
<link>http://arxiv.org/abs/1806.07963</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a method for simultaneously detecting shared and unshared
communities in heterogeneous multilayer weighted and undirected networks. The
multilayer network is assumed to follow a generative probabilistic model that
takes into account the similarities and dissimilarities between the
communities. We make use of a variational Bayes approach for jointly inferring
the shared and unshared hidden communities from multilayer network
observations. We show the robustness of our approach compared to state-of-the
art algorithms in detecting disparate (shared and private) communities on
synthetic data as well as on real genome-wide fibroblast proliferation dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ali_H/0/1/0/all/0/1&quot;&gt;Hafiz Tiomoko Ali&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1&quot;&gt;Sijia Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yilmaz_Y/0/1/0/all/0/1&quot;&gt;Yasin Yilmaz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hero_A/0/1/0/all/0/1&quot;&gt;Alfred Hero&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Couillet_R/0/1/0/all/0/1&quot;&gt;Romain Couillet&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rajapakse_I/0/1/0/all/0/1&quot;&gt;Indika Rajapakse&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.07978">
<title>The Corpus Replication Task. (arXiv:1806.07978v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.07978</link>
<description rdf:parseType="Literal">&lt;p&gt;In the field of Natural Language Processing (NLP), we revisit the well-known
word embedding algorithm word2vec. Word embeddings identify words by vectors
such that the words&apos; distributional similarity is captured. Unexpectedly,
besides semantic similarity even relational similarity has been shown to be
captured in word embeddings generated by word2vec, whence two questions arise.
Firstly, which kind of relations are representable in continuous space and
secondly, how are relations built. In order to tackle these questions we
propose a bottom-up point of view. We call generating input text for which
word2vec outputs target relations solving the Corpus Replication Task. Deeming
generalizations of this approach to any set of relations possible, we expect
solving of the Corpus Replication Task to provide partial answers to the
questions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Eichinger_T/0/1/0/all/0/1&quot;&gt;Tobias Eichinger&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.08028">
<title>Gradient Adversarial Training of Neural Networks. (arXiv:1806.08028v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.08028</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose gradient adversarial training, an auxiliary deep learning
framework applicable to different machine learning problems. In gradient
adversarial training, we leverage a prior belief that in many contexts,
simultaneous gradient updates should be statistically indistinguishable from
each other. We enforce this consistency using an auxiliary network that
classifies the origin of the gradient tensor, and the main network serves as an
adversary to the auxiliary network in addition to performing standard
task-based training. We demonstrate gradient adversarial training for three
different scenarios: (1) as a defense to adversarial examples we classify
gradient tensors and tune them to be agnostic to the class of their
corresponding example, (2) for knowledge distillation, we do binary
classification of gradient tensors derived from the student or teacher network
and tune the student gradient tensor to mimic the teacher&apos;s gradient tensor;
and (3) for multi-task learning we classify the gradient tensors derived from
different task loss functions and tune them to be statistically
indistinguishable. For each of the three scenarios we show the potential of
gradient adversarial training procedure. Specifically, gradient adversarial
training increases the robustness of a network to adversarial attacks, is able
to better distill the knowledge from a teacher network to a student network
compared to soft targets, and boosts multi-task learning by aligning the
gradient tensors derived from the task specific loss functions. Overall, our
experiments demonstrate that gradient tensors contain latent information about
whatever tasks are being trained, and can support diverse machine learning
problems when intelligently guided through adversarialization using a auxiliary
network.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sinha_A/0/1/0/all/0/1&quot;&gt;Ayan Sinha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1&quot;&gt;Zhao Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Badrinarayanan_V/0/1/0/all/0/1&quot;&gt;Vijay Badrinarayanan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rabinovich_A/0/1/0/all/0/1&quot;&gt;Andrew Rabinovich&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.08079">
<title>GrCAN: Gradient Boost Convolutional Autoencoder with Neural Decision Forest. (arXiv:1806.08079v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.08079</link>
<description rdf:parseType="Literal">&lt;p&gt;Random forest and deep neural network are two schools of effective
classification methods in machine learning. While the random forest is robust
irrespective of the data domain, the deep neural network has advantages in
handling high dimensional data. In view that a differentiable neural decision
forest can be added to the neural network to fully exploit the benefits of both
models, in our work, we further combine convolutional autoencoder with neural
decision forest, where autoencoder has its advantages in finding the hidden
representations of the input data. We develop a gradient boost module and embed
it into the proposed convolutional autoencoder with neural decision forest to
improve the performance. The idea of gradient boost is to learn and use the
residual in the prediction. In addition, we design a structure to learn the
parameters of the neural decision forest and gradient boost module at
contiguous steps. The extensive experiments on several public datasets
demonstrate that our proposed model achieves good efficiency and prediction
performance compared with a series of baseline methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dong_M/0/1/0/all/0/1&quot;&gt;Manqing Dong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yao_L/0/1/0/all/0/1&quot;&gt;Lina Yao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;Xianzhi Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Benatallah_B/0/1/0/all/0/1&quot;&gt;Boualem Benatallah&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1&quot;&gt;Shuai Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.08212">
<title>A Review of Network Inference Techniques for Neural Activation Time Series. (arXiv:1806.08212v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.08212</link>
<description rdf:parseType="Literal">&lt;p&gt;Studying neural connectivity is considered one of the most promising and
challenging areas of modern neuroscience. The underpinnings of cognition are
hidden in the way neurons interact with each other. However, our experimental
methods of studying real neural connections at a microscopic level are still
arduous and costly. An efficient alternative is to infer connectivity based on
the neuronal activations using computational methods. A reliable method for
network inference, would not only facilitate research of neural circuits
without the need of laborious experiments but also reveal insights on the
underlying mechanisms of the brain. In this work, we perform a review of
methods for neural circuit inference given the activation time series of the
neural population. Approaching it from machine learning perspective, we divide
the methodologies into unsupervised and supervised learning. The methods are
based on correlation metrics, probabilistic point processes, and neural
networks. Furthermore, we add a data mining methodology inspired by influence
estimation in social networks as a new supervised learning approach. For
comparison, we use the small version of the Chalearn Connectomics competition,
that is accompanied with ground truth connections between neurons. The
experiments indicate that unsupervised learning methods perform better,
however, supervised methods could surpass them given enough data and resources.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Panagopoulos_G/0/1/0/all/0/1&quot;&gt;George Panagopoulos&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.08240">
<title>InfoCatVAE: Representation Learning with Categorical Variational Autoencoders. (arXiv:1806.08240v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.08240</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper describes InfoCatVAE, an extension of the variational autoencoder
that enables unsupervised disentangled representation learning. InfoCatVAE uses
multimodal distributions for the prior and the inference network and then
maximizes the evidence lower bound objective (ELBO). We connect the new ELBO
derived for our model with a natural soft clustering objective which explains
the robustness of our approach. We then adapt the InfoGANs method to our
setting in order to maximize the mutual information between the categorical
code and the generated inputs and obtain an improved model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pineau_E/0/1/0/all/0/1&quot;&gt;Edouard Pineau&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lelarge_M/0/1/0/all/0/1&quot;&gt;Marc Lelarge&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.08267">
<title>Gated Complex Recurrent Neural Networks. (arXiv:1806.08267v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.08267</link>
<description rdf:parseType="Literal">&lt;p&gt;Complex numbers have long been favoured for digital signal processing, yet
complex representations rarely appear in deep learning architectures. RNNs,
widely used to process time series and sequence information, could greatly
benefit from complex representations. We present a novel complex gate recurrent
cell. When used together with norm-preserving state transition matrices, our
complex gated RNN exhibits excellent stability and convergence properties. We
demonstrate competitive performance of our complex gated RNN on the synthetic
memory and adding task, as well as on the real-world task of human motion
prediction.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wolter_M/0/1/0/all/0/1&quot;&gt;Moritz Wolter&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yao_A/0/1/0/all/0/1&quot;&gt;Angela Yao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.08297">
<title>Learning Graph Weighted Models on Pictures. (arXiv:1806.08297v1 [cs.FL])</title>
<link>http://arxiv.org/abs/1806.08297</link>
<description rdf:parseType="Literal">&lt;p&gt;Graph Weighted Models (GWMs) have recently been proposed as a natural
generalization of weighted automata over strings and trees to arbitrary
families of labeled graphs (and hypergraphs). A GWM generically associates a
labeled graph with a tensor network and computes a value by successive
contractions directed by its edges. In this paper, we consider the problem of
learning GWMs defined over the graph family of pictures (or 2-dimensional
words). As a proof of concept, we consider regression and classification tasks
over the simple Bars &amp;amp; Stripes and Shifting Bits picture languages and provide
an experimental study investigating whether these languages can be learned in
the form of a GWM from positive and negative examples using gradient-based
methods. Our results suggest that this is indeed possible and that
investigating the use of gradient-based methods to learn picture series and
functions computed by GWMs over other families of graphs could be a fruitful
direction.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Amortila_P/0/1/0/all/0/1&quot;&gt;Philip Amortila&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rabusseau_G/0/1/0/all/0/1&quot;&gt;Guillaume Rabusseau&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.01973">
<title>A Note on the Inception Score. (arXiv:1801.01973v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1801.01973</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep generative models are powerful tools that have produced impressive
results in recent years. These advances have been for the most part empirically
driven, making it essential that we use high quality evaluation metrics. In
this paper, we provide new insights into the Inception Score, a recently
proposed and widely used evaluation metric for generative models, and
demonstrate that it fails to provide useful guidance when comparing models. We
discuss both suboptimalities of the metric itself and issues with its
application. Finally, we call for researchers to be more systematic and careful
when evaluating and comparing generative models, as the advancement of the
field depends upon it.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Barratt_S/0/1/0/all/0/1&quot;&gt;Shane Barratt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sharma_R/0/1/0/all/0/1&quot;&gt;Rishi Sharma&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.01532">
<title>Lifted Neural Networks. (arXiv:1805.01532v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.01532</link>
<description rdf:parseType="Literal">&lt;p&gt;We describe a novel family of models of multi- layer feedforward neural
networks in which the activation functions are encoded via penalties in the
training problem. Our approach is based on representing a non-decreasing
activation function as the argmin of an appropriate convex optimiza- tion
problem. The new framework allows for algo- rithms such as block-coordinate
descent methods to be applied, in which each step is composed of a simple (no
hidden layer) supervised learning problem that is parallelizable across data
points and/or layers. Experiments indicate that the pro- posed models provide
excellent initial guesses for weights for standard neural networks. In addi-
tion, the model provides avenues for interesting extensions, such as robustness
against noisy in- puts and optimizing over parameters in activation functions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Askari_A/0/1/0/all/0/1&quot;&gt;Armin Askari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Negiar_G/0/1/0/all/0/1&quot;&gt;Geoffrey Negiar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sambharya_R/0/1/0/all/0/1&quot;&gt;Rajiv Sambharya&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghaoui_L/0/1/0/all/0/1&quot;&gt;Laurent El Ghaoui&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.01845">
<title>Deep Neural Networks with Multi-Branch Architectures Are Less Non-Convex. (arXiv:1806.01845v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1806.01845</link>
<description rdf:parseType="Literal">&lt;p&gt;Several recently proposed architectures of neural networks such as ResNeXt,
Inception, Xception, SqueezeNet and Wide ResNet are based on the designing idea
of having multiple branches and have demonstrated improved performance in many
applications. We show that one cause for such success is due to the fact that
the multi-branch architecture is less non-convex in terms of duality gap. The
duality gap measures the degree of intrinsic non-convexity of an optimization
problem: smaller gap in relative value implies lower degree of intrinsic
non-convexity. The challenge is to quantitatively measure the duality gap of
highly non-convex problems such as deep neural networks. In this work, we
provide strong guarantees of this quantity for two classes of network
architectures. For the neural networks with arbitrary activation functions,
multi-branch architecture and a variant of hinge loss, we show that the duality
gap of both population and empirical risks shrinks to zero as the number of
branches increases. This result sheds light on better understanding the power
of over-parametrization where increasing the network width tends to make the
loss surface less non-convex. For the neural networks with linear activation
function and $\ell_2$ loss, we show that the duality gap of empirical risk is
zero. Our two results work for arbitrary depths and adversarial data, while the
analytical techniques might be of independent interest to non-convex
optimization more broadly. Experiments on both synthetic and real-world
datasets validate our results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1&quot;&gt;Hongyang Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shao_J/0/1/0/all/0/1&quot;&gt;Junru Shao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Salakhutdinov_R/0/1/0/all/0/1&quot;&gt;Ruslan Salakhutdinov&lt;/a&gt;</dc:creator>
</item></rdf:RDF>