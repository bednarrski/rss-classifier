<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Good papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Good Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2017-12-13T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.04473"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.04602"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.04604"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1410.5610"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1708.07120"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.08961"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.01577"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.04443"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.04596"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.04603"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.04612"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.04909"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1609.03543"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1706.06133"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1707.08234"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.04326"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.06513"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.10455"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.04542"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.04543"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.04567"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.04644"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.04667"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.04688"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.04709"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.04755"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.04775"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.04802"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.04828"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.04910"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.04912"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1608.00060"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1702.01618"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1706.06066"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1707.03897"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.03638"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.04368"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.02629"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1706.06969"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1712.04473">
<title>Enhancing approximation abilities of neural networks by training derivatives. (arXiv:1712.04473v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1712.04473</link>
<description rdf:parseType="Literal">&lt;p&gt;Method for increasing precision of feedforward networks is presented. With
the aid of it they can serve as a better tool for describing smooth functions.
Namely, it is shown that when training uses derivatives of target function up
to the fourth order, approximation can be nearly machine precise. It is
demonstrated in a number of cases: 2D function approximation, training
autoencoder to compress 3D spiral into 1D, and solving 2D boundary value
problem for Poisson equation with nonlinear source. In the first case cost
function in addition to squared difference between output and target contains
squared differences between their derivatives with respect to input variables.
Training autoencoder is similar, but differentiation is done with respect to
parameter that generates the spiral. Supplied with derivatives up to the fourth
the method is found to be 30-200 times more accurate than regular training
provided networks are of sufficient size and depth. Solving PDE is more
practical since higher derivatives are not calculated beforehand, but
information about them is extracted from the equation itself. Classical
approach is to put perceptron in place of unknown function, choose the cost as
squared residual and to minimize it with respect to weights. This would ensure
that equation holds within some margin of error. Additional terms used in cost
function are squared derivatives of the residual with respect to independent
variables. Supplied with terms up to the second order the method is found to be
5 times more accurate. Efficient GPU version of algorithm is proposed.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Avrutskiy_V/0/1/0/all/0/1&quot;&gt;V.I. Avrutskiy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.04602">
<title>On the organization of grid and place cells: Neural de-noising via subspace learning. (arXiv:1712.04602v1 [q-bio.NC])</title>
<link>http://arxiv.org/abs/1712.04602</link>
<description rdf:parseType="Literal">&lt;p&gt;Place cells in the hippocampus are active when an animal visits a certain
locations (referred to as place fields) within an environment and remain silent
otherwise. Grid cells in the medial entorhinal cortex (MEC) respond at multiple
locations, with firing fields that exhibit a hexagonally symmetric periodic
pattern. The joint activity of grid and place cell populations, as a function
of location, forms a neural code for space. An ensemble of codes, for a given
set of parameters, is generated by selecting grid and place cell population and
tuning curve parameters. For each ensemble, codewords are generated by
stimulating a network with a discrete set of locations. In this manuscript, we
develop an understanding of the relationships between coding theoretic
properties of these combined populations and code construction parameters.
These observations are revisited by measuring the performances of biologically
realizable algorithms (e.g. neural bit-flipping) implemented by a network of
place and grid cell populations, as well as interneurons, which perform
de-noising operations. Simulations demonstrate that de-noising mechanisms
analyzed here can significantly improve fidelity of this neural representation
of space. Further, patterns observed in connectivity of each population of
simulated cells suggest the existence of heretofore unobserved neurobiological
phenomena.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Schwartz_D/0/1/0/all/0/1&quot;&gt;David M. Schwartz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Koyluoglu_O/0/1/0/all/0/1&quot;&gt;O. Ozan Koyluoglu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.04604">
<title>Deep Quaternion Networks. (arXiv:1712.04604v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1712.04604</link>
<description rdf:parseType="Literal">&lt;p&gt;The field of deep learning has seen significant advancement in recent years.
However, much of the existing work has been focused on real-valued numbers.
Recent work has shown that a deep learning system using the complex numbers can
be deeper for a set parameter budget compared to its real-valued counterpart.
In this work, we explore the benefits of generalizing one step further into the
hyper-complex numbers, quaternions specifically, and provide the architecture
components needed to build deep quaternion networks. We go over quaternion
convolutions, present a quaternion weight initialization scheme, and present
algorithms for quaternion batch-normalization. These pieces are tested by
end-to-end training on the CIFAR-10 and CIFAR-100 data sets to show the
improved convergence to a real-valued network.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gaudet_C/0/1/0/all/0/1&quot;&gt;Chase Gaudet&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Maida_A/0/1/0/all/0/1&quot;&gt;Anthony Maida&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1410.5610">
<title>Logarithmic distributions prove that intrinsic learning is Hebbian. (arXiv:1410.5610v3 [q-bio.NC] UPDATED)</title>
<link>http://arxiv.org/abs/1410.5610</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we present data for the lognormal distributions of spike
rates, synaptic weights and intrinsic excitability (gain) for neurons in
various brain areas, such as auditory or visual cortex, hippocampus,
cerebellum, striatum, midbrain nuclei. We find a remarkable consistency of
heavy-tailed, specifically lognormal, distributions for rates, weights and
gains in all brain areas examined. The difference between strongly recurrent
and feed-forward connectivity (cortex vs. striatum and cerebellum),
neurotransmitter (GABA (striatum) or glutamate (cortex)) or the level of
activation (low in cortex, high in Purkinje cells and midbrain nuclei) turns
out to be irrelevant for this feature. Logarithmic scale distribution of
weights and gains appears to be a general, functional property in all cases
analyzed. We then created a generic neural model to investigate adaptive
learning rules that create and maintain lognormal distributions. We
conclusively demonstrate that not only weights, but also intrinsic gains, need
to have strong Hebbian learning in order to produce and maintain the
experimentally attested distributions. This provides a solution to the
long-standing question about the type of plasticity exhibited by intrinsic
excitability.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Scheler_G/0/1/0/all/0/1&quot;&gt;Gabriele Scheler&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1708.07120">
<title>Super-Convergence: Very Fast Training of Residual Networks Using Large Learning Rates. (arXiv:1708.07120v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1708.07120</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we show a phenomenon, which we named &quot;super-convergence&quot;,
where residual networks can be trained using an order of magnitude fewer
iterations than is used with standard training methods. The existence of
super-convergence is relevant to understanding why deep networks generalize
well. One of the key elements of super-convergence is training with cyclical
learning rates and a large maximum learning rate. Furthermore, we present
evidence that training with large learning rates improves performance by
regularizing the network. In addition, we show that super-convergence provides
a greater boost in performance relative to standard training when the amount of
labeled training data is limited. We also derive a simplification of the
Hessian Free optimization method to compute an estimate of the optimal learning
rate. The architectures and code to replicate the figures in this paper are
available at github.com/lnsmith54/super-convergence.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Smith_L/0/1/0/all/0/1&quot;&gt;Leslie N. Smith&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Topin_N/0/1/0/all/0/1&quot;&gt;Nicholay Topin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.08961">
<title>Fast and Scalable Distributed Deep Convolutional Autoencoder for fMRI Big Data Analytics. (arXiv:1710.08961v2 [cs.DC] UPDATED)</title>
<link>http://arxiv.org/abs/1710.08961</link>
<description rdf:parseType="Literal">&lt;p&gt;In recent years, analyzing task-based fMRI (tfMRI) data has become an
essential tool for understanding brain function and networks. However, due to
the sheer size of tfMRI data, its intrinsic complex structure, and lack of
ground truth of underlying neural activities, modeling tfMRI data is hard and
challenging. Previously proposed data-modeling methods including Independent
Component Analysis (ICA) and Sparse Dictionary Learning only provided a weakly
established model based on blind source separation under the strong assumption
that original fMRI signals could be linearly decomposed into time series
components with corresponding spatial maps. Meanwhile, analyzing and learning a
large amount of tfMRI data from a variety of subjects has been shown to be very
demanding but yet challenging even with technological advances in computational
hardware. Given the Convolutional Neural Network (CNN), a robust method for
learning high-level abstractions from low-level data such as tfMRI time series,
in this work we propose a fast and scalable novel framework for distributed
deep Convolutional Autoencoder model. This model aims to both learn the complex
hierarchical structure of the tfMRI data and to leverage the processing power
of multiple GPUs in a distributed fashion. To implement such a model, we have
created an enhanced processing pipeline on the top of Apache Spark and
Tensorflow library, leveraging from a very large cluster of GPU machines.
Experimental data from applying the model on the Human Connectome Project (HCP)
show that the proposed model is efficient and scalable toward tfMRI big data
analytics, thus enabling data-driven extraction of hierarchical neuroscientific
information from massive fMRI big data in the future.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Makkie_M/0/1/0/all/0/1&quot;&gt;Milad Makkie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1&quot;&gt;Heng Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1&quot;&gt;Yu Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vasilakos_A/0/1/0/all/0/1&quot;&gt;Athanasios V. Vasilakos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1&quot;&gt;Tianming Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.01577">
<title>Wider and Deeper, Cheaper and Faster: Tensorized LSTMs for Sequence Learning. (arXiv:1711.01577v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1711.01577</link>
<description rdf:parseType="Literal">&lt;p&gt;Long Short-Term Memory (LSTM) is a popular approach to boosting the ability
of Recurrent Neural Networks to store longer term temporal information. The
capacity of an LSTM network can be increased by widening and adding layers.
However, usually the former introduces additional parameters, while the latter
increases the runtime. As an alternative we propose the Tensorized LSTM in
which the hidden states are represented by tensors and updated via a
cross-layer convolution. By increasing the tensor size, the network can be
widened efficiently without additional parameters since the parameters are
shared across different locations in the tensor; by delaying the output, the
network can be deepened implicitly with little additional runtime since deep
computations for each timestep are merged into temporal computations of the
sequence. Experiments conducted on five challenging sequence learning tasks
show the potential of the proposed model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+He_Z/0/1/0/all/0/1&quot;&gt;Zhen He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gao_S/0/1/0/all/0/1&quot;&gt;Shaobing Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Xiao_L/0/1/0/all/0/1&quot;&gt;Liang Xiao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Liu_D/0/1/0/all/0/1&quot;&gt;Daxue Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+He_H/0/1/0/all/0/1&quot;&gt;Hangen He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Barber_D/0/1/0/all/0/1&quot;&gt;David Barber&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.04443">
<title>Sequential Prediction of Social Media Popularity with Deep Temporal Context Networks. (arXiv:1712.04443v1 [cs.SI])</title>
<link>http://arxiv.org/abs/1712.04443</link>
<description rdf:parseType="Literal">&lt;p&gt;Prediction of popularity has profound impact for social media, since it
offers opportunities to reveal individual preference and public attention from
evolutionary social systems. Previous research, although achieves promising
results, neglects one distinctive characteristic of social data, i.e.,
sequentiality. For example, the popularity of online content is generated over
time with sequential post streams of social media. To investigate the
sequential prediction of popularity, we propose a novel prediction framework
called Deep Temporal Context Networks (DTCN) by incorporating both temporal
context and temporal attention into account. Our DTCN contains three main
components, from embedding, learning to predicting. With a joint embedding
network, we obtain a unified deep representation of multi-modal user-post data
in a common embedding space. Then, based on the embedded data sequence over
time, temporal context learning attempts to recurrently learn two adaptive
temporal contexts for sequential popularity. Finally, a novel temporal
attention is designed to predict new popularity (the popularity of a new
user-post pair) with temporal coherence across multiple time-scales.
Experiments on our released image dataset with about 600K Flickr photos
demonstrate that DTCN outperforms state-of-the-art deep prediction algorithms,
with an average of 21.51% relative performance improvement in the popularity
prediction (Spearman Ranking Correlation).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_B/0/1/0/all/0/1&quot;&gt;Bo Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_W/0/1/0/all/0/1&quot;&gt;Wen-Huang Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yongdong Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_Q/0/1/0/all/0/1&quot;&gt;Qiushi Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jintao Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mei_T/0/1/0/all/0/1&quot;&gt;Tao Mei&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.04596">
<title>Consideration on Example 2 of &quot;An Algorithm of General Fuzzy InferenceWith The Reductive Property&quot;. (arXiv:1712.04596v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1712.04596</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we will show that (1) the results about the fuzzy reasoning
algoritm obtained in the paper &quot;Computer Sciences Vol. 34, No.4, pp.145-148,
2007&quot; according to the paper &quot;IEEE Transactions On systems, Man and
cybernetics, 18, pp.1049-1056, 1988&quot; are correct; (2) example 2 in the paper
&quot;An Algorithm of General Fuzzy Inference With The Reductive Property&quot; presented
by He Ying-Si, Quan Hai-Jin and Deng Hui-Wen according to the paper &quot;An
approximate analogical reasoning approach based on similarity measures&quot;
presented by Tursken I.B. and Zhong zhao is incorrect; (3) the mistakes in
their paper are modified and then a calculation example of FMT is supplemented.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kwak_S/0/1/0/all/0/1&quot;&gt;Son-Il Kwak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gwon_O/0/1/0/all/0/1&quot;&gt;Oh-Chol Gwon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kwak_C/0/1/0/all/0/1&quot;&gt;Chung-Jin Kwak&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.04603">
<title>Multi-focus Attention Network for Efficient Deep Reinforcement Learning. (arXiv:1712.04603v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1712.04603</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep reinforcement learning (DRL) has shown incredible performance in
learning various tasks to the human level. However, unlike human perception,
current DRL models connect the entire low-level sensory input to the
state-action values rather than exploiting the relationship between and among
entities that constitute the sensory input. Because of this difference, DRL
needs vast amount of experience samples to learn. In this paper, we propose a
Multi-focus Attention Network (MANet) which mimics human ability to spatially
abstract the low-level sensory input into multiple entities and attend to them
simultaneously. The proposed method first divides the low-level input into
several segments which we refer to as partial states. After this segmentation,
parallel attention layers attend to the partial states relevant to solving the
task. Our model estimates state-action values using these attended partial
states. In our experiments, MANet attains highest scores with significantly
less experience samples. Additionally, the model shows higher performance
compared to the Deep Q-network and the single attention model as benchmarks.
Furthermore, we extend our model to attentive communication model for
performing multi-agent cooperative tasks. In multi-agent cooperative task
experiments, our model shows 20% faster learning than existing state-of-the-art
model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1&quot;&gt;Jinyoung Choi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_B/0/1/0/all/0/1&quot;&gt;Beom-Jin Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1&quot;&gt;Byoung-Tak Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.04612">
<title>Inverse Reinforcement Learning for Marketing. (arXiv:1712.04612v1 [q-fin.CP])</title>
<link>http://arxiv.org/abs/1712.04612</link>
<description rdf:parseType="Literal">&lt;p&gt;Learning customer preferences from an observed behaviour is an important
topic in the marketing literature. Structural models typically model
forward-looking customers or firms as utility-maximizing agents whose utility
is estimated using methods of Stochastic Optimal Control. We suggest an
alternative approach to study dynamic consumer demand, based on Inverse
Reinforcement Learning (IRL). We develop a version of the Maximum Entropy IRL
that leads to a highly tractable model formulation that amounts to
low-dimensional convex optimization in the search for optimal model parameters.
Using simulations of consumer demand, we show that observational noise for
identical customers can be easily confused with an apparent consumer
heterogeneity.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-fin/1/au:+Halperin_I/0/1/0/all/0/1&quot;&gt;Igor Halperin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.04909">
<title>Reasoning in Systems with Elements that Randomly Switch Characteristics. (arXiv:1712.04909v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1712.04909</link>
<description rdf:parseType="Literal">&lt;p&gt;We examine the issue of stability of probability in reasoning about complex
systems with uncertainty in structure. Normally, propositions are viewed as
probability functions on an abstract random graph where it is implicitly
assumed that the nodes of the graph have stable properties. But what if some of
the nodes change their characteristics? This is a situation that cannot be
covered by abstractions of either static or dynamic sets when these changes
take place at regular intervals. We propose the use of sets with elements that
change, and modular forms are proposed to account for one type of such change.
An expression for the dependence of the mean on the probability of the
switching elements has been determined. The system is also analyzed from the
perspective of decision between different hypotheses. Such sets are likely to
be of use in complex system queries and in analysis of surveys.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kak_S/0/1/0/all/0/1&quot;&gt;Subhash Kak&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1609.03543">
<title>Logical Induction. (arXiv:1609.03543v4 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1609.03543</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a computable algorithm that assigns probabilities to every logical
statement in a given formal language, and refines those probabilities over
time. For instance, if the language is Peano arithmetic, it assigns
probabilities to all arithmetical statements, including claims about the twin
prime conjecture, the outputs of long-running computations, and its own
probabilities. We show that our algorithm, an instance of what we call a
logical inductor, satisfies a number of intuitive desiderata, including: (1) it
learns to predict patterns of truth and falsehood in logical statements, often
long before having the resources to evaluate the statements, so long as the
patterns can be written down in polynomial time; (2) it learns to use
appropriate statistical summaries to predict sequences of statements whose
truth values appear pseudorandom; and (3) it learns to have accurate beliefs
about its own current beliefs, in a manner that avoids the standard paradoxes
of self-reference. For example, if a given computer program only ever produces
outputs in a certain range, a logical inductor learns this fact in a timely
manner; and if late digits in the decimal expansion of $\pi$ are difficult to
predict, then a logical inductor learns to assign $\approx 10\%$ probability to
&quot;the $n$th digit of $\pi$ is a 7&quot; for large $n$. Logical inductors also learn
to trust their future beliefs more than their current beliefs, and their
beliefs are coherent in the limit (whenever $\phi \implies \psi$,
$\mathbb{P}_\infty(\phi) \le \mathbb{P}_\infty(\psi)$, and so on); and logical
inductors strictly dominate the universal semimeasure in the limit.
&lt;/p&gt;
&lt;p&gt;These properties and many others all follow from a single logical induction
criterion, which is motivated by a series of stock trading analogies. Roughly
speaking, each logical sentence $\phi$ is associated with a stock that is worth
\$1 per share if [...]
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garrabrant_S/0/1/0/all/0/1&quot;&gt;Scott Garrabrant&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Benson_Tilsen_T/0/1/0/all/0/1&quot;&gt;Tsvi Benson-Tilsen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Critch_A/0/1/0/all/0/1&quot;&gt;Andrew Critch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Soares_N/0/1/0/all/0/1&quot;&gt;Nate Soares&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Taylor_J/0/1/0/all/0/1&quot;&gt;Jessica Taylor&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1706.06133">
<title>Scalable Co-Optimization of Morphology and Control in Embodied Machines. (arXiv:1706.06133v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1706.06133</link>
<description rdf:parseType="Literal">&lt;p&gt;Evolution sculpts both the body plans and nervous systems of agents together
over time. In contrast, in AI and robotics, a robot&apos;s body plan is usually
designed by hand, and control policies are then optimized for that fixed
design. The task of simultaneously co-optimizing the morphology and controller
of an embodied robot has remained a challenge. In psychology, the theory of
embodied cognition posits that behavior arises from a close coupling between
body plan and sensorimotor control, which suggests why co-optimizing these two
subsystems is so difficult: most evolutionary changes to morphology tend to
adversely impact sensorimotor control, leading to an overall decrease in
behavioral performance. Here, we further examine this hypothesis and
demonstrate a technique for &quot;morphological innovation protection&quot;, which
temporarily reduces selection pressure on recently morphologically-changed
individuals, thus enabling evolution some time to &quot;readapt&quot; to the new
morphology with subsequent control policy mutations. We show the potential for
this method to avoid local optima and converge to similar highly fit
morphologies across widely varying initial conditions, while sustaining fitness
improvements further into optimization. While this technique is admittedly only
the first of many steps that must be taken to achieve scalable optimization of
embodied machines, we hope that theoretical insight into the cause of
evolutionary stagnation in current methods will help to enable the automation
of robot design and behavioral training -- while simultaneously providing a
testbed to investigate the theory of embodied cognition.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheney_N/0/1/0/all/0/1&quot;&gt;Nick Cheney&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bongard_J/0/1/0/all/0/1&quot;&gt;Josh Bongard&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+SunSpiral_V/0/1/0/all/0/1&quot;&gt;Vytas SunSpiral&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lipson_H/0/1/0/all/0/1&quot;&gt;Hod Lipson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1707.08234">
<title>Closed-Loop Policies for Operational Tests of Safety-Critical Systems. (arXiv:1707.08234v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1707.08234</link>
<description rdf:parseType="Literal">&lt;p&gt;Manufacturers of safety-critical systems must make the case that their
product is sufficiently safe for public deployment. Much of this case often
relies upon critical event outcomes from real-world testing, requiring
manufacturers to be strategic about how they allocate testing resources in
order to maximize their chances of demonstrating system safety. This work
frames the partially observable and belief-dependent problem of test scheduling
as a Markov decision process, which can be solved efficiently to yield
closed-loop manufacturer testing policies. By solving for policies over a wide
range of problem formulations, we are able to provide high-level guidance for
manufacturers and regulators on issues relating to the testing of
safety-critical systems. This guidance spans an array of topics, including
circumstances under which manufacturers should continue testing despite
observed incidents, when manufacturers should test aggressively, and when
regulators should increase or reduce the real-world testing requirements for an
autonomous vehicle.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Morton_J/0/1/0/all/0/1&quot;&gt;Jeremy Morton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wheeler_T/0/1/0/all/0/1&quot;&gt;Tim A. Wheeler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kochenderfer_M/0/1/0/all/0/1&quot;&gt;Mykel J. Kochenderfer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.04326">
<title>Learning with Opponent-Learning Awareness. (arXiv:1709.04326v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1709.04326</link>
<description rdf:parseType="Literal">&lt;p&gt;Multi-agent settings are quickly gathering importance in machine learning.
Beyond a plethora of recent work on deep multi-agent reinforcement learning,
hierarchical reinforcement learning, generative adversarial networks and
decentralized optimization can all be seen as instances of this setting.
However, the presence of multiple learning agents in these settings renders the
training problem non-stationary and often leads to unstable training or
undesired final results. We present Learning with Opponent-Learning Awareness
(LOLA), a method that reasons about the anticipated learning of the other
agents. The LOLA learning rule includes an additional term that accounts for
the impact of the agent&apos;s policy on the anticipated parameter update of the
other agents. We show that the LOLA update rule can be efficiently calculated
using an extension of the likelihood ratio policy gradient update, making the
method suitable for model-free RL. This method thus scales to large parameter
and input spaces and nonlinear function approximators. Preliminary results show
that the encounter of two LOLA agents leads to the emergence of tit-for-tat and
therefore cooperation in the iterated prisoners&apos; dilemma (IPD), while
independent learning does not. In this domain, LOLA also receives higher
payouts compared to a naive learner, and is robust against exploitation by
higher order gradient-based methods. Applied to infinitely repeated matching
pennies, LOLA agents converge to the Nash equilibrium. In a round robin
tournament we show that LOLA agents can successfully shape the learning of a
range of multi-agent learning algorithms from literature, resulting in the
highest average returns on the IPD. We also apply LOLA to a grid world task
with an embedded social dilemma using deep recurrent policies. Again, by
considering the learning of the other agent, LOLA agents learn to cooperate out
of selfish interests.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Foerster_J/0/1/0/all/0/1&quot;&gt;Jakob N. Foerster&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_R/0/1/0/all/0/1&quot;&gt;Richard Y. Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Al_Shedivat_M/0/1/0/all/0/1&quot;&gt;Maruan Al-Shedivat&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Whiteson_S/0/1/0/all/0/1&quot;&gt;Shimon Whiteson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1&quot;&gt;Pieter Abbeel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mordatch_I/0/1/0/all/0/1&quot;&gt;Igor Mordatch&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.06513">
<title>Learning Pose Grammar to Encode Human Body Configuration for 3D Pose Estimation. (arXiv:1710.06513v5 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1710.06513</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we propose a pose grammar to tackle the problem of 3D human
pose estimation. Our model directly takes 2D pose as input and learns a
generalized 2D-3D mapping function. The proposed model consists of a base
network which efficiently captures pose-aligned features and a hierarchy of
Bi-directional RNNs (BRNN) on the top to explicitly incorporate a set of
knowledge regarding human body configuration (i.e., kinematics, symmetry, motor
coordination). The proposed model thus enforces high-level constraints over
human poses. In learning, we develop a pose sample simulator to augment
training samples in virtual camera views, which further improves our model
generalizability. We validate our method on public 3D human pose benchmarks and
propose a new evaluation protocol working on cross-view setting to verify the
generalization capability of different methods. We empirically observe that
most state-of-the-art methods encounter difficulty under such setting while our
method can well handle such challenges.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fang_H/0/1/0/all/0/1&quot;&gt;Haoshu Fang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1&quot;&gt;Yuanlu Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1&quot;&gt;Wenguan Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1&quot;&gt;Xiaobai Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_S/0/1/0/all/0/1&quot;&gt;Song-Chun Zhu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.10455">
<title>Backprop as Functor: A compositional perspective on supervised learning. (arXiv:1711.10455v2 [math.CT] UPDATED)</title>
<link>http://arxiv.org/abs/1711.10455</link>
<description rdf:parseType="Literal">&lt;p&gt;A supervised learning algorithm searches over a set of functions $A \to B$
parametrised by a space $P$ to find the best approximation to some ideal
function $f\colon A \to B$. It does this by taking examples $(a,f(a)) \in
A\times B$, and updating the parameter according to some rule. We define a
category where these update rules may be composed, and show that gradient
descent---with respect to a fixed step size and an error function satisfying a
certain property---defines a monoidal functor from a category of parametrised
functions to this category of update rules. This provides a structural
perspective on backpropagation, as well as a broad generalisation of neural
networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Fong_B/0/1/0/all/0/1&quot;&gt;Brendan Fong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Spivak_D/0/1/0/all/0/1&quot;&gt;David I. Spivak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Tuyeras_R/0/1/0/all/0/1&quot;&gt;R&amp;#xe9;my Tuy&amp;#xe9;ras&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.04542">
<title>Learning Sparse Graphs for Prediction and Filtering of Multivariate Data Processes. (arXiv:1712.04542v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1712.04542</link>
<description rdf:parseType="Literal">&lt;p&gt;We address the problem of prediction and filtering of multivariate data
process using an underlying graph model. We develop a method that learns a
sparse partial correlation graph in a tuning-free and computationally efficient
manner. Specifically, the graph structure is learned recursively without the
need for cross-validation or parameter tuning by building upon a
hyperparameter-free framework. Experiments using real-world datasets show that
the proposed method offers significant performance gains in prediction and
filtering tasks, in comparison with the graphs frequently associated with these
datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Venkitaraman_A/0/1/0/all/0/1&quot;&gt;Arun Venkitaraman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zachariah_D/0/1/0/all/0/1&quot;&gt;Dave Zachariah&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.04543">
<title>A Mathematical Programming Approach for Integrated Multiple Linear Regression Subset Selection and Validation. (arXiv:1712.04543v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1712.04543</link>
<description rdf:parseType="Literal">&lt;p&gt;Subset selection for multiple linear regression aims to construct a
regression model that minimizes errors by selecting a small number of
explanatory variables. Once a model is built, various statistical tests and
diagnostics are conducted to validate the model and to determine whether
regression assumptions are met. Most traditional approaches require human
decisions at this step, for example, the user adding or removing a variable
until a satisfactory model is obtained. However, this trial-and-error strategy
cannot guarantee that a subset that minimizes the errors while satisfying all
regression assumptions will be found. In this paper, we propose a fully
automated model building procedure for multiple linear regression subset
selection that integrates model building and validation based on mathematical
programming. The proposed model minimizes mean squared errors while ensuring
that the majority of the important regression assumptions are met. When no
subset satisfies all of the considered regression assumptions, our model
provides an alternative subset that satisfies most of these assumptions.
Computational results show that our model yields better solutions (i.e.,
satisfying more regression assumptions) compared to benchmark models while
maintaining similar explanatory power.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chung_S/0/1/0/all/0/1&quot;&gt;Seokhyun Chung&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Park_Y/0/1/0/all/0/1&quot;&gt;Young Woong Park&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Cheong_T/0/1/0/all/0/1&quot;&gt;Taesu Cheong&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.04567">
<title>Practical Bayesian optimization in the presence of outliers. (arXiv:1712.04567v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1712.04567</link>
<description rdf:parseType="Literal">&lt;p&gt;Inference in the presence of outliers is an important field of research as
outliers are ubiquitous and may arise across a variety of problems and domains.
Bayesian optimization is method that heavily relies on probabilistic inference.
This allows outstanding sample efficiency because the probabilistic machinery
provides a memory of the whole optimization process. However, that virtue
becomes a disadvantage when the memory is populated with outliers, inducing
bias in the estimation. In this paper, we present an empirical evaluation of
Bayesian optimization methods in the presence of outliers. The empirical
evidence shows that Bayesian optimization with robust regression often produces
suboptimal results. We then propose a new algorithm which combines robust
regression (a Gaussian process with Student-t likelihood) with outlier
diagnostics to classify data points as outliers or inliers. By using an
scheduler for the classification of outliers, our method is more efficient and
has better convergence over the standard robust regression. Furthermore, we
show that even in controlled situations with no expected outliers, our method
is able to produce better results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Martinez_Cantin_R/0/1/0/all/0/1&quot;&gt;Ruben Martinez-Cantin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tee_K/0/1/0/all/0/1&quot;&gt;Kevin Tee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+McCourt_M/0/1/0/all/0/1&quot;&gt;Michael McCourt&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.04644">
<title>Stochastic Low-Rank Bandits. (arXiv:1712.04644v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1712.04644</link>
<description rdf:parseType="Literal">&lt;p&gt;Many problems in computer vision and recommender systems involve low-rank
matrices. In this work, we study the problem of finding the maximum entry of a
stochastic low-rank matrix from sequential observations. At each step, a
learning agent chooses pairs of row and column arms, and receives the noisy
product of their latent values as a reward. The main challenge is that the
latent values are unobserved. We identify a class of non-negative matrices
whose maximum entry can be found statistically efficiently and propose an
algorithm for finding them, which we call LowRankElim. We derive a
$\DeclareMathOperator{\poly}{poly} O((K + L) \poly(d) \Delta^{-1} \log n)$
upper bound on its $n$-step regret, where $K$ is the number of rows, $L$ is the
number of columns, $d$ is the rank of the matrix, and $\Delta$ is the minimum
gap. The bound depends on other problem-specific constants that clearly do not
depend $K L$. To the best of our knowledge, this is the first such result in
the literature.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kveton_B/0/1/0/all/0/1&quot;&gt;Branislav Kveton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Szepesvari_C/0/1/0/all/0/1&quot;&gt;Csaba Szepesvari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rao_A/0/1/0/all/0/1&quot;&gt;Anup Rao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wen_Z/0/1/0/all/0/1&quot;&gt;Zheng Wen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abbasi_Yadkori_Y/0/1/0/all/0/1&quot;&gt;Yasin Abbasi-Yadkori&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Muthukrishnan_S/0/1/0/all/0/1&quot;&gt;S. Muthukrishnan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.04667">
<title>Variance reduction via empirical variance minimization: convergence and complexity. (arXiv:1712.04667v1 [math.NA])</title>
<link>http://arxiv.org/abs/1712.04667</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper we propose and study a generic variance reduction approach. The
proposed method is based on minimization of the empirical variance over a
suitable class of zero mean control functionals. We present the corresponding
convergence analysis and analyze complexity. Finally some numerical results
showing efficiency of the proposed approach are presented.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Belomestny_D/0/1/0/all/0/1&quot;&gt;D. Belomestny&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Iosipoi_L/0/1/0/all/0/1&quot;&gt;L. Iosipoi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Zhivotovskiy_N/0/1/0/all/0/1&quot;&gt;N. Zhivotovskiy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.04688">
<title>Stability Selection for Structured Variable Selection. (arXiv:1712.04688v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1712.04688</link>
<description rdf:parseType="Literal">&lt;p&gt;In variable or graph selection problems, finding a right-sized model or
controlling the number of false positives is notoriously difficult. Recently, a
meta-algorithm called Stability Selection was proposed that can provide
reliable finite-sample control of the number of false positives. Its benefits
were demonstrated when used in conjunction with the lasso and orthogonal
matching pursuit algorithms.
&lt;/p&gt;
&lt;p&gt;In this paper, we investigate the applicability of stability selection to
structured selection algorithms: the group lasso and the structured
input-output lasso. We find that using stability selection often increases the
power of both algorithms, but that the presence of complex structure reduces
the reliability of error control under stability selection. We give strategies
for setting tuning parameters to obtain a good model size under stability
selection, and highlight its strengths and weaknesses compared to competing
methods screen and clean and cross-validation. We give guidelines about when to
use which error control method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Philipp_G/0/1/0/all/0/1&quot;&gt;George Philipp&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lee_S/0/1/0/all/0/1&quot;&gt;Seunghak Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Xing_E/0/1/0/all/0/1&quot;&gt;Eric P. Xing&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.04709">
<title>A Quantum Extension of Variational Bayes Inference. (arXiv:1712.04709v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1712.04709</link>
<description rdf:parseType="Literal">&lt;p&gt;Variational Bayes (VB) inference is one of the most important algorithms in
machine learning and widely used in engineering and industry. However, VB is
known to suffer from the problem of local optima. In this Letter, we generalize
VB by using quantum mechanics, and propose a new algorithm, which we call
quantum annealing variational Bayes (QAVB) inference. We then show that QAVB
drastically improve the performance of VB by applying them to a clustering
problem described by a Gaussian mixture model. Finally, we discuss an intuitive
understanding on how QAVB works well.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Miyahara_H/0/1/0/all/0/1&quot;&gt;Hideyuki Miyahara&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sughiyama_Y/0/1/0/all/0/1&quot;&gt;Yuki Sughiyama&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.04755">
<title>Exponential convergence of testing error for stochastic gradient methods. (arXiv:1712.04755v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1712.04755</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider binary classification problems with positive definite kernels and
square loss, and study the convergence rates of stochastic gradient methods. We
show that while the excess testing loss (squared loss) converges slowly to zero
as the number of observations (and thus iterations) goes to infinity, the
testing error (classification error) converges exponentially fast if low-noise
conditions are assumed.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pillaud_Vivien_L/0/1/0/all/0/1&quot;&gt;Loucas Pillaud-Vivien&lt;/a&gt; (SIERRA), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rudi_A/0/1/0/all/0/1&quot;&gt;Alessandro Rudi&lt;/a&gt; (SIERRA), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bach_F/0/1/0/all/0/1&quot;&gt;Francis Bach&lt;/a&gt; (SIERRA)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.04775">
<title>Multiple testing for outlier detection in functional data. (arXiv:1712.04775v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1712.04775</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a novel procedure for outlier detection in functional data, in a
semi-supervised framework. As the data is functional, we consider the
coefficients obtained after projecting the observations onto orthonormal bases
(wavelet, PCA). A multiple testing procedure based on the two-sample test is
defined in order to highlight the levels of the coefficients on which the
outliers appear as significantly different to the normal data. The selected
coefficients are then called features for the outlier detection, on which we
compute the Local Outlier Factor to highlight the outliers. This procedure to
select the features is applied on simulated data that mimic the behaviour of
space telemetries, and compared with existing dimension reduction techniques.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Barreyre_C/0/1/0/all/0/1&quot;&gt;Cl&amp;#xe9;mentine Barreyre&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Laurent_B/0/1/0/all/0/1&quot;&gt;B&amp;#xe9;atrice Laurent&lt;/a&gt; (IMT), &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Loubes_J/0/1/0/all/0/1&quot;&gt;Jean-Michel Loubes&lt;/a&gt; (IMT), &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Cabon_B/0/1/0/all/0/1&quot;&gt;Bertrand Cabon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Boussouf_L/0/1/0/all/0/1&quot;&gt;Lo&amp;#xef;c Boussouf&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.04802">
<title>Generic Machine Learning Inference on Heterogenous Treatment Effects in Randomized Experiments. (arXiv:1712.04802v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1712.04802</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose strategies to estimate and make inference on key features of
heterogeneous effects in randomized experiments. These key features include
best linear predictors of the effects using machine learning proxies, average
effects sorted by impact groups, and average characteristics of most and least
impacted units. The approach is valid in high dimensional settings, where the
effects are proxied by machine learning methods. We post-process these proxies
into the estimates of the key features. Our approach is agnostic about the
properties of the machine learning estimators used to produce proxies, and it
completely avoids making any strong assumption. Estimation and inference relies
on repeated data splitting to avoid overfitting and achieve validity. Our
variational inference method is shown to be uniformly valid and quantifies the
uncertainty coming from both parameter estimation and data splitting. In
essence, we take medians of p-values and medians of confidence intervals,
resulting from many different data splits, and then adjust their nominal level
to guarantee uniform validity. The inference method could be of substantial
independent interest in many machine learning applications. Empirical
applications illustrate the use of the approach.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chernozhukov_V/0/1/0/all/0/1&quot;&gt;Victor Chernozhukov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Demirer_M/0/1/0/all/0/1&quot;&gt;Mert Demirer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Duflo_E/0/1/0/all/0/1&quot;&gt;Esther Duflo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Fernandez_Val_I/0/1/0/all/0/1&quot;&gt;Ivan Fernandez-Val&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.04828">
<title>Ballpark Crowdsourcing: The Wisdom of Rough Group Comparisons. (arXiv:1712.04828v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1712.04828</link>
<description rdf:parseType="Literal">&lt;p&gt;Crowdsourcing has become a popular method for collecting labeled training
data. However, in many practical scenarios traditional labeling can be
difficult for crowdworkers (for example, if the data is high-dimensional or
unintuitive, or the labels are continuous).
&lt;/p&gt;
&lt;p&gt;In this work, we develop a novel model for crowdsourcing that can complement
standard practices by exploiting people&apos;s intuitions about groups and relations
between them. We employ a recent machine learning setting, called Ballpark
Learning, that can estimate individual labels given only coarse, aggregated
signal over groups of data points. To address the important case of continuous
labels, we extend the Ballpark setting (which focused on classification) to
regression problems. We formulate the problem as a convex optimization problem
and propose fast, simple methods with an innate robustness to outliers.
&lt;/p&gt;
&lt;p&gt;We evaluate our methods on real-world datasets, demonstrating how useful
constraints about groups can be harnessed from a crowd of non-experts. Our
methods can rival supervised models trained on many true labels, and can obtain
considerably better results from the crowd than a standard label-collection
process (for a lower price). By collecting rough guesses on groups of instances
and using machine learning to infer the individual labels, our lightweight
framework is able to address core crowdsourcing challenges and train machine
learning models in a cost-effective way.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hope_T/0/1/0/all/0/1&quot;&gt;Tom Hope&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Shahaf_D/0/1/0/all/0/1&quot;&gt;Dafna Shahaf&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.04910">
<title>FFT-Based Deep Learning Deployment in Embedded Systems. (arXiv:1712.04910v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1712.04910</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep learning has delivered its powerfulness in many application domains,
especially in image and speech recognition. As the backbone of deep learning,
deep neural networks (DNNs) consist of multiple layers of various types with
hundreds to thousands of neurons. Embedded platforms are now becoming essential
for deep learning deployment due to their portability, versatility, and energy
efficiency. The large model size of DNNs, while providing excellent accuracy,
also burdens the embedded platforms with intensive computation and storage.
Researchers have investigated on reducing DNN model size with negligible
accuracy loss. This work proposes a Fast Fourier Transform (FFT)-based DNN
training and inference model suitable for embedded platforms with reduced
asymptotic complexity of both computation and storage, making our approach
distinguished from existing approaches. We develop the training and inference
algorithms based on FFT as the computing kernel and deploy the FFT-based
inference model on embedded platforms achieving extraordinary processing speed.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_S/0/1/0/all/0/1&quot;&gt;Sheng Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_N/0/1/0/all/0/1&quot;&gt;Ning Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nazemi_M/0/1/0/all/0/1&quot;&gt;Mahdi Nazemi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1&quot;&gt;Hongjia Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ding_C/0/1/0/all/0/1&quot;&gt;Caiwen Ding&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yanzhi Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pedram_M/0/1/0/all/0/1&quot;&gt;Massoud Pedram&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.04912">
<title>Learning Objectives for Treatment Effect Estimation. (arXiv:1712.04912v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1712.04912</link>
<description rdf:parseType="Literal">&lt;p&gt;We develop a general class of two-step algorithms for heterogeneous treatment
effect estimation in observational studies. We first estimate marginal effects
and treatment propensities to form an objective function that isolates the
heterogeneous treatment effects, and then optimize the learned objective. This
approach has several advantages over existing methods. From a practical
perspective, our method is very flexible and easy to use: In both steps, we can
use any method of our choice, e.g., penalized regression, a deep net, or
boosting; moreover, these methods can be fine-tuned by cross-validating on the
learned objective. Meanwhile, in the case of penalized kernel regression, we
show that our method has a quasi-oracle property, whereby even if our pilot
estimates for marginal effects and treatment propensities are not particularly
accurate, we achieve the same regret bounds as an oracle who has a-priori
knowledge of these nuisance components. We implement variants of our method
based on both penalized regression and convolutional neural networks, and find
promising performance relative to existing baselines.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Nie_X/0/1/0/all/0/1&quot;&gt;Xinkun Nie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wager_S/0/1/0/all/0/1&quot;&gt;Stefan Wager&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1608.00060">
<title>Double/Debiased Machine Learning for Treatment and Causal Parameters. (arXiv:1608.00060v6 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1608.00060</link>
<description rdf:parseType="Literal">&lt;p&gt;Most modern supervised statistical/machine learning (ML) methods are
explicitly designed to solve prediction problems very well. Achieving this goal
does not imply that these methods automatically deliver good estimators of
causal parameters. Examples of such parameters include individual regression
coefficients, average treatment effects, average lifts, and demand or supply
elasticities. In fact, estimates of such causal parameters obtained via naively
plugging ML estimators into estimating equations for such parameters can behave
very poorly due to the regularization bias. Fortunately, this regularization
bias can be removed by solving auxiliary prediction problems via ML tools.
Specifically, we can form an orthogonal score for the target low-dimensional
parameter by combining auxiliary and main ML predictions. The score is then
used to build a de-biased estimator of the target parameter which typically
will converge at the fastest possible 1/root(n) rate and be approximately
unbiased and normal, and from which valid confidence intervals for these
parameters of interest may be constructed. The resulting method thus could be
called a &quot;double ML&quot; method because it relies on estimating primary and
auxiliary predictive models. In order to avoid overfitting, our construction
also makes use of the K-fold sample splitting, which we call cross-fitting.
This allows us to use a very broad set of ML predictive methods in solving the
auxiliary and main prediction problems, such as random forest, lasso, ridge,
deep neural nets, boosted trees, as well as various hybrids and aggregators of
these methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chernozhukov_V/0/1/0/all/0/1&quot;&gt;Victor Chernozhukov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chetverikov_D/0/1/0/all/0/1&quot;&gt;Denis Chetverikov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Demirer_M/0/1/0/all/0/1&quot;&gt;Mert Demirer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Duflo_E/0/1/0/all/0/1&quot;&gt;Esther Duflo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hansen_C/0/1/0/all/0/1&quot;&gt;Christian Hansen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Newey_W/0/1/0/all/0/1&quot;&gt;Whitney Newey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Robins_J/0/1/0/all/0/1&quot;&gt;James Robins&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1702.01618">
<title>Learning of state-space models with highly informative observations: a tempered Sequential Monte Carlo solution. (arXiv:1702.01618v2 [stat.CO] UPDATED)</title>
<link>http://arxiv.org/abs/1702.01618</link>
<description rdf:parseType="Literal">&lt;p&gt;Probabilistic (or Bayesian) modeling and learning offers interesting
possibilities for systematic representation of uncertainty using probability
theory. However, probabilistic learning often leads to computationally
challenging problems. Some problems of this type that were previously
intractable can now be solved on standard personal computers thanks to recent
advances in Monte Carlo methods. In particular, for learning of unknown
parameters in nonlinear state-space models, methods based on the particle
filter (a Monte Carlo method) have proven very useful. A notoriously
challenging problem, however, still occurs when the observations in the
state-space model are highly informative, i.e. when there is very little or no
measurement noise present, relative to the amount of process noise. The
particle filter will then struggle in estimating one of the basic components
for probabilistic learning, namely the likelihood $p($data$|$parameters$)$. To
this end we suggest an algorithm which initially assumes that there is
substantial amount of artificial measurement noise present. The variance of
this noise is sequentially decreased in an adaptive fashion such that we, in
the end, recover the original problem or possibly a very close approximation of
it. The main component in our algorithm is a sequential Monte Carlo (SMC)
sampler, which gives our proposed method a clear resemblance to the SMC^2
method. Another natural link is also made to the ideas underlying the
approximate Bayesian computation (ABC). We illustrate it with numerical
examples, and in particular show promising results for a challenging
Wiener-Hammerstein benchmark problem.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Svensson_A/0/1/0/all/0/1&quot;&gt;Andreas Svensson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Schon_T/0/1/0/all/0/1&quot;&gt;Thomas B. Sch&amp;#xf6;n&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lindsten_F/0/1/0/all/0/1&quot;&gt;Fredrik Lindsten&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1706.06066">
<title>On Quadratic Convergence of DC Proximal Newton Algorithm for Nonconvex Sparse Learning in High Dimensions. (arXiv:1706.06066v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1706.06066</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a DC proximal Newton algorithm for solving nonconvex regularized
sparse learning problems in high dimensions. Our proposed algorithm integrates
the proximal Newton algorithm with multi-stage convex relaxation based on the
difference of convex (DC) programming, and enjoys both strong computational and
statistical guarantees. Specifically, by leveraging a sophisticated
characterization of sparse modeling structures/assumptions (i.e., local
restricted strong convexity and Hessian smoothness), we prove that within each
stage of convex relaxation, our proposed algorithm achieves (local) quadratic
convergence, and eventually obtains a sparse approximate local optimum with
optimal statistical properties after only a few convex relaxations. Numerical
experiments are provided to support our theory.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xingguo Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yang_L/0/1/0/all/0/1&quot;&gt;Lin F. Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ge_J/0/1/0/all/0/1&quot;&gt;Jason Ge&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Haupt_J/0/1/0/all/0/1&quot;&gt;Jarvis Haupt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhang_T/0/1/0/all/0/1&quot;&gt;Tong Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhao_T/0/1/0/all/0/1&quot;&gt;Tuo Zhao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1707.03897">
<title>ClustGeo: an R package for hierarchical clustering with spatial constraints. (arXiv:1707.03897v2 [stat.CO] UPDATED)</title>
<link>http://arxiv.org/abs/1707.03897</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we propose a Ward-like hierarchical clustering algorithm
including spatial/geographical constraints. Two dissimilarity matrices $D_0$
and $D_1$ are inputted, along with a mixing parameter $\alpha \in [0,1]$. The
dissimilarities can be non-Euclidean and the weights of the observations can be
non-uniform. The first matrix gives the dissimilarities in the &quot;feature space&quot;
and the second matrix gives the dissimilarities in the &quot;constraint space&quot;. The
criterion minimized at each stage is a convex combination of the homogeneity
criterion calculated with $D_0$ and the homogeneity criterion calculated with
$D_1$. The idea is then to determine a value of $\alpha$ which increases the
spatial contiguity without deteriorating too much the quality of the solution
based on the variables of interest i.e. those of the feature space. This
procedure is illustrated on a real dataset using the R package ClustGeo.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chavent_M/0/1/0/all/0/1&quot;&gt;Marie Chavent&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kuentz_Simonet_V/0/1/0/all/0/1&quot;&gt;Vanessa Kuentz-Simonet&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Labenne_A/0/1/0/all/0/1&quot;&gt;Amaury Labenne&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Saracco_J/0/1/0/all/0/1&quot;&gt;J&amp;#xe9;r&amp;#xf4;me Saracco&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.03638">
<title>Provably Accurate Double-Sparse Coding. (arXiv:1711.03638v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1711.03638</link>
<description rdf:parseType="Literal">&lt;p&gt;Sparse coding is a crucial subroutine in algorithms for various signal
processing, deep learning, and other machine learning applications. The central
goal is to learn an overcomplete dictionary that can sparsely represent a given
input dataset. However, a key challenge is that storage, transmission, and
processing of the learned dictionary can be untenably high if the data
dimension is high. In this paper, we consider the double-sparsity model
introduced by Rubinstein et al. (2010b) where the dictionary itself is the
product of a fixed, known basis and a data-adaptive sparse component. First, we
introduce a simple algorithm for double-sparse coding that can be amenable to
efficient implementation via neural architectures. Second, we theoretically
analyze its performance and demonstrate asymptotic sample complexity and
running time benefits over existing (provable) approaches for sparse coding. To
our knowledge, our work introduces the first computationally efficient
algorithm for double-sparse coding that enjoys rigorous statistical guarantees.
Finally, we support our analysis via several numerical experiments on simulated
data, confirming that our method can indeed be useful in problem sizes
encountered in practical applications.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Nguyen_T/0/1/0/all/0/1&quot;&gt;Thanh V. Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wong_R/0/1/0/all/0/1&quot;&gt;Raymond K. W. Wong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hegde_C/0/1/0/all/0/1&quot;&gt;Chinmay Hegde&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.04368">
<title>Machine vs Machine: Minimax-Optimal Defense Against Adversarial Examples. (arXiv:1711.04368v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1711.04368</link>
<description rdf:parseType="Literal">&lt;p&gt;Recently, researchers have discovered that the state-of-the-art object
classifiers can be fooled easily by small perturbations in the input
unnoticeable to human eyes. It is known that an attacker can generate strong
adversarial examples if she knows the classifier parameters. Conversely, a
defender can robustify the classifier by retraining if she has the adversarial
examples. The cat-and-mouse game nature of attacks and defenses raises the
question of the presence of equilibria in the dynamics. In this paper, we
present a neural-network based attack class to approximate a larger but
intractable class of attacks, and formulate the attacker-defender interaction
as a zero-sum leader-follower game. We present sensitivity-penalized
optimization algorithms to find minimax solutions, which are the best
worst-case defenses against whitebox attacks. Advantages of the learning-based
attacks and defenses compared to gradient-based attacks and defenses are
demonstrated with MNIST and CIFAR-10.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hamm_J/0/1/0/all/0/1&quot;&gt;Jihun Hamm&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.02629">
<title>Differentially Private Variational Dropout. (arXiv:1712.02629v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1712.02629</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep neural networks with their large number of parameters are highly
flexible learning systems. The high flexibility in such networks brings with
some serious problems such as overfitting, and regularization is used to
address this problem. A currently popular and effective regularization
technique for controlling the overfitting is dropout. Often, large data
collections required for neural networks contain sensitive information such as
the medical histories of patients, and the privacy of the training data should
be protected. In this paper, we modify the recently proposed variational
dropout technique which provided an elegant Bayesian interpretation to dropout,
and show that the intrinsic noise in the variational dropout can be exploited
to obtain a degree of differential privacy. The iterative nature of training
neural networks presents a challenge for privacy-preserving estimation since
multiple iterations increase the amount of noise added. We overcome this by
using a relaxed notion of differential privacy, called concentrated
differential privacy, which provides tighter estimates on the overall privacy
loss. We demonstrate the accuracy of our privacy-preserving variational dropout
algorithm on benchmark datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ermis_B/0/1/0/all/0/1&quot;&gt;Beyza Ermis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Cemgil_A/0/1/0/all/0/1&quot;&gt;Ali Taylan Cemgil&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1706.06969">
<title>Comparing deep neural networks against humans: object recognition when the signal gets weaker. (arXiv:1706.06969v1 [cs.CV] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1706.06969</link>
<description rdf:parseType="Literal">&lt;p&gt;Human visual object recognition is typically rapid and seemingly effortless,
as well as largely independent of viewpoint and object orientation. Until very
recently, animate visual systems were the only ones capable of this remarkable
computational feat. This has changed with the rise of a class of computer
vision algorithms called deep neural networks (DNNs) that achieve human-level
classification performance on object recognition tasks. Furthermore, a growing
number of studies report similarities in the way DNNs and the human visual
system process objects, suggesting that current DNNs may be good models of
human visual object recognition. Yet there clearly exist important
architectural and processing differences between state-of-the-art DNNs and the
primate visual system. The potential behavioural consequences of these
differences are not well understood. We aim to address this issue by comparing
human and DNN generalisation abilities towards image degradations. We find the
human visual system to be more robust to image manipulations like contrast
reduction, additive noise or novel eidolon-distortions. In addition, we find
progressively diverging classification error-patterns between man and DNNs when
the signal gets weaker, indicating that there may still be marked differences
in the way humans and current DNNs perform visual object recognition. We
envision that our findings as well as our carefully measured and freely
available behavioural datasets provide a new useful benchmark for the computer
vision community to improve the robustness of DNNs and a motivation for
neuroscientists to search for mechanisms in the brain that could facilitate
this robustness.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Geirhos_R/0/1/0/all/0/1&quot;&gt;Robert Geirhos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Janssen_D/0/1/0/all/0/1&quot;&gt;David H. J. Janssen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schutt_H/0/1/0/all/0/1&quot;&gt;Heiko H. Sch&amp;#xfc;tt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rauber_J/0/1/0/all/0/1&quot;&gt;Jonas Rauber&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bethge_M/0/1/0/all/0/1&quot;&gt;Matthias Bethge&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wichmann_F/0/1/0/all/0/1&quot;&gt;Felix A. Wichmann&lt;/a&gt;</dc:creator>
</item></rdf:RDF>