<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Good papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Good Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-03-06T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.01900"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.01937"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.02088"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.02097"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.02208"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.02291"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.02324"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.01840"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.01968"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.02021"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.02108"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.02247"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.02323"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.02329"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1803.01900">
<title>Style Memory: Making a Classifier Network Generative. (arXiv:1803.01900v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1803.01900</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep networks have shown great performance in classification tasks. However,
the parameters learned by the classifier networks usually discard stylistic
information of the input, in favour of information strictly relevant to
classification. We introduce a network that has the capacity to do both
classification and reconstruction by adding a &quot;style memory&quot; to the output
layer of the network. We also show how to train such a neural network as a deep
multi-layer autoencoder, jointly minimizing both classification and
reconstruction losses. The generative capacity of our network demonstrates that
the combination of style-memory neurons with the classifier neurons yield good
reconstructions of the inputs when the classification is correct. We further
investigate the nature of the style memory, and how it relates to composing
digits and letters. Finally, we propose that this architecture enables the
bidirectional flow of information used in predictive coding, and that such
bidirectional networks can help mitigate against being fooled by ambiguous or
adversarial input.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wiyatno_R/0/1/0/all/0/1&quot;&gt;Rey Wiyatno&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Orchard_J/0/1/0/all/0/1&quot;&gt;Jeff Orchard&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.01937">
<title>ROUGE 2.0: Updated and Improved Measures for Evaluation of Summarization Tasks. (arXiv:1803.01937v1 [cs.IR])</title>
<link>http://arxiv.org/abs/1803.01937</link>
<description rdf:parseType="Literal">&lt;p&gt;Evaluation of summarization tasks is extremely crucial to determining the
quality of machine generated summaries. Over the last decade, ROUGE has become
the standard automatic evaluation measure for evaluating summarization tasks.
While ROUGE has been shown to be effective in capturing n-gram overlap between
system and human composed summaries, there are several limitations with the
existing ROUGE measures in terms of capturing synonymous concepts and coverage
of topics. Thus, often times ROUGE scores do not reflect the true quality of
summaries and prevents multi-faceted evaluation of summaries (i.e. by topics,
by overall content coverage and etc). In this paper, we introduce ROUGE 2.0,
which has several updated measures of ROUGE: ROUGE-N+Synonyms, ROUGE-Topic,
ROUGE-Topic+Synonyms, ROUGE-TopicUniq and ROUGE-TopicUniq+Synonyms; all of
which are improvements over the core ROUGE measures.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ganesan_K/0/1/0/all/0/1&quot;&gt;Kavita Ganesan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.02088">
<title>Explain Yourself: A Natural Language Interface for Scrutable Autonomous Robots. (arXiv:1803.02088v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1803.02088</link>
<description rdf:parseType="Literal">&lt;p&gt;Autonomous systems in remote locations have a high degree of autonomy and
there is a need to explain what they are doing and why in order to increase
transparency and maintain trust. Here, we describe a natural language chat
interface that enables vehicle behaviour to be queried by the user. We obtain
an interpretable model of autonomy through having an expert &apos;speak out-loud&apos;
and provide explanations during a mission. This approach is agnostic to the
type of autonomy model and as expert and operator are from the same user-group,
we predict that these explanations will align well with the operator&apos;s mental
model, increase transparency and assist with operator training.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garcia_F/0/1/0/all/0/1&quot;&gt;Francisco J. Chiyah Garcia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Robb_D/0/1/0/all/0/1&quot;&gt;David A. Robb&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1&quot;&gt;Xingkun Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Laskov_A/0/1/0/all/0/1&quot;&gt;Atanas Laskov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Patron_P/0/1/0/all/0/1&quot;&gt;Pedro Patron&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hastie_H/0/1/0/all/0/1&quot;&gt;Helen Hastie&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.02097">
<title>Where is my Device? - Detecting the Smart Device&apos;s Wearing Location in the Context of Active Safety for Vulnerable Road Users. (arXiv:1803.02097v1 [cs.HC])</title>
<link>http://arxiv.org/abs/1803.02097</link>
<description rdf:parseType="Literal">&lt;p&gt;This article describes an approach to detect the wearing location of smart
devices worn by pedestrians and cyclists. The detection, which is based solely
on the sensors of the smart devices, is important context-information which can
be used to parametrize subsequent algorithms, e.g. for dead reckoning or
intention detection to improve the safety of vulnerable road users. The wearing
location recognition can in terms of Organic Computing (OC) be seen as a step
towards self-awareness and self-adaptation. For the wearing location detection
a two-stage process is presented. It is subdivided into moving detection
followed by the wearing location classification. Finally, the approach is
evaluated on a real world dataset consisting of pedestrians and cyclists.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bieshaar_M/0/1/0/all/0/1&quot;&gt;Maarten Bieshaar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.02208">
<title>Discovering Underlying Plans Based on Shallow Models. (arXiv:1803.02208v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1803.02208</link>
<description rdf:parseType="Literal">&lt;p&gt;Plan recognition aims to discover target plans (i.e., sequences of actions)
behind observed actions, with history plan libraries or domain models in hand.
Previous approaches either discover plans by maximally &quot;matching&quot; observed
actions to plan libraries, assuming target plans are from plan libraries, or
infer plans by executing domain models to best explain the observed actions,
assuming that complete domain models are available. In real world applications,
however, target plans are often not from plan libraries, and complete domain
models are often not available, since building complete sets of plans and
complete domain models are often difficult or expensive. In this paper we view
plan libraries as corpora and learn vector representations of actions using the
corpora, we then discover target plans based on the vector representations.
Specifically, we propose two approaches, DUP and RNNPlanner, to discover target
plans based on vector representations of actions. DUP explores the EM-style
framework to capture local contexts of actions and discover target plans by
optimizing the probability of target plans, while RNNPlanner aims to leverage
long-short term contexts of actions based on RNNs (recurrent neural networks)
framework to help recognize target plans. In the experiments, we empirically
show that our approaches are capable of discovering underlying plans that are
not from plan libraries, without requiring domain models provided. We
demonstrate the effectiveness of our approaches by comparing its performance to
traditional plan recognition approaches in three planning domains. We also
compare DUP and RNNPlanner to see their advantages and disadvantages.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhuo_H/0/1/0/all/0/1&quot;&gt;Hankz Hankui Zhuo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zha_Y/0/1/0/all/0/1&quot;&gt;Yantian Zha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kambhampati_S/0/1/0/all/0/1&quot;&gt;Subbarao Kambhampati&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.02291">
<title>Synthesizing Neural Network Controllers with Probabilistic Model based Reinforcement Learning. (arXiv:1803.02291v1 [cs.RO])</title>
<link>http://arxiv.org/abs/1803.02291</link>
<description rdf:parseType="Literal">&lt;p&gt;We present an algorithm for rapidly learning controllers for robotics
systems. The algorithm follows the model-based reinforcement learning paradigm,
and improves upon existing algorithms; namely Probabilistic learning in Control
(PILCO) and a sample-based version of PILCO with neural network dynamics
(Deep-PILCO). We propose training a neural network dynamics model using
variational dropout with truncated Log-Normal noise. This allows us to obtain a
dynamics model with calibrated uncertainty, which can be used to simulate
controller executions via rollouts. We also describe set of techniques,
inspired by viewing PILCO as a recurrent neural network model, that are crucial
to improve the convergence of the method. We test our method on a variety of
benchmark tasks, demonstrating data-efficiency that is competitive with PILCO,
while being able to optimize complex neural network controllers. Finally, we
assess the performance of the algorithm for learning motor controllers for a
six legged autonomous underwater vehicle. This demonstrates the potential of
the algorithm for scaling up the dimensionality and dataset sizes, in more
complex control tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Higuera_J/0/1/0/all/0/1&quot;&gt;Juan Camilo Gamboa Higuera&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meger_D/0/1/0/all/0/1&quot;&gt;David Meger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dudek_G/0/1/0/all/0/1&quot;&gt;Gregory Dudek&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.02324">
<title>Annotation Artifacts in Natural Language Inference Data. (arXiv:1803.02324v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1803.02324</link>
<description rdf:parseType="Literal">&lt;p&gt;Large-scale datasets for natural language inference are created by presenting
crowd workers with a sentence (premise), and asking them to generate three new
sentences (hypotheses) that it entails, contradicts, or is logically neutral
with respect to. We show that, in a significant portion of such data, this
protocol leaves clues that make it possible to identify the label by looking
only at the hypothesis, without observing the premise. Specifically, we show
that a simple text categorization model can correctly classify the hypothesis
alone in about 67% of SNLI (Bowman et. al, 2015) and 53% of MultiNLI (Williams
et. al, 2017). Our analysis reveals that specific linguistic phenomena such as
negation and vagueness are highly correlated with certain inference classes.
Our findings suggest that the success of natural language inference models to
date has been overestimated, and that the task remains a hard open problem.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gururangan_S/0/1/0/all/0/1&quot;&gt;Suchin Gururangan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Swayamdipta_S/0/1/0/all/0/1&quot;&gt;Swabha Swayamdipta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Levy_O/0/1/0/all/0/1&quot;&gt;Omer Levy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schwartz_R/0/1/0/all/0/1&quot;&gt;Roy Schwartz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bowman_S/0/1/0/all/0/1&quot;&gt;Samuel R. Bowman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Smith_N/0/1/0/all/0/1&quot;&gt;Noah A. Smith&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.01840">
<title>TACO: Learning Task Decomposition via Temporal Alignment for Control. (arXiv:1803.01840v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1803.01840</link>
<description rdf:parseType="Literal">&lt;p&gt;Many advanced Learning from Demonstration (LfD) methods consider the
decomposition of complex, real-world tasks into simpler sub-tasks. By reusing
the corresponding sub-policies within and between tasks, they provide training
data for each policy from different high-level tasks and compose them to
perform novel ones. Existing approaches to modular LfD focus either on learning
a single high-level task or depend on domain knowledge and temporal
segmentation. In contrast, we propose a weakly supervised, domain-agnostic
approach based on task sketches, which include only the sequence of sub-tasks
performed in each demonstration. Our approach simultaneously aligns the
sketches with the observed demonstrations and learns the required sub-policies.
This improves generalisation in comparison to separate optimisation procedures.
We evaluate the approach on multiple domains, including a simulated 3D robot
arm control task using purely image-based observations. The results show that
our approach performs commensurately with fully supervised approaches, while
requiring significantly less annotation effort.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shiarlis_K/0/1/0/all/0/1&quot;&gt;Kyriacos Shiarlis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wulfmeier_M/0/1/0/all/0/1&quot;&gt;Markus Wulfmeier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Salter_S/0/1/0/all/0/1&quot;&gt;Sasha Salter&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Whiteson_S/0/1/0/all/0/1&quot;&gt;Shimon Whiteson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Posner_I/0/1/0/all/0/1&quot;&gt;Ingmar Posner&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.01968">
<title>An Online Algorithm for Learning Buyer Behavior under Realistic Pricing Restrictions. (arXiv:1803.01968v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1803.01968</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a new efficient online algorithm to learn the parameters governing
the purchasing behavior of a utility maximizing buyer, who responds to prices,
in a repeated interaction setting. The key feature of our algorithm is that it
can learn even non-linear buyer utility while working with arbitrary price
constraints that the seller may impose. This overcomes a major shortcoming of
previous approaches, which use unrealistic prices to learn these parameters
making them unsuitable in practice.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Saharoy_D/0/1/0/all/0/1&quot;&gt;Debjyoti Saharoy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tulabandhula_T/0/1/0/all/0/1&quot;&gt;Theja Tulabandhula&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.02021">
<title>Understanding Short-Horizon Bias in Stochastic Meta-Optimization. (arXiv:1803.02021v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1803.02021</link>
<description rdf:parseType="Literal">&lt;p&gt;Careful tuning of the learning rate, or even schedules thereof, can be
crucial to effective neural net training. There has been much recent interest
in gradient-based meta-optimization, where one tunes hyperparameters, or even
learns an optimizer, in order to minimize the expected loss when the training
procedure is unrolled. But because the training procedure must be unrolled
thousands of times, the meta-objective must be defined with an
orders-of-magnitude shorter time horizon than is typical for neural net
training. We show that such short-horizon meta-objectives cause a serious bias
towards small step sizes, an effect we term short-horizon bias. We introduce a
toy problem, a noisy quadratic cost function, on which we analyze short-horizon
bias by deriving and comparing the optimal schedules for short and long time
horizons. We then run meta-optimization experiments (both offline and online)
on standard benchmark datasets, showing that meta-optimization chooses too
small a learning rate by multiple orders of magnitude, even when run with a
moderately long time horizon (100 steps) typical of work in the area. We
believe short-horizon bias is a fundamental problem that needs to be addressed
if meta-optimization is to scale to practical neural net training regimes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1&quot;&gt;Yuhuai Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ren_M/0/1/0/all/0/1&quot;&gt;Mengye Ren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liao_R/0/1/0/all/0/1&quot;&gt;Renjie Liao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grosse_R/0/1/0/all/0/1&quot;&gt;Roger Grosse&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.02108">
<title>HexaConv. (arXiv:1803.02108v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1803.02108</link>
<description rdf:parseType="Literal">&lt;p&gt;The effectiveness of Convolutional Neural Networks stems in large part from
their ability to exploit the translation invariance that is inherent in many
learning problems. Recently, it was shown that CNNs can exploit other
invariances, such as rotation invariance, by using group convolutions instead
of planar convolutions. However, for reasons of performance and ease of
implementation, it has been necessary to limit the group convolution to
transformations that can be applied to the filters without interpolation. Thus,
for images with square pixels, only integer translations, rotations by
multiples of 90 degrees, and reflections are admissible.
&lt;/p&gt;
&lt;p&gt;Whereas the square tiling provides a 4-fold rotational symmetry, a hexagonal
tiling of the plane has a 6-fold rotational symmetry. In this paper we show how
one can efficiently implement planar convolution and group convolution over
hexagonal lattices, by re-using existing highly optimized convolution routines.
We find that, due to the reduced anisotropy of hexagonal filters, planar
HexaConv provides better accuracy than planar convolution with square filters,
given a fixed parameter budget. Furthermore, we find that the increased degree
of symmetry of the hexagonal grid increases the effectiveness of group
convolutions, by allowing for more parameter sharing. We show that our method
significantly outperforms conventional CNNs on the AID aerial scene
classification dataset, even outperforming ImageNet pre-trained models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hoogeboom_E/0/1/0/all/0/1&quot;&gt;Emiel Hoogeboom&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peters_J/0/1/0/all/0/1&quot;&gt;Jorn W.T. Peters&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cohen_T/0/1/0/all/0/1&quot;&gt;Taco S. Cohen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Welling_M/0/1/0/all/0/1&quot;&gt;Max Welling&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.02247">
<title>MIMO Graph Filters for Convolutional Neural Networks. (arXiv:1803.02247v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1803.02247</link>
<description rdf:parseType="Literal">&lt;p&gt;Superior performance and ease of implementation have fostered the adoption of
Convolutional Neural Networks (CNNs) for a wide array of inference and
reconstruction tasks. CNNs implement three basic blocks: convolution, pooling
and pointwise nonlinearity. Since the two first operations are well-defined
only on regular-structured data such as audio or images, application of CNNs to
contemporary datasets where the information is defined in irregular domains is
challenging. This paper investigates CNNs architectures to operate on signals
whose support can be modeled using a graph. Architectures that replace the
regular convolution with a so-called linear shift-invariant graph filter have
been recently proposed. This paper goes one step further and, under the
framework of multiple-input multiple-output (MIMO) graph filters, imposes
additional structure on the adopted graph filters, to obtain three new (more
parsimonious) architectures. The proposed architectures result in a lower
number of model parameters, reducing the computational complexity, facilitating
the training, and mitigating the risk of overfitting. Simulations show that the
proposed simpler architectures achieve similar performance as more complex
models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gama_F/0/1/0/all/0/1&quot;&gt;Fernando Gama&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Marques_A/0/1/0/all/0/1&quot;&gt;Antonio G. Marques&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ribeiro_A/0/1/0/all/0/1&quot;&gt;Alejandro Ribeiro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leus_G/0/1/0/all/0/1&quot;&gt;Geert Leus&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.02323">
<title>Deep Super Learner: A Deep Ensemble for Classification Problems. (arXiv:1803.02323v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1803.02323</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep learning has become very popular for tasks such as predictive modeling
and pattern recognition in handling big data. Deep learning is a powerful
machine learning method that extracts lower level features and feeds them
forward for the next layer to identify higher level features that improve
performance. However, deep neural networks have drawbacks, which include many
hyper-parameters and infinite architectures, opaqueness into results, and
relatively slower convergence on smaller datasets. While traditional machine
learning algorithms can address these drawbacks, they are not typically capable
of the performance levels achieved by deep neural networks. To improve
performance, ensemble methods are used to combine multiple base learners. Super
learning is an ensemble that finds the optimal combination of diverse learning
algorithms. This paper proposes deep super learning as an approach which
achieves log loss and accuracy results competitive to deep neural networks
while employing traditional machine learning algorithms in a hierarchical
structure. The deep super learner is flexible, adaptable, and easy to train
with good performance across different tasks using identical hyper-parameter
values. Using traditional machine learning requires fewer hyper-parameters,
allows transparency into results, and has relatively fast convergence on
smaller datasets. Experimental results show that the deep super learner has
superior performance compared to the individual base learners, single-layer
ensembles, and in some cases deep neural networks. Performance of the deep
super learner may further be improved with task-specific tuning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Young_S/0/1/0/all/0/1&quot;&gt;Steven Young&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abdou_T/0/1/0/all/0/1&quot;&gt;Tamer Abdou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bener_A/0/1/0/all/0/1&quot;&gt;Ayse Bener&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.02329">
<title>Learning Memory Access Patterns. (arXiv:1803.02329v1 [cs.AR])</title>
<link>http://arxiv.org/abs/1803.02329</link>
<description rdf:parseType="Literal">&lt;p&gt;The explosion in workload complexity and the recent slow-down in Moore&apos;s law
scaling call for new approaches towards efficient computing. Researchers are
now beginning to use recent advances in machine learning in software
optimizations, augmenting or replacing traditional heuristics and data
structures. However, the space of machine learning for computer hardware
architecture is only lightly explored. In this paper, we demonstrate the
potential of deep learning to address the von Neumann bottleneck of memory
performance. We focus on the critical problem of learning memory access
patterns, with the goal of constructing accurate and efficient memory
prefetchers. We relate contemporary prefetching strategies to n-gram models in
natural language processing, and show how recurrent neural networks can serve
as a drop-in replacement. On a suite of challenging benchmark datasets, we find
that neural networks consistently demonstrate superior performance in terms of
precision and recall. This work represents the first step towards practical
neural-network based prefetching, and opens a wide range of exciting directions
for machine learning in computer architecture research.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hashemi_M/0/1/0/all/0/1&quot;&gt;Milad Hashemi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Swersky_K/0/1/0/all/0/1&quot;&gt;Kevin Swersky&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Smith_J/0/1/0/all/0/1&quot;&gt;Jamie A. Smith&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ayers_G/0/1/0/all/0/1&quot;&gt;Grant Ayers&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Litz_H/0/1/0/all/0/1&quot;&gt;Heiner Litz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chang_J/0/1/0/all/0/1&quot;&gt;Jichuan Chang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kozyrakis_C/0/1/0/all/0/1&quot;&gt;Christos Kozyrakis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ranganathan_P/0/1/0/all/0/1&quot;&gt;Parthasarathy Ranganathan&lt;/a&gt;</dc:creator>
</item></rdf:RDF>