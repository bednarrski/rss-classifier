<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Good papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Good Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-07-22T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.07848"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05438"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.06092"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09701"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.07255"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.06538"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.07752"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1707.02641"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10769"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11063"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11916"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11917"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.05936"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1709.07848">
<title>Multiqubit and multilevel quantum reinforcement learning with quantum technologies. (arXiv:1709.07848v2 [quant-ph] UPDATED)</title>
<link>http://arxiv.org/abs/1709.07848</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a protocol to perform quantum reinforcement learning with quantum
technologies. At variance with recent results on quantum reinforcement learning
with superconducting circuits, in our current protocol coherent feedback during
the learning process is not required, enabling its implementation in a wide
variety of quantum systems. We consider diverse possible scenarios for an
agent, an environment, and a register that connects them, involving multiqubit
and multilevel systems, as well as open-system dynamics. We finally propose
possible implementations of this protocol in trapped ions and superconducting
circuits. The field of quantum reinforcement learning with quantum technologies
will enable enhanced quantum control, as well as more efficient machine
learning calculations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Cardenas_Lopez_F/0/1/0/all/0/1&quot;&gt;F. A. C&amp;#xe1;rdenas-L&amp;#xf3;pez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Lamata_L/0/1/0/all/0/1&quot;&gt;L. Lamata&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Retamal_J/0/1/0/all/0/1&quot;&gt;J. C. Retamal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Solano_E/0/1/0/all/0/1&quot;&gt;E. Solano&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05438">
<title>Mean Field Multi-Agent Reinforcement Learning. (arXiv:1802.05438v4 [cs.MA] UPDATED)</title>
<link>http://arxiv.org/abs/1802.05438</link>
<description rdf:parseType="Literal">&lt;p&gt;Existing multi-agent reinforcement learning methods are limited typically to
a small number of agents. When the agent number increases largely, the learning
becomes intractable due to the curse of the dimensionality and the exponential
growth of agent interactions. In this paper, we present Mean Field
Reinforcement Learning where the interactions within the population of agents
are approximated by those between a single agent and the average effect from
the overall population or neighboring agents; the interplay between the two
entities is mutually reinforced: the learning of the individual agent&apos;s optimal
policy depends on the dynamics of the population, while the dynamics of the
population change according to the collective patterns of the individual
policies. We develop practical mean field Q-learning and mean field
Actor-Critic algorithms and analyze the convergence of the solution to Nash
equilibrium. Experiments on Gaussian squeeze, Ising model, and battle games
justify the learning effectiveness of our mean field approaches. In addition,
we report the first result to solve the Ising model via model-free
reinforcement learning methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1&quot;&gt;Yaodong Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_R/0/1/0/all/0/1&quot;&gt;Rui Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1&quot;&gt;Minne Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1&quot;&gt;Ming Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1&quot;&gt;Weinan Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jun Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.06092">
<title>A Dataset and Architecture for Visual Reasoning with a Working Memory. (arXiv:1803.06092v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1803.06092</link>
<description rdf:parseType="Literal">&lt;p&gt;A vexing problem in artificial intelligence is reasoning about events that
occur in complex, changing visual stimuli such as in video analysis or game
play. Inspired by a rich tradition of visual reasoning and memory in cognitive
psychology and neuroscience, we developed an artificial, configurable visual
question and answer dataset (COG) to parallel experiments in humans and
animals. COG is much simpler than the general problem of video analysis, yet it
addresses many of the problems relating to visual and logical reasoning and
memory -- problems that remain challenging for modern deep learning
architectures. We additionally propose a deep learning architecture that
performs competitively on other diagnostic VQA datasets (i.e. CLEVR) as well as
easy settings of the COG dataset. However, several settings of COG result in
datasets that are progressively more challenging to learn. After training, the
network can zero-shot generalize to many new tasks. Preliminary analyses of the
network architectures trained on COG demonstrate that the network accomplishes
the task in a manner interpretable to humans.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_G/0/1/0/all/0/1&quot;&gt;Guangyu Robert Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ganichev_I/0/1/0/all/0/1&quot;&gt;Igor Ganichev&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;Xiao-Jing Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shlens_J/0/1/0/all/0/1&quot;&gt;Jonathon Shlens&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sussillo_D/0/1/0/all/0/1&quot;&gt;David Sussillo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09701">
<title>R-VQA: Learning Visual Relation Facts with Semantic Attention for Visual Question Answering. (arXiv:1805.09701v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1805.09701</link>
<description rdf:parseType="Literal">&lt;p&gt;Recently, Visual Question Answering (VQA) has emerged as one of the most
significant tasks in multimodal learning as it requires understanding both
visual and textual modalities. Existing methods mainly rely on extracting image
and question features to learn their joint feature embedding via multimodal
fusion or attention mechanism. Some recent studies utilize external
VQA-independent models to detect candidate entities or attributes in images,
which serve as semantic knowledge complementary to the VQA task. However, these
candidate entities or attributes might be unrelated to the VQA task and have
limited semantic capacities. To better utilize semantic knowledge in images, we
propose a novel framework to learn visual relation facts for VQA. Specifically,
we build up a Relation-VQA (R-VQA) dataset based on the Visual Genome dataset
via a semantic similarity module, in which each data consists of an image, a
corresponding question, a correct answer and a supporting relation fact. A
well-defined relation detector is then adopted to predict visual
question-related relation facts. We further propose a multi-step attention
model composed of visual attention and semantic attention sequentially to
extract related visual knowledge and semantic knowledge. We conduct
comprehensive experiments on the two benchmark datasets, demonstrating that our
model achieves state-of-the-art performance and verifying the benefit of
considering visual relation facts.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_P/0/1/0/all/0/1&quot;&gt;Pan Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ji_L/0/1/0/all/0/1&quot;&gt;Lei Ji&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1&quot;&gt;Wei Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Duan_N/0/1/0/all/0/1&quot;&gt;Nan Duan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1&quot;&gt;Ming Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jianyong Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.07255">
<title>Towards Explainable and Controllable Open Domain Dialogue Generation with Dialogue Acts. (arXiv:1807.07255v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1807.07255</link>
<description rdf:parseType="Literal">&lt;p&gt;We study open domain dialogue generation with dialogue acts designed to
explain how people engage in social chat. To imitate human behavior, we propose
managing the flow of human-machine interactions with the dialogue acts as
policies. The policies and response generation are jointly learned from
human-human conversations, and the former is further optimized with a
reinforcement learning approach. With the dialogue acts, we achieve significant
improvement over state-of-the-art methods on response quality for given
contexts and dialogue length in both machine-machine simulation and
human-machine conversation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1&quot;&gt;Can Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_W/0/1/0/all/0/1&quot;&gt;Wei Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1&quot;&gt;Yu Wu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.06538">
<title>Pseudo-Feature Generation for Imbalanced Data Analysis in Deep Learning. (arXiv:1807.06538v2 [cs.LG] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1807.06538</link>
<description rdf:parseType="Literal">&lt;p&gt;We generate pseudo-features by multivariate probability distributions
obtained from feature maps in a low layer of trained deep neural networks.
Then, we virtually augment the data of minor classes by the pseudo-features in
order to overcome imbalanced data problems. Because all the wild data are
imbalanced, the proposed method has the possibility to improve the ability of
DNN in a broad range of problems
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Konno_T/0/1/0/all/0/1&quot;&gt;Tomohiko Konno&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Iwazume_M/0/1/0/all/0/1&quot;&gt;Michiaki Iwazume&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.07752">
<title>Twitter Sentiment Analysis System. (arXiv:1807.07752v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1807.07752</link>
<description rdf:parseType="Literal">&lt;p&gt;Social media is increasingly used by humans to express their feelings and
opinions in the form of short text messages. Detecting sentiments in the text
has a wide range of applications including identifying anxiety or depression of
individuals and measuring well-being or mood of a community. Sentiments can be
expressed in many ways that can be seen such as facial expression and gestures,
speech and by written text. Sentiment Analysis in text documents is essentially
a content-based classification problem involving concepts from the domains of
Natural Language Processing as well as Machine Learning. In this paper,
sentiment recognition based on textual data and the techniques used in
sentiment analysis are discussed.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Joshi_S/0/1/0/all/0/1&quot;&gt;Shaunak Joshi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deshpande_D/0/1/0/all/0/1&quot;&gt;Deepali Deshpande&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1707.02641">
<title>Automated versus do-it-yourself methods for causal inference: Lessons learned from a data analysis competition. (arXiv:1707.02641v5 [stat.ME] UPDATED)</title>
<link>http://arxiv.org/abs/1707.02641</link>
<description rdf:parseType="Literal">&lt;p&gt;Statisticians have made great progress in creating methods that reduce our
reliance on parametric assumptions. However this explosion in research has
resulted in a breadth of inferential strategies that both create opportunities
for more reliable inference as well as complicate the choices that an applied
researcher has to make and defend. Relatedly, researchers advocating for new
methods typically compare their method to at best 2 or 3 other causal inference
strategies and test using simulations that may or may not be designed to
equally tease out flaws in all the competing methods. The causal inference data
analysis challenge, &quot;Is Your SATT Where It&apos;s At?&quot;, launched as part of the 2016
Atlantic Causal Inference Conference, sought to make progress with respect to
both of these issues. The researchers creating the data testing grounds were
distinct from the researchers submitting methods whose efficacy would be
evaluated. Results from 30 competitors across the two versions of the
competition (black box algorithms and do-it-yourself analyses) are presented
along with post-hoc analyses that reveal information about the characteristics
of causal inference strategies and settings that affect performance. The most
consistent conclusion was that methods that flexibly model the response surface
perform better overall than methods that fail to do so. Finally new methods are
proposed that combine features of several of the top-performing submitted
methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Dorie_V/0/1/0/all/0/1&quot;&gt;Vincent Dorie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hill_J/0/1/0/all/0/1&quot;&gt;Jennifer Hill&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Shalit_U/0/1/0/all/0/1&quot;&gt;Uri Shalit&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Scott_M/0/1/0/all/0/1&quot;&gt;Marc Scott&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Cervone_D/0/1/0/all/0/1&quot;&gt;Dan Cervone&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.10769">
<title>Universality of Deep Convolutional Neural Networks. (arXiv:1805.10769v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.10769</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep learning has been widely applied and brought breakthroughs in speech
recognition, computer vision, and many other domains. The involved deep neural
network architectures and computational issues have been well studied in
machine learning. But there lacks a theoretical foundation for understanding
the approximation or generalization ability of deep learning methods generated
by the network architectures such as deep convolutional neural networks having
convolutional structures. Here we show that a deep convolutional neural network
(CNN) is universal, meaning that it can be used to approximate any continuous
function to an arbitrary accuracy when the depth of the neural network is large
enough. This answers an open question in learning theory. Our quantitative
estimate, given tightly in terms of the number of free parameters to be
computed, verifies the efficiency of deep CNNs in dealing with large
dimensional data. Our study also demonstrates the role of convolutions in deep
CNNs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_D/0/1/0/all/0/1&quot;&gt;Ding-Xuan Zhou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11063">
<title>Theory and Experiments on Vector Quantized Autoencoders. (arXiv:1805.11063v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.11063</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep neural networks with discrete latent variables offer the promise of
better symbolic reasoning, and learning abstractions that are more useful to
new tasks. There has been a surge in interest in discrete latent variable
models, however, despite several recent improvements, the training of discrete
latent variable models has remained challenging and their performance has
mostly failed to match their continuous counterparts. Recent work on vector
quantized autoencoders (VQ-VAE) has made substantial progress in this
direction, with its perplexity almost matching that of a VAE on datasets such
as CIFAR-10. In this work, we investigate an alternate training technique for
VQ-VAE, inspired by its connection to the Expectation Maximization (EM)
algorithm. Training the discrete bottleneck with EM helps us achieve better
image generation results on CIFAR-10, and together with knowledge distillation,
allows us to develop a non-autoregressive machine translation model whose
accuracy almost matches a strong greedy autoregressive baseline Transformer,
while being 3.3 times faster at inference.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roy_A/0/1/0/all/0/1&quot;&gt;Aurko Roy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vaswani_A/0/1/0/all/0/1&quot;&gt;Ashish Vaswani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Neelakantan_A/0/1/0/all/0/1&quot;&gt;Arvind Neelakantan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Parmar_N/0/1/0/all/0/1&quot;&gt;Niki Parmar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11916">
<title>On the Spectrum of Random Features Maps of High Dimensional Data. (arXiv:1805.11916v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1805.11916</link>
<description rdf:parseType="Literal">&lt;p&gt;Random feature maps are ubiquitous in modern statistical machine learning,
where they generalize random projections by means of powerful, yet often
difficult to analyze nonlinear operators. In this paper, we leverage the
&quot;concentration&quot; phenomenon induced by random matrix theory to perform a
spectral analysis on the Gram matrix of these random feature maps, here for
Gaussian mixture models of simultaneously large dimension and size. Our results
are instrumental to a deeper understanding on the interplay of the nonlinearity
and the statistics of the data, thereby allowing for a better tuning of random
feature-based techniques.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Liao_Z/0/1/0/all/0/1&quot;&gt;Zhenyu Liao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Couillet_R/0/1/0/all/0/1&quot;&gt;Romain Couillet&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11917">
<title>The Dynamics of Learning: A Random Matrix Approach. (arXiv:1805.11917v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1805.11917</link>
<description rdf:parseType="Literal">&lt;p&gt;Understanding the learning dynamics of neural networks is one of the key
issues for the improvement of optimization algorithms as well as for the
theoretical comprehension of why deep neural nets work so well today. In this
paper, we introduce a random matrix-based framework to analyze the learning
dynamics of a single-layer linear network on a binary classification problem,
for data of simultaneously large dimension and size, trained by gradient
descent. Our results provide rich insights into common questions in neural
nets, such as overfitting, early stopping and the initialization of training,
thereby opening the door for future studies of more elaborate structures and
models appearing in today&apos;s neural networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Liao_Z/0/1/0/all/0/1&quot;&gt;Zhenyu Liao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Couillet_R/0/1/0/all/0/1&quot;&gt;Romain Couillet&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.05936">
<title>Variational Inference: A Unified Framework of Generative Models and Some Revelations. (arXiv:1807.05936v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1807.05936</link>
<description rdf:parseType="Literal">&lt;p&gt;We reinterpreting the variational inference in a new perspective. Via this
way, we can easily prove that EM algorithm, VAE, GAN, AAE, ALI(BiGAN) are all
special cases of variational inference. The proof also reveals the loss of
standard GAN is incomplete and it explains why we need to train GAN cautiously.
From that, we find out a regularization term to improve stability of GAN
training.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Su_J/0/1/0/all/0/1&quot;&gt;Jianlin Su&lt;/a&gt;</dc:creator>
</item></rdf:RDF>