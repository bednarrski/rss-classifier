<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Good papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Good Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-07-23T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.08133"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.08194"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.08655"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1705.04378"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.07964"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.08169"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.08195"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.08217"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.08312"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.08325"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.08360"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.08364"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.08372"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.08405"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.08452"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.08595"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.08712"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1705.06366"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.04247"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.10755"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.07147"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.07959"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.07963"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.07998"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.08140"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.08197"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.08207"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.08241"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.08383"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.08501"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.08518"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.08666"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.08669"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.08706"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1705.07204"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.02903"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.03308"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.10574"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.00108"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.00119"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09461"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.00745"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.01961"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1807.08133">
<title>What is not where: the challenge of integrating spatial representations into deep learning architectures. (arXiv:1807.08133v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.08133</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper examines to what degree current deep learning architectures for
image caption generation capture spatial language. On the basis of the
evaluation of examples of generated captions from the literature we argue that
systems capture what objects are in the image data but not where these objects
are located: the captions generated by these systems are the output of a
language model conditioned on the output of an object detector that cannot
capture fine-grained location information. Although language models provide
useful knowledge for image captions, we argue that deep learning image
captioning architectures should also model geometric relations between objects.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kelleher_J/0/1/0/all/0/1&quot;&gt;John D. Kelleher&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dobnik_S/0/1/0/all/0/1&quot;&gt;Simon Dobnik&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.08194">
<title>Towards Distributed Coevolutionary GANs. (arXiv:1807.08194v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1807.08194</link>
<description rdf:parseType="Literal">&lt;p&gt;Generative Adversarial Networks (GANs) have become one of the dominant
methods for deep generative modeling. Despite their demonstrated success on
multiple vision tasks, GANs are difficult to train and much research has been
dedicated towards understanding and improving their gradient-based learning
dynamics. Here, we investigate the use of coevolution, a class of black-box
(gradient-free) co-optimization techniques and a powerful tool in evolutionary
computing, as a supplement to gradient-based GAN training techniques.
Experiments on a simple model that exhibits several of the GAN gradient-based
dynamics (e.g., mode collapse, oscillatory behavior, and vanishing gradients)
show that coevolution is a promising framework for escaping degenerate GAN
training behaviors.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schmiedlechner_T/0/1/0/all/0/1&quot;&gt;Tom Schmiedlechner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Al_Dujaili_A/0/1/0/all/0/1&quot;&gt;Abdullah Al-Dujaili&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hemberg_E/0/1/0/all/0/1&quot;&gt;Erik Hemberg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+OReilly_U/0/1/0/all/0/1&quot;&gt;Una-May O&amp;#x27;Reilly&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.08655">
<title>Training Humans and Machines. (arXiv:1807.08655v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1807.08655</link>
<description rdf:parseType="Literal">&lt;p&gt;For many years, researchers in psychology, education, statistics, and machine
learning have been developing practical methods to improve learning speed,
retention, and generalizability, and this work has been successful. Many of
these methods are rooted in common underlying principles that seem to drive
learning and overlearning in both humans and machines. I present a review of a
small part of this work to point to potentially novel applications in both
machine and human learning that may be worth exploring.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nikolaidis_A/0/1/0/all/0/1&quot;&gt;Aki Nikolaidis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1705.04378">
<title>An overview and comparative analysis of Recurrent Neural Networks for Short Term Load Forecasting. (arXiv:1705.04378v2 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1705.04378</link>
<description rdf:parseType="Literal">&lt;p&gt;The key component in forecasting demand and consumption of resources in a
supply network is an accurate prediction of real-valued time series. Indeed,
both service interruptions and resource waste can be reduced with the
implementation of an effective forecasting system. Significant research has
thus been devoted to the design and development of methodologies for short term
load forecasting over the past decades. A class of mathematical models, called
Recurrent Neural Networks, are nowadays gaining renewed interest among
researchers and they are replacing many practical implementation of the
forecasting systems, previously based on static methods. Despite the undeniable
expressive power of these architectures, their recurrent nature complicates
their understanding and poses challenges in the training procedures. Recently,
new important families of recurrent architectures have emerged and their
applicability in the context of load forecasting has not been investigated
completely yet. In this paper we perform a comparative study on the problem of
Short-Term Load Forecast, by using different classes of state-of-the-art
Recurrent Neural Networks. We test the reviewed models first on controlled
synthetic tasks and then on different real datasets, covering important
practical cases of study. We provide a general overview of the most important
architectures and we define guidelines for configuring the recurrent networks
to predict real-valued time series.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bianchi_F/0/1/0/all/0/1&quot;&gt;Filippo Maria Bianchi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Maiorino_E/0/1/0/all/0/1&quot;&gt;Enrico Maiorino&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kampffmeyer_M/0/1/0/all/0/1&quot;&gt;Michael C. Kampffmeyer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rizzi_A/0/1/0/all/0/1&quot;&gt;Antonello Rizzi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jenssen_R/0/1/0/all/0/1&quot;&gt;Robert Jenssen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.07964">
<title>Question-Aware Sentence Gating Networks for Question and Answering. (arXiv:1807.07964v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1807.07964</link>
<description rdf:parseType="Literal">&lt;p&gt;Machine comprehension question answering, which finds an answer to the
question given a passage, involves high-level reasoning processes of
understanding and tracking the relevant contents across various semantic units
such as words, phrases, and sentences in a document. This paper proposes the
novel question-aware sentence gating networks that directly incorporate the
sentence-level information into word-level encoding processes. To this end, our
model first learns question-aware sentence representations and then dynamically
combines them with word-level representations, resulting in semantically
meaningful word representations for QA tasks. Experimental results demonstrate
that our approach consistently improves the accuracy over existing baseline
approaches on various QA datasets and bears the wide applicability to other
neural network-based QA models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_M/0/1/0/all/0/1&quot;&gt;Minjeong Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Park_D/0/1/0/all/0/1&quot;&gt;David Keetae Park&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Noh_H/0/1/0/all/0/1&quot;&gt;Hyungjong Noh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_Y/0/1/0/all/0/1&quot;&gt;Yeonsoo Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Choo_J/0/1/0/all/0/1&quot;&gt;Jaegul Choo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.08169">
<title>Recent Advances in Deep Learning: An Overview. (arXiv:1807.08169v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.08169</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep Learning is one of the newest trends in Machine Learning and Artificial
Intelligence research. It is also one of the most popular scientific research
trends now-a-days. Deep learning methods have brought revolutionary advances in
computer vision and machine learning. Every now and then, new and new deep
learning techniques are being born, outperforming state-of-the-art machine
learning and even existing deep learning techniques. In recent years, the world
has seen many major breakthroughs in this field. Since deep learning is
evolving at a huge speed, its kind of hard to keep track of the regular
advances especially for new researchers. In this paper, we are going to briefly
discuss about recent advances in Deep Learning for past few years.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Minar_M/0/1/0/all/0/1&quot;&gt;Matiur Rahman Minar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Naher_J/0/1/0/all/0/1&quot;&gt;Jibon Naher&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.08195">
<title>Creativity and Artificial Intelligence: A Digital Art Perspective. (arXiv:1807.08195v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1807.08195</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper describes the application of artificial intelligence to the
creation of digital art. AI is a computational paradigm that codifies
intelligence into machines. There are generally three types of artificial
intelligence and these are machine learning, evolutionary programming and soft
computing. Machine learning is the statistical approach to building intelligent
systems. Evolutionary programming is the use of natural evolutionary systems to
design intelligent machines. Some of the evolutionary programming systems
include genetic algorithm which is inspired by the principles of evolution and
swarm optimization which is inspired by the swarming of birds, fish, ants etc.
Soft computing includes techniques such as agent based modelling and fuzzy
logic. Opportunities on the applications of these to digital art are explored.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xing_B/0/1/0/all/0/1&quot;&gt;Bo Xing&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Marwala_T/0/1/0/all/0/1&quot;&gt;Tshilidzi Marwala&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.08217">
<title>Asynchronous Advantage Actor-Critic Agent for Starcraft II. (arXiv:1807.08217v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1807.08217</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep reinforcement learning, and especially the Asynchronous Advantage
Actor-Critic algorithm, has been successfully used to achieve super-human
performance in a variety of video games. Starcraft II is a new challenge for
the reinforcement learning community with the release of pysc2 learning
environment proposed by Google Deepmind and Blizzard Entertainment. Despite
being a target for several AI developers, few have achieved human level
performance. In this project we explain the complexities of this environment
and discuss the results from our experiments on the environment. We have
compared various architectures and have proved that transfer learning can be an
effective paradigm in reinforcement learning research for complex scenarios
requiring skill transfer.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alghanem_B/0/1/0/all/0/1&quot;&gt;Basel Alghanem&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+G_K/0/1/0/all/0/1&quot;&gt;Keerthana P G&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.08312">
<title>Unified Hypersphere Embedding for Speaker Recognition. (arXiv:1807.08312v1 [eess.AS])</title>
<link>http://arxiv.org/abs/1807.08312</link>
<description rdf:parseType="Literal">&lt;p&gt;Incremental improvements in accuracy of Convolutional Neural Networks are
usually achieved through use of deeper and more complex models trained on
larger datasets. However, enlarging dataset and models increases the
computation and storage costs and cannot be done indefinitely. In this work, we
seek to improve the identification and verification accuracy of a
text-independent speaker recognition system without use of extra data or deeper
and more complex models by augmenting the training and testing data, finding
the optimal dimensionality of embedding space and use of more discriminative
loss functions. Results of experiments on VoxCeleb dataset suggest that: (i)
Simple repetition and random time-reversion of utterances can reduce prediction
errors by up to 18%. (ii) Lower dimensional embeddings are more suitable for
verification. (iii) Use of proposed logistic margin loss function leads to
unified embeddings with state-of-the-art identification and competitive
verification accuracies.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Hajibabaei_M/0/1/0/all/0/1&quot;&gt;Mahdi Hajibabaei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Dai_D/0/1/0/all/0/1&quot;&gt;Dengxin Dai&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.08325">
<title>Potentially Guided Bidirectionalized RRT* for Fast Optimal Path Planning in Cluttered Environments. (arXiv:1807.08325v1 [cs.RO])</title>
<link>http://arxiv.org/abs/1807.08325</link>
<description rdf:parseType="Literal">&lt;p&gt;Rapidly-exploring Random Tree star (RRT*) has recently gained immense
popularity in the motion planning community as it provides a probabilistically
complete and asymptotically optimal solution without requiring the complete
information of the obstacle space. In spite of all of its advantages, RRT*
converges to an optimal solution very slowly. Hence to improve the convergence
rate, its bidirectional variants were introduced, the Bi-directional RRT*
(B-RRT*) and Intelligent Bi-directional RRT* (IB-RRT*). However, as both
variants perform pure exploration, they tend to suffer in highly cluttered
environments. In order to overcome these limitations, we introduce a new
concept of potentially guided bidirectional trees in our proposed Potentially
Guided Intelligent Bi-directional RRT* (PIB-RRT*) and Potentially Guided
Bi-directional RRT* (PB-RRT*). The proposed algorithms greatly improve the
convergence rate and have a more efficient memory utilization. Theoretical and
experimental evaluation of the proposed algorithms have been made and compared
to the latest state of the art motion planning algorithms under different
challenging environmental conditions and have proven their remarkable
improvement in efficiency and convergence rate.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tahir_Z/0/1/0/all/0/1&quot;&gt;Zaid Tahir&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qureshi_A/0/1/0/all/0/1&quot;&gt;Ahmed H. Qureshi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ayaz_Y/0/1/0/all/0/1&quot;&gt;Yasar Ayaz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nawaz_R/0/1/0/all/0/1&quot;&gt;Raheel Nawaz&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.08360">
<title>MOBA-Slice: A Time Slice Based Evaluation Framework of Relative Advantage between Teams in MOBA Games. (arXiv:1807.08360v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.08360</link>
<description rdf:parseType="Literal">&lt;p&gt;Multiplayer Online Battle Arena (MOBA) is currently one of the most popular
genres of digital games around the world. The domain of knowledge contained in
these complicated games is large. It is hard for humans and algorithms to
evaluate the real-time game situation or predict the game result. In this
paper, we introduce MOBA-Slice, a time slice based evaluation framework of
relative advantage between teams in MOBA games. MOBA-Slice is a quantitative
evaluation method based on learning, similar to the value network of AlphaGo.
It establishes a foundation for further MOBA related research including AI
development. In MOBA-Slice, with an analysis of the deciding factors of MOBA
game results, we design a neural network model to fit our discounted evaluation
function. Then we apply MOBA-Slice to Defense of the Ancients 2 (DotA2), a
typical and popular MOBA game. Experiments on a large number of match replays
show that our model works well on arbitrary matches. MOBA-Slice not only has an
accuracy 3.7% higher than DotA Plus Assistant at result prediction, but also
supports the prediction of the remaining time of the game, and then realizes
the evaluation of relative advantage between teams.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_L/0/1/0/all/0/1&quot;&gt;Lijun Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1&quot;&gt;Dawei Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1&quot;&gt;Xiangqun Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1&quot;&gt;Xing Xie&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.08364">
<title>EnsembleDAgger: A Bayesian Approach to Safe Imitation Learning. (arXiv:1807.08364v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1807.08364</link>
<description rdf:parseType="Literal">&lt;p&gt;While imitation learning is often used in robotics, this approach often
suffers from data mismatch and compounding errors. DAgger is an iterative
algorithm that addresses these issues by aggregating training data from both
the expert and novice policies, but does not consider the impact of safety. We
present a probabilistic extension to DAgger, which attempts to quantify the
confidence of the novice policy as a proxy for safety. Our method,
EnsembleDAgger, approximates a GP using an ensemble of neural networks. Using
the variance as a measure of confidence, we compute a decision rule that
captures how much we doubt the novice, thus determining when it is safe to
allow the novice to act. With this approach, we aim to maximize the novice&apos;s
share of actions, while constraining the probability of failure. We demonstrate
improved safety and learning performance compared to other DAgger variants and
classic imitation learning on an inverted pendulum and in the MuJoCo
HalfCheetah environment.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Menda_K/0/1/0/all/0/1&quot;&gt;Kunal Menda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Driggs_Campbell_K/0/1/0/all/0/1&quot;&gt;Katherine Driggs-Campbell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kochenderfer_M/0/1/0/all/0/1&quot;&gt;Mykel J. Kochenderfer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.08372">
<title>Knowledge-based Transfer Learning Explanation. (arXiv:1807.08372v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1807.08372</link>
<description rdf:parseType="Literal">&lt;p&gt;Machine learning explanation can significantly boost machine learning&apos;s
application in decision making, but the usability of current methods is limited
in human-centric explanation, especially for transfer learning, an important
machine learning branch that aims at utilizing knowledge from one learning
domain (i.e., a pair of dataset and prediction task) to enhance prediction
model training in another learning domain. In this paper, we propose an
ontology-based approach for human-centric explanation of transfer learning.
Three kinds of knowledge-based explanatory evidence, with different
granularities, including general factors, particular narrators and core
contexts are first proposed and then inferred with both local ontologies and
external knowledge bases. The evaluation with US flight data and DBpedia has
presented their confidence and availability in explaining the transferability
of feature representation in flight departure delay forecasting.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1&quot;&gt;Jiaoyan Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lecue_F/0/1/0/all/0/1&quot;&gt;Freddy Lecue&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pan_J/0/1/0/all/0/1&quot;&gt;Jeff Z. Pan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Horrocks_I/0/1/0/all/0/1&quot;&gt;Ian Horrocks&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1&quot;&gt;Huajun Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.08405">
<title>Visual Mesh: Real-time Object Detection Using Constant Sample Density. (arXiv:1807.08405v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1807.08405</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper proposes an enhancement of convolutional neural networks for
object detection in resource-constrained robotics through a geometric input
transformation called Visual Mesh. It uses object geometry to create a graph in
vision space, reducing computational complexity by normalizing the pixel and
feature density of objects. The experiments compare the Visual Mesh with
several other fast convolutional neural networks. The results demonstrate
execution times sixteen times quicker than the fastest competitor tested, while
achieving outstanding accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Houliston_T/0/1/0/all/0/1&quot;&gt;Trent Houliston&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chalup_S/0/1/0/all/0/1&quot;&gt;Stephan K. Chalup&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.08452">
<title>Learning to Play Pong using Policy Gradient Learning. (arXiv:1807.08452v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.08452</link>
<description rdf:parseType="Literal">&lt;p&gt;Activities in reinforcement learning (RL) revolve around learning the Markov
decision process (MDP) model, in particular, the following parameters: state
values, V; state-action values, Q; and policy, pi. These parameters are
commonly implemented as an array. Scaling up the problem means scaling up the
size of the array and this will quickly lead to a computational bottleneck. To
get around this, the RL problem is commonly formulated to learn a specific task
using hand-crafted input features to curb the size of the array. In this
report, we discuss an alternative end-to-end Deep Reinforcement Learning (DRL)
approach where the DRL attempts to learn general task representations which in
our context refers to learning to play the Pong game from a sequence of screen
snapshots without game-specific hand-crafted features. We apply artificial
neural networks (ANN) to approximate a policy of the RL model. The policy
network, via Policy Gradients (PG) method, learns to play the Pong game from a
sequence of frames without any extra semantics apart from the pixel information
and the score. In contrast to the traditional tabular RL approach where the
contents in the array have clear interpretations such as V or Q, the
interpretation of knowledge content from the weights of the policy network is
more illusive. In this work, we experiment with various Deep ANN architectures
i.e., Feed forward ANN (FFNN), Convolution ANN (CNN) and Asynchronous Advantage
Actor-Critic (A3C). We also examine the activation of hidden nodes and the
weights between the input and the hidden layers, before and after the DRL has
successfully learnt to play the Pong game. Insights into the internal learning
mechanisms and future research directions are then discussed.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Phon_Amnuaisuk_S/0/1/0/all/0/1&quot;&gt;Somnuk Phon-Amnuaisuk&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.08595">
<title>Multi-View Fuzzy Logic System with the Cooperation between Visible and Hidden Views. (arXiv:1807.08595v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1807.08595</link>
<description rdf:parseType="Literal">&lt;p&gt;Multi-view datasets are frequently encountered in learning tasks, such as web
data mining and multimedia information analysis. Given a multi-view dataset,
traditional learning algorithms usually decompose it into several single-view
datasets, from each of which a single-view model is learned. In contrast, a
multi-view learning algorithm can achieve better performance by cooperative
learning on the multi-view data. However, existing multi-view approaches mainly
focus on the views that are visible and ignore the hidden information behind
the visible views, which usually contains some intrinsic information of the
multi-view data, or vice versa. To address this problem, this paper proposes a
multi-view fuzzy logic system, which utilizes both the hidden information
shared by the multiple visible views and the information of each visible view.
Extensive experiments were conducted to validate its effectiveness.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1&quot;&gt;Te Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deng_Z/0/1/0/all/0/1&quot;&gt;Zhaohong Deng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_D/0/1/0/all/0/1&quot;&gt;Dongrui Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1&quot;&gt;Shitong Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.08712">
<title>Data Science with Vadalog: Bridging Machine Learning and Reasoning. (arXiv:1807.08712v1 [cs.DB])</title>
<link>http://arxiv.org/abs/1807.08712</link>
<description rdf:parseType="Literal">&lt;p&gt;Following the recent successful examples of large technology companies, many
modern enterprises seek to build knowledge graphs to provide a unified view of
corporate knowledge and to draw deep insights using machine learning and
logical reasoning. There is currently a perceived disconnect between the
traditional approaches for data science, typically based on machine learning
and statistical modelling, and systems for reasoning with domain knowledge. In
this paper we present a state-of-the-art Knowledge Graph Management System,
Vadalog, which delivers highly expressive and efficient logical reasoning and
provides seamless integration with modern data science toolkits, such as the
Jupyter platform. We demonstrate how to use Vadalog to perform traditional data
wrangling tasks, as well as complex logical and probabilistic reasoning. We
argue that this is a significant step forward towards combining machine
learning and reasoning in data science.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bellomarini_L/0/1/0/all/0/1&quot;&gt;Luigi Bellomarini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fayzrakhmanov_R/0/1/0/all/0/1&quot;&gt;Ruslan R. Fayzrakhmanov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gottlob_G/0/1/0/all/0/1&quot;&gt;Georg Gottlob&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kravchenko_A/0/1/0/all/0/1&quot;&gt;Andrey Kravchenko&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Laurenza_E/0/1/0/all/0/1&quot;&gt;Eleonora Laurenza&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nenov_Y/0/1/0/all/0/1&quot;&gt;Yavor Nenov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Reissfelder_S/0/1/0/all/0/1&quot;&gt;Stephane Reissfelder&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sallinger_E/0/1/0/all/0/1&quot;&gt;Emanuel Sallinger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sherkhonov_E/0/1/0/all/0/1&quot;&gt;Evgeny Sherkhonov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1&quot;&gt;Lianlong Wu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1705.06366">
<title>Automatic Goal Generation for Reinforcement Learning Agents. (arXiv:1705.06366v5 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1705.06366</link>
<description rdf:parseType="Literal">&lt;p&gt;Reinforcement learning is a powerful technique to train an agent to perform a
task. However, an agent that is trained using reinforcement learning is only
capable of achieving the single task that is specified via its reward function.
Such an approach does not scale well to settings in which an agent needs to
perform a diverse set of tasks, such as navigating to varying positions in a
room or moving objects to varying locations. Instead, we propose a method that
allows an agent to automatically discover the range of tasks that it is capable
of performing. We use a generator network to propose tasks for the agent to try
to achieve, specified as goal states. The generator network is optimized using
adversarial training to produce tasks that are always at the appropriate level
of difficulty for the agent. Our method thus automatically produces a
curriculum of tasks for the agent to learn. We show that, by using this
framework, an agent can efficiently and automatically learn to perform a wide
set of tasks without requiring any prior knowledge of its environment. Our
method can also learn to achieve tasks with sparse rewards, which traditionally
pose significant challenges.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Florensa_C/0/1/0/all/0/1&quot;&gt;Carlos Florensa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Held_D/0/1/0/all/0/1&quot;&gt;David Held&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Geng_X/0/1/0/all/0/1&quot;&gt;Xinyang Geng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1&quot;&gt;Pieter Abbeel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.04247">
<title>Reciprocal Attention Fusion for Visual Question Answering. (arXiv:1805.04247v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1805.04247</link>
<description rdf:parseType="Literal">&lt;p&gt;Existing attention mechanisms either attend to local image grid or object
level features for Visual Question Answering (VQA). Motivated by the
observation that questions can relate to both object instances and their parts,
we propose a novel attention mechanism that jointly considers reciprocal
relationships between the two levels of visual details. The bottom-up attention
thus generated is further coalesced with the top-down information to only focus
on the scene elements that are most relevant to a given question. Our design
hierarchically fuses multi-modal information i.e., language, object- and
gird-level features, through an efficient tensor decomposition scheme. The
proposed model improves the state-of-the-art single model performances from
67.9% to 68.2% on VQAv1 and from 65.7% to 67.4% on VQAv2, demonstrating a
significant boost.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Farazi_M/0/1/0/all/0/1&quot;&gt;Moshiur R Farazi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khan_S/0/1/0/all/0/1&quot;&gt;Salman H Khan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.10755">
<title>A Computational Theory for Life-Long Learning of Semantics. (arXiv:1806.10755v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1806.10755</link>
<description rdf:parseType="Literal">&lt;p&gt;Semantic vectors are learned from data to express semantic relationships
between elements of information, for the purpose of solving and informing
downstream tasks. Other models exist that learn to map and classify supervised
data. However, the two worlds of learning rarely interact to inform one another
dynamically, whether across types of data or levels of semantics, in order to
form a unified model. We explore the research problem of learning these vectors
and propose a framework for learning the semantics of knowledge incrementally
and online, across multiple mediums of data, via binary vectors. We discuss the
aspects of this framework to spur future research on this approach and problem.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sutor_P/0/1/0/all/0/1&quot;&gt;Peter Sutor Jr.&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Summers_Stay_D/0/1/0/all/0/1&quot;&gt;Douglas Summers-Stay&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aloimonos_Y/0/1/0/all/0/1&quot;&gt;Yiannis Aloimonos&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.07147">
<title>Guess who? Multilingual approach for the automated generation of author-stylized poetry. (arXiv:1807.07147v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1807.07147</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper addresses the problem of stylized text generation in a
multilingual setup. A version of a language model based on a long short-term
memory (LSTM) artificial neural network with extended phonetic and semantic
embeddings is used for stylized poetry generation. Phonetics is shown to have
comparable importance for the task of stylized poetry generation as the
information on the target author. The quality of the resulting poems generated
by the network is estimated through bilingual evaluation understudy (BLEU), a
survey and a new cross-entropy based metric that is suggested for the problems
of such type. The experiments show that the proposed model consistently
outperforms random sample and vanilla-LSTM baselines, humans also tend to
attribute machine generated texts to the target author.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tikhonov_A/0/1/0/all/0/1&quot;&gt;Alexey Tikhonov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yamshchikov_I/0/1/0/all/0/1&quot;&gt;Ivan P. Yamshchikov&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.07959">
<title>A Fully Convolutional Neural Network Approach to End-to-End Speech Enhancement. (arXiv:1807.07959v1 [cs.SD])</title>
<link>http://arxiv.org/abs/1807.07959</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper will describe a novel approach to the cocktail party problem that
relies on a fully convolutional neural network (FCN) architecture. The FCN
takes noisy audio data as input and performs nonlinear, filtering operations to
produce clean audio data of the target speech at the output. Our method learns
a model for one specific speaker, and is then able to extract that speakers
voice from babble background noise. Results from experimentation indicate the
ability to generalize to new speakers and robustness to new noise environments
of varying signal-to-noise ratios. A potential application of this method would
be for use in hearing aids. A pre-trained model could be quickly fine tuned for
an individuals family members and close friends, and deployed onto a hearing
aid to assist listeners in noisy environments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Longueira_F/0/1/0/all/0/1&quot;&gt;Frank Longueira&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Keene_S/0/1/0/all/0/1&quot;&gt;Sam Keene&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.07963">
<title>Deep Transfer Learning for Cross-domain Activity Recognition. (arXiv:1807.07963v1 [eess.IV])</title>
<link>http://arxiv.org/abs/1807.07963</link>
<description rdf:parseType="Literal">&lt;p&gt;Human activity recognition plays an important role in people&apos;s daily life.
However, it is often expensive and time-consuming to acquire sufficient labeled
activity data. To solve this problem, transfer learning leverages the labeled
samples from the source domain to annotate the target domain which has few or
none labels. Unfortunately, when there are several source domains available, it
is difficult to select the right source domains for transfer. The right source
domain means that it has the most similar properties with the target domain,
thus their similarity is higher, which can facilitate transfer learning.
Choosing the right source domain helps the algorithm perform well and prevents
the negative transfer. In this paper, we propose an effective Unsupervised
Source Selection algorithm for Activity Recognition (USSAR). USSAR is able to
select the most similar $K$ source domains from a list of available domains.
After this, we propose an effective Transfer Neural Network to perform
knowledge transfer for Activity Recognition (TNNAR). TNNAR could capture both
the time and spatial relationship between activities while transferring
knowledge. Experiments on three public activity recognition datasets
demonstrate that: 1) The USSAR algorithm is effective in selecting the best
source domains. 2) The TNNAR method can reach high accuracy when performing
activity knowledge transfer.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jindong Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Zheng_V/0/1/0/all/0/1&quot;&gt;Vincent W. Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yiqiang Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Huang_M/0/1/0/all/0/1&quot;&gt;Meiyu Huang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.07998">
<title>Convolutional Neural Networks Analyzed via Inverse Problem Theory and Sparse Representations. (arXiv:1807.07998v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.07998</link>
<description rdf:parseType="Literal">&lt;p&gt;Inverse problems in imaging such as denoising, deblurring, superresolution
(SR) have been addressed for many decades. In recent years, convolutional
neural networks (CNNs) have been widely used for many inverse problem areas.
Although their indisputable success, CNNs are not mathematically validated as
to how and what they learn. In this paper, we prove that during training, CNN
elements solve for inverse problems which are optimum solutions stored as CNN
neuron filters. We discuss the necessity of mutual coherence between CNN layer
elements in order for a network to converge to the optimum solution. We prove
that required mutual coherence can be provided by the usage of residual
learning and skip connections. We have set rules over training sets and depth
of networks for better convergence, i.e. performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tarhan_C/0/1/0/all/0/1&quot;&gt;Cem Tarhan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Akar_G/0/1/0/all/0/1&quot;&gt;Gozde Bozdagi Akar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.08140">
<title>On the Analysis of Trajectories of Gradient Descent in the Optimization of Deep Neural Networks. (arXiv:1807.08140v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.08140</link>
<description rdf:parseType="Literal">&lt;p&gt;Theoretical analysis of the error landscape of deep neural networks has
garnered significant interest in recent years. In this work, we theoretically
study the importance of noise in the trajectories of gradient descent towards
optimal solutions in multi-layer neural networks. We show that adding noise (in
different ways) to a neural network while training increases the rank of the
product of weight matrices of a multi-layer linear neural network. We thus
study how adding noise can assist reaching a global optimum when the product
matrix is full-rank (under certain conditions). We establish theoretical
foundations between the noise induced into the neural network - either to the
gradient, to the architecture, or to the input/output to a neural network - and
the rank of product of weight matrices. We corroborate our theoretical findings
with empirical results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sankar_A/0/1/0/all/0/1&quot;&gt;Adepu Ravi Sankar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Srinivasan_V/0/1/0/all/0/1&quot;&gt;Vishwak Srinivasan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Balasubramanian_V/0/1/0/all/0/1&quot;&gt;Vineeth N Balasubramanian&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.08197">
<title>On Numerical Estimation of Joint Probability Distribution from Lebesgue Integral Quadratures. (arXiv:1807.08197v1 [math.NA])</title>
<link>http://arxiv.org/abs/1807.08197</link>
<description rdf:parseType="Literal">&lt;p&gt;An important application of introduced in [1] Lebesgue integral quadrature is
developed. Given two random processes $f(x)$ and $g(x)$ two generalized
eigenvalues problems can be formulated and solved. Besides obtaining two
Lebesgue quadrature (for $f$ and $g$), projections of $f$-- and $g$--
eigenvectors on each other allow to build joint distribution estimator. Two
kind of estimators are obtained: value--correlation $V_{f_i;g_j}$, that is
similar to regular correlation concept, and a new one, probability--correlation
$P_{f_i;g_j}$. The theory is implemented numerically, the software is available
under GPLv3 license.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Malyshkin_V/0/1/0/all/0/1&quot;&gt;Vladislav Gennadievich Malyshkin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.08207">
<title>Predicting purchasing intent: Automatic Feature Learning using Recurrent Neural Networks. (arXiv:1807.08207v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.08207</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a neural network for predicting purchasing intent in an Ecommerce
setting. Our main contribution is to address the significant investment in
feature engineering that is usually associated with state-of-the-art methods
such as Gradient Boosted Machines. We use trainable vector spaces to model
varied, semi-structured input data comprising categoricals, quantities and
unique instances. Multi-layer recurrent neural networks capture both
session-local and dataset-global event dependencies and relationships for user
sessions of any length. An exploration of model design decisions including
parameter sharing and skip connections further increase model accuracy. Results
on benchmark datasets deliver classification accuracy within 98% of
state-of-the-art on one and exceed state-of-the-art on the second without the
need for any domain / dataset-specific feature engineering on both short and
long event sequences.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sheil_H/0/1/0/all/0/1&quot;&gt;Humphrey Sheil&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rana_O/0/1/0/all/0/1&quot;&gt;Omer Rana&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Reilly_R/0/1/0/all/0/1&quot;&gt;Ronan Reilly&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.08241">
<title>NAVREN-RL: Learning to fly in real environment via end-to-end deep reinforcement learning using monocular images. (arXiv:1807.08241v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.08241</link>
<description rdf:parseType="Literal">&lt;p&gt;We present NAVREN-RL, an approach to NAVigate an unmanned aerial vehicle in
an indoor Real ENvironment via end-to-end reinforcement learning RL. A suitable
reward function is designed keeping in mind the cost and weight constraints for
micro drone with minimum number of sensing modalities. Collection of small
number of expert data and knowledge based data aggregation is integrated into
the RL process to aid convergence. Experimentation is carried out on a Parrot
AR drone in different indoor arenas and the results are compared with other
baseline technologies. We demonstrate how the drone successfully avoids
obstacles and navigates across different arenas.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Anwar_M/0/1/0/all/0/1&quot;&gt;Malik Aqeel Anwar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Raychowdhury_A/0/1/0/all/0/1&quot;&gt;Arijit Raychowdhury&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.08383">
<title>PaloBoost: An Overfitting-robust TreeBoost with Out-of-Bag Sample Regularization Techniques. (arXiv:1807.08383v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1807.08383</link>
<description rdf:parseType="Literal">&lt;p&gt;Stochastic Gradient TreeBoost is often found in many winning solutions in
public data science challenges. Unfortunately, the best performance requires
extensive parameter tuning and can be prone to overfitting. We propose
PaloBoost, a Stochastic Gradient TreeBoost model that uses novel regularization
techniques to guard against overfitting and is robust to parameter settings.
PaloBoost uses the under-utilized out-of-bag samples to perform gradient-aware
pruning and estimate adaptive learning rates. Unlike other Stochastic Gradient
TreeBoost models that use the out-of-bag samples to estimate test errors,
PaloBoost treats the samples as a second batch of training samples to prune the
trees and adjust the learning rates. As a result, PaloBoost can dynamically
adjust tree depths and learning rates to achieve faster learning at the start
and slower learning as the algorithm converges. We illustrate how these
regularization techniques can be efficiently implemented and propose a new
formula for calculating feature importance to reflect the node coverages and
learning rates. Extensive experimental results on seven datasets demonstrate
that PaloBoost is robust to overfitting, is less sensitivity to the parameters,
and can also effectively identify meaningful features.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Park_Y/0/1/0/all/0/1&quot;&gt;Yubin Park&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ho_J/0/1/0/all/0/1&quot;&gt;Joyce C. Ho&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.08501">
<title>Generalization Bounds for Unsupervised Cross-Domain Mapping with WGANs. (arXiv:1807.08501v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.08501</link>
<description rdf:parseType="Literal">&lt;p&gt;The recent empirical success of cross-domain mapping algorithms, between two
domains that share common characteristics, is not well-supported by theoretical
justifications. This lacuna is especially troubling, given the clear ambiguity
in such mappings. We work with the adversarial training method called the
Wasserstein GAN. We derive a novel generalization bound, which limits the risk
between the learned mapping $h$ and the target mapping $y$, by a sum of two
terms: (i) the risk between $h$ and the most distant alternative mapping that
has a small Wasserstein GAN divergence, and (ii) the Wasserstein GAN divergence
between the target domain and the domain obtained by applying $h$ on the
samples of the source domain. The bound is directly related to Occam&apos;s razor
and it encourages the selection of the minimal architecture that supports a
small Wasserstein GAN divergence. From the bound, we derive algorithms for
hyperparameter selection and early stopping in cross-domain mapping GANs. We
also demonstrate a novel capability of estimating confidence in the mapping of
every specific sample. Lastly, we show how non-minimal architectures can be
effectively trained by an inverted knowledge distillation in which a minimal
architecture is used to train a larger one, leading to higher quality outputs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Galanti_T/0/1/0/all/0/1&quot;&gt;Tomer Galanti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Benaim_S/0/1/0/all/0/1&quot;&gt;Sagie Benaim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wolf_L/0/1/0/all/0/1&quot;&gt;Lior Wolf&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.08518">
<title>Implementing Neural Turing Machines. (arXiv:1807.08518v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.08518</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural Turing Machines (NTMs) are an instance of Memory Augmented Neural
Networks, a new class of recurrent neural networks which decouple computation
from memory by introducing an external memory unit. NTMs have demonstrated
superior performance over Long Short-Term Memory Cells in several sequence
learning tasks. A number of open source implementations of NTMs exist but are
unstable during training and/or fail to replicate the reported performance of
NTMs. This paper presents the details of our successful implementation of a
NTM. Our implementation learns to solve three sequential learning tasks from
the original NTM paper. We find that the choice of memory contents
initialization scheme is crucial in successfully implementing a NTM. Networks
with memory contents initialized to small constant values converge on average 2
times faster than the next best memory contents initialization scheme.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Collier_M/0/1/0/all/0/1&quot;&gt;Mark Collier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Beel_J/0/1/0/all/0/1&quot;&gt;Joeran Beel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.08666">
<title>ASR-free CNN-DTW keyword spotting using multilingual bottleneck features for almost zero-resource languages. (arXiv:1807.08666v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1807.08666</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider multilingual bottleneck features (BNFs) for nearly zero-resource
keyword spotting. This forms part of a United Nations effort using keyword
spotting to support humanitarian relief programmes in parts of Africa where
languages are severely under-resourced. We use 1920 isolated keywords (40
types, 34 minutes) as exemplars for dynamic time warping (DTW) template
matching, which is performed on a much larger body of untranscribed speech.
These DTW costs are used as targets for a convolutional neural network (CNN)
keyword spotter, giving a much faster system than direct DTW. Here we consider
how available data from well-resourced languages can improve this CNN-DTW
approach. We show that multilingual BNFs trained on ten languages improve the
area under the ROC curve of a CNN-DTW system by 10.9% absolute relative to the
MFCC baseline. By combining low-resource DTW-based supervision with information
from well-resourced languages, CNN-DTW is a competitive option for low-resource
keyword spotting.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Menon_R/0/1/0/all/0/1&quot;&gt;Raghav Menon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kamper_H/0/1/0/all/0/1&quot;&gt;Herman Kamper&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yilmaz_E/0/1/0/all/0/1&quot;&gt;Emre Yilmaz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Quinn_J/0/1/0/all/0/1&quot;&gt;John Quinn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Niesler_T/0/1/0/all/0/1&quot;&gt;Thomas Niesler&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.08669">
<title>Automatic Speech Recognition for Humanitarian Applications in Somali. (arXiv:1807.08669v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1807.08669</link>
<description rdf:parseType="Literal">&lt;p&gt;We present our first efforts in building an automatic speech recognition
system for Somali, an under-resourced language, using 1.57 hrs of annotated
speech for acoustic model training. The system is part of an ongoing effort by
the United Nations (UN) to implement keyword spotting systems supporting
humanitarian relief programmes in parts of Africa where languages are severely
under-resourced. We evaluate several types of acoustic model, including recent
neural architectures. Language model data augmentation using a combination of
recurrent neural networks (RNN) and long short-term memory neural networks
(LSTMs) as well as the perturbation of acoustic data are also considered. We
find that both types of data augmentation are beneficial to performance, with
our best system using a combination of convolutional neural networks (CNNs),
time-delay neural networks (TDNNs) and bi-directional long short term memory
(BLSTMs) to achieve a word error rate of 53.75%.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Menon_R/0/1/0/all/0/1&quot;&gt;Raghav Menon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Biswas_A/0/1/0/all/0/1&quot;&gt;Astik Biswas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saeb_A/0/1/0/all/0/1&quot;&gt;Armin Saeb&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Quinn_J/0/1/0/all/0/1&quot;&gt;John Quinn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Niesler_T/0/1/0/all/0/1&quot;&gt;Thomas Niesler&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.08706">
<title>Contrastive Explanations for Reinforcement Learning in terms of Expected Consequences. (arXiv:1807.08706v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.08706</link>
<description rdf:parseType="Literal">&lt;p&gt;Machine Learning models become increasingly proficient in complex tasks.
However, even for experts in the field, it can be difficult to understand what
the model learned. This hampers trust and acceptance, and it obstructs the
possibility to correct the model. There is therefore a need for transparency of
machine learning models. The development of transparent classification models
has received much attention, but there are few developments for achieving
transparent Reinforcement Learning (RL) models. In this study we propose a
method that enables a RL agent to explain its behavior in terms of the expected
consequences of state transitions and outcomes. First, we define a translation
of states and actions to a description that is easier to understand for human
users. Second, we developed a procedure that enables the agent to obtain the
consequences of a single action, as well as its entire policy. The method
calculates contrasts between the consequences of a policy derived from a user
query, and of the learned policy of the agent. Third, a format for generating
explanations was constructed. A pilot survey study was conducted to explore
preferences of users for different explanation properties. Results indicate
that human users tend to favor explanations about policy rather than about
single actions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Waa_J/0/1/0/all/0/1&quot;&gt;Jasper van der Waa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Diggelen_J/0/1/0/all/0/1&quot;&gt;Jurriaan van Diggelen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bosch_K/0/1/0/all/0/1&quot;&gt;Karel van den Bosch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Neerincx_M/0/1/0/all/0/1&quot;&gt;Mark Neerincx&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1705.07204">
<title>Ensemble Adversarial Training: Attacks and Defenses. (arXiv:1705.07204v4 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1705.07204</link>
<description rdf:parseType="Literal">&lt;p&gt;Adversarial examples are perturbed inputs designed to fool machine learning
models. Adversarial training injects such examples into training data to
increase robustness. To scale this technique to large datasets, perturbations
are crafted using fast single-step methods that maximize a linear approximation
of the model&apos;s loss. We show that this form of adversarial training converges
to a degenerate global minimum, wherein small curvature artifacts near the data
points obfuscate a linear approximation of the loss. The model thus learns to
generate weak perturbations, rather than defend against strong ones. As a
result, we find that adversarial training remains vulnerable to black-box
attacks, where we transfer perturbations computed on undefended models, as well
as to a powerful novel single-step attack that escapes the non-smooth vicinity
of the input data via a small random step. We further introduce Ensemble
Adversarial Training, a technique that augments training data with
perturbations transferred from other models. On ImageNet, Ensemble Adversarial
Training yields models with strong robustness to black-box attacks. In
particular, our most robust model won the first round of the NIPS 2017
competition on Defenses against Adversarial Attacks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tramer_F/0/1/0/all/0/1&quot;&gt;Florian Tram&amp;#xe8;r&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kurakin_A/0/1/0/all/0/1&quot;&gt;Alexey Kurakin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Papernot_N/0/1/0/all/0/1&quot;&gt;Nicolas Papernot&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Goodfellow_I/0/1/0/all/0/1&quot;&gt;Ian Goodfellow&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Boneh_D/0/1/0/all/0/1&quot;&gt;Dan Boneh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+McDaniel_P/0/1/0/all/0/1&quot;&gt;Patrick McDaniel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.02903">
<title>Blind Multiclass Ensemble Classification. (arXiv:1712.02903v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1712.02903</link>
<description rdf:parseType="Literal">&lt;p&gt;The rising interest in pattern recognition and data analytics has spurred the
development of innovative machine learning algorithms and tools. However, as
each algorithm has its strengths and limitations, one is motivated to
judiciously fuse multiple algorithms in order to find the &quot;best&quot; performing
one, for a given dataset. Ensemble learning aims at such high-performance
meta-algorithm, by combining the outputs from multiple algorithms. The present
work introduces a blind scheme for learning from ensembles of classifiers,
using a moment matching method that leverages joint tensor and matrix
factorization. Blind refers to the combiner who has no knowledge of the
ground-truth labels that each classifier has been trained on. A rigorous
performance analysis is derived and the proposed scheme is evaluated on
synthetic and real datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Traganitis_P/0/1/0/all/0/1&quot;&gt;Panagiotis A. Traganitis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pages_Zamora_A/0/1/0/all/0/1&quot;&gt;Alba Pag&amp;#xe8;s-Zamora&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Giannakis_G/0/1/0/all/0/1&quot;&gt;Georgios B. Giannakis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.03308">
<title>Adversarial Training Versus Weight Decay. (arXiv:1804.03308v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1804.03308</link>
<description rdf:parseType="Literal">&lt;p&gt;Performance-critical machine learning models should be robust to input
perturbations not seen during training. Adversarial training is a method for
improving a model&apos;s robustness to some perturbations by including them in the
training process, but this tends to exacerbate other vulnerabilities of the
model. The adversarial training framework has the effect of translating the
data with respect to the cost function, while weight decay has a scaling
effect. Although weight decay could be considered a crude regularization
technique, it appears superior to adversarial training as it remains stable
over a broader range of regimes and reduces all generalization errors. Equipped
with these abstractions, we provide key baseline results and methodology for
characterizing robustness. The two approaches can be combined to yield one
small model that demonstrates good robustness to several white-box attacks
associated with different metrics.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Galloway_A/0/1/0/all/0/1&quot;&gt;Angus Galloway&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tanay_T/0/1/0/all/0/1&quot;&gt;Thomas Tanay&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Taylor_G/0/1/0/all/0/1&quot;&gt;Graham W. Taylor&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.10574">
<title>Decoupled Parallel Backpropagation with Convergence Guarantee. (arXiv:1804.10574v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1804.10574</link>
<description rdf:parseType="Literal">&lt;p&gt;Backpropagation algorithm is indispensable for the training of feedforward
neural networks. It requires propagating error gradients sequentially from the
output layer all the way back to the input layer. The backward locking in
backpropagation algorithm constrains us from updating network layers in
parallel and fully leveraging the computing resources. Recently, several
algorithms have been proposed for breaking the backward locking. However, their
performances degrade seriously when networks are deep. In this paper, we
propose decoupled parallel backpropagation algorithm for deep learning
optimization with convergence guarantee. Firstly, we decouple the
backpropagation algorithm using delayed gradients, and show that the backward
locking is removed when we split the networks into multiple modules. Then, we
utilize decoupled parallel backpropagation in two stochastic methods and prove
that our method guarantees convergence to critical points for the non-convex
problem. Finally, we perform experiments for training deep convolutional neural
networks on benchmark datasets. The experimental results not only confirm our
theoretical analysis, but also demonstrate that the proposed method can achieve
significant speedup without loss of accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huo_Z/0/1/0/all/0/1&quot;&gt;Zhouyuan Huo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gu_B/0/1/0/all/0/1&quot;&gt;Bin Gu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Q/0/1/0/all/0/1&quot;&gt;Qian Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1&quot;&gt;Heng Huang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.00108">
<title>Conditional molecular design with deep generative models. (arXiv:1805.00108v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.00108</link>
<description rdf:parseType="Literal">&lt;p&gt;Although machine learning has been successfully used to propose novel
molecules that satisfy desired properties, it is still challenging to explore a
large chemical space efficiently. In this paper, we present a conditional
molecular design method that facilitates generating new molecules with desired
properties. The proposed model, which simultaneously performs both property
prediction and molecule generation, is built as a semi-supervised variational
autoencoder trained on a set of existing molecules with only a partial
annotation. We generate new molecules with desired properties by sampling from
the generative distribution estimated by the model. We demonstrate the
effectiveness of the proposed model by evaluating it on drug-like molecules.
The model improves the performance of property prediction by exploiting
unlabeled molecules, and efficiently generates novel molecules fulfilling
various target conditions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kang_S/0/1/0/all/0/1&quot;&gt;Seokho Kang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cho_K/0/1/0/all/0/1&quot;&gt;Kyunghyun Cho&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.00119">
<title>Risk-Averse Classification. (arXiv:1805.00119v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1805.00119</link>
<description rdf:parseType="Literal">&lt;p&gt;We develop a new approach to solving classification problems, which is bases
on the theory of coherent measures of risk and risk sharing ideas. The proposed
approach aims at designing a risk-averse classifier. The new approach allows
for associating distinct risk functional to each classes. The risk may be
measured by different (non-linear in probability) measures,
&lt;/p&gt;
&lt;p&gt;We analyze the structure of the new classifier design problem and establish
its theoretical relation to known risk-neutral design problems. In particular,
we show that the risk-sharing classification problem is equivalent to an
implicitly defined optimization problem with unequal, implicitly defined but
unknown, weights for each data point. We implement our methodology in a binary
classification scenario on several different data sets and carry out numerical
comparison with classifiers which are obtained using the Huber loss function
and other loss functions known in the literature. We formulate specific
risk-averse support vector machines in order to demonstrate the viability of
our method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Vitt_C/0/1/0/all/0/1&quot;&gt;Constantine Vitt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Dentcheva_D/0/1/0/all/0/1&quot;&gt;Darinka Dentcheva&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Xiong_H/0/1/0/all/0/1&quot;&gt;Hui Xiong&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09461">
<title>Deep Reinforcement Learning For Sequence to Sequence Models. (arXiv:1805.09461v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.09461</link>
<description rdf:parseType="Literal">&lt;p&gt;In recent times, sequence-to-sequence (seq2seq) models have gained a lot of
popularity and provide state-of-the-art performance in a wide variety of tasks
such as machine translation, headline generation, text summarization, speech to
text conversion, and image caption generation. The underlying framework for all
these models is usually a deep neural network comprising an encoder and a
decoder. Although simple encoder-decoder models produce competitive results,
many researchers have proposed additional improvements over these
sequence-to-sequence models, e.g., using an attention-based model over the
input, pointer-generation models, and self-attention models. However, such
seq2seq models suffer from two common problems: 1) exposure bias and 2)
inconsistency between train/test measurement. Recently, a completely novel
point of view has emerged in addressing these two problems in seq2seq models,
leveraging methods from reinforcement learning (RL). In this survey, we
consider seq2seq problems from the RL point of view and provide a formulation
combining the power of RL methods in decision-making with sequence-to-sequence
models that enable remembering long-term memories. We present some of the most
recent frameworks that combine concepts from RL and deep neural networks and
explain how these two areas could benefit from each other in solving complex
seq2seq tasks. Our work aims to provide insights into some of the problems that
inherently arise with current approaches and how we can address them with
better RL models. We also provide the source code for implementing most of the
RL models discussed in this paper to support the complex task of abstractive
text summarization.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Keneshloo_Y/0/1/0/all/0/1&quot;&gt;Yaser Keneshloo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_T/0/1/0/all/0/1&quot;&gt;Tian Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ramakrishnan_N/0/1/0/all/0/1&quot;&gt;Naren Ramakrishnan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Reddy_C/0/1/0/all/0/1&quot;&gt;Chandan K. Reddy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.00745">
<title>Training a Neural Network in a Low-Resource Setting on Automatically Annotated Noisy Data. (arXiv:1807.00745v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1807.00745</link>
<description rdf:parseType="Literal">&lt;p&gt;Manually labeled corpora are expensive to create and often not available for
low-resource languages or domains. Automatic labeling approaches are an
alternative way to obtain labeled data in a quicker and cheaper way. However,
these labels often contain more errors which can deteriorate a classifier&apos;s
performance when trained on this data. We propose a noise layer that is added
to a neural network architecture. This allows modeling the noise and train on a
combination of clean and noisy data. We show that in a low-resource NER task we
can improve performance by up to 35% by using additional, noisy data and
handling the noise.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hedderich_M/0/1/0/all/0/1&quot;&gt;Michael A. Hedderich&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Klakow_D/0/1/0/all/0/1&quot;&gt;Dietrich Klakow&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.01961">
<title>A Boo(n) for Evaluating Architecture Performance. (arXiv:1807.01961v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1807.01961</link>
<description rdf:parseType="Literal">&lt;p&gt;We point out important problems with the common practice of using the best
single model performance for comparing deep learning architectures, and we
propose a method that corrects these flaws. Each time a model is trained, one
gets a different result due to random factors in the training process, which
include random parameter initialization and random data shuffling. Reporting
the best single model performance does not appropriately address this
stochasticity. We propose a normalized expected best-out-of-$n$ performance
($\text{Boo}_n$) as a way to correct these problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bajgar_O/0/1/0/all/0/1&quot;&gt;Ondrej Bajgar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kadlec_R/0/1/0/all/0/1&quot;&gt;Rudolf Kadlec&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kleindienst_J/0/1/0/all/0/1&quot;&gt;Jan Kleindienst&lt;/a&gt;</dc:creator>
</item></rdf:RDF>