<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Good papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Good Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-07-12T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.04587"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.04375"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.00614"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.04415"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.04439"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.04511"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.04585"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.04662"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.04687"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.04740"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.04875"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.08647"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.10846"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.00928"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.06604"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1807.04587">
<title>Assessing the Scalability of Biologically-Motivated Deep Learning Algorithms and Architectures. (arXiv:1807.04587v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.04587</link>
<description rdf:parseType="Literal">&lt;p&gt;The backpropagation of error algorithm (BP) is often said to be impossible to
implement in a real brain. The recent success of deep networks in machine
learning and AI, however, has inspired proposals for understanding how the
brain might learn across multiple layers, and hence how it might implement or
approximate BP. As of yet, none of these proposals have been rigorously
evaluated on tasks where BP-guided deep learning has proved critical, or in
architectures more structured than simple fully-connected networks. Here we
present the first results on scaling up biologically motivated models of deep
learning on datasets which need deep networks with appropriate architectures to
achieve good performance. We present results on the MNIST, CIFAR-10, and
ImageNet datasets and explore variants of target-propagation (TP) and feedback
alignment (FA) algorithms, and explore performance in both fully- and
locally-connected architectures. We also introduce weight-transport-free
variants of difference target propagation (DTP) modified to remove
backpropagation from the penultimate layer. Many of these algorithms perform
well for MNIST, but for CIFAR and ImageNet we find that TP and FA variants
perform significantly worse than BP, especially for networks composed of
locally connected units, opening questions about whether new architectures and
algorithms are required to scale these approaches. Our results and
implementation details help establish baselines for biologically motivated deep
learning schemes going forward.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bartunov_S/0/1/0/all/0/1&quot;&gt;Sergey Bartunov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Santoro_A/0/1/0/all/0/1&quot;&gt;Adam Santoro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Richards_B/0/1/0/all/0/1&quot;&gt;Blake A. Richards&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hinton_G/0/1/0/all/0/1&quot;&gt;Geoffrey E. Hinton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lillicrap_T/0/1/0/all/0/1&quot;&gt;Timothy Lillicrap&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.04375">
<title>AtDelfi: Automatically Designing Legible, Full Instructions For Games. (arXiv:1807.04375v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1807.04375</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper introduces a fully automatic method for generating video game
tutorials. The AtDELFI system (AuTomatically DEsigning Legible, Full
Instructions for games) was created to investigate procedural generation of
instructions that teach players how to play video games. We present a
representation of game rules and mechanics using a graph system as well as a
tutorial generation method that uses said graph representation. We demonstrate
the concept by testing it on games within the General Video Game Artificial
Intelligence (GVG-AI) framework; the paper discusses tutorials generated for
eight different games. Our findings suggest that a graph representation scheme
works well for simple arcade style games such as Space Invaders and Pacman, but
it appears that tutorials for more complex games might require higher-level
understanding of the game than just single mechanics.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Green_M/0/1/0/all/0/1&quot;&gt;Michael Cerny Green&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khalifa_A/0/1/0/all/0/1&quot;&gt;Ahmed Khalifa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barros_G/0/1/0/all/0/1&quot;&gt;Gabriella A.B. Barros&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Machado_T/0/1/0/all/0/1&quot;&gt;Tiago Machado&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nealen_A/0/1/0/all/0/1&quot;&gt;Andy Nealen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Togelius_J/0/1/0/all/0/1&quot;&gt;Julian Togelius&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.00614">
<title>Knowledge Compilation with Continuous Random Variables and its Application in Hybrid Probabilistic Logic Programming. (arXiv:1807.00614v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1807.00614</link>
<description rdf:parseType="Literal">&lt;p&gt;In probabilistic reasoning, the traditionally discrete domain has been
elevated to the hybrid domain encompassing additionally continuous random
variables. Inference in the hybrid domain, however, usually necessitates to
condone trade-offs on either the inference on discrete or continuous random
variables. We introduce a novel approach based on weighted model integration
and algebraic model counting that circumvents these trade-offs. We then show
how it supports knowledge compilation and exact probabilistic inference.
Moreover, we introduce the hybrid probabilistic logic programming language
HAL-ProbLog, an extension of ProbLog, to which we apply our inference approach.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Martires_P/0/1/0/all/0/1&quot;&gt;Pedro Zuidberg Dos Martires&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dries_A/0/1/0/all/0/1&quot;&gt;Anton Dries&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Raedt_L/0/1/0/all/0/1&quot;&gt;Luc De Raedt&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.04415">
<title>Process Discovery using Classification Tree Hidden Semi-Markov Model. (arXiv:1807.04415v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1807.04415</link>
<description rdf:parseType="Literal">&lt;p&gt;Various and ubiquitous information systems are being used in monitoring,
exchanging, and collecting information. These systems are generating massive
amount of event sequence logs that may help us understand underlying
phenomenon. By analyzing these logs, we can learn process models that describe
system procedures, predict the development of the system, or check whether the
changes are expected. In this paper, we consider a novel technique that models
these sequences of events in temporal-probabilistic manners. Specifically, we
propose a probabilistic process model that combines hidden semi-Markov model
and classification trees learning. Our experimental result shows that the
proposed approach can answer a kind of question-&quot;what are the most frequent
sequence of system dynamics relevant to a given sequence of observable
events?&quot;. For example, &quot;Given a series of medical treatments, what are the most
relevant patients&apos; health condition pattern changes at different times?&quot;
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kang_Y/0/1/0/all/0/1&quot;&gt;Yihuang Kang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zadorozhny_V/0/1/0/all/0/1&quot;&gt;Vladimir Zadorozhny&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.04439">
<title>Will it Blend? Composing Value Functions in Reinforcement Learning. (arXiv:1807.04439v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.04439</link>
<description rdf:parseType="Literal">&lt;p&gt;An important property for lifelong-learning agents is the ability to combine
existing skills to solve unseen tasks. In general, however, it is unclear how
to compose skills in a principled way. We provide a &quot;recipe&quot; for optimal value
function composition in entropy-regularised reinforcement learning (RL) and
then extend this to the standard RL setting. Composition is demonstrated in a
video game environment, where an agent with an existing library of policies is
able to solve new tasks without the need for further learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Niekerk_B/0/1/0/all/0/1&quot;&gt;Benjamin van Niekerk&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+James_S/0/1/0/all/0/1&quot;&gt;Steven James&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Earle_A/0/1/0/all/0/1&quot;&gt;Adam Earle&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rosman_B/0/1/0/all/0/1&quot;&gt;Benjamin Rosman&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.04511">
<title>Training Neural Networks Using Features Replay. (arXiv:1807.04511v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.04511</link>
<description rdf:parseType="Literal">&lt;p&gt;Training a neural network using backpropagation algorithm requires passing
error gradients sequentially through the network. The backward locking prevents
us from updating network layers in parallel and fully leveraging the computing
resources. Recently, there are several works trying to decouple and parallelize
the backpropagation algorithm. However, all of them suffer from severe accuracy
loss or memory explosion when the neural network is deep. To address these
challenging issues, we propose a novel parallel-objective formulation for the
objective function of the neural network. After that, we introduce features
replay algorithm and prove that it is guaranteed to converge to critical points
for the non-convex problem under certain conditions. Finally, we apply our
method to training deep convolutional neural networks, and the experimental
results show that the proposed method achieves {faster} convergence, {lower}
memory consumption, and {better} generalization error than compared methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huo_Z/0/1/0/all/0/1&quot;&gt;Zhouyuan Huo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gu_B/0/1/0/all/0/1&quot;&gt;Bin Gu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1&quot;&gt;Heng Huang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.04585">
<title>Deep Learning for Imbalance Data Classification using Class Expert Generative Adversarial Network. (arXiv:1807.04585v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.04585</link>
<description rdf:parseType="Literal">&lt;p&gt;Without any specific way for imbalance data classification, artificial
intelligence algorithm cannot recognize data from minority classes easily. In
general, modifying the existing algorithm by assuming that the training data is
imbalanced, is the only way to handle imbalance data. However, for a normal
data handling, this way mostly produces a deficient result. In this research,
we propose a class expert generative adversarial network (CE-GAN) as the
solution for imbalance data classification. CE-GAN is a modification in deep
learning algorithm architecture that does not have an assumption that the
training data is imbalance data. Moreover, CE-GAN is designed to identify more
detail about the character of each class before classification step. CE-GAN has
been proved in this research to give a good performance for imbalance data
classification.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fanny/0/1/0/all/0/1&quot;&gt;Fanny&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cenggoro_T/0/1/0/all/0/1&quot;&gt;Tjeng Wawan Cenggoro&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.04662">
<title>Scikit-Multiflow: A Multi-output Streaming Framework. (arXiv:1807.04662v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.04662</link>
<description rdf:parseType="Literal">&lt;p&gt;Scikit-multiflow is a multi-output/multi-label and stream data mining
framework for the Python programming language. Conceived to serve as a platform
to encourage democratization of stream learning research, it provides multiple
state of the art methods for stream learning, stream generators and evaluators.
scikit-multiflow builds upon popular open source frameworks including
scikit-learn, MOA and MEKA. Development follows the FOSS principles and quality
is enforced by complying with PEP8 guidelines and using continuous integration
and automatic testing. The source code is publicly available at
https://github.com/scikit-multiflow/scikit-multiflow.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Montiel_J/0/1/0/all/0/1&quot;&gt;Jacob Montiel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Read_J/0/1/0/all/0/1&quot;&gt;Jesse Read&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bifet_A/0/1/0/all/0/1&quot;&gt;Albert Bifet&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abdessalem_T/0/1/0/all/0/1&quot;&gt;Talel Abdessalem&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.04687">
<title>Making Efficient Use of a Domain Expert&apos;s Time in Relation Extraction. (arXiv:1807.04687v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.04687</link>
<description rdf:parseType="Literal">&lt;p&gt;Scarcity of labeled data is one of the most frequent problems faced in
machine learning. This is particularly true in relation extraction in text
mining, where large corpora of texts exists in many application domains, while
labeling of text data requires an expert to invest much time to read the
documents. Overall, state-of-the art models, like the convolutional neural
network used in this paper, achieve great results when trained on large enough
amounts of labeled data. However, from a practical point of view the question
arises whether this is the most efficient approach when one takes the manual
effort of the expert into account. In this paper, we report on an alternative
approach where we first construct a relation extraction model using distant
supervision, and only later make use of a domain expert to refine the results.
Distant supervision provides a mean of labeling data given known relations in a
knowledge base, but it suffers from noisy labeling. We introduce an active
learning based extension, that allows our neural network to incorporate expert
feedback and report on first results on a complex data set.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Adilova_L/0/1/0/all/0/1&quot;&gt;Linara Adilova&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Giesselbach_S/0/1/0/all/0/1&quot;&gt;Sven Giesselbach&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ruping_S/0/1/0/all/0/1&quot;&gt;Stefan R&amp;#xfc;ping&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.04740">
<title>Negative Momentum for Improved Game Dynamics. (arXiv:1807.04740v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.04740</link>
<description rdf:parseType="Literal">&lt;p&gt;Games generalize the optimization paradigm by introducing different objective
functions for different optimizing agents, known as players. Generative
Adversarial Networks (GANs) are arguably the most popular game formulation in
recent machine learning literature. GANs achieve great results on generating
realistic natural images, however they are known for being difficult to train.
Training them involves finding a Nash equilibrium, typically performed using
gradient descent on the two players&apos; objectives. Game dynamics can induce
rotations that slow down convergence to a Nash equilibrium, or prevent it
altogether. We provide a theoretical analysis of the game dynamics. Our
analysis, supported by experiments, shows that gradient descent with a negative
momentum term can improve the convergence properties of some GANs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gidel_G/0/1/0/all/0/1&quot;&gt;Gauthier Gidel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hemmat_R/0/1/0/all/0/1&quot;&gt;Reyhane Askari Hemmat&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pezeshki_M/0/1/0/all/0/1&quot;&gt;Mohammad Pezeshki&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_G/0/1/0/all/0/1&quot;&gt;Gabriel Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lepriol_R/0/1/0/all/0/1&quot;&gt;Remi Lepriol&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lacoste_Julien_S/0/1/0/all/0/1&quot;&gt;Simon Lacoste-Julien&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mitliagkas_I/0/1/0/all/0/1&quot;&gt;Ioannis Mitliagkas&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.04875">
<title>Spatio-Temporal Graph Convolutional Networks: A Deep Learning Framework for Traffic Forecasting. (arXiv:1709.04875v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1709.04875</link>
<description rdf:parseType="Literal">&lt;p&gt;Timely accurate traffic forecast is crucial for urban traffic control and
guidance. Due to the high nonlinearity and complexity of traffic flow,
traditional methods cannot satisfy the requirements of mid-and-long term
prediction tasks and often neglect spatial and temporal dependencies. In this
paper, we propose a novel deep learning framework, Spatio-Temporal Graph
Convolutional Networks (STGCN), to tackle the time series prediction problem in
traffic domain. Instead of applying regular convolutional and recurrent units,
we formulate the problem on graphs and build the model with complete
convolutional structures, which enable much faster training speed with fewer
parameters. Experiments show that our model STGCN effectively captures
comprehensive spatio-temporal correlations through modeling multi-scale traffic
networks and consistently outperforms state-of-the-art baselines on various
real-world traffic datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_B/0/1/0/all/0/1&quot;&gt;Bing Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yin_H/0/1/0/all/0/1&quot;&gt;Haoteng Yin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1&quot;&gt;Zhanxing Zhu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.08647">
<title>Fictitious GAN: Training GANs with Historical Models. (arXiv:1803.08647v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1803.08647</link>
<description rdf:parseType="Literal">&lt;p&gt;Generative adversarial networks (GANs) are powerful tools for learning
generative models. In practice, the training may suffer from lack of
convergence. GANs are commonly viewed as a two-player zero-sum game between two
neural networks. Here, we leverage this game theoretic view to study the
convergence behavior of the training process. Inspired by the fictitious play
learning process, a novel training method, referred to as Fictitious GAN, is
introduced. Fictitious GAN trains the deep neural networks using a mixture of
historical models. Specifically, the discriminator (resp. generator) is updated
according to the best-response to the mixture outputs from a sequence of
previously trained generators (resp. discriminators). It is shown that
Fictitious GAN can effectively resolve some convergence issues that cannot be
resolved by the standard training approach. It is proved that asymptotically
the average of the generator outputs has the same distribution as the data
samples.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ge_H/0/1/0/all/0/1&quot;&gt;Hao Ge&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xia_Y/0/1/0/all/0/1&quot;&gt;Yin Xia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1&quot;&gt;Xu Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Berry_R/0/1/0/all/0/1&quot;&gt;Randall Berry&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1&quot;&gt;Ying Wu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.10846">
<title>Data science is science&apos;s second chance to get causal inference right: A classification of data science tasks. (arXiv:1804.10846v4 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1804.10846</link>
<description rdf:parseType="Literal">&lt;p&gt;Causal inference from observational data is the goal of many data analyses in
the health and social sciences. However, academic statistics has often frowned
upon data analyses with a causal objective. The introduction of the term &quot;data
science&quot; provides a historical opportunity to redefine data analysis in such a
way that it naturally accommodates causal inference from observational data.
Like others before, we organize the scientific contributions of data science
into three classes of tasks: description, prediction, and causal inference. An
explicit classification of data science tasks is necessary to discuss the data,
assumptions, and analytics required to successfully accomplish each task. We
argue that a failure to adequately describe the role of subject-matter expert
knowledge in data analysis is a source of widespread misunderstandings about
data science. Specifically, causal analyses typically require not only good
data and algorithms, but also domain expert knowledge. We discuss the
implications for the use of data science to guide decision-making in the real
world and to train data scientists.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hernan_M/0/1/0/all/0/1&quot;&gt;Miguel A. Hern&amp;#xe1;n&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hsu_J/0/1/0/all/0/1&quot;&gt;John Hsu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Healy_B/0/1/0/all/0/1&quot;&gt;Brian Healy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.00928">
<title>Lidar Cloud Detection with Fully Convolutional Networks. (arXiv:1805.00928v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.00928</link>
<description rdf:parseType="Literal">&lt;p&gt;In this contribution, we present a novel approach for segmenting laser radar
(lidar) imagery into geometric time-height cloud locations with a fully
convolutional network (FCN). We describe a semi-supervised learning method to
train the FCN by: pre-training the classification layers of the FCN with
image-level annotations, pre-training the entire FCN with the cloud locations
of the MPLCMASK cloud mask algorithm, and fully supervised learning with
hand-labeled cloud locations. We show the model achieves higher levels of cloud
identification compared to the cloud mask algorithm implementation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cromwell_E/0/1/0/all/0/1&quot;&gt;Erol Cromwell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Flynn_D/0/1/0/all/0/1&quot;&gt;Donna Flynn&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.06604">
<title>Accelerating Nonnegative Matrix Factorization Algorithms using Extrapolation. (arXiv:1805.06604v2 [cs.NA] UPDATED)</title>
<link>http://arxiv.org/abs/1805.06604</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we propose a general framework to accelerate significantly the
algorithms for nonnegative matrix factorization (NMF). This framework is
inspired from the extrapolation scheme used to accelerate gradient methods in
convex optimization and from the method of parallel tangents. However, the use
of extrapolation in the context of the two-block exact coordinate descent
algorithms tackling the non-convex NMF problems is novel. We illustrate the
performance of this approach on two state-of-the-art NMF algorithms, namely,
accelerated hierarchical alternating least squares (A-HALS) and alternating
nonnegative least squares (ANLS), using synthetic, image and document data
sets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ang_A/0/1/0/all/0/1&quot;&gt;Andersen Man Shun Ang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gillis_N/0/1/0/all/0/1&quot;&gt;Nicolas Gillis&lt;/a&gt;</dc:creator>
</item></rdf:RDF>