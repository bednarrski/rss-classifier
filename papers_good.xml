<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Good papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Good Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2017-12-05T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.01507"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.01626"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.01636"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.01682"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.01694"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.01695"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.01697"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.01743"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1611.01639"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1703.07326"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1706.08498"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1708.09116"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.01262"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.01275"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.01328"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.01329"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.01455"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.01488"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.01643"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.01651"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.01668"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.01815"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1302.2223"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1610.00782"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1611.04717"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1611.05497"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1705.04448"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1705.08508"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1705.08850"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.06513"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.02974"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.09395"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.00547"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.00929"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.01312"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.01334"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.01378"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.01447"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.01473"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.01496"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.01521"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.01551"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.01572"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.01664"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.01665"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.01727"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.01807"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1601.00670"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1708.07469"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.06081"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.06219"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.10058"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.00310"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.00891"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1712.01507">
<title>Bit Fusion: Bit-Level Dynamically Composable Architecture for Accelerating Deep Neural Networks. (arXiv:1712.01507v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1712.01507</link>
<description rdf:parseType="Literal">&lt;p&gt;Hardware acceleration of Deep Neural Networks (DNNs) aims to tame their
enormous compute intensity. Fully realizing the potential of acceleration in
this domain requires understanding and leveraging algorithmic properties of
DNNs. This paper builds upon the algorithmic insight that bitwidth of
operations in DNNs can be reduced without compromising their accuracy. However,
to prevent accuracy loss, the bitwidth varies significantly across DNNs and it
may even be adjusted for each layer individually. Thus, a fixed-bitwidth
accelerator would either offer limited benefits to accommodate the worst-case
bitwidth, or inevitably lead to a degradation in final accuracy. To alleviate
these deficiencies, this work introduces dynamic bit-level fusion/decomposition
as a new dimension in the design of DNN accelerators. We explore this dimension
by designing Bit Fusion, a bit-flexible accelerator, that constitutes an array
of bit-level processing elements that dynamically fuse to match the bitwidth of
individual DNN layers. This flexibility in the architecture minimizes the
computation and the communication at the finest granularity possible with no
loss in accuracy. We evaluate the benefits of Bit Fusion using eight real-world
feed-forward and recurrent DNNs. The proposed microarchitecture is implemented
in Verilog and synthesized in 45 nm technology. Using the synthesis results and
cycle accurate simulation, we compare the benefits of Bit Fusion to two
state-of-the-art DNN accelerators, Eyeriss and Stripes. In the same area,
frequency, and technology node, Bit Fusion offers 4.3x speedup and 9.6x energy
savings over Eyeriss. Bit Fusion provides 2.4x speedup and 4.1x energy
reduction over Stripes at 45 nm node when Bit Fusion area and frequency are set
to those of Stripes. Compared to Jetson-TX2, Bit Fusion offers 4.3x speedup and
almost matches the performance of TitanX, which is 4.6x faster than TX2.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sharma_H/0/1/0/all/0/1&quot;&gt;Hardik Sharma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1&quot;&gt;Jongse Park&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Suda_N/0/1/0/all/0/1&quot;&gt;Naveen Suda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lai_L/0/1/0/all/0/1&quot;&gt;Liangzhen Lai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chau_B/0/1/0/all/0/1&quot;&gt;Benson Chau&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1&quot;&gt;Joon Kyung Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chandra_V/0/1/0/all/0/1&quot;&gt;Vikas Chandra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Esmaeilzadeh_H/0/1/0/all/0/1&quot;&gt;Hadi Esmaeilzadeh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.01626">
<title>Autonomous development and learning in artificial intelligence and robotics: Scaling up deep learning to human--like learning. (arXiv:1712.01626v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1712.01626</link>
<description rdf:parseType="Literal">&lt;p&gt;Autonomous lifelong development and learning is a fundamental capability of
humans, differentiating them from current deep learning systems. However, other
branches of artificial intelligence have designed crucial ingredients towards
autonomous learning: curiosity and intrinsic motivation, social learning and
natural interaction with peers, and embodiment. These mechanisms guide
exploration and autonomous choice of goals, and integrating them with deep
learning opens stimulating perspectives. Deep learning (DL) approaches made
great advances in artificial intelligence, but are still far away from human
learning. As argued convincingly by Lake et al., differences include human
capabilities to learn causal models of the world from very little data,
leveraging compositional representations and priors like intuitive physics and
psychology. However, there are other fundamental differences between current DL
systems and human learning, as well as technical ingredients to fill this gap,
that are either superficially, or not adequately, discussed by Lake et al.
These fundamental mechanisms relate to autonomous development and learning.
They are bound to play a central role in artificial intelligence in the future.
Current DL systems require engineers to manually specify a task-specific
objective function for every new task, and learn through off-line processing of
large training databases. On the contrary, humans learn autonomously open-ended
repertoires of skills, deciding for themselves which goals to pursue or value,
and which skills to explore, driven by intrinsic motivation/curiosity and
social learning through natural interaction with peers. Such learning processes
are incremental, online, and progressive. Human child development involves a
progressive increase of complexity in a curriculum of learning where skills are
explored, acquired, and built on each other, through particular ordering and
timing. Finally, human learning happens in the physical world, and through
bodily and physical experimentation, under severe constraints on energy, time,
and computational resources. In the two last decades, the field of
Developmental and Cognitive Robotics (Cangelosi and Schlesinger, 2015, Asada et
al., 2009), in strong interaction with developmental psychology and
neuroscience, has achieved significant advances in computational
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oudeyer_P/0/1/0/all/0/1&quot;&gt;Pierre-Yves Oudeyer&lt;/a&gt; (Flowers)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.01636">
<title>Generalization of Deep Neural Networks for Chest Pathology Classification in X-Rays Using Generative Adversarial Networks. (arXiv:1712.01636v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1712.01636</link>
<description rdf:parseType="Literal">&lt;p&gt;Medical datasets are often highly imbalanced, over representing common
medical problems, and sparsely representing rare problems. We propose
simulation of pathology in images to overcome the above limitations. Using
chest Xrays as a model medical image, we implement a generative adversarial
network (GAN) to create artificial images based upon a modest sized labeled
dataset. We employ a combination of real and artificial images to train a deep
convolutional neural network (DCNN) to detect pathology across five classes of
disease. We furthermore demonstrate that augmenting the original imbalanced
dataset with GAN generated images improves performance of chest pathology
classification using the proposed DCNN in comparison to the same DCNN trained
with the original dataset alone. This improved performance is largely
attributed to balancing of the dataset using GAN generated images, where image
classes that are lacking in example images are preferentially augmented.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Salehinejad_H/0/1/0/all/0/1&quot;&gt;Hojjat Salehinejad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Valaee_S/0/1/0/all/0/1&quot;&gt;Shahrokh Valaee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dowdell_T/0/1/0/all/0/1&quot;&gt;Tim Dowdell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Colak_E/0/1/0/all/0/1&quot;&gt;Errol Colak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barfett_J/0/1/0/all/0/1&quot;&gt;Joseph Barfett&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.01682">
<title>Artificial intelligence in peer review: How can evolutionary computation support journal editors?. (arXiv:1712.01682v1 [cs.DL])</title>
<link>http://arxiv.org/abs/1712.01682</link>
<description rdf:parseType="Literal">&lt;p&gt;With the volume of manuscripts submitted for publication growing every year,
the deficiencies of peer review (e.g. long review times) are becoming more
apparent. Editorial strategies, sets of guidelines designed to speed up the
process and reduce editors workloads, are treated as trade secrets by
publishing houses and are not shared publicly. To improve the effectiveness of
their strategies, editors in small publishing groups are faced with undertaking
an iterative trial-and-error approach. We show that Cartesian Genetic
Programming, a nature-inspired evolutionary algorithm, can dramatically improve
editorial strategies. The artificially evolved strategy reduced the duration of
the peer review process by 30%, without increasing the pool of reviewers (in
comparison to a typical human-developed strategy). Evolutionary computation has
typically been used in technological processes or biological ecosystems. Our
results demonstrate that genetic programs can improve real-world social systems
that are usually much harder to understand and control than physical systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mrowinski_M/0/1/0/all/0/1&quot;&gt;Maciej J. Mrowinski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fronczak_P/0/1/0/all/0/1&quot;&gt;Piotr Fronczak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fronczak_A/0/1/0/all/0/1&quot;&gt;Agata Fronczak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ausloos_M/0/1/0/all/0/1&quot;&gt;Marcel Ausloos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nedic_O/0/1/0/all/0/1&quot;&gt;Olgica Nedic&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.01694">
<title>Fuzzy-Based Dialectical Non-Supervised Image Classification and Clustering. (arXiv:1712.01694v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1712.01694</link>
<description rdf:parseType="Literal">&lt;p&gt;The materialist dialectical method is a philosophical investigative method to
analyze aspects of reality. These aspects are viewed as complex processes
composed by basic units named poles, which interact with each other. Dialectics
has experienced considerable progress in the 19th century, with Hegel&apos;s
dialectics and, in the 20th century, with the works of Marx, Engels, and
Gramsci, in Philosophy and Economics. The movement of poles through their
contradictions is viewed as a dynamic process with intertwined phases of
evolution and revolutionary crisis. In order to build a computational process
based on dialectics, the interaction between poles can be modeled using fuzzy
membership functions. Based on this assumption, we introduce the Objective
Dialectical Classifier (ODC), a non-supervised map for classification based on
materialist dialectics and designed as an extension of fuzzy c-means
classifier. As a case study, we used ODC to classify 181 magnetic resonance
synthetic multispectral images composed by proton density, $T_1$- and
$T_2$-weighted synthetic brain images. Comparing ODC to k-means, fuzzy c-means,
and Kohonen&apos;s self-organized maps, concerning with image fidelity indexes as
estimatives of quantization distortion, we proved that ODC can reach almost the
same quantization performance as optimal non-supervised classifiers like
Kohonen&apos;s self-organized maps.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Santos_W/0/1/0/all/0/1&quot;&gt;Wellington Pinheiro dos Santos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Assis_F/0/1/0/all/0/1&quot;&gt;Francisco Marcos de Assis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Souza_R/0/1/0/all/0/1&quot;&gt;Ricardo Emmanuel de Souza&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mendes_P/0/1/0/all/0/1&quot;&gt;Priscilla B. Mendes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Monteiro_H/0/1/0/all/0/1&quot;&gt;Henrique S. S. Monteiro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alves_H/0/1/0/all/0/1&quot;&gt;Havana Diogo Alves&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.01695">
<title>Triagem virtual de imagens de imuno-histoqu\&apos;imica usando redes neurais artificiais e espectro de padr\~oes. (arXiv:1712.01695v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1712.01695</link>
<description rdf:parseType="Literal">&lt;p&gt;The importance of organizing medical images according to their nature,
application and relevance is increasing. Furhermore, a previous selection of
medical images can be useful to accelerate the task of analysis by
pathologists. Herein this work we propose an image classifier to integrate a
CBIR (Content-Based Image Retrieval) selection system. This classifier is based
on pattern spectra and neural networks. Feature selection is performed using
pattern spectra and principal component analysis, whilst image classification
is based on multilayer perceptrons and a composition of self-organizing maps
and learning vector quantization. These methods were applied for content
selection of immunohistochemical images of placenta and newdeads lungs. Results
demonstrated that this approach can reach reasonable classification
performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lima_H/0/1/0/all/0/1&quot;&gt;Higor Neto Lima&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Santos_W/0/1/0/all/0/1&quot;&gt;Wellington Pinheiro dos Santos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Valenca_M/0/1/0/all/0/1&quot;&gt;M&amp;#xea;user Jorge Silva Valen&amp;#xe7;a&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.01697">
<title>Dialectical Multispectral Classification of Diffusion-Weighted Magnetic Resonance Images as an Alternative to Apparent Diffusion Coefficients Maps to Perform Anatomical Analysis. (arXiv:1712.01697v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1712.01697</link>
<description rdf:parseType="Literal">&lt;p&gt;Multispectral image analysis is a relatively promising field of research with
applications in several areas, such as medical imaging and satellite
monitoring. A considerable number of current methods of analysis are based on
parametric statistics. Alternatively, some methods in Computational
Intelligence are inspired by biology and other sciences. Here we claim that
Philosophy can be also considered as a source of inspiration. This work
proposes the Objective Dialectical Method (ODM): a method for classification
based on the Philosophy of Praxis. ODM is instrumental in assembling evolvable
mathematical tools to analyze multispectral images. In the case study described
in this paper, multispectral images are composed of diffusion-weighted (DW)
magnetic resonance (MR) images. The results are compared to ground-truth images
produced by polynomial networks using a morphological similarity index. The
classification results are used to improve the usual analysis of the apparent
diffusion coefficient map. Such results proved that gray and white matter can
be distinguished in DW-MR multispectral analysis and, consequently, DW-MR
images can also be used to furnish anatomical information.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Santos_W/0/1/0/all/0/1&quot;&gt;Wellington Pinheiro dos Santos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Assis_F/0/1/0/all/0/1&quot;&gt;Francisco Marcos de Assis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Souza_R/0/1/0/all/0/1&quot;&gt;Ricardo Emmanuel de Souza&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Filho_P/0/1/0/all/0/1&quot;&gt;Pl&amp;#xed;nio Batista dos Santos Filho&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Neto_F/0/1/0/all/0/1&quot;&gt;Fernando Buarque de Lima Neto&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.01743">
<title>Design Automation for Binarized Neural Networks: A Quantum Leap Opportunity?. (arXiv:1712.01743v1 [cs.OH])</title>
<link>http://arxiv.org/abs/1712.01743</link>
<description rdf:parseType="Literal">&lt;p&gt;Design automation in general, and in particular logic synthesis, can play a
key role in enabling the design of application-specific Binarized Neural
Networks (BNN). This paper presents the hardware design and synthesis of a
purely combinational BNN for ultra-low power near-sensor processing. We
leverage the major opportunities raised by BNN models, which consist mostly of
logical bit-wise operations and integer counting and comparisons, for pushing
ultra-low power deep learning circuits close to the sensor and coupling it with
binarized mixed-signal image sensor data. We analyze area, power and energy
metrics of BNNs synthesized as combinational networks. Our synthesis results in
GlobalFoundries 22nm SOI technology shows a silicon area of 2.61mm2 for
implementing a combinational BNN with 32x32 binary input sensor receptive field
and weight parameters fixed at design time. This is 2.2x smaller than a
synthesized network with re-configurable parameters. With respect to other
comparable techniques for deep learning near-sensor processing, our approach
features a 10x higher energy efficiency.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rusci_M/0/1/0/all/0/1&quot;&gt;Manuele Rusci&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cavigelli_L/0/1/0/all/0/1&quot;&gt;Lukas Cavigelli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Benini_L/0/1/0/all/0/1&quot;&gt;Luca Benini&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1611.01639">
<title>Robustly representing inferential uncertainty in deep neural networks through sampling. (arXiv:1611.01639v5 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1611.01639</link>
<description rdf:parseType="Literal">&lt;p&gt;As deep neural networks (DNNs) are applied to increasingly challenging
problems, they will need to be able to represent their own uncertainty.
Modeling uncertainty is one of the key features of Bayesian methods. Using
Bernoulli dropout with sampling at prediction time has recently been proposed
as an efficient and well performing variational inference method for DNNs.
However, sampling from other multiplicative noise based variational
distributions has not been investigated in depth. We evaluated Bayesian DNNs
trained with Bernoulli or Gaussian multiplicative masking of either the units
(dropout) or the weights (dropconnect). We tested the calibration of the
probabilistic predictions of Bayesian convolutional neural networks (CNNs) on
MNIST and CIFAR-10. Sampling at prediction time increased the calibration of
the DNNs&apos; probabalistic predictions. Sampling weights, whether Gaussian or
Bernoulli, led to more robust representation of uncertainty compared to
sampling of units. However, using either Gaussian or Bernoulli dropout led to
increased test set classification accuracy. Based on these findings we used
both Bernoulli dropout and Gaussian dropconnect concurrently, which we show
approximates the use of a spike-and-slab variational distribution without
increasing the number of learned parameters. We found that spike-and-slab
sampling had higher test set performance than Gaussian dropconnect and more
robustly represented its uncertainty compared to Bernoulli dropout.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+McClure_P/0/1/0/all/0/1&quot;&gt;Patrick McClure&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kriegeskorte_N/0/1/0/all/0/1&quot;&gt;Nikolaus Kriegeskorte&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1703.07326">
<title>One-Shot Imitation Learning. (arXiv:1703.07326v3 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1703.07326</link>
<description rdf:parseType="Literal">&lt;p&gt;Imitation learning has been commonly applied to solve different tasks in
isolation. This usually requires either careful feature engineering, or a
significant number of samples. This is far from what we desire: ideally, robots
should be able to learn from very few demonstrations of any given task, and
instantly generalize to new situations of the same task, without requiring
task-specific engineering. In this paper, we propose a meta-learning framework
for achieving such capability, which we call one-shot imitation learning.
&lt;/p&gt;
&lt;p&gt;Specifically, we consider the setting where there is a very large set of
tasks, and each task has many instantiations. For example, a task could be to
stack all blocks on a table into a single tower, another task could be to place
all blocks on a table into two-block towers, etc. In each case, different
instances of the task would consist of different sets of blocks with different
initial states. At training time, our algorithm is presented with pairs of
demonstrations for a subset of all tasks. A neural net is trained that takes as
input one demonstration and the current state (which initially is the initial
state of the other demonstration of the pair), and outputs an action with the
goal that the resulting sequence of states and actions matches as closely as
possible with the second demonstration. At test time, a demonstration of a
single instance of a new task is presented, and the neural net is expected to
perform well on new instances of this new task. The use of soft attention
allows the model to generalize to conditions and tasks unseen in the training
data. We anticipate that by training this model on a much greater variety of
tasks and settings, we will obtain a general system that can turn any
demonstrations into robust policies that can accomplish an overwhelming variety
of tasks.
&lt;/p&gt;
&lt;p&gt;Videos available at https://bit.ly/nips2017-oneshot .
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Duan_Y/0/1/0/all/0/1&quot;&gt;Yan Duan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Andrychowicz_M/0/1/0/all/0/1&quot;&gt;Marcin Andrychowicz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stadie_B/0/1/0/all/0/1&quot;&gt;Bradly C. Stadie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ho_J/0/1/0/all/0/1&quot;&gt;Jonathan Ho&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schneider_J/0/1/0/all/0/1&quot;&gt;Jonas Schneider&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sutskever_I/0/1/0/all/0/1&quot;&gt;Ilya Sutskever&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1&quot;&gt;Pieter Abbeel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zaremba_W/0/1/0/all/0/1&quot;&gt;Wojciech Zaremba&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1706.08498">
<title>Spectrally-normalized margin bounds for neural networks. (arXiv:1706.08498v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1706.08498</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents a margin-based multiclass generalization bound for neural
networks that scales with their margin-normalized &quot;spectral complexity&quot;: their
Lipschitz constant, meaning the product of the spectral norms of the weight
matrices, times a certain correction factor. This bound is empirically
investigated for a standard AlexNet network trained with SGD on the mnist and
cifar10 datasets, with both original and random labels; the bound, the
Lipschitz constants, and the excess risks are all in direct correlation,
suggesting both that SGD selects predictors whose complexity scales with the
difficulty of the learning task, and secondly that the presented bound is
sensitive to this complexity.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bartlett_P/0/1/0/all/0/1&quot;&gt;Peter Bartlett&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Foster_D/0/1/0/all/0/1&quot;&gt;Dylan J. Foster&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Telgarsky_M/0/1/0/all/0/1&quot;&gt;Matus Telgarsky&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1708.09116">
<title>Slope Stability Analysis with Geometric Semantic Genetic Programming. (arXiv:1708.09116v2 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1708.09116</link>
<description rdf:parseType="Literal">&lt;p&gt;Genetic programming has been widely used in the engineering field. Compared
with the conventional genetic programming and artificial neural network,
geometric semantic genetic programming (GSGP) is superior in astringency and
computing efficiency. In this paper, GSGP is adopted for the classification and
regression analysis of a sample dataset. Furthermore, a model for slope
stability analysis is established on the basis of geometric semantics.
According to the results of the study based on GSGP, the method can analyze
slope stability objectively and is highly precise in predicting slope stability
and safety factors. Hence, the predicted results can be used as a reference for
slope safety design.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1&quot;&gt;Juncai Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_Z/0/1/0/all/0/1&quot;&gt;Zhenzhong Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ren_Q/0/1/0/all/0/1&quot;&gt;Qingwen Ren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1&quot;&gt;Xin Xie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1&quot;&gt;Zhengyu Yang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.01262">
<title>Compatibility Family Learning for Item Recommendation and Generation. (arXiv:1712.01262v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1712.01262</link>
<description rdf:parseType="Literal">&lt;p&gt;Compatibility between items, such as clothes and shoes, is a major factor
among customer&apos;s purchasing decisions. However, learning &quot;compatibility&quot; is
challenging due to (1) broader notions of compatibility than those of
similarity, (2) the asymmetric nature of compatibility, and (3) only a small
set of compatible and incompatible items are observed. We propose an end-to-end
trainable system to embed each item into a latent vector and project a query
item into K compatible prototypes in the same space. These prototypes reflect
the broad notions of compatibility. We refer to both the embedding and
prototypes as &quot;Compatibility Family&quot;. In our learned space, we introduce a
novel Projected Compatibility Distance (PCD) function which is differentiable
and ensures diversity by aiming for at least one prototype to be close to a
compatible item, whereas none of the prototypes are close to an incompatible
item. We evaluate our system on a toy dataset, two Amazon product datasets, and
Polyvore outfit dataset. Our method consistently achieves state-of-the-art
performance. Finally, we show that we can visualize the candidate compatible
prototypes using a Metric-regularized Conditional Generative Adversarial
Network (MrCGAN), where the input is a projected prototype and the output is a
generated image of a compatible item. We ask human evaluators to judge the
relative compatibility between our generated images and images generated by
CGANs conditioned directly on query items. Our generated images are
significantly preferred, with roughly twice the number of votes as others.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shih_Y/0/1/0/all/0/1&quot;&gt;Yong-Siang Shih&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1&quot;&gt;Kai-Yueh Chang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1&quot;&gt;Hsuan-Tien Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1&quot;&gt;Min Sun&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.01275">
<title>A Deeper Look at Experience Replay. (arXiv:1712.01275v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1712.01275</link>
<description rdf:parseType="Literal">&lt;p&gt;Experience replay plays an important role in the success of deep
reinforcement learning (RL) by helping stabilize the neural networks. It has
become a new norm in deep RL algorithms. In this paper, however, we showcase
that varying the size of the experience replay buffer can hurt the performance
even in very simple tasks. The size of the replay buffer is actually a
hyper-parameter which needs careful tuning. Moreover, our study of experience
replay leads to the formulation of the Combined DQN algorithm, which can
significantly outperform primitive DQN in some tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1&quot;&gt;Shangtong Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sutton_R/0/1/0/all/0/1&quot;&gt;Richard S. Sutton&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.01328">
<title>Learning User Intent from Action Sequences on Interactive Systems. (arXiv:1712.01328v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1712.01328</link>
<description rdf:parseType="Literal">&lt;p&gt;Interactive systems have taken over the web and mobile space with increasing
participation from users. Applications across every marketing domain can now be
accessed through mobile or web where users can directly perform certain actions
and reach a desired outcome. Actions of user on a system, though, can be
representative of a certain intent. Ability to learn this intent through user&apos;s
actions can help draw certain insight into the behavior of users on a system.
&lt;/p&gt;
&lt;p&gt;In this paper, we present models to optimize interactive systems by learning
and analyzing user intent through their actions on the system. We present a
four phased model that uses time-series of interaction actions sequentially
using a Long Short-Term Memory (LSTM) based sequence learning system that helps
build a model for intent recognition. Our system then provides an objective
specific maximization followed by analysis and contrasting methods in order to
identify spaces of improvement in the interaction system. We discuss deployment
scenarios for such a system and present results from evaluation on an online
marketplace using user clickstream data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Agrawal_R/0/1/0/all/0/1&quot;&gt;Rakshit Agrawal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Habeeb_A/0/1/0/all/0/1&quot;&gt;Anwar Habeeb&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hsueh_C/0/1/0/all/0/1&quot;&gt;Chih-Hsin Hsueh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.01329">
<title>Examining Cooperation in Visual Dialog Models. (arXiv:1712.01329v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1712.01329</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work we propose a blackbox intervention method for visual dialog
models, with the aim of assessing the contribution of individual linguistic or
visual components. Concretely, we conduct structured or randomized
interventions that aim to impair an individual component of the model, and
observe changes in task performance. We reproduce a state-of-the-art visual
dialog model and demonstrate that our methodology yields surprising insights,
namely that both dialog and image information have minimal contributions to
task performance. The intervention method presented here can be applied as a
sanity check for the strength and robustness of each component in visual dialog
systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mironenco_M/0/1/0/all/0/1&quot;&gt;Mircea Mironenco&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kianfar_D/0/1/0/all/0/1&quot;&gt;Dana Kianfar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tran_K/0/1/0/all/0/1&quot;&gt;Ke Tran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kanoulas_E/0/1/0/all/0/1&quot;&gt;Evangelos Kanoulas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gavves_E/0/1/0/all/0/1&quot;&gt;Efstratios Gavves&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.01455">
<title>Multimodal Storytelling via Generative Adversarial Imitation Learning. (arXiv:1712.01455v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1712.01455</link>
<description rdf:parseType="Literal">&lt;p&gt;Deriving event storylines is an effective summarization method to succinctly
organize extensive information, which can significantly alleviate the pain of
information overload. The critical challenge is the lack of widely recognized
definition of storyline metric. Prior studies have developed various approaches
based on different assumptions about users&apos; interests. These works can extract
interesting patterns, but their assumptions do not guarantee that the derived
patterns will match users&apos; preference. On the other hand, their exclusiveness
of single modality source misses cross-modality information. This paper
proposes a method, multimodal imitation learning via generative adversarial
networks(MIL-GAN), to directly model users&apos; interests as reflected by various
data. In particular, the proposed model addresses the critical challenge by
imitating users&apos; demonstrated storylines. Our proposed model is designed to
learn the reward patterns given user-provided storylines and then applies the
learned policy to unseen data. The proposed approach is demonstrated to be
capable of acquiring the user&apos;s implicit intent and outperforming competing
methods by a substantial margin with a user study.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1&quot;&gt;Zhiqian Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xuchao Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Boedihardjo_A/0/1/0/all/0/1&quot;&gt;Arnold P. Boedihardjo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dai_J/0/1/0/all/0/1&quot;&gt;Jing Dai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_C/0/1/0/all/0/1&quot;&gt;Chang-Tien Lu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.01488">
<title>Determinism in the Certification of UNSAT Proofs. (arXiv:1712.01488v1 [cs.LO])</title>
<link>http://arxiv.org/abs/1712.01488</link>
<description rdf:parseType="Literal">&lt;p&gt;The search for increased trustworthiness of SAT solvers is very active and
uses various methods. Some of these methods obtain a proof from the provers
then check it, normally by replicating the search based on the proof&apos;s
information. Because the certification process involves another nontrivial
proof search, the trust we can place in it is decreased. Some attempts to amend
this use certifiers which have been verified by proofs assistants such as
Isabelle/HOL and Coq. Our approach is different because it is based on an
extremely simplified certifier. This certifier enjoys a very high level of
trust but is very inefficient. In this paper, we experiment with this approach
and conclude that by placing some restrictions on the formats, one can mostly
eliminate the need for search and in principle, can certify proofs of arbitrary
size.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Libal_T/0/1/0/all/0/1&quot;&gt;Tomer Libal&lt;/a&gt; (Inria, Paris), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Steele_X/0/1/0/all/0/1&quot;&gt;Xaviera Steele&lt;/a&gt; (American University of Paris)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.01643">
<title>Discriminant Projection Representation-based Classification for Vision Recognition. (arXiv:1712.01643v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1712.01643</link>
<description rdf:parseType="Literal">&lt;p&gt;Representation-based classification methods such as sparse
representation-based classification (SRC) and linear regression classification
(LRC) have attracted a lot of attentions. In order to obtain the better
representation, a novel method called projection representation-based
classification (PRC) is proposed for image recognition in this paper. PRC is
based on a new mathematical model. This model denotes that the &apos;ideal
projection&apos; of a sample point $x$ on the hyper-space $H$ may be gained by
iteratively computing the projection of $x$ on a line of hyper-space $H$ with
the proper strategy. Therefore, PRC is able to iteratively approximate the
&apos;ideal representation&apos; of each subject for classification. Moreover, the
discriminant PRC (DPRC) is further proposed, which obtains the discriminant
information by maximizing the ratio of the between-class reconstruction error
over the within-class reconstruction error. Experimental results on five
typical databases show that the proposed PRC and DPRC are effective and
outperform other state-of-the-art methods on several vision recognition tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feng_Q/0/1/0/all/0/1&quot;&gt;Qingxiang Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1&quot;&gt;Yicong Zhou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.01651">
<title>Dilated FCN for Multi-Agent 2D/3D Medical Image Registration. (arXiv:1712.01651v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1712.01651</link>
<description rdf:parseType="Literal">&lt;p&gt;2D/3D image registration to align a 3D volume and 2D X-ray images is a
challenging problem due to its ill-posed nature and various artifacts presented
in 2D X-ray images. In this paper, we propose a multi-agent system with an auto
attention mechanism for robust and efficient 2D/3D image registration.
Specifically, an individual agent is trained with dilated Fully Convolutional
Network (FCN) to perform registration in a Markov Decision Process (MDP) by
observing a local region, and the final action is then taken based on the
proposals from multiple agents and weighted by their corresponding confidence
levels. The contributions of this paper are threefold. First, we formulate
2D/3D registration as a MDP with observations, actions, and rewards properly
defined with respect to X-ray imaging systems. Second, to handle various
artifacts in 2D X-ray images, multiple local agents are employed efficiently
via FCN-based structures, and an auto attention mechanism is proposed to favor
the proposals from regions with more reliable visual cues. Third, a dilated
FCN-based training mechanism is proposed to significantly reduce the Degree of
Freedom in the simulation of registration environment, and drastically improve
training efficiency by an order of magnitude compared to standard CNN-based
training method. We demonstrate that the proposed method achieves high
robustness on both spine cone beam Computed Tomography data with a low
signal-to-noise ratio and data from minimally invasive spine surgery where
severe image artifacts and occlusions are presented due to metal screws and
guide wires, outperforming other state-of-the-art methods (single agent-based
and optimization-based) by a large margin.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Miao_S/0/1/0/all/0/1&quot;&gt;Shun Miao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Piat_S/0/1/0/all/0/1&quot;&gt;Sebastien Piat&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fischer_P/0/1/0/all/0/1&quot;&gt;Peter Fischer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tuysuzoglu_A/0/1/0/all/0/1&quot;&gt;Ahmet Tuysuzoglu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mewes_P/0/1/0/all/0/1&quot;&gt;Philip Mewes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mansi_T/0/1/0/all/0/1&quot;&gt;Tommaso Mansi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liao_R/0/1/0/all/0/1&quot;&gt;Rui Liao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.01668">
<title>A Novel Brain Decoding Method: a Correlation Network Framework for Revealing Brain Connections. (arXiv:1712.01668v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1712.01668</link>
<description rdf:parseType="Literal">&lt;p&gt;Brain decoding is a hot spot in cognitive science, which focuses on
reconstructing perceptual images from brain activities. Analyzing the
correlations of collected data from human brain activities and representing
activity patterns are two problems in brain decoding based on functional
magnetic resonance imaging (fMRI) signals. However, existing correlation
analysis methods mainly focus on the strength information of voxel, which
reveals functional connectivity in the cerebral cortex. They tend to neglect
the structural information that implies the intracortical or intrinsic
connections; that is, structural connectivity. Hence, the effective
connectivity inferred by these methods is relatively unilateral. Therefore, we
proposed a correlation network (CorrNet) framework that could be flexibly
combined with diverse pattern representation models. In the CorrNet framework,
the topological correlation was introduced to reveal structural information.
Rich correlations were obtained, which contributed to specifying the underlying
effective connectivity. We also combined the CorrNet framework with a linear
support vector machine (SVM) and a dynamic evolving spike neuron network (SNN)
for pattern representation separately, thus providing a novel method for
decoding cognitive activity patterns. Experimental results verified the
reliability and robustness of our CorrNet framework and demonstrated that the
new method achieved significant improvement in brain decoding over comparable
methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_S/0/1/0/all/0/1&quot;&gt;Siyu Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_N/0/1/0/all/0/1&quot;&gt;Nanning Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1&quot;&gt;Yongqiang Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1&quot;&gt;Hao Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1&quot;&gt;Badong Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.01815">
<title>Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm. (arXiv:1712.01815v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1712.01815</link>
<description rdf:parseType="Literal">&lt;p&gt;The game of chess is the most widely-studied domain in the history of
artificial intelligence. The strongest programs are based on a combination of
sophisticated search techniques, domain-specific adaptations, and handcrafted
evaluation functions that have been refined by human experts over several
decades. In contrast, the AlphaGo Zero program recently achieved superhuman
performance in the game of Go, by tabula rasa reinforcement learning from games
of self-play. In this paper, we generalise this approach into a single
AlphaZero algorithm that can achieve, tabula rasa, superhuman performance in
many challenging domains. Starting from random play, and given no domain
knowledge except the game rules, AlphaZero achieved within 24 hours a
superhuman level of play in the games of chess and shogi (Japanese chess) as
well as Go, and convincingly defeated a world-champion program in each case.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Silver_D/0/1/0/all/0/1&quot;&gt;David Silver&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hubert_T/0/1/0/all/0/1&quot;&gt;Thomas Hubert&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schrittwieser_J/0/1/0/all/0/1&quot;&gt;Julian Schrittwieser&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Antonoglou_I/0/1/0/all/0/1&quot;&gt;Ioannis Antonoglou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lai_M/0/1/0/all/0/1&quot;&gt;Matthew Lai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guez_A/0/1/0/all/0/1&quot;&gt;Arthur Guez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lanctot_M/0/1/0/all/0/1&quot;&gt;Marc Lanctot&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sifre_L/0/1/0/all/0/1&quot;&gt;Laurent Sifre&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kumaran_D/0/1/0/all/0/1&quot;&gt;Dharshan Kumaran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Graepel_T/0/1/0/all/0/1&quot;&gt;Thore Graepel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lillicrap_T/0/1/0/all/0/1&quot;&gt;Timothy Lillicrap&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Simonyan_K/0/1/0/all/0/1&quot;&gt;Karen Simonyan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hassabis_D/0/1/0/all/0/1&quot;&gt;Demis Hassabis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1302.2223">
<title>WNtags: A Web-Based Tool For Image Labeling And Retrieval With Lexical Ontologies. (arXiv:1302.2223v2 [cs.IR] UPDATED)</title>
<link>http://arxiv.org/abs/1302.2223</link>
<description rdf:parseType="Literal">&lt;p&gt;Ever growing number of image documents available on the Internet continuously
motivates research in better annotation models and more efficient retrieval
methods. Formal knowledge representation of objects and events in pictures,
their interaction as well as context complexity becomes no longer an option for
a quality image repository, but a necessity. We present an ontology-based
online image annotation tool WNtags and demonstrate its usefulness in several
typical multimedia retrieval tasks using International Affective Picture System
emotionally annotated image database. WNtags is built around WordNet lexical
ontology but considers Suggested Upper Merged Ontology as the preferred
labeling formalism. WNtags uses sets of weighted WordNet synsets as high-level
image semantic descriptors and query matching is performed with word stemming
and node distance metrics. We also elaborate our near future plans to expand
image content description with induced affect as in stimuli for research of
human emotion and attention.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Horvat_M/0/1/0/all/0/1&quot;&gt;Marko Horvat&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grbin_A/0/1/0/all/0/1&quot;&gt;Anton Grbin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gledec_G/0/1/0/all/0/1&quot;&gt;Gordan Gledec&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1610.00782">
<title>Network Structure Inference, A Survey: Motivations, Methods, and Applications. (arXiv:1610.00782v3 [cs.SI] UPDATED)</title>
<link>http://arxiv.org/abs/1610.00782</link>
<description rdf:parseType="Literal">&lt;p&gt;Networks represent relationships between entities in many complex systems,
spanning from online social interactions to biological cell development and
brain connectivity. In many cases, relationships between entities are
unambiguously known: are two users &apos;friends&apos; in a social network? Do two
researchers collaborate on a published paper? Do two road segments in a
transportation system intersect? These are directly observable in the system in
question. In most cases, relationship between nodes are not directly observable
and must be inferred: does one gene regulate the expression of another? Do two
animals who physically co-locate have a social bond? Who infected whom in a
disease outbreak in a population? Existing approaches for inferring networks
from data are found across many application domains, and use specialized
knowledge to infer and measure the quality of inferred network for a specific
task or hypothesis. However, current research lacks a rigorous methodology
which employs standard statistical validation on inferred models. In this
survey, we examine (1) how network representations are constructed from
underlying data, (2) the variety of questions and tasks on these
representations over several domains, and (3) validation strategies for
measuring the inferred network&apos;s capability of answering questions on the
system of interest.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brugere_I/0/1/0/all/0/1&quot;&gt;Ivan Brugere&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gallagher_B/0/1/0/all/0/1&quot;&gt;Brian Gallagher&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Berger_Wolf_T/0/1/0/all/0/1&quot;&gt;Tanya Y. Berger-Wolf&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1611.04717">
<title>#Exploration: A Study of Count-Based Exploration for Deep Reinforcement Learning. (arXiv:1611.04717v3 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1611.04717</link>
<description rdf:parseType="Literal">&lt;p&gt;Count-based exploration algorithms are known to perform near-optimally when
used in conjunction with tabular reinforcement learning (RL) methods for
solving small discrete Markov decision processes (MDPs). It is generally
thought that count-based methods cannot be applied in high-dimensional state
spaces, since most states will only occur once. Recent deep RL exploration
strategies are able to deal with high-dimensional continuous state spaces
through complex heuristics, often relying on optimism in the face of
uncertainty or intrinsic motivation. In this work, we describe a surprising
finding: a simple generalization of the classic count-based approach can reach
near state-of-the-art performance on various high-dimensional and/or continuous
deep RL benchmarks. States are mapped to hash codes, which allows to count
their occurrences with a hash table. These counts are then used to compute a
reward bonus according to the classic count-based exploration theory. We find
that simple hash functions can achieve surprisingly good results on many
challenging tasks. Furthermore, we show that a domain-dependent learned hash
code may further improve these results. Detailed analysis reveals important
aspects of a good hash function: 1) having appropriate granularity and 2)
encoding information relevant to solving the MDP. This exploration strategy
achieves near state-of-the-art performance on both continuous control tasks and
Atari 2600 games, hence providing a simple yet powerful baseline for solving
MDPs that require considerable exploration.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_H/0/1/0/all/0/1&quot;&gt;Haoran Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Houthooft_R/0/1/0/all/0/1&quot;&gt;Rein Houthooft&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Foote_D/0/1/0/all/0/1&quot;&gt;Davis Foote&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stooke_A/0/1/0/all/0/1&quot;&gt;Adam Stooke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1&quot;&gt;Xi Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Duan_Y/0/1/0/all/0/1&quot;&gt;Yan Duan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schulman_J/0/1/0/all/0/1&quot;&gt;John Schulman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Turck_F/0/1/0/all/0/1&quot;&gt;Filip De Turck&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1&quot;&gt;Pieter Abbeel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1611.05497">
<title>Explicablility as Minimizing Distance from Expected Behavior. (arXiv:1611.05497v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1611.05497</link>
<description rdf:parseType="Literal">&lt;p&gt;In order to have effective human AI collaboration, it is not simply enough to
address the question of autonomy; an equally important question is, how the
AI&apos;s behavior is being perceived by their human counterparts. When AI agent&apos;s
task plans are generated without such considerations, they may often
demonstrate inexplicable behavior from the human&apos;s point of view. This problem
arises due to the human&apos;s partial or inaccurate understanding of the agent&apos;s
planning process and/or the model. This may have serious implications on
human-AI collaboration, from increased cognitive load and reduced trust in the
agent, to more serious concerns of safety in interactions with physical agent.
In this paper, we address this issue by modeling the notion of plan
explicability as a function of the distance between a plan that agent makes and
the plan that human expects it to make. To this end, we learn a distance
function based on different plan distance measures that can accurately model
this notion of plan explicability, and develop an anytime search algorithm that
can use this distance as a heuristic to come up with progressively explicable
plans. We evaluate the effectiveness of our approach in a simulated autonomous
car domain and a physical service robot domain. We provide empirical
evaluations that demonstrate the usefulness of our approach in making the
planning process of an autonomous agent conform to human expectations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kulkarni_A/0/1/0/all/0/1&quot;&gt;Anagha Kulkarni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zha_Y/0/1/0/all/0/1&quot;&gt;Yantian Zha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chakraborti_T/0/1/0/all/0/1&quot;&gt;Tathagata Chakraborti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vadlamudi_S/0/1/0/all/0/1&quot;&gt;Satya Gautam Vadlamudi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yu Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kambhampati_S/0/1/0/all/0/1&quot;&gt;Subbarao Kambhampati&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1705.04448">
<title>R2-D2: ColoR-inspired Convolutional NeuRal Network (CNN)-based AndroiD Malware Detections. (arXiv:1705.04448v4 [cs.CR] UPDATED)</title>
<link>http://arxiv.org/abs/1705.04448</link>
<description rdf:parseType="Literal">&lt;p&gt;Machine Learning (ML) has found it particularly useful in malware detection.
However, as the malware evolves very fast, the stability of the feature
extracted from malware serves as a critical issue in malware detection. Recent
success of deep learning in image recognition, natural language processing, and
machine translation indicate a potential solution for stabilizing the malware
detection effectiveness. We present a coloR-inspired convolutional neuRal
network-based AndroiD malware Detection (R2-D2), which can detect malware
without extracting pre-selected features (e.g., the control-flow of op-code,
classes, methods of functions and the timing they are invoked etc.) from
Android apps. In particular, we develop a color representation for translating
Android apps into RGB color code and transform them to a fixed-sized encoded
image. After that, the encoded image is fed to convolutional neural network for
automatic feature extraction and learning, reducing the expert&apos;s intervention.
We have collected over 1 million malware samples and 1 million benign samples
according to the data provided by Leopard Mobile Inc. from its core product
Security Master (which has 623 million monthly active users and 10k new malware
samples per day). It is shown that R2-D2 can effectively detect the malware.
Furthermore, we keep our research results and release experiment material on
&lt;a href=&quot;http://R2D2.TWMAN.ORG&quot;&gt;this http URL&lt;/a&gt; if there is any update.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_T/0/1/0/all/0/1&quot;&gt;TonTon Hsien-De Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kao_H/0/1/0/all/0/1&quot;&gt;Hung-Yu Kao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1705.08508">
<title>Vehicle Traffic Driven Camera Placement for Better Metropolis Security Surveillance. (arXiv:1705.08508v3 [cs.CY] UPDATED)</title>
<link>http://arxiv.org/abs/1705.08508</link>
<description rdf:parseType="Literal">&lt;p&gt;Security surveillance is one of the most important issues in smart cities,
especially in an era of terrorism. Deploying a number of (video) cameras is a
common surveillance approach. Given the never-ending power offered by vehicles
to metropolises, exploiting vehicle traffic to design camera placement
strategies could potentially facilitate security surveillance. This article
constitutes the first effort toward building the linkage between vehicle
traffic and security surveillance, which is a critical problem for smart
cities. We expect our study could influence the decision making of surveillance
camera placement, and foster more research of principled ways of security
surveillance beneficial to our physical-world life.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1&quot;&gt;Yihui He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1&quot;&gt;Xiaobo Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_X/0/1/0/all/0/1&quot;&gt;Xiapu Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jianfeng Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_M/0/1/0/all/0/1&quot;&gt;Mengchen Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+An_B/0/1/0/all/0/1&quot;&gt;Bo An&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guan_X/0/1/0/all/0/1&quot;&gt;Xiaohong Guan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1705.08850">
<title>Semi-supervised Learning with GANs: Manifold Invariance with Improved Inference. (arXiv:1705.08850v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1705.08850</link>
<description rdf:parseType="Literal">&lt;p&gt;Semi-supervised learning methods using Generative Adversarial Networks (GANs)
have shown promising empirical success recently. Most of these methods use a
shared discriminator/classifier which discriminates real examples from fake
while also predicting the class label. Motivated by the ability of the GANs
generator to capture the data manifold well, we propose to estimate the tangent
space to the data manifold using GANs and employ it to inject invariances into
the classifier. In the process, we propose enhancements over existing methods
for learning the inverse mapping (i.e., the encoder) which greatly improves in
terms of semantic similarity of the reconstructed sample with the input sample.
We observe considerable empirical gains in semi-supervised learning over
baselines, particularly in the cases when the number of labeled examples is
low. We also provide insights into how fake examples influence the
semi-supervised learning procedure.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kumar_A/0/1/0/all/0/1&quot;&gt;Abhishek Kumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sattigeri_P/0/1/0/all/0/1&quot;&gt;Prasanna Sattigeri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fletcher_P/0/1/0/all/0/1&quot;&gt;P. Thomas Fletcher&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.06513">
<title>Learning Pose Grammar to Encode Human Body Configuration for 3D Pose Estimation. (arXiv:1710.06513v4 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1710.06513</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we propose a pose grammar to tackle the problem of 3D human
pose estimation. Our model directly takes 2D pose as input and learns a
generalized 2D-3D mapping function. The proposed model consists of a base
network which efficiently captures pose-aligned features and a hierarchy of
Bi-directional RNNs (BRNN) on the top to explicitly incorporate a set of
knowledge regarding human body configuration (i.e., kinematics, symmetry, motor
coordination). The proposed model thus enforces high-level constraints over
human poses. In learning, we develop a pose sample simulator to augment
training samples in virtual camera views, which further improves our model
generalizability. We validate our method on public 3D human pose benchmarks and
propose a new evaluation protocol working on cross-view setting to verify the
generalization capability of different methods. We empirically observe that
most state-of-the-art methods encounter difficulty under such setting while our
method can well handle such challenges.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fang_H/0/1/0/all/0/1&quot;&gt;Haoshu Fang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1&quot;&gt;Yuanlu Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1&quot;&gt;Wenguan Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1&quot;&gt;Xiaobai Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_S/0/1/0/all/0/1&quot;&gt;Song-Chun Zhu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.02974">
<title>Clustering with feature selection using alternating minimization, Application to computational biology. (arXiv:1711.02974v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1711.02974</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper deals with unsupervised clustering with feature selection. The
problem is to estimate both labels and a sparse projection matrix of weights.
To address this combinatorial non-convex problem maintaining a strict control
on the sparsity of the matrix of weights, we propose an alternating
minimization of the Frobenius norm criterion. We provide a new efficient
algorithm named K-sparse which alternates k-means with projection-gradient
minimization. The projection-gradient step is a method of splitting type, with
exact projection on the $\ell^1$ ball to promote sparsity. The convergence of
the gradient-projection step is addressed, and a preliminary analysis of the
alternating minimization is made. The Frobenius norm criterion converges as the
number of iterates in Algorithm K-sparse goes to infinity. Experiments on
Single Cell RNA sequencing datasets show that our method significantly improves
the results of PCA k-means, spectral clustering, SIMLR, and Sparcl methods, and
achieves a relevant selection of genes. The complexity of K-sparse is linear in
the number of samples (cells), so that the method scales up to large datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gilet_C/0/1/0/all/0/1&quot;&gt;Cyprien Gilet&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deprez_M/0/1/0/all/0/1&quot;&gt;Marie Deprez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Caillau_J/0/1/0/all/0/1&quot;&gt;Jean-Baptiste Caillau&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barlaud_M/0/1/0/all/0/1&quot;&gt;Michel Barlaud&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.09395">
<title>Improved Neural Text Attribute Transfer with Non-parallel Data. (arXiv:1711.09395v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1711.09395</link>
<description rdf:parseType="Literal">&lt;p&gt;Text attribute transfer using non-parallel data requires methods that can
perform disentanglement of content and linguistic attributes. In this work, we
propose multiple improvements over the existing approaches that enable the
encoder-decoder framework to cope with the text attribute transfer from
non-parallel data. We perform experiments on the sentiment transfer task using
two datasets. For both datasets, our proposed method outperforms a strong
baseline in two of the three employed evaluation metrics.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Melnyk_I/0/1/0/all/0/1&quot;&gt;Igor Melnyk&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Santos_C/0/1/0/all/0/1&quot;&gt;Cicero Nogueira dos Santos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wadhawan_K/0/1/0/all/0/1&quot;&gt;Kahini Wadhawan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Padhi_I/0/1/0/all/0/1&quot;&gt;Inkit Padhi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kumar_A/0/1/0/all/0/1&quot;&gt;Abhishek Kumar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.00547">
<title>Explainable AI: Beware of Inmates Running the Asylum Or: How I Learnt to Stop Worrying and Love the Social and Behavioural Sciences. (arXiv:1712.00547v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1712.00547</link>
<description rdf:parseType="Literal">&lt;p&gt;In his seminal book `The Inmates are Running the Asylum: Why High-Tech
Products Drive Us Crazy And How To Restore The Sanity&apos; [2004, Sams
Indianapolis, IN, USA], Alan Cooper argues that a major reason why software is
often poorly designed (from a user perspective) is that programmers are in
charge of design decisions, rather than interaction designers. As a result,
programmers design software for themselves, rather than for their target
audience, a phenomenon he refers to as the `inmates running the asylum&apos;. This
paper argues that explainable AI risks a similar fate. While the re-emergence
of explainable AI is positive, this paper argues most of us as AI researchers
are building explanatory agents for ourselves, rather than for the intended
users. But explainable AI is more likely to succeed if researchers and
practitioners understand, adopt, implement, and improve models from the vast
and valuable bodies of research in philosophy, psychology, and cognitive
science, and if evaluation of these models is focused more on people than on
technology. From a light scan of literature, we demonstrate that there is
considerable scope to infuse more results from the social and behavioural
sciences into explainable AI, and present some key results from these fields
that are relevant to explainable AI.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Miller_T/0/1/0/all/0/1&quot;&gt;Tim Miller&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Howe_P/0/1/0/all/0/1&quot;&gt;Piers Howe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sonenberg_L/0/1/0/all/0/1&quot;&gt;Liz Sonenberg&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.00929">
<title>SERKET: An Architecture for Connecting Stochastic Models to Realize a Large-Scale Cognitive Model. (arXiv:1712.00929v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1712.00929</link>
<description rdf:parseType="Literal">&lt;p&gt;To realize human-like robot intelligence, a large-scale cognitive
architecture is required for robots to understand the environment through a
variety of sensors with which they are equipped. In this paper, we propose a
novel framework named Serket that enables the construction of a large-scale
generative model and its inference easily by connecting sub-modules to allow
the robots to acquire various capabilities through interaction with their
environments and others. We consider that large-scale cognitive models can be
constructed by connecting smaller fundamental models hierarchically while
maintaining their programmatic independence. Moreover, connected modules are
dependent on each other, and parameters are required to be optimized as a
whole. Conventionally, the equations for parameter estimation have to be
derived and implemented depending on the models. However, it becomes harder to
derive and implement those of a larger scale model. To solve these problems, in
this paper, we propose a method for parameter estimation by communicating the
minimal parameters between various modules while maintaining their programmatic
independence. Therefore, Serket makes it easy to construct large-scale models
and estimate their parameters via the connection of modules. Experimental
results demonstrated that the model can be constructed by connecting modules,
the parameters can be optimized as a whole, and they are comparable with the
original models that we have proposed.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nakamura_T/0/1/0/all/0/1&quot;&gt;Tomoaki Nakamura&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nagai_T/0/1/0/all/0/1&quot;&gt;Takayuki Nagai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Taniguchi_T/0/1/0/all/0/1&quot;&gt;Tadahiro Taniguchi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.01312">
<title>Learning Sparse Neural Networks through $L_0$ Regularization. (arXiv:1712.01312v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1712.01312</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a practical method for $L_0$ norm regularization for neural
networks: pruning the network during training by encouraging weights to become
exactly zero. Such regularization is interesting since (1) it can greatly speed
up training and inference, and (2) it can improve generalization. AIC and BIC,
well-known model selection criteria, are special cases of $L_0$ regularization.
However, since the $L_0$ norm of weights is non-differentiable, we cannot
incorporate it directly as a regularization term in the objective function. We
propose a solution through the inclusion of a collection of non-negative
stochastic gates, which collectively determine which weights to set to zero. We
show that, somewhat surprisingly, for certain distributions over the gates, the
expected $L_0$ norm of the resulting gated weights is differentiable with
respect to the distribution parameters. We further propose the \emph{hard
concrete} distribution for the gates, which is obtained by &quot;stretching&quot; a
binary concrete distribution and then transforming its samples with a
hard-sigmoid. The parameters of the distribution over the gates can then be
jointly optimized with the original network parameters. As a result our method
allows for straightforward and efficient learning of model structures with
stochastic gradient descent and allows for conditional computation in a
principled way. We perform various experiments to demonstrate the effectiveness
of the resulting approach and regularizer.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Louizos_C/0/1/0/all/0/1&quot;&gt;Christos Louizos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Welling_M/0/1/0/all/0/1&quot;&gt;Max Welling&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kingma_D/0/1/0/all/0/1&quot;&gt;Diederik P. Kingma&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.01334">
<title>Modelling collective motion based on the principle of agency. (arXiv:1712.01334v1 [q-bio.PE])</title>
<link>http://arxiv.org/abs/1712.01334</link>
<description rdf:parseType="Literal">&lt;p&gt;Collective motion is an intriguing phenomenon, especially considering that it
arises from a set of simple rules governing local interactions between
individuals. In theoretical models, these rules are normally \emph{assumed} to
take a particular form, possibly constrained by heuristic arguments. We propose
a new class of models, which describe the individuals as \emph{agents}, capable
of deciding for themselves how to act and learning from their experiences. The
local interaction rules do not need to be postulated in this model, since they
\emph{emerge} from the learning process. We apply this ansatz to a concrete
scenario involving marching locusts, in order to model the phenomenon of
density-dependent alignment. We show that our learning agent-based model can
account for a Fokker-Planck equation that describes the collective motion and,
most notably, that the agents can learn the appropriate local interactions,
requiring no strong previous assumptions on their form. These results suggest
that learning agent-based models are a powerful tool for studying a broader
class of problems involving collective motion and animal agency in general.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Ried_K/0/1/0/all/0/1&quot;&gt;Katja Ried&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Muller_T/0/1/0/all/0/1&quot;&gt;Thomas M&amp;#xfc;ller&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Briegel_H/0/1/0/all/0/1&quot;&gt;Hans J. Briegel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.01378">
<title>Linearly-Recurrent Autoencoder Networks for Learning Dynamics. (arXiv:1712.01378v1 [math.DS])</title>
<link>http://arxiv.org/abs/1712.01378</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper describes a method for learning low-dimensional approximations of
nonlinear dynamical systems, based on neural-network approximations of the
underlying Koopman operator. Extended Dynamic Mode Decomposition (EDMD)
provides a useful data-driven approximation of the Koopman operator for
analyzing dynamical systems. This paper addresses a fundamental problem
associated with EDMD: a trade-off between representational capacity of the
dictionary and over-fitting due to insufficient data. A new neural network
architecture combining an autoencoder with linear recurrent dynamics in the
encoded state is used to learn a low-dimensional and highly informative
Koopman-invariant subspace of observables. A method is also presented for
balanced model reduction of over-specified EDMD systems in feature space.
Nonlinear reconstruction using partially linear multi-kernel regression aims to
improve reconstruction accuracy from the low-dimensional state when the data
has complex but intrinsically low-dimensional structure. The techniques
demonstrate the ability to identify Koopman eigenfunctions of the unforced
Duffing equation, create accurate low-dimensional models of an unstable
cylinder wake flow, and make short-time predictions of the chaotic
Kuramoto-Sivashinsky equation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Otto_S/0/1/0/all/0/1&quot;&gt;Samuel E. Otto&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Rowley_C/0/1/0/all/0/1&quot;&gt;Clarence W. Rowley&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.01447">
<title>Gaussian Process bandits with adaptive discretization. (arXiv:1712.01447v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1712.01447</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, the problem of maximizing a black-box function $f:\mathcal{X}
\to \mathbb{R}$ is studied in the Bayesian framework with a Gaussian Process
(GP) prior. In particular, a new algorithm for this problem is proposed, and
high probability bounds on its simple and cumulative regret are established.
The query point selection rule in most existing methods involves an exhaustive
search over an increasingly fine sequence of uniform discretizations of
$\mathcal{X}$. The proposed algorithm, in contrast, adaptively refines
$\mathcal{X}$ which leads to a lower computational complexity, particularly
when $\mathcal{X}$ is a subset of a high dimensional Euclidean space. In
addition to the computational gains, sufficient conditions are identified under
which the regret bounds of the new algorithm improve upon the known results.
Finally an extension of the algorithm to the case of contextual bandits is
proposed, and high probability bounds on the contextual regret are presented.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Shekhar_S/0/1/0/all/0/1&quot;&gt;Shubhanshu Shekhar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Javidi_T/0/1/0/all/0/1&quot;&gt;Tara Javidi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.01473">
<title>Deep linear neural networks with arbitrary loss: All local minima are global. (arXiv:1712.01473v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1712.01473</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider deep linear networks with arbitrary differentiable loss. We
provide a short and elementary proof of the following fact: all local minima
are global minima if each hidden layer is wider than either the input or output
layer.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Laurent_T/0/1/0/all/0/1&quot;&gt;Thomas Laurent&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brecht_J/0/1/0/all/0/1&quot;&gt;James von Brecht&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.01496">
<title>Learning Pain from Action Unit Combinations: A Weakly Supervised Approach via Multiple Instance Learning. (arXiv:1712.01496v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1712.01496</link>
<description rdf:parseType="Literal">&lt;p&gt;Facial pain expression is an important modality for assessing pain,
especially when a patient&apos;s verbal ability to communicate is impaired. A set of
eight facial muscle based action units (AUs), which are defined by the Facial
Action Coding System (FACS), have been widely studied and are highly reliable
for pain detection through facial expressions. However, using FACS is a very
time consuming task that makes its clinical use prohibitive. An automated
facial expression recognition system (AFER) reliably detecting pain-related AUs
would be highly beneficial for efficient and practical pain monitoring.
Automated pain detection under clinical settings is viewed as a weakly
supervised problem, which is not suitable general AFER system that trained on
well labeled data. Existing pain oriented AFER research either focus on the
individual pain-related AU recognition or bypassing the AU detection procedure
by training a binary pain classifier from pain intensity data. In this paper,
we decouple pain detection into two consecutive tasks: the AFER based AU
labeling at video frame level and a probabilistic measure of pain at sequence
level from AU combination scores. Our work is distinguished in the following
aspects, 1) State of the art AFER tools Emotient is applied on pain oriented
data sets for single AU labeling. 2) Two different data structures are proposed
to encode AU combinations from single AU scores, which forms low-dimensional
feature vectors for the learning framework. 3) Two weakly supervised learning
frameworks namely multiple instance learning and multiple clustered instance
learning are employed corresponding to each feature structure to learn pain
from video sequences. The results shows 87% pain recognition accuracy with 0.94
AUC on UNBC-McMaster dataset. Tests on Wilkie&apos;s dataset suggests the potential
value of the proposed system for pain monitoring task under clinical settings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1&quot;&gt;Zhanli Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ansari_R/0/1/0/all/0/1&quot;&gt;Rashid Ansari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wilkie_D/0/1/0/all/0/1&quot;&gt;Diana J. Wilkie&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.01521">
<title>An Online Algorithm for Nonparametric Correlations. (arXiv:1712.01521v1 [stat.AP])</title>
<link>http://arxiv.org/abs/1712.01521</link>
<description rdf:parseType="Literal">&lt;p&gt;Nonparametric correlations such as Spearman&apos;s rank correlation and Kendall&apos;s
tau correlation are widely applied in scientific and engineering fields. This
paper investigates the problem of computing nonparametric correlations on the
fly for streaming data. Standard batch algorithms are generally too slow to
handle real-world big data applications. They also require too much memory
because all the data need to be stored in the memory before processing. This
paper proposes a novel online algorithm for computing nonparametric
correlations. The algorithm has O(1) time complexity and O(1) memory cost and
is quite suitable for edge devices, where only limited memory and processing
power are available. You can seek a balance between speed and accuracy by
changing the number of cutpoints specified in the algorithm. The online
algorithm can compute the nonparametric correlations 10 to 1,000 times faster
than the corresponding batch algorithm, and it can compute them based either on
all past observations or on fixed-size sliding windows.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Xiao_W/0/1/0/all/0/1&quot;&gt;Wei Xiao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.01551">
<title>Manifold-valued Image Generation with Wasserstein Adversarial Networks. (arXiv:1712.01551v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1712.01551</link>
<description rdf:parseType="Literal">&lt;p&gt;Unsupervised image generation has recently received an increasing amount of
attention thanks to the great success of generative adversarial networks
(GANs), particularly Wasserstein GANs. Inspired by the paradigm of real-valued
image generation, this paper makes the first attempt to formulate the problem
of generating manifold-valued images, which are frequently encountered in
real-world applications. For the study, we specially exploit three typical
manifold-valued image generation tasks: hue-saturation-value (HSV) color image
generation, chromaticity-brightness (CB) color image generation, and
diffusion-tensor (DT) image generation. In order to produce such kinds of
images as realistic as possible, we generalize the state-of-the-art technique
of Wasserstein GANs to the manifold context with exploiting Riemannian
geometry. For the proposed manifold-valued image generation problem, we
recommend three benchmark datasets that are CIFAR-10 HSV/CB color images,
ImageNet HSV/CB color images, UCL DT image datasets. On the three datasets, we
experimentally demonstrate the proposed manifold-aware Wasserestein GAN can
generate high quality manifold-valued images.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1&quot;&gt;Zhiwu Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1&quot;&gt;Jiqing Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gool_L/0/1/0/all/0/1&quot;&gt;Luc Van Gool&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.01572">
<title>Eigendecompositions of Transfer Operators in Reproducing Kernel Hilbert Spaces. (arXiv:1712.01572v1 [math.DS])</title>
<link>http://arxiv.org/abs/1712.01572</link>
<description rdf:parseType="Literal">&lt;p&gt;Transfer operators such as the Perron-Frobenius or Koopman operator play an
important role in the global analysis of complex dynamical systems. The
eigenfunctions of these operators can be used to detect metastable sets, to
project the dynamics onto the dominant slow processes, or to separate
superimposed signals. We extend transfer operator theory to reproducing kernel
Hilbert spaces and show that these operators are related to Hilbert space
representations of conditional distributions, known as conditional mean
embeddings in the machine learning community. Moreover, numerical methods to
compute empirical estimates of these embeddings are akin to data-driven methods
for the approximation of transfer operators such as extended dynamic mode
decomposition and its variants. In fact, most of the existing methods can be
derived from our framework, providing a unifying view on the approximation of
transfer operators. One main benefit of the presented kernel-based approaches
is that these methods can be applied to any domain where a similarity measure
given by a kernel is available. We illustrate the results with the aid of
guiding examples and highlight potential applications in molecular dynamics as
well as video and text data analysis.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Klus_S/0/1/0/all/0/1&quot;&gt;Stefan Klus&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Schuster_I/0/1/0/all/0/1&quot;&gt;Ingmar Schuster&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Muandet_K/0/1/0/all/0/1&quot;&gt;Krikamol Muandet&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.01664">
<title>Learning a Generative Model for Validity in Complex Discrete Structures. (arXiv:1712.01664v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1712.01664</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep generative models have been successfully used to learn representations
for high-dimensional discrete spaces by representing discrete objects as
sequences, for which powerful sequence-based deep models can be employed.
Unfortunately, these techniques are significantly hindered by the fact that
these generative models often produce invalid sequences: sequences which do not
represent any underlying discrete structure. As a step towards solving this
problem, we propose to learn a deep recurrent validator model, which can
estimate whether a partial sequence can function as the beginning of a full,
valid sequence. This model not only discriminates between valid and invalid
sequences, but also provides insight as to how individual sequence elements
influence the validity of the overall sequence, and the existence of a
corresponding discrete object. To learn this model we propose a reinforcement
learning approach, where an oracle which can evaluate validity of complete
sequences provides a sparse reward signal. We believe this is a key step toward
learning generative models that faithfully produce valid sequences which
represent discrete objects. We demonstrate its effectiveness in evaluating the
validity of Python 3 source code for mathematical expressions, and improving
the ability of a variational autoencoder trained on SMILES strings to decode
valid molecular structures.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Janz_D/0/1/0/all/0/1&quot;&gt;David Janz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Westhuizen_J/0/1/0/all/0/1&quot;&gt;Jos van der Westhuizen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Paige_B/0/1/0/all/0/1&quot;&gt;Brooks Paige&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kusner_M/0/1/0/all/0/1&quot;&gt;Matt J. Kusner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hernandez_Labato_J/0/1/0/all/0/1&quot;&gt;Jose Miguel Hernandez-Labato&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.01665">
<title>Differentially Private Dropout. (arXiv:1712.01665v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1712.01665</link>
<description rdf:parseType="Literal">&lt;p&gt;Large data collections required for the training of neural networks often
contain sensitive information such as the medical histories of patients, and
the privacy of the training data must be preserved. In this paper, we introduce
a dropout technique that provides an elegant Bayesian interpretation to
dropout, and show that the intrinsic noise added, with the primary goal of
regularization, can be exploited to obtain a degree of differential privacy.
The iterative nature of training neural networks presents a challenge for
privacy-preserving estimation since multiple iterations increase the amount of
noise added. We overcome this by using a relaxed notion of differential
privacy, called concentrated differential privacy, which provides tighter
estimates on the overall privacy loss. We demonstrate the accuracy of our
privacy-preserving dropout algorithm on benchmark datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ermis_B/0/1/0/all/0/1&quot;&gt;Beyza Ermis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Cemgil_A/0/1/0/all/0/1&quot;&gt;Ali Taylan Cemgil&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.01727">
<title>OL\&apos;E: Orthogonal Low-rank Embedding, A Plug and Play Geometric Loss for Deep Learning. (arXiv:1712.01727v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1712.01727</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep neural networks trained using a softmax layer at the top and the
cross-entropy loss are ubiquitous tools for image classification. Yet, this
does not naturally enforce intra-class similarity nor inter-class margin of the
learned deep representations. To simultaneously achieve these two goals,
different solutions have been proposed in the literature, such as the pairwise
or triplet losses. However, such solutions carry the extra task of selecting
pairs or triplets, and the extra computational burden of computing and learning
for many combinations of them. In this paper, we propose a plug-and-play loss
term for deep networks that explicitly reduces intra-class variance and
enforces inter-class margin simultaneously, in a simple and elegant geometric
manner. For each class, the deep features are collapsed into a learned linear
subspace, or union of them, and inter-class subspaces are pushed to be as
orthogonal as possible. Our proposed Orthogonal Low-rank Embedding (OL\&apos;E) does
not require carefully crafting pairs or triplets of samples for training, and
works standalone as a classification loss, being the first reported deep metric
learning framework of its kind. Because of the improved margin between features
of different classes, the resulting deep networks generalize better, are more
discriminative, and more robust. We demonstrate improved classification
performance in general object recognition, plugging the proposed loss term into
existing off-the-shelf architectures. In particular, we show the advantage of
the proposed loss in the small data/model scenario, and we significantly
advance the state-of-the-art on the Stanford STL-10 benchmark.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lezama_J/0/1/0/all/0/1&quot;&gt;Jos&amp;#xe9; Lezama&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qiu_Q/0/1/0/all/0/1&quot;&gt;Qiang Qiu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Muse_P/0/1/0/all/0/1&quot;&gt;Pablo Mus&amp;#xe9;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sapiro_G/0/1/0/all/0/1&quot;&gt;Guillermo Sapiro&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.01807">
<title>Improving the Performance of Online Neural Transducer Models. (arXiv:1712.01807v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1712.01807</link>
<description rdf:parseType="Literal">&lt;p&gt;Having a sequence-to-sequence model which can operate in an online fashion is
important for streaming applications such as Voice Search. Neural transducer is
a streaming sequence-to-sequence model, but has shown a significant degradation
in performance compared to non-streaming models such as Listen, Attend and
Spell (LAS). In this paper, we present various improvements to NT.
Specifically, we look at increasing the window over which NT computes
attention, mainly by looking backwards in time so the model still remains
online. In addition, we explore initializing a NT model from a LAS-trained
model so that it is guided with a better alignment. Finally, we explore
including stronger language models such as using wordpiece models, and applying
an external LM during the beam search. On a Voice Search task, we find with
these improvements we can get NT to match the performance of LAS.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sainath_T/0/1/0/all/0/1&quot;&gt;Tara N. Sainath&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chiu_C/0/1/0/all/0/1&quot;&gt;Chung-Cheng Chiu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Prabhavalkar_R/0/1/0/all/0/1&quot;&gt;Rohit Prabhavalkar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kannan_A/0/1/0/all/0/1&quot;&gt;Anjuli Kannan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1&quot;&gt;Yonghui Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_P/0/1/0/all/0/1&quot;&gt;Patrick Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1&quot;&gt;Zhifeng Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1601.00670">
<title>Variational Inference: A Review for Statisticians. (arXiv:1601.00670v7 [stat.CO] UPDATED)</title>
<link>http://arxiv.org/abs/1601.00670</link>
<description rdf:parseType="Literal">&lt;p&gt;One of the core problems of modern statistics is to approximate
difficult-to-compute probability densities. This problem is especially
important in Bayesian statistics, which frames all inference about unknown
quantities as a calculation involving the posterior density. In this paper, we
review variational inference (VI), a method from machine learning that
approximates probability densities through optimization. VI has been used in
many applications and tends to be faster than classical methods, such as Markov
chain Monte Carlo sampling. The idea behind VI is to first posit a family of
densities and then to find the member of that family which is close to the
target. Closeness is measured by Kullback-Leibler divergence. We review the
ideas behind mean-field variational inference, discuss the special case of VI
applied to exponential family models, present a full example with a Bayesian
mixture of Gaussians, and derive a variant that uses stochastic optimization to
scale up to massive data. We discuss modern research in VI and highlight
important open problems. VI is powerful, but it is not yet well understood. Our
hope in writing this paper is to catalyze statistical research on this class of
algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Blei_D/0/1/0/all/0/1&quot;&gt;David M. Blei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kucukelbir_A/0/1/0/all/0/1&quot;&gt;Alp Kucukelbir&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+McAuliffe_J/0/1/0/all/0/1&quot;&gt;Jon D. McAuliffe&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1708.07469">
<title>DGM: A deep learning algorithm for solving partial differential equations. (arXiv:1708.07469v2 [q-fin.MF] UPDATED)</title>
<link>http://arxiv.org/abs/1708.07469</link>
<description rdf:parseType="Literal">&lt;p&gt;}High-dimensional PDEs have been a longstanding computational challenge. We
propose to solve high-dimensional PDEs by approximating the solution with a
deep neural network which is trained to satisfy the differential operator,
initial condition, and boundary conditions. We prove that the neural network
converges to the solution of the partial differential equation as the number of
hidden units increases. Our algorithm is meshfree, which is key since meshes
become infeasible in higher dimensions. Instead of forming a mesh, the neural
network is trained on batches of randomly sampled time and space points. We
implement the approach for American options (a type of free-boundary PDE which
is widely used in finance) in up to $200$ dimensions. We call the algorithm a
&quot;Deep Galerkin Method (DGM)&quot; since it is similar in spirit to Galerkin methods,
with the solution approximated by a neural network instead of a linear
combination of basis functions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-fin/1/au:+Sirignano_J/0/1/0/all/0/1&quot;&gt;Justin Sirignano&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-fin/1/au:+Spiliopoulos_K/0/1/0/all/0/1&quot;&gt;Konstantinos Spiliopoulos&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.06081">
<title>Boosting Adversarial Attacks with Momentum. (arXiv:1710.06081v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1710.06081</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep neural networks are vulnerable to adversarial examples, which poses
security concerns on these algorithms due to the potentially severe
consequences. Adversarial attacks serve as an important surrogate to evaluate
the robustness of deep learning models before they are deployed. However, most
of the existing adversarial attacks can only fool a black-box model with a low
success rate because of the coupling of the attack ability and the
transferability. To address this issue, we propose a broad class of
momentum-based iterative algorithms to boost adversarial attacks. By
integrating the momentum term into the iterative process for attacks, our
methods can stabilize update directions and escape from poor local maxima
during the iterations, resulting in more transferable adversarial examples. To
further improve the success rates for black-box attacks, we apply momentum
iterative algorithms to an ensemble of models, and show that the adversarially
trained models with a strong defense ability are also vulnerable to our
black-box attacks. We hope that the proposed methods will serve as a benchmark
for evaluating the robustness of various deep models and defense methods. We
won the first places in NIPS 2017 Non-targeted Adversarial Attack and Targeted
Adversarial Attack competitions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1&quot;&gt;Yinpeng Dong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liao_F/0/1/0/all/0/1&quot;&gt;Fangzhou Liao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pang_T/0/1/0/all/0/1&quot;&gt;Tianyu Pang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1&quot;&gt;Hang Su&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1&quot;&gt;Xiaolin Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jianguo Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1&quot;&gt;Jun Zhu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.06219">
<title>Learning to Warm-Start Bayesian Hyperparameter Optimization. (arXiv:1710.06219v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1710.06219</link>
<description rdf:parseType="Literal">&lt;p&gt;Hyperparameter optimization undergoes extensive evaluations of validation
errors in order to find its best configuration. Bayesian optimization is now
popular for hyperparameter optimization, since it reduces the number of
validation error evaluations required. Suppose that we are given a collection
of datasets on which hyperparameters are already tuned by either humans with
domain expertise or extensive trials of cross-validation. When a model is
applied to a new dataset, it is desirable to let Bayesian optimization start
from configurations that were successful on similar datasets. To this end, we
construct a Siamese network with convolutional layers followed by
bi-directional LSTM layers, to learn meta-features over image datasets. Learned
meta-features are used to select a few datasets that are similar to the new
dataset, so that a set of configurations in similar datasets is adopted as
initialization to warm-start Bayesian hyperparameter optimization. Experiments
on image datasets demonstrate that our learned meta-features are useful in
optimizing hyperparameters in deep residual networks for image classification.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kim_J/0/1/0/all/0/1&quot;&gt;Jungtaek Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kim_S/0/1/0/all/0/1&quot;&gt;Saehoon Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Choi_S/0/1/0/all/0/1&quot;&gt;Seungjin Choi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.10058">
<title>Dependent relevance determination for smooth and structured sparse regression. (arXiv:1711.10058v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1711.10058</link>
<description rdf:parseType="Literal">&lt;p&gt;In many problem settings, parameter vectors are not merely sparse, but
dependent in such a way that non-zero coefficients tend to cluster together. We
refer to this form of dependency as &quot;region sparsity&quot;. Classical sparse
regression methods, such as the lasso and automatic relevance determination
(ARD), which model parameters as independent a priori, and therefore do not
exploit such dependencies. Here we introduce a hierarchical model for smooth,
region-sparse weight vectors and tensors in a linear regression setting. Our
approach represents a hierarchical extension of the relevance determination
framework, where we add a transformed Gaussian process to model the
dependencies between the prior variances of regression weights. We combine this
with a structured model of the prior variances of Fourier coefficients, which
eliminates unnecessary high frequencies. The resulting prior encourages weights
to be region-sparse in two different bases simultaneously. We develop Laplace
approximation and Monte Carlo Markov Chain (MCMC) sampling to provide efficient
inference for the posterior. Furthermore, a two-stage convex relaxation of the
Laplace approximation approach is also provided to relax the inevitable
non-convexity during the optimization. We finally show substantial improvements
over comparable methods for both simulated and real datasets from brain
imaging.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wu_A/0/1/0/all/0/1&quot;&gt;Anqi Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Koyejo_O/0/1/0/all/0/1&quot;&gt;Oluwasanmi Koyejo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pillow_J/0/1/0/all/0/1&quot;&gt;Jonathan W. Pillow&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.00310">
<title>Deep Learning with Permutation-invariant Operator for Multi-instance Histopathology Classification. (arXiv:1712.00310v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1712.00310</link>
<description rdf:parseType="Literal">&lt;p&gt;The computer-aided analysis of medical scans is a longstanding goal in the
medical imaging field. Currently, deep learning has became a dominant
methodology for supporting pathologists and radiologist. Deep learning
algorithms have been successfully applied to digital pathology and radiology,
nevertheless, there are still practical issues that prevent these tools to be
widely used in practice. The main obstacles are low number of available cases
and large size of images (a.k.a. the small n, large p problem in machine
learning), and a very limited access to annotation at a pixel level that can
lead to severe overfitting and large computational requirements. We propose to
handle these issues by introducing a framework that processes a medical image
as a collection of small patches using a single, shared neural network. The
final diagnosis is provided by combining scores of individual patches using a
permutation-invariant operator (combination). In machine learning community
such approach is called a multi-instance learning (MIL).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tomczak_J/0/1/0/all/0/1&quot;&gt;Jakub M. Tomczak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ilse_M/0/1/0/all/0/1&quot;&gt;Maximilian Ilse&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Welling_M/0/1/0/all/0/1&quot;&gt;Max Welling&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.00891">
<title>Data Dropout in Arbitrary Basis for Deep Network Regularization. (arXiv:1712.00891v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1712.00891</link>
<description rdf:parseType="Literal">&lt;p&gt;An important problem in training deep networks with high capacity is to
ensure that the trained network works well when presented with new inputs
outside the training dataset. Dropout is an effective regularization technique
to boost the network generalization in which a random subset of the elements of
the given data and the extracted features are set to zero during the training
process. In this paper, a new randomized regularization technique in which we
withhold a random part of the data without necessarily turning off the
neurons/data-elements is proposed. In the proposed method, of which the
conventional dropout is shown to be a special case, random data dropout is
performed in an arbitrary basis, hence the designation Generalized Dropout. We
also present a framework whereby the proposed technique can be applied
efficiently to convolutional neural networks. The presented numerical
experiments demonstrate that the proposed technique yields notable performance
gain. Generalized Dropout provides new insight into the idea of dropout, shows
that we can achieve different performance gains by using different bases
matrices, and opens up a new research question as of how to choose optimal
bases matrices that achieve maximal performance gain.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rahmani_M/0/1/0/all/0/1&quot;&gt;Mostafa Rahmani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Atia_G/0/1/0/all/0/1&quot;&gt;George Atia&lt;/a&gt;</dc:creator>
</item></rdf:RDF>