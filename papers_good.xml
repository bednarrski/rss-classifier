<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Good papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Good Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-04-09T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.02464"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.02491"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.02813"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09913"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.00497"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.02391"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.02477"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.02528"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.02596"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.02698"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.03126"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1612.07139"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.03430"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.06128"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.02209"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.02852"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.00612"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.11439"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.02411"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.02484"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.02485"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.02617"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.02665"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.02763"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.03077"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1209.0367"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.04833"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.01952"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.09136"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06441"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08770"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.01682"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.10122"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1804.02464">
<title>Differentiable plasticity: training plastic neural networks with backpropagation. (arXiv:1804.02464v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1804.02464</link>
<description rdf:parseType="Literal">&lt;p&gt;How can we build agents that keep learning from experience, quickly and
efficiently, after their initial training? Here we take inspiration from the
main mechanism of learning in biological brains: synaptic plasticity, carefully
tuned by evolution to produce efficient lifelong learning. We show that
plasticity, just like connection weights, can be optimized by gradient descent
in large (millions of parameters) recurrent networks with Hebbian plastic
connections. First, recurrent plastic networks with more than two million
parameters can be trained to memorize and reconstruct sets of novel,
high-dimensional 1000+ pixels natural images not seen during training.
Crucially, traditional non-plastic recurrent networks fail to solve this task.
Furthermore, trained plastic networks can also solve generic meta-learning
tasks such as the Omniglot task, with competitive results and little parameter
overhead. Finally, in reinforcement learning settings, plastic networks
outperform a non-plastic equivalent in a maze exploration task. We conclude
that differentiable plasticity may provide a powerful novel approach to the
learning-to-learn problem.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Miconi_T/0/1/0/all/0/1&quot;&gt;Thomas Miconi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Clune_J/0/1/0/all/0/1&quot;&gt;Jeff Clune&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stanley_K/0/1/0/all/0/1&quot;&gt;Kenneth O. Stanley&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.02491">
<title>Continuously Constructive Deep Neural Networks. (arXiv:1804.02491v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1804.02491</link>
<description rdf:parseType="Literal">&lt;p&gt;Traditionally, deep learning algorithms update the network weights whereas
the network architecture is chosen manually, using a process of trial and
error. In this work, we propose two novel approaches that automatically update
the network structure while also learning its weights. The novelty of our
approach lies in our parameterization where the depth, or additional
complexity, is encapsulated continuously in the parameter space through control
parameters that add additional complexity. We propose two methods: In tunnel
networks, this selection is done at the level of a hidden unit, and in budding
perceptrons, this is done at the level of a network layer; updating this
control parameter introduces either another hidden unit or another hidden
layer. We show the effectiveness of our methods on the synthetic two-spirals
data and on two real data sets of MNIST and MIRFLICKR, where we see that our
proposed methods, with the same set of hyperparameters, can correctly adjust
the network complexity to the task complexity.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Irsoy_O/0/1/0/all/0/1&quot;&gt;Ozan &amp;#x130;rsoy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alpaydin_E/0/1/0/all/0/1&quot;&gt;Ethem Alpayd&amp;#x131;n&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.02813">
<title>An Adaptive Learning Method of Personality Trait Based Mood in Mental State Transition Network by Recurrent Neural Network. (arXiv:1804.02813v1 [cs.HC])</title>
<link>http://arxiv.org/abs/1804.02813</link>
<description rdf:parseType="Literal">&lt;p&gt;Mental State Transition Network (MSTN) is a basic concept of approximating to
human psychological and mental responses. A stimulus calculated by Emotion
Generating Calculations (EGC) method can cause the transition of mood from an
emotional state to others. In this paper, the agent can interact with human to
realize smooth communication by an adaptive learning method of the user&apos;s
personality trait based mood. The learning method consists of the profit
sharing (PS) method and the recurrent neural network (RNN). An emotion for
sensor inputs to MSTN is calculated by EGC and the variance of emotion leads to
the change of mental state, and then the sequence of states forms an episode.
In order to learn the tendency of personality trait effectively, the
ineffective rules should be removed from the episode. PS method finds out a
detour in episode and should be deleted. Furthermore, RNN works to realize the
variance of user&apos;s mood. Some experimental results were shown the success of
representing a various human&apos;s delicate emotion.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ichimura_T/0/1/0/all/0/1&quot;&gt;Takumi Ichimura&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tanabe_K/0/1/0/all/0/1&quot;&gt;Kosuke Tanabe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yamashita_T/0/1/0/all/0/1&quot;&gt;Toshiyuki Yamashita&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09913">
<title>Multi-task Learning of Pairwise Sequence Classification Tasks Over Disparate Label Spaces. (arXiv:1802.09913v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1802.09913</link>
<description rdf:parseType="Literal">&lt;p&gt;We combine multi-task learning and semi-supervised learning by inducing a
joint embedding space between disparate label spaces and learning transfer
functions between label embeddings, enabling us to jointly leverage unlabelled
data and auxiliary, annotated datasets. We evaluate our approach on a variety
of sequence classification tasks with disparate label spaces. We outperform
strong single and multi-task baselines and achieve a new state-of-the-art for
topic-based sentiment analysis.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Augenstein_I/0/1/0/all/0/1&quot;&gt;Isabelle Augenstein&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ruder_S/0/1/0/all/0/1&quot;&gt;Sebastian Ruder&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sogaard_A/0/1/0/all/0/1&quot;&gt;Anders S&amp;#xf8;gaard&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.00497">
<title>muNet: A Highly Compact Deep Convolutional Neural Network Architecture for Real-time Embedded Traffic Sign Classification. (arXiv:1804.00497v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1804.00497</link>
<description rdf:parseType="Literal">&lt;p&gt;Traffic sign recognition is a very important computer vision task for a
number of real-world applications such as intelligent transportation
surveillance and analysis. While deep neural networks have been demonstrated in
recent years to provide state-of-the-art performance traffic sign recognition,
a key challenge for enabling the widespread deployment of deep neural networks
for embedded traffic sign recognition is the high computational and memory
requirements of such networks. As a consequence, there are significant benefits
in investigating compact deep neural network architectures for traffic sign
recognition that are better suited for embedded devices. In this paper, we
introduce muNet, a highly compact deep convolutional neural network for
real-time embedded traffic sign recognition based on macroarchitecture design
principles as well as microarchitecture optimization strategies. The resulting
overall architecture of muNet is thus designed with as few parameters and
computations as possible while maintaining recognition performance. The
resulting muNet possesses a model size of just ~1MB and ~510,000 parameters
(~27x fewer parameters than state-of-the-art) while still achieving a human
performance level top-1 accuracy of 98.9% on the German traffic sign
recognition benchmark. Furthermore, muNet requires just $\sim$10 million
multiply-accumulate operations to perform inference. These experimental results
show that highly compact, optimized deep neural network architectures can be
designed for real-time traffic sign recognition that are well-suited for
embedded scenarios.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wong_A/0/1/0/all/0/1&quot;&gt;Alexander Wong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shafiee_M/0/1/0/all/0/1&quot;&gt;Mohammad Javad Shafiee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jules_M/0/1/0/all/0/1&quot;&gt;Michael St. Jules&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.02391">
<title>Learn To Pay Attention. (arXiv:1804.02391v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1804.02391</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose an end-to-end-trainable attention module for convolutional neural
network (CNN) architectures built for image classification. The module takes as
input the 2D feature vector maps which form the intermediate representations of
the input image at different stages in the CNN pipeline, and outputs a 2D
matrix of scores for each map. Standard CNN architectures are modified through
the incorporation of this module, and trained under the constraint that a
convex combination of the intermediate 2D feature vectors, as parameterised by
the score matrices, must \textit{alone} be used for classification.
Incentivised to amplify the relevant and suppress the irrelevant or misleading,
the scores thus assume the role of attention values. Our experimental
observations provide clear evidence to this effect: the learned attention maps
neatly highlight the regions of interest while suppressing background clutter.
Consequently, the proposed function is able to bootstrap standard CNN
architectures for the task of image classification, demonstrating superior
generalisation over 6 unseen benchmark datasets. When binarised, our attention
maps outperform other CNN-based attention maps, traditional saliency maps, and
top object proposals for weakly supervised segmentation as demonstrated on the
Object Discovery dataset. We also demonstrate improved robustness against the
fast gradient sign method of adversarial attack.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jetley_S/0/1/0/all/0/1&quot;&gt;Saumya Jetley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lord_N/0/1/0/all/0/1&quot;&gt;Nicholas A. Lord&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_N/0/1/0/all/0/1&quot;&gt;Namhoon Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Torr_P/0/1/0/all/0/1&quot;&gt;Philip H.S. Torr&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.02477">
<title>Programmatically Interpretable Reinforcement Learning. (arXiv:1804.02477v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1804.02477</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the problem of generating interpretable and verifiable policies
through reinforcement learning. Unlike the popular Deep Reinforcement Learning
(DRL) paradigm, in which the policy is represented by a neural network, the aim
in Programmatically Interpretable Reinforcement Learning is to find a policy
that can be represented in a high-level programming language. Such programmatic
policies have the benefits of being more easily interpreted than neural
networks, and being amenable to verification by symbolic methods. We propose a
new method, called Neurally Directed Program Search (NDPS), for solving the
challenging nonsmooth optimization problem of finding a programmatic policy
with maxima reward. NDPS works by first learning a neural policy network using
DRL, and then performing a local search over programmatic policies that seeks
to minimize a distance from this neural &quot;oracle&quot;. We evaluate NDPS on the task
of learning to drive a simulated car in the TORCS car-racing environment. We
demonstrate that NDPS is able to discover human-readable policies that pass
some significant performance bars. We also find that a well-designed policy
language can serve as a regularizer, and result in the discovery of policies
that lead to smoother trajectories and are more easily transferred to
environments not encountered during training.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Verma_A/0/1/0/all/0/1&quot;&gt;Abhinav Verma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Murali_V/0/1/0/all/0/1&quot;&gt;Vijayaraghavan Murali&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singh_R/0/1/0/all/0/1&quot;&gt;Rishabh Singh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kohli_P/0/1/0/all/0/1&quot;&gt;Pushmeet Kohli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chaudhuri_S/0/1/0/all/0/1&quot;&gt;Swarat Chaudhuri&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.02528">
<title>ANNETT-O: An Ontology for Describing Artificial Neural Network Evaluation, Topology and Training. (arXiv:1804.02528v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1804.02528</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep learning models, while effective and versatile, are becoming
increasingly complex, often including multiple overlapping networks of
arbitrary depths, multiple objectives and non-intuitive training methodologies.
This makes it increasingly difficult for researchers and practitioners to
design, train and understand them. In this paper we present ANNETT-O, a
much-needed, generic and computer-actionable vocabulary for researchers and
practitioners to describe their deep learning configurations, training
procedures and experiments. The proposed ontology focuses on topological,
training and evaluation aspects of complex deep neural configurations, while
keeping peripheral entities more succinct. Knowledge bases implementing
ANNETT-O can support a wide variety of queries, providing relevant insights to
users. In addition to a detailed description of the ontology, we demonstrate
its suitability to the task via a number of hypothetical use-cases of
increasing complexity.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Klampanos_I/0/1/0/all/0/1&quot;&gt;Iraklis A. Klampanos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Davvetas_A/0/1/0/all/0/1&quot;&gt;Athanasios Davvetas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koukourikos_A/0/1/0/all/0/1&quot;&gt;Antonis Koukourikos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Karkaletsis_V/0/1/0/all/0/1&quot;&gt;Vangelis Karkaletsis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.02596">
<title>Simple Models for Word Formation in English Slang. (arXiv:1804.02596v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1804.02596</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose generative models for three types of extra-grammatical word
formation phenomena abounding in English slang: Blends, Clippings, and
Reduplicatives. Adopting a data-driven approach coupled with linguistic
knowledge, we propose simple models with state of the art performance on human
annotated gold standard datasets. Overall, our models reveal insights into the
generative processes of word formation in slang -- insights which are
increasingly relevant in the context of the rising prevalence of slang and
non-standard varieties on the Internet.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kulkarni_V/0/1/0/all/0/1&quot;&gt;Vivek Kulkarni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1&quot;&gt;William Yang Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.02698">
<title>Hierarchical Modular Reinforcement Learning Method and Knowledge Acquisition of State-Action Rule for Multi-target Problem. (arXiv:1804.02698v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1804.02698</link>
<description rdf:parseType="Literal">&lt;p&gt;Hierarchical Modular Reinforcement Learning (HMRL), consists of 2 layered
learning where Profit Sharing works to plan a prey position in the higher layer
and Q-learning method trains the state-actions to the target in the lower
layer. In this paper, we expanded HMRL to multi-target problem to take the
distance between targets to the consideration. The function, called `AT field&apos;,
can estimate the interests for an agent according to the distance between 2
agents and the advantage/disadvantage of the other agent. Moreover, the
knowledge related to state-action rules is extracted by C4.5. The action under
the situation is decided by using the acquired knowledge. To verify the
effectiveness of proposed method, some experimental results are reported.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ichimura_T/0/1/0/all/0/1&quot;&gt;Takumi Ichimura&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Igaue_D/0/1/0/all/0/1&quot;&gt;Daisuke Igaue&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.03126">
<title>Data2Vis: Automatic Generation of Data Visualizations Using Sequence-to-Sequence Recurrent Neural Networks. (arXiv:1804.03126v1 [cs.HC])</title>
<link>http://arxiv.org/abs/1804.03126</link>
<description rdf:parseType="Literal">&lt;p&gt;Rapidly creating effective visualizations using expressive grammars is
challenging for users who have limited time and limited skills in statistics
and data visualization. Even high-level, dedicated visualization tools often
require users to manually select among data attributes, decide which
transformations to apply, and specify mappings between visual encoding
variables and raw or transformed attributes. In this paper, we introduce
Data2Vis, a neural translation model, for automatically generating
visualizations from given datasets. We formulate visualization generation as a
sequence to sequence translation problem where data specification is mapped to
a visualization specification in a declarative language (Vega-Lite). To this
end, we train a multilayered Long Short-Term Memory (LSTM) model with attention
on a corpus of visualization specifications. Qualitative results show that our
model learns the vocabulary and syntax for a valid visualization specification,
appropriate transformations (count, bins, mean) and how to use common data
selection patterns that occur within data visualizations. Our model generates
visualizations that are comparable to manually-created visualizations in a
fraction of the time, with potential to learn more complex visualization
strategies at scale.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dibia_V/0/1/0/all/0/1&quot;&gt;Victor Dibia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Demiralp_C/0/1/0/all/0/1&quot;&gt;&amp;#xc7;a&amp;#x11f;atay Demiralp&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1612.07139">
<title>A Survey of Deep Network Solutions for Learning Control in Robotics: From Reinforcement to Imitation. (arXiv:1612.07139v4 [cs.RO] UPDATED)</title>
<link>http://arxiv.org/abs/1612.07139</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep learning techniques have been widely applied, achieving state-of-the-art
results in various fields of study. This survey focuses on deep learning
solutions that target learning control policies for robotics applications. We
carry out our discussions on the two main paradigms for learning control with
deep networks: deep reinforcement learning and imitation learning. For deep
reinforcement learning (DRL), we begin from traditional reinforcement learning
algorithms, showing how they are extended to the deep context and effective
mechanisms that could be added on top of the DRL algorithms. We then introduce
representative works that utilize DRL to solve navigation and manipulation
tasks in robotics. We continue our discussion on methods addressing the
challenge of the reality gap for transferring DRL policies trained in
simulation to real-world scenarios, and summarize robotics simulation platforms
for conducting DRL research. For imitation leaning, we go through its three
main categories, behavior cloning, inverse reinforcement learning and
generative adversarial imitation learning, by introducing their formulations
and their corresponding robotics applications. Finally, we discuss the open
challenges and research frontiers.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tai_L/0/1/0/all/0/1&quot;&gt;Lei Tai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Jingwei Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1&quot;&gt;Ming Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Boedecker_J/0/1/0/all/0/1&quot;&gt;Joschka Boedecker&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Burgard_W/0/1/0/all/0/1&quot;&gt;Wolfram Burgard&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.03430">
<title>Learning to Rank Question-Answer Pairs using Hierarchical Recurrent Encoder with Latent Topic Clustering. (arXiv:1710.03430v3 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1710.03430</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we propose a novel end-to-end neural architecture for ranking
candidate answers, that adapts a hierarchical recurrent neural network and a
latent topic clustering module. With our proposed model, a text is encoded to a
vector representation from an word-level to a chunk-level to effectively
capture the entire meaning. In particular, by adapting the hierarchical
structure, our model shows very small performance degradations in longer text
comprehension while other state-of-the-art recurrent neural network models
suffer from it. Additionally, the latent topic clustering module extracts
semantic information from target samples. This clustering module is useful for
any text related tasks by allowing each data sample to find its nearest topic
cluster, thus helping the neural network model analyze the entire data. We
evaluate our models on the Ubuntu Dialogue Corpus and consumer electronic
domain question answering dataset, which is related to Samsung products. The
proposed model shows state-of-the-art results for ranking question-answer
pairs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yoon_S/0/1/0/all/0/1&quot;&gt;Seunghyun Yoon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shin_J/0/1/0/all/0/1&quot;&gt;Joongbo Shin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jung_K/0/1/0/all/0/1&quot;&gt;Kyomin Jung&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.06128">
<title>Enabling Reasoning with LegalRuleML. (arXiv:1711.06128v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1711.06128</link>
<description rdf:parseType="Literal">&lt;p&gt;In order to automate verification process, regulatory rules written in
natural language need to be translated into a format that machines can
understand. However, none of the existing formalisms can fully represent the
elements that appear in legal norms. For instance, most of these formalisms do
not provide features to capture the behavior of deontic effects, which is an
important aspect in automated compliance checking. This paper presents an
approach for transforming legal norms represented using LegalRuleML to a
variant of Modal Defeasible Logic (and vice versa) such that a legal statement
represented using LegalRuleML can be transformed into a machine-readable format
that can be understood and reasoned about depending upon the client&apos;s
preferences.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lam_H/0/1/0/all/0/1&quot;&gt;Ho-Pun Lam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hashmi_M/0/1/0/all/0/1&quot;&gt;Mustafa Hashmi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.02209">
<title>Building Generalizable Agents with a Realistic and Rich 3D Environment. (arXiv:1801.02209v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1801.02209</link>
<description rdf:parseType="Literal">&lt;p&gt;Teaching an agent to navigate in an unseen 3D environment is a challenging
task, even in the event of simulated environments. To generalize to unseen
environments, an agent needs to be robust to low-level variations (e.g. color,
texture, object changes), and also high-level variations (e.g. layout changes
of the environment). To improve overall generalization, all types of variations
in the environment have to be taken under consideration via different level of
data augmentation steps. To this end, we propose House3D, a rich, extensible
and efficient environment that contains 45,622 human-designed 3D scenes of
visually realistic houses, ranging from single-room studios to multi-storied
houses, equipped with a diverse set of fully labeled 3D objects, textures and
scene layouts, based on the SUNCG dataset (Song et.al.). The diversity in
House3D opens the door towards scene-level augmentation, while the label-rich
nature of House3D enables us to inject pixel- &amp;amp; task-level augmentations such
as domain randomization (Toubin et. al.) and multi-task training. Using a
subset of houses in House3D, we show that reinforcement learning agents trained
with an enhancement of different levels of augmentations perform much better in
unseen environments than our baselines with raw RGB input by over 8% in terms
of navigation success rate. House3D is publicly available at
&lt;a href=&quot;http://github.com/facebookresearch/House3D.&quot;&gt;this http URL&lt;/a&gt;
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1&quot;&gt;Yi Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1&quot;&gt;Yuxin Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gkioxari_G/0/1/0/all/0/1&quot;&gt;Georgia Gkioxari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1&quot;&gt;Yuandong Tian&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.02852">
<title>Distributed Deep Reinforcement Learning: Learn how to play Atari games in 21 minutes. (arXiv:1801.02852v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1801.02852</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a study in Distributed Deep Reinforcement Learning (DDRL) focused
on scalability of a state-of-the-art Deep Reinforcement Learning algorithm
known as Batch Asynchronous Advantage ActorCritic (BA3C). We show that using
the Adam optimization algorithm with a batch size of up to 2048 is a viable
choice for carrying out large scale machine learning computations. This,
combined with careful reexamination of the optimizer&apos;s hyperparameters, using
synchronous training on the node level (while keeping the local, single node
part of the algorithm asynchronous) and minimizing the memory footprint of the
model, allowed us to achieve linear scaling for up to 64 CPU nodes. This
corresponds to a training time of 21 minutes on 768 CPU cores, as opposed to 10
hours when using a single node with 24 cores achieved by a baseline single-node
implementation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Adamski_I/0/1/0/all/0/1&quot;&gt;Igor Adamski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Adamski_R/0/1/0/all/0/1&quot;&gt;Robert Adamski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grel_T/0/1/0/all/0/1&quot;&gt;Tomasz Grel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jedrych_A/0/1/0/all/0/1&quot;&gt;Adam J&amp;#x119;drych&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kaczmarek_K/0/1/0/all/0/1&quot;&gt;Kamil Kaczmarek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Michalewski_H/0/1/0/all/0/1&quot;&gt;Henryk Michalewski&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.00612">
<title>Knowledge Base Relation Detection via Multi-View Matching. (arXiv:1803.00612v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1803.00612</link>
<description rdf:parseType="Literal">&lt;p&gt;Relation detection is a core component for Knowledge Base Question Answering
(KBQA). In this paper, we propose a KB relation detection model via multi-view
matching which utilizes more useful information extracted from question and KB.
The matching inside each view is through multiple perspectives to compare two
input texts thoroughly. All these components are designed in an end-to-end
trainable neural network model. Experiments on SimpleQuestions and WebQSP yield
state-of-the-art results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1&quot;&gt;Yang Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hasan_K/0/1/0/all/0/1&quot;&gt;Kazi Saidul Hasan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_M/0/1/0/all/0/1&quot;&gt;Mo Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1&quot;&gt;Wei Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zhiguo Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.11439">
<title>Regularizing RNNs for Caption Generation by Reconstructing The Past with The Present. (arXiv:1803.11439v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1803.11439</link>
<description rdf:parseType="Literal">&lt;p&gt;Recently, caption generation with an encoder-decoder framework has been
extensively studied and applied in different domains, such as image captioning,
code captioning, and so on. In this paper, we propose a novel architecture,
namely Auto-Reconstructor Network (ARNet), which, coupling with the
conventional encoder-decoder framework, works in an end-to-end fashion to
generate captions. ARNet aims at reconstructing the previous hidden state with
the present one, besides behaving as the input-dependent transition operator.
Therefore, ARNet encourages the current hidden state to embed more information
from the previous one, which can help regularize the transition dynamics of
recurrent neural networks (RNNs). Extensive experimental results show that our
proposed ARNet boosts the performance over the existing encoder-decoder models
on both image captioning and source code captioning tasks. Additionally, ARNet
remarkably reduces the discrepancy between training and inference processes for
caption generation. Furthermore, the performance on permuted sequential MNIST
demonstrates that ARNet can effectively regularize RNN, especially on modeling
long-term dependencies. Our code is available at:
https://github.com/chenxinpeng/ARNet
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1&quot;&gt;Xinpeng Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_L/0/1/0/all/0/1&quot;&gt;Lin Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_W/0/1/0/all/0/1&quot;&gt;Wenhao Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yao_J/0/1/0/all/0/1&quot;&gt;Jian Yao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1&quot;&gt;Wei Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.02411">
<title>The Loss Surface of XOR Artificial Neural Networks. (arXiv:1804.02411v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1804.02411</link>
<description rdf:parseType="Literal">&lt;p&gt;Training an artificial neural network involves an optimization process over
the landscape defined by the cost (loss) as a function of the network
parameters. We explore these landscapes using optimisation tools developed for
potential energy landscapes in molecular science. The number of local minima
and transition states (saddle points of index one), as well as the ratio of
transition states to minima, grow rapidly with the number of nodes in the
network. There is also a strong dependence on the regularisation parameter,
with the landscape becoming more convex (fewer minima) as the regularisation
term increases. We demonstrate that in our formulation, stationary points for
networks with $N_h$ hidden nodes, including the minimal network required to fit
the XOR data, are also stationary points for networks with $N_{h} +1$ hidden
nodes when all the weights involving the additional nodes are zero. Hence,
smaller networks optimized to train the XOR data are embedded in the landscapes
of larger networks. Our results clarify certain aspects of the classification
and sensitivity (to perturbations in the input data) of minima and saddle
points for this system, and may provide insight into dropout and network
compression.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mehta_D/0/1/0/all/0/1&quot;&gt;Dhagash Mehta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhao_X/0/1/0/all/0/1&quot;&gt;Xiaojun Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bernal_E/0/1/0/all/0/1&quot;&gt;Edgar A. Bernal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wales_D/0/1/0/all/0/1&quot;&gt;David J. Wales&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.02484">
<title>Approximating Hamiltonian dynamics with the Nystr\&quot;om method. (arXiv:1804.02484v1 [quant-ph])</title>
<link>http://arxiv.org/abs/1804.02484</link>
<description rdf:parseType="Literal">&lt;p&gt;Simulating the time-evolution of quantum mechanical systems is BQP-hard and
expected to be one of the foremost applications of quantum computers. We
consider the approximation of Hamiltonian dynamics using subsampling methods
from randomized numerical linear algebra. We propose conditions for the
efficient approximation of state vectors evolving under a given Hamiltonian. As
an immediate application, we show that sample based quantum simulation, a type
of evolution where the Hamiltonian is a density matrix, can be efficiently
classically simulated under specific structural conditions. Our main technical
contribution is a randomized algorithm for approximating Hermitian matrix
exponentials. The proof leverages the Nystr\&quot;om method to obtain low-rank
approximations of the Hamiltonian. We envisage that techniques from randomized
linear algebra will bring further insights into the power of quantum
computation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Rudi_A/0/1/0/all/0/1&quot;&gt;Alessandro Rudi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Wossnig_L/0/1/0/all/0/1&quot;&gt;Leonard Wossnig&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Ciliberto_C/0/1/0/all/0/1&quot;&gt;Carlo Ciliberto&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Rocchetto_A/0/1/0/all/0/1&quot;&gt;Andrea Rocchetto&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Pontil_M/0/1/0/all/0/1&quot;&gt;Massimiliano Pontil&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Severini_S/0/1/0/all/0/1&quot;&gt;Simone Severini&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.02485">
<title>Fortified Networks: Improving the Robustness of Deep Networks by Modeling the Manifold of Hidden Representations. (arXiv:1804.02485v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1804.02485</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep networks have achieved impressive results across a variety of important
tasks. However a known weakness is a failure to perform well when evaluated on
data which differ from the training distribution, even if these differences are
very small, as is the case with adversarial examples. We propose Fortified
Networks, a simple transformation of existing networks, which fortifies the
hidden layers in a deep network by identifying when the hidden states are off
of the data manifold, and maps these hidden states back to parts of the data
manifold where the network performs well. Our principal contribution is to show
that fortifying these hidden states improves the robustness of deep networks
and our experiments (i) demonstrate improved robustness to standard adversarial
attacks in both black-box and white-box threat models; (ii) suggest that our
improvements are not primarily due to the gradient masking problem and (iii)
show the advantage of doing this fortification in the hidden layers instead of
the input space.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lamb_A/0/1/0/all/0/1&quot;&gt;Alex Lamb&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Binas_J/0/1/0/all/0/1&quot;&gt;Jonathan Binas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Goyal_A/0/1/0/all/0/1&quot;&gt;Anirudh Goyal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Serdyuk_D/0/1/0/all/0/1&quot;&gt;Dmitriy Serdyuk&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Subramanian_S/0/1/0/all/0/1&quot;&gt;Sandeep Subramanian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mitliagkas_I/0/1/0/all/0/1&quot;&gt;Ioannis Mitliagkas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bengio_Y/0/1/0/all/0/1&quot;&gt;Yoshua Bengio&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.02617">
<title>Language Modeling with Generative AdversarialNetworks. (arXiv:1804.02617v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1804.02617</link>
<description rdf:parseType="Literal">&lt;p&gt;Generative Adversarial Networks (GANs) have been promising in the field of
image generation, however, they have been hard to train for language
generation. GANs were originally designed to output differentiable values, so
discrete language generation is challenging for them which causes high levels
of instability in training GANs. Consequently, past work has resorted to
pre-training with maximum-likelihood or training GANs without pre-training with
a WGAN objective with a gradient penalty. In this study, we present a
comparison of those approaches. Furthermore, we present the results of some
experiments that indicate better training and convergence of Wasserstein GANs
(WGANs) when a weaker regularization term is enforcing the Lipschitz
constraint.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moradshahi_M/0/1/0/all/0/1&quot;&gt;Mehrad Moradshahi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Contractor_U/0/1/0/all/0/1&quot;&gt;Utkarsh Contractor&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.02665">
<title>Environmental Sound Recognition using Masked Conditional Neural Networks. (arXiv:1804.02665v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1804.02665</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural network based architectures used for sound recognition are usually
adapted from other application domains, which may not harness sound related
properties. The ConditionaL Neural Network (CLNN) is designed to consider the
relational properties across frames in a temporal signal, and its extension the
Masked ConditionaL Neural Network (MCLNN) embeds a filterbank behavior within
the network, which enforces the network to learn in frequency bands rather than
bins. Additionally, it automates the exploration of different feature
combinations analogous to handcrafting the optimum combination of features for
a recognition task. We applied the MCLNN to the environmental sounds of the
ESC-10 dataset. The MCLNN achieved competitive accuracies compared to
state-of-the-art convolutional neural networks and hand-crafted attempts.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Medhat_F/0/1/0/all/0/1&quot;&gt;Fady Medhat&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chesmore_D/0/1/0/all/0/1&quot;&gt;David Chesmore&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Robinson_J/0/1/0/all/0/1&quot;&gt;John Robinson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.02763">
<title>Comparison of non-linear activation functions for deep neural networks on MNIST classification task. (arXiv:1804.02763v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1804.02763</link>
<description rdf:parseType="Literal">&lt;p&gt;Activation functions play a key role in neural networks so it becomes
fundamental to understand their advantages and disadvantages in order to
achieve better performances. This paper will first introduce common types of
non linear activation functions that are alternative to the well known sigmoid
function and then evaluate their characteristics. Moreover deeper neural
networks will be analysed because they positively influence the final
performances compared to shallower networks. They also strictly depend on the
weight initialisation hence the effect of drawing weights from Gaussian and
uniform distribution will be analysed making particular attention on how the
number of incoming and outgoing connection to a node influence the whole
network.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pedamonti_D/0/1/0/all/0/1&quot;&gt;Dabal Pedamonti&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.03077">
<title>A plug-in approach to maximising precision at the top and recall at the top. (arXiv:1804.03077v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1804.03077</link>
<description rdf:parseType="Literal">&lt;p&gt;For information retrieval and binary classification, we show that precision
at the top (or precision at k) and recall at the top (or recall at k) are
maximised by thresholding the posterior probability of the positive class. This
finding is a consequence of a result on constrained minimisation of the
cost-sensitive expected classification error which generalises an earlier
related result from the literature.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tasche_D/0/1/0/all/0/1&quot;&gt;Dirk Tasche&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1209.0367">
<title>Seeded Graph Matching. (arXiv:1209.0367v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1209.0367</link>
<description rdf:parseType="Literal">&lt;p&gt;Given two graphs, the graph matching problem is to align the two vertex sets
so as to minimize the number of adjacency disagreements between the two graphs.
The seeded graph matching problem is the graph matching problem when we are
first given a partial alignment that we are tasked with completing. In this
paper, we modify the state-of-the-art approximate graph matching algorithm
&quot;FAQ&quot; of Vogelstein et al. (2015) to make it a fast approximate seeded graph
matching algorithm, adapt its applicability to include graphs with differently
sized vertex sets, and extend the algorithm so as to provide, for each
individual vertex, a nomination list of likely matches. We demonstrate the
effectiveness of our algorithm via simulation and real data experiments;
indeed, knowledge of even a few seeds can be extremely effective when our
seeded graph matching algorithm is used to recover a naturally existing
alignment that is only partially observed.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Fishkind_D/0/1/0/all/0/1&quot;&gt;Donniell E. Fishkind&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Adali_S/0/1/0/all/0/1&quot;&gt;Sancar Adali&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Patsolic_H/0/1/0/all/0/1&quot;&gt;Heather G. Patsolic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Meng_L/0/1/0/all/0/1&quot;&gt;Lingyao Meng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Singh_D/0/1/0/all/0/1&quot;&gt;Digvijay Singh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lyzinski_V/0/1/0/all/0/1&quot;&gt;Vince Lyzinski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Priebe_C/0/1/0/all/0/1&quot;&gt;Carey E. Priebe&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.04833">
<title>Machine Learning by Two-Dimensional Hierarchical Tensor Networks: A Quantum Information Theoretic Perspective on Deep Architectures. (arXiv:1710.04833v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1710.04833</link>
<description rdf:parseType="Literal">&lt;p&gt;The resemblance between the tensor networks (TNs) and machine learning has
drawn considerable attention. In particular, TNs and deep learning
architectures bear striking similarities suggesting using quantum techniques
for machine learning. In this work, we train two-dimensional hierarchical TNs
to solve image recognition problems, using a training algorithm derived from
the multipartite entanglement renormalization ansatz. This approach overcomes
scalability issues and implies novel mathematical connections among quantum
many-body physics, quantum information theory, and machine learning. The
algorithm optimally encodes each image class into a TN state, so that the
learning tasks as well as the image classes can be characterized by quantum
properties of the state including quantum entanglement and fidelity.
Furthermore, the unitary conditions of the local mappings in our algorithm make
it possible to realize the machine learning by, e.g., quantum state tomography
techniques or quantum computations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Liu_D/0/1/0/all/0/1&quot;&gt;Ding Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ran_S/0/1/0/all/0/1&quot;&gt;Shi-Ju Ran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wittek_P/0/1/0/all/0/1&quot;&gt;Peter Wittek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Peng_C/0/1/0/all/0/1&quot;&gt;Cheng Peng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Garcia_R/0/1/0/all/0/1&quot;&gt;Raul Bl&amp;#xe1;zquez Garc&amp;#xed;a&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Su_G/0/1/0/all/0/1&quot;&gt;Gang Su&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lewenstein_M/0/1/0/all/0/1&quot;&gt;Maciej Lewenstein&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.01952">
<title>Generating Neural Networks with Neural Networks. (arXiv:1801.01952v4 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1801.01952</link>
<description rdf:parseType="Literal">&lt;p&gt;Hypernetworks are neural networks that generate weights for another neural
network. We formulate the hypernetwork training objective as a compromise
between accuracy and diversity, where the diversity takes into account trivial
symmetry transformations of the target network. We explain how this simple
formulation generalizes variational inference. We use multi-layered perceptrons
to form the mapping from the low dimensional input random vector to the high
dimensional weight space, and demonstrate how to reduce the number of
parameters in this mapping by parameter sharing. We perform experiments and
show that the generated weights are diverse and lie on a non-trivial manifold.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Deutsch_L/0/1/0/all/0/1&quot;&gt;Lior Deutsch&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.09136">
<title>Gradient descent revisited via an adaptive online learning rate. (arXiv:1801.09136v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1801.09136</link>
<description rdf:parseType="Literal">&lt;p&gt;Any gradient descent optimization requires to choose a learning rate. With
deeper and deeper models, tuning that learning rate can easily become tedious
and does not necessarily lead to an ideal convergence. We propose a variation
of the gradient descent algorithm in the which the learning rate is not fixed.
Instead, we learn the learning rate itself, either by another gradient descent
(first-order method), or by Newton&apos;s method (second-order). This way, gradient
descent for any machine learning algorithm can be optimized.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ravaut_M/0/1/0/all/0/1&quot;&gt;Mathieu Ravaut&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gorti_S/0/1/0/all/0/1&quot;&gt;Satya Gorti&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06441">
<title>Deep neural decoders for near term fault-tolerant experiments. (arXiv:1802.06441v2 [quant-ph] UPDATED)</title>
<link>http://arxiv.org/abs/1802.06441</link>
<description rdf:parseType="Literal">&lt;p&gt;Finding efficient decoders for quantum error correcting codes adapted to
realistic experimental noise in fault-tolerant devices represents a significant
challenge. In this paper we introduce several decoding algorithms complemented
by deep neural decoders and apply them to analyze several fault-tolerant error
correction protocols such as the surface code as well as Steane and Knill error
correction. Our methods require no knowledge of the underlying noise model
afflicting the quantum device making them appealing for real-world experiments.
Our analysis is based on a full circuit-level noise model. It considers both
distance-three and five codes, and is performed near the codes pseudo-threshold
regime. Training deep neural decoders in low noise rate regimes appears to be a
challenging machine learning endeavour. We provide a detailed description of
our neural network architectures and training methodology. We then discuss both
the advantages and limitations of deep neural decoders. Lastly, we provide a
rigorous analysis of the decoding runtime of trained deep neural decoders and
compare our methods with anticipated gate times in future quantum devices.
Given the broad applications of our decoding schemes, we believe that the
methods presented in this paper could have practical applications for near term
fault-tolerant experiments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Chamberland_C/0/1/0/all/0/1&quot;&gt;Christopher Chamberland&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Ronagh_P/0/1/0/all/0/1&quot;&gt;Pooya Ronagh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08770">
<title>A Walk with SGD. (arXiv:1802.08770v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1802.08770</link>
<description rdf:parseType="Literal">&lt;p&gt;We present novel empirical observations regarding how stochastic gradient
descent (SGD) navigates the loss landscape of over-parametrized deep neural
networks (DNNs). These observations expose the qualitatively different the
roles of learning rate and batch-size in DNN optimization and generalization.
Specifically we study the DNN loss surface along the trajectory of SGD by
interpolating the loss surface between parameters from consecutive
\textit{iterations} and tracking various metrics during training. We find that
the loss interpolation between parameters before and after each training
iteration&apos;s update is roughly convex with a minimum (\textit{valley floor}) in
between for most of the training. Based on this and other metrics, we deduce
that for most of the training update steps, SGD moves in valley like regions of
the loss surface by jumping from one valley wall to another at a height above
the valley floor. This &apos;bouncing off walls at a height&apos; mechanism helps SGD
traverse larger distance for small batch sizes and large learning rates which
we find play qualitatively different roles in the dynamics. While a large
learning rate maintains a large height from the valley floor, a small batch
size injects noise facilitating exploration. We find this mechanism is crucial
for generalization because the valley floor has barriers and this exploration
above the valley floor allows SGD to quickly travel far away from the
initialization point (without being affected by barriers) and find flatter
regions, corresponding to better generalization.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Xing_C/0/1/0/all/0/1&quot;&gt;Chen Xing&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Arpit_D/0/1/0/all/0/1&quot;&gt;Devansh Arpit&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tsirigotis_C/0/1/0/all/0/1&quot;&gt;Christos Tsirigotis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bengio_Y/0/1/0/all/0/1&quot;&gt;Yoshua Bengio&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.01682">
<title>Optimizing Slate Recommendations via Slate-CVAE. (arXiv:1803.01682v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1803.01682</link>
<description rdf:parseType="Literal">&lt;p&gt;The slate recommendation problem aims to find the &quot;optimal&quot; ordering of a
subset of documents to be presented on a surface that we call &quot;slate&quot;. The
definition of &quot;optimal&quot; changes depending on the underlying applications but a
typical goal is to maximize user engagement with the slate. Solving this
problem at scale is hard due to the combinatorial explosion of documents to
show and their display positions on the slate. In this paper, we introduce
Slate Conditional Variational Auto-Encoders (Slate-CVAE) to generate optimal
slates. To the best of our knowledge, this is the first conditional generative
model that provides a unified framework for slate recommendation by direct
generation. Slate-CVAE automatically takes into account the format of the slate
and any biases that the representation causes, thus truly proposing the optimal
slate. Additionally, to deal with large corpora of documents, we present a
novel approach that uses pretrained document embeddings combined with a
soft-nearest-neighbors layer within our CVAE model. Experiments show that on
the simulated and real-world datasets, Slate-CVAE outperforms recommender
systems that consists of greedily ranking documents by a significant margin
while remaining scalable.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Jiang_R/0/1/0/all/0/1&quot;&gt;Ray Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gowal_S/0/1/0/all/0/1&quot;&gt;Sven Gowal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mann_T/0/1/0/all/0/1&quot;&gt;Timothy A. Mann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rezende_D/0/1/0/all/0/1&quot;&gt;Danilo J. Rezende&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.10122">
<title>World Models. (arXiv:1803.10122v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1803.10122</link>
<description rdf:parseType="Literal">&lt;p&gt;We explore building generative neural network models of popular reinforcement
learning environments. Our world model can be trained quickly in an
unsupervised manner to learn a compressed spatial and temporal representation
of the environment. By using features extracted from the world model as inputs
to an agent, we can train a very compact and simple policy that can solve the
required task. We can even train our agent entirely inside of its own
hallucinated dream generated by its world model, and transfer this policy back
into the actual environment.
&lt;/p&gt;
&lt;p&gt;An interactive version of this paper is available at
https://worldmodels.github.io/
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ha_D/0/1/0/all/0/1&quot;&gt;David Ha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schmidhuber_J/0/1/0/all/0/1&quot;&gt;J&amp;#xfc;rgen Schmidhuber&lt;/a&gt;</dc:creator>
</item></rdf:RDF>