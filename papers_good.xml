<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Good papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Good Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-03-05T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.01686"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1701.09175"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.01044"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.01118"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.01271"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.01365"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.01403"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.01648"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.01719"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.01798"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1705.09382"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1708.01729"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.07979"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.07896"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08454"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.00909"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.01013"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.01088"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.01216"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.01314"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.01682"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.01833"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.01834"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1706.04499"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1707.03269"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.08894"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.00165"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.04094"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.09913"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.10116"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.00930"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1702.08690"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1803.01686">
<title>On Extended Long Short-term Memory and Dependent Bidirectional Recurrent Neural Network. (arXiv:1803.01686v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1803.01686</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work, we investigate the memory capability of recurrent neural
networks (RNNs), where this capability is defined as a function that maps an
element in a sequence to the current output. We first analyze the system
function of a recurrent neural network (RNN) cell, and provide analytical
results for three RNNs. They are the simple recurrent neural network (SRN), the
long short-term memory (LSTM), and the gated recurrent unit (GRU). Based on the
analysis, we propose a new design to extend the memory length of a cell, and
call it the extended long short-term memory (ELSTM). Next, we present a
dependent bidirectional recurrent neural network (DBRNN) for the
sequence-in-sequence-out (SISO) problem, which is more robust to previous
erroneous predictions. Extensive experiments are carried out on different
language tasks to demonstrate the superiority of our proposed ELSTM and DBRNN
solutions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Su_Y/0/1/0/all/0/1&quot;&gt;Yuanhang Su&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1&quot;&gt;Yuzhong Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kuo_C/0/1/0/all/0/1&quot;&gt;C.-C. Jay Kuo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1701.09175">
<title>Skip Connections Eliminate Singularities. (arXiv:1701.09175v8 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1701.09175</link>
<description rdf:parseType="Literal">&lt;p&gt;Skip connections made the training of very deep networks possible and have
become an indispensable component in a variety of neural architectures. A
completely satisfactory explanation for their success remains elusive. Here, we
present a novel explanation for the benefits of skip connections in training
very deep networks. The difficulty of training deep networks is partly due to
the singularities caused by the non-identifiability of the model. Several such
singularities have been identified in previous works: (i) overlap singularities
caused by the permutation symmetry of nodes in a given layer, (ii) elimination
singularities corresponding to the elimination, i.e. consistent deactivation,
of nodes, (iii) singularities generated by the linear dependence of the nodes.
These singularities cause degenerate manifolds in the loss landscape that slow
down learning. We argue that skip connections eliminate these singularities by
breaking the permutation symmetry of nodes, by reducing the possibility of node
elimination and by making the nodes less linearly dependent. Moreover, for
typical initializations, skip connections move the network away from the
&quot;ghosts&quot; of these singularities and sculpt the landscape around them to
alleviate the learning slow-down. These hypotheses are supported by evidence
from simplified models, as well as from experiments with deep networks trained
on real-world datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Orhan_A/0/1/0/all/0/1&quot;&gt;A. Emin Orhan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pitkow_X/0/1/0/all/0/1&quot;&gt;Xaq Pitkow&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.01044">
<title>Multi-Agent Imitation Learning for Driving Simulation. (arXiv:1803.01044v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1803.01044</link>
<description rdf:parseType="Literal">&lt;p&gt;Simulation is an appealing option for validating the safety of autonomous
vehicles. Generative Adversarial Imitation Learning (GAIL) has recently been
shown to learn representative human driver models. These human driver models
were learned through training in single-agent environments, but they have
difficulty in generalizing to multi-agent driving scenarios. We argue these
difficulties arise because observations at training and test time are sampled
from different distributions. This difference makes such models unsuitable for
the simulation of driving scenes, where multiple agents must interact
realistically over long time horizons. We extend GAIL to address these
shortcomings through a parameter-sharing approach grounded in curriculum
learning. Compared with single-agent GAIL policies, policies generated by our
PS-GAIL method prove superior at interacting stably in a multi-agent setting
and capturing the emergent behavior of human drivers.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bhattacharyya_R/0/1/0/all/0/1&quot;&gt;Raunak P. Bhattacharyya&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Phillips_D/0/1/0/all/0/1&quot;&gt;Derek J. Phillips&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wulfe_B/0/1/0/all/0/1&quot;&gt;Blake Wulfe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Morton_J/0/1/0/all/0/1&quot;&gt;Jeremy Morton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kuefler_A/0/1/0/all/0/1&quot;&gt;Alex Kuefler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kochenderfer_M/0/1/0/all/0/1&quot;&gt;Mykel J. Kochenderfer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.01118">
<title>Some Considerations on Learning to Explore via Meta-Reinforcement Learning. (arXiv:1803.01118v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1803.01118</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the problem of exploration in meta reinforcement learning. Two
new meta reinforcement learning algorithms are suggested: E-MAML and
E-$\text{RL}^2$. Results are presented on a novel environment we call `Krazy
World&apos; and a set of maze environments. We show E-MAML and E-$\text{RL}^2$
deliver better performance on tasks where exploration is important.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stadie_B/0/1/0/all/0/1&quot;&gt;Bradly C. Stadie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_G/0/1/0/all/0/1&quot;&gt;Ge Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Houthooft_R/0/1/0/all/0/1&quot;&gt;Rein Houthooft&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1&quot;&gt;Xi Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Duan_Y/0/1/0/all/0/1&quot;&gt;Yan Duan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1&quot;&gt;Yuhuai Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1&quot;&gt;Pieter Abbeel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sutskever_I/0/1/0/all/0/1&quot;&gt;Ilya Sutskever&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.01271">
<title>An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling. (arXiv:1803.01271v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1803.01271</link>
<description rdf:parseType="Literal">&lt;p&gt;For most deep learning practitioners, sequence modeling is synonymous with
recurrent networks. Yet recent results indicate that convolutional
architectures can outperform recurrent networks on tasks such as audio
synthesis and machine translation. Given a new sequence modeling task or
dataset, which architecture should one use? We conduct a systematic evaluation
of generic convolutional and recurrent architectures for sequence modeling. The
models are evaluated across a broad range of standard tasks that are commonly
used to benchmark recurrent networks. Our results indicate that a simple
convolutional architecture outperforms canonical recurrent networks such as
LSTMs across a diverse range of tasks and datasets, while demonstrating longer
effective memory. We conclude that the common association between sequence
modeling and recurrent networks should be reconsidered, and convolutional
networks should be regarded as a natural starting point for sequence modeling
tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bai_S/0/1/0/all/0/1&quot;&gt;Shaojie Bai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kolter_J/0/1/0/all/0/1&quot;&gt;J. Zico Kolter&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koltun_V/0/1/0/all/0/1&quot;&gt;Vladlen Koltun&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.01365">
<title>Improving Multi-Step Traffic Flow Prediction. (arXiv:1803.01365v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1803.01365</link>
<description rdf:parseType="Literal">&lt;p&gt;In its simplest form, the traffic flow prediction problem is restricted to
predicting a single time-step into the future. Multi-step traffic flow
prediction extends this set-up to the case where predicting multiple time-steps
into the future based on some finite history is of interest. This problem is
significantly more difficult than its single-step variant and is known to
suffer from degradation in predictions as the time step increases. In this
paper, two approaches to improve multi-step traffic flow prediction performance
in recursive and multi-output settings are introduced. In particular, a model
that allows recursive prediction approaches to take into account the temporal
context in term of time-step index when making predictions is introduced. In
addition, a conditional generative adversarial network-based data augmentation
method is proposed to improve prediction performance in the multi-output
setting. The experiments on a real-world traffic flow dataset show that the two
methods improve on multi-step traffic flow prediction in recursive and
multi-output settings, respectively.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koesdwiady_A/0/1/0/all/0/1&quot;&gt;Arief Koesdwiady&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Karray_F/0/1/0/all/0/1&quot;&gt;Fakhri Karray&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.01403">
<title>Exploring Novel Game Spaces with Fluidic Games. (arXiv:1803.01403v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1803.01403</link>
<description rdf:parseType="Literal">&lt;p&gt;With the growing integration of smartphones into our daily lives, and their
increased ease of use, mobile games have become highly popular across all
demographics. People listen to music, play games or read the news while in
transit or bridging gap times. While mobile gaming is gaining popularity,
mobile expression of creativity is still in its early stages. We present here a
new type of mobile app -- fluidic games -- and illustrate our iterative
approach to their design. This new type of app seamlessly integrates
exploration of the design space into the actual user experience of playing the
game, and aims to enrich the user experience. To better illustrate the game
domain and our approach, we discuss one specific fluidic game, which is
available as a commercial product. We also briefly discuss open challenges such
as player support and how generative techniques can aid the exploration of the
game space further.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gaudl_S/0/1/0/all/0/1&quot;&gt;Swen E. Gaudl&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nelson_M/0/1/0/all/0/1&quot;&gt;Mark J. Nelson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Colton_S/0/1/0/all/0/1&quot;&gt;Simon Colton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saunders_R/0/1/0/all/0/1&quot;&gt;Rob Saunders&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Powley_E/0/1/0/all/0/1&quot;&gt;Edward J. Powley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ivey_P/0/1/0/all/0/1&quot;&gt;Peter Ivey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ferrer_B/0/1/0/all/0/1&quot;&gt;Blanca Perez Ferrer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cook_M/0/1/0/all/0/1&quot;&gt;Michael Cook&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.01648">
<title>A Genetic Programming Framework for 2D Platform AI. (arXiv:1803.01648v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1803.01648</link>
<description rdf:parseType="Literal">&lt;p&gt;There currently exists a wide range of techniques to model and evolve
artificial players for games. Existing techniques range from black box neural
networks to entirely hand-designed solutions. In this paper, we demonstrate the
feasibility of a genetic programming framework using human controller input to
derive meaningful artificial players which can, later on, be optimised by hand.
The current state of the art in game character design relies heavily on human
designers to manually create and edit scripts and rules for game characters. To
address this manual editing bottleneck, current computational intelligence
techniques approach the issue with fully autonomous character generators,
replacing most of the design process using black box solutions such as neural
networks or the like. Our GP approach to this problem creates character
controllers which can be further authored and developed by a designer it also
offers designers to included their play style without the need to use a
programming language. This keeps the designer in the loop while reducing
repetitive manual labour. Our system also provides insights into how players
express themselves in games and into deriving appropriate models for
representing those insights. We present our framework, supporting findings and
open challenges.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gaudl_S/0/1/0/all/0/1&quot;&gt;Swen E. Gaudl&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.01719">
<title>How to Start Training: The Effect of Initialization and Architecture. (arXiv:1803.01719v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1803.01719</link>
<description rdf:parseType="Literal">&lt;p&gt;We investigate the effects of initialization and architecture on the start of
training in deep ReLU nets. We identify two common failure modes for early
training in which the mean and variance of activations are poorly behaved. For
each failure mode, we give a rigorous proof of when it occurs at initialization
and how to avoid it. The first failure mode, exploding/vanishing mean
activation length, can be avoided by initializing weights from a symmetric
distribution with variance 2/fan-in. The second failure mode, exponentially
large variance of activation length, can be avoided by keeping constant the sum
of the reciprocals of layer widths. We demonstrate empirically the
effectiveness of our theoretical results in predicting when networks are able
to start training. In particular, we note that many popular initializations
fail our criteria, whereas correct initialization and architecture allows much
deeper networks to be trained.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hanin_B/0/1/0/all/0/1&quot;&gt;Boris Hanin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rolnick_D/0/1/0/all/0/1&quot;&gt;David Rolnick&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.01798">
<title>One-Class Adversarial Nets for Fraud Detection. (arXiv:1803.01798v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1803.01798</link>
<description rdf:parseType="Literal">&lt;p&gt;Many online applications, such as online social networks or knowledge bases,
are often attacked by malicious users who commit different types of actions
such as vandalism on Wikipedia or fraudulent reviews on eBay. Currently, most
of the fraud detection approaches require a training dataset that contains
records of both benign and malicious users. However, in practice, there are
often no or very few records of malicious users. In this paper, we develop
one-class adversarial nets (OCAN) for fraud detection using training data with
only benign users. OCAN first uses LSTM-Autoencoder to learn the
representations of benign users from their sequences of online activities. It
then detects malicious users by training a discriminator with a complementary
GAN model that is different from the regular GAN model. Experimental results
show that our OCAN outperforms the state-of-the-art one-class classification
models and achieves comparable performance with the latest multi-source LSTM
model that requires both benign and malicious users in the training phase.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_P/0/1/0/all/0/1&quot;&gt;Panpan Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yuan_S/0/1/0/all/0/1&quot;&gt;Shuhan Yuan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1&quot;&gt;Xintao Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jun Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_A/0/1/0/all/0/1&quot;&gt;Aidong Lu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1705.09382">
<title>Distributed Robust Subspace Recovery. (arXiv:1705.09382v2 [math.NA] UPDATED)</title>
<link>http://arxiv.org/abs/1705.09382</link>
<description rdf:parseType="Literal">&lt;p&gt;We study Robust Subspace Recovery (RSR) in distributed settings. We consider
a huge dataset in an ad hoc network without a central processor, where each
node has access only to one chunk of the dataset. We assume that part of the
whole dataset lies around a low-dimensional subspace and the other part is
composed of outliers that lie away from that subspace. The goal is to recover
the underlying subspace for the whole dataset, without transferring the data
itself between the nodes. We apply the Consensus-Based Gradient method for the
Geometric Median Subspace algorithm for RSR. We propose an iterative solution
for the local dual minimization problem and establish its $r$-linear
convergence. We also explain how to distributedly implement the Reaper and Fast
Median Subspace algorithms for RSR. We demonstrate the competitive performance
of our algorithms for both synthetic and real data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Huroyan_V/0/1/0/all/0/1&quot;&gt;Vahan Huroyan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Lerman_G/0/1/0/all/0/1&quot;&gt;Gilad Lerman&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1708.01729">
<title>Inception Score, Label Smoothing, Gradient Vanishing and -log(D(x)) Alternative. (arXiv:1708.01729v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1708.01729</link>
<description rdf:parseType="Literal">&lt;p&gt;In this article, we mathematically study several GAN related topics,
including Inception score, label smoothing, gradient vanishing and the
-log(D(x)) alternative.
&lt;/p&gt;
&lt;p&gt;--- An advanced version is included in &lt;a href=&quot;/abs/1703.02000&quot;&gt;arXiv:1703.02000&lt;/a&gt; &quot;Activation
Maximization Generative Adversarial Nets&quot;. Please refer Section 6 in &lt;a href=&quot;/abs/1703.02000&quot;&gt;1703.02000&lt;/a&gt;
for detailed analysis on Inception Score, and refer its appendix for the
discussions on Label Smoothing, Gradient Vanishing and -log(D(x)) Alternative.
---
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1&quot;&gt;Zhiming Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1&quot;&gt;Weinan Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jun Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.07979">
<title>Multi-task Learning with Gradient Guided Policy Specialization. (arXiv:1709.07979v3 [cs.RO] UPDATED)</title>
<link>http://arxiv.org/abs/1709.07979</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a method for efficient learning of control policies for multiple
related robotic motor skills. Our approach consists of two stages, joint
training and specialization training. During the joint training stage, a neural
network policy is trained with minimal information to disambiguate the motor
skills. This forces the policy to learn a common representation of the
different tasks. Then, during the specialization training stage we selectively
split the weights of the policy based on a per-weight metric that measures the
disagreement among the multiple tasks. By splitting part of the control policy,
it can be further trained to specialize to each task. To update the control
policy during learning, we use Trust Region Policy Optimization with
Generalized Advantage Function (TRPOGAE). We propose a modification to the
gradient update stage of TRPO to better accommodate multi-task learning
scenarios. We evaluate our approach on three continuous motor skill learning
problems in simulation: 1) a locomotion task where three single legged robots
with considerable difference in shape and size are trained to hop forward, 2) a
manipulation task where three robot manipulators with different sizes and joint
types are trained to reach different locations in 3D space, and 3) locomotion
of a two-legged robot, whose range of motion of one leg is constrained in
different ways. We compare our training method to three baselines. The first
baseline uses only joint training for the policy, the second trains independent
policies for each task, and the last randomly selects weights to split. We show
that our approach learns more efficiently than each of the baseline methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_W/0/1/0/all/0/1&quot;&gt;Wenhao Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1&quot;&gt;C. Karen Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Turk_G/0/1/0/all/0/1&quot;&gt;Greg Turk&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.07896">
<title>L2-Nonexpansive Neural Networks. (arXiv:1802.07896v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1802.07896</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper proposes a class of well-conditioned neural networks in which a
unit amount of change in the inputs causes at most a unit amount of change in
the outputs or any of the internal layers. We develop the known methodology of
controlling Lipschitz constants to realize its full potential in maximizing
robustness: our linear and convolution layers subsume those in the previous
Parseval networks as a special case and allow greater degrees of freedom;
aggregation, pooling, splitting and other operators are adapted in new ways,
and a new loss function is proposed, all for the purpose of improving
robustness. With MNIST and CIFAR-10 classifiers, we demonstrate a number of
advantages. Without needing any adversarial training, the proposed classifiers
exceed the state of the art in robustness against white-box L2-bounded
adversarial attacks. Their outputs are quantitatively more meaningful than
ordinary networks and indicate levels of confidence. They are also free of
exploding gradients, among other desirable properties.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qian_H/0/1/0/all/0/1&quot;&gt;Haifeng Qian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wegman_M/0/1/0/all/0/1&quot;&gt;Mark N. Wegman&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08454">
<title>Faithful Semantical Embedding of a Dyadic Deontic Logic in HOL. (arXiv:1802.08454v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1802.08454</link>
<description rdf:parseType="Literal">&lt;p&gt;A shallow semantical embedding of a dyadic deontic logic by Carmo and Jones
in classical higher-order logic is presented. This embedding is proven sound
and complete, that is, faithful.
&lt;/p&gt;
&lt;p&gt;The work presented here provides the theoretical foundation for the
implementation and automation of dyadic deontic logic within off-the-shelf
higher-order theorem provers and proof assistants.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Benzmuller_C/0/1/0/all/0/1&quot;&gt;Christoph Benzm&amp;#xfc;ller&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Farjami_A/0/1/0/all/0/1&quot;&gt;Ali Farjami&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Parent_X/0/1/0/all/0/1&quot;&gt;Xavier Parent&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.00909">
<title>Understanding the Loss Surface of Neural Networks for Binary Classification. (arXiv:1803.00909v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1803.00909</link>
<description rdf:parseType="Literal">&lt;p&gt;It is widely conjectured that the reason that training algorithms for neural
networks are successful because all local minima lead to similar performance,
for example, see (LeCun et al., 2015, Choromanska et al., 2015, Dauphin et al.,
2014). Performance is typically measured in terms of two metrics: training
performance and generalization performance. Here we focus on the training
performance of single-layered neural networks for binary classification, and
provide conditions under which the training error is zero at all local minima
of a smooth hinge loss function. Our conditions are roughly in the following
form: the neurons have to be strictly convex and the surrogate loss function
should be a smooth version of hinge loss. We also provide counterexamples to
show that when the loss function is replaced with quadratic loss or logistic
loss, the result may not hold.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_S/0/1/0/all/0/1&quot;&gt;Shiyu Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_R/0/1/0/all/0/1&quot;&gt;Ruoyu Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yixuan Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Srikant_R/0/1/0/all/0/1&quot;&gt;R. Srikant&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.01013">
<title>An Overview of Robust Subspace Recovery. (arXiv:1803.01013v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1803.01013</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper will serve as an introduction to the body of work on robust
subspace recovery. Robust subspace recovery involves finding an underlying
low-dimensional subspace in a dataset that is possibly corrupted with outliers.
While this problem is easy to state, it has been difficult to develop optimal
algorithms due to its underlying nonconvexity. This work will emphasize
advantages and disadvantages of proposed approaches and unsolved problems in
the area.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lerman_G/0/1/0/all/0/1&quot;&gt;Gilad Lerman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Maunu_T/0/1/0/all/0/1&quot;&gt;Tyler Maunu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.01088">
<title>Practical Contextual Bandits with Regression Oracles. (arXiv:1803.01088v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1803.01088</link>
<description rdf:parseType="Literal">&lt;p&gt;A major challenge in contextual bandits is to design general-purpose
algorithms that are both practically useful and theoretically well-founded. We
present a new technique that has the empirical and computational advantages of
realizability-based approaches combined with the flexibility of agnostic
methods. Our algorithms leverage the availability of a regression oracle for
the value-function class, a more realistic and reasonable oracle than the
classification oracles over policies typically assumed by agnostic methods. Our
approach generalizes both UCB and LinUCB to far more expressive possible model
classes and achieves low regret under certain distributional assumptions. In an
extensive empirical evaluation, compared to both realizability-based and
agnostic baselines, we find that our approach typically gives comparable or
superior results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Foster_D/0/1/0/all/0/1&quot;&gt;Dylan J. Foster&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Agarwal_A/0/1/0/all/0/1&quot;&gt;Alekh Agarwal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dudik_M/0/1/0/all/0/1&quot;&gt;Miroslav Dud&amp;#xed;k&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_H/0/1/0/all/0/1&quot;&gt;Haipeng Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schapire_R/0/1/0/all/0/1&quot;&gt;Robert E. Schapire&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.01216">
<title>Deep Bayesian Active Semi-Supervised Learning. (arXiv:1803.01216v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1803.01216</link>
<description rdf:parseType="Literal">&lt;p&gt;In many applications the process of generating label information is expensive
and time consuming. We present a new method that combines active and
semi-supervised deep learning to achieve high generalization performance from a
deep convolutional neural network with as few known labels as possible. In a
setting where a small amount of labeled data as well as a large amount of
unlabeled data is available, our method first learns the labeled data set. This
initialization is followed by an expectation maximization algorithm, where
further training reduces classification entropy on the unlabeled data by
targeting a low entropy fit which is consistent with the labeled data. In
addition the algorithm asks at a specified frequency an oracle for labels of
data with entropy above a certain entropy quantile. Using this active learning
component we obtain an agile labeling process that achieves high accuracy, but
requires only a small amount of known labels. For the MNIST dataset we report
an error rate of 2.06% using only 300 labels and 1.06% for 1000 labels. These
results are obtained without employing any special network architecture or data
augmentation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rottmann_M/0/1/0/all/0/1&quot;&gt;Matthias Rottmann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kahl_K/0/1/0/all/0/1&quot;&gt;Karsten Kahl&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gottschalk_H/0/1/0/all/0/1&quot;&gt;Hanno Gottschalk&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.01314">
<title>Training Deep Learning based Denoisers without Ground Truth Data. (arXiv:1803.01314v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1803.01314</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent deep learning based denoisers are trained to minimize the mean squared
error (MSE) between the output of a network and the ground truth noiseless
image in the training data. Thus, it is crucial to have high quality noiseless
training data for high performance denoisers. Unfortunately, in some
application areas such as medical imaging, it is expensive or even infeasible
to acquire such a clean ground truth image. We propose a Stein&apos;s Unbiased Risk
Estimator (SURE) based method for training deep learning based denoisers
without ground truth data. We demonstrated that our SURE based method only with
noisy input data was able to train CNN based denoising networks that yielded
performance close to that of the original MSE based deep learning denoisers
with ground truth data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Soltanayev_S/0/1/0/all/0/1&quot;&gt;Shakarim Soltanayev&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chun_S/0/1/0/all/0/1&quot;&gt;Se Young Chun&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.01682">
<title>Optimizing Slate Recommendations via Slate-CVAE. (arXiv:1803.01682v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1803.01682</link>
<description rdf:parseType="Literal">&lt;p&gt;The slate recommendation problem aims to find the &quot;optimal&quot; ordering of a
subset of documents to be presented on a surface that we call &quot;slate&quot;. The
definition of &quot;optimal&quot; changes depending on the underlying applications but a
typical goal is to maximize user engagement with the slate. Solving this
problem at scale is hard due to the combinatorial explosion of documents to
show and their display positions on the slate. In this paper, we introduce
Slate Conditional Variational Auto-Encoders (Slate-CVAE) to generate optimal
slates. To the best of our knowledge, this is the first conditional generative
model that provides a unified framework for slate recommendation by direct
generation. Slate-CVAE automatically takes into account the format of the slate
and any biases that the representation causes, thus truly proposing the optimal
slate. Additionally, to deal with large corpora of documents, we present a
novel approach that uses pretrained document embeddings combined with a
soft-nearest-neighbors layer within our CVAE model. Experiments show that on
the simulated and real-world datasets, Slate-CVAE outperforms recommender
systems that consists of greedily ranking documents by a significant margin
while remaining scalable.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Jiang_R/0/1/0/all/0/1&quot;&gt;Ray Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gowal_S/0/1/0/all/0/1&quot;&gt;Sven Gowal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mann_T/0/1/0/all/0/1&quot;&gt;Timothy A. Mann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rezende_D/0/1/0/all/0/1&quot;&gt;Danilo J. Rezende&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.01833">
<title>Marginal Singularity, and the Benefits of Labels in Covariate-Shift. (arXiv:1803.01833v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1803.01833</link>
<description rdf:parseType="Literal">&lt;p&gt;We present new minimax results that concisely capture the relative benefits
of source and target labeled data, under covariate-shift. Namely, we show that
the benefits of target labels are controlled by a transfer-exponent $\gamma$
that encodes how singular Q is locally w.r.t. P, and interestingly allows
situations where transfer did not seem possible under previous insights. In
fact, our new minimax analysis - in terms of $\gamma$ - reveals a continuum of
regimes ranging from situations where target labels have little benefit, to
regimes where target labels dramatically improve classification. We then show
that a recently proposed semi-supervised procedure can be extended to adapt to
unknown $\gamma$, and therefore requests labels only when beneficial, while
achieving minimax transfer rates.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kpotufe_S/0/1/0/all/0/1&quot;&gt;Samory Kpotufe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Martinet_G/0/1/0/all/0/1&quot;&gt;Guillaume Martinet&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.01834">
<title>Conducting Credit Assignment by Aligning Local Representations. (arXiv:1803.01834v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1803.01834</link>
<description rdf:parseType="Literal">&lt;p&gt;The use of back-propagation and its variants to train deep networks is often
problematic for new users, with issues such as exploding gradients, vanishing
gradients, and high sensitivity to weight initialization strategies often
making networks difficult to train. In this paper, we present Local
Representation Alignment (LRA), a training procedure that is much less
sensitive to bad initializations, does not require modifications to the network
architecture, and can be adapted to networks with highly nonlinear and
discrete-valued activation functions. Furthermore, we show that one variation
of LRA can start with a null initialization of network weights and still
successfully train networks with a wide variety of nonlinearities, including
tanh, ReLU-6, softplus, signum and others that are more biologically plausible.
&lt;/p&gt;
&lt;p&gt;Experiments on MNIST and Fashion MNIST validate the performance of the
algorithm and show that LRA can train networks robustly and effectively,
succeeding even when back-propagation fails and outperforming other alternative
learning algorithms, such as target propagation and feedback alignment.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ororbia_A/0/1/0/all/0/1&quot;&gt;Alexander G. Ororbia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mali_A/0/1/0/all/0/1&quot;&gt;Ankur Mali&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kifer_D/0/1/0/all/0/1&quot;&gt;Daniel Kifer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Giles_C/0/1/0/all/0/1&quot;&gt;C. Lee Giles&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1706.04499">
<title>SEARNN: Training RNNs with Global-Local Losses. (arXiv:1706.04499v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1706.04499</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose SEARNN, a novel training algorithm for recurrent neural networks
(RNNs) inspired by the &quot;learning to search&quot; (L2S) approach to structured
prediction. RNNs have been widely successful in structured prediction
applications such as machine translation or parsing, and are commonly trained
using maximum likelihood estimation (MLE). Unfortunately, this training loss is
not always an appropriate surrogate for the test error: by only maximizing the
ground truth probability, it fails to exploit the wealth of information offered
by structured losses. Further, it introduces discrepancies between training and
predicting (such as exposure bias) that may hurt test performance. Instead,
SEARNN leverages test-alike search space exploration to introduce global-local
losses that are closer to the test error. We first demonstrate improved
performance over MLE on two different tasks: OCR and spelling correction. Then,
we propose a subsampling strategy to enable SEARNN to scale to large vocabulary
sizes. This allows us to validate the benefits of our approach on a machine
translation task.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leblond_R/0/1/0/all/0/1&quot;&gt;R&amp;#xe9;mi Leblond&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alayrac_J/0/1/0/all/0/1&quot;&gt;Jean-Baptiste Alayrac&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Osokin_A/0/1/0/all/0/1&quot;&gt;Anton Osokin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lacoste_Julien_S/0/1/0/all/0/1&quot;&gt;Simon Lacoste-Julien&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1707.03269">
<title>Q-Learning Algorithm for VoLTE Closed-Loop Power Control in Indoor Small Cells. (arXiv:1707.03269v4 [cs.NI] UPDATED)</title>
<link>http://arxiv.org/abs/1707.03269</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a closed-loop power control algorithm for the downlink of the
voice over LTE (VoLTE) radio bearer for an indoor environment served by small
cells. The main contributions of our paper are: 1) proposing closed-loop power
control for downlink VoLTE (or any packetized voice bearer), 2) deriving an
upper bound of the loss in VoLTE downlink signal to noise plus interference
ratio which the closed-loop power control has to overcome, 3) employing
reinforcement learning to perform closed-loop power control, and 4) showing
that this closed-loop power control method can improve the quality of VoLTE in
a realistic network setup. Our simulation results have shown that our proposed
algorithm significantly improved both voice retainability and mean opinion
score as a result of maintaining the effective downlink signal to interference
plus noise ratio against adverse network operational issues and faults.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mismar_F/0/1/0/all/0/1&quot;&gt;Faris B. Mismar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Evans_B/0/1/0/all/0/1&quot;&gt;Brian L. Evans&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.08894">
<title>On the regularization of Wasserstein GANs. (arXiv:1709.08894v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1709.08894</link>
<description rdf:parseType="Literal">&lt;p&gt;Since their invention, generative adversarial networks (GANs) have become a
popular approach for learning to model a distribution of real (unlabeled) data.
Convergence problems during training are overcome by Wasserstein GANs which
minimize the distance between the model and the empirical distribution in terms
of a different metric, but thereby introduce a Lipschitz constraint into the
optimization problem. A simple way to enforce the Lipschitz constraint on the
class of functions, which can be modeled by the neural network, is weight
clipping. It was proposed that training can be improved by instead augmenting
the loss by a regularization term that penalizes the deviation of the gradient
of the critic (as a function of the network&apos;s input) from one. We present
theoretical arguments why using a weaker regularization term enforcing the
Lipschitz constraint is preferable. These arguments are supported by
experimental results on toy data sets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Petzka_H/0/1/0/all/0/1&quot;&gt;Henning Petzka&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Fischer_A/0/1/0/all/0/1&quot;&gt;Asja Fischer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lukovnicov_D/0/1/0/all/0/1&quot;&gt;Denis Lukovnicov&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.00165">
<title>Deep Neural Networks as Gaussian Processes. (arXiv:1711.00165v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1711.00165</link>
<description rdf:parseType="Literal">&lt;p&gt;It has long been known that a single-layer fully-connected neural network
with an i.i.d. prior over its parameters is equivalent to a Gaussian process
(GP), in the limit of infinite network width. This correspondence enables exact
Bayesian inference for infinite width neural networks on regression tasks by
means of evaluating the corresponding GP. Recently, kernel functions which
mimic multi-layer random neural networks have been developed, but only outside
of a Bayesian framework. As such, previous work has not identified that these
kernels can be used as covariance functions for GPs and allow fully Bayesian
prediction with a deep neural network.
&lt;/p&gt;
&lt;p&gt;In this work, we derive the exact equivalence between infinitely wide deep
networks and GPs. We further develop a computationally efficient pipeline to
compute the covariance function for these GPs. We then use the resulting GPs to
perform Bayesian inference for wide deep neural networks on MNIST and CIFAR-10.
We observe that trained neural network accuracy approaches that of the
corresponding GP with increasing layer width, and that the GP uncertainty is
strongly correlated with trained network prediction error. We further find that
test performance increases as finite-width trained networks are made wider and
more similar to a GP, and thus that GP predictions typically outperform those
of finite-width networks. Finally we connect the performance of these GPs to
the recent theory of signal propagation in random neural networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lee_J/0/1/0/all/0/1&quot;&gt;Jaehoon Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bahri_Y/0/1/0/all/0/1&quot;&gt;Yasaman Bahri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Novak_R/0/1/0/all/0/1&quot;&gt;Roman Novak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Schoenholz_S/0/1/0/all/0/1&quot;&gt;Samuel S. Schoenholz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pennington_J/0/1/0/all/0/1&quot;&gt;Jeffrey Pennington&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sohl_Dickstein_J/0/1/0/all/0/1&quot;&gt;Jascha Sohl-Dickstein&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.04094">
<title>Enhancing Network Embedding with Auxiliary Information: An Explicit Matrix Factorization Perspective. (arXiv:1711.04094v2 [cs.SI] UPDATED)</title>
<link>http://arxiv.org/abs/1711.04094</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent advances in the field of network embedding have shown the
low-dimensional network representation is playing a critical role in network
analysis. However, most of the existing principles of network embedding do not
incorporate auxiliary information such as content and labels of nodes flexibly.
In this paper, we take a matrix factorization perspective of network embedding,
and incorporate structure, content and label information of the network
simultaneously. For structure, we validate that the matrix we construct
preserves high-order proximities of the network. Label information can be
further integrated into the matrix via the process of random walk sampling to
enhance the quality of embedding in an unsupervised manner, i.e., without
leveraging downstream classifiers. In addition, we generalize the Skip-Gram
Negative Sampling model to integrate the content of the network in a matrix
factorization framework. As a consequence, network embedding can be learned in
a unified framework integrating network structure and node content as well as
label information simultaneously. We demonstrate the efficacy of the proposed
model with the tasks of semi-supervised node classification and link prediction
on a variety of real-world benchmark network datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1&quot;&gt;Junliang Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_L/0/1/0/all/0/1&quot;&gt;Linli Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1&quot;&gt;Xunpeng Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_E/0/1/0/all/0/1&quot;&gt;Enhong Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.09913">
<title>Visualizing the Loss Landscape of Neural Nets. (arXiv:1712.09913v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1712.09913</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural network training relies on our ability to find &quot;good&quot; minimizers of
highly non-convex loss functions. It is well known that certain network
architecture designs (e.g., skip connections) produce loss functions that train
easier, and well-chosen training parameters (batch size, learning rate,
optimizer) produce minimizers that generalize better. However, the reasons for
these differences, and their effect on the underlying loss landscape, is not
well understood. In this paper, we explore the structure of neural loss
functions, and the effect of loss landscapes on generalization, using a range
of visualization methods. First, we introduce a simple &quot;filter normalization&quot;
method that helps us visualize loss function curvature, and make meaningful
side-by-side comp arisons between loss functions. Then, using a variety of
visualizations, we explore how network architecture affects the loss landscape,
and how training parameters affect the shape of minimizers.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1&quot;&gt;Hao Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1&quot;&gt;Zheng Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Taylor_G/0/1/0/all/0/1&quot;&gt;Gavin Taylor&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Studer_C/0/1/0/all/0/1&quot;&gt;Christoph Studer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goldstein_T/0/1/0/all/0/1&quot;&gt;Tom Goldstein&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.10116">
<title>Generalized Byzantine-tolerant SGD. (arXiv:1802.10116v2 [cs.DC] UPDATED)</title>
<link>http://arxiv.org/abs/1802.10116</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose three new robust aggregation rules for distributed synchronous
Stochastic Gradient Descent~(SGD) under a general Byzantine failure model. The
attackers can arbitrarily manipulate the data transferred between the servers
and the workers in the parameter server~(PS) architecture. We prove the
Byzantine resilience properties of these aggregation rules. Empirical analysis
shows that the proposed techniques outperform current approaches for realistic
use cases and Byzantine attack scenarios.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_C/0/1/0/all/0/1&quot;&gt;Cong Xie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koyejo_O/0/1/0/all/0/1&quot;&gt;Oluwasanmi Koyejo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gupta_I/0/1/0/all/0/1&quot;&gt;Indranil Gupta&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.00930">
<title>Beyond black-boxes in Bayesian inverse problems and model validation: applications in solid mechanics of elastography. (arXiv:1803.00930v2 [physics.comp-ph] UPDATED)</title>
<link>http://arxiv.org/abs/1803.00930</link>
<description rdf:parseType="Literal">&lt;p&gt;The present paper is motivated by one of the most fundamental challenges in
inverse problems, that of quantifying model discrepancies and errors. While
significant strides have been made in calibrating model parameters, the
overwhelming majority of pertinent methods is based on the assumption of a
perfect model. Motivated by problems in solid mechanics which, as all problems
in continuum thermodynamics, are described by conservation laws and
phenomenological constitutive closures, we argue that in order to quantify
model uncertainty in a physically meaningful manner, one should break open the
black-box forward model. In particular we propose formulating an undirected
probabilistic model that explicitly accounts for the governing equations and
their validity. This recasts the solution of both forward and inverse problems
as probabilistic inference tasks where the problem&apos;s state variables should not
only be compatible with the data but also with the governing equations as well.
Even though the probability densities involved do not contain any black-box
terms, they live in much higher-dimensional spaces. In combination with the
intractability of the normalization constant of the undirected model employed,
this poses significant challenges which we propose to address with a
linearly-scaling, double-layer of Stochastic Variational Inference. We
demonstrate the capabilities and efficacy of the proposed model in synthetic
forward and inverse problems (with and without model error) in elastography.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Bruder_L/0/1/0/all/0/1&quot;&gt;Lukas Bruder&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Koutsourelakis_P/0/1/0/all/0/1&quot;&gt;Phaedon-Stelios Koutsourelakis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1702.08690">
<title>Borrowing Treasures from the Wealthy: Deep Transfer Learning through Selective Joint Fine-tuning. (arXiv:1702.08690v2 [cs.CV] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1702.08690</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep neural networks require a large amount of labeled training data during
supervised learning. However, collecting and labeling so much data might be
infeasible in many cases. In this paper, we introduce a source-target selective
joint fine-tuning scheme for improving the performance of deep learning tasks
with insufficient training data. In this scheme, a target learning task with
insufficient training data is carried out simultaneously with another source
learning task with abundant training data. However, the source learning task
does not use all existing training data. Our core idea is to identify and use a
subset of training images from the original source learning task whose
low-level characteristics are similar to those from the target learning task,
and jointly fine-tune shared convolutional layers for both tasks. Specifically,
we compute descriptors from linear or nonlinear filter bank responses on
training images from both tasks, and use such descriptors to search for a
desired subset of training samples for the source learning task.
&lt;/p&gt;
&lt;p&gt;Experiments demonstrate that our selective joint fine-tuning scheme achieves
state-of-the-art performance on multiple visual classification tasks with
insufficient training data for deep learning. Such tasks include Caltech 256,
MIT Indoor 67, Oxford Flowers 102 and Stanford Dogs 120. In comparison to
fine-tuning without a source domain, the proposed method can improve the
classification accuracy by 2% - 10% using a single model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ge_W/0/1/0/all/0/1&quot;&gt;Weifeng Ge&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1&quot;&gt;Yizhou Yu&lt;/a&gt;</dc:creator>
</item></rdf:RDF>