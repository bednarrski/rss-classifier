<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Good papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Good Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-01-21T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1608.01818"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.06294"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.06316"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1704.01006"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.05785"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.06287"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.06309"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.06397"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1608.01818">
<title>The BioDynaMo Project: a platform for computer simulations of biological dynamics. (arXiv:1608.01818v2 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1608.01818</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper is a brief update on developments in the BioDynaMo project, a new
platform for computer simulations for biological research. We will discuss the
new capabilities of the simulator, important new concepts simulation
methodology as well as its numerous applications to the computational biology
and nanoscience communities.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Johard_L/0/1/0/all/0/1&quot;&gt;Leonard Johard&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Breitwieser_L/0/1/0/all/0/1&quot;&gt;Lukas Breitwieser&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meglio_A/0/1/0/all/0/1&quot;&gt;Alberto Di Meglio&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Manca_M/0/1/0/all/0/1&quot;&gt;Marco Manca&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mazzara_M/0/1/0/all/0/1&quot;&gt;Manuel Mazzara&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Talanov_M/0/1/0/all/0/1&quot;&gt;Max Talanov&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.06294">
<title>Multi-Task Pharmacovigilance Mining from Social Media Posts. (arXiv:1801.06294v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1801.06294</link>
<description rdf:parseType="Literal">&lt;p&gt;Social media has grown to be a crucial information source for
pharmacovigilance studies where an increasing number of people post adverse
reactions to medical drugs that are previously unreported. Aiming to
effectively monitor various aspects of Adverse Drug Reactions (ADRs) from
diversely expressed social medical posts, we propose a multi-task neural
network framework that learns several tasks associated with ADR monitoring with
different levels of supervisions collectively. Besides being able to correctly
classify ADR posts and accurately extract ADR mentions from online posts, the
proposed framework is also able to further understand reasons for which the
drug is being taken, known as &apos;indication&apos;, from the given social media post. A
coverage-based attention mechanism is adopted in our framework to help the
model properly identify &apos;phrasal&apos; ADRs and Indications that are attentive to
multiple words in a post. Our framework is applicable in situations where
limited parallel data for different pharmacovigilance tasks are available.We
evaluate the proposed framework on real-world Twitter datasets, where the
proposed model outperforms the state-of-the-art alternatives of each individual
task consistently.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chowdhury_S/0/1/0/all/0/1&quot;&gt;Shaika Chowdhury&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1&quot;&gt;Chenwei Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1&quot;&gt;Philip S. Yu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.06316">
<title>Demonstration of Topological Data Analysis on a Quantum Processor. (arXiv:1801.06316v1 [quant-ph])</title>
<link>http://arxiv.org/abs/1801.06316</link>
<description rdf:parseType="Literal">&lt;p&gt;Topological data analysis offers a robust way to extract useful information
from noisy, unstructured data by identifying its underlying structure.
Recently, an efficient quantum algorithm was proposed [Lloyd, Garnerone,
Zanardi, Nat. Commun. 7, 10138 (2016)] for calculating Betti numbers of data
points -- topological features that count the number of topological holes of
various dimensions in a scatterplot. Here, we implement a proof-of-principle
demonstration of this quantum algorithm by employing a six-photon quantum
processor to successfully analyze the topological features of Betti numbers of
a network including three data points, providing new insights into data
analysis in the era of quantum computing.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Huang_H/0/1/0/all/0/1&quot;&gt;He-Liang Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;Xi-Lin Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Rohde_P/0/1/0/all/0/1&quot;&gt;Peter P. Rohde&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Luo_Y/0/1/0/all/0/1&quot;&gt;Yi-Han Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Zhao_Y/0/1/0/all/0/1&quot;&gt;You-Wei Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Liu_C/0/1/0/all/0/1&quot;&gt;Chang Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Li_L/0/1/0/all/0/1&quot;&gt;Li Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Liu_N/0/1/0/all/0/1&quot;&gt;Nai-Le Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Lu_C/0/1/0/all/0/1&quot;&gt;Chao-Yang Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Pan_J/0/1/0/all/0/1&quot;&gt;Jian-Wei Pan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1704.01006">
<title>Ontology based Scene Creation for the Development of Automated Vehicles. (arXiv:1704.01006v4 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1704.01006</link>
<description rdf:parseType="Literal">&lt;p&gt;The introduction of automated vehicles without permanent human supervision
demands a functional system description, including functional system boundaries
and a comprehensive safety analysis. These inputs to the technical development
can be identified and analyzed by a scenario-based approach. Furthermore, to
establish an economical test and release process, a large number of scenarios
must be identified to obtain meaningful test results. Experts are doing well to
identify scenarios that are difficult to handle or unlikely to happen. However,
experts are unlikely to identify all scenarios possible based on the knowledge
they have on hand. Expert knowledge modeled for computer aided processing may
help for the purpose of providing a wide range of scenarios. This contribution
reviews ontologies as knowledge-based systems in the field of automated
vehicles, and proposes a generation of traffic scenes in natural language as a
basis for a scenario creation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bagschik_G/0/1/0/all/0/1&quot;&gt;Gerrit Bagschik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Menzel_T/0/1/0/all/0/1&quot;&gt;Till Menzel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Maurer_M/0/1/0/all/0/1&quot;&gt;Markus Maurer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.05785">
<title>Sentiment Predictability for Stocks. (arXiv:1712.05785v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1712.05785</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work, we present our findings and experiments for stock-market
prediction using various textual sentiment analysis tools, such as mood
analysis and event extraction, as well as prediction models, such as LSTMs and
specific convolutional architectures.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Prosky_J/0/1/0/all/0/1&quot;&gt;Jordan Prosky&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_X/0/1/0/all/0/1&quot;&gt;Xingyou Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tan_A/0/1/0/all/0/1&quot;&gt;Andrew Tan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_M/0/1/0/all/0/1&quot;&gt;Michael Zhao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.06287">
<title>What Does a TextCNN Learn?. (arXiv:1801.06287v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1801.06287</link>
<description rdf:parseType="Literal">&lt;p&gt;TextCNN, the convolutional neural network for text, is a useful deep learning
algorithm for sentence classification tasks such as sentiment analysis and
question classification. However, neural networks have long been known as black
boxes because interpreting them is a challenging task. Researchers have
developed several tools to understand a CNN for image classification by deep
visualization, but research about deep TextCNNs is still insufficient. In this
paper, we are trying to understand what a TextCNN learns on two classical NLP
datasets. Our work focuses on functions of different convolutional kernels and
correlations between convolutional kernels.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gong_L/0/1/0/all/0/1&quot;&gt;Linyuan Gong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ji_R/0/1/0/all/0/1&quot;&gt;Ruyi Ji&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.06309">
<title>Composite Functional Gradient Learning of Generative Adversarial Models. (arXiv:1801.06309v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1801.06309</link>
<description rdf:parseType="Literal">&lt;p&gt;Generative adversarial networks (GAN) have become popular for generating data
that mimic observations by learning a suitable variable transformation from a
random variable. However, empirically, GAN is known to suffer from instability.
Also, the theory provided based on the minimax optimization formulation of GAN
cannot explain the widely-used practical procedure that uses the so-called logd
trick. This paper provides a different theoretical foundation for generative
adversarial methods which does not rely on the minimax formulation. We show
that with a strong discriminator, it is possible to learn a good variable
transformation via functional gradient learning, which updates the functional
definition of a generator model, instead of updating only the model parameters
as in GAN. The theory guarantees that the learned generator improves the
KL-divergence between the probability distributions of real data and generated
data after each functional gradient step, until the KL-divergence converges to
zero. This new point of view leads to enhanced stable procedures for training
generative models that can utilize arbitrary learning algorithms. It also gives
a new theoretical insight into the original GAN procedure both with and without
the logd trick. Empirical results are shown on image generation to illustrate
the effectiveness of our new method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Johnson_R/0/1/0/all/0/1&quot;&gt;Rie Johnson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhang_T/0/1/0/all/0/1&quot;&gt;Tong Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.06397">
<title>What Makes Good Synthetic Training Data for Learning Disparity and Optical Flow Estimation?. (arXiv:1801.06397v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1801.06397</link>
<description rdf:parseType="Literal">&lt;p&gt;The finding that very large networks can be trained efficiently and reliably
has led to a paradigm shift in computer vision from engineered solutions to
learning formulations. As a result, the research challenge shifts from devising
algorithms to creating suitable and abundant training data for supervised
learning. How to efficiently create such training data? The dominant data
acquisition method in visual recognition is based on web data and manual
annotation. Yet, for many computer vision problems, such as stereo or optical
flow estimation, this approach is not feasible because humans cannot manually
enter a pixel-accurate flow field. In this paper, we promote the use of
synthetically generated data for the purpose of training deep networks on such
tasks.We suggest multiple ways to generate such data and evaluate the influence
of dataset properties on the performance and generalization properties of the
resulting networks. We also demonstrate the benefit of learning schedules that
use different types of data at selected stages of the training process.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mayer_N/0/1/0/all/0/1&quot;&gt;Nikolaus Mayer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ilg_E/0/1/0/all/0/1&quot;&gt;Eddy Ilg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fischer_P/0/1/0/all/0/1&quot;&gt;Philipp Fischer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hazirbas_C/0/1/0/all/0/1&quot;&gt;Caner Hazirbas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cremers_D/0/1/0/all/0/1&quot;&gt;Daniel Cremers&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dosovitskiy_A/0/1/0/all/0/1&quot;&gt;Alexey Dosovitskiy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brox_T/0/1/0/all/0/1&quot;&gt;Thomas Brox&lt;/a&gt;</dc:creator>
</item></rdf:RDF>