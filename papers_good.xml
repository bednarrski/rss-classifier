<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Good papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Good Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-06-17T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05695"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05759"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05876"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05978"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.06530"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05740"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05780"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05789"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1706.07160"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.04623"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00807"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05421"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05703"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05768"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05779"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05805"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05810"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05819"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05897"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05964"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05975"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06047"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1705.08153"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.06559"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.01396"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.00530"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.00722"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.01947"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09039"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1806.05695">
<title>Evolving simple programs for playing Atari games. (arXiv:1806.05695v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1806.05695</link>
<description rdf:parseType="Literal">&lt;p&gt;Cartesian Genetic Programming (CGP) has previously shown capabilities in
image processing tasks by evolving programs with a function set specialized for
computer vision. A similar approach can be applied to Atari playing. Programs
are evolved using mixed type CGP with a function set suited for matrix
operations, including image processing, but allowing for controller behavior to
emerge. While the programs are relatively small, many controllers are
competitive with state of the art methods for the Atari benchmark set and
require less training time. By evaluating the programs of the best evolved
individuals, simple but effective strategies can be found.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wilson_D/0/1/0/all/0/1&quot;&gt;Dennis G Wilson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cussat_Blanc_S/0/1/0/all/0/1&quot;&gt;Sylvain Cussat-Blanc&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luga_H/0/1/0/all/0/1&quot;&gt;Herv&amp;#xe9; Luga&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Miller_J/0/1/0/all/0/1&quot;&gt;Julian F Miller&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05759">
<title>Insights on representational similarity in neural networks with canonical correlation. (arXiv:1806.05759v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.05759</link>
<description rdf:parseType="Literal">&lt;p&gt;Comparing different neural network representations and determining how
representations evolve over time remain challenging open questions in our
understanding of the function of neural networks. Comparing representations in
neural networks is fundamentally difficult as the structure of representations
varies greatly, even across groups of networks trained on identical tasks, and
over the course of training. Here, we develop projection weighted CCA
(Canonical Correlation Analysis) as a tool for understanding neural networks,
building off of SVCCA, a recently proposed method. We first improve the core
method, showing how to differentiate between signal and noise, and then apply
this technique to compare across a group of CNNs, demonstrating that networks
which generalize converge to more similar representations than networks which
memorize, that wider networks converge to more similar solutions than narrow
networks, and that trained networks with identical topology but different
learning rates converge to distinct clusters with diverse representations. We
also investigate the representational dynamics of RNNs, across both training
and sequential timesteps, finding that RNNs converge in a bottom-up pattern
over the course of training and that the hidden state is highly variable over
the course of a sequence, even when accounting for linear transforms. Together,
these results provide new insights into the function of CNNs and RNNs, and
demonstrate the utility of using CCA to understand representations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Morcos_A/0/1/0/all/0/1&quot;&gt;Ari S. Morcos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Raghu_M/0/1/0/all/0/1&quot;&gt;Maithra Raghu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bengio_S/0/1/0/all/0/1&quot;&gt;Samy Bengio&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05876">
<title>Financial Risk and Returns Prediction with Modular Networked Learning. (arXiv:1806.05876v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.05876</link>
<description rdf:parseType="Literal">&lt;p&gt;An artificial agent for financial risk and returns&apos; prediction is built with
a modular cognitive system comprised of interconnected recurrent neural
networks, such that the agent learns to predict the financial returns, and
learns to predict the squared deviation around these predicted returns. These
two expectations are used to build a volatility-sensitive interval prediction
for financial returns, which is evaluated on three major financial indices and
shown to be able to predict financial returns with higher than 80% success rate
in interval prediction in both training and testing, raising into question the
Efficient Market Hypothesis. The agent is introduced as an example of a class
of artificial intelligent systems that are equipped with a Modular Networked
Learning cognitive system, defined as an integrated networked system of machine
learning modules, where each module constitutes a functional unit that is
trained for a given specific task that solves a subproblem of a complex main
problem expressed as a network of linked subproblems. In the case of neural
networks, these systems function as a form of an &quot;artificial brain&quot;, where each
module is like a specialized brain region comprised of a neural network with a
specific architecture.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goncalves_C/0/1/0/all/0/1&quot;&gt;Carlos Pedro Gon&amp;#xe7;alves&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05978">
<title>Bayesian Convolutional Neural Networks. (arXiv:1806.05978v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.05978</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a Bayesian convolutional neural network built upon Bayes by
Backprop and elaborate how this known method can serve as the fundamental
construct of our novel reliable variational inference method for convolutional
neural networks. First, we show how Bayes by Backprop can be applied to
convolutional layers where weights in filters have probability distributions
instead of point-estimates; and second, how our proposed framework leads with
various network architectures to performances comparable to convolutional
neural networks with point-estimates weights. This work represents the
expansion of the group of Bayesian neural networks, which consist now of
feedforward, recurrent, and convolutional ones.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Laumann_F/0/1/0/all/0/1&quot;&gt;Felix Laumann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shridhar_K/0/1/0/all/0/1&quot;&gt;Kumar Shridhar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.06530">
<title>Dynamic Weight Alignment for Convolutional Neural Networks. (arXiv:1712.06530v4 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1712.06530</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we propose a method of improving Convolutional Neural Networks
(CNN) by determining the optimal alignment of weights and inputs using dynamic
programming. Conventional CNNs convolve learnable shared weights, or filters,
across the input data. The filters use a linear matching of weights to inputs
using an inner product between the filter and a window of the input. However,
it is possible that there exists a more optimal alignment of weights. Thus, we
propose the use of Dynamic Time Warping (DTW) to dynamically align the weights
to optimized input elements. This dynamic alignment is useful for time series
recognition due to the complexities with temporal distortions, such as varying
rates and sequence lengths. We demonstrate the effectiveness of the proposed
architecture on the Unipen online handwritten digit and character datasets, the
UCI Spoken Arabic Digit dataset, and the UCI Activities of Daily Life dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Iwana_B/0/1/0/all/0/1&quot;&gt;Brian Kenji Iwana&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Uchida_S/0/1/0/all/0/1&quot;&gt;Seiichi Uchida&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05740">
<title>Using Search Queries to Understand Health Information Needs in Africa. (arXiv:1806.05740v1 [cs.CY])</title>
<link>http://arxiv.org/abs/1806.05740</link>
<description rdf:parseType="Literal">&lt;p&gt;The lack of comprehensive, high-quality health data in developing nations
creates a roadblock for combating the impacts of disease. One key challenge is
understanding the health information needs of people in these nations. Without
understanding people&apos;s everyday needs, concerns, and misconceptions, health
organizations and policymakers lack the ability to effectively target education
and programming efforts. In this paper, we propose a bottom-up approach that
uses search data from individuals to uncover and gain insight into health
information needs in Africa. We analyze Bing searches related to HIV/AIDS,
malaria, and tuberculosis from all 54 African nations. For each disease, we
automatically derive a set of common search themes or topics, revealing a
wide-spread interest in various types of information, including disease
symptoms, drugs, concerns about breastfeeding, as well as stigma, beliefs in
natural cures, and other topics that may be hard to uncover through traditional
surveys. We expose the different patterns that emerge in health information
needs by demographic groups (age and sex) and country. We also uncover
discrepancies in the quality of content returned by search engines to users by
topic. Combined, our results suggest that search data can help illuminate
health information needs in Africa and inform discussions on health policy and
targeted education efforts both on- and offline.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abebe_R/0/1/0/all/0/1&quot;&gt;Rediet Abebe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hill_S/0/1/0/all/0/1&quot;&gt;Shawndra Hill&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vaughan_J/0/1/0/all/0/1&quot;&gt;Jennifer Wortman Vaughan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Small_P/0/1/0/all/0/1&quot;&gt;Peter M. Small&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schwartz_H/0/1/0/all/0/1&quot;&gt;H. Andrew Schwartz&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05780">
<title>Sample-Efficient Deep RL with Generative Adversarial Tree Search. (arXiv:1806.05780v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.05780</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose Generative Adversarial Tree Search (GATS), a sample-efficient Deep
Reinforcement Learning (DRL) algorithm. While Monte Carlo Tree Search (MCTS) is
known to be effective for search and planning in RL, it is often
sample-inefficient and therefore expensive to apply in practice. In this work,
we develop a Generative Adversarial Network (GAN) architecture to model an
environment&apos;s dynamics and a predictor model for the reward function. We
exploit collected data from interaction with the environment to learn these
models, which we then use for model-based planning. During planning, we deploy
a finite depth MCTS, using the learned model for tree search and a learned
Q-value for the leaves, to find the best action. We theoretically show that
GATS improves the bias-variance trade-off in value-based DRL. Moreover, we show
that the generative model learns the model dynamics using orders of magnitude
fewer samples than the Q-learner. In non-stationary settings where the
environment model changes, we find the generative model adapts significantly
faster than the Q-learner to the new environment.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Azizzadenesheli_K/0/1/0/all/0/1&quot;&gt;Kamyar Azizzadenesheli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_B/0/1/0/all/0/1&quot;&gt;Brandon Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1&quot;&gt;Weitang Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brunskill_E/0/1/0/all/0/1&quot;&gt;Emma Brunskill&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lipton_Z/0/1/0/all/0/1&quot;&gt;Zachary C Lipton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Anandkumar_A/0/1/0/all/0/1&quot;&gt;Animashree Anandkumar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05789">
<title>Random depthwise signed convolutional neural networks. (arXiv:1806.05789v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1806.05789</link>
<description rdf:parseType="Literal">&lt;p&gt;Random weights in convolutional neural networks have shown promising results
in previous studies yet remain below par compared to trained networks on image
benchmarks. We explore depthwise convolutional neural networks with thousands
of random filters in each layer, the sign activation function in between
layers, and training performed only at the last layer with a linear support
vector machine. We show that our network attains higher accuracies than
previous random networks and is comparable to trained large networks on large
images from the STL10 and ImageNet benchmarks. Since our network lacks a
gradient due to the sign activation it is not possible to produce
gradient-based adversarial examples targeting it. We show that our network is
also less affected by gradient based adversarial examples produced from state
of the art networks that considerably hamper their performance. As a possible
explanation for our network&apos;s accuracy with random weights we show that the the
margin of the linear support vector machine is larger on our final
representation compared to the original dataset and increases with the number
of random filters. Our network is simple and fast to train and predict, attains
high classification accuracy particularly on large images, is hard to attack
with adversarial examples, and is less affected by gradient based adversarial
examples compared to state of the art networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xue_Y/0/1/0/all/0/1&quot;&gt;Yunzhe Xue&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roshan_U/0/1/0/all/0/1&quot;&gt;Usman Roshan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1706.07160">
<title>MAGIX: Model Agnostic Globally Interpretable Explanations. (arXiv:1706.07160v3 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1706.07160</link>
<description rdf:parseType="Literal">&lt;p&gt;Explaining the behavior of a black box machine learning model at the instance
level is useful for building trust. However, it is also important to understand
how the model behaves globally. Such an understanding provides insight into
both the data on which the model was trained and the patterns that it learned.
We present here an approach that learns if-then rules to globally explain the
behavior of black box machine learning models that have been used to solve
classification problems. The approach works by first extracting conditions that
were important at the instance level and then evolving rules through a genetic
algorithm with an appropriate fitness function. Collectively, these rules
represent the patterns followed by the model for decisioning and are useful for
understanding its behavior. We demonstrate the validity and usefulness of the
approach by interpreting black box models created using publicly available data
sets as well as a private digital marketing data set.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Puri_N/0/1/0/all/0/1&quot;&gt;Nikaash Puri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gupta_P/0/1/0/all/0/1&quot;&gt;Piyush Gupta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Agarwal_P/0/1/0/all/0/1&quot;&gt;Pratiksha Agarwal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Verma_S/0/1/0/all/0/1&quot;&gt;Sukriti Verma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Krishnamurthy_B/0/1/0/all/0/1&quot;&gt;Balaji Krishnamurthy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.04623">
<title>Three Factors Influencing Minima in SGD. (arXiv:1711.04623v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1711.04623</link>
<description rdf:parseType="Literal">&lt;p&gt;We investigate the dynamical and convergent properties of stochastic gradient
descent (SGD) applied to Deep Neural Networks (DNNs). Characterizing the
relation between learning rate, batch size and the properties of the final
minima, such as width or generalization, remains an open question. In order to
tackle this problem we investigate the previously proposed approximation of SGD
by a stochastic differential equation (SDE). We theoretically argue that three
factors - learning rate, batch size and gradient covariance - influence the
minima found by SGD. In particular we find that the ratio of learning rate to
batch size is a key determinant of SGD dynamics and of the width of the final
minima, and that higher values of the ratio lead to wider minima and often
better generalization. We confirm these findings experimentally. Further, we
include experiments which show that learning rate schedules can be replaced
with batch size schedules and that the ratio of learning rate to batch size is
an important factor influencing the memorization process.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jastrzebski_S/0/1/0/all/0/1&quot;&gt;Stanis&amp;#x142;aw Jastrz&amp;#x119;bski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kenton_Z/0/1/0/all/0/1&quot;&gt;Zachary Kenton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Arpit_D/0/1/0/all/0/1&quot;&gt;Devansh Arpit&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ballas_N/0/1/0/all/0/1&quot;&gt;Nicolas Ballas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fischer_A/0/1/0/all/0/1&quot;&gt;Asja Fischer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bengio_Y/0/1/0/all/0/1&quot;&gt;Yoshua Bengio&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Storkey_A/0/1/0/all/0/1&quot;&gt;Amos Storkey&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00807">
<title>Learning Semantic Sentence Embeddings using Pair-wise Discriminator. (arXiv:1806.00807v3 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1806.00807</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we propose a method for obtaining sentence-level embeddings.
While the problem of securing word-level embeddings is very well studied, we
propose a novel method for obtaining sentence-level embeddings. This is
obtained by a simple method in the context of solving the paraphrase generation
task. If we use a sequential encoder-decoder model for generating paraphrase,
we would like the generated paraphrase to be semantically close to the original
sentence. One way to ensure this is by adding constraints for true paraphrase
embeddings to be close and unrelated paraphrase candidate sentence embeddings
to be far. This is ensured by using a sequential pair-wise discriminator that
shares weights with the encoder that is trained with a suitable loss function.
Our loss function penalizes paraphrase sentence embedding distances from being
too large. This loss is used in combination with a sequential encoder-decoder
network. We also validated our method by evaluating the obtained embeddings for
a sentiment analysis task. The proposed method results in semantic embeddings
and outperforms the state-of-the-art on the paraphrase generation and sentiment
analysis task on standard datasets. These results are also shown to be
statistically significant.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Patro_B/0/1/0/all/0/1&quot;&gt;Badri N. Patro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kurmi_V/0/1/0/all/0/1&quot;&gt;Vinod K. Kurmi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1&quot;&gt;Sandeep Kumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Namboodiri_V/0/1/0/all/0/1&quot;&gt;Vinay P. Namboodiri&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05421">
<title>Selfless Sequential Learning. (arXiv:1806.05421v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1806.05421</link>
<description rdf:parseType="Literal">&lt;p&gt;Sequential learning studies the problem of learning tasks in a sequence with
restricted access to only the data of the current task. In the setting with a
fixed model capacity, the learning process should not be selfish and account
for later tasks to be added and therefore aim at utilizing a minimum number of
neurons, leaving enough capacity for future needs. We explore different
regularization strategies and activation functions that could lead to less
interference between the different tasks. We show that learning a sparse
representation is more beneficial for sequential learning than encouraging
parameter sparsity regardless of their corresponding neurons. We particularly
propose a novel regularizer that encourages representation sparsity by means of
neural inhibition. It results in few active neurons which in turn leaves more
free neurons to be utilized by upcoming tasks. We combine our regularizer with
state-of-the-art lifelong learning methods that penalize changes on important
previously learned parts of the network. We show that increased sparsity
translates in a performance improvement on the different tasks that are learned
in a sequence.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Aljundi_R/0/1/0/all/0/1&quot;&gt;Rahaf Aljundi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rohrbach_M/0/1/0/all/0/1&quot;&gt;Marcus Rohrbach&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tuytelaars_T/0/1/0/all/0/1&quot;&gt;Tinne Tuytelaars&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05703">
<title>Multilevel Artificial Neural Network Training for Spatially Correlated Learning. (arXiv:1806.05703v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.05703</link>
<description rdf:parseType="Literal">&lt;p&gt;Multigrid modeling algorithms are a technique used to accelerate relaxation
models running on a hierarchy of similar graphlike structures. We introduce and
demonstrate a new method for training neural networks which uses multilevel
methods. Using an objective function derived from a graph-distance metric, we
perform orthogonally-constrained optimization to find optimal prolongation and
restriction maps between graphs. We compare and contrast several methods for
performing this numerical optimization, and additionally present some new
theoretical results on upper bounds of this type of objective function. Once
calculated, these optimal maps between graphs form the core of Multiscale
Artificial Neural Network (MsANN) training, a new procedure we present which
simultaneously trains a hierarchy of neural network models of varying spatial
resolution. Parameter information is passed between members of this hierarchy
according to standard coarsening and refinement schedules from the multiscale
modelling literature. In our machine learning experiments, these models are
able to learn faster than default training, achieving a comparable level of
error in an order of magnitude fewer training examples.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Scott_C/0/1/0/all/0/1&quot;&gt;C.B. Scott&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mjolsness_E/0/1/0/all/0/1&quot;&gt;Eric Mjolsness&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05768">
<title>Hardware Trojan Attacks on Neural Networks. (arXiv:1806.05768v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.05768</link>
<description rdf:parseType="Literal">&lt;p&gt;With the rising popularity of machine learning and the ever increasing demand
for computational power, there is a growing need for hardware optimized
implementations of neural networks and other machine learning models. As the
technology evolves, it is also plausible that machine learning or artificial
intelligence will soon become consumer electronic products and military
equipment, in the form of well-trained models. Unfortunately, the modern
fabless business model of manufacturing hardware, while economic, leads to
deficiencies in security through the supply chain. In this paper, we illuminate
these security issues by introducing hardware Trojan attacks on neural
networks, expanding the current taxonomy of neural network security to
incorporate attacks of this nature. To aid in this, we develop a novel
framework for inserting malicious hardware Trojans in the implementation of a
neural network classifier. We evaluate the capabilities of the adversary in
this setting by implementing the attack algorithm on convolutional neural
networks while controlling a variety of parameters available to the adversary.
Our experimental results show that the proposed algorithm could effectively
classify a selected input trigger as a specified class on the MNIST dataset by
injecting hardware Trojans into $0.03\%$, on average, of neurons in the 5th
hidden layer of arbitrary 7-layer convolutional neural networks, while
undetectable under the test data. Finally, we discuss the potential defenses to
protect neural networks against hardware Trojan attacks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Clements_J/0/1/0/all/0/1&quot;&gt;Joseph Clements&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lao_Y/0/1/0/all/0/1&quot;&gt;Yingjie Lao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05779">
<title>Deep Learning Approximation: Zero-Shot Neural Network Speedup. (arXiv:1806.05779v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1806.05779</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural networks offer high-accuracy solutions to a range of problems, but are
costly to run in production systems because of computational and memory
requirements during a forward pass. Given a trained network, we propose a
techique called Deep Learning Approximation to build a faster network in a tiny
fraction of the time required for training by only manipulating the network
structure and coefficients without requiring re-training or access to the
training data. Speedup is achieved by by applying a sequential series of
independent optimizations that reduce the floating-point operations (FLOPs)
required to perform a forward pass. First, lossless optimizations are applied,
followed by lossy approximations using singular value decomposition (SVD) and
low-rank matrix decomposition. The optimal approximation is chosen by weighing
the relative accuracy loss and FLOP reduction according to a single parameter
specified by the user. On PASCAL VOC 2007 with the YOLO network, we show an
end-to-end 2x speedup in a network forward pass with a 5% drop in mAP that can
be re-gained by finetuning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pratusevich_M/0/1/0/all/0/1&quot;&gt;Michele Pratusevich&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05805">
<title>Molecular generative model based on conditional variational autoencoder for de novo molecular design. (arXiv:1806.05805v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.05805</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a molecular generative model based on the conditional variational
autoencoder for de novo molecular design. It is specialized to control multiple
molecular properties simultaneously by imposing them on a latent space. As a
proof of concept, we demonstrate that it can be used to generate drug-like
molecules with five target properties. We were also able to adjust a single
property without changing the others and to manipulate it beyond the range of
the dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lim_J/0/1/0/all/0/1&quot;&gt;Jaechang Lim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ryu_S/0/1/0/all/0/1&quot;&gt;Seongok Ryu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1&quot;&gt;Jin Woo Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_W/0/1/0/all/0/1&quot;&gt;Woo Youn Kim&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05810">
<title>Best sources forward: domain generalization through source-specific nets. (arXiv:1806.05810v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1806.05810</link>
<description rdf:parseType="Literal">&lt;p&gt;A long standing problem in visual object categorization is the ability of
algorithms to generalize across different testing conditions. The problem has
been formalized as a covariate shift among the probability distributions
generating the training data (source) and the test data (target) and several
domain adaptation methods have been proposed to address this issue. While these
approaches have considered the single source-single target scenario, it is
plausible to have multiple sources and require adaptation to any possible
target domain. This last scenario, named Domain Generalization (DG), is the
focus of our work. Differently from previous DG methods which learn domain
invariant representations from source data, we design a deep network with
multiple domain-specific classifiers, each associated to a source domain. At
test time we estimate the probabilities that a target sample belongs to each
source domain and exploit them to optimally fuse the classifiers predictions.
To further improve the generalization ability of our model, we also introduced
a domain agnostic component supporting the final classifier. Experiments on two
public benchmarks demonstrate the power of our approach.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mancini_M/0/1/0/all/0/1&quot;&gt;Massimiliano Mancini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bulo_S/0/1/0/all/0/1&quot;&gt;Samuel Rota Bul&amp;#xf2;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Caputo_B/0/1/0/all/0/1&quot;&gt;Barbara Caputo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ricci_E/0/1/0/all/0/1&quot;&gt;Elisa Ricci&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05819">
<title>BubbleRank: Safe Online Learning to Rerank. (arXiv:1806.05819v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.05819</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the problem of online learning to re-rank, where users provide
feedback to improve the quality of displayed lists. Learning to rank has been
traditionally studied in two settings. In the offline setting, rankers are
typically learned from relevance labels of judges. These approaches have become
the industry standard. However, they lack exploration, and thus are limited by
the information content of offline data. In the online setting, an algorithm
can propose a list and learn from the feedback on it in a sequential fashion.
Bandit algorithms developed for this setting actively experiment, and in this
way overcome the biases of offline data. But they also tend to ignore offline
data, which results in a high initial cost of exploration. We propose
BubbleRank, a bandit algorithm for re-ranking that combines the strengths of
both settings. The algorithm starts with an initial base list and improves it
gradually by swapping higher-ranked less attractive items for lower-ranked more
attractive items. We prove an upper bound on the n-step regret of BubbleRank
that degrades gracefully with the quality of the initial base list. Our
theoretical findings are supported by extensive numerical experiments on a
large real-world click dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kveton_B/0/1/0/all/0/1&quot;&gt;Branislav Kveton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1&quot;&gt;Chang Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lattimore_T/0/1/0/all/0/1&quot;&gt;Tor Lattimore&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Markov_I/0/1/0/all/0/1&quot;&gt;Ilya Markov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rijke_M/0/1/0/all/0/1&quot;&gt;Maarten de Rijke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Szepesvari_C/0/1/0/all/0/1&quot;&gt;Csaba Szepesvari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zoghi_M/0/1/0/all/0/1&quot;&gt;Masrour Zoghi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05897">
<title>Mining Rank Data. (arXiv:1806.05897v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.05897</link>
<description rdf:parseType="Literal">&lt;p&gt;The problem of frequent pattern mining has been studied quite extensively for
various types of data, including sets, sequences, and graphs. Somewhat
surprisingly, another important type of data, namely rank data, has received
very little attention in data mining so far. In this paper, we therefore
addresses the problem of mining rank data, that is, data in the form of
rankings (total orders) of an underlying set of items. More specifically, two
types of patterns are considered, namely frequent rankings and dependencies
between such rankings in the form of association rules. Algorithms for mining
frequent rankings and frequent closed rankings are proposed and tested
experimentally, using both synthetic and real data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Henzgen_S/0/1/0/all/0/1&quot;&gt;Sascha Henzgen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hullermeier_E/0/1/0/all/0/1&quot;&gt;Eyke H&amp;#xfc;llermeier&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05964">
<title>Supervised learning with generalized tensor networks. (arXiv:1806.05964v1 [quant-ph])</title>
<link>http://arxiv.org/abs/1806.05964</link>
<description rdf:parseType="Literal">&lt;p&gt;Tensor networks have found a wide use in a variety of applications in physics
and computer science, recently leading to both theoretical insights as well as
practical algorithms in machine learning. In this work we explore the
connection between tensor networks and probabilistic graphical models, and show
that it motivates the definition of generalized tensor networks where
information from a tensor can be copied and reused in other parts of the
network. We discuss the relationship between generalized tensor network
architectures used in quantum physics, such as String-Bond States and Entangled
Plaquette States, and architectures commonly used in machine learning. We
provide an algorithm to train these networks in a supervised learning context
and show that they overcome the limitations of regular tensor networks in
higher dimensions, while keeping the computation efficient. A method to combine
neural networks and tensor networks as part of a common deep learning
architecture is also introduced. We benchmark our algorithm for several
generalized tensor network architectures on the task of classifying images and
sounds, and show that they outperform previously introduced tensor network
algorithms. Some of the models we consider can be realized on a quantum
computer and may guide the development of near-term quantum machine learning
architectures.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Glasser_I/0/1/0/all/0/1&quot;&gt;Ivan Glasser&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Pancotti_N/0/1/0/all/0/1&quot;&gt;Nicola Pancotti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Cirac_J/0/1/0/all/0/1&quot;&gt;J. Ignacio Cirac&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05975">
<title>Structured Variational Learning of Bayesian Neural Networks with Horseshoe Priors. (arXiv:1806.05975v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.05975</link>
<description rdf:parseType="Literal">&lt;p&gt;Bayesian Neural Networks (BNNs) have recently received increasing attention
for their ability to provide well-calibrated posterior uncertainties. However,
model selection---even choosing the number of nodes---remains an open question.
Recent work has proposed the use of a horseshoe prior over node pre-activations
of a Bayesian neural network, which effectively turns off nodes that do not
help explain the data. In this work, we propose several modeling and inference
advances that consistently improve the compactness of the model learned while
maintaining predictive performance, especially in smaller-sample settings
including reinforcement learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ghosh_S/0/1/0/all/0/1&quot;&gt;Soumya Ghosh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yao_J/0/1/0/all/0/1&quot;&gt;Jiayu Yao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Doshi_Velez_F/0/1/0/all/0/1&quot;&gt;Finale Doshi-Velez&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06047">
<title>Computationally Efficient Estimation of the Spectral Gap of a Markov Chain. (arXiv:1806.06047v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.06047</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the problem of estimating from sample paths the absolute spectral
gap $\gamma_*$ of a reversible, irreducible and aperiodic Markov chain
$(X_t)_{t \in \mathbb{N}}$ over a finite state $\Omega$. We propose the ${\tt
UCPI}$ (Upper Confidence Power Iteration) algorithm for this problem, a
low-complexity algorithm which estimates the spectral gap in time ${\cal O}(n)$
and memory space ${\cal O}((\ln n)^2)$ given $n$ samples. This is in stark
contrast with most known methods which require at least memory space ${\cal
O}(|\Omega|)$, so that they cannot be applied to large state spaces.
Furthermore, ${\tt UCPI}$ is amenable to parallel implementation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Combes_R/0/1/0/all/0/1&quot;&gt;Richard Combes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Touati_M/0/1/0/all/0/1&quot;&gt;Mikael Touati&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1705.08153">
<title>Techniques for visualizing LSTMs applied to electrocardiograms. (arXiv:1705.08153v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1705.08153</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper explores four different visualization techniques for long
short-term memory (LSTM) networks applied to continuous-valued time series. On
the datasets analysed, we find that the best visualization technique is to
learn an input deletion mask that optimally reduces the true class score. With
a specific focus on single-lead electrocardiograms from the MIT-BIH arrhythmia
dataset, we show that salient input features for the LSTM classifier align well
with medical theory.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Westhuizen_J/0/1/0/all/0/1&quot;&gt;Jos van der Westhuizen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lasenby_J/0/1/0/all/0/1&quot;&gt;Joan Lasenby&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.06559">
<title>The Power of Interpolation: Understanding the Effectiveness of SGD in Modern Over-parametrized Learning. (arXiv:1712.06559v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1712.06559</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper we aim to formally explain the phenomenon of fast convergence
of SGD observed in modern machine learning. The key observation is that most
modern learning architectures are over-parametrized and are trained to
interpolate the data by driving the empirical loss (classification and
regression) close to zero. While it is still unclear why these interpolated
solutions perform well on test data, we show that these regimes allow for fast
convergence of SGD, comparable in number of iterations to full gradient
descent.
&lt;/p&gt;
&lt;p&gt;For convex loss functions we obtain an exponential convergence bound for {\it
mini-batch} SGD parallel to that for full gradient descent. We show that there
is a critical batch size $m^*$ such that: (a) SGD iteration with mini-batch
size $m\leq m^*$ is nearly equivalent to $m$ iterations of mini-batch size $1$
(\emph{linear scaling regime}). (b) SGD iteration with mini-batch $m&amp;gt; m^*$ is
nearly equivalent to a full gradient descent iteration (\emph{saturation
regime}).
&lt;/p&gt;
&lt;p&gt;Moreover, for the quadratic loss, we derive explicit expressions for the
optimal mini-batch and step size and explicitly characterize the two regimes
above. The critical mini-batch size can be viewed as the limit for effective
mini-batch parallelization. It is also nearly independent of the data size,
implying $O(n)$ acceleration over GD per unit of computation. We give
experimental evidence on real data which closely follows our theoretical
analyses.
&lt;/p&gt;
&lt;p&gt;Finally, we show how our results fit in the recent developments in training
deep neural networks and discuss connections to adaptive rates for SGD and
variance reduction.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_S/0/1/0/all/0/1&quot;&gt;Siyuan Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bassily_R/0/1/0/all/0/1&quot;&gt;Raef Bassily&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Belkin_M/0/1/0/all/0/1&quot;&gt;Mikhail Belkin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.01396">
<title>To understand deep learning we need to understand kernel learning. (arXiv:1802.01396v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1802.01396</link>
<description rdf:parseType="Literal">&lt;p&gt;Generalization performance of classifiers in deep learning has recently
become a subject of intense study. Deep models, typically over-parametrized,
tend to fit the training data exactly. Despite this &quot;overfitting&quot;, they perform
well on test data, a phenomenon not yet fully understood.
&lt;/p&gt;
&lt;p&gt;The first point of our paper is that strong performance of overfitted
classifiers is not a unique feature of deep learning. Using six real-world and
two synthetic datasets, we establish experimentally that kernel machines
trained to have zero classification or near zero regression error perform very
well on test data, even when the labels are corrupted with a high level of
noise. We proceed to give a lower bound on the norm of zero loss solutions for
smooth kernels, showing that they increase nearly exponentially with data size.
We point out that this is difficult to reconcile with the existing
generalization bounds. Moreover, none of the bounds produce non-trivial results
for interpolating solutions.
&lt;/p&gt;
&lt;p&gt;Second, we show experimentally that (non-smooth) Laplacian kernels easily fit
random labels, a finding that parallels results for ReLU neural networks. In
contrast, fitting noisy data requires many more epochs for smooth Gaussian
kernels. Similar performance of overfitted Laplacian and Gaussian classifiers
on test, suggests that generalization is tied to the properties of the kernel
function rather than the optimization process.
&lt;/p&gt;
&lt;p&gt;Certain key phenomena of deep learning are manifested similarly in kernel
methods in the modern &quot;overfitted&quot; regime. The combination of the experimental
and theoretical results presented in this paper indicates a need for new
theoretical ideas for understanding properties of classical kernel methods. We
argue that progress on understanding deep learning will be difficult until more
tractable &quot;shallow&quot; kernel methods are better understood.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Belkin_M/0/1/0/all/0/1&quot;&gt;Mikhail Belkin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ma_S/0/1/0/all/0/1&quot;&gt;Siyuan Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mandal_S/0/1/0/all/0/1&quot;&gt;Soumik Mandal&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.00530">
<title>Online Feature Ranking for Intrusion Detection Systems. (arXiv:1803.00530v2 [cs.CR] UPDATED)</title>
<link>http://arxiv.org/abs/1803.00530</link>
<description rdf:parseType="Literal">&lt;p&gt;Many current approaches to the design of intrusion detection systems apply
feature selection in a static, non-adaptive fashion. These methods often
neglect the dynamic nature of network data which requires to use adaptive
feature selection techniques. In this paper, we present a simple technique
based on incremental learning of support vector machines in order to rank the
features in real time within a streaming model for network data. Some
illustrative numerical experiments with two popular benchmark datasets show
that our approach allows to adapt to the changes in normal network behaviour
and novel attack patterns which have not been experienced before.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Atli_B/0/1/0/all/0/1&quot;&gt;Buse Gul Atli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jung_A/0/1/0/all/0/1&quot;&gt;Alexander Jung&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.00722">
<title>Hierarchical Novelty Detection for Visual Object Recognition. (arXiv:1804.00722v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1804.00722</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep neural networks have achieved impressive success in large-scale visual
object recognition tasks with a predefined set of classes. However, recognizing
objects of novel classes unseen during training still remains challenging. The
problem of detecting such novel classes has been addressed in the literature,
but most prior works have focused on providing simple binary or regressive
decisions, e.g., the output would be &quot;known,&quot; &quot;novel,&quot; or corresponding
confidence intervals. In this paper, we study more informative novelty
detection schemes based on a hierarchical classification framework. For an
object of a novel class, we aim for finding its closest super class in the
hierarchical taxonomy of known classes. To this end, we propose two different
approaches termed top-down and flatten methods, and their combination as well.
The essential ingredients of our methods are confidence-calibrated classifiers,
data relabeling, and the leave-one-out strategy for modeling novel classes
under the hierarchical taxonomy. Furthermore, our method can generate a
hierarchical embedding that leads to improved generalized zero-shot learning
performance in combination with other commonly-used semantic embeddings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1&quot;&gt;Kibok Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1&quot;&gt;Kimin Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Min_K/0/1/0/all/0/1&quot;&gt;Kyle Min&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yuting Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shin_J/0/1/0/all/0/1&quot;&gt;Jinwoo Shin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1&quot;&gt;Honglak Lee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.01947">
<title>Sliced-Wasserstein Autoencoder: An Embarrassingly Simple Generative Model. (arXiv:1804.01947v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1804.01947</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper we study generative modeling via autoencoders while using the
elegant geometric properties of the optimal transport (OT) problem and the
Wasserstein distances. We introduce Sliced-Wasserstein Autoencoders (SWAE),
which are generative models that enable one to shape the distribution of the
latent space into any samplable probability distribution without the need for
training an adversarial network or defining a closed-form for the distribution.
In short, we regularize the autoencoder loss with the sliced-Wasserstein
distance between the distribution of the encoded training samples and a
predefined samplable distribution. We show that the proposed formulation has an
efficient numerical solution that provides similar capabilities to Wasserstein
Autoencoders (WAE) and Variational Autoencoders (VAE), while benefiting from an
embarrassingly simple implementation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kolouri_S/0/1/0/all/0/1&quot;&gt;Soheil Kolouri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pope_P/0/1/0/all/0/1&quot;&gt;Phillip E. Pope&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Martin_C/0/1/0/all/0/1&quot;&gt;Charles E. Martin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rohde_G/0/1/0/all/0/1&quot;&gt;Gustavo K. Rohde&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09039">
<title>Amortized Context Vector Inference for Sequence-to-Sequence Networks. (arXiv:1805.09039v5 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.09039</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural attention (NA) is an effective mechanism for inferring complex
structural data dependencies that span long temporal horizons. As a
consequence, it has become a key component of sequence-to-sequence models that
yield state-of-the-art performance in as hard tasks as abstractive document
summarization (ADS), machine translation (MT), and video captioning (VC). NA
mechanisms perform inference of context vectors; these constitute weighted sums
of deterministic input sequence encodings, adaptively sourced over long
temporal horizons. However, recent work in the field of amortized variational
inference (AVI) has shown that it is often useful to treat the representations
generated by deep networks as latent random variables. This allows for the
models to better explore the space of possible representations. Based on this
motivation, in this work we introduce a novel regard towards a popular NA
mechanism, namely soft-attention (SA). Our approach treats the context vectors
generated by SA models as latent variables, the posteriors of which are
inferred by employing AVI. Both the means and the covariance matrices of the
inferred posteriors are parameterized via deep network mechanisms similar to
those employed in the context of standard SA. To illustrate our method, we
implement it in the context of popular sequence-to-sequence model variants with
SA. We conduct an extensive experimental evaluation using challenging ADS, VC,
and MT benchmarks, and show how our approach compares to the baselines.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chatzis_S/0/1/0/all/0/1&quot;&gt;Sotirios Chatzis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Charalampous_A/0/1/0/all/0/1&quot;&gt;Aristotelis Charalampous&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tolias_K/0/1/0/all/0/1&quot;&gt;Kyriacos Tolias&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vassou_S/0/1/0/all/0/1&quot;&gt;Sotiris A. Vassou&lt;/a&gt;</dc:creator>
</item></rdf:RDF>