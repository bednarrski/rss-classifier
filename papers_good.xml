<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Good papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Good Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-07-05T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.03039"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.00930"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.01736"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.01747"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.01763"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.01798"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.01830"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.01909"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.01960"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.01972"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.02072"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.12487"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.08915"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.00366"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.00734"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.01270"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.01705"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.01784"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.01846"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.01961"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.01985"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.04159"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04418"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.09856"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.01619"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1802.03039">
<title>Few-shot learning of neural networks from scratch by pseudo example optimization. (arXiv:1802.03039v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1802.03039</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we propose a simple but effective method for training neural
networks with a limited amount of training data. Our approach inherits the idea
of knowledge distillation that transfers knowledge from a deep or wide
reference model to a shallow or narrow target model. The proposed method
employs this idea to mimic predictions of reference estimators that are more
robust against overfitting than the network we want to train. Different from
almost all the previous work for knowledge distillation that requires a large
amount of labeled training data, the proposed method requires only a small
amount of training data. Instead, we introduce pseudo training examples that
are optimized as a part of model parameters. Experimental results for several
benchmark datasets demonstrate that the proposed method outperformed all the
other baselines, such as naive training of the target model and standard
knowledge distillation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kimura_A/0/1/0/all/0/1&quot;&gt;Akisato Kimura&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ghahramani_Z/0/1/0/all/0/1&quot;&gt;Zoubin Ghahramani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Takeuchi_K/0/1/0/all/0/1&quot;&gt;Koh Takeuchi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Iwata_T/0/1/0/all/0/1&quot;&gt;Tomoharu Iwata&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ueda_N/0/1/0/all/0/1&quot;&gt;Naonori Ueda&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.00930">
<title>Neural Random Projections for Language Modelling. (arXiv:1807.00930v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1807.00930</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural network-based language models deal with data sparsity problems by
mapping the large discrete space of words into a smaller continuous space of
real-valued vectors. By learning distributed vector representations for words,
each training sample informs the neural network model about a combinatorial
number of other patterns. We exploit the sparsity in natural language even
further by encoding each unique input word using a reduced sparse random
representation. In this paper, we propose an encoder for discrete inputs that
uses random projections to allow for the learning of language models using
significantly smaller parameter spaces when compared with similar neural
network architectures. Furthermore, random projections also eliminate the
dependency between a neural network architecture and the size of a
pre-established dictionary. We investigate the properties of our encoding
mechanism empirically, by evaluating its performance on the widely used Penn
Treebank corpus, using several configurations of baseline feedforward neural
network models. We show that guaranteeing approximately equidistant inner
products between representations of unique discrete inputs is enough to provide
the neural network model with enough information to learn useful distributed
representations for these inputs. By not requiring prior enumeration of the
lexicon, random projections allow us to face the dynamic and open character of
natural languages.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nunes_D/0/1/0/all/0/1&quot;&gt;Davide Nunes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Antunes_L/0/1/0/all/0/1&quot;&gt;Luis Antunes&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.01736">
<title>Transfer with Model Features in Reinforcement Learning. (arXiv:1807.01736v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.01736</link>
<description rdf:parseType="Literal">&lt;p&gt;A key question in Reinforcement Learning is which representation an agent can
learn to efficiently reuse knowledge between different tasks. Recently the
Successor Representation was shown to have empirical benefits for transferring
knowledge between tasks with shared transition dynamics. This paper presents
Model Features: a feature representation that clusters behaviourally equivalent
states and that is equivalent to a Model-Reduction. Further, we present a
Successor Feature model which shows that learning Successor Features is
equivalent to learning a Model-Reduction. A novel optimization objective is
developed and we provide bounds showing that minimizing this objective results
in an increasingly improved approximation of a Model-Reduction. Further, we
provide transfer experiments on randomly generated MDPs which vary in their
transition and reward functions but approximately preserve behavioural
equivalence between states. These results demonstrate that Model Features are
suitable for transfer between tasks with varying transition and reward
functions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lehnert_L/0/1/0/all/0/1&quot;&gt;Lucas Lehnert&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Littman_M/0/1/0/all/0/1&quot;&gt;Michael L. Littman&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.01747">
<title>Shannon entropy for intuitionistic fuzzy information. (arXiv:1807.01747v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1807.01747</link>
<description rdf:parseType="Literal">&lt;p&gt;The paper presents an extension of Shannon fuzzy entropy for intuitionistic
fuzzy one. Firstly, we presented a new formula for calculating the distance and
similarity of intuitionistic fuzzy information. Then, we constructed measures
for information features like score, certainty and uncertainty. Also, a new
concept was introduced, namely escort fuzzy information. Then, using the escort
fuzzy information, Shannon&apos;s formula for intuitionistic fuzzy information was
obtained. It should be underlined that Shannon&apos;s entropy for intuitionistic
fuzzy information verifies the four defining conditions of intuitionistic fuzzy
uncertainty. The measures of its two components were also identified: fuzziness
(ambiguity) and incompleteness (ignorance).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Patrascu_V/0/1/0/all/0/1&quot;&gt;Vasile Patrascu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.01763">
<title>Seq2RDF: An end-to-end application for deriving Triples from Natural Language Text. (arXiv:1807.01763v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1807.01763</link>
<description rdf:parseType="Literal">&lt;p&gt;We present an end-to-end approach that takes unstructured textual input and
generates structured output compliant with a given vocabulary. Inspired by
recent successes in neural machine translation, we treat the triples within a
given knowledge graph as an independent graph language and propose an
encoder-decoder framework with an attention mechanism that leverages knowledge
graph embeddings. Our model learns the mapping from natural language text to
triple representation in the form of subject-predicate-object using the
selected knowledge graph vocabulary. Experiments on three different data sets
show that we achieve competitive F1-Measures over the baselines using our
simple yet effective approach. A demo video is included.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yue Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1&quot;&gt;Tongtao Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_Z/0/1/0/all/0/1&quot;&gt;Zhicheng Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ji_H/0/1/0/all/0/1&quot;&gt;Heng Ji&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+McGuinness_D/0/1/0/all/0/1&quot;&gt;Deborah L. McGuinness&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.01798">
<title>Regularizing Autoencoder-Based Matrix Completion Models via Manifold Learning. (arXiv:1807.01798v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.01798</link>
<description rdf:parseType="Literal">&lt;p&gt;Autoencoders are popular among neural-network-based matrix completion models
due to their ability to retrieve potential latent factors from the partially
observed matrices. Nevertheless, when training data is scarce their performance
is significantly degraded due to overfitting. In this paper, we mit- igate
overfitting with a data-dependent regularization technique that relies on the
principles of multi-task learning. Specifically, we propose an
autoencoder-based matrix completion model that performs prediction of the
unknown matrix values as a main task, and manifold learning as an auxiliary
task. The latter acts as an inductive bias, leading to solutions that
generalize better. The proposed model outperforms the existing
autoencoder-based models designed for matrix completion, achieving high
reconstruction accuracy in well-known datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_D/0/1/0/all/0/1&quot;&gt;Duc Minh Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tsiligianni_E/0/1/0/all/0/1&quot;&gt;Evaggelia Tsiligianni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Calderbank_R/0/1/0/all/0/1&quot;&gt;Robert Calderbank&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deligiannis_N/0/1/0/all/0/1&quot;&gt;Nikos Deligiannis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.01830">
<title>Per-decision Multi-step Temporal Difference Learning with Control Variates. (arXiv:1807.01830v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.01830</link>
<description rdf:parseType="Literal">&lt;p&gt;Multi-step temporal difference (TD) learning is an important approach in
reinforcement learning, as it unifies one-step TD learning with Monte Carlo
methods in a way where intermediate algorithms can outperform either extreme.
They address a bias-variance trade off between reliance on current estimates,
which could be poor, and incorporating longer sampled reward sequences into the
updates. Especially in the off-policy setting, where the agent aims to learn
about a policy different from the one generating its behaviour, the variance in
the updates can cause learning to diverge as the number of sampled rewards used
in the estimates increases. In this paper, we introduce per-decision control
variates for multi-step TD algorithms, and compare them to existing methods.
Our results show that including the control variates can greatly improve
performance on both on and off-policy multi-step temporal difference learning
tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Asis_K/0/1/0/all/0/1&quot;&gt;Kristopher De Asis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sutton_R/0/1/0/all/0/1&quot;&gt;Richard S. Sutton&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.01909">
<title>Multi-robot Path Planning in Well-formed Infrastructures: Prioritized Planning vs. Prioritized Wait Adjustment (Preliminary Results). (arXiv:1807.01909v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1807.01909</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the problem of planning collision-free paths for a group of
homogeneous robots. We propose a novel approach for turning the paths that were
planned egocentrically by the robots, e.g. without taking other robots&apos; moves
into account, into collision-free trajectories and evaluate it empirically.
Suggested algorithm is much faster (up to one order of magnitude) than
state-of-the-art but this comes at the price of notable drop-down of the
solution cost.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Andreychuk_A/0/1/0/all/0/1&quot;&gt;Anton Andreychuk&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yakovlev_K/0/1/0/all/0/1&quot;&gt;Konstantin Yakovlev&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.01960">
<title>Deep Reinforcement Learning for Doom using Unsupervised Auxiliary Tasks. (arXiv:1807.01960v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.01960</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent developments in deep reinforcement learning have enabled the creation
of agents for solving a large variety of games given a visual input. These
methods have been proven successful for 2D games, like the Atari games, or for
simple tasks, like navigating in mazes. It is still an open question, how to
address more complex environments, in which the reward is sparse and the state
space is huge. In this paper we propose a divide and conquer deep reinforcement
learning solution and we test our agent in the first person shooter (FPS) game
of Doom. Our work is based on previous works in deep reinforcement learning and
in Doom agents. We also present how our agent is able to perform better in
unknown environments compared to a state of the art reinforcement learning
algorithm.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Papoudakis_G/0/1/0/all/0/1&quot;&gt;Georgios Papoudakis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chatzidimitriou_K/0/1/0/all/0/1&quot;&gt;Kyriakos C. Chatzidimitriou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mitkas_P/0/1/0/all/0/1&quot;&gt;Pericles A. Mitkas&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.01972">
<title>Beef Cattle Instance Segmentation Using Fully Convolutional Neural Network. (arXiv:1807.01972v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1807.01972</link>
<description rdf:parseType="Literal">&lt;p&gt;We present an instance segmentation algorithm trained and applied to a CCTV
recording of beef cattle during a winter finishing period. A fully
convolutional network was transformed into an instance segmentation network
that learns to label each instance of an animal separately. We introduce a
conceptually simple framework that the network uses to output a single
prediction for every animal. These results are a contribution towards behaviour
analysis in winter finishing beef cattle for early detection of animal
welfare-related problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ter_Sarkisov_A/0/1/0/all/0/1&quot;&gt;Aram Ter-Sarkisov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ross_R/0/1/0/all/0/1&quot;&gt;Robert Ross&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kelleher_J/0/1/0/all/0/1&quot;&gt;John Kelleher&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Earley_B/0/1/0/all/0/1&quot;&gt;Bernadette Earley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Keane_M/0/1/0/all/0/1&quot;&gt;Michael Keane&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.02072">
<title>Representing scenarios for process evolution management. (arXiv:1807.02072v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1807.02072</link>
<description rdf:parseType="Literal">&lt;p&gt;In the following writing we discuss a conceptual framework for representing
events and scenarios from the perspective of a novel form of causal analysis.
This causal analysis is applied to the events and scenarios so as to determine
measures that could be used to manage the development of the processes that
they are a part of in real time. An overall terminological framework and
entity-relationship model are suggested along with a specification of the
functional sets involved in both reasoning and analytics. The model is
considered to be a specific case of the generic problem of finding sequential
series in disparate data. The specific inference and reasoning processes are
identified for future implementation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kolonin_A/0/1/0/all/0/1&quot;&gt;Anton Kolonin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.12487">
<title>Sequential Attacks on Agents for Long-Term Adversarial Goals. (arXiv:1805.12487v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.12487</link>
<description rdf:parseType="Literal">&lt;p&gt;Reinforcement learning (RL) has advanced greatly in the past few years with
the employment of effective deep neural networks (DNNs) on the policy networks.
With the great effectiveness came serious vulnerability issues with DNNs that
small adversarial perturbations on the input can change the output of the
network. Several works have pointed out that learned agents with a DNN policy
network can be manipulated against achieving the original task through a
sequence of small perturbations on the input states. In this paper, we
demonstrate furthermore that it is also possible to impose an arbitrary
adversarial reward on the victim policy network through a sequence of attacks.
Our method involves the latest adversarial attack technique, Adversarial
Transformer Network (ATN), that learns to generate the attack and is easy to
integrate into the policy network. As a result of our attack, the victim agent
is misguided to optimise for the adversarial reward over time. Our results
expose serious security threats for RL applications in safety-critical systems
including drones, medical analysis, and self-driving cars.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tretschk_E/0/1/0/all/0/1&quot;&gt;Edgar Tretschk&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oh_S/0/1/0/all/0/1&quot;&gt;Seong Joon Oh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fritz_M/0/1/0/all/0/1&quot;&gt;Mario Fritz&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.08915">
<title>DALEX: explainers for complex predictive models. (arXiv:1806.08915v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1806.08915</link>
<description rdf:parseType="Literal">&lt;p&gt;Predictive modeling is invaded by elastic, yet complex methods such as neural
networks or ensembles (model stacking, boosting or bagging). Such methods are
usually described by a large number of parameters or hyper parameters - a price
that one needs to pay for elasticity. The very number of parameters makes
models hard to understand. This paper describes a consistent collection of
explainers for predictive models, a.k.a. black boxes. Each explainer is a
technique for exploration of a black box model. Presented approaches are
model-agnostic, what means that they extract useful information from any
predictive method despite its internal structure. Each explainer is linked with
a specific aspect of a model. Some are useful in decomposing predictions, some
serve better in understanding performance, while others are useful in
understanding importance and conditional responses of a particular variable.
Every explainer presented in this paper works for a single model or for a
collection of models. In the latter case, models can be compared against each
other. Such comparison helps to find strengths and weaknesses of different
approaches and gives additional possibilities for model validation. Presented
explainers are implemented in the DALEX package for R. They are based on a
uniform standardized grammar of model exploration which may be easily extended.
The current implementation supports the most popular frameworks for
classification and regression.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Biecek_P/0/1/0/all/0/1&quot;&gt;Przemyslaw Biecek&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.00366">
<title>Beyond Winning and Losing: Modeling Human Motivations and Behaviors Using Inverse Reinforcement Learning. (arXiv:1807.00366v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1807.00366</link>
<description rdf:parseType="Literal">&lt;p&gt;In recent years, reinforcement learning (RL) methods have been applied to
model gameplay with great success, achieving super-human performance in various
environments, such as Atari, Go, and Poker. However, those studies mostly focus
on winning the game and have largely ignored the rich and complex human
motivations, which are essential for understanding different players&apos; diverse
behaviors. In this paper, we present a novel method called Multi-Motivation
Behavior Modeling (MMBM) that takes the multifaceted human motivations into
consideration and models the underlying value structure of the players using
inverse RL. Our approach does not require the access to the dynamic of the
system, making it feasible to model complex interactive environments such as
massively multiplayer online games. MMBM is tested on the World of Warcraft
Avatar History dataset, which recorded over 70,000 users&apos; gameplay spanning
three years period. Our model reveals the significant difference of value
structures among different player groups. Using the results of motivation
modeling, we also predict and explain their diverse gameplay behaviors and
provide a quantitative assessment of how the redesign of the game environment
impacts players&apos; behaviors.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1&quot;&gt;Baoxiang Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_T/0/1/0/all/0/1&quot;&gt;Tongfang Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_X/0/1/0/all/0/1&quot;&gt;Xianjun Sam Zheng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.00734">
<title>The relativistic discriminator: a key element missing from standard GAN. (arXiv:1807.00734v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1807.00734</link>
<description rdf:parseType="Literal">&lt;p&gt;In standard generative adversarial network (SGAN), the discriminator
estimates the probability that the input data is real. The generator is trained
to increase the probability that fake data is real. We argue that it should
also simultaneously decrease the probability that real data is real because 1)
this would account for a priori knowledge that half of the data in the
mini-batch is fake, 2) this would be observed with divergence minimization, and
3) in optimal settings, SGAN would be equivalent to integral probability metric
(IPM) GANs.
&lt;/p&gt;
&lt;p&gt;We show that this property can be induced by using a relativistic
discriminator which estimate the probability that the given real data is more
realistic than a randomly sampled fake data. We also present a variant in which
the discriminator estimate the probability that the given real data is more
realistic than fake data, on average. We generalize both approaches to
non-standard GAN loss functions and we refer to them respectively as
Relativistic GANs (RGANs) and Relativistic average GANs (RaGANs). We show that
IPM-based GANs are a subset of RGANs which use the identity function.
&lt;/p&gt;
&lt;p&gt;Empirically, we observe that 1) RGANs and RaGANs are significantly more
stable and generate higher quality data samples than their non-relativistic
counterparts, 2) Standard RaGAN with gradient penalty generate data of better
quality than WGAN-GP while only requiring a single discriminator update per
generator update (reducing the time taken for reaching the state-of-the-art by
400%), and 3) RaGANs are able to generate plausible high resolutions images
(256x256) from a very small sample (N=2011), while GAN and LSGAN cannot; these
images are of significantly better quality than the ones generated by WGAN-GP
and SGAN with spectral normalization.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jolicoeur_Martineau_A/0/1/0/all/0/1&quot;&gt;Alexia Jolicoeur-Martineau&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.01270">
<title>Reaching Human-level Performance in Automatic Grammatical Error Correction: An Empirical Study. (arXiv:1807.01270v3 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1807.01270</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural sequence-to-sequence (seq2seq) approaches have proven to be successful
in grammatical error correction (GEC). Based on the seq2seq framework, we
propose a novel fluency boost learning and inference mechanism. Fluency
boosting learning generates diverse error-corrected sentence pairs during
training, enabling the error correction model to learn how to improve a
sentence&apos;s fluency from more instances, while fluency boosting inference allows
the model to correct a sentence incrementally with multiple inference steps.
Combining fluency boost learning and inference with convolutional seq2seq
models, our approach achieves the state-of-the-art performance: 75.72 (F_{0.5})
on CoNLL-2014 10 annotation dataset and 62.42 (GLEU) on JFLEG test set
respectively, becoming the first GEC system that reaches human-level
performance (72.58 for CoNLL and 62.37 for JFLEG) on both of the benchmarks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ge_T/0/1/0/all/0/1&quot;&gt;Tao Ge&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1&quot;&gt;Furu Wei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1&quot;&gt;Ming Zhou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.01705">
<title>Transfer Learning for Clinical Time Series Analysis using Recurrent Neural Networks. (arXiv:1807.01705v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.01705</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep neural networks have shown promising results for various clinical
prediction tasks such as diagnosis, mortality prediction, predicting duration
of stay in hospital, etc. However, training deep networks -- such as those
based on Recurrent Neural Networks (RNNs) -- requires large labeled data, high
computational resources, and significant hyperparameter tuning effort. In this
work, we investigate as to what extent can transfer learning address these
issues when using deep RNNs to model multivariate clinical time series. We
consider transferring the knowledge captured in an RNN trained on several
source tasks simultaneously using a large labeled dataset to build the model
for a target task with limited labeled data. An RNN pre-trained on several
tasks provides generic features, which are then used to build simpler linear
models for new target tasks without training task-specific RNNs. For
evaluation, we train a deep RNN to identify several patient phenotypes on time
series from MIMIC-III database, and then use the features extracted using that
RNN to build classifiers for identifying previously unseen phenotypes, and also
for a seemingly unrelated task of in-hospital mortality. We demonstrate that
(i) models trained on features extracted using pre-trained RNN outperform or,
in the worst case, perform as well as task-specific RNNs; (ii) the models using
features from pre-trained models are more robust to the size of labeled data
than task-specific RNNs; and (iii) features extracted using pre-trained RNN are
generic enough and perform better than typical statistical hand-crafted
features.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gupta_P/0/1/0/all/0/1&quot;&gt;Priyanka Gupta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Malhotra_P/0/1/0/all/0/1&quot;&gt;Pankaj Malhotra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vig_L/0/1/0/all/0/1&quot;&gt;Lovekesh Vig&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shroff_G/0/1/0/all/0/1&quot;&gt;Gautam Shroff&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.01784">
<title>Program Language Translation Using a Grammar-Driven Tree-to-Tree Model. (arXiv:1807.01784v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.01784</link>
<description rdf:parseType="Literal">&lt;p&gt;The task of translating between programming languages differs from the
challenge of translating natural languages in that programming languages are
designed with a far more rigid set of structural and grammatical rules.
Previous work has used a tree-to-tree encoder/decoder model to take advantage
of the inherent tree structure of programs during translation. Neural decoders,
however, by default do not exploit known grammar rules of the target language.
In this paper, we describe a tree decoder that leverages knowledge of a
language&apos;s grammar rules to exclusively generate syntactically correct
programs. We find that this grammar-based tree-to-tree model outperforms the
state of the art tree-to-tree model in translating between two programming
languages on a previously used synthetic task.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Drissi_M/0/1/0/all/0/1&quot;&gt;Mehdi Drissi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Watkins_O/0/1/0/all/0/1&quot;&gt;Olivia Watkins&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khant_A/0/1/0/all/0/1&quot;&gt;Aditya Khant&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ojha_V/0/1/0/all/0/1&quot;&gt;Vivaswat Ojha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sandoval_P/0/1/0/all/0/1&quot;&gt;Pedro Sandoval&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Segev_R/0/1/0/all/0/1&quot;&gt;Rakia Segev&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Weiner_E/0/1/0/all/0/1&quot;&gt;Eric Weiner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Keller_R/0/1/0/all/0/1&quot;&gt;Robert Keller&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.01846">
<title>Logistic Regression, Neural Networks and Dempster-Shafer Theory: a New Perspective. (arXiv:1807.01846v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.01846</link>
<description rdf:parseType="Literal">&lt;p&gt;We revisit logistic regression and its nonlinear extensions, including
multilayer feedforward neural networks, by showing that these classifiers can
be viewed as converting input or higher-level features into Dempster-Shafer
mass functions and aggregating them by Dempster&apos;s rule of combination. The
probabilistic outputs of these classifiers are the normalized plausibilities
corresponding to the underlying combined mass function. This mass function is
more informative than the output probability distribution. In particular, it
makes it possible to distinguish between lack of evidence (when none of the
features provides discriminant information) from conflicting evidence (when
different features support different classes). This expressivity of mass
functions allows us to gain insight into the role played by each input feature
in logistic regression, and to interpret hidden unit outputs in multilayer
neural networks. It also makes it possible to use alternative decision rules,
such as interval dominance, which select a set of classes when the available
evidence does not unambiguously point to a single class, thus trading reduced
error rate for higher imprecision.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Denoeux_T/0/1/0/all/0/1&quot;&gt;Thierry Denoeux&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.01961">
<title>A Boo(n) for Evaluating Architecture Performance. (arXiv:1807.01961v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.01961</link>
<description rdf:parseType="Literal">&lt;p&gt;We point out important problems with the common practice of using the best
single model performance for comparing deep learning architectures, and we
propose a method that corrects these flaws. Each time a model is trained, one
gets a different result due to random factors in the training process, which
include random parameter initialization and random data shuffling. Reporting
the best single model performance does not appropriately address this
stochasticity. We propose a normalized expected best-out-of-$n$ performance
($\text{Boo}_n$) as a way to correct these problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bajgar_O/0/1/0/all/0/1&quot;&gt;Ondrej Bajgar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kadlec_R/0/1/0/all/0/1&quot;&gt;Rudolf Kadlec&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kleindienst_J/0/1/0/all/0/1&quot;&gt;Jan Kleindienst&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.01985">
<title>BayesGrad: Explaining Predictions of Graph Convolutional Networks. (arXiv:1807.01985v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.01985</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent advances in graph convolutional networks have significantly improved
the performance of chemical predictions, raising a new research question: &quot;how
do we explain the predictions of graph convolutional networks?&quot; A possible
approach to answer this question is to visualize evidence substructures
responsible for the predictions. For chemical property prediction tasks, the
sample size of the training data is often small and/or a label imbalance
problem occurs, where a few samples belong to a single class and the majority
of samples belong to the other classes. This can lead to uncertainty related to
the learned parameters of the machine learning model. To address this
uncertainty, we propose BayesGrad, utilizing the Bayesian predictive
distribution, to define the importance of each node in an input graph, which is
computed efficiently using the dropout technique. We demonstrate that BayesGrad
successfully visualizes the substructures responsible for the label prediction
in the artificial experiment, even when the sample size is small. Furthermore,
we use a real dataset to evaluate the effectiveness of the visualization. The
basic idea of BayesGrad is not limited to graph-structured data and can be
applied to other data types.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Akita_H/0/1/0/all/0/1&quot;&gt;Hirotaka Akita&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nakago_K/0/1/0/all/0/1&quot;&gt;Kosuke Nakago&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Komatsu_T/0/1/0/all/0/1&quot;&gt;Tomoki Komatsu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sugawara_Y/0/1/0/all/0/1&quot;&gt;Yohei Sugawara&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Maeda_S/0/1/0/all/0/1&quot;&gt;Shin-ichi Maeda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Baba_Y/0/1/0/all/0/1&quot;&gt;Yukino Baba&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kashima_H/0/1/0/all/0/1&quot;&gt;Hisashi Kashima&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.04159">
<title>Can Who-Edits-What Predict Edit Survival?. (arXiv:1801.04159v2 [stat.AP] UPDATED)</title>
<link>http://arxiv.org/abs/1801.04159</link>
<description rdf:parseType="Literal">&lt;p&gt;As the number of contributors to online peer-production systems grows, it
becomes increasingly important to predict whether the edits that users make
will eventually be beneficial to the project. Existing solutions either rely on
a user reputation system or consist of a highly specialized predictor that is
tailored to a specific peer-production system. In this work, we explore a
different point in the solution space that goes beyond user reputation but does
not involve any content-based feature of the edits. We view each edit as a game
between the editor and the component of the project. We posit that the
probability that an edit is accepted is a function of the editor&apos;s skill, of
the difficulty of editing the component and of a user-component interaction
term. Our model is broadly applicable, as it only requires observing data about
who makes an edit, what the edit affects and whether the edit survives or not.
We apply our model on Wikipedia and the Linux kernel, two examples of
large-scale peer-production systems, and we seek to understand whether it can
effectively predict edit survival: in both cases, we provide a positive answer.
Our approach significantly outperforms those based solely on user reputation
and bridges the gap with specialized predictors that use content-based
features. It is simple to implement, computationally inexpensive, and in
addition it enables us to discover interesting structure in the data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yardim_A/0/1/0/all/0/1&quot;&gt;Ali Batuhan Yard&amp;#x131;m&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kristof_V/0/1/0/all/0/1&quot;&gt;Victor Kristof&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Maystre_L/0/1/0/all/0/1&quot;&gt;Lucas Maystre&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Grossglauser_M/0/1/0/all/0/1&quot;&gt;Matthias Grossglauser&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04418">
<title>Quaternion Recurrent Neural Networks. (arXiv:1806.04418v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1806.04418</link>
<description rdf:parseType="Literal">&lt;p&gt;Recurrent neural networks (RNNs) are powerful architectures to model
sequential data, due to their capability to learn short and long-term
dependencies between the basic elements of a sequence. Nonetheless, popular
tasks such as speech or images recognition, involve multi-dimensional input
features that are characterized by strong internal dependencies between the
dimensions of the input vector. We propose a novel quaternion recurrent neural
network (QRNN) that takes into account both the external relations and these
internal structural dependencies with the quaternion algebra. Similarly to
capsules, quaternions allow the QRNN to code internal dependencies by composing
and processing multidimensional features as single entities, while the
recurrent operation reveals correlations between the elements composing the
sequence. We show that the QRNN achieves better performances in both a
synthetic memory copy task and in realistic applications of automatic speech
recognition. Finally, we show that the QRNN reduces by a factor of 3x the
number of free parameters needed, compared to RNNs to reach better results,
leading to a more compact representation of the relevant information.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Parcollet_T/0/1/0/all/0/1&quot;&gt;Titouan Parcollet&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ravanelli_M/0/1/0/all/0/1&quot;&gt;Mirco Ravanelli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Morchid_M/0/1/0/all/0/1&quot;&gt;Mohamed Morchid&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Linares_G/0/1/0/all/0/1&quot;&gt;Georges Linar&amp;#xe8;s&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Trabelsi_C/0/1/0/all/0/1&quot;&gt;Chiheb Trabelsi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mori_R/0/1/0/all/0/1&quot;&gt;Renato De Mori&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bengio_Y/0/1/0/all/0/1&quot;&gt;Yoshua Bengio&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.09856">
<title>Dropout-based Active Learning for Regression. (arXiv:1806.09856v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1806.09856</link>
<description rdf:parseType="Literal">&lt;p&gt;Active learning is relevant and challenging for high-dimensional regression
models when the annotation of the samples is expensive. Yet most of the
existing sampling methods cannot be applied to large-scale problems, consuming
too much time for data processing. In this paper, we propose a fast active
learning algorithm for regression, tailored for neural network models. It is
based on uncertainty estimation from stochastic dropout output of the network.
Experiments on both synthetic and real-world datasets show comparable or better
performance (depending on the accuracy metric) as compared to the baselines.
This approach can be generalized to other deep learning architectures. It can
be used to systematically improve a machine-learning model as it offers a
computationally efficient way of sampling additional data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tsymbalov_E/0/1/0/all/0/1&quot;&gt;Evgenii Tsymbalov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Panov_M/0/1/0/all/0/1&quot;&gt;Maxim Panov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shapeev_A/0/1/0/all/0/1&quot;&gt;Alexander Shapeev&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.01619">
<title>Ensemble learning with Conformal Predictors: Targeting credible predictions of conversion from Mild Cognitive Impairment to Alzheimer&apos;s Disease. (arXiv:1807.01619v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1807.01619</link>
<description rdf:parseType="Literal">&lt;p&gt;Most machine learning classifiers give predictions for new examples
accurately, yet without indicating how trustworthy predictions are. In the
medical domain, this hampers their integration in decision support systems,
which could be useful in the clinical practice. We use a supervised learning
approach that combines Ensemble learning with Conformal Predictors to predict
conversion from Mild Cognitive Impairment to Alzheimer&apos;s Disease. Our goal is
to enhance the classification performance (Ensemble learning) and complement
each prediction with a measure of credibility (Conformal Predictors). Our
results showed the superiority of the proposed approach over a similar ensemble
framework with standard classifiers.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pereira_T/0/1/0/all/0/1&quot;&gt;Telma Pereira&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cardoso_S/0/1/0/all/0/1&quot;&gt;Sandra Cardoso&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Silva_D/0/1/0/all/0/1&quot;&gt;Dina Silva&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guerreiro_M/0/1/0/all/0/1&quot;&gt;Manuela Guerreiro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mendonca_A/0/1/0/all/0/1&quot;&gt;Alexandre de Mendon&amp;#xe7;a&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Madeira_S/0/1/0/all/0/1&quot;&gt;Sara C. Madeira&lt;/a&gt;</dc:creator>
</item></rdf:RDF>