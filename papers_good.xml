<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Good papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Good Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-08-26T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.08121"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.08173"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.03963"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.08003"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.08079"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.08213"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.06511"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.07910"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.07945"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.07982"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.07997"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.08013"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.08023"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.08095"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.08097"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.08111"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.08149"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.05760"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.07632"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1808.08121">
<title>An Improvement of Data Classification Using Random Multimodel Deep Learning (RMDL). (arXiv:1808.08121v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1808.08121</link>
<description rdf:parseType="Literal">&lt;p&gt;The exponential growth in the number of complex datasets every year requires
more enhancement in machine learning methods to provide robust and accurate
data classification. Lately, deep learning approaches have achieved surpassing
results in comparison to previous machine learning algorithms. However, finding
the suitable structure for these models has been a challenge for researchers.
This paper introduces Random Multimodel Deep Learning (RMDL): a new ensemble,
deep learning approach for classification. RMDL solves the problem of finding
the best deep learning structure and architecture while simultaneously
improving robustness and accuracy through ensembles of deep learning
architectures. In short, RMDL trains multiple randomly generated models of Deep
Neural Network (DNN), Convolutional Neural Network (CNN) and Recurrent Neural
Network (RNN) in parallel and combines their results to produce better result
of any of those models individually. In this paper, we describe RMDL model and
compare the results for image and text classification as well as face
recognition. We used MNIST and CIFAR-10 datasets as ground truth datasets for
image classification and WOS, Reuters, IMDB, and 20newsgroup datasets for text
classification. Lastly, we used ORL dataset to compare the model performance on
face recognition task.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Heidarysafa_M/0/1/0/all/0/1&quot;&gt;Mojtaba Heidarysafa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kowsari_K/0/1/0/all/0/1&quot;&gt;Kamran Kowsari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brown_D/0/1/0/all/0/1&quot;&gt;Donald E. Brown&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meimandi_K/0/1/0/all/0/1&quot;&gt;Kiana Jafari Meimandi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barnes_L/0/1/0/all/0/1&quot;&gt;Laura E. Barnes&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.08173">
<title>STDP Learning of Image Patches with Convolutional Spiking Neural Networks. (arXiv:1808.08173v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1808.08173</link>
<description rdf:parseType="Literal">&lt;p&gt;Spiking neural networks are motivated from principles of neural systems and
may possess unexplored advantages in the context of machine learning. A class
of \textit{convolutional spiking neural networks} is introduced, trained to
detect image features with an unsupervised, competitive learning mechanism.
Image features can be shared within subpopulations of neurons, or each may
evolve independently to capture different features in different regions of
input space. We analyze the time and memory requirements of learning with and
operating such networks. The MNIST dataset is used as an experimental testbed,
and comparisons are made between the performance and convergence speed of a
baseline spiking neural network.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saunders_D/0/1/0/all/0/1&quot;&gt;Daniel J. Saunders&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Siegelmann_H/0/1/0/all/0/1&quot;&gt;Hava T. Siegelmann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kozma_R/0/1/0/all/0/1&quot;&gt;Robert Kozma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ruszinko_M/0/1/0/all/0/1&quot;&gt;Mikl&amp;#xf3;s Ruszink&amp;#xf3;&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.03963">
<title>Monotone Learning with Rectified Wire Networks. (arXiv:1805.03963v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.03963</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce a new neural network model, together with a tractable and
monotone online learning algorithm. Our model describes feed-forward networks
for classification, with one output node for each class. The only nonlinear
operation is rectification using a ReLU function with a bias. However, there is
a rectifier on every edge rather than at the nodes of the network. There are
also weights, but these are positive, static, and associated with the nodes.
Our &quot;rectified wire&quot; networks are able to represent arbitrary Boolean
functions. Only the bias parameters, on the edges of the network, are learned.
Another departure in our approach, from standard neural networks, is that the
loss function is replaced by a constraint. This constraint is simply that the
value of the output node associated with the correct class should be zero. Our
model has the property that the exact norm-minimizing parameter update,
required to correctly classify a training item, is the solution to a quadratic
program that can be computed with a few passes through the network. We
demonstrate a training algorithm using this update, called sequential
deactivation (SDA), on MNIST and some synthetic datasets. Upon adopting a
natural choice for the nodal weights, SDA has no hyperparameters other than
those describing the network structure. Our experiments explore behavior with
respect to network size and depth in a family of sparse expander networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Elser_V/0/1/0/all/0/1&quot;&gt;Veit Elser&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schmidt_D/0/1/0/all/0/1&quot;&gt;Dan Schmidt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yedidia_J/0/1/0/all/0/1&quot;&gt;Jonathan Yedidia&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.08003">
<title>Approximate Distribution Matching for Sequence-to-Sequence Learning. (arXiv:1808.08003v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1808.08003</link>
<description rdf:parseType="Literal">&lt;p&gt;Sequence-to-Sequence models were introduced to tackle many real-life problems
like machine translation, summarization, image captioning, etc. The standard
optimization algorithms are mainly based on example-to-example matching like
maximum likelihood estimation, which is known to suffer from data sparsity
problem. Here we present an alternate view to explain sequence-to-sequence
learning as a distribution matching problem, where each source or target
example is viewed to represent a local latent distribution in the source or
target domain. Then, we interpret sequence-to-sequence learning as learning a
transductive model to transform the source local latent distributions to match
their corresponding target distributions. In our framework, we approximate both
the source and target latent distributions with recurrent neural networks
(augmenter). During training, the parallel augmenters learn to better
approximate the local latent distributions, while the sequence prediction model
learns to minimize the KL-divergence of the transformed source distributions
and the approximated target distributions. This algorithm can alleviate the
data sparsity issues in sequence learning by locally augmenting more unseen
data pairs and increasing the model&apos;s robustness. Experiments conducted on
machine translation and image captioning consistently demonstrate the
superiority of our proposed algorithm over the other competing algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1&quot;&gt;Wenhu Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1&quot;&gt;Guanlin Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1&quot;&gt;Shujie Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1&quot;&gt;Zhirui Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1&quot;&gt;Mu Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1&quot;&gt;Ming Zhou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.08079">
<title>Under the Hood: Using Diagnostic Classifiers to Investigate and Improve how Language Models Track Agreement Information. (arXiv:1808.08079v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1808.08079</link>
<description rdf:parseType="Literal">&lt;p&gt;How do neural language models keep track of number agreement between subject
and verb? We show that `diagnostic classifiers&apos;, trained to predict number from
the internal states of a language model, provide a detailed understanding of
how, when, and where this information is represented. Moreover, they give us
insight into when and where number information is corrupted in cases where the
language model ends up making agreement errors. To demonstrate the causal role
played by the representations we find, we then use agreement information to
influence the course of the LSTM during the processing of difficult sentences.
Results from such an intervention reveal a large increase in the language
model&apos;s accuracy. Together, these results show that diagnostic classifiers give
us an unrivalled detailed look into the representation of linguistic
information in neural models, and demonstrate that this knowledge can be used
to improve their performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Giulianelli_M/0/1/0/all/0/1&quot;&gt;Mario Giulianelli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Harding_J/0/1/0/all/0/1&quot;&gt;Jack Harding&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mohnert_F/0/1/0/all/0/1&quot;&gt;Florian Mohnert&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hupkes_D/0/1/0/all/0/1&quot;&gt;Dieuwke Hupkes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zuidema_W/0/1/0/all/0/1&quot;&gt;Willem Zuidema&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.08213">
<title>Future Automation Engineering using Structural Graph Convolutional Neural Networks. (arXiv:1808.08213v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1808.08213</link>
<description rdf:parseType="Literal">&lt;p&gt;The digitalization of automation engineering generates large quantities of
engineering data that is interlinked in knowledge graphs. Classifying and
clustering subgraphs according to their functionality is useful to discover
functionally equivalent engineering artifacts that exhibit different graph
structures. This paper presents a new graph learning algorithm designed to
classify engineering data artifacts -- represented in the form of graphs --
according to their structure and neighborhood features. Our Structural Graph
Convolutional Neural Network (SGCNN) is capable of learning graphs and
subgraphs with a novel graph invariant convolution kernel and
downsampling/pooling algorithm. On a realistic engineering-related dataset, we
show that SGCNN is capable of achieving ~91% classification accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wan_J/0/1/0/all/0/1&quot;&gt;Jiang Wan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pollard_B/0/1/0/all/0/1&quot;&gt;Blake S. Pollard&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chhetri_S/0/1/0/all/0/1&quot;&gt;Sujit Rokka Chhetri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goyal_P/0/1/0/all/0/1&quot;&gt;Palash Goyal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Faruque_M/0/1/0/all/0/1&quot;&gt;Mohammad Abdullah Al Faruque&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Canedo_A/0/1/0/all/0/1&quot;&gt;Arquimedes Canedo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.06511">
<title>State-of-the-art Chinese Word Segmentation with Bi-LSTMs. (arXiv:1808.06511v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1808.06511</link>
<description rdf:parseType="Literal">&lt;p&gt;A wide variety of neural-network architectures have been proposed for the
task of Chinese word segmentation.
&lt;/p&gt;
&lt;p&gt;Surprisingly, we find that a bidirectional LSTM model, when combined with
standard deep learning techniques and best practices, can achieve better
accuracy on many of the popular datasets as compared to models based on more
complex neural-network architectures.
&lt;/p&gt;
&lt;p&gt;Furthermore, our error analysis shows that out-of-vocabulary words remain
challenging for neural-network models, and many of the remaining errors are
unlikely to be fixed through architecture changes.
&lt;/p&gt;
&lt;p&gt;Instead, more effort should be made on exploring resources for further
improvement.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1&quot;&gt;Ji Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ganchev_K/0/1/0/all/0/1&quot;&gt;Kuzman Ganchev&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Weiss_D/0/1/0/all/0/1&quot;&gt;David Weiss&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.07910">
<title>The Importance of Generation Order in Language Modeling. (arXiv:1808.07910v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1808.07910</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural language models are a critical component of state-of-the-art systems
for machine translation, summarization, audio transcription, and other tasks.
These language models are almost universally autoregressive in nature,
generating sentences one token at a time from left to right. This paper studies
the influence of token generation order on model quality via a novel two-pass
language model that produces partially-filled sentence &quot;templates&quot; and then
fills in missing tokens. We compare various strategies for structuring these
two passes and observe a surprisingly large variation in model quality. We find
the most effective strategy generates function words in the first pass followed
by content words in the second. We believe these experimental results justify a
more extensive investigation of generation order for neural language models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ford_N/0/1/0/all/0/1&quot;&gt;Nicolas Ford&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Duckworth_D/0/1/0/all/0/1&quot;&gt;Daniel Duckworth&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Norouzi_M/0/1/0/all/0/1&quot;&gt;Mohammad Norouzi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dahl_G/0/1/0/all/0/1&quot;&gt;George E. Dahl&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.07945">
<title>Maximal Jacobian-based Saliency Map Attack. (arXiv:1808.07945v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1808.07945</link>
<description rdf:parseType="Literal">&lt;p&gt;The Jacobian-based Saliency Map Attack is a family of adversarial attack
methods for fooling classification models, such as deep neural networks for
image classification tasks. By saturating a few pixels in a given image to
their maximum or minimum values, JSMA can cause the model to misclassify the
resulting adversarial image as a specified erroneous target class. We propose
two variants of JSMA, one which removes the requirement to specify a target
class, and another that additionally does not need to specify whether to only
increase or decrease pixel intensities. Our experiments highlight the
competitive speeds and qualities of these variants when applied to datasets of
hand-written digits and natural scenes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wiyatno_R/0/1/0/all/0/1&quot;&gt;Rey Wiyatno&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_A/0/1/0/all/0/1&quot;&gt;Anqi Xu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.07982">
<title>Proximal Policy Optimization and its Dynamic Version for Sequence Generation. (arXiv:1808.07982v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1808.07982</link>
<description rdf:parseType="Literal">&lt;p&gt;In sequence generation task, many works use policy gradient for model
optimization to tackle the intractable backpropagation issue when maximizing
the non-differentiable evaluation metrics or fooling the discriminator in
adversarial learning. In this paper, we replace policy gradient with proximal
policy optimization (PPO), which is a proved more efficient reinforcement
learning algorithm, and propose a dynamic approach for PPO (PPO-dynamic). We
demonstrate the efficacy of PPO and PPO-dynamic on conditional sequence
generation tasks including synthetic experiment and chit-chat chatbot. The
results show that PPO and PPO-dynamic can beat policy gradient by stability and
performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tuan_Y/0/1/0/all/0/1&quot;&gt;Yi-Lin Tuan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Jinzhi Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yujia Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1&quot;&gt;Hung-yi Lee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.07997">
<title>Non-asymptotic bounds for percentiles of independent non-identical random variables. (arXiv:1808.07997v1 [math.ST])</title>
<link>http://arxiv.org/abs/1808.07997</link>
<description rdf:parseType="Literal">&lt;p&gt;This note displays an interesting phenomenon for percentiles of independent
but non-identical random variables. Let $X_1,\cdots,X_n$ be independent random
variables obeying non-identical continuous distributions and $X^{(1)}\geq
\cdots\geq X^{(n)}$ be the corresponding order statistics. For any $p\in(0,1)$,
we investigate the $100(1-p)$%-th percentile $X^{(pn)}$ and prove
non-asymptotic bounds for $X^{(pn)}$. In particular, for a wide class of
distributions, we discover an intriguing connection between their median and
the harmonic mean of the associated standard deviations. For example, if
$X_k\sim\mathcal{N}(0,\sigma_k^2)$ for $k=1,\cdots,n$ and $p=\frac{1}{2}$, we
show that its median $\big|{\rm Med}\big(X_1,\cdots,X_n\big)\big|=
O_P\Big(n^{1/2}\cdot\big(\sum_{k=1}^n\sigma_k^{-1}\big)^{-1}\Big)$ as long as
$\{\sigma_k\}_{k=1}^n$ satisfy certain mild non-dispersion property.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Xia_D/0/1/0/all/0/1&quot;&gt;Dong Xia&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.08013">
<title>Reinforcement Learning for Relation Classification from Noisy Data. (arXiv:1808.08013v1 [cs.IR])</title>
<link>http://arxiv.org/abs/1808.08013</link>
<description rdf:parseType="Literal">&lt;p&gt;Existing relation classification methods that rely on distant supervision
assume that a bag of sentences mentioning an entity pair are all describing a
relation for the entity pair. Such methods, performing classification at the
bag level, cannot identify the mapping between a relation and a sentence, and
largely suffers from the noisy labeling problem. In this paper, we propose a
novel model for relation classification at the sentence level from noisy data.
The model has two modules: an instance selector and a relation classifier. The
instance selector chooses high-quality sentences with reinforcement learning
and feeds the selected sentences into the relation classifier, and the relation
classifier makes sentence level prediction and provides rewards to the instance
selector. The two modules are trained jointly to optimize the instance
selection and relation classification processes. Experiment results show that
our model can deal with the noise of data effectively and obtains better
performance for relation classification at the sentence level.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1&quot;&gt;Jun Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_M/0/1/0/all/0/1&quot;&gt;Minlie Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_L/0/1/0/all/0/1&quot;&gt;Li Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1&quot;&gt;Yang Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1&quot;&gt;Xiaoyan Zhu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.08023">
<title>A Jointly Learned Context-Aware Place of Interest Embedding for Trip Recommendations. (arXiv:1808.08023v1 [cs.IR])</title>
<link>http://arxiv.org/abs/1808.08023</link>
<description rdf:parseType="Literal">&lt;p&gt;Trip recommendation is an important location-based service that helps relieve
users from the time and efforts for trip planning. It aims to recommend a
sequence of places of interest (POIs) for a user to visit that maximizes the
user&apos;s satisfaction. When adding a POI to a recommended trip, it is essential
to understand the context of the recommendation, including the POI popularity,
other POIs co-occurring in the trip, and the preferences of the user. These
contextual factors are learned separately in existing studies, while in
reality, they impact jointly on a user&apos;s choice of a POI to visit. In this
study, we propose a POI embedding model to jointly learn the impact of these
contextual factors. We call the learned POI embedding a context-aware POI
embedding. To showcase the effectiveness of this embedding, we apply it to
generate trip recommendations given a user and a time budget. We propose two
trip recommendation algorithms based on our context-aware POI embedding. The
first algorithm finds the exact optimal trip by transforming and solving the
trip recommendation problem as an integer linear programming problem. To
achieve a high computation efficiency, the second algorithm finds a
heuristically optimal trip based on adaptive large neighborhood search. We
perform extensive experiments on real datasets. The results show that our
proposed algorithms consistently outperform state-of-the-art algorithms in trip
recommendation quality, with an advantage of up to 43% in F1-score.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1&quot;&gt;Jiayuan He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qi_J/0/1/0/all/0/1&quot;&gt;Jianzhong Qi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ramamohanarao_K/0/1/0/all/0/1&quot;&gt;Kotagiri Ramamohanarao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.08095">
<title>Multi-scenario deep learning for multi-speaker source separation. (arXiv:1808.08095v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1808.08095</link>
<description rdf:parseType="Literal">&lt;p&gt;Research in deep learning for multi-speaker source separation has received a
boost in the last years. However, most studies are restricted to mixtures of a
specific number of speakers, called a specific scenario. While some works
included experiments for different scenarios, research towards combining data
of different scenarios or creating a single model for multiple scenarios have
been very rare. In this work it is shown that data of a specific scenario is
relevant for solving another scenario. Furthermore, it is concluded that a
single model, trained on different scenarios is capable of matching performance
of scenario specific models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zegers_J/0/1/0/all/0/1&quot;&gt;Jeroen Zegers&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+hamme_H/0/1/0/all/0/1&quot;&gt;Hugo Van hamme&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.08097">
<title>Memory Time Span in LSTMs for Multi-Speaker Source Separation. (arXiv:1808.08097v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1808.08097</link>
<description rdf:parseType="Literal">&lt;p&gt;With deep learning approaches becoming state-of-the-art in many speech (as
well as non-speech) related machine learning tasks, efforts are being taken to
delve into the neural networks which are often considered as a black box. In
this paper it is analyzed how recurrent neural network (RNNs) cope with
temporal dependencies by determining the relevant memory time span in a long
short-term memory (LSTM) cell. This is done by leaking the state variable with
a controlled lifetime and evaluating the task performance. This technique can
be used for any task to estimate the time span the LSTM exploits in that
specific scenario. The focus in this paper is on the task of separating
speakers from overlapping speech. We discern two effects: A long term effect,
probably due to speaker characterization and a short term effect, probably
exploiting phone-size formant tracks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zegers_J/0/1/0/all/0/1&quot;&gt;Jeroen Zegers&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+hamme_H/0/1/0/all/0/1&quot;&gt;Hugo Van hamme&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.08111">
<title>Multiclass Universum SVM. (arXiv:1808.08111v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1808.08111</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce Universum learning for multiclass problems and propose a novel
formulation for multiclass universum SVM (MU-SVM). We also propose an analytic
span bound for model selection with almost 2-4x faster computation times than
standard resampling techniques. We empirically demonstrate the efficacy of the
proposed MUSVM formulation on several real world datasets achieving &amp;gt; 20%
improvement in test accuracies compared to multi-class SVM.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dhar_S/0/1/0/all/0/1&quot;&gt;Sauptik Dhar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cherkassky_V/0/1/0/all/0/1&quot;&gt;Vladimir Cherkassky&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shah_M/0/1/0/all/0/1&quot;&gt;Mohak Shah&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.08149">
<title>From Random to Supervised: A Novel Dropout Mechanism Integrated with Global Information. (arXiv:1808.08149v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1808.08149</link>
<description rdf:parseType="Literal">&lt;p&gt;Dropout is used to avoid overfitting by randomly dropping units from the
neural networks during training. Inspired by dropout, this paper presents
GI-Dropout, a novel dropout method integrating with global information to
improve neural networks for text classification. Unlike the traditional dropout
method in which the units are dropped randomly according to the same
probability, we aim to use explicit instructions based on global information of
the dataset to guide the training process. With GI-Dropout, the model is
supposed to pay more attention to inapparent features or patterns. Experiments
demonstrate the effectiveness of the dropout with global information on seven
text classification tasks, including sentiment analysis and topic
classification.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1&quot;&gt;Hengru Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1&quot;&gt;Shen Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_R/0/1/0/all/0/1&quot;&gt;Renfen Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1&quot;&gt;Si Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_S/0/1/0/all/0/1&quot;&gt;Sheng Gao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.05760">
<title>Data Poisoning Attacks in Contextual Bandits. (arXiv:1808.05760v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1808.05760</link>
<description rdf:parseType="Literal">&lt;p&gt;We study offline data poisoning attacks in contextual bandits, a class of
reinforcement learning problems with important applications in online
recommendation and adaptive medical treatment, among others. We provide a
general attack framework based on convex optimization and show that by slightly
manipulating rewards in the data, an attacker can force the bandit algorithm to
pull a target arm for a target contextual vector. The target arm and target
contextual vector are both chosen by the attacker. That is, the attacker can
hijack the behavior of a contextual bandit. We also investigate the feasibility
and the side effects of such attacks, and identify future directions for
defense. Experiments on both synthetic and real-world data demonstrate the
efficiency of the attack algorithm.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1&quot;&gt;Yuzhe Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jun_K/0/1/0/all/0/1&quot;&gt;Kwang-Sung Jun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1&quot;&gt;Lihong Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1&quot;&gt;Xiaojin Zhu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.07632">
<title>DOPING: Generative Data Augmentation for Unsupervised Anomaly Detection with GAN. (arXiv:1808.07632v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1808.07632</link>
<description rdf:parseType="Literal">&lt;p&gt;Recently, the introduction of the generative adversarial network (GAN) and
its variants has enabled the generation of realistic synthetic samples, which
has been used for enlarging training sets. Previous work primarily focused on
data augmentation for semi-supervised and supervised tasks. In this paper, we
instead focus on unsupervised anomaly detection and propose a novel generative
data augmentation framework optimized for this task. In particular, we propose
to oversample infrequent normal samples - normal samples that occur with small
probability, e.g., rare normal events. We show that these samples are
responsible for false positives in anomaly detection. However, oversampling of
infrequent normal samples is challenging for real-world high-dimensional data
with multimodal distributions. To address this challenge, we propose to use a
GAN variant known as the adversarial autoencoder (AAE) to transform the
high-dimensional multimodal data distributions into low-dimensional unimodal
latent distributions with well-defined tail probability. Then, we
systematically oversample at the `edge&apos; of the latent distributions to increase
the density of infrequent normal samples. We show that our oversampling
pipeline is a unified one: it is generally applicable to datasets with
different complex data distributions. To the best of our knowledge, our method
is the first data augmentation technique focused on improving performance in
unsupervised anomaly detection. We validate our method by demonstrating
consistent improvements across several real-world datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lim_S/0/1/0/all/0/1&quot;&gt;Swee Kiat Lim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Loo_Y/0/1/0/all/0/1&quot;&gt;Yi Loo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tran_N/0/1/0/all/0/1&quot;&gt;Ngoc-Trung Tran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheung_N/0/1/0/all/0/1&quot;&gt;Ngai-Man Cheung&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roig_G/0/1/0/all/0/1&quot;&gt;Gemma Roig&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Elovici_Y/0/1/0/all/0/1&quot;&gt;Yuval Elovici&lt;/a&gt;</dc:creator>
</item></rdf:RDF>