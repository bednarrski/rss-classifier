<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Good papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Good Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-04-23T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.07824"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.08042"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.08328"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.08378"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1702.07805"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.06567"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.07633"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.07757"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.07759"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.07819"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.07855"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.07875"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.07918"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.08069"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.08117"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.08138"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.08139"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.08204"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.08229"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.08256"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.08316"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.08426"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.08454"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.08497"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.08597"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1611.04642"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1704.00783"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1707.02920"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1707.04822"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.04307"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05883"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.00109"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.05839"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.06898"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.07837"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.07839"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.07846"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.07931"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.08071"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.08369"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.08420"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.08501"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.08598"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1603.06846"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1704.03581"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1706.08839"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.05750"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.06010"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.03878"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.00171"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.03840"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.03308"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.07270"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1804.07824">
<title>Autotune: A Derivative-free Optimization Framework for Hyperparameter Tuning. (arXiv:1804.07824v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1804.07824</link>
<description rdf:parseType="Literal">&lt;p&gt;Machine learning applications often require hyperparameter tuning. The
hyperparameters usually drive both the efficiency of the model training process
and the resulting model quality. For hyperparameter tuning, machine learning
algorithms are complex black-boxes. This creates a class of challenging
optimization problems, whose objective functions tend to be nonsmooth,
discontinuous, unpredictably varying in computational expense, and include
continuous, categorical, and/or integer variables. Further, function
evaluations can fail for a variety of reasons including numerical difficulties
or hardware failures. Additionally, not all hyperparameter value combinations
are compatible, which creates so called hidden constraints. Robust and
efficient optimization algorithms are needed for hyperparameter tuning. In this
paper we present an automated parallel derivative-free optimization framework
called \textbf{Autotune}, which combines a number of specialized sampling and
search methods that are very effective in tuning machine learning models
despite these challenges. Autotune provides significantly improved models over
using default hyperparameter settings with minimal user interaction on
real-world applications. Given the inherent expense of training numerous
candidate models, we demonstrate the effectiveness of Autotune&apos;s search methods
and the efficient distributed and parallel paradigms for training and tuning
models, and also discuss the resource trade-offs associated with the ability to
both distribute the training process and parallelize the tuning process.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koch_P/0/1/0/all/0/1&quot;&gt;Patrick Koch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Golovidov_O/0/1/0/all/0/1&quot;&gt;Oleg Golovidov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gardner_S/0/1/0/all/0/1&quot;&gt;Steven Gardner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wujek_B/0/1/0/all/0/1&quot;&gt;Brett Wujek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Griffin_J/0/1/0/all/0/1&quot;&gt;Joshua Griffin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1&quot;&gt;Yan Xu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.08042">
<title>Bridgeout: stochastic bridge regularization for deep neural networks. (arXiv:1804.08042v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1804.08042</link>
<description rdf:parseType="Literal">&lt;p&gt;A major challenge in training deep neural networks is overfitting, i.e.
inferior performance on unseen test examples compared to performance on
training examples. To reduce overfitting, stochastic regularization methods
have shown superior performance compared to deterministic weight penalties on a
number of image recognition tasks. Stochastic methods such as Dropout and
Shakeout, in expectation, are equivalent to imposing a ridge and elastic-net
penalty on the model parameters, respectively. However, the choice of the norm
of weight penalty is problem dependent and is not restricted to $\{L_1,L_2\}$.
Therefore, in this paper we propose the Bridgeout stochastic regularization
technique and prove that it is equivalent to an $L_q$ penalty on the weights,
where the norm $q$ can be learned as a hyperparameter from data. Experimental
results show that Bridgeout results in sparse model weights, improved gradients
and superior classification performance compared to Dropout and Shakeout on
synthetic and real datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khan_N/0/1/0/all/0/1&quot;&gt;Najeeb Khan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shah_J/0/1/0/all/0/1&quot;&gt;Jawad Shah&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stavness_I/0/1/0/all/0/1&quot;&gt;Ian Stavness&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.08328">
<title>Taskonomy: Disentangling Task Transfer Learning. (arXiv:1804.08328v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1804.08328</link>
<description rdf:parseType="Literal">&lt;p&gt;Do visual tasks have a relationship, or are they unrelated? For instance,
could having surface normals simplify estimating the depth of an image?
Intuition answers these questions positively, implying existence of a structure
among visual tasks. Knowing this structure has notable values; it is the
concept underlying transfer learning and provides a principled way for
identifying redundancies across tasks, e.g., to seamlessly reuse supervision
among related tasks or solve many tasks in one system without piling up the
complexity.
&lt;/p&gt;
&lt;p&gt;We proposes a fully computational approach for modeling the structure of
space of visual tasks. This is done via finding (first and higher-order)
transfer learning dependencies across a dictionary of twenty six 2D, 2.5D, 3D,
and semantic tasks in a latent space. The product is a computational taxonomic
map for task transfer learning. We study the consequences of this structure,
e.g. nontrivial emerged relationships, and exploit them to reduce the demand
for labeled data. For example, we show that the total number of labeled
datapoints needed for solving a set of 10 tasks can be reduced by roughly 2/3
(compared to training independently) while keeping the performance nearly the
same. We provide a set of tools for computing and probing this taxonomical
structure including a solver that users can employ to devise efficient
supervision policies for their use cases.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zamir_A/0/1/0/all/0/1&quot;&gt;Amir Zamir&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sax_A/0/1/0/all/0/1&quot;&gt;Alexander Sax&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_W/0/1/0/all/0/1&quot;&gt;William Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guibas_L/0/1/0/all/0/1&quot;&gt;Leonidas Guibas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Malik_J/0/1/0/all/0/1&quot;&gt;Jitendra Malik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Savarese_S/0/1/0/all/0/1&quot;&gt;Silvio Savarese&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.08378">
<title>BrainSlug: Transparent Acceleration of Deep Learning Through Depth-First Parallelism. (arXiv:1804.08378v1 [cs.DC])</title>
<link>http://arxiv.org/abs/1804.08378</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural network frameworks such as PyTorch and TensorFlow are the workhorses
of numerous machine learning applications ranging from object recognition to
machine translation. While these frameworks are versatile and straightforward
to use, the training of and inference in deep neural networks is resource
(energy, compute, and memory) intensive. In contrast to recent works focusing
on algorithmic enhancements, we introduce BrainSlug, a framework that
transparently accelerates neural network workloads by changing the default
layer-by-layer processing to a depth-first approach, reducing the amount of
data required by the computations and thus improving the performance of the
available hardware caches. BrainSlug achieves performance improvements of up to
41.1% on CPUs and 35.7% on GPUs. These optimizations come at zero cost to the
user as they do not require hardware changes and only need tiny adjustments to
the software.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Weber_N/0/1/0/all/0/1&quot;&gt;Nicolas Weber&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schmidt_F/0/1/0/all/0/1&quot;&gt;Florian Schmidt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Niepert_M/0/1/0/all/0/1&quot;&gt;Mathias Niepert&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huici_F/0/1/0/all/0/1&quot;&gt;Felipe Huici&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1702.07805">
<title>Analyzing and Exploiting NARX Recurrent Neural Networks for Long-Term Dependencies. (arXiv:1702.07805v4 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1702.07805</link>
<description rdf:parseType="Literal">&lt;p&gt;Recurrent neural networks (RNNs) have achieved state-of-the-art performance
on many diverse tasks, from machine translation to surgical activity
recognition, yet training RNNs to capture long-term dependencies remains
difficult. To date, the vast majority of successful RNN architectures alleviate
this problem using nearly-additive connections between states, as introduced by
long short-term memory (LSTM). We take an orthogonal approach and introduce
MIST RNNs, a NARX RNN architecture that allows direct connections from the very
distant past. We show that MIST RNNs 1) exhibit superior vanishing-gradient
properties in comparison to LSTM and previously-proposed NARX RNNs; 2) are far
more efficient than previously-proposed NARX RNN architectures, requiring even
fewer computations than LSTM; and 3) improve performance substantially over
LSTM and Clockwork RNNs on tasks requiring very long-term dependencies.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+DiPietro_R/0/1/0/all/0/1&quot;&gt;Robert DiPietro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rupprecht_C/0/1/0/all/0/1&quot;&gt;Christian Rupprecht&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Navab_N/0/1/0/all/0/1&quot;&gt;Nassir Navab&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hager_G/0/1/0/all/0/1&quot;&gt;Gregory D. Hager&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.06567">
<title>Deep Neuroevolution: Genetic Algorithms Are a Competitive Alternative for Training Deep Neural Networks for Reinforcement Learning. (arXiv:1712.06567v3 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1712.06567</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep artificial neural networks (DNNs) are typically trained via
gradient-based learning algorithms, namely backpropagation. Evolution
strategies (ES) can rival backprop-based algorithms such as Q-learning and
policy gradients on challenging deep reinforcement learning (RL) problems.
However, ES can be considered a gradient-based algorithm because it performs
stochastic gradient descent via an operation similar to a finite-difference
approximation of the gradient. That raises the question of whether
non-gradient-based evolutionary algorithms can work at DNN scales. Here we
demonstrate they can: we evolve the weights of a DNN with a simple,
gradient-free, population-based genetic algorithm (GA) and it performs well on
hard deep RL problems, including Atari and humanoid locomotion. The Deep GA
successfully evolves networks with over four million free parameters, the
largest neural networks ever evolved with a traditional evolutionary algorithm.
These results (1) expand our sense of the scale at which GAs can operate, (2)
suggest intriguingly that in some cases following the gradient is not the best
choice for optimizing performance, and (3) make immediately available the
multitude of neuroevolution techniques that improve performance. We demonstrate
the latter by showing that combining DNNs with novelty search, which encourages
exploration on tasks with deceptive or sparse reward functions, can solve a
high-dimensional problem on which reward-maximizing algorithms (e.g.\ DQN, A3C,
ES, and the GA) fail. Additionally, the Deep GA is faster than ES, A3C, and DQN
(it can train Atari in ${\raise.17ex\hbox{$\scriptstyle\sim$}}$4 hours on one
desktop or ${\raise.17ex\hbox{$\scriptstyle\sim$}}$1 hour distributed on 720
cores), and enables a state-of-the-art, up to 10,000-fold compact encoding
technique.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Such_F/0/1/0/all/0/1&quot;&gt;Felipe Petroski Such&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Madhavan_V/0/1/0/all/0/1&quot;&gt;Vashisht Madhavan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Conti_E/0/1/0/all/0/1&quot;&gt;Edoardo Conti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lehman_J/0/1/0/all/0/1&quot;&gt;Joel Lehman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stanley_K/0/1/0/all/0/1&quot;&gt;Kenneth O. Stanley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Clune_J/0/1/0/all/0/1&quot;&gt;Jeff Clune&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.07633">
<title>A Simple Quantum Neural Net with a Periodic Activation Function. (arXiv:1804.07633v2 [quant-ph] UPDATED)</title>
<link>http://arxiv.org/abs/1804.07633</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we propose a simple neural net that requires only $O(nlog_2k)$
number of qubits and $O(nk)$ quantum gates: Here, $n$ is the number of input
parameters, and $k$ is the number of weights applied to these parameters in the
proposed neural net. We describe the network in terms of a quantum circuit, and
then draw its equivalent classical neural net which involves $O(k^n)$ nodes in
the hidden layer. Then, we show that the network uses a periodic activation
function of cosine values of the linear combinations of the inputs and weights.
The backpropagation is described through the gradient descent, and then iris
and breast cancer datasets are used for the simulations. The numerical results
indicate the network can be used in machine learning problems and it may
provide exponential speedup over the same structured classical neural net.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Daskin_A/0/1/0/all/0/1&quot;&gt;Ammar Daskin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.07757">
<title>Learning More Robust Features with Adversarial Training. (arXiv:1804.07757v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1804.07757</link>
<description rdf:parseType="Literal">&lt;p&gt;In recent years, it has been found that neural networks can be easily fooled
by adversarial examples, which is a potential safety hazard in some
safety-critical applications. Many researchers have proposed various method to
make neural networks more robust to white-box adversarial attacks, but an
effective method have not been found so far. In this short paper, we focus on
the robustness of the features learned by neural networks. We show that the
features learned by neural networks are not robust, and find that the
robustness of the learned features is closely related to the resistance against
adversarial examples of neural networks. We also find that adversarial training
against fast gradients sign method (FGSM) does not make the leaned features
very robust, even if it can make the trained networks very resistant to FGSM
attack. Then we propose a method, which can be seen as an extension of
adversarial training, to train neural networks to learn more robust features.
We perform experiments on MNIST and CIFAR-10 to evaluate our method, and the
experiment results show that this method greatly improves the robustness of the
learned features and the resistance to adversarial attacks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1&quot;&gt;Shuangtao Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yuanke Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peng_Y/0/1/0/all/0/1&quot;&gt;Yanlin Peng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bai_L/0/1/0/all/0/1&quot;&gt;Lin Bai&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.07759">
<title>A Self-paced Regularization Framework for Partial-Label Learning. (arXiv:1804.07759v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1804.07759</link>
<description rdf:parseType="Literal">&lt;p&gt;Partial label learning (PLL) aims to solve the problem where each training
instance is associated with a set of candidate labels, one of which is the
correct label. Most PLL algorithms try to disambiguate the candidate label set,
by either simply treating each candidate label equally or iteratively
identifying the true label. Nonetheless, existing algorithms usually treat all
labels and instances equally, and the complexities of both labels and instances
are not taken into consideration during the learning stage. Inspired by the
successful application of self-paced learning strategy in machine learning
field, we integrate the self-paced regime into the partial label learning
framework and propose a novel Self-Paced Partial-Label Learning (SP-PLL)
algorithm, which could control the learning process to alleviate the problem by
ranking the priorities of the training examples together with their candidate
labels during each learning iteration. Extensive experiments and comparisons
with other baseline methods demonstrate the effectiveness and robustness of the
proposed method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lyu_G/0/1/0/all/0/1&quot;&gt;Gengyu Lyu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feng_S/0/1/0/all/0/1&quot;&gt;Songhe Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lang_C/0/1/0/all/0/1&quot;&gt;Congyang Lang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1&quot;&gt;Tao Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.07819">
<title>Understanding AI Data Repositories with Automatic Query Generation. (arXiv:1804.07819v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1804.07819</link>
<description rdf:parseType="Literal">&lt;p&gt;We describe a set of techniques to generate queries automatically based on
one or more ingested, input corpuses. These queries require no a priori domain
knowledge, and hence no human domain experts. Thus, these auto-generated
queries help address the epistemological question of how we know what we know,
or more precisely in this case, how an AI system with ingested data knows what
it knows. These auto-generated queries can also be used to identify and remedy
problem areas in ingested material -- areas for which the knowledge of the AI
system is incomplete or even erroneous. Similarly, the proposed techniques
facilitate tests of AI capability -- both in terms of coverage and accuracy. By
removing humans from the main learning loop, our approach also allows more
effective scaling of AI and cognitive capabilities to provide (1) broader
coverage in a single domain such as health or geology; and (2) more rapid
deployment to new domains. The proposed techniques also allow ingested
knowledge to be extended naturally. Our investigations are early, and this
paper provides a description of the techniques. Assessment of their efficacy is
our next step for future work.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Altman_E/0/1/0/all/0/1&quot;&gt;Erik Altman&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.07855">
<title>Subgoal Discovery for Hierarchical Dialogue Policy Learning. (arXiv:1804.07855v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1804.07855</link>
<description rdf:parseType="Literal">&lt;p&gt;Developing conversational agents to engage in complex dialogues is
challenging partly because the dialogue policy needs to explore a large
state-action space. In this paper, we propose a divide-and-conquer approach
that discovers and exploits the hidden structure of the task to enable
efficient policy learning. First, given a set of successful dialogue sessions,
we present a Subgoal Discovery Network (SDN) to divide a complex goal-oriented
task into a set of simpler subgoals in an unsupervised fashion. We then use
these subgoals to learn a hierarchical policy which consists of 1) a top-level
policy that selects among subgoals, and 2) a low-level policy that selects
primitive actions to accomplish the subgoal. We exemplify our method by
building a dialogue agent for the composite task of travel planning.
Experiments with simulated and real users show that an agent trained with
automatically discovered subgoals performs competitively against an agent with
human-defined subgoals, and significantly outperforms an agent without
subgoals. Moreover, we show that learned subgoals are human comprehensible.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_D/0/1/0/all/0/1&quot;&gt;Da Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xiujun Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1&quot;&gt;Jianfeng Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1&quot;&gt;Chong Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1&quot;&gt;Lihong Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jebara_T/0/1/0/all/0/1&quot;&gt;Tony Jebara&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.07875">
<title>Multi-lingual Common Semantic Space Construction via Cluster-consistent Word Embedding. (arXiv:1804.07875v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1804.07875</link>
<description rdf:parseType="Literal">&lt;p&gt;We construct a multilingual common semantic space based on distributional
semantics, where words from multiple languages are projected into a shared
space to enable knowledge and resource transfer across languages. Beyond word
alignment, we introduce multiple cluster-level alignments and enforce the word
clusters to be consistently distributed across multiple languages. We exploit
three signals for clustering: (1) neighbor words in the monolingual word
embedding space; (2) character-level information; and (3) linguistic properties
(e.g., apposition, locative suffix) derived from linguistic structure knowledge
bases available for thousands of languages. We introduce a new
cluster-consistent correlational neural network to construct the common
semantic space by aligning words as well as clusters. Intrinsic evaluation on
monolingual and multilingual QVEC tasks shows our approach achieves
significantly higher correlation with linguistic features than state-of-the-art
multi-lingual embedding learning methods do. Using low-resource language name
tagging as a case study for extrinsic evaluation, our approach achieves up to
24.5\% absolute F-score gain over the state of the art.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1&quot;&gt;Lifu Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cho_K/0/1/0/all/0/1&quot;&gt;Kyunghyun Cho&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1&quot;&gt;Boliang Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ji_H/0/1/0/all/0/1&quot;&gt;Heng Ji&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Knight_K/0/1/0/all/0/1&quot;&gt;Kevin Knight&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.07918">
<title>Decoupling Structure and Lexicon for Zero-Shot Semantic Parsing. (arXiv:1804.07918v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1804.07918</link>
<description rdf:parseType="Literal">&lt;p&gt;Building a semantic parser quickly in a new domain is a fundamental challenge
for conversational interfaces, as current semantic parsers require expensive
supervision and lack the ability to generalize to new domains. In this paper,
we introduce a zero-shot approach to semantic parsing that can parse utterances
in unseen domains while only being trained on examples in other source domains.
First, we map an utterance to an abstract, domain-independent, logical form
that represents the structure of the logical form, but contains slots instead
of KB constants. Then, we replace slots with KB constants via lexical alignment
scores and global inference. Our model reaches an average accuracy of 53.1% on
7 domains in the Overnight dataset, substantially better than other zero-shot
baselines, and performs as good as a parser trained on over 30% of the target
domain examples.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Herzig_J/0/1/0/all/0/1&quot;&gt;Jonathan Herzig&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Berant_J/0/1/0/all/0/1&quot;&gt;Jonathan Berant&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.08069">
<title>Unsupervised Discrete Sentence Representation Learning for Interpretable Neural Dialog Generation. (arXiv:1804.08069v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1804.08069</link>
<description rdf:parseType="Literal">&lt;p&gt;The encoder-decoder dialog model is one of the most prominent methods used to
build dialog systems in complex domains. Yet it is limited because it cannot
output interpretable actions as in traditional systems, which hinders humans
from understanding its generation process. We present an unsupervised discrete
sentence representation learning method that can integrate with any existing
encoder-decoder dialog models for interpretable response generation. Building
upon variational autoencoders (VAEs), we present two novel models, DI-VAE and
DI-VST that improve VAEs and can discover interpretable semantics via either
auto encoding or context predicting. Our methods have been validated on
real-world dialog datasets to discover semantic representations and enhance
encoder-decoder models with interpretable generation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_T/0/1/0/all/0/1&quot;&gt;Tiancheng Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1&quot;&gt;Kyusong Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Eskenazi_M/0/1/0/all/0/1&quot;&gt;Maxine Eskenazi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.08117">
<title>Performance Impact Caused by Hidden Bias of Training Data for Recognizing Textual Entailment. (arXiv:1804.08117v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1804.08117</link>
<description rdf:parseType="Literal">&lt;p&gt;The quality of training data is one of the crucial problems when a
learning-centered approach is employed. This paper proposes a new method to
investigate the quality of a large corpus designed for the recognizing textual
entailment (RTE) task. The proposed method, which is inspired by a statistical
hypothesis test, consists of two phases: the first phase is to introduce the
predictability of textual entailment labels as a null hypothesis which is
extremely unacceptable if a target corpus has no hidden bias, and the second
phase is to test the null hypothesis using a Naive Bayes model. The
experimental result of the Stanford Natural Language Inference (SNLI) corpus
does not reject the null hypothesis. Therefore, it indicates that the SNLI
corpus has a hidden bias which allows prediction of textual entailment labels
from hypothesis sentences even if no context information is given by a premise
sentence. This paper also presents the performance impact of NN models for RTE
caused by this hidden bias.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tsuchiya_M/0/1/0/all/0/1&quot;&gt;Masatoshi Tsuchiya&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.08138">
<title>Complex Network Analysis of Men Single ATP Tennis Matches. (arXiv:1804.08138v1 [physics.soc-ph])</title>
<link>http://arxiv.org/abs/1804.08138</link>
<description rdf:parseType="Literal">&lt;p&gt;Who are the most significant players in the history of men tennis? Is the
official ATP ranking system fair in evaluating players scores? Which players
deserved the most contemplation looking at their match records? Which players
have never faced yet and are likely to play against in the future? Those are
just some of the questions developed in this paper supported by data updated at
April 2018. In order to give an answer to the aforementioned questions, complex
network science techniques have been applied to some representations of the
network of men singles tennis matches. Additionally, a new predictive algorithm
is proposed in order to forecast the winner of a match.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Michieli_U/0/1/0/all/0/1&quot;&gt;Umberto Michieli&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.08139">
<title>Same Representation, Different Attentions: Shareable Sentence Representation Learning from Multiple Tasks. (arXiv:1804.08139v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1804.08139</link>
<description rdf:parseType="Literal">&lt;p&gt;Distributed representation plays an important role in deep learning based
natural language processing. However, the representation of a sentence often
varies in different tasks, which is usually learned from scratch and suffers
from the limited amounts of training data. In this paper, we claim that a good
sentence representation should be invariant and can benefit the various
subsequent tasks. To achieve this purpose, we propose a new scheme of
information sharing for multi-task learning. More specifically, all tasks share
the same sentence representation and each task can select the task-specific
information from the shared sentence representation with attention mechanism.
The query vector of each task&apos;s attention could be either static parameters or
generated dynamically. We conduct extensive experiments on 16 different text
classification tasks, which demonstrate the benefits of our architecture.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_R/0/1/0/all/0/1&quot;&gt;Renjie Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1&quot;&gt;Junkun Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qiu_X/0/1/0/all/0/1&quot;&gt;Xipeng Qiu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.08204">
<title>Knowledge-based end-to-end memory networks. (arXiv:1804.08204v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1804.08204</link>
<description rdf:parseType="Literal">&lt;p&gt;End-to-end dialog systems have become very popular because they hold the
promise of learning directly from human to human dialog interaction. Retrieval
and Generative methods have been explored in this area with mixed results. A
key element that is missing so far, is the incorporation of a-priori knowledge
about the task at hand. This knowledge may exist in the form of structured or
unstructured information. As a first step towards this direction, we present a
novel approach, Knowledge based end-to-end memory networks (KB-memN2N), which
allows special handling of named entities for goal-oriented dialog tasks. We
present results on two datasets, DSTC6 challenge dataset and dialog bAbI tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ganhotra_J/0/1/0/all/0/1&quot;&gt;Jatin Ganhotra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Polymenakos_L/0/1/0/all/0/1&quot;&gt;Lazaros Polymenakos&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.08229">
<title>An Empirical Comparison of PDDL-based and ASP-based Task Planners. (arXiv:1804.08229v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1804.08229</link>
<description rdf:parseType="Literal">&lt;p&gt;General purpose planners enable AI systems to solve many different types of
planning problems. However, many different planners exist, each with different
strengths and weaknesses, and there are no general rules for which planner
would be best to apply to a given problem. In this paper, we empirically
compare the performance of state-of-the-art planners that use either the
Planning Domain Description Language (PDDL), or Answer Set Programming (ASP) as
the underlying action language. PDDL is designed for automated planning, and
PDDL-based planners are widely used for a variety of planning problems. ASP is
designed for knowledge-intensive reasoning, but can also be used for solving
planning problems. Given domain encodings that are as similar as possible, we
find that PDDL-based planners perform better on problems with longer solutions,
and ASP-based planners are better on tasks with a large number of objects or in
which complex reasoning is required to reason about action preconditions and
effects. The resulting analysis can inform selection among general purpose
planning systems for a particular domain.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1&quot;&gt;Yuqian Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1&quot;&gt;Shiqi Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khandelwal_P/0/1/0/all/0/1&quot;&gt;Piyush Khandelwal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stone_P/0/1/0/all/0/1&quot;&gt;Peter Stone&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.08256">
<title>Progressive refinement: a method of coarse-to-fine image parsing using stacked network. (arXiv:1804.08256v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1804.08256</link>
<description rdf:parseType="Literal">&lt;p&gt;To parse images into fine-grained semantic parts, the complex fine-grained
elements will put it in trouble when using off-the-shelf semantic segmentation
networks. In this paper, for image parsing task, we propose to parse images
from coarse to fine with progressively refined semantic classes. It is achieved
by stacking the segmentation layers in a segmentation network several times.
The former segmentation module parses images at a coarser-grained level, and
the result will be feed to the following one to provide effective contextual
clues for the finer-grained parsing. To recover the details of small
structures, we add skip connections from shallow layers of the network to
fine-grained parsing modules. As for the network training, we merge classes in
groundtruth to get coarse-to-fine label maps, and train the stacked network
with these hierarchical supervision end-to-end. Our coarse-to-fine stacked
framework can be injected into many advanced neural networks to improve the
parsing results. Extensive evaluations on several public datasets including
face parsing and human parsing well demonstrate the superiority of our method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_J/0/1/0/all/0/1&quot;&gt;Jiagao Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_Z/0/1/0/all/0/1&quot;&gt;Zhengxing Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1&quot;&gt;Yunhan Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_J/0/1/0/all/0/1&quot;&gt;Jinlong Shi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.08316">
<title>Bilingual Embeddings with Random Walks over Multilingual Wordnets. (arXiv:1804.08316v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1804.08316</link>
<description rdf:parseType="Literal">&lt;p&gt;Bilingual word embeddings represent words of two languages in the same space,
and allow to transfer knowledge from one language to the other without machine
translation. The main approach is to train monolingual embeddings first and
then map them using bilingual dictionaries. In this work, we present a novel
method to learn bilingual embeddings based on multilingual knowledge bases (KB)
such as WordNet. Our method extracts bilingual information from multilingual
wordnets via random walks and learns a joint embedding space in one go. We
further reinforce cross-lingual equivalence adding bilingual con- straints in
the loss function of the popular skipgram model. Our experiments involve twelve
cross-lingual word similarity and relatedness datasets in six lan- guage pairs
covering four languages, and show that: 1) random walks over mul- tilingual
wordnets improve results over just using dictionaries; 2) multilingual wordnets
on their own improve over text-based systems in similarity datasets; 3) the
good results are consistent for large wordnets (e.g. English, Spanish), smaller
wordnets (e.g. Basque) or loosely aligned wordnets (e.g. Italian); 4) the
combination of wordnets and text yields the best results, above mapping-based
approaches. Our method can be applied to richer KBs like DBpedia or Babel- Net,
and can be easily extended to multilingual embeddings. All software and
resources are open source.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goikoetxea_J/0/1/0/all/0/1&quot;&gt;J.Goikoetxea&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Soroa_A/0/1/0/all/0/1&quot;&gt;A.Soroa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Agirre_E/0/1/0/all/0/1&quot;&gt;E.Agirre&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.08426">
<title>LightRel SemEval-2018 Task 7: Lightweight and Fast Relation Classification. (arXiv:1804.08426v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1804.08426</link>
<description rdf:parseType="Literal">&lt;p&gt;We present LightRel, a lightweight and fast relation classifier. Our goal is
to develop a high baseline for different relation extraction tasks. By defining
only very few data-internal, word-level features and external knowledge sources
in the form of word clusters and word embeddings, we train a fast and simple
linear classifier.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Renslow_T/0/1/0/all/0/1&quot;&gt;Tyler Renslow&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Neumann_G/0/1/0/all/0/1&quot;&gt;G&amp;#xfc;nter Neumann&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.08454">
<title>Attention Based Natural Language Grounding by Navigating Virtual Environment. (arXiv:1804.08454v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1804.08454</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work, we focus on the problem of grounding language by training an
agent to follow a set of natural language instructions and navigate to a target
object in an environment. The agent receives visual information through raw
pixels and a natural language instruction telling what task needs to be
achieved. Other than these two sources of information, our model does not have
any prior information of both the visual and textual modalities and is
end-to-end trainable. We develop an attention mechanism for multi-modal fusion
of visual and textual modalities that allows the agent to learn to complete the
task and also achieve language grounding. Our experimental results show that
our attention mechanism outperforms the existing multi-modal fusion mechanisms
proposed for both 2D and 3D environments in order to solve the above mentioned
task. We show that the learnt textual representations are semantically
meaningful as they follow vector arithmetic and are also consistent enough to
induce translation between instructions in different natural languages. We also
show that our model generalizes effectively to unseen scenarios and exhibit
\textit{zero-shot} generalization capabilities both in 2D and 3D environments.
The code for our 2D environment as well as the models that we developed for
both 2D and 3D are available at
\href{https://github.com/rl-lang-grounding/rl-lang-ground}{https://github.com/rl-lang-grounding/rl-lang-ground}
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sinha_A/0/1/0/all/0/1&quot;&gt;Abhishek Sinha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+B_A/0/1/0/all/0/1&quot;&gt;Akilesh B&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sarkar_M/0/1/0/all/0/1&quot;&gt;Mausoom Sarkar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Krishnamurthy_B/0/1/0/all/0/1&quot;&gt;Balaji Krishnamurthy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.08497">
<title>ALIGNet: Partial-Shape Agnostic Alignment via Unsupervised Learning. (arXiv:1804.08497v1 [cs.GR])</title>
<link>http://arxiv.org/abs/1804.08497</link>
<description rdf:parseType="Literal">&lt;p&gt;The process of aligning a pair of shapes is a fundamental operation in
computer graphics. Traditional approaches rely heavily on matching
corresponding points or features to guide the alignment, a paradigm that
falters when significant shape portions are missing. These techniques generally
do not incorporate prior knowledge about expected shape characteristics, which
can help compensate for any misleading cues left by inaccuracies exhibited in
the input shapes. We present an approach based on a deep neural network,
leveraging shape datasets to learn a shape-aware prior for source-to-target
alignment that is robust to shape incompleteness. In the absence of ground
truth alignments for supervision, we train a network on the task of shape
alignment using incomplete shapes generated from full shapes for
self-supervision. Our network, called ALIGNet, is trained to warp complete
source shapes to incomplete targets, as if the target shapes were complete,
thus essentially rendering the alignment partial-shape agnostic. We aim for the
network to develop specialized expertise over the common characteristics of the
shapes in each dataset, thereby achieving a higher-level understanding of the
expected shape space to which a local approach would be oblivious. We constrain
ALIGNet through an anisotropic total variation identity regularization to
promote piecewise smooth deformation fields, facilitating both partial-shape
agnosticism and post-deformation applications. We demonstrate that ALIGNet
learns to align geometrically distinct shapes, and is able to infer plausible
mappings even when the target shape is significantly incomplete. We show that
our network learns the common expected characteristics of shape collections,
without over-fitting or memorization, enabling it to produce plausible
deformations on unseen data during test time.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hanocka_R/0/1/0/all/0/1&quot;&gt;Rana Hanocka&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fish_N/0/1/0/all/0/1&quot;&gt;Noa Fish&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zhenhua Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Giryes_R/0/1/0/all/0/1&quot;&gt;Raja Giryes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fleishman_S/0/1/0/all/0/1&quot;&gt;Shachar Fleishman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cohen_Or_D/0/1/0/all/0/1&quot;&gt;Daniel Cohen-Or&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.08597">
<title>Towards Symbolic Reinforcement Learning with Common Sense. (arXiv:1804.08597v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1804.08597</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep Reinforcement Learning (deep RL) has made several breakthroughs in
recent years in applications ranging from complex control tasks in unmanned
vehicles to game playing. Despite their success, deep RL still lacks several
important capacities of human intelligence, such as transfer learning,
abstraction and interpretability. Deep Symbolic Reinforcement Learning (DSRL)
seeks to incorporate such capacities to deep Q-networks (DQN) by learning a
relevant symbolic representation prior to using Q-learning. In this paper, we
propose a novel extension of DSRL, which we call Symbolic Reinforcement
Learning with Common Sense (SRL+CS), offering a better balance between
generalization and specialization, inspired by principles of common sense when
assigning rewards and aggregating Q-values. Experiments reported in this paper
show that SRL+CS learns consistently faster than Q-learning and DSRL, achieving
also a higher accuracy. In the hardest case, where agents were trained in a
deterministic environment and tested in a random environment, SRL+CS achieves
nearly 100% average accuracy compared to DSRL&apos;s 70% and DQN&apos;s 50% accuracy. To
the best of our knowledge, this is the first case of near perfect zero-shot
transfer learning using Reinforcement Learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garcez_A/0/1/0/all/0/1&quot;&gt;Artur d&amp;#x27;Avila Garcez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dutra_A/0/1/0/all/0/1&quot;&gt;Aimore Resende Riquetti Dutra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alonso_E/0/1/0/all/0/1&quot;&gt;Eduardo Alonso&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1611.04642">
<title>Link Prediction using Embedded Knowledge Graphs. (arXiv:1611.04642v5 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1611.04642</link>
<description rdf:parseType="Literal">&lt;p&gt;Since large knowledge bases are typically incomplete, missing facts need to
be inferred from observed facts in a task called knowledge base completion. The
most successful approaches to this task have typically explored explicit paths
through sequences of triples. These approaches have usually resorted to
human-designed sampling procedures, since large knowledge graphs produce
prohibitively large numbers of possible paths, most of which are uninformative.
As an alternative approach, we propose performing a single, short sequence of
interactive lookup operations on an embedded knowledge graph which has been
trained through end-to-end backpropagation to be an optimized and compressed
version of the initial knowledge base. Our proposed model, called Embedded
Knowledge Graph Network (EKGN), achieves new state-of-the-art results on
popular knowledge base completion benchmarks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1&quot;&gt;Yelong Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_P/0/1/0/all/0/1&quot;&gt;Po-Sen Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chang_M/0/1/0/all/0/1&quot;&gt;Ming-Wei Chang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1&quot;&gt;Jianfeng Gao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1704.00783">
<title>Brief Notes on Hard Takeoff, Value Alignment, and Coherent Extrapolated Volition. (arXiv:1704.00783v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1704.00783</link>
<description rdf:parseType="Literal">&lt;p&gt;I make some basic observations about hard takeoff, value alignment, and
coherent extrapolated volition, concepts which have been central in analyses of
superintelligent AI systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sarma_G/0/1/0/all/0/1&quot;&gt;Gopal P. Sarma&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1707.02920">
<title>Vision-Based Multi-Task Manipulation for Inexpensive Robots Using End-To-End Learning from Demonstration. (arXiv:1707.02920v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1707.02920</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a technique for multi-task learning from demonstration that trains
the controller of a low-cost robotic arm to accomplish several complex picking
and placing tasks, as well as non-prehensile manipulation. The controller is a
recurrent neural network using raw images as input and generating robot arm
trajectories, with the parameters shared across the tasks. The controller also
combines VAE-GAN-based reconstruction with autoregressive multimodal action
prediction. Our results demonstrate that it is possible to learn complex
manipulation tasks, such as picking up a towel, wiping an object, and
depositing the towel to its previous position, entirely from raw images with
direct behavior cloning. We show that weight sharing and reconstruction-based
regularization substantially improve generalization and robustness, and
training on multiple tasks simultaneously increases the success rate on all
tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rahmatizadeh_R/0/1/0/all/0/1&quot;&gt;Rouhollah Rahmatizadeh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abolghasemi_P/0/1/0/all/0/1&quot;&gt;Pooya Abolghasemi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Boloni_L/0/1/0/all/0/1&quot;&gt;Ladislau B&amp;#xf6;l&amp;#xf6;ni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1&quot;&gt;Sergey Levine&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1707.04822">
<title>Block-Normalized Gradient Method: An Empirical Study for Training Deep Neural Network. (arXiv:1707.04822v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1707.04822</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we propose a generic and simple strategy for utilizing
stochastic gradient information in optimization. The technique essentially
contains two consecutive steps in each iteration: 1) computing and normalizing
each block (layer) of the mini-batch stochastic gradient; 2) selecting
appropriate step size to update the decision variable (parameter) towards the
negative of the block-normalized gradient. We conduct extensive empirical
studies on various non-convex neural network optimization problems, including
multi-layer perceptron, convolution neural networks and recurrent neural
networks. The results indicate the block-normalized gradient can help
accelerate the training of neural networks. In particular, we observe that the
normalized gradient methods having constant step size with occasionally decay,
such as SGD with momentum, have better performance in the deep convolution
neural networks, while those with adaptive step sizes, such as Adam, perform
better in recurrent neural networks. Besides, we also observe this line of
methods can lead to solutions with better generalization properties, which is
confirmed by the performance improvement over strong baselines.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_A/0/1/0/all/0/1&quot;&gt;Adams Wei Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1&quot;&gt;Lei Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_Q/0/1/0/all/0/1&quot;&gt;Qihang Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Salakhutdinov_R/0/1/0/all/0/1&quot;&gt;Ruslan Salakhutdinov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Carbonell_J/0/1/0/all/0/1&quot;&gt;Jaime Carbonell&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.04307">
<title>AI Safety and Reproducibility: Establishing Robust Foundations for the Neuroscience of Human Values. (arXiv:1712.04307v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1712.04307</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose the creation of a systematic effort to identify and replicate key
findings in neuroscience and allied fields related to understanding human
values. Our aim is to ensure that research underpinning the value alignment
problem of artificial intelligence has been sufficiently validated to play a
role in the design of AI systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sarma_G/0/1/0/all/0/1&quot;&gt;Gopal P. Sarma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hay_N/0/1/0/all/0/1&quot;&gt;Nick J. Hay&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Safron_A/0/1/0/all/0/1&quot;&gt;Adam Safron&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05883">
<title>Deep Generative Model for Joint Alignment and Word Representation. (arXiv:1802.05883v3 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1802.05883</link>
<description rdf:parseType="Literal">&lt;p&gt;This work exploits translation data as a source of semantically relevant
learning signal for models of word representation. In particular, we exploit
equivalence through translation as a form of distributed context and jointly
learn how to embed and align with a deep generative model. Our EmbedAlign model
embeds words in their complete observed context and learns by marginalisation
of latent lexical alignments. Besides, it embeds words as posterior probability
densities, rather than point estimates, which allows us to compare words in
context using a measure of overlap between distributions (e.g. KL divergence).
We investigate our model&apos;s performance on a range of lexical semantics tasks
achieving competitive results on several standard benchmarks including natural
language inference, paraphrasing, and text similarity.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rios_M/0/1/0/all/0/1&quot;&gt;Miguel Rios&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aziz_W/0/1/0/all/0/1&quot;&gt;Wilker Aziz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Simaan_K/0/1/0/all/0/1&quot;&gt;Khalil Sima&amp;#x27;an&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.00109">
<title>QDEE: Question Difficulty and Expertise Estimation in Community Question Answering Sites. (arXiv:1804.00109v2 [cs.SI] UPDATED)</title>
<link>http://arxiv.org/abs/1804.00109</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we present a framework for Question Difficulty and Expertise
Estimation (QDEE) in Community Question Answering sites (CQAs) such as Yahoo!
Answers and Stack Overflow, which tackles a fundamental challenge in
crowdsourcing: how to appropriately route and assign questions to users with
the suitable expertise. This problem domain has been the subject of much
research and includes both language-agnostic as well as language conscious
solutions. We bring to bear a key language-agnostic insight: that users gain
expertise and therefore tend to ask as well as answer more difficult questions
over time. We use this insight within the popular competition (directed) graph
model to estimate question difficulty and user expertise by identifying key
hierarchical structure within said model. An important and novel contribution
here is the application of &quot;social agony&quot; to this problem domain. Difficulty
levels of newly posted questions (the cold-start problem) are estimated by
using our QDEE framework and additional textual features. We also propose a
model to route newly posted questions to appropriate users based on the
difficulty level of the question and the expertise of the user. Extensive
experiments on real world CQAs such as Yahoo! Answers and Stack Overflow data
demonstrate the improved efficacy of our approach over contemporary
state-of-the-art models. The QDEE framework also allows us to characterize user
expertise in novel ways by identifying interesting patterns and roles played by
different users in such CQAs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1&quot;&gt;Jiankai Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moosavi_S/0/1/0/all/0/1&quot;&gt;Sobhan Moosavi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ramnath_R/0/1/0/all/0/1&quot;&gt;Rajiv Ramnath&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Parthasarathy_S/0/1/0/all/0/1&quot;&gt;Srinivasan Parthasarathy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.05839">
<title>BigDL: A Distributed Deep Learning Framework for Big Data. (arXiv:1804.05839v2 [cs.DC] UPDATED)</title>
<link>http://arxiv.org/abs/1804.05839</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we present BigDL, a distributed deep learning framework for
Big Data platforms and workflows. It is implemented on top of Apache Spark, and
allows users to write their deep learning applications as standard Spark
programs (running directly on large-scale big data clusters in a distributed
fashion). It provides an expressive, &quot;data-analytics integrated&quot; deep learning
programming model, so that users can easily build the end-to-end analytics + AI
pipelines under a unified programming paradigm; by implementing an AllReduce
like operation using existing primitives in Spark (e.g., shuffle, broadcast,
and in-memory data persistence), it also provides a highly efficient &quot;parameter
server&quot; style architecture, so as to achieve highly scalable, data-parallel
distributed training. Since its initial open source release, BigDL users have
built many analytics and deep learning applications (e.g., object detection,
sequence-to-sequence generation, visual similarity, neural recommendations,
fraud detection, etc.) on Spark.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dai_J/0/1/0/all/0/1&quot;&gt;Jason Dai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yiheng Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qiu_X/0/1/0/all/0/1&quot;&gt;Xin Qiu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ding_D/0/1/0/all/0/1&quot;&gt;Ding Ding&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yao Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yanzhang Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jia_X/0/1/0/all/0/1&quot;&gt;Xianyan Jia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1&quot;&gt;Cherry Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wan_Y/0/1/0/all/0/1&quot;&gt;Yan Wan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Zhichao Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jiao Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1&quot;&gt;Shengsheng Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1&quot;&gt;Zhongyuan Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yang Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1&quot;&gt;Yuhao Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+She_B/0/1/0/all/0/1&quot;&gt;Bowen She&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_D/0/1/0/all/0/1&quot;&gt;Dongjie Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_Q/0/1/0/all/0/1&quot;&gt;Qi Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1&quot;&gt;Kai Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_G/0/1/0/all/0/1&quot;&gt;Guoqiong Song&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.06898">
<title>Neural Automated Essay Scoring and Coherence Modeling for Adversarially Crafted Input. (arXiv:1804.06898v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1804.06898</link>
<description rdf:parseType="Literal">&lt;p&gt;We demonstrate that current state-of-the-art approaches to Automated Essay
Scoring (AES) are not well-suited to capturing adversarially crafted input of
grammatical but incoherent sequences of sentences. We develop a neural model of
local coherence that can effectively learn connectedness features between
sentences, and propose a framework for integrating and jointly training the
local coherence model with a state-of-the-art AES model. We evaluate our
approach against a number of baselines and experimentally demonstrate its
effectiveness on both the AES task and the task of flagging adversarial input,
further contributing to the development of an approach that strengthens the
validity of neural essay scoring models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Farag_Y/0/1/0/all/0/1&quot;&gt;Youmna Farag&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yannakoudakis_H/0/1/0/all/0/1&quot;&gt;Helen Yannakoudakis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Briscoe_T/0/1/0/all/0/1&quot;&gt;Ted Briscoe&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.07837">
<title>Online Improper Learning with an Approximation Oracle. (arXiv:1804.07837v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1804.07837</link>
<description rdf:parseType="Literal">&lt;p&gt;We revisit the question of reducing online learning to approximate
optimization of the offline problem. In this setting, we give two algorithms
with near-optimal performance in the full information setting: they guarantee
optimal regret and require only poly-logarithmically many calls to the
approximation oracle per iteration. Furthermore, these algorithms apply to the
more general improper learning problems. In the bandit setting, our algorithm
also significantly improves the best previously known oracle complexity while
maintaining the same regret.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hazan_E/0/1/0/all/0/1&quot;&gt;Elad Hazan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_W/0/1/0/all/0/1&quot;&gt;Wei Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yuanzhi Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Zhiyuan Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.07839">
<title>Large Scale Automated Reading of Frontal and Lateral Chest X-Rays using Dual Convolutional Neural Networks. (arXiv:1804.07839v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1804.07839</link>
<description rdf:parseType="Literal">&lt;p&gt;The MIMIC-CXR dataset is (to date) the largest publicly released chest x-ray
dataset consisting of 473,064 chest x-rays and 206,574 radiology reports
collected from 63,478 patients. We present the results of training and
evaluating a collection of deep convolutional neural networks on this dataset
to recognize multiple common thorax diseases. To the best of our knowledge,
this is the first work that trains CNNs for this task on such a large
collection of chest x-ray images, which is over four times the size of the
largest previously released chest x-ray corpus. We describe and evaluate
individual CNN models trained on frontal and lateral CXR view types. In
addition, we present a novel DualNet architecture that emulates routine
clinical practice by simultaneously processing both frontal and lateral CXR
images obtained from a radiological exam. Our DualNet architecture shows
improved performance in recognizing findings in CXR images when compared to
applying separate baseline frontal and lateral classifiers.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rubin_J/0/1/0/all/0/1&quot;&gt;Jonathan Rubin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sanghavi_D/0/1/0/all/0/1&quot;&gt;Deepan Sanghavi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_C/0/1/0/all/0/1&quot;&gt;Claire Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1&quot;&gt;Kathy Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qadir_A/0/1/0/all/0/1&quot;&gt;Ashequl Qadir&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Wilson_M/0/1/0/all/0/1&quot;&gt;Minnan Xu-Wilson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.07846">
<title>CactusNets: Layer Applicability as a Metric for Transfer Learning. (arXiv:1804.07846v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1804.07846</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep neural networks trained over large datasets learn features that are both
generic to the whole dataset, and specific to individual classes in the
dataset. Learned features tend towards generic in the lower layers and specific
in the higher layers of a network. Methods like fine-tuning are made possible
because of the ability for one filter to apply to multiple target classes. Much
like the human brain this behavior, can also be used to cluster and separate
classes. However, to the best of our knowledge there is no metric for how
applicable learned features are to specific classes. In this paper we propose a
definition and metric for measuring the applicability of learned features to
individual classes, and use this applicability metric to estimate input
applicability and produce a new method of unsupervised learning we call the
CactusNet.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Collier_E/0/1/0/all/0/1&quot;&gt;Edward Collier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+DiBiano_R/0/1/0/all/0/1&quot;&gt;Robert DiBiano&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mukhopadhyay_S/0/1/0/all/0/1&quot;&gt;Supratik Mukhopadhyay&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.07931">
<title>Entire Space Multi-Task Model: An Effective Approach for Estimating Post-Click Conversion Rate. (arXiv:1804.07931v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1804.07931</link>
<description rdf:parseType="Literal">&lt;p&gt;Estimating post-click conversion rate (CVR) accurately is crucial for ranking
systems in industrial applications such as recommendation and advertising.
Conventional CVR modeling applies popular deep learning methods and achieves
state-of-the-art performance. However it encounters several task-specific
problems in practice, making CVR modeling challenging. For example,
conventional CVR models are trained with samples of clicked impressions while
utilized to make inference on the entire space with samples of all impressions.
This causes a sample selection bias problem. Besides, there exists an extreme
data sparsity problem, making the model fitting rather difficult. In this
paper, we model CVR in a brand-new perspective by making good use of sequential
pattern of user actions, i.e., impression -&amp;gt; click -&amp;gt; conversion. The proposed
Entire Space Multi-task Model (ESMM) can eliminate the two problems
simultaneously by i) modeling CVR directly over the entire space, ii) employing
a feature representation transfer learning strategy. Experiments on dataset
gathered from Taobao&apos;s recommender system demonstrate that ESMM significantly
outperforms competitive methods. We also release a sampling version of this
dataset to enable future research. To the best of our knowledge, this is the
first public dataset which contains samples with sequential dependence of click
and conversion labels for CVR modeling.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ma_X/0/1/0/all/0/1&quot;&gt;Xiao Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhao_L/0/1/0/all/0/1&quot;&gt;Liqin Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Huang_G/0/1/0/all/0/1&quot;&gt;Guan Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zhi Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hu_Z/0/1/0/all/0/1&quot;&gt;Zelin Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhu_X/0/1/0/all/0/1&quot;&gt;Xiaoqiang Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gai_K/0/1/0/all/0/1&quot;&gt;Kun Gai&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.08071">
<title>Decoupled Networks. (arXiv:1804.08071v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1804.08071</link>
<description rdf:parseType="Literal">&lt;p&gt;Inner product-based convolution has been a central component of convolutional
neural networks (CNNs) and the key to learning visual representations. Inspired
by the observation that CNN-learned features are naturally decoupled with the
norm of features corresponding to the intra-class variation and the angle
corresponding to the semantic difference, we propose a generic decoupled
learning framework which models the intra-class variation and semantic
difference independently. Specifically, we first reparametrize the inner
product to a decoupled form and then generalize it to the decoupled convolution
operator which serves as the building block of our decoupled networks. We
present several effective instances of the decoupled convolution operator. Each
decoupled operator is well motivated and has an intuitive geometric
interpretation. Based on these decoupled operators, we further propose to
directly learn the operator from data. Extensive experiments show that such
decoupled reparameterization renders significant performance gain with easier
convergence and stronger robustness.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1&quot;&gt;Weiyang Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1&quot;&gt;Zhen Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1&quot;&gt;Zhiding Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dai_B/0/1/0/all/0/1&quot;&gt;Bo Dai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_R/0/1/0/all/0/1&quot;&gt;Rongmei Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yisen Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rehg_J/0/1/0/all/0/1&quot;&gt;James M. Rehg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_L/0/1/0/all/0/1&quot;&gt;Le Song&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.08369">
<title>Gaussian Material Synthesis. (arXiv:1804.08369v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1804.08369</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a learning-based system for rapid mass-scale material synthesis
that is useful for novice and expert users alike. The user preferences are
learned via Gaussian Process Regression and can be easily sampled for new
recommendations. Typically, each recommendation takes 40-60 seconds to render
with global illumination, which makes this process impracticable for real-world
workflows. Our neural network eliminates this bottleneck by providing
high-quality image predictions in real time, after which it is possible to pick
the desired materials from a gallery and assign them to a scene in an intuitive
manner. Workflow timings against Disney&apos;s &quot;principled&quot; shader reveal that our
system scales well with the number of sought materials, thus empowering even
novice users to generate hundreds of high-quality material models without any
expertise in material modeling. Similarly, expert users experience a
significant decrease in the total modeling time when populating a scene with
materials. Furthermore, our proposed solution also offers controllable
recommendations and a novel latent space variant generation step to enable the
real-time fine-tuning of materials without requiring any domain expertise.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zsolnai_Feher_K/0/1/0/all/0/1&quot;&gt;K&amp;#xe1;roly Zsolnai-Feh&amp;#xe9;r&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wonka_P/0/1/0/all/0/1&quot;&gt;Peter Wonka&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wimmer_M/0/1/0/all/0/1&quot;&gt;Michael Wimmer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.08420">
<title>Exploiting Partially Annotated Data for Temporal Relation Extraction. (arXiv:1804.08420v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1804.08420</link>
<description rdf:parseType="Literal">&lt;p&gt;Annotating temporal relations (TempRel) between events described in natural
language is known to be labor intensive, partly because the total number of
TempRels is quadratic in terms of the number of events. As a result, only a
small number of documents are typically annotated, limiting the coverage of
various lexical/semantic phenomena. One possibility is to make use of the
readily available, partially annotated data (P) that cover more documents.
However, missing annotations in P are known to hurt, rather than help, existing
systems. This work is a case study in exploring various usages of P for TempRel
extraction. Results show that despite missing annotations, P is still a useful
supervision signal for this task.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ning_Q/0/1/0/all/0/1&quot;&gt;Qiang Ning&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1&quot;&gt;Zhongzhi Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fan_C/0/1/0/all/0/1&quot;&gt;Chuchu Fan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roth_D/0/1/0/all/0/1&quot;&gt;Dan Roth&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.08501">
<title>Dropping Networks for Transfer Learning. (arXiv:1804.08501v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1804.08501</link>
<description rdf:parseType="Literal">&lt;p&gt;In natural language understanding, many challenges require learning
relationships between two sequences for various tasks such as similarity,
relatedness, paraphrasing and question matching. Some of these challenges are
inherently closer in nature, hence the knowledge acquired from one task to
another is easier acquired and adapted. However, transferring all knowledge
might be undesired and can lead to sub-optimal results due to \textit{negative}
transfer. Hence, this paper focuses on the transferability of both instances
and parameters across natural language understanding tasks using an
ensemble-based transfer learning method to circumvent such issues. The primary
contribution of this paper is the combination of both \textit{Dropout} and
\textit{Bagging} for improved transferability in neural networks, referred to
as \textit{Dropping} herein. Secondly, we present a straightforward yet novel
approach to incorporating source \textit{Dropping} Networks to a target task
for few-shot learning that mitigates \textit{negative} transfer. This is
achieved by using a decaying parameter chosen according to the slope changes of
a smoothed spline error curve at sub-intervals during training. We compare the
approach over the hard parameter sharing, soft parameter sharing and
single-task learning to compare its effectiveness. The aforementioned
adjustment leads to improved transfer learning performance and comparable
results to the current state of the art only using few instances from the
target task.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Neill_J/0/1/0/all/0/1&quot;&gt;James O&amp;#x27; Neill&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.08598">
<title>Black-box Adversarial Attacks with Limited Queries and Information. (arXiv:1804.08598v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1804.08598</link>
<description rdf:parseType="Literal">&lt;p&gt;Current neural network-based classifiers are susceptible to adversarial
examples even in the black-box setting, where the attacker only has query
access to the model. In practice, the threat model for real-world systems is
often more restrictive than the typical black-box model of full query access.
We define three realistic threat models that more accurately characterize many
real-world classifiers: the query-limited setting, the partial-information
setting, and the label-only setting. We develop new attacks that fool
classifiers under these more restrictive threat models, where previous methods
would be impractical or ineffective. We demonstrate that our methods are
effective against an ImageNet classifier under our proposed threat models. We
also demonstrate a targeted black-box attack against a commercial classifier,
overcoming the challenges of limited query access, partial information, and
other practical issues to attack the Google Cloud Vision API.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ilyas_A/0/1/0/all/0/1&quot;&gt;Andrew Ilyas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Engstrom_L/0/1/0/all/0/1&quot;&gt;Logan Engstrom&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Athalye_A/0/1/0/all/0/1&quot;&gt;Anish Athalye&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1&quot;&gt;Jessy Lin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1603.06846">
<title>A new class of metrics for learning on real-valued and structured data. (arXiv:1603.06846v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1603.06846</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a new class of metrics on sets, vectors, and functions that can be
used in various stages of data mining, including exploratory data analysis,
learning, and result interpretation. These new distance functions unify and
generalize some of the popular metrics, such as the Jaccard and bag distances
on sets, Manhattan distance on vector spaces, and Marczewski-Steinhaus distance
on integrable functions. We prove that the new metrics are complete and show
useful relationships with $f$-divergences for probability distributions. To
further extend our approach to structured objects such as concept hierarchies
and ontologies, we introduce information-theoretic metrics on directed acyclic
graphs drawn according to a fixed probability distribution. We conduct
empirical investigation to demonstrate intuitive interpretation of the new
metrics and their effectiveness on real-valued, high-dimensional, and
structured data. Extensive comparative evaluation demonstrates that the new
metrics outperformed multiple similarity and dissimilarity functions
traditionally used in data mining, including the Minkowski family, the
fractional $L^p$ family, two $f$-divergences, cosine distance, and two
correlation coefficients. Finally, we argue that the new class of metrics is
particularly appropriate for rapid processing of high-dimensional and
structured data in distance-based learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yang_R/0/1/0/all/0/1&quot;&gt;Ruiyu Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Jiang_Y/0/1/0/all/0/1&quot;&gt;Yuxiang Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mathews_S/0/1/0/all/0/1&quot;&gt;Scott Mathews&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Housworth_E/0/1/0/all/0/1&quot;&gt;Elizabeth A. Housworth&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hahn_M/0/1/0/all/0/1&quot;&gt;Matthew W. Hahn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Radivojac_P/0/1/0/all/0/1&quot;&gt;Predrag Radivojac&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1704.03581">
<title>Polya Urn Latent Dirichlet Allocation: a doubly sparse massively parallel sampler. (arXiv:1704.03581v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1704.03581</link>
<description rdf:parseType="Literal">&lt;p&gt;Latent Dirichlet Allocation (LDA) is a topic model widely used in natural
language processing and machine learning. Most approaches to training the model
rely on iterative algorithms, which makes it difficult to run LDA on big
corpora that are best analyzed in parallel and distributed computational
environments. Indeed, current approaches to parallel inference either don&apos;t
converge to the correct posterior or require storage of large dense matrices in
memory. We present a novel sampler that overcomes both problems, and we show
that this sampler is faster, both empirically and theoretically, than previous
Gibbs samplers for LDA. We do so by employing a novel P\&apos;olya-urn-based
approximation in the sparse partially collapsed sampler for LDA. We prove that
the approximation error vanishes with data size, making our algorithm
asymptotically exact, a property of importance for large-scale topic models. In
addition, we show, via an explicit example, that -- contrary to popular belief
in the topic modeling literature -- partially collapsed samplers can be more
efficient than fully collapsed samplers. We conclude by comparing the
performance of our algorithm with that of other approaches on well-known
corpora.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Terenin_A/0/1/0/all/0/1&quot;&gt;Alexander Terenin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Magnusson_M/0/1/0/all/0/1&quot;&gt;M&amp;#xe5;ns Magnusson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Jonsson_L/0/1/0/all/0/1&quot;&gt;Leif Jonsson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Draper_D/0/1/0/all/0/1&quot;&gt;David Draper&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1706.08839">
<title>Preserving Differential Privacy in Convolutional Deep Belief Networks. (arXiv:1706.08839v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1706.08839</link>
<description rdf:parseType="Literal">&lt;p&gt;The remarkable development of deep learning in medicine and healthcare domain
presents obvious privacy issues, when deep neural networks are built on users&apos;
personal and highly sensitive data, e.g., clinical records, user profiles,
biomedical images, etc. However, only a few scientific studies on preserving
privacy in deep learning have been conducted. In this paper, we focus on
developing a private convolutional deep belief network (pCDBN), which
essentially is a convolutional deep belief network (CDBN) under differential
privacy. Our main idea of enforcing epsilon-differential privacy is to leverage
the functional mechanism to perturb the energy-based objective functions of
traditional CDBNs, rather than their results. One key contribution of this work
is that we propose the use of Chebyshev expansion to derive the approximate
polynomial representation of objective functions. Our theoretical analysis
shows that we can further derive the sensitivity and error bounds of the
approximate polynomial representation. As a result, preserving differential
privacy in CDBNs is feasible. We applied our model in a health social network,
i.e., YesiWell data, and in a handwriting digit dataset, i.e., MNIST data, for
human behavior prediction, human behavior classification, and handwriting digit
recognition tasks. Theoretical analysis and rigorous experimental evaluations
show that the pCDBN is highly effective. It significantly outperforms existing
solutions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Phan_N/0/1/0/all/0/1&quot;&gt;NhatHai Phan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1&quot;&gt;Xintao Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dou_D/0/1/0/all/0/1&quot;&gt;Dejing Dou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.05750">
<title>Adaptive Laplace Mechanism: Differential Privacy Preservation in Deep Learning. (arXiv:1709.05750v2 [cs.CR] UPDATED)</title>
<link>http://arxiv.org/abs/1709.05750</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we focus on developing a novel mechanism to preserve
differential privacy in deep neural networks, such that: (1) The privacy budget
consumption is totally independent of the number of training steps; (2) It has
the ability to adaptively inject noise into features based on the contribution
of each to the output; and (3) It could be applied in a variety of different
deep neural networks. To achieve this, we figure out a way to perturb affine
transformations of neurons, and loss functions used in deep neural networks. In
addition, our mechanism intentionally adds &quot;more noise&quot; into features which are
&quot;less relevant&quot; to the model output, and vice-versa. Our theoretical analysis
further derives the sensitivities and error bounds of our mechanism. Rigorous
experiments conducted on MNIST and CIFAR-10 datasets show that our mechanism is
highly effective and outperforms existing solutions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Phan_N/0/1/0/all/0/1&quot;&gt;NhatHai Phan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1&quot;&gt;Xintao Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1&quot;&gt;Han Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dou_D/0/1/0/all/0/1&quot;&gt;Dejing Dou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.06010">
<title>Learning Neural Networks with Two Nonlinear Layers in Polynomial Time. (arXiv:1709.06010v4 [cs.DS] UPDATED)</title>
<link>http://arxiv.org/abs/1709.06010</link>
<description rdf:parseType="Literal">&lt;p&gt;We give a polynomial-time algorithm for learning neural networks with one
layer of sigmoids feeding into any Lipschitz, monotone activation function
(e.g., sigmoid or ReLU). We make no assumptions on the structure of the
network, and the algorithm succeeds with respect to {\em any} distribution on
the unit ball in $n$ dimensions (hidden weight vectors also have unit norm).
This is the first assumption-free, provably efficient algorithm for learning
neural networks with two nonlinear layers.
&lt;/p&gt;
&lt;p&gt;Our algorithm-- {\em Alphatron}-- is a simple, iterative update rule that
combines isotonic regression with kernel methods. It outputs a hypothesis that
yields efficient oracle access to interpretable features. It also suggests a
new approach to Boolean learning problems via real-valued conditional-mean
functions, sidestepping traditional hardness results from computational
learning theory.
&lt;/p&gt;
&lt;p&gt;Along these lines, we subsume and improve many longstanding results for PAC
learning Boolean functions to the more general, real-valued setting of {\em
probabilistic concepts}, a model that (unlike PAC learning) requires non-i.i.d.
noise-tolerance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goel_S/0/1/0/all/0/1&quot;&gt;Surbhi Goel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Klivans_A/0/1/0/all/0/1&quot;&gt;Adam Klivans&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.03878">
<title>Generalized Zero-Shot Learning via Synthesized Examples. (arXiv:1712.03878v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1712.03878</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a generative framework for generalized zero-shot learning where
the training and test classes are not necessarily disjoint. Built upon a
variational autoencoder based architecture, consisting of a probabilistic
encoder and a probabilistic conditional decoder, our model can generate novel
exemplars from seen/unseen classes, given their respective class attributes.
These exemplars can subsequently be used to train any off-the-shelf
classification model. One of the key aspects of our encoder-decoder
architecture is a feedback-driven mechanism in which a discriminator (a
multivariate regressor) learns to map the generated exemplars to the
corresponding class attribute vectors, leading to an improved generator. Our
model&apos;s ability to generate and leverage examples from unseen classes to train
the classification model naturally helps to mitigate the bias towards
predicting seen classes in generalized zero-shot learning settings. Through a
comprehensive set of experiments, we show that our model outperforms several
state-of-the-art methods, on several benchmark datasets, for both standard as
well as generalized zero-shot learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Arora_G/0/1/0/all/0/1&quot;&gt;Gundeep Arora&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Verma_V/0/1/0/all/0/1&quot;&gt;Vinay Kumar Verma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mishra_A/0/1/0/all/0/1&quot;&gt;Ashish Mishra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rai_P/0/1/0/all/0/1&quot;&gt;Piyush Rai&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.00171">
<title>PAC-Bayesian Margin Bounds for Convolutional Neural Networks. (arXiv:1801.00171v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1801.00171</link>
<description rdf:parseType="Literal">&lt;p&gt;Recently the generalization error of deep neural networks has been analyzed
through the PAC-Bayesian framework, for the case of fully connected layers. We
adapt this approach to the convolutional setting.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pitas_K/0/1/0/all/0/1&quot;&gt;Konstantinos Pitas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Davies_M/0/1/0/all/0/1&quot;&gt;Mike Davies&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vandergheynst_P/0/1/0/all/0/1&quot;&gt;Pierre Vandergheynst&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.03840">
<title>Uncharted Forest a Technique for Exploratory Data Analysis. (arXiv:1802.03840v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1802.03840</link>
<description rdf:parseType="Literal">&lt;p&gt;Exploratory data analysis is crucial for developing and understanding
classification models from high-dimensional datasets. We explore the utility of
a new unsupervised tree ensemble called uncharted forest for visualizing class
associations, sample-sample associations, class heterogeneity, and
uninformative classes for provenance studies. The uncharted forest algorithm
can be used to partition data using random selections of variables and metrics
based on statistical spread. After each tree is grown, a tally of the samples
that arrive at every terminal node is maintained. Those tallies are stored in
single sample association matrix and a likelihood measure for each sample being
partitioned with one another can be made. That matrix may be readily viewed as
a heat map, and the probabilities can be quantified via new metrics that
account for class or cluster membership. We display the advantages and
limitations of using this technique by applying it to one classification
dataset and two provenance study datasets. Two of the metrics presented in this
paper are also compared with widely used metrics from two algorithms that have
variance-based clustering mechanisms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kneale_C/0/1/0/all/0/1&quot;&gt;Casey Kneale&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Brown_S/0/1/0/all/0/1&quot;&gt;Steven D. Brown&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.03308">
<title>Adversarial Training Versus Weight Decay. (arXiv:1804.03308v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1804.03308</link>
<description rdf:parseType="Literal">&lt;p&gt;Performance-critical machine learning models should be robust to input
perturbations not seen during training. Adversarial training is a method for
improving a model&apos;s robustness to some perturbations by including them in the
training process, but this tends to exacerbate other vulnerabilities of the
model. The adversarial training framework has the effect of translating the
data with respect to the cost function, while weight decay has a scaling
effect. Although weight decay could be considered a crude regularization
technique, it appears superior to adversarial training as it remains stable
over a broader range of regimes and reduces all generalization errors. Equipped
with these abstractions, we provide key baseline results and methodology for
characterizing robustness. The two approaches can be combined to yield one
small model that demonstrates good robustness to several white-box attacks
associated with different metrics.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Galloway_A/0/1/0/all/0/1&quot;&gt;Angus Galloway&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tanay_T/0/1/0/all/0/1&quot;&gt;Thomas Tanay&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Taylor_G/0/1/0/all/0/1&quot;&gt;Graham W. Taylor&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.07270">
<title>A Dynamic Boosted Ensemble Learning Method Based on Random Forest. (arXiv:1804.07270v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1804.07270</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a dynamic boosted ensemble learning method based on random forest
(DBRF), a novel ensemble algorithm that incorporates the notion of hard example
mining into Random Forest (RF) and thus combines the high accuracy of Boosting
algorithm with the strong generalization of Bagging algorithm. Specifically, we
propose to measure the quality of each leaf node of every decision tree in the
random forest to determine hard examples. By iteratively training and then
removing easy examples and noise examples from training data, we evolve the
random forest to focus on hard examples dynamically so as to learn decision
boundaries better. Data can be cascaded through these random forests learned in
each iteration in sequence to generate predictions, thus making RF deep. We
also propose to use evolution mechanism and smart iteration mechanism to
improve the performance of the model. DBRF outperforms RF on three UCI datasets
and achieved state-of-the-art results compared to other deep models. Moreover,
we show that DBRF is also a new way of sampling and can be very useful when
learning from unbalanced data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1&quot;&gt;Xingzhang Ren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Long_C/0/1/0/all/0/1&quot;&gt;Chen Long&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1&quot;&gt;Leilei Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wei_Y/0/1/0/all/0/1&quot;&gt;Ye Wei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Du_D/0/1/0/all/0/1&quot;&gt;Dongdong Du&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_J/0/1/0/all/0/1&quot;&gt;Jingxi Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1&quot;&gt;Shikun Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1&quot;&gt;Weiping Li&lt;/a&gt;</dc:creator>
</item></rdf:RDF>