<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Good papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Good Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-05-23T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08786"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09282"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.02799"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.07447"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.06176"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.06744"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.00222"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08522"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07475"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08776"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08877"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08899"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09042"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09157"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1707.01310"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04253"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.09840"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07848"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08296"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08809"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08905"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08916"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08939"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09001"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09039"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09112"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09122"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09156"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09180"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09208"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09214"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09298"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09317"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1708.08157"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.06146"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.00168"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.03713"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04350"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.00184"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08090"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1805.08786">
<title>Expectation propagation: a probabilistic view of Deep Feed Forward Networks. (arXiv:1805.08786v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.08786</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a statistical mechanics model of deep feed forward neural networks
(FFN). Our energy-based approach naturally explains several known results and
heuristics, providing a solid theoretical framework and new instruments for a
systematic development of FFN. We infer that FFN can be understood as
performing three basic steps: encoding, representation validation and
propagation. We obtain a set of natural activations -- such as sigmoid, $\tanh$
and ReLu -- together with a state-of-the-art one, recently obtained by
Ramachandran et al.(&lt;a href=&quot;/abs/1710.05941&quot;&gt;arXiv:1710.05941&lt;/a&gt;) using an extensive search algorithm. We
term this activation ESP (Expected Signal Propagation), explain its
probabilistic meaning, and study the eigenvalue spectrum of the associated
Hessian on classification tasks. We find that ESP allows for faster training
and more consistent performances over a wide range of network architectures.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Milletari_M/0/1/0/all/0/1&quot;&gt;Mirco Milletar&amp;#xed;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chotibut_T/0/1/0/all/0/1&quot;&gt;Thiparat Chotibut&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Trevisanutto_P/0/1/0/all/0/1&quot;&gt;Paolo E. Trevisanutto&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09282">
<title>On self-play computation of equilibrium in poker. (arXiv:1805.09282v1 [cs.GT])</title>
<link>http://arxiv.org/abs/1805.09282</link>
<description rdf:parseType="Literal">&lt;p&gt;We compare performance of the genetic algorithm and the counterfactual regret
minimization algorithm in computing the near-equilibrium strategies in the
simplified poker games. We focus on the von Neumann poker and the simplified
version of the Texas Hold&apos;Em poker, and test outputs of the considered
algorithms against analytical expressions defining the Nash equilibrium
strategies. We comment on the performance of the studied algorithms against
opponents deviating from equilibrium.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goykhman_M/0/1/0/all/0/1&quot;&gt;Mikhail Goykhman&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.02799">
<title>Fidelity-Weighted Learning. (arXiv:1711.02799v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1711.02799</link>
<description rdf:parseType="Literal">&lt;p&gt;Training deep neural networks requires many training samples, but in practice
training labels are expensive to obtain and may be of varying quality, as some
may be from trusted expert labelers while others might be from heuristics or
other sources of weak supervision such as crowd-sourcing. This creates a
fundamental quality versus-quantity trade-off in the learning process. Do we
learn from the small amount of high-quality data or the potentially large
amount of weakly-labeled data? We argue that if the learner could somehow know
and take the label-quality into account when learning the data representation,
we could get the best of both worlds. To this end, we propose
&quot;fidelity-weighted learning&quot; (FWL), a semi-supervised student-teacher approach
for training deep neural networks using weakly-labeled data. FWL modulates the
parameter updates to a student network (trained on the task we care about) on a
per-sample basis according to the posterior confidence of its label-quality
estimated by a teacher (who has access to the high-quality labels). Both
student and teacher are learned from the data. We evaluate FWL on two tasks in
information retrieval and natural language processing where we outperform
state-of-the-art alternative semi-supervised methods, indicating that our
approach makes better use of strong and weak labels, and leads to better
task-dependent data representations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dehghani_M/0/1/0/all/0/1&quot;&gt;Mostafa Dehghani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mehrjou_A/0/1/0/all/0/1&quot;&gt;Arash Mehrjou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gouws_S/0/1/0/all/0/1&quot;&gt;Stephan Gouws&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kamps_J/0/1/0/all/0/1&quot;&gt;Jaap Kamps&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Scholkopf_B/0/1/0/all/0/1&quot;&gt;Bernhard Sch&amp;#xf6;lkopf&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.07447">
<title>Dataflow Matrix Machines and V-values: a Bridge between Programs and Neural Nets. (arXiv:1712.07447v2 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1712.07447</link>
<description rdf:parseType="Literal">&lt;p&gt;1) Dataflow matrix machines (DMMs) generalize neural nets by replacing
streams of numbers with linear streams (streams supporting linear
combinations), allowing arbitrary input and output arities for activation
functions, countable-sized networks with finite dynamically changeable active
part capable of unbounded growth, and a very expressive self-referential
mechanism.
&lt;/p&gt;
&lt;p&gt;2) DMMs are suitable for general-purpose programming, while retaining the key
property of recurrent neural networks: programs are expressed via matrices of
real numbers, and continuous changes to those matrices produce arbitrarily
small variations in the associated programs.
&lt;/p&gt;
&lt;p&gt;3) Spaces of V-values (vector-like elements based on nested maps) are
particularly useful, enabling DMMs with variadic activation functions and
conveniently representing conventional data structures.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bukatin_M/0/1/0/all/0/1&quot;&gt;Michael Bukatin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Anthony_J/0/1/0/all/0/1&quot;&gt;Jon Anthony&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.06176">
<title>Deep Dyna-Q: Integrating Planning for Task-Completion Dialogue Policy Learning. (arXiv:1801.06176v3 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1801.06176</link>
<description rdf:parseType="Literal">&lt;p&gt;Training a task-completion dialogue agent via reinforcement learning (RL) is
costly because it requires many interactions with real users. One common
alternative is to use a user simulator. However, a user simulator usually lacks
the language complexity of human interlocutors and the biases in its design may
tend to degrade the agent. To address these issues, we present Deep Dyna-Q,
which to our knowledge is the first deep RL framework that integrates planning
for task-completion dialogue policy learning. We incorporate into the dialogue
agent a model of the environment, referred to as the world model, to mimic real
user response and generate simulated experience. During dialogue policy
learning, the world model is constantly updated with real user experience to
approach real user behavior, and in turn, the dialogue agent is optimized using
both real experience and simulated experience. The effectiveness of our
approach is demonstrated on a movie-ticket booking task in both simulated and
human-in-the-loop settings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peng_B/0/1/0/all/0/1&quot;&gt;Baolin Peng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xiujun Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1&quot;&gt;Jianfeng Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Jingjing Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wong_K/0/1/0/all/0/1&quot;&gt;Kam-Fai Wong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Su_S/0/1/0/all/0/1&quot;&gt;Shang-Yu Su&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.06744">
<title>Neural Architecture Construction using EnvelopeNets. (arXiv:1803.06744v2 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1803.06744</link>
<description rdf:parseType="Literal">&lt;p&gt;In recent years, several automated search methods for neural network
architectures have been proposed using methods such as evolutionary algorithms
and reinforcement learning. These methods use an objective function (usually
accuracy) that is evaluated after a full training and evaluation cycle. We show
that statistics derived from filter featuremaps reach a state where the utility
of different filters within a network can be compared and hence can be used to
construct networks. The training epochs needed for filters within a network to
reach this state is much less than the training epochs needed for the accuracy
of a network to stabilize. EnvelopeNets is a construction method that exploits
this finding to design convolutional neural nets (CNNs) in a fraction of the
time needed by conventional search methods. The constructed networks show close
to state of the art performance on the image classification problem on well
known datasets (CIFAR-10, ImageNet) and consistently show better performance
than hand constructed and randomly generated networks of the same depth,
operators and approximately the same number of parameters.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kamath_P/0/1/0/all/0/1&quot;&gt;Purushotham Kamath&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1&quot;&gt;Abhishek Singh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dutta_D/0/1/0/all/0/1&quot;&gt;Debo Dutta&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.00222">
<title>Learning Unsupervised Learning Rules. (arXiv:1804.00222v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1804.00222</link>
<description rdf:parseType="Literal">&lt;p&gt;A major goal of unsupervised learning is to discover data representations
that are useful for subsequent tasks, without access to supervised labels
during training. Typically, this goal is approached by minimizing a surrogate
objective, such as the negative log likelihood of a generative model, with the
hope that representations useful for subsequent tasks will arise incidentally.
In this work, we propose instead to directly target a later desired task by
meta-learning an unsupervised learning rule, which leads to representations
useful for that task. Here, our desired task (meta-objective) is the
performance of the representation on semi-supervised classification, and we
meta-learn an algorithm -- an unsupervised weight update rule -- that produces
representations that perform well under this meta-objective. Additionally, we
constrain our unsupervised update rule to a be a biologically-motivated,
neuron-local function, which enables it to generalize to novel neural network
architectures. We show that the meta-learned update rule produces useful
features and sometimes outperforms existing unsupervised learning techniques.
We further show that the meta-learned unsupervised update rule generalizes to
train networks with different widths, depths, and nonlinearities. It also
generalizes to train on data with randomly permuted input dimensions and even
generalizes from image datasets to a text task.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Metz_L/0/1/0/all/0/1&quot;&gt;Luke Metz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Maheswaranathan_N/0/1/0/all/0/1&quot;&gt;Niru Maheswaranathan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheung_B/0/1/0/all/0/1&quot;&gt;Brian Cheung&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sohl_Dickstein_J/0/1/0/all/0/1&quot;&gt;Jascha Sohl-Dickstein&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08522">
<title>Deep learning generalizes because the parameter-function map is biased towards simple functions. (arXiv:1805.08522v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1805.08522</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep neural networks generalize remarkably well without explicit
regularization even in the strongly over-parametrized regime. This success
suggests that some form of implicit regularization must be at work. By applying
a modified version of the coding theorem from algorithmic information theory
and by performing extensive empirical analysis of random neural networks, we
argue that the parameter function map of deep neural networks is exponentially
biased towards functions with lower descriptional complexity. We show
explicitly for supervised learning of Boolean functions that the intrinsic
simplicity bias of deep neural networks means that they generalize
significantly better than an unbiased learning algorithm does. The superior
generalization due to simplicity bias can be explained using PAC-Bayes theory,
which yields useful generalization error bounds for learning Boolean functions
with a wide range of complexities. Finally, we provide evidence that deeper
neural networks trained on the CIFAR10 data set exhibit stronger simplicity
bias than shallow networks do, which may help explain why deeper networks
generalize better than shallow ones do.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Perez_G/0/1/0/all/0/1&quot;&gt;Guillermo Valle P&amp;#xe9;rez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Camargo_C/0/1/0/all/0/1&quot;&gt;Chico Q. Camargo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Louis_A/0/1/0/all/0/1&quot;&gt;Ard A. Louis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07475">
<title>Learning to Repair Software Vulnerabilities with Generative Adversarial Networks. (arXiv:1805.07475v2 [cs.CL] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1805.07475</link>
<description rdf:parseType="Literal">&lt;p&gt;Motivated by the problem of automated repair of software vulnerabilities, we
propose an adversarial learning approach that maps from one discrete source
domain to another target domain without requiring paired labeled examples or
source and target domains to be bijections. We demonstrate that the proposed
adversarial learning approach is an effective technique for repairing software
vulnerabilities, performing close to seq2seq approaches that require labeled
pairs. The proposed Generative Adversarial Network approach is
application-agnostic in that it can be applied to other problems similar to
code repair, such as grammar correction or sentiment translation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Harer_J/0/1/0/all/0/1&quot;&gt;Jacob Harer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ozdemir_O/0/1/0/all/0/1&quot;&gt;Onur Ozdemir&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lazovich_T/0/1/0/all/0/1&quot;&gt;Tomo Lazovich&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Reale_C/0/1/0/all/0/1&quot;&gt;Christopher P. Reale&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Russell_R/0/1/0/all/0/1&quot;&gt;Rebecca L. Russell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_L/0/1/0/all/0/1&quot;&gt;Louis Y. Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chin_P/0/1/0/all/0/1&quot;&gt;Peter Chin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08776">
<title>Scalable Centralized Deep Multi-Agent Reinforcement Learning via Policy Gradients. (arXiv:1805.08776v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.08776</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we explore using deep reinforcement learning for problems with
multiple agents. Most existing methods for deep multi-agent reinforcement
learning consider only a small number of agents. When the number of agents
increases, the dimensionality of the input and control spaces increase as well,
and these methods do not scale well. To address this, we propose casting the
multi-agent reinforcement learning problem as a distributed optimization
problem. Our algorithm assumes that for multi-agent settings, policies of
individual agents in a given population live close to each other in parameter
space and can be approximated by a single policy. With this simple assumption,
we show our algorithm to be extremely effective for reinforcement learning in
multi-agent settings. We demonstrate its effectiveness against existing
comparable approaches on co-operative and competitive tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khan_A/0/1/0/all/0/1&quot;&gt;Arbaaz Khan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1&quot;&gt;Clark Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1&quot;&gt;Daniel D. Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kumar_V/0/1/0/all/0/1&quot;&gt;Vijay Kumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ribeiro_A/0/1/0/all/0/1&quot;&gt;Alejandro Ribeiro&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08877">
<title>Adversarial Labeling for Learning without Labels. (arXiv:1805.08877v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.08877</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the task of training classifiers without labels. We propose a
weakly supervised method---adversarial label learning---that trains classifiers
to perform well against an adversary that chooses labels for training data. The
weak supervision constrains what labels the adversary can choose. The method
therefore minimizes an upper bound of the classifier&apos;s error rate using
projected primal-dual subgradient descent. Minimizing this bound protects
against bias and dependencies in the weak supervision. Experiments on three
real datasets show that our method can train without labels and outperforms
other approaches for weakly supervised learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Arachie_C/0/1/0/all/0/1&quot;&gt;Chidubem Arachie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_B/0/1/0/all/0/1&quot;&gt;Bert Huang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08899">
<title>EcoRNN: Fused LSTM RNN Implementation with Data Layout Optimization. (arXiv:1805.08899v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.08899</link>
<description rdf:parseType="Literal">&lt;p&gt;Long-Short-Term-Memory Recurrent Neural Network (LSTM RNN) is a
state-of-the-art (SOTA) model for analyzing sequential data. Current
implementations of LSTM RNN in machine learning frameworks usually either lack
performance or flexibility. For example, default implementations in Tensorflow
and MXNet invoke many tiny GPU kernels, leading to excessive overhead in
launching GPU threads. Although cuDNN, NVIDIA&apos;s deep learning library, can
accelerate performance by around 2x, it is closed-source and inflexible,
hampering further research and performance improvements in frameworks, such as
PyTorch, that use cuDNN as their backend. In this paper, we introduce a new RNN
implementation called EcoRNN that is significantly faster than the SOTA
open-source implementation in MXNet and is competitive with the closed-source
cuDNN. We show that (1) fusing tiny GPU kernels and (2) applying data layout
optimization can give us a maximum performance boost of 3x over MXNet default
and 1.5x over cuDNN implementations. Our optimizations also apply to other RNN
cell types such as LSTM variants and Gated Recurrent Units (GRUs). We integrate
EcoRNN into MXNet Python library and open-source it to benefit machine learning
practitioners.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_B/0/1/0/all/0/1&quot;&gt;Bojian Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nair_A/0/1/0/all/0/1&quot;&gt;Akshay Nair&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1&quot;&gt;Qiongsi Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vijaykumar_N/0/1/0/all/0/1&quot;&gt;Nandita Vijaykumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pekhimenko_G/0/1/0/all/0/1&quot;&gt;Gennady Pekhimenko&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09042">
<title>Generalisation of structural knowledge in the Hippocampal-Entorhinal system. (arXiv:1805.09042v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1805.09042</link>
<description rdf:parseType="Literal">&lt;p&gt;A central problem to understanding intelligence is the concept of
generalisation. This allows previously learnt structure to be exploited to
solve tasks in novel situations differing in their particularities. We take
inspiration from neuroscience, specifically the Hippocampal-Entorhinal system
(containing place and grid cells), known to be important for generalisation. We
propose that to generalise structural knowledge, the representations of the
structure of the world, i.e. how entities in the world relate to each other,
need to be separated from representations of the entities themselves. We show,
under these principles, artificial neural networks embedded with hierarchy and
fast Hebbian memory, can learn the statistics of memories, generalise
structural knowledge, and also exhibit neuronal representations mirroring those
found in the brain. We experimentally support model assumptions, showing a
preserved relationship between grid and place cells across environments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Whittington_J/0/1/0/all/0/1&quot;&gt;James C. R. Whittington&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Muller_T/0/1/0/all/0/1&quot;&gt;Timothy H. Muller&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barry_C/0/1/0/all/0/1&quot;&gt;Caswell Barry&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Behrens_T/0/1/0/all/0/1&quot;&gt;Timothy E. J. Behrens&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09157">
<title>A New Finitely Controllable Class of Tuple Generating Dependencies: The Triangularly-Guarded Class. (arXiv:1805.09157v1 [cs.DB])</title>
<link>http://arxiv.org/abs/1805.09157</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper we introduce a new class of tuple-generating dependencies
(TGDs) called triangularly-guarded (TG) TGDs. We show that conjunctive query
answering under this new class of TGDs is decidable since this new class of
TGDs also satisfies the finite controllability (FC) property. We further show
that this new class strictly contains some other decidable classes such as
weak-acyclic, guarded, sticky and shy. In this sense, the class TG provides a
unified representation of all these aforementioned classes of TGDs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Asuncion_V/0/1/0/all/0/1&quot;&gt;Vernon Asuncion&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yan Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1707.01310">
<title>Learning to Design Games: Strategic Environments in Reinforcement Learning. (arXiv:1707.01310v4 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1707.01310</link>
<description rdf:parseType="Literal">&lt;p&gt;In typical reinforcement learning (RL), the environment is assumed given and
the goal of the learning is to identify an optimal policy for the agent taking
actions through its interactions with the environment. In this paper, we extend
this setting by considering the environment is not given, but controllable and
learnable through its interaction with the agent at the same time. This
extension is motivated by environment design scenarios in the real-world,
including game design, shopping space design and traffic signal design.
Theoretically, we find a dual Markov decision process (MDP) w.r.t. the
environment to that w.r.t. the agent, and derive a policy gradient solution to
optimizing the parametrized environment. Furthermore, discontinuous
environments are addressed by a proposed general generative framework. Our
experiments on a Maze game design task show the effectiveness of the proposed
algorithms in generating diverse and challenging Mazes against various agent
settings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1&quot;&gt;Haifeng Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jun Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1&quot;&gt;Zhiming Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1&quot;&gt;Weinan Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wen_Y/0/1/0/all/0/1&quot;&gt;Ying Wen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1&quot;&gt;Yong Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1&quot;&gt;Wenxin Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04253">
<title>Global Model Interpretation via Recursive Partitioning. (arXiv:1802.04253v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1802.04253</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work, we propose a simple but effective method to interpret black-box
machine learning models globally. That is, we use a compact binary tree, the
interpretation tree, to explicitly represent the most important decision rules
that are implicitly contained in the black-box machine learning models. This
tree is learned from the contribution matrix which consists of the
contributions of input variables to predicted scores for each single
prediction. To generate the interpretation tree, a unified process recursively
partitions the input variable space by maximizing the difference in the average
contribution of the split variable between the divided spaces. We demonstrate
the effectiveness of our method in diagnosing machine learning models on
multiple tasks. Also, it is useful for new knowledge discovery as such insights
are not easily identifiable when only looking at single predictions. In
general, our work makes it easier and more efficient for human beings to
understand machine learning models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1&quot;&gt;Chengliang Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rangarajan_A/0/1/0/all/0/1&quot;&gt;Anand Rangarajan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ranka_S/0/1/0/all/0/1&quot;&gt;Sanjay Ranka&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.09840">
<title>Empirical Analysis of Foundational Distinctions in Linked Open Data. (arXiv:1803.09840v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1803.09840</link>
<description rdf:parseType="Literal">&lt;p&gt;The Web and its Semantic extension (i.e. Linked Open Data) contain open
global-scale knowledge and make it available to potentially intelligent
machines that want to benefit from it. Nevertheless, most of Linked Open Data
lack ontological distinctions and have sparse axiomatisation. For example,
distinctions such as whether an entity is inherently a class or an individual,
or whether it is a physical object or not, are hardly expressed in the data,
although they have been largely studied and formalised by foundational
ontologies (e.g. DOLCE, SUMO). These distinctions belong to common sense too,
which is relevant for many artificial intelligence tasks such as natural
language understanding, scene recognition, and the like. There is a gap between
foundational ontologies, that often formalise or are inspired by pre-existing
philosophical theories and are developed with a top-down approach, and Linked
Open Data that mostly derive from existing databases or crowd-based effort
(e.g. DBpedia, Wikidata). We investigate whether machines can learn
foundational distinctions over Linked Open Data entities, and if they match
common sense. We want to answer questions such as &quot;does the DBpedia entity for
dog refer to a class or to an instance?&quot;. We report on a set of experiments
based on machine learning and crowdsourcing that show promising results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Asprino_L/0/1/0/all/0/1&quot;&gt;Luigi Asprino&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Basile_V/0/1/0/all/0/1&quot;&gt;Valerio Basile&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ciancarini_P/0/1/0/all/0/1&quot;&gt;Paolo Ciancarini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Presutti_V/0/1/0/all/0/1&quot;&gt;Valentina Presutti&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07848">
<title>A Universal Music Translation Network. (arXiv:1805.07848v2 [cs.SD] UPDATED)</title>
<link>http://arxiv.org/abs/1805.07848</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a method for translating music across musical instruments, genres,
and styles. This method is based on a multi-domain wavenet autoencoder, with a
shared encoder and a disentangled latent space that is trained end-to-end on
waveforms. Employing a diverse training dataset and large net capacity, the
domain-independent encoder allows us to translate even from musical domains
that were not seen during training. The method is unsupervised and does not
rely on supervision in the form of matched samples between domains or musical
transcriptions. We evaluate our method on NSynth, as well as on a dataset
collected from professional musicians, and achieve convincing translations,
even when translating from whistling, potentially enabling the creation of
instrumental music by untrained humans.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mor_N/0/1/0/all/0/1&quot;&gt;Noam Mor&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wolf_L/0/1/0/all/0/1&quot;&gt;Lior Wolf&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Polyak_A/0/1/0/all/0/1&quot;&gt;Adam Polyak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Taigman_Y/0/1/0/all/0/1&quot;&gt;Yaniv Taigman&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08296">
<title>Data-Efficient Hierarchical Reinforcement Learning. (arXiv:1805.08296v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.08296</link>
<description rdf:parseType="Literal">&lt;p&gt;Hierarchical reinforcement learning (HRL) is a promising approach to extend
traditional reinforcement learning (RL) methods to solve more complex tasks.
Yet, the majority of current HRL methods require careful task-specific design
and on-policy training, making them difficult to apply in real-world scenarios.
In this paper, we study how we can develop HRL algorithms that are general, in
that they do not make onerous additional assumptions beyond standard RL
algorithms, and efficient, in the sense that they can be used with modest
numbers of interaction samples, making them suitable for real-world problems
such as robotic control. For generality, we develop a scheme where lower-level
controllers are supervised with goals that are learned and proposed
automatically by the higher-level controllers. To address efficiency, we
propose to use off-policy experience for both higher and lower-level training.
This poses a considerable challenge, since changes to the lower-level behaviors
change the action space for the higher-level policy, and we introduce an
off-policy correction to remedy this challenge. This allows us to take
advantage of recent advances in off-policy model-free RL to learn both higher-
and lower-level policies using substantially fewer environment interactions
than on-policy algorithms. We term the resulting HRL agent HIRO and find that
it is generally applicable and highly sample-efficient. Our experiments show
that HIRO can be used to learn highly complex behaviors for simulated robots,
such as pushing objects and utilizing them to reach target locations, learning
from only a few million samples, equivalent to a few days of real-time
interaction. In comparisons with a number of prior HRL methods, we find that
our approach substantially outperforms previous state-of-the-art techniques.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nachum_O/0/1/0/all/0/1&quot;&gt;Ofir Nachum&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gu_S/0/1/0/all/0/1&quot;&gt;Shixiang Gu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1&quot;&gt;Honglak Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1&quot;&gt;Sergey Levine&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08809">
<title>Infinite-Task Learning with Vector-Valued RKHSs. (arXiv:1805.08809v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.08809</link>
<description rdf:parseType="Literal">&lt;p&gt;Machine learning has witnessed the tremendous success of solving tasks
depending on a hyperparameter. While multi-task learning is celebrated for its
capacity to solve jointly a finite number of tasks, learning a continuum of
tasks for various loss functions is still a challenge. A promising approach,
called Parametric Task Learning, has paved the way in the case of
piecewise-linear loss functions. We propose a generic approach, called
Infinite-Task Learning, to solve jointly a continuum of tasks via vector-valued
RKHSs. We provide generalization guarantees to the suggested scheme and
illustrate its efficiency in cost-sensitive classification, quantile regression
and density level set estimation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brault_R/0/1/0/all/0/1&quot;&gt;Romain Brault&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lambert_A/0/1/0/all/0/1&quot;&gt;Alex Lambert&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Szabo_Z/0/1/0/all/0/1&quot;&gt;Zolt&amp;#xe1;n Szab&amp;#xf3;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sangnier_M/0/1/0/all/0/1&quot;&gt;Maxime Sangnier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+dAlche_Buc_F/0/1/0/all/0/1&quot;&gt;Florence d&amp;#x27;Alch&amp;#xe9;-Buc&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08905">
<title>AffinityNet: semi-supervised few-shot learning for disease type prediction. (arXiv:1805.08905v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.08905</link>
<description rdf:parseType="Literal">&lt;p&gt;Motivation:While deep learning has achieved great success in computer vision
and other fields, currently it does not work well on genomic data due to &quot;big
p, small n&quot; problem (i.e., relatively small number of samples with
high-dimensional features). In order to make deep learning work with a small
amount of training data, we have to design new models that can facilitate
few-shot learning. In this paper we focus on developing data efficient deep
learning models that learn from a limited number of training examples and
generalize well. Results: We developed two deep learningmodules: feature
attention layer and k-Nearest-Neighbor (kNN) attention poolinglayer tomake
ourmodelmuchmore data efficient than conventionaldeep learningmodels. Feature
attention layer can directly select important features that are useful for
patient classification. kNN attention pooling layer is based on graph attention
model, and is good for semi-supervised few-shot learning. Experiments on both
synthetic data and cancer genomic data from TCGA projects show that our method
has better generalization power than conventional neural network model.
Availability: We have implemented our method using PyTorch deep learning
framework (https://pytorch.org). The code is freely available at
https://github.com/BeautyOfWeb/AffinityNet.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_T/0/1/0/all/0/1&quot;&gt;Tianle Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_A/0/1/0/all/0/1&quot;&gt;Aidong Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08916">
<title>Distribution Aware Active Learning. (arXiv:1805.08916v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.08916</link>
<description rdf:parseType="Literal">&lt;p&gt;Discriminative learning machines often need a large set of labeled samples
for training. Active learning (AL) settings assume that the learner has the
freedom to ask an oracle to label its desired samples. Traditional AL
algorithms heuristically choose query samples about which the current learner
is uncertain. This strategy does not make good use of the structure of the
dataset at hand and is prone to be misguided by outliers. To alleviate this
problem, we propose to distill the structural information into a probabilistic
generative model which acts as a \emph{teacher} in our model. The active
\emph{learner} uses this information effectively at each cycle of active
learning. The proposed method is generic and does not depend on the type of
learner and teacher. We then suggest a query criterion for active learning that
is aware of distribution of data and is more robust against outliers. Our
method can be combined readily with several other query criteria for active
learning. We provide the formulation and empirically show our idea via toy and
real examples.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mehrjou_A/0/1/0/all/0/1&quot;&gt;Arash Mehrjou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Khodabandeh_M/0/1/0/all/0/1&quot;&gt;Mehran Khodabandeh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mori_G/0/1/0/all/0/1&quot;&gt;Greg Mori&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08939">
<title>Approximate Random Dropout. (arXiv:1805.08939v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.08939</link>
<description rdf:parseType="Literal">&lt;p&gt;The training phases of Deep neural network (DNN) consume enormous processing
time and energy. Compression techniques for inference acceleration leveraging
the sparsity of DNNs, however, can be hardly used in the training phase.
Because the training involves dense matrix-multiplication using GPGPU, which
endorse regular and structural data layout. In this paper, we exploit the
sparsity of DNN resulting from the random dropout technique to eliminate the
unnecessary computation and data access for those dropped neurons or synapses
in the training phase. Experiments results on MLP and LSTM on standard
benchmarks show that the proposed Approximate Random Dropout can reduce the
training time by half on average with ignorable accuracy loss.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_Z/0/1/0/all/0/1&quot;&gt;Zhuoran Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ru_D/0/1/0/all/0/1&quot;&gt;Dongyu Ru&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1&quot;&gt;Ru Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1&quot;&gt;Hongru Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peng_Z/0/1/0/all/0/1&quot;&gt;Zhenghao Peng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ke_J/0/1/0/all/0/1&quot;&gt;Jing Ke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_X/0/1/0/all/0/1&quot;&gt;Xiaoyao Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_L/0/1/0/all/0/1&quot;&gt;Li Jiang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09001">
<title>On the Relation of Impulse Propagation to Synaptic Strength. (arXiv:1805.09001v1 [q-bio.NC])</title>
<link>http://arxiv.org/abs/1805.09001</link>
<description rdf:parseType="Literal">&lt;p&gt;In neural network, synaptic strength could be seen as probability to transmit
impulse, and function could exist from transmission probability to synaptic
strength. If the function satisfies constraint such as continuity and
monotonicity, neural network would always go to one unique fixed point. An
biological image classifier is proposed to utilize this fixed point.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Sizhong_L/0/1/0/all/0/1&quot;&gt;Lan Sizhong&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09039">
<title>Amortized Context Vector Inference for Sequence-to-Sequence Networks. (arXiv:1805.09039v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.09039</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural attention (NA) is an effective mechanism for inferring complex
structural data dependencies that span long temporal horizons. As a
consequence, it has become a key component of sequence-to-sequence models that
yield state-of-the-art performance in as hard tasks as abstractive document
summarization (ADS), machine translation (MT), and video captioning (VC). NA
mechanisms perform inference of context vectors; these constitute weighted sums
of deterministic input sequence encodings, adaptively sourced over long
temporal horizons. However, recent work in the field of amortized variational
inference (AVI) has shown that it is often useful to treat the representations
generated by deep networks as latent random variables. This allows for the
models to better explore the space of possible representations. Based on this
motivation, in this work we introduce a novel regard towards a popular NA
mechanism, namely soft-attention (SA). Our approach treats the context vectors
generated by SA models as latent variables, the posteriors of which are
inferred by employing AVI. Both the means and the covariance matrices of the
inferred posteriors are parameterized via deep network mechanisms similar to
those employed in the context of standard SA. To illustrate our method, we
implement it in the context of popular sequence-to-sequence model variants with
SA. We conduct an extensive experimental evaluation using challenging ADS, VC,
and MT benchmarks, and show how our approach compares to the baselines.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chatzis_S/0/1/0/all/0/1&quot;&gt;Sotirios Chatzis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Charalampous_A/0/1/0/all/0/1&quot;&gt;Aristotelis Charalampous&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tolias_K/0/1/0/all/0/1&quot;&gt;Kyriacos Tolias&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vassou_S/0/1/0/all/0/1&quot;&gt;Sotiris A. Vassou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09112">
<title>Hyperbolic Neural Networks. (arXiv:1805.09112v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.09112</link>
<description rdf:parseType="Literal">&lt;p&gt;Hyperbolic spaces have recently gained momentum in the context of machine
learning due to their high capacity and tree-likeliness properties. However,
the representational power of hyperbolic geometry is not yet on par with
Euclidean geometry, mostly because of the absence of corresponding hyperbolic
neural network layers. This makes it hard to use hyperbolic embeddings in
downstream tasks. Here, we bridge this gap in a principled manner by combining
the formalism of M\&quot;obius gyrovector spaces with the Riemannian geometry of the
Poincar\&apos;e model of hyperbolic spaces. As a result, we derive hyperbolic
versions of important deep learning tools: multinomial logistic regression,
feed-forward and recurrent neural networks such as gated recurrent units. This
allows to embed sequential data and perform classification in the hyperbolic
space. Empirically, we show that, even if hyperbolic optimization tools are
limited, hyperbolic sentence embeddings either outperform or are on par with
their Euclidean variants on textual entailment and noisy-prefix recognition
tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ganea_O/0/1/0/all/0/1&quot;&gt;Octavian-Eugen Ganea&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Becigneul_G/0/1/0/all/0/1&quot;&gt;Gary B&amp;#xe9;cigneul&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hofmann_T/0/1/0/all/0/1&quot;&gt;Thomas Hofmann&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09122">
<title>Probabilistic Riemannian submanifold learning with wrapped Gaussian process latent variable models. (arXiv:1805.09122v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.09122</link>
<description rdf:parseType="Literal">&lt;p&gt;Latent variable models learn a stochastic embedding from a low-dimensional
latent space onto a submanifold of the Euclidean input space, on which the data
is assumed to lie. Frequently, however, the data objects are known to satisfy
constraints or invariances, which are not enforced by traditional latent
variable models. As a result, significant probability mass is assigned to
points that violate the known constraints. To remedy this, we propose the
wrapped Gaussian process latent variable model (WGPLVM). The model allows
non-linear, probabilistic inference of a lower-dimensional submanifold where
data is assumed to reside, while respecting known constraints or invariances
encoded in a Riemannian manifold. We evaluate our model against the Euclidean
GPLVM on several datasets and tasks, including encoding, visualization and
uncertainty quantification.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mallasto_A/0/1/0/all/0/1&quot;&gt;Anton Mallasto&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hauberg_S/0/1/0/all/0/1&quot;&gt;S&amp;#xf8;ren Hauberg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Feragen_A/0/1/0/all/0/1&quot;&gt;Aasa Feragen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09156">
<title>Matrix Co-completion for Multi-label Classification with Missing Features and Labels. (arXiv:1805.09156v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.09156</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider a challenging multi-label classification problem where both
feature matrix $\X$ and label matrix $\Y$ have missing entries. An existing
method concatenated $\X$ and $\Y$ as $[\X; \Y]$ and applied a matrix completion
(MC) method to fill the missing entries, under the assumption that $[\X; \Y]$
is of low-rank. However, since entries of $\Y$ take binary values in the
multi-label setting, it is unlikely that $\Y$ is of low-rank. Moreover, such
assumption implies a linear relationship between $\X$ and $\Y$ which may not
hold in practice. In this paper, we consider a latent matrix $\Z$ that produces
the probability $\sigma(Z_{ij})$ of generating label $Y_{ij}$, where
$\sigma(\cdot)$ is nonlinear. Considering label correlation, we assume $[\X;
\Z]$ is of low-rank, and propose an MC algorithm based on subgradient descent
named co-completion (COCO) motivated by elastic net and one-bit MC. We give a
theoretical bound on the recovery effect of COCO and demonstrate its practical
usefulness through experiments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1&quot;&gt;Miao Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Niu_G/0/1/0/all/0/1&quot;&gt;Gang Niu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Han_B/0/1/0/all/0/1&quot;&gt;Bo Han&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tsang_I/0/1/0/all/0/1&quot;&gt;Ivor W. Tsang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1&quot;&gt;Zhi-Hua Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sugiyama_M/0/1/0/all/0/1&quot;&gt;Masashi Sugiyama&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09180">
<title>Semi-supervised learning: When and why it works. (arXiv:1805.09180v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.09180</link>
<description rdf:parseType="Literal">&lt;p&gt;Semi-supervised learning deals with the problem of how, if possible, to take
advantage of a huge amount of unclassified data, to perform a classification in
situations when, typically, there is little labelled data. Even though this is
not always possible (it depends on how useful, for inferring the labels, it
would be to know the distribution of the unlabelled data), several algorithm
have been proposed recently. A new algorithm is proposed, that under almost
necessary conditions, attains asymptotically the performance of the best
theoretical rule as the amount of unlabelled data tends to infinity. The set of
necessary assumptions, although reasonable, show that semi-parametric classi-
fication only works for very well conditioned problems. The perfor- mance of
the algorithm is assessed in the well known &quot;Isolet&quot; real-data of phonemes,
where a strong dependence on the choice of the initial training sample is
shown.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Cholaquidis_A/0/1/0/all/0/1&quot;&gt;Alejandro Cholaquidis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Fraimand_R/0/1/0/all/0/1&quot;&gt;Ricardo Fraimand&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sued_M/0/1/0/all/0/1&quot;&gt;Mariela Sued&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09208">
<title>Pushing the bounds of dropout. (arXiv:1805.09208v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.09208</link>
<description rdf:parseType="Literal">&lt;p&gt;We show that dropout training is best understood as performing MAP estimation
concurrently for a family of conditional models whose objectives are themselves
lower bounded by the original dropout objective. This discovery allows us to
pick any model from this family after training, which leads to a substantial
improvement on regularisation-heavy language modelling. The family includes
models that compute a power mean over the sampled dropout masks, and their less
stochastic subvariants with tighter and higher lower bounds than the fully
stochastic dropout objective. We argue that since the deterministic
subvariant&apos;s bound is equal to its objective, and the highest amongst these
models, the predominant view of it as a good approximation to MC averaging is
misleading. Rather, deterministic dropout is the best available approximation
to the true objective.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Melis_G/0/1/0/all/0/1&quot;&gt;G&amp;#xe1;bor Melis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Blundell_C/0/1/0/all/0/1&quot;&gt;Charles Blundell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kocisky_T/0/1/0/all/0/1&quot;&gt;Tom&amp;#xe1;&amp;#x161; Ko&amp;#x10d;isk&amp;#xfd;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hermann_K/0/1/0/all/0/1&quot;&gt;Karl Moritz Hermann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Dyer_C/0/1/0/all/0/1&quot;&gt;Chris Dyer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Blunsom_P/0/1/0/all/0/1&quot;&gt;Phil Blunsom&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09214">
<title>A Unified Framework for Training Neural Networks. (arXiv:1805.09214v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.09214</link>
<description rdf:parseType="Literal">&lt;p&gt;The lack of mathematical tractability of Deep Neural Networks (DNNs) has
hindered progress towards having a unified convergence analysis of training
algorithms, in the general setting. We propose a unified optimization framework
for training different types of DNNs, and establish its convergence for
arbitrary loss, activation, and regularization functions, assumed to be smooth.
We show that framework generalizes well-known first- and second-order training
methods, and thus allows us to show the convergence of these methods for
various DNN architectures and learning tasks, as a special case of our
approach. We discuss some of its applications in training various DNN
architectures (e.g., feed-forward, convolutional, linear networks), to
regression and classification tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghauch_H/0/1/0/all/0/1&quot;&gt;Hadi Ghauch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shokri_Ghadikolaei_H/0/1/0/all/0/1&quot;&gt;Hossein Shokri-Ghadikolaei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fischione_C/0/1/0/all/0/1&quot;&gt;Carlo Fischione&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Skoglund_M/0/1/0/all/0/1&quot;&gt;Mikael Skoglund&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09298">
<title>Learning towards Minimum Hyperspherical Energy. (arXiv:1805.09298v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.09298</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural networks are a powerful class of nonlinear functions that can be
trained end-to-end on various applications. While the over-parametrization
nature in many neural networks renders the ability to fit complex functions and
the strong representation power to handle challenging tasks, it also leads to
highly correlated neurons that can hurt the generalization ability and incur
unnecessary computation cost. As a result, how to regularize the network to
avoid undesired representation redundancy becomes an important issue. To this
end, we draw inspiration from a well-known problem in physics -- Thomson
problem, where one seeks to find a state that distributes N electrons on a unit
sphere as even as possible with minimum potential energy. In light of this
intuition, we reduce the redundancy regularization problem to generic energy
minimization, and propose a minimum hyperspherical energy (MHE) objective as
generic regularization for neural networks. We also propose a few novel
variants of MHE, and provide some insights from a theoretical point of view.
Finally, we apply networks with MHE regularization to several challenging
tasks. Extensive experiments demonstrate the effectiveness of our method, by
showing the superior performance with MHE regularization.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1&quot;&gt;Weiyang Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_R/0/1/0/all/0/1&quot;&gt;Rongmei Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1&quot;&gt;Zhen Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1&quot;&gt;Lixin Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1&quot;&gt;Zhiding Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dai_B/0/1/0/all/0/1&quot;&gt;Bo Dai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_L/0/1/0/all/0/1&quot;&gt;Le Song&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09317">
<title>Communication Algorithms via Deep Learning. (arXiv:1805.09317v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.09317</link>
<description rdf:parseType="Literal">&lt;p&gt;Coding theory is a central discipline underpinning wireline and wireless
modems that are the workhorses of the information age. Progress in coding
theory is largely driven by individual human ingenuity with sporadic
breakthroughs over the past century. In this paper we study whether it is
possible to automate the discovery of decoding algorithms via deep learning. We
study a family of sequential codes parameterized by recurrent neural network
(RNN) architectures. We show that creatively designed and trained RNN
architectures can decode well known sequential codes such as the convolutional
and turbo codes with close to optimal performance on the additive white
Gaussian noise (AWGN) channel, which itself is achieved by breakthrough
algorithms of our times (Viterbi and BCJR decoders, representing dynamic
programing and forward-backward algorithms). We show strong generalizations,
i.e., we train at a specific signal to noise ratio and block length but test at
a wide range of these quantities, as well as robustness and adaptivity to
deviations from the AWGN setting.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kim_H/0/1/0/all/0/1&quot;&gt;Hyeji Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Jiang_Y/0/1/0/all/0/1&quot;&gt;Yihan Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rana_R/0/1/0/all/0/1&quot;&gt;Ranvir Rana&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kannan_S/0/1/0/all/0/1&quot;&gt;Sreeram Kannan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Oh_S/0/1/0/all/0/1&quot;&gt;Sewoong Oh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Viswanath_P/0/1/0/all/0/1&quot;&gt;Pramod Viswanath&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1708.08157">
<title>Characteristic and Universal Tensor Product Kernels. (arXiv:1708.08157v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1708.08157</link>
<description rdf:parseType="Literal">&lt;p&gt;Maximum mean discrepancy (MMD), also called energy distance or N-distance in
statistics and Hilbert-Schmidt independence criterion (HSIC), specifically
distance covariance in statistics, are among the most popular and successful
approaches to quantify the difference and independence of random variables,
respectively. Thanks to their kernel-based foundations, MMD and HSIC are
applicable on a wide variety of domains. Despite their tremendous success,
quite little is known about when HSIC characterizes independence and when MMD
with tensor product kernel can discriminate probability distributions. In this
paper, we answer these questions by studying various notions of characteristic
property of the tensor product kernel.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Szabo_Z/0/1/0/all/0/1&quot;&gt;Zoltan Szabo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sriperumbudur_B/0/1/0/all/0/1&quot;&gt;Bharath K. Sriperumbudur&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.06146">
<title>Universal Language Model Fine-tuning for Text Classification. (arXiv:1801.06146v5 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1801.06146</link>
<description rdf:parseType="Literal">&lt;p&gt;Inductive transfer learning has greatly impacted computer vision, but
existing approaches in NLP still require task-specific modifications and
training from scratch. We propose Universal Language Model Fine-tuning
(ULMFiT), an effective transfer learning method that can be applied to any task
in NLP, and introduce techniques that are key for fine-tuning a language model.
Our method significantly outperforms the state-of-the-art on six text
classification tasks, reducing the error by 18-24% on the majority of datasets.
Furthermore, with only 100 labeled examples, it matches the performance of
training from scratch on 100x more data. We open-source our pretrained models
and code.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Howard_J/0/1/0/all/0/1&quot;&gt;Jeremy Howard&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ruder_S/0/1/0/all/0/1&quot;&gt;Sebastian Ruder&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.00168">
<title>Deep Neural Nets with Interpolating Function as Output Activation. (arXiv:1802.00168v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1802.00168</link>
<description rdf:parseType="Literal">&lt;p&gt;We replace the output layer of deep neural nets, typically the softmax
function, by a novel interpolating function. And we propose end-to-end training
and testing algorithms for this new architecture. Compared to classical neural
nets with softmax function as output activation, the surrogate with
interpolating function as output activation combines advantages of both deep
and manifold learning. The new framework demonstrates the following major
advantages: First, it is better applicable to the case with insufficient
training data. Second, it significantly improves the generalization accuracy on
a wide variety of networks. The algorithm is implemented in PyTorch, and code
will be made publicly available.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1&quot;&gt;Bao Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_X/0/1/0/all/0/1&quot;&gt;Xiyang Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Zhen Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_W/0/1/0/all/0/1&quot;&gt;Wei Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_Z/0/1/0/all/0/1&quot;&gt;Zuoqiang Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Osher_S/0/1/0/all/0/1&quot;&gt;Stanley J. Osher&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.03713">
<title>Optimization of ReLU Neural Networks using Quotient Stochastic Gradient Descent. (arXiv:1802.03713v4 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1802.03713</link>
<description rdf:parseType="Literal">&lt;p&gt;It has been well known that neural networks with rectified linear hidden
units (ReLU) as activation functions are positively scale invariant, which
results in severe redundancy in their weight space (i.e., many ReLU networks
with different weights are actually equivalent). In this paper, we formally
characterize this redundancy/equivalence using the language of \emph{quotient
space} and discuss its negative impact on the optimization of ReLU neural
networks. Specifically, we show that all equivalent ReLU networks correspond to
the same vector in the quotient space, and each such vector can be
characterized by the so-called skeleton paths in the ReLU networks. With this,
we prove that the dimensionality of the quotient space is
$\#$weight$-\#$(hidden nodes), indicating that the redundancy of the weight
space is huge. In this paper, we propose to optimize ReLU neural networks
directly in the quotient space, instead of the original weight space. We
represent the loss function in the quotient space and design a new stochastic
gradient descent algorithm to iteratively learn the model, which we call
\emph{Quotient stochastic gradient descent } (abbreviated as Quotient SGD). We
also develop efficient tricks to ensure that the implementation of Quotient SGD
almost requires no extra computations as compared to standard SGD. According to
the experiments on benchmark datasets, our proposed Quotient SGD can
significantly improve the accuracy of the learned model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Meng_Q/0/1/0/all/0/1&quot;&gt;Qi Meng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chen_W/0/1/0/all/0/1&quot;&gt;Wei Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zheng_S/0/1/0/all/0/1&quot;&gt;Shuxin Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ye_Q/0/1/0/all/0/1&quot;&gt;Qiwei Ye&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Liu_T/0/1/0/all/0/1&quot;&gt;Tie-Yan Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04350">
<title>On the Sample Complexity of Learning from a Sequence of Experiments. (arXiv:1802.04350v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1802.04350</link>
<description rdf:parseType="Literal">&lt;p&gt;We analyze the sample complexity of a new problem: learning from a sequence
of experiments. In this problem, the learner should choose a hypothesis that
performs well with respect to an infinite sequence of experiments, and their
related data distributions. In practice, the learner can only perform a finite
number of experiments with a total of $N$ samples drawn from those data
distributions. By using a Rademacher complexity approach, we show that the gap
between the training and generalization error is O(N^{-1/2}). We also provide
some examples for linear prediction, two-layer neural networks and kernel
methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_L/0/1/0/all/0/1&quot;&gt;Longyun Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Honorio_J/0/1/0/all/0/1&quot;&gt;Jean Honorio&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Morgan_J/0/1/0/all/0/1&quot;&gt;John Morgan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.00184">
<title>Learning Sparse Structured Ensembles with SG-MCMC and Network Pruning. (arXiv:1803.00184v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1803.00184</link>
<description rdf:parseType="Literal">&lt;p&gt;An ensemble of neural networks is known to be more robust and accurate than
an individual network, however usually with linearly-increased cost in both
training and testing. In this work, we propose a two-stage method to learn
Sparse Structured Ensembles (SSEs) for neural networks. In the first stage, we
run SG-MCMC with group sparse priors to draw an ensemble of samples from the
posterior distribution of network parameters. In the second stage, we apply
weight-pruning to each sampled network and then perform retraining over the
remained connections. In this way of learning SSEs with SG-MCMC and pruning, we
not only achieve high prediction accuracy since SG-MCMC enhances exploration of
the model-parameter space, but also reduce memory and computation cost
significantly in both training and testing of NN ensembles. This is thoroughly
evaluated in the experiments of learning SSE ensembles of both FNNs and LSTMs.
For example, in LSTM based language modeling (LM), we obtain 21% relative
reduction in LM perplexity by learning a SSE of 4 large LSTM models, which has
only 30% of model parameters and 70% of computations in total, as compared to
the baseline large LSTM LM. To the best of our knowledge, this work represents
the first methodology and empirical study of integrating SG-MCMC, group sparse
prior and network pruning together for learning NN ensembles.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yichi Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ou_Z/0/1/0/all/0/1&quot;&gt;Zhijian Ou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08090">
<title>Graph Capsule Convolutional Neural Networks. (arXiv:1805.08090v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1805.08090</link>
<description rdf:parseType="Literal">&lt;p&gt;Graph Convolutional Neural Networks (GCNNs) are the most recent exciting
advancement in deep learning field and their applications are quickly spreading
in multi-cross-domains including bioinformatics, chemoinformatics, social
networks, natural language processing and computer vision. In this paper, we
expose and tackle some of the basic weaknesses of a GCNN model with a capsule
idea presented in \cite{hinton2011transforming} and propose our Graph Capsule
Network (GCAPS-CNN) model. In addition, we design our GCAPS-CNN model to solve
especially graph classification problem which current GCNN models find
challenging. Through extensive experiments, we show that our proposed Graph
Capsule Network can significantly outperforms both the existing state-of-art
deep learning methods and graph kernels on graph classification benchmark
datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Verma_S/0/1/0/all/0/1&quot;&gt;Saurabh Verma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhang_Z/0/1/0/all/0/1&quot;&gt;Zhi-Li Zhang&lt;/a&gt;</dc:creator>
</item></rdf:RDF>