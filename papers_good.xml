<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Good papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Good Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-02-27T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09660"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09913"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09941"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.00948"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09612"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09669"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09728"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09914"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09924"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.10054"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1705.01196"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1707.04402"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05844"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09583"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09707"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09725"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09732"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09750"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09777"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09791"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09802"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09901"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09979"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1705.04977"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.06424"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08195"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1802.09660">
<title>Computational Red Teaming in a Sudoku Solving Context: Neural Network Based Skill Representation and Acquisition. (arXiv:1802.09660v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.09660</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper we provide an insight into the skill representation, where
skill representation is seen as an essential part of the skill assessment stage
in the Computational Red Teaming process. Skill representation is demonstrated
in the context of Sudoku puzzle, for which the real human skills used in Sudoku
solving, along with their acquisition, are represented computationally in a
cognitively plausible manner, by using feed-forward neural networks with
back-propagation, and supervised learning. The neural network based skills are
then coupled with a hard-coded constraint propagation computational Sudoku
solver, in which the solving sequence is kept hard-coded, and the skills are
represented through neural networks. The paper demonstrates that the modified
solver can achieve different levels of proficiency, depending on the amount of
skills acquired through the neural networks. Results are encouraging for
developing more complex skill and skill acquisition models usable in general
frameworks related to the skill assessment aspect of Computational Red Teaming.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leu_G/0/1/0/all/0/1&quot;&gt;George Leu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abbass_H/0/1/0/all/0/1&quot;&gt;Hussein Abbass&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09913">
<title>Multi-task Learning of Pairwise Sequence Classification Tasks Over Disparate Label Spaces. (arXiv:1802.09913v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1802.09913</link>
<description rdf:parseType="Literal">&lt;p&gt;We combine multi-task learning and semi-supervised learning by inducing a
joint embedding space between disparate label spaces and learning transfer
functions between label embeddings, enabling us to jointly leverage unlabelled
data and auxiliary, annotated datasets. We evaluate our approach on a variety
of sequence classification tasks with disparate label spaces. We outperform
strong single and multi-task baselines and achieve a new state-of-the-art for
aspect- and topic-based sentiment analysis.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Augenstein_I/0/1/0/all/0/1&quot;&gt;Isabelle Augenstein&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ruder_S/0/1/0/all/0/1&quot;&gt;Sebastian Ruder&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sogaard_A/0/1/0/all/0/1&quot;&gt;Anders S&amp;#xf8;gaard&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09941">
<title>Demystifying Parallel and Distributed Deep Learning: An In-Depth Concurrency Analysis. (arXiv:1802.09941v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.09941</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep Neural Networks (DNNs) are becoming an important tool in modern
computing applications. Accelerating their training is a major challenge and
techniques range from distributed algorithms to low-level circuit design. In
this survey, we describe the problem from a theoretical perspective, followed
by approaches for its parallelization. Specifically, we present trends in DNN
architectures and the resulting implications on parallelization strategies. We
discuss the different types of concurrency in DNNs; synchronous and
asynchronous stochastic gradient descent; distributed system architectures;
communication schemes; and performance modeling. Based on these approaches, we
extrapolate potential directions for parallelism in deep learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ben_Nun_T/0/1/0/all/0/1&quot;&gt;Tal Ben-Nun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hoefler_T/0/1/0/all/0/1&quot;&gt;Torsten Hoefler&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.00948">
<title>Hierarchical Actor-Critic. (arXiv:1712.00948v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1712.00948</link>
<description rdf:parseType="Literal">&lt;p&gt;The ability to learn at different resolutions in time may help overcome one
of the main challenges in deep reinforcement learning -- sample efficiency.
Hierarchical agents that operate at different levels of temporal abstraction
can learn tasks more quickly because they can divide the work of learning
behaviors among multiple policies and can also explore the environment at a
higher level. In this paper, we present a novel approach to hierarchical
reinforcement learning called Hierarchical Actor-Critic (HAC) that enables
agents to learn to break down problems involving continuous action spaces into
simpler subproblems belonging to different time scales. HAC has two key
advantages over most existing hierarchical learning methods: (i) the potential
for faster learning as agents learn short policies at each level of the
hierarchy and (ii) an end-to-end approach. We demonstrate that HAC
significantly accelerates learning in a series of tasks that require behavior
over a relatively long time horizon and involve sparse rewards.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Levy_A/0/1/0/all/0/1&quot;&gt;Andrew Levy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Platt_R/0/1/0/all/0/1&quot;&gt;Robert Platt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saenko_K/0/1/0/all/0/1&quot;&gt;Kate Saenko&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09612">
<title>MILE: A Multi-Level Framework for Scalable Graph Embedding. (arXiv:1802.09612v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.09612</link>
<description rdf:parseType="Literal">&lt;p&gt;Recently there has been a surge of interest in designing graph embedding
methods. Few, if any, can scale to a large-sized graph with millions of nodes
due to both computational complexity and memory requirements. In this paper, we
relax this limitation by introducing the MultI-Level Embedding (MILE) framework
-- a generic methodology allowing contemporary graph embedding methods to scale
to large graphs. MILE repeatedly coarsens the graph into smaller ones using a
hybrid matching technique to maintain the backbone structure of the graph. It
then applies existing embedding methods on the coarsest graph and refines the
embeddings to the original graph through a novel graph convolution neural
network that it learns. The proposed MILE framework is agnostic to the
underlying graph embedding techniques and can be applied to many existing graph
embedding methods without modifying them. We employ our framework on several
popular graph embedding techniques and conduct embedding for real-world graphs.
Experimental results on five large-scale datasets demonstrate that MILE
significantly boosts the speed (order of magnitude) of graph embedding while
also often generating embeddings of better quality for the task of node
classification. MILE can comfortably scale to a graph with 9 million nodes and
40 million edges, on which existing methods run out of memory or take too long
to compute on a modern workstation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_J/0/1/0/all/0/1&quot;&gt;Jiongqian Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gurukar_S/0/1/0/all/0/1&quot;&gt;Saket Gurukar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Parthasarathy_S/0/1/0/all/0/1&quot;&gt;Srinivasan Parthasarathy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09669">
<title>A Multi-Disciplinary Review of Knowledge Acquisition Methods: From Human to Autonomous Eliciting Agents. (arXiv:1802.09669v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.09669</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper offers a multi-disciplinary review of knowledge acquisition
methods in human activity systems. The review captures the degree of
involvement of various types of agencies in the knowledge acquisition process,
and proposes a classification with three categories of methods: the human
agent, the human-inspired agent, and the autonomous machine agent methods. In
the first two categories, the acquisition of knowledge is seen as a cognitive
task analysis exercise, while in the third category knowledge acquisition is
treated as an autonomous knowledge-discovery endeavour. The motivation for this
classification stems from the continuous change over time of the structure,
meaning and purpose of human activity systems, which are seen as the factor
that fuelled researchers&apos; and practitioners&apos; efforts in knowledge acquisition
for more than a century.
&lt;/p&gt;
&lt;p&gt;We show through this review that the KA field is increasingly active due to
the higher and higher pace of change in human activity, and conclude by
discussing the emergence of a fourth category of knowledge acquisition methods,
which are based on red-teaming and co-evolution.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leu_G/0/1/0/all/0/1&quot;&gt;George Leu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abbass_H/0/1/0/all/0/1&quot;&gt;Hussein Abbass&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09728">
<title>Modelling and Analysis of Temporal Preference Drifts Using A Component-Based Factorised Latent Approach. (arXiv:1802.09728v1 [cs.IR])</title>
<link>http://arxiv.org/abs/1802.09728</link>
<description rdf:parseType="Literal">&lt;p&gt;The changes in user preferences can originate from substantial reasons, like
personality shift, or transient and circumstantial ones, like seasonal changes
in item popularities. Disregarding these temporal drifts in modelling user
preferences can result in unhelpful recommendations. Moreover, different
temporal patterns can be associated with various preference domains, and
preference components and their combinations. These components comprise
preferences over features, preferences over feature values, conditional
dependencies between features, socially-influenced preferences, and bias. For
example, in the movies domain, the user can change his rating behaviour (bias
shift), her preference for genre over language (feature preference shift), or
start favouring drama over comedy (feature value preference shift). In this
paper, we first propose a novel latent factor model to capture the
domain-dependent component-specific temporal patterns in preferences. The
component-based approach followed in modelling the aspects of preferences and
their temporal effects enables us to arbitrarily switch components on and off.
We evaluate the proposed method on three popular recommendation datasets and
show that it significantly outperforms the most accurate state-of-the-art
static models. The experiments also demonstrate the greater robustness and
stability of the proposed dynamic model in comparison with the most successful
models to date. We also analyse the temporal behaviour of different preference
components and their combinations and show that the dynamic behaviour of
preference components is highly dependent on the preference dataset and domain.
Therefore, the results also highlight the importance of modelling temporal
effects but also underline the advantages of a component-based architecture
that is better suited to capture domain-specific balances in the contributions
of the aspects.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zafari_F/0/1/0/all/0/1&quot;&gt;F. Zafari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moser_I/0/1/0/all/0/1&quot;&gt;I. Moser&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Baarslag_T/0/1/0/all/0/1&quot;&gt;T. Baarslag&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09914">
<title>High-Dimensional Vector Semantics. (arXiv:1802.09914v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1802.09914</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper we explore the &quot;vector semantics&quot; problem from the perspective
of &quot;almost orthogonal&quot; property of high-dimensional random vectors. We show
that this intriguing property can be used to &quot;memorize&quot; random vectors by
simply adding them, and we provide an efficient probabilistic solution to the
set membership problem. Also, we discuss several applications to word context
vector embeddings, document sentences similarity, and spam filtering.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Andrecut_M/0/1/0/all/0/1&quot;&gt;M. Andrecut&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09924">
<title>Introduction to the SP theory of intelligence. (arXiv:1802.09924v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.09924</link>
<description rdf:parseType="Literal">&lt;p&gt;This article provides a brief introduction to the &quot;Theory of Intelligence&quot;
and its realisation in the &quot;SP Computer Model&quot;. The overall goal of the SP
programme of research, in accordance with long-established principles in
science, has been the simplification and integration of observations and
concepts across artificial intelligence, mainstream computing, mathematics, and
human learning, perception, and cognition. In broad terms, the SP system is a
brain-like system that takes in &quot;New&quot; information through its senses and stores
some or all of it as &quot;Old&quot; information. A central idea in the system is the
powerful concept of &quot;SP-multiple-alignment&quot;, borrowed and adapted from
bioinformatics. This the key to the system&apos;s versatility in aspects of
intelligence, in the representation of diverse kinds of knowledge, and in the
seamless integration of diverse aspects of intelligence and diverse kinds of
knowledge, in any combination. There are many potential benefits and
applications of the SP system. It is envisaged that the system will be
developed as the &quot;SP Machine&quot;, which will initially be a software virtual
machine, hosted on a high-performance computer, a vehicle for further research
and a step towards the development of an industrial-strength SP Machine.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wolff_J/0/1/0/all/0/1&quot;&gt;J Gerard Wolff&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.10054">
<title>Domain Modelling in Computational Persuasion for Behaviour Change in Healthcare. (arXiv:1802.10054v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.10054</link>
<description rdf:parseType="Literal">&lt;p&gt;The aim of behaviour change is to help people to change aspects of their
behaviour for the better (e.g., to decrease calorie intake, to drink in
moderation, to take more exercise, to complete a course of antibiotics once
started, etc.). In current persuasion technology for behaviour change, the
emphasis is on helping people to explore their issues (e.g., through
questionnaires or game playing) or to remember to follow a behaviour change
plan (e.g., diaries and email reminders). However, recent developments in
computational persuasion are leading to an argument-centric approach to
persuasion that can potentially be harnessed in behaviour change applications.
In this paper, we review developments in computational persuasion, and then
focus on domain modelling as a key component. We present a multi-dimensional
approach to domain modelling. At the core of this proposal is an ontology which
provides a representation of key factors, in particular kinds of belief, which
we have identified in the behaviour change literature as being important in
diverse behaviour change initiatives. Our proposal for domain modelling is
intended to facilitate the acquisition and representation of the arguments that
can be used in persuasion dialogues, together with meta-level information about
them which can be used by the persuader to make strategic choices of argument
to present.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chalaguine_L/0/1/0/all/0/1&quot;&gt;Lisa Chalaguine&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hadoux_E/0/1/0/all/0/1&quot;&gt;Emmanuel Hadoux&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hamilton_F/0/1/0/all/0/1&quot;&gt;Fiona Hamilton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hayward_A/0/1/0/all/0/1&quot;&gt;Andrew Hayward&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hunter_A/0/1/0/all/0/1&quot;&gt;Anthony Hunter&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Polberg_S/0/1/0/all/0/1&quot;&gt;Sylwia Polberg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Potts_H/0/1/0/all/0/1&quot;&gt;Henry W. W. Potts&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1705.01196">
<title>Navigating Occluded Intersections with Autonomous Vehicles using Deep Reinforcement Learning. (arXiv:1705.01196v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1705.01196</link>
<description rdf:parseType="Literal">&lt;p&gt;Providing an efficient strategy to navigate safely through unsignaled
intersections is a difficult task that requires determining the intent of other
drivers. We explore the effectiveness of Deep Reinforcement Learning to handle
intersection problems. Using recent advances in Deep RL, we are able to learn
policies that surpass the performance of a commonly-used heuristic approach in
several metrics including task completion time and goal success rate and have
limited ability to generalize. We then explore a system&apos;s ability to learn
active sensing behaviors to enable navigating safely in the case of occlusions.
Our analysis, provides insight into the intersection handling problem, the
solutions learned by the network point out several shortcomings of current
rule-based methods, and the failures of our current deep reinforcement learning
system point to future research directions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Isele_D/0/1/0/all/0/1&quot;&gt;David Isele&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rahimi_R/0/1/0/all/0/1&quot;&gt;Reza Rahimi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cosgun_A/0/1/0/all/0/1&quot;&gt;Akansel Cosgun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Subramanian_K/0/1/0/all/0/1&quot;&gt;Kaushik Subramanian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fujimura_K/0/1/0/all/0/1&quot;&gt;Kikuo Fujimura&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1707.04402">
<title>Lenient Multi-Agent Deep Reinforcement Learning. (arXiv:1707.04402v2 [cs.MA] UPDATED)</title>
<link>http://arxiv.org/abs/1707.04402</link>
<description rdf:parseType="Literal">&lt;p&gt;Much of the success of single agent deep reinforcement learning (DRL) in
recent years can be attributed to the use of experience replay memories (ERM),
which allow Deep Q-Networks (DQNs) to be trained efficiently through sampling
stored state transitions. However, care is required when using ERMs for
multi-agent deep reinforcement learning (MA-DRL), as stored transitions can
become outdated because agents update their policies in parallel [11]. In this
work we apply leniency [23] to MA-DRL. Lenient agents map state-action pairs to
decaying temperature values that control the amount of leniency applied towards
negative policy updates that are sampled from the ERM. This introduces optimism
in the value-function update, and has been shown to facilitate cooperation in
tabular fully-cooperative multi-agent reinforcement learning problems. We
evaluate our Lenient-DQN (LDQN) empirically against the related Hysteretic-DQN
(HDQN) algorithm [22] as well as a modified version we call scheduled-HDQN,
that uses average reward learning near terminal states. Evaluations take place
in extended variations of the Coordinated Multi-Agent Object Transportation
Problem (CMOTP) [8] which include fully-cooperative sub-tasks and stochastic
rewards. We find that LDQN agents are more likely to converge to the optimal
policy in a stochastic reward CMOTP compared to standard and scheduled-HDQN
agents.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Palmer_G/0/1/0/all/0/1&quot;&gt;Gregory Palmer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tuyls_K/0/1/0/all/0/1&quot;&gt;Karl Tuyls&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bloembergen_D/0/1/0/all/0/1&quot;&gt;Daan Bloembergen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Savani_R/0/1/0/all/0/1&quot;&gt;Rahul Savani&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05844">
<title>A Unified View of Causal and Non-causal Feature Selection. (arXiv:1802.05844v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1802.05844</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we unify causal and non-causal feature selection methods based
on the Bayesian network framework. We first show that the objectives of causal
and non-causal feature selection methods are equal and are to find the Markov
blanket of a class attribute, the theoretically optimal feature set for
classification. We demonstrate that causal and non-causal feature selection
take different assumptions of dependency among features to find Markov blanket,
and their algorithms are shown different level of approximation for finding
Markov blanket. In this framework, we are able to analyze the sample and error
bounds of casual and non-causal methods. We conducted extensive experiments to
show the correctness of our theoretical analysis.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_K/0/1/0/all/0/1&quot;&gt;Kui Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1&quot;&gt;Lin Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jiuyong Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09583">
<title>Data-dependent PAC-Bayes priors via differential privacy. (arXiv:1802.09583v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.09583</link>
<description rdf:parseType="Literal">&lt;p&gt;The Probably Approximately Correct (PAC) Bayes framework (McAllester, 1999)
can incorporate knowledge about the learning algorithm and data distribution
through the use of distribution-dependent priors, yielding tighter
generalization bounds on data-dependent posteriors. Using this flexibility,
however, is difficult, especially when the data distribution is presumed to be
unknown. We show how an {\epsilon}-differentially private data-dependent prior
yields a valid PAC-Bayes bound, and then show how non-private mechanisms for
choosing priors obtain the same generalization bound provided they converge
weakly to the private mechanism. As an application of this result, we show that
a Gaussian prior mean chosen via stochastic gradient Langevin dynamics (SGLD;
Welling and Teh, 2011) leads to a valid PAC-Bayes bound, despite SGLD only
converging weakly to an {\epsilon}-differentially private mechanism. As the
bounds are data-dependent, we study the bounds empirically on synthetic data
and standard neural network benchmarks in order to illustrate the gains of
data-dependent priors over existing distribution-dependent PAC-Bayes bound.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dziugaite_G/0/1/0/all/0/1&quot;&gt;Gintare Karolina Dziugaite&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roy_D/0/1/0/all/0/1&quot;&gt;Daniel M. Roy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09707">
<title>Understanding and Enhancing the Transferability of Adversarial Examples. (arXiv:1802.09707v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.09707</link>
<description rdf:parseType="Literal">&lt;p&gt;State-of-the-art deep neural networks are known to be vulnerable to
adversarial examples, formed by applying small but malicious perturbations to
the original inputs. Moreover, the perturbations can \textit{transfer across
models}: adversarial examples generated for a specific model will often mislead
other unseen models. Consequently the adversary can leverage it to attack
deployed systems without any query, which severely hinder the application of
deep learning, especially in the areas where security is crucial. In this work,
we systematically study how two classes of factors that might influence the
transferability of adversarial examples. One is about model-specific factors,
including network architecture, model capacity and test accuracy. The other is
the local smoothness of loss function for constructing adversarial examples.
Based on these understanding, a simple but effective strategy is proposed to
enhance transferability. We call it variance-reduced attack, since it utilizes
the variance-reduced gradient to generate adversarial example. The
effectiveness is confirmed by a variety of experiments on both CIFAR-10 and
ImageNet datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wu_L/0/1/0/all/0/1&quot;&gt;Lei Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhu_Z/0/1/0/all/0/1&quot;&gt;Zhanxing Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tai_C/0/1/0/all/0/1&quot;&gt;Cheng Tai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+E_W/0/1/0/all/0/1&quot;&gt;Weinan E&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09725">
<title>High-dimensional ABC. (arXiv:1802.09725v1 [stat.CO])</title>
<link>http://arxiv.org/abs/1802.09725</link>
<description rdf:parseType="Literal">&lt;p&gt;This Chapter, &quot;High-dimensional ABC&quot;, is to appear in the forthcoming
Handbook of Approximate Bayesian Computation (2018). It details the main ideas
and concepts behind extending ABC methods to higher dimensions, with supporting
examples and illustrations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Nott_D/0/1/0/all/0/1&quot;&gt;D. J. Nott&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ong_V/0/1/0/all/0/1&quot;&gt;V. M.-H. Ong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Fan_Y/0/1/0/all/0/1&quot;&gt;Y. Fan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sisson_S/0/1/0/all/0/1&quot;&gt;S. A. Sisson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09732">
<title>Online learning with kernel losses. (arXiv:1802.09732v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.09732</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a generalization of the adversarial linear bandits framework,
where the underlying losses are kernel functions (with an associated
reproducing kernel Hilbert space) rather than linear functions. We study a
version of the exponential weights algorithm and bound its regret in this
setting. Under conditions on the eigendecay of the kernel we provide a sharp
characterization of the regret for this algorithm. When we have polynomial
eigendecay $\mu_j \le \mathcal{O}(j^{-\beta})$, we find that the regret is
bounded by $\mathcal{R}_n \le \mathcal{O}(n^{\beta/(2(\beta-1))})$; while under
the assumption of exponential eigendecay $\mu_j \le \mathcal{O}(e^{-\beta j
})$, we get an even tighter bound on the regret $\mathcal{R}_n \le
\mathcal{O}(n^{1/2}\log(n)^{1/2})$. We also study the full information setting
when the underlying losses are kernel functions and present an adapted
exponential weights algorithm and a conditional gradient descent algorithm.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pacchiano_A/0/1/0/all/0/1&quot;&gt;Aldo Pacchiano&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chatterji_N/0/1/0/all/0/1&quot;&gt;Niladri S. Chatterji&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bartlett_P/0/1/0/all/0/1&quot;&gt;Peter L. Bartlett&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09750">
<title>Train Feedfoward Neural Network with Layer-wise Adaptive Rate via Approximating Back-matching Propagation. (arXiv:1802.09750v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.09750</link>
<description rdf:parseType="Literal">&lt;p&gt;Stochastic gradient descent (SGD) has achieved great success in training deep
neural network, where the gradient is computed through back-propagation.
However, the back-propagated values of different layers vary dramatically. This
inconsistence of gradient magnitude across different layers renders
optimization of deep neural network with a single learning rate problematic. We
introduce the back-matching propagation which computes the backward values on
the layer&apos;s parameter and the input by matching backward values on the layer&apos;s
output. This leads to solving a bunch of least-squares problems, which requires
high computational cost. We then reduce the back-matching propagation with
approximations and propose an algorithm that turns to be the regular SGD with a
layer-wise adaptive learning rate strategy. This allows an easy implementation
of our algorithm in current machine learning frameworks equipped with
auto-differentiation. We apply our algorithm in training modern deep neural
networks and achieve favorable results over SGD.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhang_H/0/1/0/all/0/1&quot;&gt;Huishuai Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chen_W/0/1/0/all/0/1&quot;&gt;Wei Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Liu_T/0/1/0/all/0/1&quot;&gt;Tie-Yan Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09777">
<title>Gaussian meta-embeddings for efficient scoring of a heavy-tailed PLDA model. (arXiv:1802.09777v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.09777</link>
<description rdf:parseType="Literal">&lt;p&gt;Embeddings in machine learning are low-dimensional representations of complex
input patterns, with the property that simple geometric operations like
Euclidean distances and dot products can be used for classification and
comparison tasks. The proposed meta-embeddings are special embeddings that live
in more general inner product spaces. They are designed to propagate
uncertainty to the final output in speaker recognition and similar
applications. The familiar Gaussian PLDA model (GPLDA) can be re-formulated as
an extractor for Gaussian meta-embeddings (GMEs), such that likelihood ratio
scores are given by Hilbert space inner products between Gaussian likelihood
functions. GMEs extracted by the GPLDA model have fixed precisions and do not
propagate uncertainty. We show that a generalization to heavy-tailed PLDA gives
GMEs with variable precisions, which do propagate uncertainty. Experiments on
NIST SRE 2010 and 2016 show that the proposed method applied to i-vectors
without length normalization is up to 20% more accurate than GPLDA applied to
length-normalized ivectors.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Brummer_N/0/1/0/all/0/1&quot;&gt;Niko Brummer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Silnova_A/0/1/0/all/0/1&quot;&gt;Anna Silnova&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Burget_L/0/1/0/all/0/1&quot;&gt;Lukas Burget&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Stafylakis_T/0/1/0/all/0/1&quot;&gt;Themos Stafylakis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09791">
<title>Bioinformatics and Medicine in the Era of Deep Learning. (arXiv:1802.09791v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.09791</link>
<description rdf:parseType="Literal">&lt;p&gt;Many of the current scientific advances in the life sciences have their
origin in the intensive use of data for knowledge discovery. In no area this is
so clear as in bioinformatics, led by technological breakthroughs in data
acquisition technologies. It has been argued that bioinformatics could quickly
become the field of research generating the largest data repositories, beating
other data-intensive areas such as high-energy physics or astroinformatics.
Over the last decade, deep learning has become a disruptive advance in machine
learning, giving new live to the long-standing connectionist paradigm in
artificial intelligence. Deep learning methods are ideally suited to
large-scale data and, therefore, they should be ideally suited to knowledge
discovery in bioinformatics and biomedicine at large. In this brief paper, we
review key aspects of the application of deep learning in bioinformatics and
medicine, drawing from the themes covered by the contributions to an ESANN 2018
special session devoted to this topic.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bacciu_D/0/1/0/all/0/1&quot;&gt;Davide Bacciu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lisboa_P/0/1/0/all/0/1&quot;&gt;Paulo J.G. Lisboa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Martin_J/0/1/0/all/0/1&quot;&gt;Jos&amp;#xe9; D. Mart&amp;#xed;n&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stoean_R/0/1/0/all/0/1&quot;&gt;Ruxandra Stoean&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vellido_A/0/1/0/all/0/1&quot;&gt;Alfredo Vellido&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09802">
<title>Matching Convolutional Neural Networks without Priors about Data. (arXiv:1802.09802v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.09802</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose an extension of Convolutional Neural Networks (CNNs) to
graph-structured data, including strided convolutions and data augmentation on
graphs.
&lt;/p&gt;
&lt;p&gt;Our method matches the accuracy of state-of-the-art CNNs when applied on
images, without any prior about their 2D regular structure.
&lt;/p&gt;
&lt;p&gt;On fMRI data, we obtain a significant gain in accuracy compared with existing
graph-based alternatives.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lassance_C/0/1/0/all/0/1&quot;&gt;Carlos Eduardo Rosar Kos Lassance&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vialatte_J/0/1/0/all/0/1&quot;&gt;Jean-Charles Vialatte&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gripon_V/0/1/0/all/0/1&quot;&gt;Vincent Gripon&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09901">
<title>Learning to recognize touch gestures: recurrent vs. convolutional features and dynamic sampling. (arXiv:1802.09901v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.09901</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a fully automatic method for learning gestures on big touch
devices in a potentially multi-user context. The goal is to learn general
models capable of adapting to different gestures, user styles and hardware
variations (e.g. device sizes, sampling frequencies and regularities).
&lt;/p&gt;
&lt;p&gt;Based on deep neural networks, our method features a novel dynamic sampling
and temporal normalization component, transforming variable length gestures
into fixed length representations while preserving finger/surface contact
transitions, that is, the topology of the signal. This sequential
representation is then processed with a convolutional model capable, unlike
recurrent networks, of learning hierarchical representations with different
levels of abstraction.
&lt;/p&gt;
&lt;p&gt;To demonstrate the interest of the proposed method, we introduce a new touch
gestures dataset with 6591 gestures performed by 27 people, which is, up to our
knowledge, the first of its kind: a publicly available multi-touch gesture
dataset for interaction.
&lt;/p&gt;
&lt;p&gt;We also tested our method on a standard dataset of symbolic touch gesture
recognition, the MMG dataset, outperforming the state of the art and reporting
close to perfect performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Debard_Q/0/1/0/all/0/1&quot;&gt;Quentin Debard&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wolf_C/0/1/0/all/0/1&quot;&gt;Christian Wolf&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Canu_S/0/1/0/all/0/1&quot;&gt;St&amp;#xe9;phane Canu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Arne_J/0/1/0/all/0/1&quot;&gt;Julien Arn&amp;#xe9;&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09979">
<title>The Emergence of Spectral Universality in Deep Networks. (arXiv:1802.09979v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.09979</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent work has shown that tight concentration of the entire spectrum of
singular values of a deep network&apos;s input-output Jacobian around one at
initialization can speed up learning by orders of magnitude. Therefore, to
guide important design choices, it is important to build a full theoretical
understanding of the spectra of Jacobians at initialization. To this end, we
leverage powerful tools from free probability theory to provide a detailed
analytic understanding of how a deep network&apos;s Jacobian spectrum depends on
various hyperparameters including the nonlinearity, the weight and bias
distributions, and the depth. For a variety of nonlinearities, our work reveals
the emergence of new universal limiting spectral distributions that remain
concentrated around one even as the depth goes to infinity.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pennington_J/0/1/0/all/0/1&quot;&gt;Jeffrey Pennington&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Schoenholz_S/0/1/0/all/0/1&quot;&gt;Samuel S. Schoenholz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ganguli_S/0/1/0/all/0/1&quot;&gt;Surya Ganguli&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1705.04977">
<title>Detecting Statistical Interactions from Neural Network Weights. (arXiv:1705.04977v4 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1705.04977</link>
<description rdf:parseType="Literal">&lt;p&gt;Interpreting neural networks is a crucial and challenging task in machine
learning. In this paper, we develop a novel framework for detecting statistical
interactions captured by a feedforward multilayer neural network by directly
interpreting its learned weights. Depending on the desired interactions, our
method can achieve significantly better or similar interaction detection
performance compared to the state-of-the-art without searching an exponential
solution space of possible interactions. We obtain this accuracy and efficiency
by observing that interactions between input features are created by the
non-additive effect of nonlinear activation functions, and that interacting
paths are encoded in weight matrices. We demonstrate the performance of our
method and the importance of discovered interactions via experimental results
on both synthetic datasets and real-world application datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tsang_M/0/1/0/all/0/1&quot;&gt;Michael Tsang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Cheng_D/0/1/0/all/0/1&quot;&gt;Dehua Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yan Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.06424">
<title>A Resizable Mini-batch Gradient Descent based on a Multi-Armed Bandit. (arXiv:1711.06424v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1711.06424</link>
<description rdf:parseType="Literal">&lt;p&gt;Determining the appropriate batch size for mini-batch gradient descent is
always time consuming as it often relies on grid search. This paper considers a
resizable mini-batch gradient descent (RMGD) algorithm based on a multi-armed
bandit for achieving best performance in grid search by selecting an
appropriate batch size at each epoch with a probability defined as a function
of its previous success/failure. This probability encourages exploration of
different batch size and then later exploitation of batch size with history of
success. At each epoch, the RMGD samples a batch size from its probability
distribution, then uses the selected batch size for mini-batch gradient
descent. After obtaining the validation loss at each epoch, the probability
distribution is updated to incorporate the effectiveness of the sampled batch
size. The RMGD essentially assists the learning process to explore the possible
domain of the batch size and exploit successful batch size. Experimental
results show that the RMGD achieves performance better than the best performing
single batch size. Furthermore, it, obviously, attains this performance in a
shorter amount of time than grid search. It is surprising that the RMGD
achieves better performance than grid search.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Cho_S/0/1/0/all/0/1&quot;&gt;Seong Jin Cho&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kang_S/0/1/0/all/0/1&quot;&gt;Sunghun Kang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yoo_C/0/1/0/all/0/1&quot;&gt;Chang D. Yoo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08195">
<title>Adversarial Examples that Fool both Human and Computer Vision. (arXiv:1802.08195v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1802.08195</link>
<description rdf:parseType="Literal">&lt;p&gt;Machine learning models are vulnerable to adversarial examples: small changes
to images can cause computer vision models to make mistakes such as identifying
a school bus as an ostrich. However, it is still an open question whether
humans are prone to similar mistakes. Here, we create the first adversarial
examples designed to fool humans, by leveraging recent techniques that transfer
adversarial examples from computer vision models with known parameters and
architecture to other models with unknown parameters and architecture, and by
modifying models to more closely match the initial processing of the human
visual system. We find that adversarial examples that strongly transfer across
computer vision models influence the classifications made by time-limited human
observers.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Elsayed_G/0/1/0/all/0/1&quot;&gt;Gamaleldin F. Elsayed&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shankar_S/0/1/0/all/0/1&quot;&gt;Shreya Shankar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheung_B/0/1/0/all/0/1&quot;&gt;Brian Cheung&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Papernot_N/0/1/0/all/0/1&quot;&gt;Nicolas Papernot&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kurakin_A/0/1/0/all/0/1&quot;&gt;Alex Kurakin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goodfellow_I/0/1/0/all/0/1&quot;&gt;Ian Goodfellow&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sohl_Dickstein_J/0/1/0/all/0/1&quot;&gt;Jascha Sohl-Dickstein&lt;/a&gt;</dc:creator>
</item></rdf:RDF>