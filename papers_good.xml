<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Good papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Good Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-01-23T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.07353"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.07546"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.07648"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.07537"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1703.00955"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.07316"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.07508"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.07606"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1707.01217"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.02642"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1801.07353">
<title>Flexible Deep Neural Network Processing. (arXiv:1801.07353v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1801.07353</link>
<description rdf:parseType="Literal">&lt;p&gt;The recent success of Deep Neural Networks (DNNs) has drastically improved
the state of the art for many application domains. While achieving high
accuracy performance, deploying state-of-the-art DNNs is a challenge since they
typically require billions of expensive arithmetic computations. In addition,
DNNs are typically deployed in ensemble to boost accuracy performance, which
further exacerbates the system requirements. This computational overhead is an
issue for many platforms, e.g. data centers and embedded systems, with tight
latency and energy budgets. In this article, we introduce flexible DNNs
ensemble processing technique, which achieves large reduction in average
inference latency while incurring small to negligible accuracy drop. Our
technique is flexible in that it allows for dynamic adaptation between quality
of results (QoR) and execution runtime. We demonstrate the effectiveness of the
technique on AlexNet and ResNet-50 using the ImageNet dataset. This technique
can also easily handle other types of networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tann_H/0/1/0/all/0/1&quot;&gt;Hokchhay Tann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hashemi_S/0/1/0/all/0/1&quot;&gt;Soheil Hashemi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Reda_S/0/1/0/all/0/1&quot;&gt;Sherief Reda&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.07546">
<title>Hyper-heuristics Can Achieve Optimal Performance for Pseudo-Boolean Optimisation. (arXiv:1801.07546v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1801.07546</link>
<description rdf:parseType="Literal">&lt;p&gt;Selection hyper-heuristics are randomised search methodologies which choose
and execute heuristics from a set of low-level heuristics. Recent research for
the LeadingOnes benchmark function has shown that the standard Simple Random,
Permutation, Random Gradient, Greedy and Reinforcement Learning selection
mechanisms show no effects of learning. The idea behind the learning mechanisms
is to continue to exploit the currently selected heuristic as long as it is
successful. However, the probability that a promising heuristic is successful
in the next step is relatively low when perturbing a reasonable solution to a
combinatorial optimisation problem. In this paper we generalise the `simple&apos;
selection-perturbation mechanisms so success can be measured over some fixed
period of time tau, rather than in a single iteration. We present a benchmark
function where it is necessary to learn to exploit a particular low-level
heuristic, rigorously proving that it makes the difference between an efficient
and an inefficient algorithm. For LeadingOnes we prove that the Generalised
Random Gradient, and the Generalised Greedy Gradient hyper-heuristics achieve
optimal performance, while Generalised Greedy, although not as fast, still
outperforms Random Local Search. The performance of the former two
hyper-heuristics improves as the number of operators to choose from increases,
while that of the Generalised Greedy hyper-heuristic does not. Experimental
analyses confirm these results for realistic problem sizes and shed some light
on the best choices of the parameter tau in various situations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lissovoi_A/0/1/0/all/0/1&quot;&gt;Andrei Lissovoi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oliveto_P/0/1/0/all/0/1&quot;&gt;Pietro S. Oliveto&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Warwicker_J/0/1/0/all/0/1&quot;&gt;John Alasdair Warwicker&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.07648">
<title>Clustering with Deep Learning: Taxonomy and New Methods. (arXiv:1801.07648v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1801.07648</link>
<description rdf:parseType="Literal">&lt;p&gt;Clustering is a fundamental machine learning method. The quality of its
results is dependent on the data distribution. For this reason, deep neural
networks can be used for learning better representations of the data. In this
paper, we propose a systematic taxonomy for clustering with deep learning, in
addition to a review of methods from the field. Based on our taxonomy, creating
new methods is more straightforward. We also propose a new approach which is
built on the taxonomy and surpasses some of the limitations of some previous
work. Our experimental evaluation on image datasets shows that the method
approaches state-of-the-art clustering quality, and performs better in some
cases.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aljalbout_E/0/1/0/all/0/1&quot;&gt;Elie Aljalbout&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Golkov_V/0/1/0/all/0/1&quot;&gt;Vladimir Golkov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Siddiqui_Y/0/1/0/all/0/1&quot;&gt;Yawar Siddiqui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cremers_D/0/1/0/all/0/1&quot;&gt;Daniel Cremers&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.07537">
<title>Analyzing Language Learned by an Active Question Answering Agent. (arXiv:1801.07537v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1801.07537</link>
<description rdf:parseType="Literal">&lt;p&gt;We analyze the language learned by an agent trained with reinforcement
learning as a component of the ActiveQA system [Buck et al., 2017]. In
ActiveQA, question answering is framed as a reinforcement learning task in
which an agent sits between the user and a black box question-answering system.
The agent learns to reformulate the user&apos;s questions to elicit the optimal
answers. It probes the system with many versions of a question that are
generated via a sequence-to-sequence question reformulation model, then
aggregates the returned evidence to find the best answer. This process is an
instance of \emph{machine-machine} communication. The question reformulation
model must adapt its language to increase the quality of the answers returned,
matching the language of the question answering system. We find that the agent
does not learn transformations that align with semantic intuitions but
discovers through learning classical information retrieval techniques such as
tf-idf re-weighting and stemming.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Buck_C/0/1/0/all/0/1&quot;&gt;Christian Buck&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bulian_J/0/1/0/all/0/1&quot;&gt;Jannis Bulian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ciaramita_M/0/1/0/all/0/1&quot;&gt;Massimiliano Ciaramita&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gajewski_W/0/1/0/all/0/1&quot;&gt;Wojciech Gajewski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gesmundo_A/0/1/0/all/0/1&quot;&gt;Andrea Gesmundo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Houlsby_N/0/1/0/all/0/1&quot;&gt;Neil Houlsby&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1&quot;&gt;Wei Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1703.00955">
<title>Toward Controlled Generation of Text. (arXiv:1703.00955v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1703.00955</link>
<description rdf:parseType="Literal">&lt;p&gt;Generic generation and manipulation of text is challenging and has limited
success compared to recent deep generative modeling in visual domain. This
paper aims at generating plausible natural language sentences, whose attributes
are dynamically controlled by learning disentangled latent representations with
designated semantics. We propose a new neural generative model which combines
variational auto-encoders and holistic attribute discriminators for effective
imposition of semantic structures. With differentiable approximation to
discrete text samples, explicit constraints on independent attribute controls,
and efficient collaborative learning of generator and discriminators, our model
learns highly interpretable representations from even only word annotations,
and produces realistic sentences with desired attributes. Quantitative
evaluation validates the accuracy of sentence and attribute generation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1&quot;&gt;Zhiting Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1&quot;&gt;Zichao Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_X/0/1/0/all/0/1&quot;&gt;Xiaodan Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Salakhutdinov_R/0/1/0/all/0/1&quot;&gt;Ruslan Salakhutdinov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xing_E/0/1/0/all/0/1&quot;&gt;Eric P. Xing&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.07316">
<title>The Hybrid Bootstrap: A Drop-in Replacement for Dropout. (arXiv:1801.07316v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1801.07316</link>
<description rdf:parseType="Literal">&lt;p&gt;Regularization is an important component of predictive model building. The
hybrid bootstrap is a regularization technique that functions similarly to
dropout except that features are resampled from other training points rather
than replaced with zeros. We show that the hybrid bootstrap offers superior
performance to dropout. We also present a sampling based technique to simplify
hyperparameter choice. Next, we provide an alternative sampling technique for
convolutional neural networks. Finally, we demonstrate the efficacy of the
hybrid bootstrap on non-image tasks using tree-based models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kosar_R/0/1/0/all/0/1&quot;&gt;Robert Kosar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Scott_D/0/1/0/all/0/1&quot;&gt;David W. Scott&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.07508">
<title>Experimentally detecting a quantum change point via Bayesian inference. (arXiv:1801.07508v1 [quant-ph])</title>
<link>http://arxiv.org/abs/1801.07508</link>
<description rdf:parseType="Literal">&lt;p&gt;Detecting a change point is a crucial task in statistics that has been
recently extended to the quantum realm. A source state generator that emits a
series of single photons in a default state suffers an alteration at some point
and starts to emit photons in a mutated state. The problem consists in
identifying the point where the change took place. In this work, we consider a
learning agent that applies Bayesian inference on experimental data to solve
this problem. This learning machine adjusts the measurement over each photon
according to the past experimental results finds the change position in an
online fashion. Our results show that the local-detection success probability
can be largely improved by using such a machine learning technique. This
protocol provides a tool for improvement in many applications where a sequence
of identical quantum states is required.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Yu_S/0/1/0/all/0/1&quot;&gt;Shang Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Huang_C/0/1/0/all/0/1&quot;&gt;Chang-Jiang Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Tang_J/0/1/0/all/0/1&quot;&gt;Jian-Shun Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Jia_Z/0/1/0/all/0/1&quot;&gt;Zhih-Ahn Jia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yi-Tao Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Ke_Z/0/1/0/all/0/1&quot;&gt;Zhi-Jin Ke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Liu_W/0/1/0/all/0/1&quot;&gt;Wei Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Liu_X/0/1/0/all/0/1&quot;&gt;Xiao Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Zhou_Z/0/1/0/all/0/1&quot;&gt;Zong-Quan Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Cheng_Z/0/1/0/all/0/1&quot;&gt;Ze-Di Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Xu_J/0/1/0/all/0/1&quot;&gt;Jin-Shi Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Wu_Y/0/1/0/all/0/1&quot;&gt;Yu-Chun Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Zhao_Y/0/1/0/all/0/1&quot;&gt;Yuan-Yuan Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Xiang_G/0/1/0/all/0/1&quot;&gt;Guo-Yong Xiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Li_C/0/1/0/all/0/1&quot;&gt;Chuan-Feng Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Guo_G/0/1/0/all/0/1&quot;&gt;Guang-Can Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Sentis_G/0/1/0/all/0/1&quot;&gt;Gael Sent&amp;#xed;s&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Munoz_Tapia_R/0/1/0/all/0/1&quot;&gt;Ramon Mu&amp;#xf1;oz-Tapia&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.07606">
<title>Deeper Insights into Graph Convolutional Networks for Semi-Supervised Learning. (arXiv:1801.07606v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1801.07606</link>
<description rdf:parseType="Literal">&lt;p&gt;Many interesting problems in machine learning are being revisited with new
deep learning tools. For graph-based semisupervised learning, a recent
important development is graph convolutional networks (GCNs), which nicely
integrate local vertex features and graph topology in the convolutional layers.
Although the GCN model compares favorably with other state-of-the-art methods,
its mechanisms are not clear and it still requires a considerable amount of
labeled data for validation and model selection. In this paper, we develop
deeper insights into the GCN model and address its fundamental limits. First,
we show that the graph convolution of the GCN model is actually a special form
of Laplacian smoothing, which is the key reason why GCNs work, but it also
brings potential concerns of over-smoothing with many convolutional layers.
Second, to overcome the limits of the GCN model with shallow architectures, we
propose both co-training and self-training approaches to train GCNs. Our
approaches significantly improve GCNs in learning with very few labels, and
exempt them from requiring additional labels for validation. Extensive
experiments on benchmarks have verified our theory and proposals.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1&quot;&gt;Qimai Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Han_Z/0/1/0/all/0/1&quot;&gt;Zhichao Han&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1&quot;&gt;Xiao-Ming Wu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1707.01217">
<title>Wasserstein Distance Guided Representation Learning for Domain Adaptation. (arXiv:1707.01217v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1707.01217</link>
<description rdf:parseType="Literal">&lt;p&gt;Domain adaptation aims at generalizing a high-performance learner on a target
domain via utilizing the knowledge distilled from a source domain which has a
different but related data distribution. One solution to domain adaptation is
to learn domain invariant feature representations while the learned
representations should also be discriminative in prediction. To learn such
representations, domain adaptation frameworks usually include a domain
invariant representation learning approach to measure and reduce the domain
discrepancy, as well as a discriminator for classification. Inspired by
Wasserstein GAN, in this paper we propose a novel approach to learn domain
invariant feature representations, namely Wasserstein Distance Guided
Representation Learning (WDGRL). WDGRL utilizes a neural network, denoted by
the domain critic, to estimate empirical Wasserstein distance between the
source and target samples and optimizes the feature extractor network to
minimize the estimated Wasserstein distance in an adversarial manner. The
theoretical advantages of Wasserstein distance for domain adaptation lie in its
gradient property and promising generalization bound. Empirical studies on
common sentiment and image classification adaptation datasets demonstrate that
our proposed WDGRL outperforms the state-of-the-art domain invariant
representation learning approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Shen_J/0/1/0/all/0/1&quot;&gt;Jian Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Qu_Y/0/1/0/all/0/1&quot;&gt;Yanru Qu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhang_W/0/1/0/all/0/1&quot;&gt;Weinan Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yu_Y/0/1/0/all/0/1&quot;&gt;Yong Yu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.02642">
<title>Boundary Optimizing Network (BON). (arXiv:1801.02642v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1801.02642</link>
<description rdf:parseType="Literal">&lt;p&gt;Despite all the success that deep neural networks have seen in classifying
certain datasets, the challenge of finding optimal solutions that generalize
still remains. In this paper, we propose the Boundary Optimizing Network (BON),
a new approach to generalization for deep neural networks when used for
supervised learning. Given a classification network, we propose to use a
collaborative generative network that produces new synthetic data points in the
form of perturbations of original data points. In this way, we create a data
support around each original data point which prevents decision boundaries from
passing too close to the original data points, i.e. prevents overfitting. We
show that BON improves convergence on CIFAR-10 using the state-of-the-art
Densenet. We do however observe that the generative network suffers from
catastrophic forgetting during training, and we therefore propose to use a
variation of Memory Aware Synapses to optimize the generative network (called
BON++). On the Iris dataset, we visualize the effect of BON++ when the
generator does not suffer from catastrophic forgetting and conclude that the
approach has the potential to create better boundaries in a higher dimensional
space.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singh_M/0/1/0/all/0/1&quot;&gt;Marco Singh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pai_A/0/1/0/all/0/1&quot;&gt;Akshay Pai&lt;/a&gt;</dc:creator>
</item></rdf:RDF>