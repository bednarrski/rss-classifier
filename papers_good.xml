<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Good papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Good Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-07-26T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.09830"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.09844"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.09946"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.10068"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06467"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.09341"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.09825"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.09942"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.10117"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.10251"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.04488"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.07729"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08440"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.09245"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.09809"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.09842"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.09902"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.09912"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.09932"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.10079"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.10272"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.04035"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.07268"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.00400"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.01290"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.08501"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1807.09830">
<title>Iterative evaluation of LSTM cells. (arXiv:1807.09830v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.09830</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work we present a modification in the conventional flow of
information through a LSTM network, which we consider well suited for RNNs in
general. The modification leads to a iterative scheme where the computations
performed by the LSTM cell are repeated over a constant input and cell state
values, while updating the hidden state a finite number of times. We provide
theoretical and empirical evidence to support the augmented capabilities of the
iterative scheme and show examples related to language modeling. The
modification yields an enhancement in the model performance comparable with the
original model augmented more than 3 times in terms of the total amount of
parameters.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Palma_L/0/1/0/all/0/1&quot;&gt;Leandro Palma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Argerich_L/0/1/0/all/0/1&quot;&gt;Luis Argerich&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.09844">
<title>Modular Mechanistic Networks: On Bridging Mechanistic and Phenomenological Models with Deep Neural Networks in Natural Language Processing. (arXiv:1807.09844v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1807.09844</link>
<description rdf:parseType="Literal">&lt;p&gt;Natural language processing (NLP) can be done using either top-down (theory
driven) and bottom-up (data driven) approaches, which we call mechanistic and
phenomenological respectively. The approaches are frequently considered to
stand in opposition to each other. Examining some recent approaches in deep
learning we argue that deep neural networks incorporate both perspectives and,
furthermore, that leveraging this aspect of deep learning may help in solving
complex problems within language technology, such as modelling language and
perception in the domain of spatial cognition.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dobnik_S/0/1/0/all/0/1&quot;&gt;Simon Dobnik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kelleher_J/0/1/0/all/0/1&quot;&gt;John D. Kelleher&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.09946">
<title>Computationally Efficient Measures of Internal Neuron Importance. (arXiv:1807.09946v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.09946</link>
<description rdf:parseType="Literal">&lt;p&gt;The challenge of assigning importance to individual neurons in a network is
of interest when interpreting deep learning models. In recent work, Dhamdhere
et al. proposed Total Conductance, a &quot;natural refinement of Integrated
Gradients&quot; for attributing importance to internal neurons. Unfortunately, the
authors found that calculating conductance in tensorflow required the addition
of several custom gradient operators and did not scale well. In this work, we
show that the formula for Total Conductance is mathematically equivalent to
Path Integrated Gradients computed on a hidden layer in the network. We provide
a scalable implementation of Total Conductance using standard tensorflow
gradient operators that we call Neuron Integrated Gradients. We compare Neuron
Integrated Gradients to DeepLIFT, a pre-existing computationally efficient
approach that is applicable to calculating internal neuron importance. We find
that DeepLIFT produces strong empirical results and is faster to compute, but
because it lacks the theoretical properties of Neuron Integrated Gradients, it
may not always be preferred in practice. Colab notebook reproducing results:
&lt;a href=&quot;http://bit.ly/neuronintegratedgradients&quot;&gt;this http URL&lt;/a&gt;
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shrikumar_A/0/1/0/all/0/1&quot;&gt;Avanti Shrikumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Su_J/0/1/0/all/0/1&quot;&gt;Jocelin Su&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kundaje_A/0/1/0/all/0/1&quot;&gt;Anshul Kundaje&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.10068">
<title>A Linear Constrained Optimization Benchmark For Probabilistic Search Algorithms: The Rotated Klee-Minty Problem. (arXiv:1807.10068v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1807.10068</link>
<description rdf:parseType="Literal">&lt;p&gt;The development, assessment, and comparison of randomized search algorithms
heavily rely on benchmarking. Regarding the domain of constrained optimization,
the number of currently available benchmark environments bears no relation to
the number of distinct problem features. The present paper advances a proposal
of a scalable linear constrained optimization problem that is suitable for
benchmarking Evolutionary Algorithms. By comparing two recent EA variants, the
linear benchmarking environment is demonstrated.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hellwig_M/0/1/0/all/0/1&quot;&gt;Michael Hellwig&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Beyer_H/0/1/0/all/0/1&quot;&gt;Hans-Georg Beyer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06467">
<title>Memorize or generalize? Searching for a compositional RNN in a haystack. (arXiv:1802.06467v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1802.06467</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural networks are very powerful learning systems, but they do not readily
generalize from one task to the other. This is partly due to the fact that they
do not learn in a compositional way, that is, by discovering skills that are
shared by different tasks, and recombining them to solve new problems. In this
paper, we explore the compositional generalization capabilities of recurrent
neural networks (RNNs). We first propose the lookup table composition domain as
a simple setup to test compositional behaviour and show that it is
theoretically possible for a standard RNN to learn to behave compositionally in
this domain when trained with standard gradient descent and provided with
additional supervision. We then remove this additional supervision and perform
a search over a large number of model initializations to investigate the
proportion of RNNs that can still converge to a compositional solution. We
discover that a small but non-negligible proportion of RNNs do reach partial
compositional solutions even without special architectural constraints. This
suggests that a combination of gradient descent and evolutionary strategies
directly favouring the minority models that developed more compositional
approaches might suffice to lead standard RNNs towards compositional solutions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liska_A/0/1/0/all/0/1&quot;&gt;Adam Li&amp;#x161;ka&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kruszewski_G/0/1/0/all/0/1&quot;&gt;Germ&amp;#xe1;n Kruszewski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Baroni_M/0/1/0/all/0/1&quot;&gt;Marco Baroni&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.09341">
<title>Learning Plannable Representations with Causal InfoGAN. (arXiv:1807.09341v1 [cs.LG] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1807.09341</link>
<description rdf:parseType="Literal">&lt;p&gt;In recent years, deep generative models have been shown to &apos;imagine&apos;
convincing high-dimensional observations such as images, audio, and even video,
learning directly from raw data. In this work, we ask how to imagine
goal-directed visual plans -- a plausible sequence of observations that
transition a dynamical system from its current configuration to a desired goal
state, which can later be used as a reference trajectory for control. We focus
on systems with high-dimensional observations, such as images, and propose an
approach that naturally combines representation learning and planning. Our
framework learns a generative model of sequential observations, where the
generative process is induced by a transition in a low-dimensional planning
model, and an additional noise. By maximizing the mutual information between
the generated observations and the transition in the planning model, we obtain
a low-dimensional representation that best explains the causal nature of the
data. We structure the planning model to be compatible with efficient planning
algorithms, and we propose several such models based on either discrete or
continuous states. Finally, to generate a visual plan, we project the current
and goal observations onto their respective states in the planning model, plan
a trajectory, and then use the generative model to transform the trajectory to
a sequence of observations. We demonstrate our method on imagining plausible
visual plans of rope manipulation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kurutach_T/0/1/0/all/0/1&quot;&gt;Thanard Kurutach&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tamar_A/0/1/0/all/0/1&quot;&gt;Aviv Tamar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_G/0/1/0/all/0/1&quot;&gt;Ge Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Russell_S/0/1/0/all/0/1&quot;&gt;Stuart Russell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1&quot;&gt;Pieter Abbeel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.09825">
<title>An Affective Robot Companion for Assisting the Elderly in a Cognitive Game Scenario. (arXiv:1807.09825v1 [cs.HC])</title>
<link>http://arxiv.org/abs/1807.09825</link>
<description rdf:parseType="Literal">&lt;p&gt;Being able to recognize emotions in human users is considered a highly
desirable trait in Human-Robot Interaction (HRI) scenarios. However, most
contemporary approaches rarely attempt to apply recognized emotional features
in an active manner to modulate robot decision-making and dialogue for the
benefit of the user. In this position paper, we propose a method of
incorporating recognized emotions into a Reinforcement Learning (RL) based
dialogue management module that adapts its dialogue responses in order to
attempt to make cognitive training tasks, like the 2048 Puzzle Game, more
enjoyable for the users.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Churamani_N/0/1/0/all/0/1&quot;&gt;Nikhil Churamani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sutherland_A/0/1/0/all/0/1&quot;&gt;Alexander Sutherland&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barros_P/0/1/0/all/0/1&quot;&gt;Pablo Barros&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.09942">
<title>On Strengthening the Logic of Iterated Belief Revision: Proper Ordinal Interval Operators. (arXiv:1807.09942v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1807.09942</link>
<description rdf:parseType="Literal">&lt;p&gt;Darwiche and Pearl&apos;s seminal 1997 article outlined a number of baseline
principles for a logic of iterated belief revision. These principles, the DP
postulates, have been supplemented in a number of alternative ways. Most of the
suggestions made have resulted in a form of `reductionism&apos; that identifies
belief states with orderings of worlds. However, this position has recently
been criticised as being unacceptably strong. Other proposals, such as the
popular principle (P), aka `Independence&apos;, characteristic of `admissible&apos;
revision operators, remain commendably more modest. In this paper, we
supplement both the DP postulates and (P) with a number of novel conditions.
While the DP postulates constrain the relation between a prior and a posterior
conditional belief set, our new principles notably govern the relation between
two posterior conditional belief sets obtained from a common prior by different
revisions. We show that operators from the resulting family, which subsumes
both lexicographic and restrained revision, can be represented as relating
belief states that are associated with a `proper ordinal interval&apos; (POI)
assignment, a structure more fine-grained than a simple ordering of worlds. We
close the paper by noting that these operators satisfy iterated versions of a
large number of AGM era postulates, including Superexpansion, that are not
sound for admissible operators in general.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Booth_R/0/1/0/all/0/1&quot;&gt;Richard Booth&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chandler_J/0/1/0/all/0/1&quot;&gt;Jake Chandler&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.10117">
<title>Effectiveness of Scaled Exponentially-Regularized Linear Units (SERLUs). (arXiv:1807.10117v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.10117</link>
<description rdf:parseType="Literal">&lt;p&gt;Recently, self-normalizing neural networks (SNNs) have been proposed with the
intention to avoid batch or weight normalization. The key step in SNNs is to
properly scale the exponential linear unit (referred to as SELU) to inherently
incorporate normalization based on central limit theory. SELU is a
monotonically increasing function, where it has an approximately constant
negative output for large negative input. In this work, we propose a new
activation function to break the monotonicity property of SELU while still
preserving the self-normalizing property. Differently from SELU, the new
function introduces a bump-shaped function in the region of negative input by
regularizing a linear function with a scaled exponential function, which is
referred to as a scaled exponentially-regularized linear unit (SERLU). The
bump-shaped function has approximately zero response to large negative input
while being able to push the output of SERLU towards zero mean statistically.
To effectively combat over-fitting, we develop a so-called shift-dropout for
SERLU, which includes standard dropout as a special case. Experimental results
on MNIST, CIFAR10 and CIFAR100 show that SERLU-based neural networks provide
consistently promising results in comparison to other 5 activation functions
including ELU, SELU, Swish, Leakly ReLU and ReLU.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1&quot;&gt;G. Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1&quot;&gt;H. Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.10251">
<title>Aggregated Learning: A Vector Quantization Approach to Learning with Neural Networks. (arXiv:1807.10251v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.10251</link>
<description rdf:parseType="Literal">&lt;p&gt;We establish an equivalence between information bottleneck (IB) learning and
an unconventional quantization problem, `IB quantization&apos;. Under this
equivalence, standard neural network models correspond to scalar IB quantizers.
We prove a coding theorem for IB quantization, which implies that scalar IB
quantizers are in general inferior to vector IB quantizers. This inspires us to
develop a learning framework for neural networks, AgrLearn, that corresponds to
vector IB quantizers. We experimentally verify that AgrLearn applied to some
deep network models of current art improves upon them, while requiring less
training data. With a heuristic smoothing, AgrLearn further improves its
performance, resulting in new state of the art in image classification on
Cifar10.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_H/0/1/0/all/0/1&quot;&gt;Hongyu Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mao_Y/0/1/0/all/0/1&quot;&gt;Yongyi Mao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1&quot;&gt;Richong Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.04488">
<title>Concept2vec: Metrics for Evaluating Quality of Embeddings for Ontological Concepts. (arXiv:1803.04488v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1803.04488</link>
<description rdf:parseType="Literal">&lt;p&gt;Although there is an emerging trend towards generating embeddings for
primarily unstructured data, and recently for structured data, there is not yet
any systematic suite for measuring the quality of embeddings. This deficiency
is further sensed with respect to embeddings generated for structured data
because there are no concrete evaluation metrics measuring the quality of
encoded structure as well as semantic patterns in the embedding space. In this
paper, we introduce a framework containing three distinct tasks concerned with
the individual aspects of ontological concepts: (i) the categorization aspect,
(ii) the hierarchical aspect, and (iii) the relational aspect. Then, in the
scope of each task, a number of intrinsic metrics are proposed for evaluating
the quality of the embeddings. Furthermore, w.r.t. this framework multiple
experimental studies were run to compare the quality of the available embedding
models. Employing this framework in future research can reduce misjudgment and
provide greater insight about quality comparisons of embeddings for ontological
concepts.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alshargi_F/0/1/0/all/0/1&quot;&gt;Faisal Alshargi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shekarpour_S/0/1/0/all/0/1&quot;&gt;Saeedeh Shekarpour&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Soru_T/0/1/0/all/0/1&quot;&gt;Tommaso Soru&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sheth_A/0/1/0/all/0/1&quot;&gt;Amit Sheth&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.07729">
<title>Look Before You Leap: Bridging Model-Free and Model-Based Reinforcement Learning for Planned-Ahead Vision-and-Language Navigation. (arXiv:1803.07729v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1803.07729</link>
<description rdf:parseType="Literal">&lt;p&gt;Existing research studies on vision and language grounding for robot
navigation focus on improving model-free deep reinforcement learning (DRL)
models in synthetic environments. However, model-free DRL models do not
consider the dynamics in the real-world environments, and they often fail to
generalize to new scenes. In this paper, we take a radical approach to bridge
the gap between synthetic studies and real-world practices---We propose a
novel, planned-ahead hybrid reinforcement learning model that combines
model-free and model-based reinforcement learning to solve a real-world
vision-language navigation task. Our look-ahead module tightly integrates a
look-ahead policy model with an environment model that predicts the next state
and the reward. Experimental results suggest that our proposed method
significantly outperforms the baselines and achieves the best on the real-world
Room-to-Room dataset. Moreover, our scalable method is more generalizable when
transferring to unseen environments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;Xin Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiong_W/0/1/0/all/0/1&quot;&gt;Wenhan Xiong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1&quot;&gt;Hongmin Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1&quot;&gt;William Yang Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08440">
<title>Classification Uncertainty of Deep Neural Networks Based on Gradient Information. (arXiv:1805.08440v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.08440</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the quantification of uncertainty of Convolutional Neural Networks
(CNNs) based on gradient metrics. Unlike the classical softmax entropy, such
metrics gather information from all layers of the CNN. We show for the EMNIST
digits data set that for several such metrics we achieve the same meta
classification accuracy -- i.e. the task of classifying predictions as correct
or incorrect without knowing the actual label -- as for entropy thresholding.
We apply meta classification to unknown concepts (out-of-distribution samples)
-- EMNIST/Omniglot letters, CIFAR10 and noise -- and demonstrate that meta
classification rates for unknown concepts can be increased when using entropy
together with several gradient based metrics as input quantities for a meta
classifier. Meta classifiers only trained on the uncertainty metrics of known
concepts, i.e. EMNIST digits, usually do not perform equally well for all
unknown concepts. If we however allow the meta classifier to be trained on
uncertainty metrics for some out-of-distribution samples, meta classification
for concepts remote from EMNIST digits (then termed known unknowns) can be
improved considerably.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oberdiek_P/0/1/0/all/0/1&quot;&gt;Philipp Oberdiek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rottmann_M/0/1/0/all/0/1&quot;&gt;Matthias Rottmann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gottschalk_H/0/1/0/all/0/1&quot;&gt;Hanno Gottschalk&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.09245">
<title>Visual Dynamics: Stochastic Future Generation via Layered Cross Convolutional Networks. (arXiv:1807.09245v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1807.09245</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the problem of synthesizing a number of likely future frames from a
single input image. In contrast to traditional methods that have tackled this
problem in a deterministic or non-parametric way, we propose to model future
frames in a probabilistic manner. Our probabilistic model makes it possible for
us to sample and synthesize many possible future frames from a single input
image. To synthesize realistic movement of objects, we propose a novel network
structure, namely a Cross Convolutional Network; this network encodes image and
motion information as feature maps and convolutional kernels, respectively. In
experiments, our model performs well on synthetic data, such as 2D shapes and
animated game sprites, and on real-world video frames. We present analyses of
the learned network representations, showing it is implicitly learning a
compact encoding of object appearance and motion. We also demonstrate a few of
its applications, including visual analogy-making and video extrapolation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xue_T/0/1/0/all/0/1&quot;&gt;Tianfan Xue&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1&quot;&gt;Jiajun Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bouman_K/0/1/0/all/0/1&quot;&gt;Katherine L. Bouman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Freeman_W/0/1/0/all/0/1&quot;&gt;William T. Freeman&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.09809">
<title>Deep Contextual Multi-armed Bandits. (arXiv:1807.09809v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.09809</link>
<description rdf:parseType="Literal">&lt;p&gt;Contextual multi-armed bandit problems arise frequently in important
industrial applications. Existing solutions model the context either linearly,
which enables uncertainty driven (principled) exploration, or non-linearly, by
using epsilon-greedy exploration policies. Here we present a deep learning
framework for contextual multi-armed bandits that is both non-linear and
enables principled exploration at the same time. We tackle the exploration vs.
exploitation trade-off through Thompson sampling by exploiting the connection
between inference time dropout and sampling from the posterior over the weights
of a Bayesian neural network. In order to adjust the level of exploration
automatically as more data is made available to the model, the dropout rate is
learned rather than considered a hyperparameter. We demonstrate that our
approach substantially reduces regret on two tasks (the UCI Mushroom task and
the Casino Parity task) when compared to 1) non-contextual bandits, 2)
epsilon-greedy deep contextual bandits, and 3) fixed dropout rate deep
contextual bandits. Our approach is currently being applied to marketing
optimization problems at HubSpot.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Collier_M/0/1/0/all/0/1&quot;&gt;Mark Collier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Llorens_H/0/1/0/all/0/1&quot;&gt;Hector Urdiales Llorens&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.09842">
<title>Understanding and representing the semantics of large structured documents. (arXiv:1807.09842v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1807.09842</link>
<description rdf:parseType="Literal">&lt;p&gt;Understanding large, structured documents like scholarly articles, requests
for proposals or business reports is a complex and difficult task. It involves
discovering a document&apos;s overall purpose and subject(s), understanding the
function and meaning of its sections and subsections, and extracting low level
entities and facts about them. In this research, we present a deep learning
based document ontology to capture the general purpose semantic structure and
domain specific semantic concepts from a large number of academic articles and
business documents. The ontology is able to describe different functional parts
of a document, which can be used to enhance semantic indexing for a better
understanding by human beings and machines. We evaluate our models through
extensive experiments on datasets of scholarly articles from arXiv and Request
for Proposal documents.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rahman_M/0/1/0/all/0/1&quot;&gt;Muhammad Mahbubur Rahman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Finin_T/0/1/0/all/0/1&quot;&gt;Tim Finin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.09902">
<title>General-purpose Tagging of Freesound Audio with AudioSet Labels: Task Description, Dataset, and Baseline. (arXiv:1807.09902v1 [cs.SD])</title>
<link>http://arxiv.org/abs/1807.09902</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper describes Task 2 of the DCASE 2018 Challenge, titled
&quot;General-purpose audio tagging of Freesound content with AudioSet labels&quot;. This
task was hosted on the Kaggle platform as &quot;Freesound General-Purpose Audio
Tagging Challenge&quot;. The goal of the task is to build an audio tagging system
that can recognize the category of an audio clip from a subset of 41
heterogeneous categories drawn from the AudioSet Ontology. We present the task,
the dataset prepared for the competition, and a baseline system.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fonseca_E/0/1/0/all/0/1&quot;&gt;Eduardo Fonseca&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Plakal_M/0/1/0/all/0/1&quot;&gt;Manoj Plakal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Font_F/0/1/0/all/0/1&quot;&gt;Frederic Font&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ellis_D/0/1/0/all/0/1&quot;&gt;Daniel P. W. Ellis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Favory_X/0/1/0/all/0/1&quot;&gt;Xavier Favory&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pons_J/0/1/0/all/0/1&quot;&gt;Jordi Pons&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Serra_X/0/1/0/all/0/1&quot;&gt;Xavier Serra&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.09912">
<title>Meta-learning autoencoders for few-shot prediction. (arXiv:1807.09912v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.09912</link>
<description rdf:parseType="Literal">&lt;p&gt;Compared to humans, machine learning models generally require significantly
more training examples and fail to extrapolate from experience to solve
previously unseen challenges. To help close this performance gap, we augment
single-task neural networks with a meta-recognition model which learns a
succinct model code via its autoencoder structure, using just a few informative
examples. The model code is then employed by a meta-generative model to
construct parameters for the task-specific model. We demonstrate that for
previously unseen tasks, without additional training, this Meta-Learning
Autoencoder (MeLA) framework can build models that closely match the true
underlying models, with loss significantly lower than given by fine-tuned
baseline networks, and performance that compares favorably with
state-of-the-art meta-learning algorithms. MeLA also adds the ability to
identify influential training examples and predict which additional data will
be most valuable to acquire to improve model prediction.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_T/0/1/0/all/0/1&quot;&gt;Tailin Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peurifoy_J/0/1/0/all/0/1&quot;&gt;John Peurifoy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chuang_I/0/1/0/all/0/1&quot;&gt;Isaac L. Chuang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tegmark_M/0/1/0/all/0/1&quot;&gt;Max Tegmark&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.09932">
<title>EBIC: an open source software for high-dimensional and big data biclustering analyses. (arXiv:1807.09932v1 [q-bio.GN])</title>
<link>http://arxiv.org/abs/1807.09932</link>
<description rdf:parseType="Literal">&lt;p&gt;Motivation: In this paper we present the latest release of EBIC, a
next-generation biclustering algorithm for mining genetic data. The major
contribution of this paper is adding support for big data, making it possible
to efficiently run large genomic data mining analyses. Additional enhancements
include integration with R and Bioconductor and an option to remove influence
of missing value on the final result.
&lt;/p&gt;
&lt;p&gt;Results: EBIC was applied to datasets of different sizes, including a large
DNA methylation dataset with 436,444 rows. For the largest dataset we observed
over 6.6 fold speedup in computation time on a cluster of 8 GPUs compared to
running the method on a single GPU. This proves high scalability of the
algorithm.
&lt;/p&gt;
&lt;p&gt;Availability: The latest version of EBIC could be downloaded from
&lt;a href=&quot;http://github.com/EpistasisLab/ebic&quot;&gt;this http URL&lt;/a&gt; . Installation and usage instructions are
also available online.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Orzechowski_P/0/1/0/all/0/1&quot;&gt;Patryk Orzechowski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Moore_J/0/1/0/all/0/1&quot;&gt;Jason H. Moore&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.10079">
<title>Automatic Detection of Node-Replication Attack in Vehicular Ad-hoc Networks. (arXiv:1807.10079v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.10079</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent advances in smart cities applications enforce security threads such as
node replication attacks. Such attack is take place when the attacker plants a
replicated network node within the network. Vehicular Ad hoc networks are
connecting sensors that have limited resources and required the response time
to be as low as possible. In this type networks, traditional detection
algorithms of node replication attacks are not efficient. In this paper, we
propose an initial idea to apply a newly adapted statistical methodology that
can detect node replication attacks with high performance as compared to
state-of-the-art techniques. We provide a sufficient description of this
methodology and a road-map for testing and experiment its performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zamil_M/0/1/0/all/0/1&quot;&gt;Mohammed GH. I. AL Zamil&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.10272">
<title>Evaluating and Understanding the Robustness of Adversarial Logit Pairing. (arXiv:1807.10272v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1807.10272</link>
<description rdf:parseType="Literal">&lt;p&gt;We evaluate the robustness of Adversarial Logit Pairing, a recently proposed
defense against adversarial examples. We find that a network trained with
Adversarial Logit Pairing achieves 0.6% accuracy in the threat model in which
the defense is considered. We provide a brief overview of the defense and the
threat models/claims considered, as well as a discussion of the methodology and
results of our attack, which may offer insights into the reasons underlying the
vulnerability of ALP to adversarial attack.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Engstrom_L/0/1/0/all/0/1&quot;&gt;Logan Engstrom&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ilyas_A/0/1/0/all/0/1&quot;&gt;Andrew Ilyas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Athalye_A/0/1/0/all/0/1&quot;&gt;Anish Athalye&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.04035">
<title>Scaling limit of the Stein variational gradient descent part I: the mean field regime. (arXiv:1805.04035v2 [math.AP] UPDATED)</title>
<link>http://arxiv.org/abs/1805.04035</link>
<description rdf:parseType="Literal">&lt;p&gt;We study an interacting particle system in $\mathbf{R}^d$ motivated by Stein
variational gradient descent [Q. Liu and D. Wang, NIPS 2016], a deterministic
algorithm for sampling from a given probability density with unknown
normalization. We prove that in the large particle limit the empirical measure
converges to a solution of a non-local and nonlinear PDE. We also prove global
well-posedness and uniqueness of the solution to the limiting PDE. Finally, we
prove that the solution to the PDE converges to the unique invariant solution
in large time limit.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Lu_J/0/1/0/all/0/1&quot;&gt;Jianfeng Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Lu_Y/0/1/0/all/0/1&quot;&gt;Yulong Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Nolen_J/0/1/0/all/0/1&quot;&gt;James Nolen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.07268">
<title>Beyond Local Nash Equilibria for Adversarial Networks. (arXiv:1806.07268v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1806.07268</link>
<description rdf:parseType="Literal">&lt;p&gt;Save for some special cases, current training methods for Generative
Adversarial Networks (GANs) are at best guaranteed to converge to a `local Nash
equilibrium` (LNE). Such LNEs, however, can be arbitrarily far from an actual
Nash equilibrium (NE), which implies that there are no guarantees on the
quality of the found generator or classifier. This paper proposes to model GANs
explicitly as finite games in mixed strategies, thereby ensuring that every LNE
is an NE. With this formulation, we propose a solution method that is proven to
monotonically converge to a resource-bounded Nash equilibrium (RB-NE): by
increasing computational resources we can find better solutions. We empirically
demonstrate that our method is less prone to typical GAN problems such as mode
collapse, and produces solutions that are less exploitable than those produced
by GANs and MGANs, and closely resemble theoretical predictions about NEs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oliehoek_F/0/1/0/all/0/1&quot;&gt;Frans A. Oliehoek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Savani_R/0/1/0/all/0/1&quot;&gt;Rahul Savani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gallego_J/0/1/0/all/0/1&quot;&gt;Jose Gallego&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pol_E/0/1/0/all/0/1&quot;&gt;Elise van der Pol&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gross_R/0/1/0/all/0/1&quot;&gt;Roderich Gro&amp;#xdf;&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.00400">
<title>Antithetic and Monte Carlo kernel estimators for partial rankings. (arXiv:1807.00400v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1807.00400</link>
<description rdf:parseType="Literal">&lt;p&gt;In the modern age, rankings data is ubiquitous and it is useful for a variety
of applications such as recommender systems, multi-object tracking and
preference learning. However, most rankings data encountered in the real world
is incomplete, which prevents the direct application of existing modelling
tools for complete rankings. Our contribution is a novel way to extend kernel
methods for complete rankings to partial rankings, via consistent Monte Carlo
estimators for Gram matrices: matrices of kernel values between pairs of
observations. We also present a novel variance reduction scheme based on an
antithetic variate construction between permutations to obtain an improved
estimator for the Mallows kernel. The corresponding antithetic kernel estimator
has lower variance and we demonstrate empirically that it has a better
performance in a variety of Machine Learning tasks. Both kernel estimators are
based on extending kernel mean embeddings to the embedding of a set of full
rankings consistent with an observed partial ranking. They form a
computationally tractable alternative to previous approaches for partial
rankings data. An overview of the existing kernels and metrics for permutations
is also provided.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lomeli_M/0/1/0/all/0/1&quot;&gt;Maria Lomeli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rowland_M/0/1/0/all/0/1&quot;&gt;Mark Rowland&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gretton_A/0/1/0/all/0/1&quot;&gt;Arthur Gretton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ghahramani_Z/0/1/0/all/0/1&quot;&gt;Zoubin Ghahramani&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.01290">
<title>New Losses for Generative Adversarial Learning. (arXiv:1807.01290v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1807.01290</link>
<description rdf:parseType="Literal">&lt;p&gt;Generative Adversarial Networks (Goodfellow et al., 2014), a major
breakthrough in the field of generative modeling, learn a discriminator to
estimate some distance between the target and the candidate distributions.
&lt;/p&gt;
&lt;p&gt;This paper examines mathematical issues regarding the way the gradients for
the generative model are computed in this context, and notably how to take into
account how the discriminator itself depends on the generator parameters.
&lt;/p&gt;
&lt;p&gt;A unifying methodology is presented to define mathematically sound training
objectives for generative models taking this dependency into account in a
robust way, covering both GAN, VAE and some GAN variants as particular cases.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Berger_V/0/1/0/all/0/1&quot;&gt;Victor Berger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sebag_M/0/1/0/all/0/1&quot;&gt;Mich&amp;#xe8;le Sebag&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.08501">
<title>Generalization Bounds for Unsupervised Cross-Domain Mapping with WGANs. (arXiv:1807.08501v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1807.08501</link>
<description rdf:parseType="Literal">&lt;p&gt;The recent empirical success of cross-domain mapping algorithms, between two
domains that share common characteristics, is not well-supported by theoretical
justifications. This lacuna is especially troubling, given the clear ambiguity
in such mappings. We work with the adversarial training method called the
Wasserstein GAN. We derive a novel generalization bound, which limits the risk
between the learned mapping $h$ and the target mapping $y$, by a sum of two
terms: (i) the risk between $h$ and the most distant alternative mapping that
was learned by the same cross-domain mapping algorithm, and (ii) the minimal
Wasserstein GAN divergence between the target domain and the domain obtained by
applying a hypothesis $h^*$ on the samples of the source domain, where $h^*$ is
a hypothesis selected by the same algorithm. The bound is directly related to
Occam&apos;s razor and it encourages the selection of the minimal architecture that
supports a small Wasserstein GAN divergence. From the bound, we derive
algorithms for hyperparameter selection and early stopping in cross-domain
mapping GANs. We also demonstrate a novel capability of estimating confidence
in the mapping of every specific sample. Lastly, we show how non-minimal
architectures can be effectively trained by an inverted knowledge distillation
in which a minimal architecture is used to train a larger one, leading to
higher quality outputs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Galanti_T/0/1/0/all/0/1&quot;&gt;Tomer Galanti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Benaim_S/0/1/0/all/0/1&quot;&gt;Sagie Benaim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wolf_L/0/1/0/all/0/1&quot;&gt;Lior Wolf&lt;/a&gt;</dc:creator>
</item></rdf:RDF>