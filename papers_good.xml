<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Good papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Good Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-02-06T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.02006"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1708.04251"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.01569"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.01604"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.02032"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.02046"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.03678"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.01173"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.01239"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.06171"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.06559"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.01396"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.01528"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1802.02006">
<title>An Adaptive Genetic Algorithm for Solving N-Queens Problem. (arXiv:1802.02006v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1802.02006</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper a Metaheuristic approach for solving the N-Queens Problem is
introduced to find the best possible solution in a reasonable amount of time.
Genetic Algorithm is used with a novel fitness function as the Metaheuristic.
The aim of N-Queens Problem is to place N queens on an N x N chessboard, in a
way so that no queen is in conflict with the others. Chromosome representation
and genetic operations like Mutation and Crossover are described in detail.
Results show that this approach yields promising and satisfactory results in
less time compared to that obtained from the previous approaches for several
large values of N.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sarkar_U/0/1/0/all/0/1&quot;&gt;Uddalok Sarkar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nag_S/0/1/0/all/0/1&quot;&gt;Sayan Nag&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1708.04251">
<title>A learning framework for winner-take-all networks with stochastic synapses. (arXiv:1708.04251v2 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1708.04251</link>
<description rdf:parseType="Literal">&lt;p&gt;Many recent generative models make use of neural networks to transform the
probability distribution of a simple low-dimensional noise process into the
complex distribution of the data. This raises the question of whether
biological networks operate along similar principles to implement a
probabilistic model of the environment through transformations of intrinsic
noise processes. The intrinsic neural and synaptic noise processes in
biological networks, however, are quite different from the noise processes used
in current abstract generative networks. This, together with the discrete
nature of spikes and local circuit interactions among the neurons, raises
several difficulties when using recent generative modeling frameworks to train
biologically motivated models. In this paper, we show that a biologically
motivated model based on multi-layer winner-take-all (WTA) circuits and
stochastic synapses admits an approximate analytical description. This allows
us to use the proposed networks in a variational learning setting where
stochastic backpropagation is used to optimize a lower bound on the data log
likelihood, thereby learning a generative model of the data. We illustrate the
generality of the proposed networks and learning technique by using them in a
structured output prediction task, and in a semi-supervised learning task. Our
results extend the domain of application of modern stochastic network
architectures to networks where synaptic transmission failure is the principal
noise mechanism.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mostafa_H/0/1/0/all/0/1&quot;&gt;Hesham Mostafa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cauwenberghs_G/0/1/0/all/0/1&quot;&gt;Gert Cauwenberghs&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.01569">
<title>Alleviating catastrophic forgetting using context-dependent gating and synaptic stabilization. (arXiv:1802.01569v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.01569</link>
<description rdf:parseType="Literal">&lt;p&gt;Humans and most animals can learn new tasks without forgetting old ones.
However, training artificial neural networks (ANNs) on new tasks typically
cause it to forget previously learned tasks. This phenomenon is the result of
&quot;catastrophic forgetting&quot;, in which training an ANN disrupts connection weights
that were important for solving previous tasks, degrading task performance.
Several recent studies have proposed methods to stabilize connection weights of
ANNs that are deemed most important for solving a task, which helps alleviate
catastrophic forgetting. Here, drawing inspiration from algorithms that are
believed to be implemented in vivo, we propose a complementary method: adding a
context-dependent gating signal, such that only sparse, mostly non-overlapping
patterns of units are active for any one task. This method is easy to
implement, requires little computational overhead, and allows ANNs to maintain
high performance across large numbers of sequentially presented tasks when
combined with weight stabilization. This work provides another example of how
neuroscience-inspired algorithms can benefit ANN design and capability.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Masse_N/0/1/0/all/0/1&quot;&gt;Nicolas Y. Masse&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grant_G/0/1/0/all/0/1&quot;&gt;Gregory D. Grant&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Freedman_D/0/1/0/all/0/1&quot;&gt;David J. Freedman&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.01604">
<title>Learning from Richer Human Guidance: Augmenting Comparison-Based Learning with Feature Queries. (arXiv:1802.01604v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.01604</link>
<description rdf:parseType="Literal">&lt;p&gt;We focus on learning the desired objective function for a robot. Although
trajectory demonstrations can be very informative of the desired objective,
they can also be difficult for users to provide. Answers to comparison queries,
asking which of two trajectories is preferable, are much easier for users, and
have emerged as an effective alternative. Unfortunately, comparisons are far
less informative. We propose that there is much richer information that users
can easily provide and that robots ought to leverage. We focus on augmenting
comparisons with feature queries, and introduce a unified formalism for
treating all answers as observations about the true desired reward. We derive
an active query selection algorithm, and test these queries in simulation and
on real users. We find that richer, feature-augmented queries can extract more
information faster, leading to robots that better match user preferences in
their behavior.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Basu_C/0/1/0/all/0/1&quot;&gt;Chandrayee Basu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singhal_M/0/1/0/all/0/1&quot;&gt;Mukesh Singhal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dragan_A/0/1/0/all/0/1&quot;&gt;Anca D. Dragan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.02032">
<title>Improving Variational Encoder-Decoders in Dialogue Generation. (arXiv:1802.02032v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1802.02032</link>
<description rdf:parseType="Literal">&lt;p&gt;Variational encoder-decoders (VEDs) have shown promising results in dialogue
generation. However, the latent variable distributions are usually approximated
by a much simpler model than the powerful RNN structure used for encoding and
decoding, yielding the KL-vanishing problem and inconsistent training
objective. In this paper, we separate the training step into two phases: The
first phase learns to autoencode discrete texts into continuous embeddings,
from which the second phase learns to generalize latent representations by
reconstructing the encoded embedding. In this case, latent variables are
sampled by transforming Gaussian noise through multi-layer perceptrons and are
trained with a separate VED model, which has the potential of realizing a much
more flexible distribution. We compare our model with current popular models
and the experiment demonstrates substantial improvement in both metric-based
and human evaluations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_X/0/1/0/all/0/1&quot;&gt;Xiaoyu Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1&quot;&gt;Hui Su&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Niu_S/0/1/0/all/0/1&quot;&gt;Shuzi Niu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Demberg_V/0/1/0/all/0/1&quot;&gt;Vera Demberg&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.02046">
<title>Neural Network Detection of Data Sequences in Communication Systems. (arXiv:1802.02046v1 [eess.SP])</title>
<link>http://arxiv.org/abs/1802.02046</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider detection based on deep learning, and show it is possible to
train detectors that perform well, without any knowledge of the underlying
channel models. Moreover, when the channel model is known, we demonstrate that
it is possible to train detectors that do not require channel state information
(CSI). In particular, a technique we call sliding bidirectional recurrent
neural network (SBRNN) is proposed for detection where, after training, the
detector estimates the data in real-time as the signal stream arrives at the
receiver. We evaluate this algorithm, as well as other neural network (NN)
architectures, using the Poisson channel model, which is applicable to both
optical and chemical communication systems. In addition, we also evaluate the
performance of this detection method applied to data sent over a chemical
communication platform, where the channel model is difficult to model
analytically. We show that SBRNN is computationally efficient, and can perform
detection under various channel conditions without knowing the underlying
channel model. We also demonstrate that the bit error rate (BER) performance of
the proposed SBRNN detector is better than that of a Viterbi detector with
imperfect CSI as well as that of other NN detectors that have been previously
proposed.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Farsad_N/0/1/0/all/0/1&quot;&gt;Nariman Farsad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Goldsmith_A/0/1/0/all/0/1&quot;&gt;Andrea Goldsmith&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.03678">
<title>Self-Supervised Intrinsic Image Decomposition. (arXiv:1711.03678v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1711.03678</link>
<description rdf:parseType="Literal">&lt;p&gt;Intrinsic decomposition from a single image is a highly challenging task, due
to its inherent ambiguity and the scarcity of training data. In contrast to
traditional fully supervised learning approaches, in this paper we propose
learning intrinsic image decomposition by explaining the input image. Our
model, the Rendered Intrinsics Network (RIN), joins together an image
decomposition pipeline, which predicts reflectance, shape, and lighting
conditions given a single image, with a recombination function, a learned
shading model used to recompose the original input based off of intrinsic image
predictions. Our network can then use unsupervised reconstruction error as an
additional signal to improve its intermediate representations. This allows
large-scale unlabeled data to be useful during training, and also enables
transferring learned knowledge to images of unseen object categories, lighting
conditions, and shapes. Extensive experiments demonstrate that our method
performs well on both intrinsic image decomposition and knowledge transfer.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Janner_M/0/1/0/all/0/1&quot;&gt;Michael Janner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1&quot;&gt;Jiajun Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kulkarni_T/0/1/0/all/0/1&quot;&gt;Tejas D. Kulkarni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yildirim_I/0/1/0/all/0/1&quot;&gt;Ilker Yildirim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tenenbaum_J/0/1/0/all/0/1&quot;&gt;Joshua B. Tenenbaum&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.01173">
<title>Tunneling Neural Perception and Logic Reasoning through Abductive Learning. (arXiv:1802.01173v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1802.01173</link>
<description rdf:parseType="Literal">&lt;p&gt;Perception and reasoning are basic human abilities that are seamlessly
connected as part of human intelligence. However, in current machine learning
systems, the perception and reasoning modules are incompatible. Tasks requiring
joint perception and reasoning ability are difficult to accomplish autonomously
and still demand human intervention. Inspired by the way language experts
decoded Mayan scripts by joining two abilities in an abductive manner, this
paper proposes the abductive learning framework. The framework learns
perception and reasoning simultaneously with the help of a trial-and-error
abductive process. We present the Neural-Logical Machine as an implementation
of this novel learning framework. We demonstrate that--using human-like
abductive learning--the machine learns from a small set of simple hand-written
equations and then generalizes well to complex equations, a feat that is beyond
the capability of state-of-the-art neural network models. The abductive
learning framework explores a new direction for approaching human-level
learning ability.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dai_W/0/1/0/all/0/1&quot;&gt;Wang-Zhou Dai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Q/0/1/0/all/0/1&quot;&gt;Qiu-Ling Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1&quot;&gt;Yang Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1&quot;&gt;Zhi-Hua Zhou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.01239">
<title>Counting and Uniform Sampling from Markov Equivalent DAGs. (arXiv:1802.01239v1 [cs.DS] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1802.01239</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose an exact solution for the problem of finding the size of a Markov
equivalence class (MEC). For the bounded degree graphs, the proposed solution
is capable of computing the size of the MEC in polynomial time. Our proposed
approach is based on a recursive method for counting the number of the elements
of the MEC when a specific vertex is set as the source variable. We will
further use the idea to design a sampler, which is capable of sampling from an
MEC uniformly in polynomial time.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghassami_A/0/1/0/all/0/1&quot;&gt;AmirEmad Ghassami&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Salehkaleybar_S/0/1/0/all/0/1&quot;&gt;Saber Salehkaleybar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kiyavash_N/0/1/0/all/0/1&quot;&gt;Negar Kiyavash&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.06171">
<title>Learning Low-Dimensional Metrics. (arXiv:1709.06171v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1709.06171</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper investigates the theoretical foundations of metric learning,
focused on three key questions that are not fully addressed in prior work: 1)
we consider learning general low-dimensional (low-rank) metrics as well as
sparse metrics; 2) we develop upper and lower (minimax)bounds on the
generalization error; 3) we quantify the sample complexity of metric learning
in terms of the dimension of the feature space and the dimension/rank of the
underlying metric;4) we also bound the accuracy of the learned metric relative
to the underlying true generative metric. All the results involve novel
mathematical approaches to the metric learning problem, and lso shed new light
on the special case of ordinal embedding (aka non-metric multidimensional
scaling).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Jain_L/0/1/0/all/0/1&quot;&gt;Lalit Jain&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mason_B/0/1/0/all/0/1&quot;&gt;Blake Mason&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Nowak_R/0/1/0/all/0/1&quot;&gt;Robert Nowak&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.06559">
<title>The Power of Interpolation: Understanding the Effectiveness of SGD in Modern Over-parametrized Learning. (arXiv:1712.06559v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1712.06559</link>
<description rdf:parseType="Literal">&lt;p&gt;Stochastic Gradient Descent (SGD) with small mini-batch is a key component in
modern large-scale learning. However, its efficiency has not been easy to
analyze as most theoretical results require adaptive rates and show convergence
rates far slower than that for gradient descent, making computational
comparisons difficult.
&lt;/p&gt;
&lt;p&gt;In this paper we aim to clarify the issue of fast SGD convergence. The key
observation is that most modern architectures are over-parametrized and are
trained to interpolate the data by driving the empirical loss close to zero.
While it is still unclear why these interpolated solutions perform well on test
data, we show that these regimes allow for very fast convergence of SGD,
comparable in the number of iterations to full gradient descent.
&lt;/p&gt;
&lt;p&gt;Specifically, consider the setting with a quadratic objective function, or a
general objective function in the proximity of a minimum, where the quadratic
term is dominant. First, we obtain the optimal convergence rate for any
mini-batch SGD and derive the optimal step size as a function of the batch size
$m$. Second, we show: (1) $m=1$ is optimal in terms of number of computations
required to achieve any desired accuracy. (2) There is a critical mini-batch
size $m^*$ such that: (2a) SGD iteration with batch size $m\leq m^*$ is nearly
equivalent to $m$ iterations of batch size $1$. (2b) SGD iteration with
mini-batch $m&amp;gt; m^*$ is nearly equivalent to a full gradient descent iteration.
&lt;/p&gt;
&lt;p&gt;The critical mini-batch size can be viewed as the limit for effective
mini-batch parallelization. It is also nearly independent of the data size,
implying $O(n)$ acceleration over GD per unit of computation. These theoretical
analyses are verified by experimental results.
&lt;/p&gt;
&lt;p&gt;Finally, we show how the interpolation perspective and our results fit in the
deep neural networks and discuss connections to adaptive rates for SGD and
variance reduction.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_S/0/1/0/all/0/1&quot;&gt;Siyuan Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bassily_R/0/1/0/all/0/1&quot;&gt;Raef Bassily&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Belkin_M/0/1/0/all/0/1&quot;&gt;Mikhail Belkin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.01396">
<title>To understand deep learning we need to understand kernel learning. (arXiv:1802.01396v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1802.01396</link>
<description rdf:parseType="Literal">&lt;p&gt;Generalization performance of classifiers in deep learning has recently
become a subject of intense study. Heavily over-parametrized deep models tend
to fit training data exactly. Despite overfitting, they perform well on test
data, a phenomenon not yet fully understood.
&lt;/p&gt;
&lt;p&gt;The first point of our paper is that strong performance of overfitted
classifiers is not a unique feature of deep learning. Using real-world and
synthetic datasets, we establish that kernel classifiers trained to have zero
classification error (overfitting) or even zero regression error
(interpolation) perform very well on test data.
&lt;/p&gt;
&lt;p&gt;We proceed to prove lower bounds on the norm of overfitted solutions for
smooth kernels, showing that they increase nearly exponentially with the data
size. Since most generalization bounds depend polynomially on the norm of the
solution, this result implies that they diverge as data increases. Furthermore,
the existing bounds do not apply to interpolated classifiers.
&lt;/p&gt;
&lt;p&gt;We also show experimentally that (non-smooth) Laplacian kernels easily fit
random labels using a version of SGD, a finding that parallels results reported
for ReLU neural networks. In contrast, fitting noisy data requires many more
epochs for smooth Gaussian kernels. The observation that the performance of
overfitted Laplacian and Gaussian classifiers on the test is quite similar,
suggests that generalization is tied to the properties of the kernel function
rather than the optimization process.
&lt;/p&gt;
&lt;p&gt;We see that some key phenomena of deep learning are manifested similarly in
kernel methods in the overfitted regime. We argue that progress on
understanding deep learning will be difficult, until more analytically
tractable &quot;shallow&quot; kernel methods are better understood. The experimental and
theoretical results presented in this paper indicate a need for new theoretical
ideas for understanding classical kernel methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Belkin_M/0/1/0/all/0/1&quot;&gt;Mikhail Belkin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ma_S/0/1/0/all/0/1&quot;&gt;Siyuan Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mandal_S/0/1/0/all/0/1&quot;&gt;Soumik Mandal&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.01528">
<title>The Matrix Calculus You Need For Deep Learning. (arXiv:1802.01528v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1802.01528</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper is an attempt to explain all the matrix calculus you need in order
to understand the training of deep neural networks. We assume no math knowledge
beyond what you learned in calculus 1, and provide links to help you refresh
the necessary math where needed. Note that you do not need to understand this
material before you start learning to train and use deep learning in practice;
rather, this material is for those who are already familiar with the basics of
neural networks, and wish to deepen their understanding of the underlying math.
Don&apos;t worry if you get stuck at some point along the way---just go back and
reread the previous section, and try writing down and working through some
examples. And if you&apos;re still stuck, we&apos;re happy to answer your questions in
the Theory category at forums.fast.ai. Note: There is a reference section at
the end of the paper summarizing all the key matrix calculus rules and
terminology discussed here.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Parr_T/0/1/0/all/0/1&quot;&gt;Terence Parr&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Howard_J/0/1/0/all/0/1&quot;&gt;Jeremy Howard&lt;/a&gt;</dc:creator>
</item></rdf:RDF>