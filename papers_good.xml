<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Good papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Good Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-03-20T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.07307"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.07488"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.00554"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.06959"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.07131"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.07133"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.07139"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.07170"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.07233"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.07482"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.07517"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1604.08612"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1708.08559"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.10026"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.07164"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.07192"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.07416"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.07445"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.07551"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1506.03410"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1702.01417"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.04540"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.03764"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1803.07307">
<title>Information content of coevolutionary game landscapes. (arXiv:1803.07307v1 [q-bio.PE])</title>
<link>http://arxiv.org/abs/1803.07307</link>
<description rdf:parseType="Literal">&lt;p&gt;Coevolutionary game dynamics is the result of players that may change their
strategies and their network of interaction. For such games, and based on
interpreting strategies as configurations, strategy-to-payoff maps can be
defined for every interaction network, which opens up to derive game
landscapes. This paper presents an analysis of these game landscapes by their
information content. By this analysis, we particularly study the effect of a
rescaled payoff matrix generalizing social dilemmas and differences between
well-mixed and structured populations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Richter_H/0/1/0/all/0/1&quot;&gt;Hendrik Richter&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.07488">
<title>Linearizing Visual Processes with Convolutional Variational Autoencoders. (arXiv:1803.07488v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1803.07488</link>
<description rdf:parseType="Literal">&lt;p&gt;This work studies the problem of modeling non-linear visual processes by
learning linear generative models from observed sequences. We propose a joint
learning framework, combining a Linear Dynamic System and a Variational
Autoencoder with convolutional layers. After discussing several conditions for
linearizing neural networks, we propose an architecture that allows Variational
Autoencoders to simultaneously learn the non-linear observation as well as the
linear state-transition from a sequence of observed frames. The proposed
framework is demonstrated experimentally in three series of synthesis
experiments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sagel_A/0/1/0/all/0/1&quot;&gt;Alexander Sagel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_H/0/1/0/all/0/1&quot;&gt;Hao Shen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.00554">
<title>Generating Redundant Features with Unsupervised Multi-Tree Genetic Programming. (arXiv:1802.00554v2 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1802.00554</link>
<description rdf:parseType="Literal">&lt;p&gt;Recently, feature selection has become an increasingly important area of
research due to the surge in high-dimensional datasets in all areas of modern
life. A plethora of feature selection algorithms have been proposed, but it is
difficult to truly analyse the quality of a given algorithm. Ideally, an
algorithm would be evaluated by measuring how well it removes known bad
features. Acquiring datasets with such features is inherently difficult, and so
a common technique is to add synthetic bad features to an existing dataset.
While adding noisy features is an easy task, it is very difficult to
automatically add complex, redundant features. This work proposes one of the
first approaches to generating redundant features, using a novel genetic
programming approach. Initial experiments show that our proposed method can
automatically create difficult, redundant features which have the potential to
be used for creating high-quality feature selection benchmark datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lensen_A/0/1/0/all/0/1&quot;&gt;Andrew Lensen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xue_B/0/1/0/all/0/1&quot;&gt;Bing Xue&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1&quot;&gt;Mengjie Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.06959">
<title>On the importance of single directions for generalization. (arXiv:1803.06959v1 [stat.ML] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1803.06959</link>
<description rdf:parseType="Literal">&lt;p&gt;Despite their ability to memorize large datasets, deep neural networks often
achieve good generalization performance. However, the differences between the
learned solutions of networks which generalize and those which do not remain
unclear. Additionally, the tuning properties of single directions (defined as
the activation of a single unit or some linear combination of units in response
to some input) have been highlighted, but their importance has not been
evaluated. Here, we connect these lines of inquiry to demonstrate that a
network&apos;s reliance on single directions is a good predictor of its
generalization performance, across networks trained on datasets with different
fractions of corrupted labels, across ensembles of networks trained on datasets
with unmodified labels, across different hyperparameters, and over the course
of training. While dropout only regularizes this quantity up to a point, batch
normalization implicitly discourages single direction reliance, in part by
decreasing the class selectivity of individual units. Finally, we find that
class selectivity is a poor predictor of task importance, suggesting not only
that networks which generalize well minimize their dependence on individual
units by reducing their selectivity, but also that individually selective units
may not be necessary for strong network performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Morcos_A/0/1/0/all/0/1&quot;&gt;Ari S. Morcos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Barrett_D/0/1/0/all/0/1&quot;&gt;David G.T. Barrett&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rabinowitz_N/0/1/0/all/0/1&quot;&gt;Neil C. Rabinowitz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Botvinick_M/0/1/0/all/0/1&quot;&gt;Matthew Botvinick&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.07131">
<title>Automated Curriculum Learning by Rewarding Temporally Rare Events. (arXiv:1803.07131v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1803.07131</link>
<description rdf:parseType="Literal">&lt;p&gt;Reward shaping allows reinforcement learning (RL) agents to accelerate
learning by receiving additional reward signals. However, these signals can be
difficult to design manually, especially for complex RL tasks. We propose a
simple and general approach that determines the reward of pre-defined events by
their rarity alone. Here events become less rewarding as they are experienced
more often, which encourages the agent to continually explore new types of
events as it learns. The adaptiveness of this reward function results in a form
of automated curriculum learning that does not have to be specified by the
experimenter. We demonstrate that this Rarity of Events (RoE) approach enables
the agent to succeed in challenging VizDoom scenarios without access to the
extrinsic reward from the environment. Furthermore, the results demonstrate
that RoE learns a more versatile policy that adapts well to critical changes in
the environment. Rewarding events based on their rarity could help in many
unsolved RL environments that are characterized by sparse extrinsic rewards but
a plethora of known event types.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Justesen_N/0/1/0/all/0/1&quot;&gt;Niels Justesen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Risi_S/0/1/0/all/0/1&quot;&gt;Sebastian Risi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.07133">
<title>Neural Text Generation: Past, Present and Beyond. (arXiv:1803.07133v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1803.07133</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents a systematic survey on recent development of neural text
generation models. Specifically, we start from recurrent neural network
language models with the traditional maximum likelihood estimation training
scheme and point out its shortcoming for text generation. We thus introduce the
recently proposed methods for text generation based on reinforcement learning,
re-parametrization tricks and generative adversarial nets (GAN) techniques. We
compare different properties of these models and the corresponding techniques
to handle their common problems such as gradient vanishing and generation
diversity. Finally, we conduct a benchmarking experiment with different types
of neural text generation models on two well-known datasets and discuss the
empirical results along with the aforementioned model properties.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_S/0/1/0/all/0/1&quot;&gt;Sidi Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1&quot;&gt;Yaoming Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1&quot;&gt;Weinan Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jun Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1&quot;&gt;Yong Yu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.07139">
<title>English-Catalan Neural Machine Translation in the Biomedical Domain through the cascade approach. (arXiv:1803.07139v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1803.07139</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper describes the methodology followed to build a neural machine
translation system in the biomedical domain for the English-Catalan language
pair. This task can be considered a low-resourced task from the point of view
of the domain and the language pair. To face this task, this paper reports
experiments on a cascade pivot strategy through Spanish for the neural machine
translation using the English-Spanish SCIELO and Spanish-Catalan El Peri\&apos;odico
database. To test the final performance of the system, we have created a new
test data set for English-Catalan in the biomedical domain which is freely
available on request.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Costa_jussa_M/0/1/0/all/0/1&quot;&gt;Marta R. Costa-juss&amp;#xe0;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Casas_N/0/1/0/all/0/1&quot;&gt;Noe Casas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Melero_M/0/1/0/all/0/1&quot;&gt;Maite Melero&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.07170">
<title>Blaming humans in autonomous vehicle accidents: Shared responsibility across levels of automation. (arXiv:1803.07170v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1803.07170</link>
<description rdf:parseType="Literal">&lt;p&gt;When a semi-autonomous car crashes and harms someone, how are blame and
causal responsibility distributed across the human and machine drivers? In this
article, we consider cases in which a pedestrian was hit and killed by a car
being operated under shared control of a primary and a secondary driver. We
find that when only one driver makes an error, that driver receives the blame
and is considered causally responsible for the harm, regardless of whether that
driver is a machine or a human. However, when both drivers make errors in cases
of shared control between a human and a machine, the blame and responsibility
attributed to the machine is reduced. This finding portends a public
under-reaction to the malfunctioning AI components of semi-autonomous cars and
therefore has a direct policy implication: a bottom-up regulatory scheme (which
operates through tort law that is adjudicated through the jury system) could
fail to properly regulate the safety of shared-control vehicles; instead, a
top-down scheme (enacted through federal laws) may be called for.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Awad_E/0/1/0/all/0/1&quot;&gt;Edmond Awad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1&quot;&gt;Sydney Levine&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kleiman_Weiner_M/0/1/0/all/0/1&quot;&gt;Max Kleiman-Weiner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dsouza_S/0/1/0/all/0/1&quot;&gt;Sohan Dsouza&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tenenbaum_J/0/1/0/all/0/1&quot;&gt;Josh Tenenbaum&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shariff_A/0/1/0/all/0/1&quot;&gt;Azim Shariff&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bonnefon_J/0/1/0/all/0/1&quot;&gt;Jean-Fran&amp;#xe7;ois Bonnefon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rahwan_I/0/1/0/all/0/1&quot;&gt;Iyad Rahwan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.07233">
<title>Closing the AI Knowledge Gap. (arXiv:1803.07233v1 [cs.CY])</title>
<link>http://arxiv.org/abs/1803.07233</link>
<description rdf:parseType="Literal">&lt;p&gt;AI researchers employ not only the scientific method, but also methodology
from mathematics and engineering. However, the use of the scientific method -
specifically hypothesis testing - in AI is typically conducted in service of
engineering objectives. Growing interest in topics such as fairness and
algorithmic bias show that engineering-focused questions only comprise a subset
of the important questions about AI systems. This results in the AI Knowledge
Gap: the number of unique AI systems grows faster than the number of studies
that characterize these systems&apos; behavior. To close this gap, we argue that the
study of AI could benefit from the greater inclusion of researchers who are
well positioned to formulate and test hypotheses about the behavior of AI
systems. We examine the barriers preventing social and behavioral scientists
from conducting such studies. Our diagnosis suggests that accelerating the
scientific study of AI systems requires new incentives for academia and
industry, mediated by new tools and institutions. To address these needs, we
propose a two-sided marketplace called TuringBox. On one side, AI contributors
upload existing and novel algorithms to be studied scientifically by others. On
the other side, AI examiners develop and post machine intelligence tasks
designed to evaluate and characterize algorithmic behavior. We discuss this
market&apos;s potential to democratize the scientific study of AI behavior, and thus
narrow the AI Knowledge Gap.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Epstein_Z/0/1/0/all/0/1&quot;&gt;Ziv Epstein&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Payne_B/0/1/0/all/0/1&quot;&gt;Blakeley H. Payne&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_J/0/1/0/all/0/1&quot;&gt;Judy Hanwen Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dubey_A/0/1/0/all/0/1&quot;&gt;Abhimanyu Dubey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Felbo_B/0/1/0/all/0/1&quot;&gt;Bjarke Felbo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Groh_M/0/1/0/all/0/1&quot;&gt;Matthew Groh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Obradovich_N/0/1/0/all/0/1&quot;&gt;Nick Obradovich&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cebrian_M/0/1/0/all/0/1&quot;&gt;Manuel Cebrian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rahwan_I/0/1/0/all/0/1&quot;&gt;Iyad Rahwan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.07482">
<title>Natural Gradient Deep Q-learning. (arXiv:1803.07482v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1803.07482</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents findings for training a Q-learning reinforcement learning
agent using natural gradient techniques. We compare the original deep Q-network
(DQN) algorithm to its natural gradient counterpart (NGDQN), measuring NGDQN
and DQN performance on classic controls environments without target networks.
We find that NGDQN performs favorably relative to DQN, converging to
significantly better policies faster and more frequently. These results
indicate that natural gradient could be used for value function optimization in
reinforcement learning to accelerate and stabilize training.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Knight_E/0/1/0/all/0/1&quot;&gt;Ethan Knight&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lerner_O/0/1/0/all/0/1&quot;&gt;Osher Lerner&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.07517">
<title>Explanation Methods in Deep Learning: Users, Values, Concerns and Challenges. (arXiv:1803.07517v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1803.07517</link>
<description rdf:parseType="Literal">&lt;p&gt;Issues regarding explainable AI involve four components: users, laws &amp;amp;
regulations, explanations and algorithms. Together these components provide a
context in which explanation methods can be evaluated regarding their adequacy.
The goal of this chapter is to bridge the gap between expert users and lay
users. Different kinds of users are identified and their concerns revealed,
relevant statements from the General Data Protection Regulation are analyzed in
the context of Deep Neural Networks (DNNs), a taxonomy for the classification
of existing explanation methods is introduced, and finally, the various classes
of explanation methods are analyzed to verify if user concerns are justified.
Overall, it is clear that (visual) explanations can be given about various
aspects of the influence of the input on the output. However, it is noted that
explanation methods or interfaces for lay users are missing and we speculate
which criteria these methods / interfaces should satisfy. Finally it is noted
that two important concerns are difficult to address with explanation methods:
the concern about bias in datasets that leads to biased DNNs, as well as the
suspicion about unfair outcomes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ras_G/0/1/0/all/0/1&quot;&gt;Gabrielle Ras&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Haselager_P/0/1/0/all/0/1&quot;&gt;Pim Haselager&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gerven_M/0/1/0/all/0/1&quot;&gt;Marcel van Gerven&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1604.08612">
<title>Mysteries of Visual Experience. (arXiv:1604.08612v4 [q-bio.NC] UPDATED)</title>
<link>http://arxiv.org/abs/1604.08612</link>
<description rdf:parseType="Literal">&lt;p&gt;Science is a crowning glory of the human spirit and its applications remain
our best hope for social progress. But there are limitations to current science
and perhaps to any science. The general mind-body problem is known to be
intractable and currently mysterious. This is one of many deep problems that
are universally agreed to be beyond the current purview of Science, including
quantum phenomena, etc. But all of these famous unsolved problems are either
remote from everyday experience (entanglement, dark matter) or are hard to even
define sharply (phenomenology, consciousness, etc.).
&lt;/p&gt;
&lt;p&gt;In this note, we will consider some obvious computational problems in vision
that arise every time that we open our eyes and yet are demonstrably
incompatible with current theories of neural computation. The focus will be on
two related phenomena, known as the neural binding problem and the illusion of
a detailed stable visual world.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Feldman_J/0/1/0/all/0/1&quot;&gt;Jerome Feldman&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1708.08559">
<title>DeepTest: Automated Testing of Deep-Neural-Network-driven Autonomous Cars. (arXiv:1708.08559v2 [cs.SE] UPDATED)</title>
<link>http://arxiv.org/abs/1708.08559</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent advances in Deep Neural Networks (DNNs) have led to the development of
DNN-driven autonomous cars that, using sensors like camera, LiDAR, etc., can
drive without any human intervention. Most major manufacturers including Tesla,
GM, Ford, BMW, and Waymo/Google are working on building and testing different
types of autonomous vehicles. The lawmakers of several US states including
California, Texas, and New York have passed new legislation to fast-track the
process of testing and deployment of autonomous vehicles on their roads.
&lt;/p&gt;
&lt;p&gt;However, despite their spectacular progress, DNNs, just like traditional
software, often demonstrate incorrect or unexpected corner case behaviors that
can lead to potentially fatal collisions. Several such real-world accidents
involving autonomous cars have already happened including one which resulted in
a fatality. Most existing testing techniques for DNN-driven vehicles are
heavily dependent on the manual collection of test data under different driving
conditions which become prohibitively expensive as the number of test
conditions increases.
&lt;/p&gt;
&lt;p&gt;In this paper, we design, implement and evaluate DeepTest, a systematic
testing tool for automatically detecting erroneous behaviors of DNN-driven
vehicles that can potentially lead to fatal crashes. First, our tool is
designed to automatically generated test cases leveraging real-world changes in
driving conditions like rain, fog, lighting conditions, etc. DeepTest
systematically explores different parts of the DNN logic by generating test
inputs that maximize the numbers of activated neurons. DeepTest found thousands
of erroneous behaviors under different realistic driving conditions (e.g.,
blurring, rain, fog, etc.) many of which lead to potentially fatal crashes in
three top performing DNNs in the Udacity self-driving car challenge.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1&quot;&gt;Yuchi Tian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pei_K/0/1/0/all/0/1&quot;&gt;Kexin Pei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jana_S/0/1/0/all/0/1&quot;&gt;Suman Jana&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ray_B/0/1/0/all/0/1&quot;&gt;Baishakhi Ray&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.10026">
<title>Loss Surfaces, Mode Connectivity, and Fast Ensembling of DNNs. (arXiv:1802.10026v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1802.10026</link>
<description rdf:parseType="Literal">&lt;p&gt;The loss functions of deep neural networks are complex and their geometric
properties are not well understood. We show that the optima of these complex
loss functions are in fact connected by simple curves, such as a polygonal
chain with only one bend, over which training and test accuracy are nearly
constant. We introduce a training procedure to discover these high-accuracy
pathways between modes. Inspired by this new geometric insight, we also propose
a new ensembling method entitled Fast Geometric Ensembling (FGE). Using FGE we
can train high-performing ensembles in the time required to train a single
model. We achieve improved performance compared to the recent state-of-the-art
Snapshot Ensembles, on CIFAR-10 and CIFAR-100, using state-of-the-art deep
residual networks. On ImageNet we improve the top-1 error-rate of a pre-trained
ResNet by 0.56% by running FGE for just 5 epochs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Garipov_T/0/1/0/all/0/1&quot;&gt;Timur Garipov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Izmailov_P/0/1/0/all/0/1&quot;&gt;Pavel Izmailov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Podoprikhin_D/0/1/0/all/0/1&quot;&gt;Dmitrii Podoprikhin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Vetrov_D/0/1/0/all/0/1&quot;&gt;Dmitry Vetrov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wilson_A/0/1/0/all/0/1&quot;&gt;Andrew Gordon Wilson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.07164">
<title>Adversarial Generalized Method of Moments. (arXiv:1803.07164v1 [econ.EM])</title>
<link>http://arxiv.org/abs/1803.07164</link>
<description rdf:parseType="Literal">&lt;p&gt;We provide an approach for learning deep neural net representations of models
described via conditional moment restrictions. Conditional moment restrictions
are widely used, as they are the language by which social scientists describe
the assumptions they make to enable causal inference. We formulate the problem
of estimating the underling model as a zero-sum game between a modeler and an
adversary and apply adversarial training. Our approach is similar in nature to
Generative Adversarial Networks (GAN), though here the modeler is learning a
representation of a function that satisfies a continuum of moment conditions
and the adversary is identifying violating moments. We outline ways of
constructing effective adversaries in practice, including kernels centered by
k-means clustering, and random forests. We examine the practical performance of
our approach in the setting of non-parametric instrumental variable regression.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/econ/1/au:+Lewis_G/0/1/0/all/0/1&quot;&gt;Greg Lewis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/econ/1/au:+Syrgkanis_V/0/1/0/all/0/1&quot;&gt;Vasilis Syrgkanis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.07192">
<title>Diagnostic Classification Of Lung Nodules Using 3D Neural Networks. (arXiv:1803.07192v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1803.07192</link>
<description rdf:parseType="Literal">&lt;p&gt;Lung cancer is the leading cause of cancer-related death worldwide. Early
diagnosis of pulmonary nodules in Computed Tomography (CT) chest scans provides
an opportunity for designing effective treatment and making financial and care
plans. In this paper, we consider the problem of diagnostic classification
between benign and malignant lung nodules in CT images, which aims to learn a
direct mapping from 3D images to class labels. To achieve this goal, four
two-pathway Convolutional Neural Networks (CNN) are proposed, including a basic
3D CNN, a novel multi-output network, a 3D DenseNet, and an augmented 3D
DenseNet with multi-outputs. These four networks are evaluated on the public
LIDC-IDRI dataset and outperform most existing methods. In particular, the 3D
multi-output DenseNet (MoDenseNet) achieves the state-of-the-art classification
accuracy on the task of end-to-end lung nodule diagnosis. In addition, the
networks pretrained on the LIDC-IDRI dataset can be further extended to handle
smaller datasets using transfer learning. This is demonstrated on our dataset
with encouraging prediction accuracy in lung nodule classification.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dey_R/0/1/0/all/0/1&quot;&gt;Raunak Dey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_Z/0/1/0/all/0/1&quot;&gt;Zhongjie Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hong_Y/0/1/0/all/0/1&quot;&gt;Yi Hong&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.07416">
<title>Tensor2Tensor for Neural Machine Translation. (arXiv:1803.07416v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1803.07416</link>
<description rdf:parseType="Literal">&lt;p&gt;Tensor2Tensor is a library for deep learning models that is well-suited for
neural machine translation and includes the reference implementation of the
state-of-the-art Transformer model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vaswani_A/0/1/0/all/0/1&quot;&gt;Ashish Vaswani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bengio_S/0/1/0/all/0/1&quot;&gt;Samy Bengio&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brevdo_E/0/1/0/all/0/1&quot;&gt;Eugene Brevdo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chollet_F/0/1/0/all/0/1&quot;&gt;Francois Chollet&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gomez_A/0/1/0/all/0/1&quot;&gt;Aidan N. Gomez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gouws_S/0/1/0/all/0/1&quot;&gt;Stephan Gouws&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jones_L/0/1/0/all/0/1&quot;&gt;Llion Jones&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kaiser_L/0/1/0/all/0/1&quot;&gt;&amp;#x141;ukasz Kaiser&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kalchbrenner_N/0/1/0/all/0/1&quot;&gt;Nal Kalchbrenner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Parmar_N/0/1/0/all/0/1&quot;&gt;Niki Parmar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sepassi_R/0/1/0/all/0/1&quot;&gt;Ryan Sepassi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shazeer_N/0/1/0/all/0/1&quot;&gt;Noam Shazeer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Uszkoreit_J/0/1/0/all/0/1&quot;&gt;Jakob Uszkoreit&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.07445">
<title>MLtuner: System Support for Automatic Machine Learning Tuning. (arXiv:1803.07445v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1803.07445</link>
<description rdf:parseType="Literal">&lt;p&gt;MLtuner automatically tunes settings for training tunables (such as the
learning rate, the momentum, the mini-batch size, and the data staleness bound)
that have a significant impact on large-scale machine learning (ML)
performance. Traditionally, these tunables are set manually, which is
unsurprisingly error-prone and difficult to do without extensive domain
knowledge. MLtuner uses efficient snapshotting, branching, and
optimization-guided online trial-and-error to find good initial settings as
well as to re-tune settings during execution. Experiments show that MLtuner can
robustly find and re-tune tunable settings for a variety of ML applications,
including image classification (for 3 models and 2 datasets), video
classification, and matrix factorization. Compared to state-of-the-art ML
auto-tuning approaches, MLtuner is more robust for large problems and over an
order of magnitude faster.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cui_H/0/1/0/all/0/1&quot;&gt;Henggang Cui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ganger_G/0/1/0/all/0/1&quot;&gt;Gregory R. Ganger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gibbons_P/0/1/0/all/0/1&quot;&gt;Phillip B. Gibbons&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.07551">
<title>Meta Reinforcement Learning with Latent Variable Gaussian Processes. (arXiv:1803.07551v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1803.07551</link>
<description rdf:parseType="Literal">&lt;p&gt;Data efficiency, i.e., learning from small data sets, is critical in many
practical applications where data collection is time consuming or expensive,
e.g., robotics, animal experiments or drug design. Meta learning is one way to
increase the data efficiency of learning algorithms by generalizing learned
concepts from a set of training tasks to unseen, but related, tasks. Often,
this relationship between tasks is hard coded or relies in some other way on
human expertise. In this paper, we propose to automatically learn the
relationship between tasks using a latent variable model. Our approach finds a
variational posterior over tasks and averages over all plausible (according to
this posterior) tasks when making predictions. We apply this framework within a
model-based reinforcement learning setting for learning dynamics models and
controllers of many related tasks. We apply our framework in a model-based
reinforcement learning setting, and show that our model effectively generalizes
to novel tasks, and that it reduces the average interaction time needed to
solve tasks by up to 60% compared to strong baselines.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Saemundsson_S/0/1/0/all/0/1&quot;&gt;Steind&amp;#xf3;r S&amp;#xe6;mundsson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hofmann_K/0/1/0/all/0/1&quot;&gt;Katja Hofmann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Deisenroth_M/0/1/0/all/0/1&quot;&gt;Marc Peter Deisenroth&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1506.03410">
<title>Randomer Forests. (arXiv:1506.03410v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1506.03410</link>
<description rdf:parseType="Literal">&lt;p&gt;Ensemble methods -- particularly those based on decision trees -- have
recently demonstrated superior performance in a variety of machine learning
settings. Specifically, Random Forest (RF) was found to outperform &amp;gt;100 other
methods in several manuscripts, and gradient boosting trees have been a crucial
component of several recent Kaggle competition victories. Building off these
successes and recent advances in sparse learning and random matrix theory, we
propose a novel ensemble tree method called &quot;Randomer Forest&quot; (RerF). The key
intuition behind RerF is that we can use sparse linear combinations at each
decision node rather than just one feature (as in RF) or all of them (as in
Rotation Forests). RerF significantly outperforms other methods on a standard
benchmark suite containing 105 problems with varying dimension, sample size,
and number of classes. Moreover, we provide an implementation that scales as or
more efficiently than other available packages. Via a combination of basic
principles, theory, and extensive numerical experiments, we demonstrate why,
when, and how RerF achieves its performance properties.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tomita_T/0/1/0/all/0/1&quot;&gt;Tyler M. Tomita&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Browne_J/0/1/0/all/0/1&quot;&gt;James Browne&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Shen_C/0/1/0/all/0/1&quot;&gt;Cencheng Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Priebe_C/0/1/0/all/0/1&quot;&gt;Carey E. Priebe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Burns_R/0/1/0/all/0/1&quot;&gt;Randal Burns&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Maggioni_M/0/1/0/all/0/1&quot;&gt;Mauro Maggioni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Vogelstein_J/0/1/0/all/0/1&quot;&gt;Joshua T. Vogelstein&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1702.01417">
<title>All-but-the-Top: Simple and Effective Postprocessing for Word Representations. (arXiv:1702.01417v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1702.01417</link>
<description rdf:parseType="Literal">&lt;p&gt;Real-valued word representations have transformed NLP applications; popular
examples are word2vec and GloVe, recognized for their ability to capture
linguistic regularities. In this paper, we demonstrate a {\em very simple}, and
yet counter-intuitive, postprocessing technique -- eliminate the common mean
vector and a few top dominating directions from the word vectors -- that
renders off-the-shelf representations {\em even stronger}. The postprocessing
is empirically validated on a variety of lexical-level intrinsic tasks (word
similarity, concept categorization, word analogy) and sentence-level tasks
(semantic textural similarity and { text classification}) on multiple datasets
and with a variety of representation methods and hyperparameter choices in
multiple languages; in each case, the processed representations are
consistently better than the original ones.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mu_J/0/1/0/all/0/1&quot;&gt;Jiaqi Mu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bhat_S/0/1/0/all/0/1&quot;&gt;Suma Bhat&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Viswanath_P/0/1/0/all/0/1&quot;&gt;Pramod Viswanath&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.04540">
<title>Fix your classifier: the marginal value of training the last weight layer. (arXiv:1801.04540v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1801.04540</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural networks are commonly used as models for classification for a wide
variety of tasks. Typically, a learned affine transformation is placed at the
end of such models, yielding a per-class value used for classification. This
classifier can have a vast number of parameters, which grows linearly with the
number of possible classes, thus requiring increasingly more resources. In this
work we argue that this classifier can be fixed, up to a global scale constant,
with little or no loss of accuracy for most tasks, allowing memory and
computational benefits. Moreover, we show that by initializing the classifier
with a Hadamard matrix we can speed up inference as well. We discuss the
implications for current understanding of neural network models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hoffer_E/0/1/0/all/0/1&quot;&gt;Elad Hoffer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hubara_I/0/1/0/all/0/1&quot;&gt;Itay Hubara&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Soudry_D/0/1/0/all/0/1&quot;&gt;Daniel Soudry&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.03764">
<title>Variance Networks: When Expectation Does Not Meet Your Expectations. (arXiv:1803.03764v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1803.03764</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we propose variance networks, a new model that stores the
learned information in the variances of the network weights. Surprisingly, no
information gets stored in the expectations of the weights, therefore if we
replace these weights with their expectations, we would obtain a random guess
quality prediction. We provide a numerical criterion that uses the loss
curvature to determine which random variables can be replaced with their
expected values, and find that only a small fraction of weights is needed for
ensembling. Variance networks represent a diverse ensemble that is more robust
to adversarial attacks than conventional low-variance ensembles. The success of
this model raises several counter-intuitive implications for the training and
application of Deep Learning models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Neklyudov_K/0/1/0/all/0/1&quot;&gt;Kirill Neklyudov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Molchanov_D/0/1/0/all/0/1&quot;&gt;Dmitry Molchanov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ashukha_A/0/1/0/all/0/1&quot;&gt;Arsenii Ashukha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Vetrov_D/0/1/0/all/0/1&quot;&gt;Dmitry Vetrov&lt;/a&gt;</dc:creator>
</item></rdf:RDF>