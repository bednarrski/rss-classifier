<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Good papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Good Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-05-21T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07433"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07443"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07494"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07500"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07502"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07504"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07508"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07531"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07569"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07802"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07907"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08079"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08180"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1703.04706"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08219"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.03635"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.06959"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.09574"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07440"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07470"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07473"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07476"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07541"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07603"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07648"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07715"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07782"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07797"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07798"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07828"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07848"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07883"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07894"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07897"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07941"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07966"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08000"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.04520"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.00386"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05312"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05944"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.00215"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.01109"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.06020"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07418"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07441"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07475"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07483"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07517"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07544"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07557"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07594"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07631"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07640"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07674"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07722"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07723"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07813"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07852"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07857"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07862"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07869"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07892"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07898"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07984"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08006"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08090"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08095"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08096"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08097"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08122"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08136"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1708.08863"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.10628"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05335"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.00502"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.03467"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.05296"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.05532"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.06431"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07137"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07324"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.08557"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1805.07433">
<title>DeepLogic: End-to-End Logical Reasoning. (arXiv:1805.07433v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1805.07433</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural networks have been learning complex multi-hop reasoning in various
domains. One such formal setting for reasoning, logic, provides a challenging
case for neural networks. In this article, we propose a Neural Inference
Network (NIN) for learning logical inference over classes of logic programs.
Trained in an end-to-end fashion NIN learns representations of normal logic
programs, by processing them at a character level, and the reasoning algorithm
for checking whether a logic program entails a given query. We define 12
classes of logic programs that exemplify increased level of complexity of the
inference process (multi-hop and default reasoning) and show that our NIN
passes 10 out of the 12 tasks. We also analyse the learnt representations of
logic programs that NIN uses to perform the logical inference.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cingillioglu_N/0/1/0/all/0/1&quot;&gt;Nuri Cingillioglu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Russo_A/0/1/0/all/0/1&quot;&gt;Alessandra Russo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07443">
<title>Multi-view Sentence Representation Learning. (arXiv:1805.07443v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1805.07443</link>
<description rdf:parseType="Literal">&lt;p&gt;Multi-view learning can provide self-supervision when different views are
available of the same data. The distributional hypothesis provides another form
of useful self-supervision from adjacent sentences which are plentiful in large
unlabelled corpora. Motivated by the asymmetry in the two hemispheres of the
human brain as well as the observation that different learning architectures
tend to emphasise different aspects of sentence meaning, we create a unified
multi-view sentence representation learning framework, in which, one view
encodes the input sentence with a Recurrent Neural Network (RNN), and the other
view encodes it with a simple linear model, and the training objective is to
maximise the agreement specified by the adjacent context information between
two views. We show that, after training, the vectors produced from our
multi-view training provide improved representations over the single-view
training, and the combination of different views gives further representational
improvement and demonstrates solid transferability on standard downstream
tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_S/0/1/0/all/0/1&quot;&gt;Shuai Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sa_V/0/1/0/all/0/1&quot;&gt;Virginia R. de Sa&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07494">
<title>Number Sequence Prediction Problems and Computational Powers of Neural Network Models. (arXiv:1805.07494v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1805.07494</link>
<description rdf:parseType="Literal">&lt;p&gt;Inspired by number series tests to measure human intelligence, we suggest
number sequence prediction tasks to assess neural network models&apos; computational
powers for solving algorithmic problems. We define complexity and difficulty of
a number sequence prediction task with the structure of the smallest automation
that can generate the sequence. We suggest two types of number sequence
prediction problems: the number-level and the digit-level problems. The
number-level problems format sequences as 2-dimensional grids of digits, and
the digit-level problem provides a single digit input per a time step, hence
solving this problem is equivalent to modeling a sequential state automation.
The complexity of a number-level sequence problem can be defined with the depth
of an equivalent combinatorial logic. Experimental results with CNN models
suggest that they are capable of learning the compound operations of the
number-level sequence generation rules but the depths of the compound
operations are limited. For the digit-level problems, GRU and LSTM models can
solve the problems with complexity of finite state automations, but they cannot
solve the problems with complexity of pushdown automations or Turing machines.
The results show that our number sequence prediction problems effectively
evaluate machine learning models&apos; computational capabilities.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nam_H/0/1/0/all/0/1&quot;&gt;Hyoungwook Nam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1&quot;&gt;Segwang Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jung_K/0/1/0/all/0/1&quot;&gt;Kyomin Jung&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07500">
<title>GADAM: Genetic-Evolutionary ADAM for Deep Neural Network Optimization. (arXiv:1805.07500v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.07500</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep neural network learning can be formulated as a non-convex optimization
problem. Existing optimization algorithms, e.g., Adam, can learn the models
fast, but may get stuck in local optima easily. In this paper, we introduce a
novel optimization algorithm, namely GADAM (Genetic-Evolutionary Adam). GADAM
learns deep neural network models based on a number of unit models generations
by generations: it trains the unit models with Adam, and evolves them to the
new generations with genetic algorithm. We will show that GADAM can effectively
jump out of the local optima in the learning process to obtain better
solutions, and prove that GADAM can also achieve a very fast convergence.
Extensive experiments have been done on various benchmark datasets, and the
learning results will demonstrate the effectiveness and efficiency of the GADAM
algorithm.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Jiawei Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cui_L/0/1/0/all/0/1&quot;&gt;Limeng Cui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gouza_F/0/1/0/all/0/1&quot;&gt;Fisher B. Gouza&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07502">
<title>On Deep Ensemble Learning from a Function Approximation Perspective. (arXiv:1805.07502v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.07502</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we propose to provide a general ensemble learning framework
based on deep learning models. Given a group of unit models, the proposed deep
ensemble learning framework will effectively combine their learning results via
a multilayered ensemble model. In the case when the unit model mathematical
mappings are bounded, sigmoidal and discriminatory, we demonstrate that the
deep ensemble learning framework can achieve a universal approximation of any
functions from the input space to the output space. Meanwhile, to achieve such
a performance, the deep ensemble learning framework also impose a strict
constraint on the number of involved unit models. According to the theoretic
proof provided in this paper, given the input feature space of dimension d, the
required unit model number will be 2d, if the ensemble model involves one
single layer. Furthermore, as the ensemble component goes deeper, the number of
required unit model is proved to be lowered down exponentially.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Jiawei Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cui_L/0/1/0/all/0/1&quot;&gt;Limeng Cui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gouza_F/0/1/0/all/0/1&quot;&gt;Fisher B. Gouza&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07504">
<title>Deep Loopy Neural Network Model for Graph Structured Data Representation Learning. (arXiv:1805.07504v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.07504</link>
<description rdf:parseType="Literal">&lt;p&gt;Existing deep learning models may encounter great challenges in handling
graph structured data. In this paper, we introduce a new deep learning model
for graph data specifically, namely the deep loopy neural network.
Significantly different from the previous deep models, inside the deep loopy
neural network, there exist a large number of loops created by the extensive
connections among nodes in the input graph data, which makes model learning an
infeasible task. To resolve such a problem, in this paper, we will introduce a
new learning algorithm for the deep loopy neural network specifically. Instead
of learning the model variables based on the original model, in the proposed
learning algorithm, errors will be back-propagated through the edges in a group
of extracted spanning trees. Extensive numerical experiments have been done on
several real-world graph datasets, and the experimental results demonstrate the
effectiveness of both the proposed model and the learning algorithm in handling
graph data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Jiawei Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cui_L/0/1/0/all/0/1&quot;&gt;Limeng Cui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gouza_F/0/1/0/all/0/1&quot;&gt;Fisher B. Gouza&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07508">
<title>GEN Model: An Alternative Approach to Deep Neural Network Models. (arXiv:1805.07508v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.07508</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we introduce an alternative approach, namely GEN (Genetic
Evolution Network) Model, to the deep learning models. Instead of building one
single deep model, GEN adopts a genetic-evolutionary learning strategy to build
a group of unit models generations by generations. Significantly different from
the wellknown representation learning models with extremely deep structures,
the unit models covered in GEN are of a much shallower architecture. In the
training process, from each generation, a subset of unit models will be
selected based on their performance to evolve and generate the child models in
the next generation. GEN has significant advantages compared with existing deep
representation learning models in terms of both learning effectiveness,
efficiency and interpretability of the learning process and learned results.
Extensive experiments have been done on diverse benchmark datasets, and the
experimental results have demonstrated the outstanding performance of GEN
compared with the state-of-the-art baseline methods in both effectiveness of
efficiency.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Jiawei Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cui_L/0/1/0/all/0/1&quot;&gt;Limeng Cui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gouza_F/0/1/0/all/0/1&quot;&gt;Fisher B. Gouza&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07531">
<title>Neural networks with dynamical coefficients and adjustable connections on the basis of integrated backpropagation. (arXiv:1805.07531v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1805.07531</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider artificial neurons which will update their weight coefficients
with internal rule based on backpropagation, rather than using it as an
external training procedure. To achieve this we include the backpropagation
error estimate as a separate entity in all the neuron models and perform its
exchange along the synaptic connections. In addition to this we add some
special type of neurons with reference inputs, which will serve as a base
source of error estimates for the whole network. Finally, we introduce a
training control signal for all the neurons, which can enable the correction of
weights and the exchange of error estimates. For recurrent neural networks we
also demonstrate how to include backpropagation through time into their
formalism with the help of some stack memory for reference inputs and external
data inputs of neurons. As a useful consequence, our approach enables us to
introduce neural networks with the adjustment of synaptic connections, tied to
the incorporated backpropagation. Also, for widely used neural networks, such
as long short-term memory, radial basis function networks, multilayer
perceptrons and convolutional neural networks we demonstrate their alternative
description within the framework of our new formalism.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nazarov_M/0/1/0/all/0/1&quot;&gt;M. N. Nazarov&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07569">
<title>Reliable counting of weakly labeled concepts by a single spiking neuron model. (arXiv:1805.07569v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1805.07569</link>
<description rdf:parseType="Literal">&lt;p&gt;Making an informed, correct and quick decision can be life-saving. It&apos;s
crucial for animals during an escape behaviour or for autonomous cars during
driving. The decision can be complex and may involve an assessment of the
amount of threats present and the nature of each threat. Thus, we should expect
early sensory processing to supply classification information fast and
accurately, even before relying the information to higher brain areas or more
complex system components downstream. Today, advanced convolution artificial
neural networks can successfully solve such tasks and are commonly used to
build complex decision making systems. However, in order to achieve excellent
performance on these tasks they require increasingly complex, &quot;very deep&quot; model
structure, which is costly in inference run-time, energy consumption and
training samples, only trainable on cloud-computing clusters. A single spiking
neuron has been shown to be able to solve many of these required tasks for
homogeneous Poisson input statistics, a commonly used model for spiking
activity in the neocortex; when modeled as leaky integrate and fire with
gradient decent learning algorithm it was shown to posses a wide variety of
complex computational capabilities. Here we improve its learning algorithm. We
also account for more natural stimulus generated inputs that deviate from this
homogeneous Poisson spiking. The improved gradient-based local learning rule
allows for significantly better and stable generalization and more efficient
performance. We finally apply our model to a problem of multiple instance
learning with counting where labels are only available for collections of
concepts. In this counting MNIST task the neuron exploits the improved
algorithm and succeeds while out performing the previously introduced single
neuron learning algorithm as well as conventional ConvNet architecture under
similar conditions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rapp_H/0/1/0/all/0/1&quot;&gt;Hannes Rapp&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nawrot_M/0/1/0/all/0/1&quot;&gt;Martin Paul Nawrot&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stern_M/0/1/0/all/0/1&quot;&gt;Merav Stern&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07802">
<title>Network Learning with Local Propagation. (arXiv:1805.07802v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.07802</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents a locally decoupled network parameter learning with local
propagation. Three elements are taken into account: (i) sets of nonlinear
transforms that describe the representations at all nodes, (ii) a local
objective at each node related to the corresponding local representation goal,
and (iii) a local propagation model that relates the nonlinear error vectors at
each node with the goal error vectors from the directly connected nodes. The
modeling concepts (i), (ii) and (iii) offer several advantages, including (a) a
unified learning principle for any network that is represented as a graph, (b)
understanding and interpretation of the local and the global learning dynamics,
(c) decoupled and parallel parameter learning, (d) a possibility for learning
in infinitely long, multi-path and multi-goal networks. Numerical experiments
validate the potential of the learning principle. The preliminary results show
advantages in comparison to the state-of-the-art methods, w.r.t. the learning
time and the network size while having comparable recognition accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kostadinov_D/0/1/0/all/0/1&quot;&gt;Dimche Kostadinov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Razeghi_B/0/1/0/all/0/1&quot;&gt;Behrooz Razeghi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ferdowsi_S/0/1/0/all/0/1&quot;&gt;Sohrab Ferdowsi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Voloshynovskiy_S/0/1/0/all/0/1&quot;&gt;Slava Voloshynovskiy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07907">
<title>IoT2Vec: Identification of Similar IoT Devices via Activity Footprints. (arXiv:1805.07907v1 [cs.HC])</title>
<link>http://arxiv.org/abs/1805.07907</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider a smart home or smart office environment with a number of IoT
devices connected and passing data between one another. The footprints of the
data transferred can provide valuable information about the devices, which can
be used to (a) identify the IoT devices and (b) in case of failure, to identify
the correct replacements for these devices. In this paper, we generate the
embeddings for IoT devices in a smart home using Word2Vec, and explore the
possibility of having a similar concept for IoT devices, aka IoT2Vec. These
embeddings can be used in a number of ways, such as to find similar devices in
an IoT device store, or as a signature of each type of IoT device. We show
results of a feasibility study on the CASAS dataset of IoT device activity
logs, using our method to identify the patterns in embeddings of various types
of IoT devices in a household.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singla_K/0/1/0/all/0/1&quot;&gt;Kushal Singla&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bose_J/0/1/0/all/0/1&quot;&gt;Joy Bose&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08079">
<title>Faster Neural Network Training with Approximate Tensor Operations. (arXiv:1805.08079v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.08079</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a novel technique for faster Neural Network (NN) training by
systematically approximating all the constituent matrix multiplications and
convolutions. This approach is complementary to other approximation techniques,
requires no changes to the dimensions of the network layers, hence compatible
with existing training frameworks. We first analyze the applicability of the
existing methods for approximating matrix multiplication to NN training, and
extend the most suitable column-row sampling algorithm to approximating
multi-channel convolutions. We apply approximate tensor operations to training
MLP, CNN and LSTM network architectures on MNIST, CIFAR-100 and Penn Tree Bank
datasets and demonstrate 30%-80% reduction in the amount of computations while
maintaining little or no impact on the test accuracy. Our promising results
encourage further study of general methods for approximating tensor operations
and their application to NN training.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Adelman_M/0/1/0/all/0/1&quot;&gt;Menachem Adelman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Silberstein_M/0/1/0/all/0/1&quot;&gt;Mark Silberstein&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08180">
<title>Hierarchical Reinforcement Learning with Hindsight. (arXiv:1805.08180v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.08180</link>
<description rdf:parseType="Literal">&lt;p&gt;Reinforcement Learning (RL) algorithms can suffer from poor sample efficiency
when rewards are delayed and sparse. We introduce a solution that enables
agents to learn temporally extended actions at multiple levels of abstraction
in a sample efficient and automated fashion. Our approach combines universal
value functions and hindsight learning, allowing agents to learn policies
belonging to different time scales in parallel. We show that our method
significantly accelerates learning in a variety of discrete and continuous
tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Levy_A/0/1/0/all/0/1&quot;&gt;Andrew Levy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Platt_R/0/1/0/all/0/1&quot;&gt;Robert Platt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saenko_K/0/1/0/all/0/1&quot;&gt;Kate Saenko&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1703.04706">
<title>Tree Memory Networks for Modelling Long-term Temporal Dependencies. (arXiv:1703.04706v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1703.04706</link>
<description rdf:parseType="Literal">&lt;p&gt;In the domain of sequence modelling, Recurrent Neural Networks (RNN) have
been capable of achieving impressive results in a variety of application areas
including visual question answering, part-of-speech tagging and machine
translation. However this success in modelling short term dependencies has not
successfully transitioned to application areas such as trajectory prediction,
which require capturing both short term and long term relationships. In this
paper, we propose a Tree Memory Network (TMN) for modelling long term and short
term relationships in sequence-to-sequence mapping problems. The proposed
network architecture is composed of an input module, controller and a memory
module. In contrast to related literature, which models the memory as a
sequence of historical states, we model the memory as a recursive tree
structure. This structure more effectively captures temporal dependencies
across both short term and long term sequences using its hierarchical
structure. We demonstrate the effectiveness and flexibility of the proposed TMN
in two practical problems, aircraft trajectory modelling and pedestrian
trajectory modelling in a surveillance setting, and in both cases we outperform
the current state-of-the-art. Furthermore, we perform an in depth analysis on
the evolution of the memory module content over time and provide visual
evidence on how the proposed TMN is able to map both long term and short term
relationships efficiently via a hierarchical structure.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fernando_T/0/1/0/all/0/1&quot;&gt;Tharindu Fernando&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Denman_S/0/1/0/all/0/1&quot;&gt;Simon Denman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+McFadyen_A/0/1/0/all/0/1&quot;&gt;Aaron McFadyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sridharan_S/0/1/0/all/0/1&quot;&gt;Sridha Sridharan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fookes_C/0/1/0/all/0/1&quot;&gt;Clinton Fookes&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08219">
<title>Tensor field networks: Rotation- and translation-equivariant neural networks for 3D point clouds. (arXiv:1802.08219v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1802.08219</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce tensor field neural networks, which are locally equivariant to
3D rotations, translations, and permutations of points at every layer. 3D
rotation equivariance removes the need for data augmentation to identify
features in arbitrary orientations. Our network uses filters built from
spherical harmonics; due to the mathematical consequences of this filter
choice, each layer accepts as input (and guarantees as output) scalars,
vectors, and higher-order tensors, in the geometric sense of these terms. We
demonstrate the capabilities of tensor field networks with tasks in geometry,
physics, and chemistry.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Thomas_N/0/1/0/all/0/1&quot;&gt;Nathaniel Thomas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Smidt_T/0/1/0/all/0/1&quot;&gt;Tess Smidt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kearnes_S/0/1/0/all/0/1&quot;&gt;Steven Kearnes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1&quot;&gt;Lusann Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1&quot;&gt;Li Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kohlhoff_K/0/1/0/all/0/1&quot;&gt;Kai Kohlhoff&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Riley_P/0/1/0/all/0/1&quot;&gt;Patrick Riley&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.03635">
<title>The Lottery Ticket Hypothesis: Finding Small, Trainable Neural Networks. (arXiv:1803.03635v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1803.03635</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural network compression techniques are able to reduce the parameter counts
of trained networks by over 90%--decreasing storage requirements and improving
inference performance--without compromising accuracy. However, contemporary
experience is that it is difficult to train small architectures from scratch,
which would similarly improve training performance.
&lt;/p&gt;
&lt;p&gt;We articulate a new conjecture to explain why it is easier to train large
networks: the &quot;lottery ticket hypothesis.&quot; It states that large networks that
train successfully contain subnetworks that--when trained in
isolation--converge in a comparable number of iterations to comparable
accuracy. These subnetworks, which we term &quot;winning tickets,&quot; have won the
initialization lottery: their connections have initial weights that make
training particularly effective.
&lt;/p&gt;
&lt;p&gt;We find that a standard technique for pruning unnecessary network weights
naturally uncovers a subnetwork which, at the start of training, comprised a
winning ticket. We present an algorithm to identify winning tickets and a
series of experiments that support the lottery ticket hypothesis. We
consistently find winning tickets that are less than 20% of the size of several
fully-connected, convolutional, and residual architectures for MNIST and
CIFAR10. Furthermore, winning tickets at moderate levels of pruning (20-50% of
the original network size) converge up to 6.7x faster than the original network
and exhibit higher test accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Frankle_J/0/1/0/all/0/1&quot;&gt;Jonathan Frankle&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Carbin_M/0/1/0/all/0/1&quot;&gt;Michael Carbin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.06959">
<title>On the importance of single directions for generalization. (arXiv:1803.06959v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1803.06959</link>
<description rdf:parseType="Literal">&lt;p&gt;Despite their ability to memorize large datasets, deep neural networks often
achieve good generalization performance. However, the differences between the
learned solutions of networks which generalize and those which do not remain
unclear. Additionally, the tuning properties of single directions (defined as
the activation of a single unit or some linear combination of units in response
to some input) have been highlighted, but their importance has not been
evaluated. Here, we connect these lines of inquiry to demonstrate that a
network&apos;s reliance on single directions is a good predictor of its
generalization performance, across networks trained on datasets with different
fractions of corrupted labels, across ensembles of networks trained on datasets
with unmodified labels, across different hyperparameters, and over the course
of training. While dropout only regularizes this quantity up to a point, batch
normalization implicitly discourages single direction reliance, in part by
decreasing the class selectivity of individual units. Finally, we find that
class selectivity is a poor predictor of task importance, suggesting not only
that networks which generalize well minimize their dependence on individual
units by reducing their selectivity, but also that individually selective units
may not be necessary for strong network performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Morcos_A/0/1/0/all/0/1&quot;&gt;Ari S. Morcos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Barrett_D/0/1/0/all/0/1&quot;&gt;David G.T. Barrett&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rabinowitz_N/0/1/0/all/0/1&quot;&gt;Neil C. Rabinowitz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Botvinick_M/0/1/0/all/0/1&quot;&gt;Matthew Botvinick&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.09574">
<title>Long short-term memory and learning-to-learn in networks of spiking neurons. (arXiv:1803.09574v2 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1803.09574</link>
<description rdf:parseType="Literal">&lt;p&gt;The brain carries out demanding computations and learning processes with
recurrent networks of spiking neurons (RSNNs). But computing and learning
capabilities of currently available RSNN models have remained poor, especially
in comparison with the performance of recurrent networks of artificial neurons,
such as Long Short-Term Memory (LSTM) networks. In this article, we investigate
whether deep learning can improve RSNN performance. We applied backpropagation
through time (BPTT), augmented by biologically inspired heuristics for synaptic
rewiring, to RSNNs whose inherent time constants were enriched through simple
models for adapting spiking neurons. We found that the resulting RSNNs
approximate, for the first time, the computational power of LSTM networks on
two common benchmark tasks. Furthermore, our results show that recent successes
with applications of Learning-to-Learn (L2L) to LSTM networks can be ported to
RSNNs. This opens the door to the investigation of L2L in data-based models for
neural networks of the brain, whose activity can -- unlike that of LSTM
networks -- be compared directly with recordings from neurons in the brain. In
particular, L2L shows that RSNNs can learn large families of non-linear
transformations from very few examples, using previously unknown network
learning mechanisms. Furthermore, meta-reinforcement learning (meta-RL) shows
that LSNNs can learn and execute complex exploration and exploitation
strategies.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bellec_G/0/1/0/all/0/1&quot;&gt;Guillaume Bellec&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Salaj_D/0/1/0/all/0/1&quot;&gt;Darjan Salaj&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Subramoney_A/0/1/0/all/0/1&quot;&gt;Anand Subramoney&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Legenstein_R/0/1/0/all/0/1&quot;&gt;Robert Legenstein&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Maass_W/0/1/0/all/0/1&quot;&gt;Wolfgang Maass&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07440">
<title>AlphaX: eXploring Neural Architectures with Deep Neural Networks and Monte Carlo Tree Search. (arXiv:1805.07440v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.07440</link>
<description rdf:parseType="Literal">&lt;p&gt;We present AlphaX, a fully automated agent that designs complex neural
architectures from scratch. AlphaX explores the exponentially exploded search
space with a novel distributed Monte Carlo Tree Search (MCTS) and a Meta-Deep
Neural Network (DNN). MCTS intrinsically improves the search efficiency by
automatically balancing the exploration and exploitation at each state, while
Meta-DNN predicts the network accuracy to guide the search, and to provide an
estimated reward for the preemptive backpropagation in the distributed setup.
As the search progresses, AlphaX also generates the training date for Meta-DNN.
So, the learning of Meta-DNN is end-to-end. In searching for NASNet style
architectures, AlphaX found several promising architectures with up to 1%
higher accuracy than NASNet using only 17 GPUs for 5 days, demonstrating up to
23.5x speedup over the original searching for NASNet that used 500 GPUs in 4
days.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1&quot;&gt;Linnan Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1&quot;&gt;Yiyang Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jinnai_Y/0/1/0/all/0/1&quot;&gt;Yuu Jinnai&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07470">
<title>Solving the Rubik&apos;s Cube Without Human Knowledge. (arXiv:1805.07470v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1805.07470</link>
<description rdf:parseType="Literal">&lt;p&gt;A generally intelligent agent must be able to teach itself how to solve
problems in complex domains with minimal human supervision. Recently, deep
reinforcement learning algorithms combined with self-play have achieved
superhuman proficiency in Go, Chess, and Shogi without human data or domain
knowledge. In these environments, a reward is always received at the end of the
game, however, for many combinatorial optimization environments, rewards are
sparse and episodes are not guaranteed to terminate. We introduce Autodidactic
Iteration: a novel reinforcement learning algorithm that is able to teach
itself how to solve the Rubik&apos;s Cube with no human assistance. Our algorithm is
able to solve 100% of randomly scrambled cubes while achieving a median solve
length of 30 moves -- less than or equal to solvers that employ human domain
knowledge.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+McAleer_S/0/1/0/all/0/1&quot;&gt;Stephen McAleer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Agostinelli_F/0/1/0/all/0/1&quot;&gt;Forest Agostinelli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shmakov_A/0/1/0/all/0/1&quot;&gt;Alexander Shmakov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Baldi_P/0/1/0/all/0/1&quot;&gt;Pierre Baldi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07473">
<title>Self-Training Ensemble Networks for Zero-Shot Image Recognition. (arXiv:1805.07473v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.07473</link>
<description rdf:parseType="Literal">&lt;p&gt;Despite the advancement of supervised image recognition algorithms, their de-
pendence on the availability of labeled data and the rapid expansion of image
categories raise the significant challenge of zero-shot learning. Zero-shot
learn- ing (ZSL) aims to transfer knowledge from labeled classes into unlabeled
classes to reduce human labeling effort. In this paper, we propose a novel
self-training ensemble network model to address zero-shot image recognition.
The ensemble network is built by learning multiple image classification
functions with a shared feature extraction network but different label
embedding representations, each of which facilitates information transfer to
different subsets of unlabeled classes. A self-training framework is then
deployed to iteratively label the most confident images in each unlabeled class
with predicted pseudo-labels and update the ensem- ble network with the
training data augmented by the pseudo-labels. The proposed model performs
training on both labeled and unlabeled data. It can naturally bridge the domain
shift problem in visual appearances and be extended to the generalized
zero-shot learning scenario. We conduct experiments on multiple standard ZSL
datasets and the empirical results demonstrate the efficacy of the proposed
model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ye_M/0/1/0/all/0/1&quot;&gt;Meng Ye&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1&quot;&gt;Yuhong Guo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07476">
<title>Two geometric input transformation methods for fast online reinforcement learning with neural nets. (arXiv:1805.07476v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.07476</link>
<description rdf:parseType="Literal">&lt;p&gt;We apply neural nets with ReLU gates in online reinforcement learning. Our
goal is to train these networks in an incremental manner, without the
computationally expensive experience replay. By studying how individual neural
nodes behave in online training, we recognize that the global nature of ReLU
gates can cause undesirable learning interference in each node&apos;s learning
behavior. We propose reducing such interferences with two efficient input
transformation methods that are geometric in nature and match well the
geometric property of ReLU gates. The first one is tile coding, a classic
binary encoding scheme originally designed for local generalization based on
the topological structure of the input space. The second one (EmECS) is a new
method we introduce; it is based on geometric properties of convex sets and
topological embedding of the input space into the boundary of a convex set. We
discuss the behavior of the network when it operates on the transformed inputs.
We also compare it experimentally with some neural nets that do not use the
same input transformations, and with the classic algorithm of tile coding plus
a linear function approximator, and on several online reinforcement learning
tasks, we show that the neural net with tile coding or EmECS can achieve not
only faster learning but also more accurate approximations. Our results
strongly suggest that geometric input transformation of this type can be
effective for interference reduction and takes us a step closer to fully
incremental reinforcement learning with neural nets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghiassian_S/0/1/0/all/0/1&quot;&gt;Sina Ghiassian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1&quot;&gt;Huizhen Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rafiee_B/0/1/0/all/0/1&quot;&gt;Banafsheh Rafiee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sutton_R/0/1/0/all/0/1&quot;&gt;Richard S. Sutton&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07541">
<title>Learning to Multitask. (arXiv:1805.07541v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.07541</link>
<description rdf:parseType="Literal">&lt;p&gt;Multitask learning has shown promising performance in many applications and
many multitask models have been proposed. In order to identify an effective
multitask model for a given multitask problem, we propose a learning framework
called learning to multitask (L2MT). To achieve the goal, L2MT exploits
historical multitask experience which is organized as a training set consists
of several tuples, each of which contains a multitask problem with multiple
tasks, a multitask model, and the relative test error. Based on such training
set, L2MT first uses a proposed layerwise graph neural network to learn task
embeddings for all the tasks in a multitask problem and then learns an
estimation function to estimate the relative test error based on task
embeddings and the representation of the multitask model based on a unified
formulation. Given a new multitask problem, the estimation function is used to
identify a suitable multitask model. Experiments on benchmark datasets show the
effectiveness of the proposed L2MT framework.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yu Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wei_Y/0/1/0/all/0/1&quot;&gt;Ying Wei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Q/0/1/0/all/0/1&quot;&gt;Qiang Yang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07603">
<title>Episodic Memory Deep Q-Networks. (arXiv:1805.07603v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.07603</link>
<description rdf:parseType="Literal">&lt;p&gt;Reinforcement learning (RL) algorithms have made huge progress in recent
years by leveraging the power of deep neural networks (DNN). Despite the
success, deep RL algorithms are known to be sample inefficient, often requiring
many rounds of interaction with the environments to obtain satisfactory
performance. Recently, episodic memory based RL has attracted attention due to
its ability to latch on good actions quickly. In this paper, we present a
simple yet effective biologically inspired RL algorithm called Episodic Memory
Deep Q-Networks (EMDQN), which leverages episodic memory to supervise an agent
during training. Experiments show that our proposed method can lead to better
sample efficiency and is more likely to find good policies. It only requires
1/5 of the interactions of DQN to achieve many state-of-the-art performances on
Atari games, significantly outperforming regular DQN and other episodic memory
based RL algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1&quot;&gt;Zichuan Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_T/0/1/0/all/0/1&quot;&gt;Tianqi Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_G/0/1/0/all/0/1&quot;&gt;Guangwen Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1&quot;&gt;Lintao Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07648">
<title>On Attention Models for Human Activity Recognition. (arXiv:1805.07648v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1805.07648</link>
<description rdf:parseType="Literal">&lt;p&gt;Most approaches that model time-series data in human activity recognition
based on body-worn sensing (HAR) use a fixed size temporal context to represent
different activities. This might, however, not be apt for sets of activities
with individ- ually varying durations. We introduce attention models into HAR
research as a data driven approach for exploring relevant temporal context.
Attention models learn a set of weights over input data, which we leverage to
weight the temporal context being considered to model each sensor reading. We
construct attention models for HAR by adding attention layers to a state-
of-the-art deep learning HAR model (DeepConvLSTM) and evaluate our approach on
benchmark datasets achieving sig- nificant increase in performance. Finally, we
visualize the learned weights to better understand what constitutes relevant
temporal context.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Murahari_V/0/1/0/all/0/1&quot;&gt;Vishvak S Murahari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ploetz_T/0/1/0/all/0/1&quot;&gt;Thomas Ploetz&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07715">
<title>An Online RFID Localization in the Manufacturing Shopfloor. (arXiv:1805.07715v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1805.07715</link>
<description rdf:parseType="Literal">&lt;p&gt;Radio Frequency Identification technology has gained popularity for cheap and
easy deployment. In the realm of manufacturing shopfloor, it can be used to
track the location of manufacturing objects to achieve better efficiency. The
underlying challenge of localization lies in the non-stationary characteristics
of manufacturing shopfloor which calls for an adaptive life-long learning
strategy in order to arrive at accurate localization results. This paper
presents an evolving model based on a novel evolving intelligent system, namely
evolving Type-2 Quantum Fuzzy Neural Network (eT2QFNN), which features an
interval type-2 quantum fuzzy set with uncertain jump positions. The quantum
fuzzy set possesses a graded membership degree which enables better
identification of overlaps between classes. The eT2QFNN works fully in the
evolving mode where all parameters including the number of rules are
automatically adjusted and generated on the fly. The parameter adjustment
scenario relies on decoupled extended Kalman filter method. Our numerical study
shows that eT2QFNN is able to deliver comparable accuracy compared to
state-of-the-art algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ashfahani_A/0/1/0/all/0/1&quot;&gt;Andri Ashfahani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pratama_M/0/1/0/all/0/1&quot;&gt;Mahardhika Pratama&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lughofer_E/0/1/0/all/0/1&quot;&gt;Edwin Lughofer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cai_Q/0/1/0/all/0/1&quot;&gt;Qing Cai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sheng_H/0/1/0/all/0/1&quot;&gt;Huang Sheng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07782">
<title>Knowledge Aggregation via Epsilon Model Spaces. (arXiv:1805.07782v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.07782</link>
<description rdf:parseType="Literal">&lt;p&gt;In many practical applications, machine learning is divided over multiple
agents, where each agent learns a different task and/or learns from a different
dataset. We present Epsilon Model Spaces (EMS), a framework for learning a
global model by aggregating local learnings performed by each agent. Our
approach forgoes sharing of data between agents, makes no assumptions on the
distribution of data across agents, and requires minimal communication between
agents. We empirically validate our techniques on MNIST experiments and discuss
how EMS can generalize to a wide range of problem settings, including federated
averaging and catastrophic forgetting. We believe our framework to be among the
first to lay out a general methodology for &quot;combining&quot; distinct models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guha_N/0/1/0/all/0/1&quot;&gt;Neel Guha&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07797">
<title>One Formalization of Virtue Ethics via Learning. (arXiv:1805.07797v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1805.07797</link>
<description rdf:parseType="Literal">&lt;p&gt;Given that there exist many different formal and precise treatments of
deontologi- cal and consequentialist ethics, we turn to virtue ethics and
consider what could be a formalization of virtue ethics that makes it amenable
to automation. We present an embroyonic formalization in a cognitive calculus
(which subsumes a quantified first-order logic) that has been previously used
to model robust ethical principles, in both the deontological and
consequentialist traditions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Govindarajulu_N/0/1/0/all/0/1&quot;&gt;Naveen Sundar Govindarajulu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bringjsord_S/0/1/0/all/0/1&quot;&gt;Selmer Bringjsord&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghosh_R/0/1/0/all/0/1&quot;&gt;Rikhiya Ghosh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07798">
<title>Improved Learning of One-hidden-layer Convolutional Neural Networks with Overlaps. (arXiv:1805.07798v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.07798</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a new algorithm to learn a one-hidden-layer convolutional neural
network where both the convolutional weights and the outputs weights are
parameters to be learned. Our algorithm works for a general class of
(potentially overlapping) patches, including commonly used structures for
computer vision tasks. Our algorithm draws ideas from (1) isotonic regression
for learning neural networks and (2) landscape analysis of non-convex matrix
factorization problems. We believe these findings may inspire further
development in designing provable algorithms for learning neural networks and
other complex models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Du_S/0/1/0/all/0/1&quot;&gt;Simon S. Du&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goel_S/0/1/0/all/0/1&quot;&gt;Surbhi Goel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07828">
<title>A Vest of the Pseudoinverse Learning Algorithm. (arXiv:1805.07828v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.07828</link>
<description rdf:parseType="Literal">&lt;p&gt;In this letter, we briefly review the basic scheme of the pseudoinverse
learning (PIL) algorithm and present some discussions on the PIL, as well as
its variants. The PIL algorithm, first presented in 1995, is a non-gradient
descent algorithm for multi-layer neural networks and has several advantages
compared with gradient descent based algorithms. We also show that the
so-called extreme learning machine (ELM) is a vest (another name) of the PIL
algorithm for single hidden layer feedforward neural networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_P/0/1/0/all/0/1&quot;&gt;Ping Guo&lt;/a&gt; (School of Systems Science, Beijing Normal University, Beijing 100875, China)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07848">
<title>A Universal Music Translation Network. (arXiv:1805.07848v1 [cs.SD])</title>
<link>http://arxiv.org/abs/1805.07848</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a method for translating music across musical instruments, genres,
and styles. This method is based on a multi-domain wavenet autoencoder, with a
shared encoder and a disentangled latent space that is trained end-to-end on
waveforms. Employing a diverse training dataset and large net capacity, the
domain-independent encoder allows us to translate even from musical domains
that were not seen during training. The method is unsupervised and does not
rely on supervision in the form of matched samples between domains or musical
transcriptions. We evaluate our method on NSynth, as well as on a dataset
collected from professional musicians, and achieve convincing translations,
even when translating from whistling, potentially enabling the creation of
instrumental music by untrained humans.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mor_N/0/1/0/all/0/1&quot;&gt;Noam Mor&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wolf_L/0/1/0/all/0/1&quot;&gt;Lior Wolf&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Polyak_A/0/1/0/all/0/1&quot;&gt;Adam Polyak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Taigman_Y/0/1/0/all/0/1&quot;&gt;Yaniv Taigman&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07883">
<title>How Many Samples are Needed to Learn a Convolutional Neural Network?. (arXiv:1805.07883v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.07883</link>
<description rdf:parseType="Literal">&lt;p&gt;A widespread folklore for explaining the success of convolutional neural
network (CNN) is that CNN is a more compact representation than the fully
connected neural network (FNN) and thus requires fewer samples for learning. We
initiate the study of rigorously characterizing the sample complexity of
learning convolutional neural networks. We show that for learning an
$m$-dimensional convolutional filter with linear activation acting on a
$d$-dimensional input, the sample complexity of achieving population prediction
error of $\epsilon$ is $\widetilde{O} (m/\epsilon^2)$, whereas its FNN
counterpart needs at least $\Omega(d/\epsilon^2)$ samples. Since $m \ll d$,
this result demonstrates the advantage of using CNN. We further consider the
sample complexity of learning a one-hidden-layer CNN with linear activation
where both the $m$-dimensional convolutional filter and the $r$-dimensional
output weights are unknown. For this model, we show the sample complexity is
$\widetilde{O}\left((m+r)/\epsilon^2\right)$ when the ratio between the stride
size and the filter size is a constant. For both models, we also present lower
bounds showing our sample complexities are tight up to logarithmic factors. Our
main tools for deriving these results are localized empirical process and a new
lemma characterizing the convolutional structure. We believe these tools may
inspire further developments in understanding CNN.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Du_S/0/1/0/all/0/1&quot;&gt;Simon S. Du&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yining Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhai_X/0/1/0/all/0/1&quot;&gt;Xiyu Zhai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Balakrishnan_S/0/1/0/all/0/1&quot;&gt;Sivaraman Balakrishnan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Salakhutdinov_R/0/1/0/all/0/1&quot;&gt;Ruslan Salakhutdinov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Singh_A/0/1/0/all/0/1&quot;&gt;Aarti Singh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07894">
<title>Generative Adversarial Examples. (arXiv:1805.07894v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.07894</link>
<description rdf:parseType="Literal">&lt;p&gt;Adversarial examples are typically constructed by perturbing an existing data
point, and current defense methods are focused on guarding against this type of
attack. In this paper, we propose a new class of adversarial examples that are
synthesized entirely from scratch using a conditional generative model. We
first train an Auxiliary Classifier Generative Adversarial Network (AC-GAN) to
model the class-conditional distribution over inputs. Then, conditioned on a
desired class, we search over the AC-GAN latent space to find images that are
likely under the generative model and are misclassified by a target classifier.
We demonstrate through human evaluation that this new kind of adversarial
inputs, which we call Generative Adversarial Examples, are legitimate and
belong to the desired class. Our empirical results on the MNIST, SVHN, and
CelebA datasets show that generative adversarial examples can easily bypass
strong adversarial training and certified defense methods which can foil
existing adversarial attacks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1&quot;&gt;Yang Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shu_R/0/1/0/all/0/1&quot;&gt;Rui Shu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kushman_N/0/1/0/all/0/1&quot;&gt;Nate Kushman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ermon_S/0/1/0/all/0/1&quot;&gt;Stefano Ermon&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07897">
<title>Predicting Electricity Outages Caused by Convective Storms. (arXiv:1805.07897v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1805.07897</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the problem of predicting power outages in an electrical power
grid due to hazards produced by convective storms. These storms produce extreme
weather phenomena such as intense wind, tornadoes and lightning over a small
area. In this paper, we discuss the application of state-of-the-art machine
learning techniques, such as random forest classifiers and deep neural
networks, to predict the amount of damage caused by storms. We cast this
application as a classification problem where the goal is to classify storm
cells into a finite number of classes, each corresponding to a certain amount
of expected damage. The classification method use as input features estimates
for storm cell location and movement which has to be extracted from the raw
data.
&lt;/p&gt;
&lt;p&gt;A main challenge of this application is that the training data is heavily
imbalanced as the occurrence of extreme weather events is rare. In order to
address this issue, we applied SMOTE technique.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tervo_R/0/1/0/all/0/1&quot;&gt;Roope Tervo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Karjalainen_J/0/1/0/all/0/1&quot;&gt;Joonas Karjalainen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jung_A/0/1/0/all/0/1&quot;&gt;Alexander Jung&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07941">
<title>Quantizing Convolutional Neural Networks for Low-Power High-Throughput Inference Engines. (arXiv:1805.07941v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.07941</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep learning as a means to inferencing has proliferated thanks to its
versatility and ability to approach or exceed human-level accuracy. These
computational models have seemingly insatiable appetites for computational
resources not only while training, but also when deployed at scales ranging
from data centers all the way down to embedded devices. As such, increasing
consideration is being made to maximize the computational efficiency given
limited hardware and energy resources and, as a result, inferencing with
reduced precision has emerged as a viable alternative to the IEEE 754 Standard
for Floating-Point Arithmetic. We propose a quantization scheme that allows
inferencing to be carried out using arithmetic that is fundamentally more
efficient when compared to even half-precision floating-point. Our quantization
procedure is significant in that we determine our quantization scheme
parameters by calibrating against its reference floating-point model using a
single inference batch rather than (re)training and achieve end-to-end post
quantization accuracies comparable to the reference model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Settle_S/0/1/0/all/0/1&quot;&gt;Sean O. Settle&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bollavaram_M/0/1/0/all/0/1&quot;&gt;Manasa Bollavaram&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+DAlberto_P/0/1/0/all/0/1&quot;&gt;Paolo D&amp;#x27;Alberto&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Delaye_E/0/1/0/all/0/1&quot;&gt;Elliott Delaye&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fernandez_O/0/1/0/all/0/1&quot;&gt;Oscar Fernandez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fraser_N/0/1/0/all/0/1&quot;&gt;Nicholas Fraser&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ng_A/0/1/0/all/0/1&quot;&gt;Aaron Ng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sirasao_A/0/1/0/all/0/1&quot;&gt;Ashish Sirasao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_M/0/1/0/all/0/1&quot;&gt;Michael Wu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07966">
<title>Aff2Vec: Affect--Enriched Distributional Word Representations. (arXiv:1805.07966v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1805.07966</link>
<description rdf:parseType="Literal">&lt;p&gt;Human communication includes information, opinions, and reactions. Reactions
are often captured by the affective-messages in written as well as verbal
communications. While there has been work in affect modeling and to some extent
affective content generation, the area of affective word distributions in not
well studied. Synsets and lexica capture semantic relationships across words.
These models however lack in encoding affective or emotional word
interpretations. Our proposed model, Aff2Vec provides a method for enriched
word embeddings that are representative of affective interpretations of words.
Aff2Vec outperforms the state--of--the--art in intrinsic word-similarity tasks.
Further, the use of Aff2Vec representations outperforms baseline embeddings in
downstream natural language understanding tasks including sentiment analysis,
personality detection, and frustration prediction.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khosla_S/0/1/0/all/0/1&quot;&gt;Sopan Khosla&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chhaya_N/0/1/0/all/0/1&quot;&gt;Niyati Chhaya&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chawla_K/0/1/0/all/0/1&quot;&gt;Kushal Chawla&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08000">
<title>Adversarial Noise Layer: Regularize Neural Network By Adding Noise. (arXiv:1805.08000v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1805.08000</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we introduce a novel regularization method called Adversarial
Noise Layer (ANL), which significantly improve the CNN&apos;s generalization ability
by adding adversarial noise in the hidden layers. ANL is easy to implement and
can be integrated with most of the CNN-based models. We compared the impact of
the different type of noise and visually demonstrate that adversarial noise
guide CNNs to learn to extract cleaner feature maps, further reducing the risk
of over-fitting. We also conclude that the model trained with ANL is more
robust to FGSM and IFGSM attack. Code is available at:
https://github.com/youzhonghui/ANL
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+You_Z/0/1/0/all/0/1&quot;&gt;Zhonghui You&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1&quot;&gt;Jinmian Ye&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_K/0/1/0/all/0/1&quot;&gt;Kunming Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1&quot;&gt;Ping Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.04520">
<title>Non-Parametric Transformation Networks. (arXiv:1801.04520v5 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1801.04520</link>
<description rdf:parseType="Literal">&lt;p&gt;ConvNets, through their architecture, only enforce invariance to translation.
In this paper, we introduce a new class of deep convolutional architectures
called Non-Parametric Transformation Networks (NPTNs) which can learn general
invariances and symmetries directly from data. NPTNs are a natural
generalization of ConvNets and can be optimized directly using gradient
descent. Unlike almost all previous works in deep architectures, they make no
assumption regarding the structure of the invariances present in the data and
in that aspect are flexible and powerful. We also model ConvNets and NPTNs
under a unified framework called Transformation Networks (TN), which yields a
better understanding of the connection between the two. We demonstrate the
efficacy of NPTNs on data such as MNIST with extreme transformations and
CIFAR10 where they outperform baselines, and further outperform
state-of-the-art algorithms on ETH-80. They do so while having the same number
of parameters. We show it is more effective than ConvNets in modelling
symmetries and invariances from data, without the explicit knowledge of the
added arbitrary nuisance transformations. Finally, we replace ConvNets with
NPTNs within Capsule Networks and show that this enables Capsule Nets to
perform even better.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pal_D/0/1/0/all/0/1&quot;&gt;Dipan K. Pal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Savvides_M/0/1/0/all/0/1&quot;&gt;Marios Savvides&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.00386">
<title>Cross-City Transfer Learning for Deep Spatio-Temporal Prediction. (arXiv:1802.00386v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1802.00386</link>
<description rdf:parseType="Literal">&lt;p&gt;Spatio-temporal prediction is a key type of tasks in urban computing, e.g.,
traffic flow and air quality. Adequate data is usually a prerequisite,
especially when deep learning is adopted. However, the development levels of
different cities are unbalanced, and still many cities suffer from data
scarcity. To address the problem, we propose a novel cross-city transfer
learning method for deep spatio-temporal prediction tasks, called RegionTrans.
RegionTrans aims to effectively transfer knowledge from a data-rich source city
to a data-scarce target city. More specifically, we first learn an inter-city
region matching function to match each target city region to a similar source
city region. A neural network is designed to effectively extract region-level
representation for spatio-temporal prediction. Finally, an optimization
algorithm is proposed to transfer learned features from the source city to the
target city with the region matching function. Using citywide crowd flow
prediction as a demonstration experiment, we verify the effectiveness of
RegionTrans. Results show that RegionTrans can outperform the state-of-the-art
fine-tuning deep spatio-temporal prediction models by reducing up to 10.7%
prediction error.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1&quot;&gt;Leye Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Geng_X/0/1/0/all/0/1&quot;&gt;Xu Geng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1&quot;&gt;Xiaojuan Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1&quot;&gt;Feng Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Q/0/1/0/all/0/1&quot;&gt;Qiang Yang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05312">
<title>Learning Deep Disentangled Embeddings with the F-Statistic Loss. (arXiv:1802.05312v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1802.05312</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep-embedding methods aim to discover representations of a domain that make
explicit the domain&apos;s class structure and thereby support few-shot learning.
Disentangling methods aim to make explicit compositional or factorial
structure. We combine these two active but independent lines of research and
propose a new paradigm suitable for both goals. We propose and evaluate a novel
loss function based on the $F$ statistic, which describes the separation of two
or more distributions. By ensuring that distinct classes are well separated on
a subset of embedding dimensions, we obtain embeddings that are useful for
few-shot learning. By not requiring separation on all dimensions, we encourage
the discovery of disentangled representations. Our embedding method matches or
beats state-of-the-art, as evaluated by performance on recall@$k$ and few-shot
learning tasks. Our method also obtains performance superior to a variety of
alternatives on disentangling, as evaluated by two key properties of a
disentangled representation: modularity and explicitness. The goal of our work
is to obtain more interpretable, manipulable, and generalizable deep
representations of concepts and categories.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ridgeway_K/0/1/0/all/0/1&quot;&gt;Karl Ridgeway&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mozer_M/0/1/0/all/0/1&quot;&gt;Michael C. Mozer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05944">
<title>Monte Carlo Q-learning for General Game Playing. (arXiv:1802.05944v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1802.05944</link>
<description rdf:parseType="Literal">&lt;p&gt;After the recent groundbreaking results of AlphaGo, we have seen a strong
interest in reinforcement learning in game playing. General Game Playing (GGP)
provides a good testbed for reinforcement learning. In GGP, a specification of
games rules is given. GGP problems can be solved by reinforcement learning.
Q-learning is one of the canonical reinforcement learning methods, and has been
used by (Banerjee &amp;amp; Stone, IJCAI 2007) in GGP. In this paper we implement
Q-learning in GGP for three small-board games (Tic-Tac-Toe, Connect Four, Hex),
to allow comparison to Banerjee et al. As expected, Q-learning converges,
although much slower than MCTS. Borrowing an idea from MCTS, we enhance
Q-learning with Monte Carlo Search, to give QM-learning. This enhancement
improves the performance of pure Q-learning. We believe that QM-learning can
also be used to improve performance of reinforcement learning further for
larger games, something which we will test in future work.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1&quot;&gt;Hui Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Emmerich_M/0/1/0/all/0/1&quot;&gt;Michael Emmerich&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Plaat_A/0/1/0/all/0/1&quot;&gt;Aske Plaat&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.00215">
<title>Internal node bagging: an explicit ensemble learning method in neural network training. (arXiv:1805.00215v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.00215</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce a novel view to understand how dropout works as an inexplicit
ensemble learning method, which doesn&apos;t point out how many and which nodes to
learn a certain feature. We propose a new training method named internal node
bagging, it explicitly forces a group of nodes to learn a certain feature in
training time, and combine those nodes to be one node in inference time. It
means we can use much more parameters to improve model&apos;s fitting ability in
training time while keeping model small in inference time. We test our method
on several benchmark datasets and find it performs significantly better than
dropout on small models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yi_S/0/1/0/all/0/1&quot;&gt;Shun Yi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.01109">
<title>AGI Safety Literature Review. (arXiv:1805.01109v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1805.01109</link>
<description rdf:parseType="Literal">&lt;p&gt;The development of Artificial General Intelligence (AGI) promises to be a
major event. Along with its many potential benefits, it also raises serious
safety concerns (Bostrom, 2014). The intention of this paper is to provide an
easily accessible and up-to-date collection of references for the emerging
field of AGI safety. A significant number of safety problems for AGI have been
identified. We list these, and survey recent research on solving them. We also
cover works on how best to think of AGI from the limited knowledge we have
today, predictions for when AGI will first be created, and what will happen
after its creation. Finally, we review the current public policy on AGI.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Everitt_T/0/1/0/all/0/1&quot;&gt;Tom Everitt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lea_G/0/1/0/all/0/1&quot;&gt;Gary Lea&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hutter_M/0/1/0/all/0/1&quot;&gt;Marcus Hutter&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.06020">
<title>Do deep reinforcement learning agents model intentions?. (arXiv:1805.06020v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1805.06020</link>
<description rdf:parseType="Literal">&lt;p&gt;Inferring other agents&apos; mental states such as their knowledge, beliefs and
intentions is thought to be essential for effective interactions with other
agents. Recently, multiagent systems trained via deep reinforcement learning
have been shown to succeed in solving different tasks, but it remains unclear
how each agent modeled or represented other agents in their environment. In
this work we test whether deep reinforcement learning agents explicitly
represent other agents&apos; intentions (their specific aims or goals) during a task
in which the agents had to coordinate the covering of different spots in a 2D
environment. In particular, we tracked over time the performance of a linear
decoder trained to predict the final goal of all agents from the hidden state
of each agent&apos;s neural network controller. We observed that the hidden layers
of agents represented explicit information about other agents&apos; goals, i.e. the
target landmark they ended up covering. We also performed a series of
experiments, in which some agents were replaced by others with fixed goals, to
test the level of generalization of the trained agents. We noticed that during
the training phase the agents developed a differential preference for each
goal, which hindered generalization. To alleviate the above problem, we propose
simple changes to the MADDPG training algorithm which leads to better
generalization against unseen agents. We believe that training protocols
promoting more active intention reading mechanisms, e.g. by preventing simple
symmetry-breaking solutions, is a promising direction towards achieving a more
robust generalization in different cooperative and competitive tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Matiisen_T/0/1/0/all/0/1&quot;&gt;Tambet Matiisen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Labash_A/0/1/0/all/0/1&quot;&gt;Aqeel Labash&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Majoral_D/0/1/0/all/0/1&quot;&gt;Daniel Majoral&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aru_J/0/1/0/all/0/1&quot;&gt;Jaan Aru&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vicente_R/0/1/0/all/0/1&quot;&gt;Raul Vicente&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07418">
<title>Sequential Learning of Principal Curves: Summarizing Data Streams on the Fly. (arXiv:1805.07418v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.07418</link>
<description rdf:parseType="Literal">&lt;p&gt;When confronted with massive data streams, summarizing data with dimension
reduction methods such as PCA raises theoretical and algorithmic pitfalls.
Principal curves act as a nonlinear generalization of PCA and the present paper
proposes a novel algorithm to automatically and sequentially learn principal
curves from data streams. We show that our procedure is supported by regret
bounds with optimal sublinear remainder terms. A greedy local search
implementation that incorporates both sleeping experts and multi-armed bandit
ingredients is presented, along with its regret bound and performance on a toy
example and seismic data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Guedj_B/0/1/0/all/0/1&quot;&gt;Benjamin Guedj&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Li_L/0/1/0/all/0/1&quot;&gt;Le Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07441">
<title>Overcoming catastrophic forgetting problem by weight consolidation and long-term memory. (arXiv:1805.07441v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.07441</link>
<description rdf:parseType="Literal">&lt;p&gt;Sequential learning of multiple tasks in artificial neural networks using
gradient descent leads to catastrophic forgetting, whereby previously learned
knowledge is erased during learning of new, disjoint knowledge. Here, we
propose a new approach to sequential learning which leverages the recent
discovery of adversarial examples. We use adversarial subspaces from previous
tasks to enable learning of new tasks with less interference. We apply our
method to sequentially learning to classify digits 0, 1, 2 (task 1), 4, 5, 6,
(task 2), and 7, 8, 9 (task 3) in MNIST (disjoint MNIST task). We compare and
combine our Adversarial Direction (AD) method with the recently proposed
Elastic Weight Consolidation (EWC) method for sequential learning. We train
each task for 20 epochs, which yields good initial performance (99.24% correct
task 1 performance). After training task 2, and then task 3, both plain
gradient descent (PGD) and EWC largely forget task 1 (task 1 accuracy 32.95%
for PGD and 41.02% for EWC), while our combined approach (AD+EWC) still
achieves 94.53% correct on task 1. We obtain similar results with a much more
difficult disjoint CIFAR10 task, which to our knowledge had not been attempted
before (70.10% initial task 1 performance, 67.73% after learning tasks 2 and 3
for AD+EWC, while PGD and EWC both fall to chance level). Our results suggest
that AD+EWC can provide better sequential learning performance than either PGD
or EWC.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wen_S/0/1/0/all/0/1&quot;&gt;Shixian Wen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Itti_L/0/1/0/all/0/1&quot;&gt;Laurent Itti&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07475">
<title>Learning to Repair Software Vulnerabilities with Generative Adversarial Networks. (arXiv:1805.07475v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1805.07475</link>
<description rdf:parseType="Literal">&lt;p&gt;Motivated by the problem of automated repair of software vulnerabilities, we
propose an adversarial learning approach that maps from one discrete source
domain to another target domain without requiring paired labeled examples or
source and target domains to be bijections. We demonstrate that the proposed
adversarial learning approach is an effective technique for repairing software
vulnerabilities, performing close to seq2seq approaches that require labeled
pairs. The proposed Generative Adversarial Network approach is
application-agnostic in that it can be applied to other problems similar to
code repair, such as grammar correction or sentiment translation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Harer_J/0/1/0/all/0/1&quot;&gt;Jacob Harer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ozdemir_O/0/1/0/all/0/1&quot;&gt;Onur Ozdemir&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lazovich_T/0/1/0/all/0/1&quot;&gt;Tomo Lazovich&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Reale_C/0/1/0/all/0/1&quot;&gt;Christopher P. Reale&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Russell_R/0/1/0/all/0/1&quot;&gt;Rebecca L. Russell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_L/0/1/0/all/0/1&quot;&gt;Louis Y. Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chin_P/0/1/0/all/0/1&quot;&gt;Peter Chin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07483">
<title>Tell Me Something New: a new framework for asynchronous parallel learning. (arXiv:1805.07483v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.07483</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a novel approach for parallel computation in the context of
machine learning that we call &quot;Tell Me Something New&quot; (TMSN). This approach
involves a set of independent workers that use broadcast to update each other
when they observe &quot;something new&quot;. TMSN does not require synchronization or a
head node and is highly resilient against failing machines or laggards. We
demonstrate the utility of TMSN by applying it to learning boosted trees. We
show that our implementation is 10 times faster than XGBoost and LightGBM on
the splice-site prediction problem.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alafate_J/0/1/0/all/0/1&quot;&gt;Julaiti Alafate&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Freund_Y/0/1/0/all/0/1&quot;&gt;Yoav Freund&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07517">
<title>Integral representation of the global minimizer. (arXiv:1805.07517v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.07517</link>
<description rdf:parseType="Literal">&lt;p&gt;We have obtained an integral representation of the shallow neural network
that attains the global minimum of its backpropagation (BP) training problem.
According to our unpublished numerical simulations conducted several years
prior to this study, we had noticed that such an integral representation may
exist, but it was not proven until today. First, we introduced a Hilbert space
of coefficient functions, and a reproducing kernel Hilbert space (RKHS) of
hypotheses, associated with the integral representation. The RKHS reflects the
approximation ability of neural networks. Second, we established the ridgelet
analysis on RKHS. The analytic property of the integral representation is
remarkably clear. Third, we reformulated the BP training as the optimization
problem in the space of coefficient functions, and obtained a formal expression
of the unique global minimizer, according to the Tikhonov regularization
theory. Finally, we demonstrated that the global minimizer is the shrink
ridgelet transform. Since the relation between an integral representation and
an ordinary finite network is not clear, and BP is convex in the integral
representation, we cannot immediately answer the question such as &quot;Is a local
minimum a global minimum?&quot; However, the obtained integral representation
provides an explicit expression of the global minimizer, without linearity-like
assumptions, such as partial linearity and monotonicity. Furthermore, it
indicates that the ordinary ridgelet transform provides the minimum norm
solution to the original training equation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sonoda_S/0/1/0/all/0/1&quot;&gt;Sho Sonoda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ishikawa_I/0/1/0/all/0/1&quot;&gt;Isao Ishikawa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ikeda_M/0/1/0/all/0/1&quot;&gt;Masahiro Ikeda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hagihara_K/0/1/0/all/0/1&quot;&gt;Kei Hagihara&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sawano_Y/0/1/0/all/0/1&quot;&gt;Yoshihiro Sawano&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Matsubara_T/0/1/0/all/0/1&quot;&gt;Takuo Matsubara&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Murata_N/0/1/0/all/0/1&quot;&gt;Noboru Murata&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07544">
<title>Conditional Network Embeddings. (arXiv:1805.07544v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.07544</link>
<description rdf:parseType="Literal">&lt;p&gt;Network embeddings map the nodes of a given network into $d$-dimensional
Euclidean space $\mathbb{R}^d$. Ideally, this mapping is such that `similar&apos;
nodes are mapped onto nearby points, such that the embedding can be used for
purposes such as link prediction (if `similar&apos; means being `more likely to be
connected&apos;) or classification (if `similar&apos; means `being more likely to have
the same label&apos;).
&lt;/p&gt;
&lt;p&gt;In recent years various methods for network embedding have been introduced.
These methods all follow a similar strategy, defining a notion of similarity
between nodes (typically deeming nodes more similar if they are nearby in the
network in some metric), a distance measure in the embedding space, and
minimizing a loss function that penalizes large distances for similar nodes or
small distances for dissimilar nodes.
&lt;/p&gt;
&lt;p&gt;A difficulty faced by existing methods is that certain networks are
fundamentally hard to embed due to their structural properties, such as
(approximate) multipartiteness, certain degree distributions, or certain kinds
of assortativity. Overcoming this difficulty, we introduce a conceptual
innovation to the literature on network embedding, proposing to create
embeddings that maximally add information with respect to such structural
properties (e.g. node degrees, block densities, etc.). We use a simple Bayesian
approach to achieve this, and propose a block stochastic gradient descent
algorithm for fitting it efficiently.
&lt;/p&gt;
&lt;p&gt;Finally, we demonstrate that the combination of information such structural
properties and a Euclidean embedding provides superior performance across a
range of link prediction tasks. Moreover, we demonstrate the potential of our
approach for network visualization.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kang_B/0/1/0/all/0/1&quot;&gt;Bo Kang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lijffijt_J/0/1/0/all/0/1&quot;&gt;Jefrey Lijffijt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bie_T/0/1/0/all/0/1&quot;&gt;Tijl De Bie&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07557">
<title>Nostalgic Adam: Weighing more of the past gradients when designing the adaptive learning rate. (arXiv:1805.07557v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.07557</link>
<description rdf:parseType="Literal">&lt;p&gt;First-order optimization methods have been playing a prominent role in deep
learning. Algorithms such as RMSProp and Adam are rather popular in training
deep neural networks on large datasets. Recently, Reddi et al. discovered a
flaw in the proof of convergence of Adam, and the authors proposed an
alternative algorithm, AMSGrad, which has guaranteed convergence under certain
conditions. In this paper, we propose a new algorithm, called Nostalgic Adam
(NosAdam), which places bigger weights on the past gradients than the recent
gradients when designing the adaptive learning rate. This is a new observation
made through mathematical analysis of the algorithm. We also show that the
estimate of the second moment of the gradient in NosAdam vanishes slower than
Adam, which may account for faster convergence of NosAdam. We analyze the
convergence of NosAdam and discover a convergence rate that achieves the best
known convergence rate $O(1/\sqrt{T})$ for general convex online learning
problems. Empirically, we show that NosAdam outperforms AMSGrad and Adam in
some common machine learning problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1&quot;&gt;Haiwen Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1&quot;&gt;Chang Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dong_B/0/1/0/all/0/1&quot;&gt;Bin Dong&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07594">
<title>Generalizing Point Embeddings using the Wasserstein Space of Elliptical Distributions. (arXiv:1805.07594v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.07594</link>
<description rdf:parseType="Literal">&lt;p&gt;Embedding complex objects as vectors in low dimensional spaces is a
longstanding problem in machine learning. We propose in this work an extension
of that approach, which consists in embedding objects as elliptical probability
distributions, namely distributions whose densities have elliptical level sets.
We endow these measures with the 2-Wasserstein metric, with two important
benefits: (i) For such measures, the squared 2-Wasserstein metric has a closed
form, equal to the sum of the squared Euclidean distance between means and the
squared Bures metric between covariance matrices. The latter is a Riemannian
metric between positive semi-definite matrices, which turns out to be Euclidean
on a suitable factor representation of such matrices, which is valid on the
entire geodesic between these matrices. (ii) The 2-Wasserstein distance boils
down to the usual Euclidean metric when comparing Diracs, and therefore
provides the natural framework to extend point embeddings. We show that for
these reasons Wasserstein elliptical embeddings are more intuitive and yield
tools that are better behaved numerically than the alternative choice of
Gaussian embeddings with the Kullback-Leibler divergence. In particular, and
unlike previous work based on the KL geometry, we learn elliptical
distributions that are not necessarily diagonal. We demonstrate the interest of
elliptical embeddings by using them for visualization, to compute embeddings of
words, and to reflect entanglement or hypernymy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Muzellec_B/0/1/0/all/0/1&quot;&gt;Boris Muzellec&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Cuturi_M/0/1/0/all/0/1&quot;&gt;Marco Cuturi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07631">
<title>Learning to Detect. (arXiv:1805.07631v1 [cs.IT])</title>
<link>http://arxiv.org/abs/1805.07631</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper we consider Multiple-Input-Multiple-Output (MIMO) detection
using deep neural networks. We introduce two different deep architectures: a
standard fully connected multi-layer network, and a Detection Network (DetNet)
which is specifically designed for the task. The structure of DetNet is
obtained by unfolding the iterations of a projected gradient descent algorithm
into a network. We compare the accuracy and runtime complexity of the purposed
approaches and achieve state-of-the-art performance while maintaining low
computational requirements. Furthermore, we manage to train a single network to
detect over an entire distribution of channels. Finally, we consider detection
with soft outputs and show that the networks can easily be modified to produce
soft decisions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Samuel_N/0/1/0/all/0/1&quot;&gt;Neev Samuel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Diskin_T/0/1/0/all/0/1&quot;&gt;Tzvi Diskin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wiesel_A/0/1/0/all/0/1&quot;&gt;Ami Wiesel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07640">
<title>Comments on &quot;Momentum fractional LMS for power signal parameter estimation&quot;. (arXiv:1805.07640v1 [math.OC])</title>
<link>http://arxiv.org/abs/1805.07640</link>
<description rdf:parseType="Literal">&lt;p&gt;The purpose of this paper is to indicate that the recently proposed Momentum
fractional least mean squares (mFLMS) algorithm has some serious flaws in its
design and analysis. Our apprehensions are based on the evidence we found in
the derivation and analysis in the paper titled: \textquotedblleft
\textit{Momentum fractional LMS for power signal parameter
estimation}\textquotedblright. In addition to the theoretical bases our claims
are also verified through extensive simulation results. The experiments clearly
show that the new method does not have any advantage over the classical least
mean square (LMS) method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Khan_S/0/1/0/all/0/1&quot;&gt;Shujaat Khan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Naseem_I/0/1/0/all/0/1&quot;&gt;Imran Naseem&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Sadiq_A/0/1/0/all/0/1&quot;&gt;Alishba Sadiq&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Ahmad_J/0/1/0/all/0/1&quot;&gt;Jawwad Ahmad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Moinuddin_M/0/1/0/all/0/1&quot;&gt;Muhammad Moinuddin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07674">
<title>BourGAN: Generative Networks with Metric Embeddings. (arXiv:1805.07674v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.07674</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper addresses the mode collapse for generative adversarial networks
(GANs). We view modes as a geometric structure of data distribution in a metric
space. Under this geometric lens, we embed subsamples of the dataset from an
arbitrary metric space into the l2 space, while preserving their pairwise
distance distribution. Not only does this metric embedding determine the
dimensionality of the latent space automatically, it also enables us to
construct a mixture of Gaussians to draw latent space random vectors. We use
the Gaussian mixture model in tandem with a simple augmentation of the
objective function to train GANs. Every major step of our method is supported
by theoretical analysis, and our experiments on real and synthetic data confirm
that the generator is able to produce samples spreading over most of the modes
while avoiding unwanted samples, outperforming several recent GAN variants on a
number of metrics and offering new features.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Xiao_C/0/1/0/all/0/1&quot;&gt;Chang Xiao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhong_P/0/1/0/all/0/1&quot;&gt;Peilin Zhong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zheng_C/0/1/0/all/0/1&quot;&gt;Changxi Zheng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07722">
<title>Task-Agnostic Meta-Learning for Few-shot Learning. (arXiv:1805.07722v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.07722</link>
<description rdf:parseType="Literal">&lt;p&gt;Meta-learning approaches have been proposed to tackle the few-shot learning
problem.Typically, a meta-learner is trained on a variety of tasks in the hopes
of being generalizable to new tasks. However, the generalizability on new tasks
of a meta-learner could be fragile when it is over-trained on existing tasks
during meta-training phase. In other words, the initial model of a meta-learner
could be too biased towards existing tasks to adapt to new tasks, especially
when only very few examples are available to update the model. To avoid a
biased meta-learner and improve its generalizability, we propose a novel
paradigm of Task-Agnostic Meta-Learning (TAML) algorithms. Specifically, we
present an entropy-based approach that meta-learns an unbiased initial model
with the largest uncertainty over the output labels by preventing it from
over-performing in classification tasks. Alternatively, a more general
inequality-minimization TAML is presented for more ubiquitous scenarios by
directly minimizing the inequality of initial losses beyond the classification
tasks wherever a suitable loss can be defined.Experiments on benchmarked
datasets demonstrate that the proposed approaches outperform compared
meta-learning algorithms in both few-shot classification and reinforcement
learning tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jamal_M/0/1/0/all/0/1&quot;&gt;Muhammad Abdullah Jamal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qi_G/0/1/0/all/0/1&quot;&gt;Guo-Jun Qi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shah_M/0/1/0/all/0/1&quot;&gt;Mubarak Shah&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07723">
<title>Minimax Lower Bounds for Cost Sensitive Classification. (arXiv:1805.07723v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.07723</link>
<description rdf:parseType="Literal">&lt;p&gt;The cost-sensitive classification problem plays a crucial role in
mission-critical machine learning applications, and differs with traditional
classification by taking the misclassification costs into consideration.
Although being studied extensively in the literature, the fundamental limits of
this problem are still not well understood. We investigate the hardness of this
problem by extending the standard minimax lower bound of balanced binary
classification problem (due to \cite{massart2006risk}), and emphasize the
impact of cost terms on the hardness.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kamalaruban_P/0/1/0/all/0/1&quot;&gt;Parameswaran Kamalaruban&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Williamson_R/0/1/0/all/0/1&quot;&gt;Robert C. Williamson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07813">
<title>Learning Real-World Robot Policies by Dreaming. (arXiv:1805.07813v1 [cs.RO])</title>
<link>http://arxiv.org/abs/1805.07813</link>
<description rdf:parseType="Literal">&lt;p&gt;Learning to control robots directly based on images is a primary challenge in
robotics. However, many existing reinforcement learning approaches require
iteratively obtaining millions of samples to learn a policy which can take
significant time. In this paper, we focus on the problem of learning real-world
robot action policies solely based on a few random off-policy samples. We learn
a realistic dreaming model that can emulate samples equivalent to a sequence of
images from the actual environment, and make the agent learn action policies by
interacting with the dreaming model rather than the real world. We
experimentally confirm that our dreaming model can learn realistic policies
that transfer to the real-world.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Piergiovanni_A/0/1/0/all/0/1&quot;&gt;AJ Piergiovanni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_A/0/1/0/all/0/1&quot;&gt;Alan Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ryoo_M/0/1/0/all/0/1&quot;&gt;Michael S. Ryoo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07852">
<title>Kernel Pre-Training in Feature Space via m-Kernels. (arXiv:1805.07852v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.07852</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents a novel approach to kernel tuning. The method presented
borrows techniques from reproducing kernel Banach space (RKBS) theory and
tensor kernels and leverages them to convert (re-weight in feature space)
existing kernel functions into new, problem-specific kernels using auxiliary
data. The proposed method is applied to accelerating Bayesian optimisation via
covariance (kernel) function pre-tuning for short-polymer fibre manufacture and
alloy design.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Shilton_A/0/1/0/all/0/1&quot;&gt;Alistair Shilton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gupta_S/0/1/0/all/0/1&quot;&gt;Sunil Gupta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rana_S/0/1/0/all/0/1&quot;&gt;Santu Rana&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Vellanki_P/0/1/0/all/0/1&quot;&gt;Pratibha Vellanki&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Li_C/0/1/0/all/0/1&quot;&gt;Cheng Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Venkatesh_S/0/1/0/all/0/1&quot;&gt;Svetha Venkatesh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Park_L/0/1/0/all/0/1&quot;&gt;Laurence Park&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sutti_A/0/1/0/all/0/1&quot;&gt;Alessandra Sutti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rubin_D/0/1/0/all/0/1&quot;&gt;David Rubin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Dorin_T/0/1/0/all/0/1&quot;&gt;Thomas Dorin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Vahid_A/0/1/0/all/0/1&quot;&gt;Alireza Vahid&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Height_M/0/1/0/all/0/1&quot;&gt;Murray Height&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Slezak_T/0/1/0/all/0/1&quot;&gt;Teo Slezak&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07857">
<title>Parallel Transport Convolution: A New Tool for Convolutional Neural Networks on Manifolds. (arXiv:1805.07857v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.07857</link>
<description rdf:parseType="Literal">&lt;p&gt;Convolution has been playing a prominent role in various applications in
science and engineering for many years. It is the most important operation in
convolutional neural networks. There has been a recent growth of interests of
research in generalizing convolutions on curved domains such as manifolds and
graphs. However, existing approaches cannot preserve all the desirable
properties of Euclidean convolutions, namely compactly supported filters,
directionality, transferability across different manifolds. In this paper we
develop a new generalization of the convolution operation, referred to as
parallel transport convolution (PTC), on Riemannian manifolds and their
discrete counterparts. PTC is designed based on the parallel transportation
which is able to translate information along a manifold and to intrinsically
preserve directionality. PTC allows for the construction of compactly supported
filters and is also robust to manifold deformations. This enables us to preform
wavelet-like operations and to define deep convolutional neural networks on
curved domains.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schonsheck_S/0/1/0/all/0/1&quot;&gt;Stefan C. Schonsheck&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dong_B/0/1/0/all/0/1&quot;&gt;Bin Dong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lai_R/0/1/0/all/0/1&quot;&gt;Rongjie Lai&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07862">
<title>Featurized Bidirectional GAN: Adversarial Defense via Adversarially Learned Semantic Inference. (arXiv:1805.07862v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.07862</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep neural networks have been demonstrated to be vulnerable to adversarial
attacks, where small perturbations are intentionally added to the original
inputs to fool the classifier. In this paper, we propose a defense method,
Featurized Bidirectional Generative Adversarial Networks (FBGAN), to capture
the semantic features of the input and filter the non-semantic perturbation.
FBGAN is pre-trained on the clean dataset in an unsupervised manner,
adversarially learning a bidirectional mapping between the high-dimensional
data space and the low-dimensional semantic space, and mutual information is
applied to disentangle the semantically meaningful features. After the
bidirectional mapping, the adversarial data can be reconstructed to denoised
data, which could be fed into the classifier for classification. We empirically
show the quality of reconstruction images and the effectiveness of defense.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bao_R/0/1/0/all/0/1&quot;&gt;Ruying Bao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_S/0/1/0/all/0/1&quot;&gt;Sihang Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1&quot;&gt;Qingcan Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07869">
<title>Learning Device Models with Recurrent Neural Networks. (arXiv:1805.07869v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.07869</link>
<description rdf:parseType="Literal">&lt;p&gt;Recurrent neural networks (RNNs) are powerful constructs capable of modeling
complex systems, up to and including Turing Machines. However, learning such
complex models from finite training sets can be difficult. In this paper we
empirically show that RNNs can learn models of computer peripheral devices
through input and output state observation. This enables automated development
of functional software-only models of hardware devices. Such models are
applicable to any number of tasks, including device validation, driver
development, code de-obfuscation, and reverse engineering. We show that the
same RNN structure successfully models six different devices from simple test
circuits up to a 16550 UART serial port, and verify that these models are
capable of producing equivalent output to real hardware.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Clemens_J/0/1/0/all/0/1&quot;&gt;John Clemens&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07892">
<title>Localized Multiple Kernel Learning for Anomaly Detection: One-class Classification. (arXiv:1805.07892v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.07892</link>
<description rdf:parseType="Literal">&lt;p&gt;Multi-kernel learning has been well explored in the recent past and has
exhibited promising outcomes for multi-class classification and regression
tasks. In this paper, we present a multiple kernel learning approach for the
One-class Classification (OCC) task and employ it for anomaly detection.
Recently, the basic multi-kernel approach has been proposed to solve the OCC
problem, which is simply a convex combination of different kernels with equal
weights. This paper proposes a Localized Multiple Kernel learning approach for
Anomaly Detection (LMKAD) using OCC, where the weight for each kernel is
assigned locally. Proposed LMKAD approach adapts the weight for each kernel
using a gating function. The parameters of the gating function and one-class
classifier are optimized simultaneously through a two-step optimization
process. We present the empirical results of the performance of LMKAD on 25
benchmark datasets from various disciplines. This performance is evaluated
against existing Multi Kernel Anomaly Detection (MKAD) algorithm, and four
other existing kernel-based one class classifiers to showcase the credibility
of our approach. Our algorithm achieves significantly better Gmean scores while
using a lesser number of support vectors compared to MKAD. Friedman test is
also performed to verify the statistical significance of the results claimed in
this paper.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gautam_C/0/1/0/all/0/1&quot;&gt;Chandan Gautam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Balaji_R/0/1/0/all/0/1&quot;&gt;Ramesh Balaji&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+K_S/0/1/0/all/0/1&quot;&gt;Sudharsan K&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tiwari_A/0/1/0/all/0/1&quot;&gt;Aruna Tiwari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ahuja_K/0/1/0/all/0/1&quot;&gt;Kapil Ahuja&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07898">
<title>SmoothOut: Smoothing Out Sharp Minima for Generalization in Large-Batch Deep Learning. (arXiv:1805.07898v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.07898</link>
<description rdf:parseType="Literal">&lt;p&gt;In distributed deep learning, a large batch size in Stochastic Gradient
Descent is required to fully exploit the computing power in distributed
systems. However, generalization gap (accuracy loss) was observed because
large-batch training converges to sharp minima which have bad generalization
[1][2]. This contradiction hinders the scalability of distributed deep
learning. We propose SmoothOut to smooth out sharp minima in Deep Neural
Networks (DNNs) and thereby close generalization gap. SmoothOut perturbs
multiple copies of the DNN in the parameter space and averages these copies. We
prove that SmoothOut can eliminate sharp minima. Perturbing and training
multiple DNN copies is inefficient, we propose a stochastic version of
SmoothOut which only introduces overhead of noise injection and denoising per
iteration. We prove that the Stochastic SmoothOut is an unbiased approximation
of the original SmoothOut. In experiments on a variety of DNNs and datasets,
SmoothOut consistently closes generalization gap in large-batch training within
the same epochs. Moreover, SmoothOut can guide small-batch training to flatter
minima and improve generalization. Our source code is in
https://github.com/wenwei202/smoothout
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wen_W/0/1/0/all/0/1&quot;&gt;Wei Wen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yandan Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yan_F/0/1/0/all/0/1&quot;&gt;Feng Yan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1&quot;&gt;Cong Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yiran Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1&quot;&gt;Hai Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07984">
<title>Adversarial Attacks on Classification Models for Graphs. (arXiv:1805.07984v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.07984</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep learning models for graphs have achieved strong performance for the task
of node classification. Despite their proliferation, currently there is no
study of their robustness to adversarial attacks. Yet, in domains where they
are likely to be used, e.g. the web, adversaries are common. Can deep learning
models for graphs be easily fooled? In this work, we introduce the first study
of adversarial attacks on attributed graphs, specifically focusing on models
exploiting ideas of graph convolutions. We generate adversarial perturbations
targeting the node&apos;s features and the graph structure, thus, taking the
dependencies between instances in account. To cope with the underlying discrete
domain we propose an efficient algorithm Nettack exploiting incremental
computations. Our experimental study shows that accuracy of node classification
significantly drops even when performing only few perturbations. Even more, our
attacks are transferable: the learned attacks generalize to other
state-of-the-art node classification models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zugner_D/0/1/0/all/0/1&quot;&gt;Daniel Z&amp;#xfc;gner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Akbarnejad_A/0/1/0/all/0/1&quot;&gt;Amir Akbarnejad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gunnemann_S/0/1/0/all/0/1&quot;&gt;Stephan G&amp;#xfc;nnemann&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08006">
<title>Bidirectional Learning for Robust Neural Networks. (arXiv:1805.08006v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.08006</link>
<description rdf:parseType="Literal">&lt;p&gt;A multilayer perceptron can behave as a generative classifier by applying
bidirectional learning (BL). It consists of training an undirected neural
network to map input to output and vice-versa; therefore it can produce a
classifier in one direction, and a generator in the opposite direction for the
same data. In this paper, two novel learning techniques are introduced which
use BL for improving robustness to white noise static and adversarial examples.
The first method is bidirectional propagation of errors, which the error
propagation occurs in backward and forward directions. Motivated by the fact
that its generative model receives as input a constant vector per class, we
introduce as a second method the hybrid adversarial networks (HAN). Its
generative model receives a random vector as input and its training is based on
generative adversarial networks (GAN). To assess the performance of BL, we
perform experiments using several architectures with fully and convolutional
layers, with and without bias. Experimental results show that both methods
improve robustness to white noise static and adversarial examples, but have
different behaviour depending on the architecture and task, being more
beneficial to use the one or the other. Nevertheless, HAN using a convolutional
architecture with batch normalization presents outstanding robustness, reaching
state-of-the-art accuracy on adversarial examples of hand-written digits.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pontes_Filho_S/0/1/0/all/0/1&quot;&gt;Sidney Pontes-Filho&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liwicki_M/0/1/0/all/0/1&quot;&gt;Marcus Liwicki&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08090">
<title>Graph Capsule Convolutional Neural Networks. (arXiv:1805.08090v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.08090</link>
<description rdf:parseType="Literal">&lt;p&gt;Graph Convolutional Neural Networks (GCNNs) are the most recent exciting
advancement in deep learning field and their applications are quickly spreading
in multi-cross-domains including bioinformatics, chemoinformatics, social
networks, natural language processing and computer vision. In this paper, we
expose and tackle some of the basic weaknesses of a GCNN model with a capsule
idea presented in~\cite{hinton2011transforming} and propose our Graph Capsule
Network (GCAPS-CNN) model. In addition, we design our GCAPS-CNN model to solve
especially graph classification problem which current GCNN models find
challenging. Through extensive experiments, we show that our proposed Graph
Capsule Network can significantly outperforms both the existing state-of-art
deep learning methods and graph kernels on graph classification benchmark
datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Verma_S/0/1/0/all/0/1&quot;&gt;Saurabh Verma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhang_Z/0/1/0/all/0/1&quot;&gt;Zhi-Li Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08095">
<title>Small steps and giant leaps: Minimal Newton solvers for Deep Learning. (arXiv:1805.08095v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.08095</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a fast second-order method that can be used as a drop-in
replacement for current deep learning solvers. Compared to stochastic gradient
descent (SGD), it only requires two additional forward-mode automatic
differentiation operations per iteration, which has a computational cost
comparable to two standard forward passes and is easy to implement. Our method
addresses long-standing issues with current second-order solvers, which invert
an approximate Hessian matrix every iteration exactly or by conjugate-gradient
methods, a procedure that is both costly and sensitive to noise. Instead, we
propose to keep a single estimate of the gradient projected by the inverse
Hessian matrix, and update it once per iteration. This estimate has the same
size and is similar to the momentum variable that is commonly used in SGD. No
estimate of the Hessian is maintained. We first validate our method, called
CurveBall, on small problems with known closed-form solutions (noisy Rosenbrock
function and degenerate 2-layer linear networks), where current deep learning
solvers seem to struggle. We then train several large models on CIFAR and
ImageNet, including ResNet and VGG-f networks, where we demonstrate faster
convergence with no hyperparameter tuning. Code is available.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Henriques_J/0/1/0/all/0/1&quot;&gt;Jo&amp;#xe3;o F. Henriques&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ehrhardt_S/0/1/0/all/0/1&quot;&gt;Sebastien Ehrhardt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Albanie_S/0/1/0/all/0/1&quot;&gt;Samuel Albanie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vedaldi_A/0/1/0/all/0/1&quot;&gt;Andrea Vedaldi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08096">
<title>Understanding Self-Paced Learning under Concave Conjugacy Theory. (arXiv:1805.08096v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.08096</link>
<description rdf:parseType="Literal">&lt;p&gt;By simulating the easy-to-hard learning manners of humans/animals, the
learning regimes called curriculum learning~(CL) and self-paced learning~(SPL)
have been recently investigated and invoked broad interests. However, the
intrinsic mechanism for analyzing why such learning regimes can work has not
been comprehensively investigated. To this issue, this paper proposes a concave
conjugacy theory for looking into the insight of CL/SPL. Specifically, by using
this theory, we prove the equivalence of the SPL regime and a latent concave
objective, which is closely related to the known non-convex regularized penalty
widely used in statistics and machine learning. Beyond the previous theory for
explaining CL/SPL insights, this new theoretical framework on one hand
facilitates two direct approaches for designing new SPL models for certain
tasks, and on the other hand can help conduct the latent objective of
self-paced curriculum learning, which is the advanced version of both CL/SPL
and possess advantages of both learning regimes to a certain extent. This
further facilitates a theoretical understanding for SPCL, instead of only
CL/SPL as conventional. Under this theory, we attempt to attain intrinsic
latent objectives of two curriculum forms, the partial order and group
curriculums, which easily follow the theoretical understanding of the
corresponding SPCL regimes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1&quot;&gt;Shiqi Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_Z/0/1/0/all/0/1&quot;&gt;Zilu Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meng_D/0/1/0/all/0/1&quot;&gt;Deyu Meng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08097">
<title>Invariant Representations from Adversarially Censored Autoencoders. (arXiv:1805.08097v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.08097</link>
<description rdf:parseType="Literal">&lt;p&gt;We combine conditional variational autoencoders (VAE) with adversarial
censoring in order to learn invariant representations that are disentangled
from nuisance/sensitive variations. In this method, an adversarial network
attempts to recover the nuisance variable from the representation, which the
VAE is trained to prevent. Conditioning the decoder on the nuisance variable
enables clean separation of the representation, since they are recombined for
model learning and data reconstruction. We show this natural approach is
theoretically well-founded with information-theoretic arguments. Experiments
demonstrate that this method achieves invariance while preserving model
learning performance, and results in visually improved performance for style
transfer and generative sampling tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Ye Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koike_Akino_T/0/1/0/all/0/1&quot;&gt;Toshiaki Koike-Akino&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Erdogmus_D/0/1/0/all/0/1&quot;&gt;Deniz Erdogmus&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08122">
<title>A General Family of Robust Stochastic Operators for Reinforcement Learning. (arXiv:1805.08122v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.08122</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider a new family of operators for reinforcement learning with the
goal of alleviating the negative effects and becoming more robust to
approximation or estimation errors. Various theoretical results are
established, which include showing on a sample path basis that our family of
operators preserve optimality and increase the action gap. Our empirical
results illustrate the strong benefits of our family of operators,
significantly outperforming the classical Bellman operator and recently
proposed operators.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lu_Y/0/1/0/all/0/1&quot;&gt;Yingdong Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Squillante_M/0/1/0/all/0/1&quot;&gt;Mark S. Squillante&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wu_C/0/1/0/all/0/1&quot;&gt;Chai Wah Wu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08136">
<title>Meta-learning with differentiable closed-form solvers. (arXiv:1805.08136v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1805.08136</link>
<description rdf:parseType="Literal">&lt;p&gt;Adapting deep networks to new concepts from few examples is extremely
challenging, due to the high computational and data requirements of standard
fine-tuning procedures. Most works on meta-learning and few-shot learning have
thus focused on simple learning techniques for adaptation, such as nearest
neighbors or gradient descent. Nonetheless, the machine learning literature
contains a wealth of methods that learn non-deep models very efficiently. In
this work we propose to use these fast convergent methods as the main
adaptation mechanism for few-shot learning. The main idea is to teach a deep
network to use standard machine learning tools, such as logistic regression, as
part of its own internal model, enabling it to quickly adapt to novel tasks.
This requires back-propagating errors through the solver steps. While normally
the matrix operations involved would be costly, the small number of examples
works to our advantage, by making use of the Woodbury identity. We propose both
iterative and closed-form solvers, based on logistic regression and ridge
regression components. Our methods achieve excellent performance on three
few-shot learning benchmarks, showing competitive performance on Omniglot and
surpassing all state-of-the-art alternatives on miniImageNet and CIFAR-100.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bertinetto_L/0/1/0/all/0/1&quot;&gt;Luca Bertinetto&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Henriques_J/0/1/0/all/0/1&quot;&gt;Jo&amp;#xe3;o F. Henriques&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Torr_P/0/1/0/all/0/1&quot;&gt;Philip H.S. Torr&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vedaldi_A/0/1/0/all/0/1&quot;&gt;Andrea Vedaldi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1708.08863">
<title>Gradual Learning of Recurrent Neural Networks. (arXiv:1708.08863v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1708.08863</link>
<description rdf:parseType="Literal">&lt;p&gt;Recurrent Neural Networks (RNNs) achieve state-of-the-art results in many
sequence-to-sequence modeling tasks. However, RNNs are difficult to train and
tend to suffer from overfitting. Motivated by the Data Processing Inequality
(DPI), we formulate the multi-layered network as a Markov chain, introducing a
training method that comprises training the network gradually and using
layer-wise gradient clipping. We found that applying our methods, combined with
previously introduced regularization and optimization methods, resulted in
improvements in state-of-the-art architectures operating in language modeling
tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Aharoni_Z/0/1/0/all/0/1&quot;&gt;Ziv Aharoni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rattner_G/0/1/0/all/0/1&quot;&gt;Gal Rattner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Permuter_H/0/1/0/all/0/1&quot;&gt;Haim Permuter&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.10628">
<title>Variational Continual Learning. (arXiv:1710.10628v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1710.10628</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper develops variational continual learning (VCL), a simple but
general framework for continual learning that fuses online variational
inference (VI) and recent advances in Monte Carlo VI for neural networks. The
framework can successfully train both deep discriminative models and deep
generative models in complex continual learning settings where existing tasks
evolve over time and entirely new tasks emerge. Experimental results show that
VCL outperforms state-of-the-art continual learning methods on a variety of
tasks, avoiding catastrophic forgetting in a fully automatic way.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Nguyen_C/0/1/0/all/0/1&quot;&gt;Cuong V. Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yingzhen Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bui_T/0/1/0/all/0/1&quot;&gt;Thang D. Bui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Turner_R/0/1/0/all/0/1&quot;&gt;Richard E. Turner&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05335">
<title>Multimodal Generative Models for Scalable Weakly-Supervised Learning. (arXiv:1802.05335v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1802.05335</link>
<description rdf:parseType="Literal">&lt;p&gt;Multiple modalities often co-occur when describing natural phenomena.
Learning a joint representation of these modalities should yield deeper and
more useful representations. Previous generative approaches to multi-modal
input either do not learn a joint distribution or require additional
computation to handle missing data. Here, we introduce a multimodal variational
autoencoder (MVAE) that uses a product-of-experts inference network and a
sub-sampled training paradigm to solve the multi-modal inference problem.
Notably, our model shares parameters to efficiently learn under any combination
of missing modalities. We apply the MVAE on four datasets and show that we
match state-of-the-art performance using many fewer parameters. In addition, we
show that the MVAE is directly applicable to weakly-supervised learning, and is
robust to incomplete supervision. We then consider a case study of learning
image transformations---edge detection, colorization, facial landmark
segmentation, etc.---as a set of modalities. We find appealing results across
this range of tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_M/0/1/0/all/0/1&quot;&gt;Mike Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goodman_N/0/1/0/all/0/1&quot;&gt;Noah Goodman&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.00502">
<title>Understand Functionality and Dimensionality of Vector Embeddings: the Distributional Hypothesis, the Pairwise Inner Product Loss and Its Bias-Variance Trade-off. (arXiv:1803.00502v4 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1803.00502</link>
<description rdf:parseType="Literal">&lt;p&gt;Vector embedding is a foundational building block of many deep learning
models, especially in natural language processing. In this paper, we present a
theoretical framework for understanding the effect of dimensionality on vector
embeddings. We observe that the distributional hypothesis, a governing
principle of statistical semantics, requires a natural unitary-invariance for
vector embeddings. Motivated by the unitary-invariance observation, we propose
the Pairwise Inner Product (PIP) loss, a unitary-invariant metric on the
similarity between two embeddings. We demonstrate that the PIP loss captures
the difference in functionality between embeddings, and that the PIP loss is
tightly connect with two basic properties of vector embeddings, namely
similarity and compositionality. By formulating the embedding training process
as matrix factorization with noise, we reveal a fundamental bias-variance
trade-off between the signal spectrum and noise power in the dimensionality
selection process. This bias-variance trade-off sheds light on many empirical
observations which have not been thoroughly explained, for example the
existence of an optimal dimensionality. Moreover, we discover two new results
about vector embeddings, namely their robustness against over-parametrization
and their forward stability. The bias-variance trade-off of the PIP loss
explicitly answers the fundamental open problem of dimensionality selection for
vector embeddings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yin_Z/0/1/0/all/0/1&quot;&gt;Zi Yin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.03467">
<title>Ripple Network: Propagating User Preferences on the Knowledge Graph for Recommender Systems. (arXiv:1803.03467v2 [cs.IR] UPDATED)</title>
<link>http://arxiv.org/abs/1803.03467</link>
<description rdf:parseType="Literal">&lt;p&gt;To address the sparsity and cold start problem of collaborative filtering,
researchers usually make use of side information, such as social networks or
item attributes, to improve recommendation performance. This paper considers
the knowledge graph as the source of side information. To address the
limitations of existing embedding-based and path-based methods for
knowledge-graph-aware recommendation, we propose Ripple Network, an end-to-end
framework that naturally incorporates the knowledge graph into recommender
systems. Similar to actual ripples propagating on the surface of water, Ripple
Network stimulates the propagation of user preferences over the set of
knowledge entities by automatically and iteratively extending a user&apos;s
potential interests along links in the knowledge graph. The multiple &quot;ripples&quot;
activated by a user&apos;s historically clicked items are thus superposed to form
the preference distribution of the user with respect to a candidate item, which
could be used for predicting the final clicking probability. Through extensive
experiments on real-world datasets, we demonstrate that Ripple Network achieves
substantial gains in a variety of scenarios, including movie, book and news
recommendation, over several state-of-the-art baselines.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1&quot;&gt;Hongwei Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1&quot;&gt;Fuzheng Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jialin Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_M/0/1/0/all/0/1&quot;&gt;Miao Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1&quot;&gt;Wenjie Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1&quot;&gt;Xing Xie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_M/0/1/0/all/0/1&quot;&gt;Minyi Guo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.05296">
<title>Adversarial Attacks Against Medical Deep Learning Systems. (arXiv:1804.05296v2 [cs.CR] UPDATED)</title>
<link>http://arxiv.org/abs/1804.05296</link>
<description rdf:parseType="Literal">&lt;p&gt;The discovery of adversarial examples has raised concerns about the practical
deployment of deep learning systems. In this paper, we argue that the field of
medicine may be uniquely susceptible to adversarial attacks, both in terms of
monetary incentives and technical vulnerability. To this end, we outline the
healthcare economy and the incentives it creates for fraud, we extend
adversarial attacks to three popular medical imaging tasks, and we provide
concrete examples of how and why such attacks could be realistically carried
out. For each of our representative medical deep learning classifiers, both
white and black box attacks were highly successful. We urge caution in
deploying deep learning systems in clinical settings, and encourage the machine
learning community to further investigate the domain-specific characteristics
of medical learning systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Finlayson_S/0/1/0/all/0/1&quot;&gt;Samuel G. Finlayson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chung_H/0/1/0/all/0/1&quot;&gt;Hyung Won Chung&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kohane_I/0/1/0/all/0/1&quot;&gt;Isaac S. Kohane&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Beam_A/0/1/0/all/0/1&quot;&gt;Andrew L. Beam&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.05532">
<title>Knowledge Distillation with Adversarial Samples Supporting Decision Boundary. (arXiv:1805.05532v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.05532</link>
<description rdf:parseType="Literal">&lt;p&gt;Many recent works on knowledge distillation have provided ways to transfer
the knowledge of a trained network for improving the learning process of a new
one, but finding a good technique for knowledge distillation is still an open
problem. In this paper, we provide a new perspective based on a decision
boundary, which is one of the most important component of a classifier. The
generalization performance of a classifier is closely related to the adequacy
of its decision boundary, so a good classifier bears a good decision boundary.
Therefore, transferring information closely related to the decision boundary
can be a good attempt for knowledge distillation. To realize this goal, we
utilize an adversarial attack to discover samples supporting a decision
boundary. Based on this idea, to transfer more accurate information about the
decision boundary, the proposed algorithm trains a student classifier based on
the adversarial samples supporting the decision boundary. Experiments show that
the proposed method indeed improves knowledge distillation and achieves the
state-of-the-arts performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Heo_B/0/1/0/all/0/1&quot;&gt;Byeongho Heo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_M/0/1/0/all/0/1&quot;&gt;Minsik Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yun_S/0/1/0/all/0/1&quot;&gt;Sangdoo Yun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1&quot;&gt;Jin Young Choi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.06431">
<title>ChoiceNet: Robust Learning by Revealing Output Correlations. (arXiv:1805.06431v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.06431</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we focus on the supervised learning problem with corrupted
training data. We assume that the training dataset is generated from a mixture
of a target distribution and other unknown distributions. We estimate the
quality of each data by revealing the correlation between the generated
distribution and the target distribution. To this end, we present a novel
framework referred to here as ChoiceNet that can robustly infer the target
distribution in the presence of inconsistent data. We demonstrate that the
proposed framework is applicable to both classification and regression tasks.
ChoiceNet is evaluated in comprehensive experiments, where we show that it
constantly outperforms existing baseline methods in the handling of noisy data.
Particularly, ChoiceNet is successfully applied to autonomous driving tasks
where it learns a safe driving policy from a dataset with mixed qualities. In
the classification task, we apply the proposed method to the MNIST and CIFAR-10
datasets and it shows superior performances in terms of robustness to noisy
labels.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Choi_S/0/1/0/all/0/1&quot;&gt;Sungjoon Choi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hong_S/0/1/0/all/0/1&quot;&gt;Sanghoon Hong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lim_S/0/1/0/all/0/1&quot;&gt;Sungbin Lim&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07137">
<title>Knowledge Discovery from Layered Neural Networks based on Non-negative Task Decomposition. (arXiv:1805.07137v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1805.07137</link>
<description rdf:parseType="Literal">&lt;p&gt;Interpretability has become an important issue in the machine learning field,
along with the success of layered neural networks in various practical tasks.
Since a trained layered neural network consists of a complex nonlinear
relationship between large number of parameters, we failed to understand how
they could achieve input-output mappings with a given data set. In this paper,
we propose the non-negative task decomposition method, which applies
non-negative matrix factorization to a trained layered neural network. This
enables us to decompose the inference mechanism of a trained layered neural
network into multiple principal tasks of input-output mapping, and reveal the
roles of hidden units in terms of their contribution to each principal task.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Watanabe_C/0/1/0/all/0/1&quot;&gt;Chihiro Watanabe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hiramatsu_K/0/1/0/all/0/1&quot;&gt;Kaoru Hiramatsu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kashino_K/0/1/0/all/0/1&quot;&gt;Kunio Kashino&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07324">
<title>GANE: A Generative Adversarial Network Embedding. (arXiv:1805.07324v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.07324</link>
<description rdf:parseType="Literal">&lt;p&gt;Network embedding has become a hot research topic recently which can provide
low-dimensional feature representations for many machine learning applications.
Current work focuses on either (1) whether the embedding is designed as an
unsupervised learning task by explicitly preserving the structural connectivity
in the network, or (2) whether the embedding is a by-product during the
supervised learning of a specific discriminative task in a deep neural network.
In this paper, we focus on bridging the gap of the two lines of the research.
We propose to adapt the Generative Adversarial model to perform network
embedding, in which the generator is trying to generate vertex pairs, while the
discriminator tries to distinguish the generated vertex pairs from real
connections (edges) in the network. Wasserstein-1 distance is adopted to train
the generator to gain better stability. We develop three variations of models,
including GANE which applies cosine similarity, GANE-O1 which preserves the
first-order proximity, and GANE-O2 which tries to preserves the second-order
proximity of the network in the low-dimensional embedded vector space. We later
prove that GANE-O2 has the same objective function as GANE-O1 when negative
sampling is applied to simplify the training process in GANE-O2. Experiments
with real-world network datasets demonstrate that our models constantly
outperform state-of-the-art solutions with significant improvements on
precision in link prediction, as well as on visualizations and accuracy in
clustering tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hong_H/0/1/0/all/0/1&quot;&gt;Huiting Hong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xin Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1&quot;&gt;Mingzhong Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.08557">
<title>Probing Hidden Spin Order with Interpretable Machine Learning. (arXiv:1804.08557v2 [cond-mat.stat-mech] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1804.08557</link>
<description rdf:parseType="Literal">&lt;p&gt;Machine learning shows promise for improving our understanding of many-body
problems. Tackling an unsolved problem, or classifying intricate phases,
remains however a daunting task. Building on a recently introduced
interpretable supervised learning scheme, we introduce a generic protocol to
probe and identify nonlinear orientational spin order, and extract the
analytical form of the tensorial order parameter up to rank 6. Moreover, we
find that our approach yields reliable results already for a modest amount of
training data and without knowledge of the exact phase boundary. Our approach
may prove useful for identifying novel spin order and ruling out spurious spin
liquid candidates.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Greitemann_J/0/1/0/all/0/1&quot;&gt;Jonas Greitemann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Liu_K/0/1/0/all/0/1&quot;&gt;Ke Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Pollet_L/0/1/0/all/0/1&quot;&gt;Lode Pollet&lt;/a&gt;</dc:creator>
</item></rdf:RDF>