<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Good papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Good Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-06-25T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.09057"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.01548"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.08874"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.08894"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.08908"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.08915"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.09030"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.09141"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.09192"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.09455"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.09464"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.09504"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.09511"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1704.03574"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.09990"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.03825"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.00885"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.05839"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.03852"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.06824"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02091"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.07377"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.07937"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.08156"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.08805"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.08867"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.08990"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.09018"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.09035"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.09038"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.09055"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.09070"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.09186"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.09206"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.09211"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.09231"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.09235"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.09266"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.09385"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.09463"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.09471"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.09533"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.09542"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.03713"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05411"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.09522"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.00108"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.08079"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.08240"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1806.09057">
<title>In-situ Stochastic Training of MTJ Crossbar based Neural Networks. (arXiv:1806.09057v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1806.09057</link>
<description rdf:parseType="Literal">&lt;p&gt;Owing to high device density, scalability and non-volatility, Magnetic Tunnel
Junction-based crossbars have garnered significant interest for implementing
the weights of an artificial neural network. The existence of only two stable
states in MTJs implies a high overhead of obtaining optimal binary weights in
software. We illustrate that the inherent parallelism in the crossbar structure
makes it highly appropriate for in-situ training, wherein the network is taught
directly on the hardware. It leads to significantly smaller training overhead
as the training time is independent of the size of the network, while also
circumventing the effects of alternate current paths in the crossbar and
accounting for manufacturing variations in the device. We show how the
stochastic switching characteristics of MTJs can be leveraged to perform
probabilistic weight updates using the gradient descent algorithm. We describe
how the update operations can be performed on crossbars both with and without
access transistors and perform simulations on them to demonstrate the
effectiveness of our techniques. The results reveal that stochastically trained
MTJ-crossbar NNs achieve a classification accuracy nearly same as that of
real-valued-weight networks trained in software and exhibit immunity to device
variations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mondal_A/0/1/0/all/0/1&quot;&gt;Ankit Mondal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Srivastava_A/0/1/0/all/0/1&quot;&gt;Ankur Srivastava&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.01548">
<title>Regularized Evolution for Image Classifier Architecture Search. (arXiv:1802.01548v4 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1802.01548</link>
<description rdf:parseType="Literal">&lt;p&gt;The effort devoted to hand-crafting image classifiers has motivated the use
of architecture search to discover them automatically. Although evolutionary
algorithms have been repeatedly applied to architecture search, the
architectures thus discovered have remained inferior to human-crafted ones.
Here we show for the first time that artificially-evolved architectures can
match or surpass human-crafted and RL-designed image classifiers. In
particular, our models---named AmoebaNets---achieved a state-of-the-art
accuracy of 97.87% on CIFAR-10 and top-1 accuracy of 83.1% on ImageNet. Among
mobile-size models, an AmoebaNet with only 5.1M parameters also achieved a
state-of-the-art top-1 accuracy of 75.1% on ImageNet. We also compared this
method against strong baselines. Finally, we performed platform-aware
architecture search with evolution to find a model that trains quickly on
Google Cloud TPUs. This method produced an AmoebaNet that won the Stanford
DAWNBench competition for lowest ImageNet training cost.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Real_E/0/1/0/all/0/1&quot;&gt;Esteban Real&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aggarwal_A/0/1/0/all/0/1&quot;&gt;Alok Aggarwal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1&quot;&gt;Yanping Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Le_Q/0/1/0/all/0/1&quot;&gt;Quoc V Le&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.08874">
<title>The Foundations of Deep Learning with a Path Towards General Intelligence. (arXiv:1806.08874v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1806.08874</link>
<description rdf:parseType="Literal">&lt;p&gt;Like any field of empirical science, AI may be approached axiomatically. We
formulate requirements for a general-purpose, human-level AI system in terms of
postulates. We review the methodology of deep learning, examining the explicit
and tacit assumptions in deep learning research. Deep Learning methodology
seeks to overcome limitations in traditional machine learning research as it
combines facets of model richness, generality, and practical applicability. The
methodology so far has produced outstanding results due to a productive synergy
of function approximation, under plausible assumptions of irreducibility and
the efficiency of back-propagation family of algorithms. We examine these
winning traits of deep learning, and also observe the various known failure
modes of deep learning. We conclude by giving recommendations on how to extend
deep learning methodology to cover the postulates of general-purpose AI
including modularity, and cognitive architecture. We also relate deep learning
to advances in theoretical neuroscience research.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ozkural_E/0/1/0/all/0/1&quot;&gt;Eray &amp;#xd6;zkural&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.08894">
<title>Deep Reinforcement Learning: An Overview. (arXiv:1806.08894v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.08894</link>
<description rdf:parseType="Literal">&lt;p&gt;In recent years, a specific machine learning method called deep learning has
gained huge attraction, as it has obtained astonishing results in broad
applications such as pattern recognition, speech recognition, computer vision,
and natural language processing. Recent research has also been shown that deep
learning techniques can be combined with reinforcement learning methods to
learn useful representations for the problems with high dimensional raw data
input. This chapter reviews the recent advances in deep reinforcement learning
with a focus on the most used deep architectures such as autoencoders,
convolutional neural networks and recurrent neural networks which have
successfully been come together with the reinforcement learning framework.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mousavi_S/0/1/0/all/0/1&quot;&gt;Seyed Sajad Mousavi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schukat_M/0/1/0/all/0/1&quot;&gt;Michael Schukat&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Howley_E/0/1/0/all/0/1&quot;&gt;Enda Howley&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.08908">
<title>Zeta Distribution and Transfer Learning Problem. (arXiv:1806.08908v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1806.08908</link>
<description rdf:parseType="Literal">&lt;p&gt;We explore the relations between the zeta distribution and algorithmic
information theory via a new model of the transfer learning problem. The
program distribution is approximated by a zeta distribution with parameter near
$1$. We model the training sequence as a stochastic process. We analyze the
upper temporal bound for learning a training sequence and its entropy rates,
assuming an oracle for the transfer learning problem. We argue from empirical
evidence that power-law models are suitable for natural processes. Four
sequence models are proposed. Random typing model is like no-free lunch where
transfer learning does not work. Zeta process independently samples programs
from the zeta distribution. A model of common sub-programs inspired by genetics
uses a database of sub-programs. An evolutionary zeta process samples mutations
from Zeta distribution. The analysis of stochastic processes inspired by
evolution suggest that AI may be feasible in nature, countering no-free lunch
sort of arguments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ozkural_E/0/1/0/all/0/1&quot;&gt;Eray &amp;#xd6;zkural&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.08915">
<title>DALEX: explainers for complex predictive models. (arXiv:1806.08915v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.08915</link>
<description rdf:parseType="Literal">&lt;p&gt;Predictive modeling is invaded by elastic, yet complex methods such as neural
networks or ensembles (model stacking, boosting or bagging). Such methods are
usually described by a large number of parameters or hyper parameters - a price
that one needs to pay for elasticity. The very number of parameters makes
models hard to understand.
&lt;/p&gt;
&lt;p&gt;This paper describes a consistent collection of explainers for predictive
models, a.k.a. black boxes. Each explainer is a technique for exploration of a
black box model. Presented approaches are model-agnostic, what means that they
extract useful information from any predictive method despite its internal
structure. Each explainer is linked with a specific aspect of a model. Some are
useful in decomposing predictions, some serve better in understanding
performance, while others are useful in understanding importance and
conditional responses of a particular variable.
&lt;/p&gt;
&lt;p&gt;Every explainer presented in this paper works for a single model or for a
collection of models. In the latter case, models can be compared against each
other. Such comparison helps to find strengths and weaknesses of different
approaches and gives additional possibilities for model validation.
&lt;/p&gt;
&lt;p&gt;Presented explainers are implemented in the DALEX package for R. They are
based on a uniform standardized grammar of model exploration which may be
easily extended. The current implementation supports the most popular
frameworks for classification and regression.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Biecek_P/0/1/0/all/0/1&quot;&gt;Przemyslaw Biecek&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.09030">
<title>On Adversarial Examples for Character-Level Neural Machine Translation. (arXiv:1806.09030v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1806.09030</link>
<description rdf:parseType="Literal">&lt;p&gt;Evaluating on adversarial examples has become a standard procedure to measure
robustness of deep learning models. Due to the difficulty of creating white-box
adversarial examples for discrete text input, most analyses of the robustness
of NLP models have been done through black-box adversarial examples. We
investigate adversarial examples for character-level neural machine translation
(NMT), and contrast black-box adversaries with a novel white-box adversary,
which employs differentiable string-edit operations to rank adversarial
changes. We propose two novel types of attacks which aim to remove or change a
word in a translation, rather than simply break the NMT. We demonstrate that
white-box adversarial examples are significantly stronger than their black-box
counterparts in different attack scenarios, which show more serious
vulnerabilities than previously known. In addition, after performing
adversarial training, which takes only 3 times longer than regular training, we
can improve the model&apos;s robustness significantly.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ebrahimi_J/0/1/0/all/0/1&quot;&gt;Javid Ebrahimi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lowd_D/0/1/0/all/0/1&quot;&gt;Daniel Lowd&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dou_D/0/1/0/all/0/1&quot;&gt;Dejing Dou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.09141">
<title>Constructing Deep Neural Networks by Bayesian Network Structure Learning. (arXiv:1806.09141v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.09141</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce a principled approach for unsupervised structure learning of
deep neural networks. We propose a new interpretation for depth and inter-layer
connectivity where conditional independencies in the input distribution are
encoded hierarchically in the network structure. Thus, the depth of the network
is determined inherently (equal to the maximal order of independence in the
input distribution). The proposed method casts the problem of neural network
structure learning as a problem of Bayesian network structure learning. Then,
instead of directly learning the discriminative structure, it learns a
generative graph, constructs its stochastic inverse, and then constructs a
discriminative graph. We prove that conditional-dependency relations among the
latent variables in the generative graph are preserved in the class-conditional
discriminative graph. We demonstrate on image classification benchmarks that
the deepest layers (convolutional and dense) of common networks can be replaced
by significantly smaller learned structures, while maintaining classification
accuracy---state-of-the-art on tested benchmarks. Our structure learning
algorithm requires a small computational cost and runs efficiently on a
standard desktop CPU.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rohekar_R/0/1/0/all/0/1&quot;&gt;Raanan Y. Yehezkel Rohekar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Nisimov_S/0/1/0/all/0/1&quot;&gt;Shami Nisimov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Koren_G/0/1/0/all/0/1&quot;&gt;Guy Koren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gurwicz_Y/0/1/0/all/0/1&quot;&gt;Yaniv Gurwicz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Novik_G/0/1/0/all/0/1&quot;&gt;Gal Novik&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.09192">
<title>On The Differential Privacy of Thompson Sampling With Gaussian Prior. (arXiv:1806.09192v1 [cs.CR])</title>
<link>http://arxiv.org/abs/1806.09192</link>
<description rdf:parseType="Literal">&lt;p&gt;We show that Thompson Sampling with Gaussian Prior as detailed by Algorithm 2
in (Agrawal &amp;amp; Goyal, 2013) is already differentially private. Theorem 1 show
that it enjoys a very competitive privacy loss of only $\mathcal{O}(\ln^2 T)$
after T rounds. Finally, Theorem 2 show that one can control the privacy loss
to any desirable $\epsilon$ level by appropriately increasing the variance of
the samples from the Gaussian posterior. And this increases the regret only by
a term of $\mathcal{O}(\frac{\ln^2 T}{\epsilon})$. This compares favorably to
the previous result for Thompson Sampling in the literature ((Mishra &amp;amp;
Thakurta, 2015)) which adds a term of $\mathcal{O}(\frac{K \ln^3
T}{\epsilon^2})$ to the regret in order to achieve the same privacy level.
Furthermore, our result use the basic Thompson Sampling with few modifications
whereas the result of (Mishra &amp;amp; Thakurta, 2015) required sophisticated
constructions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tossou_A/0/1/0/all/0/1&quot;&gt;Aristide C. Y. Tossou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dimitrakakis_C/0/1/0/all/0/1&quot;&gt;Christos Dimitrakakis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.09455">
<title>Compact Policies for Fully-Observable Non-Deterministic Planning as SAT. (arXiv:1806.09455v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1806.09455</link>
<description rdf:parseType="Literal">&lt;p&gt;Fully observable non-deterministic (FOND) planning is becoming increasingly
important as an approach for computing proper policies in probabilistic
planning, extended temporal plans in LTL planning, and general plans in
generalized planning. In this work, we introduce a SAT encoding for FOND
planning that is compact and can produce compact strong cyclic policies. Simple
variations of the encodings are also introduced for strong planning and for
what we call, dual FOND planning, where some non-deterministic actions are
assumed to be fair (e.g., probabilistic) and others unfair (e.g., adversarial).
The resulting FOND planners are compared empirically with existing planners
over existing and new benchmarks. The notion of &quot;probabilistic interesting
problems&quot; is also revisited to yield a more comprehensive picture of the
strengths and limitations of current FOND planners and the proposed SAT
approach.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Geffner_T/0/1/0/all/0/1&quot;&gt;Tomas Geffner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Geffner_H/0/1/0/all/0/1&quot;&gt;Hector Geffner&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.09464">
<title>Learning K-way D-dimensional Discrete Codes for Compact Embedding Representations. (arXiv:1806.09464v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.09464</link>
<description rdf:parseType="Literal">&lt;p&gt;Conventional embedding methods directly associate each symbol with a
continuous embedding vector, which is equivalent to applying a linear
transformation based on a &quot;one-hot&quot; encoding of the discrete symbols. Despite
its simplicity, such approach yields the number of parameters that grows
linearly with the vocabulary size and can lead to overfitting. In this work, we
propose a much more compact K-way D-dimensional discrete encoding scheme to
replace the &quot;one-hot&quot; encoding. In the proposed &quot;KD encoding&quot;, each symbol is
represented by a $D$-dimensional code with a cardinality of $K$, and the final
symbol embedding vector is generated by composing the code embedding vectors.
To end-to-end learn semantically meaningful codes, we derive a relaxed discrete
optimization approach based on stochastic gradient descent, which can be
generally applied to any differentiable computational graph with an embedding
layer. In our experiments with various applications from natural language
processing to graph convolutional networks, the total size of the embedding
layer can be reduced up to 98\% while achieving similar or better performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1&quot;&gt;Ting Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Min_M/0/1/0/all/0/1&quot;&gt;Martin Renqiang Min&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1&quot;&gt;Yizhou Sun&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.09504">
<title>Interpreting Embedding Models of Knowledge Bases: A Pedagogical Approach. (arXiv:1806.09504v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1806.09504</link>
<description rdf:parseType="Literal">&lt;p&gt;Knowledge bases are employed in a variety of applications from natural
language processing to semantic web search; alas, in practice their usefulness
is hurt by their incompleteness. Embedding models attain state-of-the-art
accuracy in knowledge base completion, but their predictions are notoriously
hard to interpret. In this paper, we adapt &quot;pedagogical approaches&quot; (from the
literature on neural networks) so as to interpret embedding models by
extracting weighted Horn rules from them. We show how pedagogical approaches
have to be adapted to take upon the large-scale relational aspects of knowledge
bases and show experimentally their strengths and weaknesses.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gusmao_A/0/1/0/all/0/1&quot;&gt;Arthur Colombini Gusm&amp;#xe3;o&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Correia_A/0/1/0/all/0/1&quot;&gt;Alvaro Henrique Chaim Correia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bona_G/0/1/0/all/0/1&quot;&gt;Glauber De Bona&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cozman_F/0/1/0/all/0/1&quot;&gt;Fabio Gagliardi Cozman&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.09511">
<title>A Hierarchical Deep Learning Natural Language Parser for Fashion. (arXiv:1806.09511v1 [cs.IR])</title>
<link>http://arxiv.org/abs/1806.09511</link>
<description rdf:parseType="Literal">&lt;p&gt;This work presents a hierarchical deep learning natural language parser for
fashion. Our proposal intends not only to recognize fashion-domain entities but
also to expose syntactic and morphologic insights. We leverage the usage of an
architecture of specialist models, each one for a different task (from parsing
to entity recognition). Such architecture renders a hierarchical model able to
capture the nuances of the fashion language. The natural language parser is
able to deal with textual ambiguities which are left unresolved by our
currently existing solution. Our empirical results establish a robust baseline,
which justifies the use of hierarchical architectures of deep learning models
while opening new research avenues to explore.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Marcelino_J/0/1/0/all/0/1&quot;&gt;Jos&amp;#xe9; Marcelino&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Faria_J/0/1/0/all/0/1&quot;&gt;Jo&amp;#xe3;o Faria&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Baia_L/0/1/0/all/0/1&quot;&gt;Lu&amp;#xed;s Ba&amp;#xed;a&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sousa_R/0/1/0/all/0/1&quot;&gt;Ricardo Gamelas Sousa&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1704.03574">
<title>CASP Solutions for Planning in Hybrid Domains. (arXiv:1704.03574v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1704.03574</link>
<description rdf:parseType="Literal">&lt;p&gt;CASP is an extension of ASP that allows for numerical constraints to be added
in the rules. PDDL+ is an extension of the PDDL standard language of automated
planning for modeling mixed discrete-continuous dynamics.
&lt;/p&gt;
&lt;p&gt;In this paper, we present CASP solutions for dealing with PDDL+ problems,
i.e., encoding from PDDL+ to CASP, and extensions to the algorithm of the EZCSP
CASP solver in order to solve CASP programs arising from PDDL+ domains. An
experimental analysis, performed on well-known linear and non-linear variants
of PDDL+ domains, involving various configurations of the EZCSP solver, other
CASP solvers, and PDDL+ planners, shows the viability of our solution.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Balduccini_M/0/1/0/all/0/1&quot;&gt;Marcello Balduccini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Magazzeni_D/0/1/0/all/0/1&quot;&gt;Daniele Magazzeni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Maratea_M/0/1/0/all/0/1&quot;&gt;Marco Maratea&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+LeBlanc_E/0/1/0/all/0/1&quot;&gt;Emily LeBlanc&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.09990">
<title>Identification of Strong Edges in AMP Chain Graphs. (arXiv:1711.09990v3 [math.CO] UPDATED)</title>
<link>http://arxiv.org/abs/1711.09990</link>
<description rdf:parseType="Literal">&lt;p&gt;The essential graph is a distinguished member of a Markov equivalence class
of AMP chain graphs. However, the directed edges in the essential graph are not
necessarily strong or invariant, i.e. they may not be shared by every member of
the equivalence class. Likewise for the undirected edges. In this paper, we
develop a procedure for identifying which edges in an essential graph are
strong. We also show how this makes it possible to bound some causal effects
when the true chain graph is unknown.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Pena_J/0/1/0/all/0/1&quot;&gt;Jose M. Pe&amp;#xf1;a&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.03825">
<title>EARL: Joint Entity and Relation Linking for Question Answering over Knowledge Graphs. (arXiv:1801.03825v4 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1801.03825</link>
<description rdf:parseType="Literal">&lt;p&gt;Many question answering systems over knowledge graphs rely on entity and
relation linking components in order to connect the natural language input to
the underlying knowledge graph. Traditionally, entity linking and relation
linking have been performed either as dependent sequential tasks or as
independent parallel tasks. In this paper, we propose a framework called EARL,
which performs entity linking and relation linking as a joint task. EARL
implements two different solution strategies for which we provide a comparative
analysis in this paper: The first strategy is a formalisation of the joint
entity and relation linking tasks as an instance of the Generalised Travelling
Salesman Problem (GTSP). In order to be computationally feasible, we employ
approximate GTSP solvers. The second strategy uses machine learning in order to
exploit the connection density between nodes in the knowledge graph. It relies
on three base features and re-ranking steps in order to predict entities and
relations. We compare the strategies and evaluate them on a dataset with 5000
questions. Both strategies significantly outperform the current
state-of-the-art approaches for entity and relation linking.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dubey_M/0/1/0/all/0/1&quot;&gt;Mohnish Dubey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Banerjee_D/0/1/0/all/0/1&quot;&gt;Debayan Banerjee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chaudhuri_D/0/1/0/all/0/1&quot;&gt;Debanjan Chaudhuri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lehmann_J/0/1/0/all/0/1&quot;&gt;Jens Lehmann&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.00885">
<title>Essentially No Barriers in Neural Network Energy Landscape. (arXiv:1803.00885v4 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1803.00885</link>
<description rdf:parseType="Literal">&lt;p&gt;Training neural networks involves finding minima of a high-dimensional
non-convex loss function. Knowledge of the structure of this energy landscape
is sparse. Relaxing from linear interpolations, we construct continuous paths
between minima of recent neural network architectures on CIFAR10 and CIFAR100.
Surprisingly, the paths are essentially flat in both the training and test
landscapes. This implies that neural networks have enough capacity for
structural changes, or that these changes are small between minima. Also, each
minimum has at least one vanishing Hessian eigenvalue in addition to those
resulting from trivial invariance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Draxler_F/0/1/0/all/0/1&quot;&gt;Felix Draxler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Veschgini_K/0/1/0/all/0/1&quot;&gt;Kambis Veschgini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Salmhofer_M/0/1/0/all/0/1&quot;&gt;Manfred Salmhofer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hamprecht_F/0/1/0/all/0/1&quot;&gt;Fred A. Hamprecht&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.05839">
<title>BigDL: A Distributed Deep Learning Framework for Big Data. (arXiv:1804.05839v3 [cs.DC] UPDATED)</title>
<link>http://arxiv.org/abs/1804.05839</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we present BigDL, a distributed deep learning framework for
Big Data platforms and workflows. It is implemented on top of Apache Spark, and
allows users to write their deep learning applications as standard Spark
programs (running directly on large-scale big data clusters in a distributed
fashion). It provides an expressive, &quot;data-analytics integrated&quot; deep learning
programming model, so that users can easily build the end-to-end analytics + AI
pipelines under a unified programming paradigm; by implementing an AllReduce
like operation using existing primitives in Spark (e.g., shuffle, broadcast,
and in-memory data persistence), it also provides a highly efficient &quot;parameter
server&quot; style architecture, so as to achieve highly scalable, data-parallel
distributed training. Since its initial open source release, BigDL users have
built many analytics and deep learning applications (e.g., object detection,
sequence-to-sequence generation, visual similarity, neural recommendations,
fraud detection, etc.) on Spark.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dai_J/0/1/0/all/0/1&quot;&gt;Jason Dai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yiheng Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qiu_X/0/1/0/all/0/1&quot;&gt;Xin Qiu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ding_D/0/1/0/all/0/1&quot;&gt;Ding Ding&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yao Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yanzhang Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jia_X/0/1/0/all/0/1&quot;&gt;Xianyan Jia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1&quot;&gt;Cherry Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wan_Y/0/1/0/all/0/1&quot;&gt;Yan Wan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Zhichao Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jiao Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1&quot;&gt;Shengsheng Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1&quot;&gt;Zhongyuan Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yang Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1&quot;&gt;Yuhao Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+She_B/0/1/0/all/0/1&quot;&gt;Bowen She&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_D/0/1/0/all/0/1&quot;&gt;Dongjie Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_Q/0/1/0/all/0/1&quot;&gt;Qi Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1&quot;&gt;Kai Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_G/0/1/0/all/0/1&quot;&gt;Guoqiong Song&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.03852">
<title>When Names Are Not Commonly Known: Epistemic Logic with Assignments. (arXiv:1805.03852v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1805.03852</link>
<description rdf:parseType="Literal">&lt;p&gt;In standard epistemic logic, agent names are usually assumed to be common
knowledge implicitly. This is unreasonable for various applications. Inspired
by term modal logic and assignment operators in dynamic logic, we introduce a
lightweight modal predicate logic where names can be non-rigid. The language
can handle various de dicto and de re distinctions in a natural way. The main
technical result is a complete axiomatisation of this logic over S5 models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yanjing Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Seligman_J/0/1/0/all/0/1&quot;&gt;Jeremy Seligman&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.06824">
<title>Learning Time-Sensitive Strategies in Space Fortress. (arXiv:1805.06824v3 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1805.06824</link>
<description rdf:parseType="Literal">&lt;p&gt;Although there has been remarkable progress and impressive performance on
reinforcement learning (RL) on Atari games, there are many problems with
challenging characteristics that have not yet been explored in Deep Learning
for RL. These include reward sparsity, abrupt context-dependent reversals of
strategy and time-sensitive game play. In this paper, we present Space
Fortress, a game that incorporates all these characteristics and experimentally
show that the presence of any of these renders state of the art Deep RL
algorithms incapable of learning. Then, we present our enhancements to an
existing algorithm and show big performance increases through each enhancement
through an ablation study. We discuss how each of these enhancements was able
to help and also argue that appropriate transfer learning boosts performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Agarwal_A/0/1/0/all/0/1&quot;&gt;Akshat Agarwal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hope_R/0/1/0/all/0/1&quot;&gt;Ryan Hope&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sycara_K/0/1/0/all/0/1&quot;&gt;Katia Sycara&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02091">
<title>Can Machines Design? An Artificial General Intelligence Approach. (arXiv:1806.02091v3 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1806.02091</link>
<description rdf:parseType="Literal">&lt;p&gt;Can machines design? Can they come up with creative solutions to problems and
build tools and artifacts across a wide range of domains? Recent advances in
the field of computational creativity and formal Artificial General
Intelligence (AGI) provide frameworks for machines with the general ability to
design. In this paper we propose to integrate a formal computational creativity
framework into the G\&quot;odel machine framework. We call this machine a design
G\&quot;odel machine. Such a machine could solve a variety of design problems by
generating novel concepts. In addition, it could change the way these concepts
are generated by modifying itself. The design G\&quot;odel machine is able to
improve its initial design program, once it has proven that a modification
would increase its return on the utility function. Finally, we sketch out a
specific version of the design G\&quot;odel machine which specifically aims at the
design of complex software and hardware systems. Future work could be the
development of a more formal version of the Design G\&quot;odel machine and a
potential implementation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hein_A/0/1/0/all/0/1&quot;&gt;Andreas Makoto Hein&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Condat_H/0/1/0/all/0/1&quot;&gt;H&amp;#xe9;l&amp;#xe8;ne Condat&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.07377">
<title>Transfer Learning for Related Reinforcement Learning Tasks via Image-to-Image Translation. (arXiv:1806.07377v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1806.07377</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep Reinforcement Learning has managed to achieve state-of-the-art results
in learning control policies directly from raw pixels. However, despite its
remarkable success, it fails to generalize, a fundamental component required in
a stable Artificial Intelligence system. Using the Atari game Breakout, we
demonstrate the difficulty of a trained agent in adjusting to simple
modifications in the raw image, ones that a human could adapt to trivially. In
transfer learning, the goal is to use the knowledge gained from the source task
to make the training of the target task faster and better. We show that using
various forms of fine-tuning, a common method for transfer learning, is not
effective for adapting to such small visual changes. In fact, it is often
easier to re-train the agent from scratch than to fine-tune a trained agent. We
suggest that in some cases transfer learning can be improved by adding a
dedicated component whose goal is to learn to visually map between the known
domain and the new one. Concretely, we use Generative Adversarial Networks
(GANs) to create a mapping function to translate images in the target task to
corresponding images in the source task, allowing us to transform between the
different tasks. We show that learning this mapping is substantially more
efficient than re-training. A visualization of a trained agent playing in a
modified condition, with and without the GAN transfer, can be seen in
https://youtu.be/e2TwjduPT8g.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gamrian_S/0/1/0/all/0/1&quot;&gt;Shani Gamrian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goldberg_Y/0/1/0/all/0/1&quot;&gt;Yoav Goldberg&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.07937">
<title>A Dissection of Overfitting and Generalization in Continuous Reinforcement Learning. (arXiv:1806.07937v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1806.07937</link>
<description rdf:parseType="Literal">&lt;p&gt;The risks and perils of overfitting in machine learning are well known.
However most of the treatment of this, including diagnostic tools and remedies,
was developed for the supervised learning case. In this work, we aim to offer
new perspectives on the characterization and prevention of overfitting in deep
Reinforcement Learning (RL) methods, with a particular focus on continuous
domains. We examine several aspects, such as how to define and diagnose
overfitting in MDPs, and how to reduce risks by injecting sufficient training
diversity. This work complements recent findings on the brittleness of deep RL
methods and offers practical observations for RL researchers and practitioners.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_A/0/1/0/all/0/1&quot;&gt;Amy Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ballas_N/0/1/0/all/0/1&quot;&gt;Nicolas Ballas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pineau_J/0/1/0/all/0/1&quot;&gt;Joelle Pineau&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.08156">
<title>Identifiability of Gaussian Structural Equation Models with Dependent Errors Having Equal Variances. (arXiv:1806.08156v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1806.08156</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we prove that some Gaussian structural equation models with
dependent errors having equal variances are identifiable from their
corresponding Gaussian distributions. Specifically, we prove identifiability
for the Gaussian structural equation models that can be represented as
Andersson-Madigan-Perlman chain graphs (Andersson et al., 2001). These chain
graphs were originally developed to represent independence models. However,
they are also suitable for representing causal models with additive noise
(Pe\~{n}a, 2016. Our result implies then that these causal models can be
identified from observational data alone. Our result generalizes the result by
Peters and B\&quot;{u}hlmann (2014), who considered independent errors having equal
variances. The suitability of the equal error variances assumption should be
assessed on a per domain basis.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pena_J/0/1/0/all/0/1&quot;&gt;Jose M. Pe&amp;#xf1;a&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.08805">
<title>PCA of high dimensional random walks with comparison to neural network training. (arXiv:1806.08805v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.08805</link>
<description rdf:parseType="Literal">&lt;p&gt;One technique to visualize the training of neural networks is to perform PCA
on the parameters over the course of training and to project to the subspace
spanned by the first few PCA components. In this paper we compare this
technique to the PCA of a high dimensional random walk. We compute the
eigenvalues and eigenvectors of the covariance of the trajectory and prove that
in the long trajectory and high dimensional limit most of the variance is in
the first few PCA components, and that the projection of the trajectory onto
any subspace spanned by PCA components is a Lissajous curve. We generalize
these results to a random walk with momentum and to an Ornstein-Uhlenbeck
processes (i.e., a random walk in a quadratic potential) and show that in high
dimensions the walk is not mean reverting, but will instead be trapped at a
fixed distance from the minimum. We finally compare the distribution of PCA
variances and the PCA projected training trajectories of a linear model trained
on CIFAR-10 and ResNet-50-v2 trained on Imagenet and find that the distribution
of PCA variances resembles a random walk with drift.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Antognini_J/0/1/0/all/0/1&quot;&gt;Joseph M. Antognini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sohl_Dickstein_J/0/1/0/all/0/1&quot;&gt;Jascha Sohl-Dickstein&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.08867">
<title>xGEMs: Generating Examplars to Explain Black-Box Models. (arXiv:1806.08867v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.08867</link>
<description rdf:parseType="Literal">&lt;p&gt;This work proposes xGEMs or manifold guided exemplars, a framework to
understand black-box classifier behavior by exploring the landscape of the
underlying data manifold as data points cross decision boundaries. To do so, we
train an unsupervised implicit generative model -- treated as a proxy to the
data manifold. We summarize black-box model behavior quantitatively by
perturbing data samples along the manifold. We demonstrate xGEMs&apos; ability to
detect and quantify bias in model learning and also for understanding the
changes in model behavior as training progresses.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Joshi_S/0/1/0/all/0/1&quot;&gt;Shalmali Joshi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koyejo_O/0/1/0/all/0/1&quot;&gt;Oluwasanmi Koyejo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_B/0/1/0/all/0/1&quot;&gt;Been Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghosh_J/0/1/0/all/0/1&quot;&gt;Joydeep Ghosh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.08990">
<title>Stroke-based Character Recognition with Deep Reinforcement Learning. (arXiv:1806.08990v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1806.08990</link>
<description rdf:parseType="Literal">&lt;p&gt;The stroke sequence of characters is significant for the character
recognition task. In this paper, we propose a stroke-based character
recognition (SCR) method. We train a stroke inference module under deep
reinforcement learning (DRL) framework. This module extracts the sequence of
strokes from characters, which can be integrated with character recognizers to
improve their robustness to noise. Our experiments show that the module can
handle complicated noise and reconstruct the characters. Meanwhile, it can also
help achieve great ability in defending adversarial attacks of character
recognizers.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1&quot;&gt;Zhewei Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Heng_W/0/1/0/all/0/1&quot;&gt;Wen Heng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tao_Y/0/1/0/all/0/1&quot;&gt;Yuanzheng Tao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1&quot;&gt;Shuchang Zhou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.09018">
<title>Optimizing the Wisdom of the Crowd: Inference, Learning, and Teaching. (arXiv:1806.09018v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.09018</link>
<description rdf:parseType="Literal">&lt;p&gt;The unprecedented demand for large amount of data has catalyzed the trend of
combining human insights with machine learning techniques, which facilitate the
use of crowdsourcing to enlist label information both effectively and
efficiently. The classic work on crowdsourcing mainly focuses on the label
inference problem under the categorization setting. However, inferring the true
label requires sophisticated aggregation models that usually can only perform
well under certain assumptions. Meanwhile, no matter how complicated the
aggregation model is, the true model that generated the crowd labels remains
unknown. Therefore, the label inference problem can never infer the ground
truth perfectly. Based on the fact that the crowdsourcing labels are abundant
and utilizing aggregation will lose such kind of rich annotation information
(e.g., which worker provided which labels), we believe that it is critical to
take the diverse labeling abilities of the crowdsourcing workers as well as
their correlations into consideration. To address the above challenge, we
propose to tackle three research problems, namely inference, learning, and
teaching.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhou_Y/0/1/0/all/0/1&quot;&gt;Yao Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+He_J/0/1/0/all/0/1&quot;&gt;Jingrui He&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.09035">
<title>Defending Malware Classification Networks Against Adversarial Perturbations with Non-Negative Weight Restrictions. (arXiv:1806.09035v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.09035</link>
<description rdf:parseType="Literal">&lt;p&gt;There is a growing body of literature showing that deep neural networks are
vulnerable to adversarial input modification. Recently this work has been
extended from image classification to malware classification over boolean
features. In this paper we present several new methods for training restricted
networks in this specific domain that are highly effective at preventing
adversarial perturbations. We start with a fully adversarially resistant neural
network that has hard non-negative weight restrictions and is equivalent to
learning a monotonic boolean function and then attempt to relax the constraints
to improve classifier accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kouzemtchenko_A/0/1/0/all/0/1&quot;&gt;Alex Kouzemtchenko&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.09038">
<title>Deductron - A Recurrent Neural Network. (arXiv:1806.09038v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.09038</link>
<description rdf:parseType="Literal">&lt;p&gt;The current paper is a study in Recurrent Neural Networks (RNN), motivated by
the lack of examples simple enough so that they can be thoroughly understood
theoretically, but complex enough to be realistic. We constructed an example of
structured data, motivated by problems from image-to-text conversion (OCR),
which requires long-term memory to decode. Our data is a simple writing system,
encoding characters &apos;X&apos; and &apos;O&apos; as their upper halves, which is possible due to
symmetry of the two characters. The characters can be connected, as in some
languages using cursive, such as Arabic (abjad). The string &apos;XOOXXO&apos; may be
encoded as
&apos;${\vee}{\wedge}\kern-1.5pt{\wedge}{\vee}\kern-1.5pt{\vee}{\wedge}$&apos;. It
follows that we may need to know arbitrarily long past to decode a current
character, thus requiring long-term memory. Subsequently we constructed an RNN
capable of decoding sequences encoded in this manner. Rather than by training,
we constructed our RNN &quot;by inspection&quot;, i.e. we guessed its weights. This
involved a sequence of steps. We wrote a conventional program which decodes the
sequences as the example above. Subsequently, we interpreted the program as a
neural network (the only example of this kind known to us). Finally, we
generalized this neural network to discover a new RNN architecture whose
instance is our handcrafted RNN. It turns out to be a 3 layer network, where
the middle layer is capable of performing simple logical inferences; thus the
name &quot;deductron&quot;. It is demonstrated that it is possible to train our network
by simulated annealing. Also, known variants of stochastic gradient descent
(SGD) methods are shown to work.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rychlik_M/0/1/0/all/0/1&quot;&gt;Marek Rychlik&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.09055">
<title>DARTS: Differentiable Architecture Search. (arXiv:1806.09055v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.09055</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper addresses the scalability challenge of architecture search by
formulating the task in a differentiable manner. Unlike conventional approaches
of applying evolution or reinforcement learning over a discrete and
non-differentiable search space, our method is based on the continuous
relaxation of the architecture representation, allowing efficient search of the
architecture using gradient descent. Extensive experiments on CIFAR-10,
ImageNet, Penn Treebank and WikiText-2 show that our algorithm excels in
discovering high-performance convolutional architectures for image
classification and recurrent architectures for language modeling, while being
orders of magnitude faster than state-of-the-art non-differentiable techniques.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1&quot;&gt;Hanxiao Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Simonyan_K/0/1/0/all/0/1&quot;&gt;Karen Simonyan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1&quot;&gt;Yiming Yang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.09070">
<title>Generative Models for Pose Transfer. (arXiv:1806.09070v1 [cs.GR])</title>
<link>http://arxiv.org/abs/1806.09070</link>
<description rdf:parseType="Literal">&lt;p&gt;We investigate nearest neighbor and generative models for transferring pose
between persons. We take in a video of one person performing a sequence of
actions and attempt to generate a video of another person performing the same
actions. Our generative model (pix2pix) outperforms k-NN at both generating
corresponding frames and generalizing outside the demonstrated action set. Our
most salient contribution is determining a pipeline (pose detection, face
detection, k-NN based pairing) that is effective at perform-ing the desired
task. We also detail several iterative improvements and failure modes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chao_P/0/1/0/all/0/1&quot;&gt;Patrick Chao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_A/0/1/0/all/0/1&quot;&gt;Alexander Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Swamy_G/0/1/0/all/0/1&quot;&gt;Gokul Swamy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.09186">
<title>Detecting Adversarial Examples Based on Steganalysis. (arXiv:1806.09186v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1806.09186</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep Neural Networks (DNNs) have recently led to significant improvement in
many fields, such as image classification. However, these machine learning
models are vulnerable to adversarial examples which can mislead machine
learning classifiers to give incorrect classifications. Adversarial examples
pose security concerns in areas where privacy requirements are strict, such as
face recognition, autonomous cars and malware detection. What&apos;s more, they
could be used to perform an attack on machine learning systems, even if the
adversary has no access to the underlying model. In this paper, we focus on
detecting adversarial examples. We propose to augment deep neural networks with
a detector. The detector is constructed by modeling the differences between
adjacent pixels in natural images. And then we identify deviations from this
model and assume that such deviations are due to adversarial attack. We
construct the detector based on steganalysis which can detect minor
modifications to an image because the adversarial attack can be treated as a
sort of accidental steganography.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Jiayang Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1&quot;&gt;Weiming Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yiwei Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hou_D/0/1/0/all/0/1&quot;&gt;Dongdong Hou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yujia Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_N/0/1/0/all/0/1&quot;&gt;Nenghai Yu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.09206">
<title>N-Gram Graph, A Novel Molecule Representation. (arXiv:1806.09206v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.09206</link>
<description rdf:parseType="Literal">&lt;p&gt;Virtual high-throughput screening provides a strategy for prioritizing
compounds for physical screens. Machine learning methods offer an ancillary
benefit to make molecule predictions, yet the choice of representation has been
challenging when selecting algorithms. We emphasize the effects of different
levels of molecule representation. Then, we introduce N-gram graph, a novel
representation for a molecular graph. We demonstrate that N-gram graph is able
to attain most accurate prediction with several non-deep machine learning
methods on multiple tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1&quot;&gt;Shengchao Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chandereng_T/0/1/0/all/0/1&quot;&gt;Thevaa Chandereng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1&quot;&gt;Yingyu Liang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.09211">
<title>Equalizing Financial Impact in Supervised Learning. (arXiv:1806.09211v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.09211</link>
<description rdf:parseType="Literal">&lt;p&gt;Notions of &quot;fair classification&quot; that have arisen in computer science
generally revolve around equalizing certain statistics across protected groups.
This approach has been criticized as ignoring societal issues, including how
errors can hurt certain groups disproportionately. We pose a modification of
one of the fairness criteria from Hardt, Price, and Srebro [NIPS, 2016] that
makes a small step towards addressing this issue in the case of financial
decisions like giving loans. We call this new notion &quot;equalized financial
impact.&quot;
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ramnarayan_G/0/1/0/all/0/1&quot;&gt;Govind Ramnarayan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.09231">
<title>Clebsch-Gordan Nets: a Fully Fourier Space Spherical Convolutional Neural Network. (arXiv:1806.09231v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.09231</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent work by Cohen \emph{et al.} has achieved state-of-the-art results for
learning spherical images in a rotation invariant way by using ideas from group
representation theory and noncommutative harmonic analysis. In this paper we
propose a generalization of this work that generally exhibits improved
performace, but from an implementation point of view is actually simpler. An
unusual feature of the proposed architecture is that it uses the
Clebsch--Gordan transform as its only source of nonlinearity, thus avoiding
repeated forward and backward Fourier transforms. The underlying ideas of the
paper generalize to constructing neural networks that are invariant to the
action of other compact groups.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kondor_R/0/1/0/all/0/1&quot;&gt;Risi Kondor&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lin_Z/0/1/0/all/0/1&quot;&gt;Zhen Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Trivedi_S/0/1/0/all/0/1&quot;&gt;Shubhendu Trivedi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.09235">
<title>JR-GAN: Jacobian Regularization for Generative Adversarial Networks. (arXiv:1806.09235v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.09235</link>
<description rdf:parseType="Literal">&lt;p&gt;Generative adversarial networks (GANs) are notoriously difficult to train and
the reasons for their (non-)convergence behaviors are still not completely
understood. Using a simple GAN example, we mathematically analyze the local
convergence behavior of its training dynamics in a non-asymptotic way. We find
that in order to ensure a good convergence rate two factors of the Jacobian
should be \textit{simultaneously} avoided, which are (1) Phase Factor: the
Jacobian has complex eigenvalues with a large imaginary-to-real ratio, (2)
Conditioning Factor: the Jacobian is ill-conditioned. Previous methods of
regularizing the Jacobian can only alleviate one of these two factors, while
making the other more severe. From our theoretical analysis, we propose the
Jacobian Regularized GANs (JR-GANs), which insure the two factors are
alleviated by construction. With extensive experiments on several popular
datasets, we show that the JR-GAN training is highly stable and achieves near
state-of-the-art results both qualitatively and quantitatively.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Nie_W/0/1/0/all/0/1&quot;&gt;Weili Nie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Patel_A/0/1/0/all/0/1&quot;&gt;Ankit Patel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.09266">
<title>Learning Task-Oriented Grasping for Tool Manipulation from Simulated Self-Supervision. (arXiv:1806.09266v1 [cs.RO])</title>
<link>http://arxiv.org/abs/1806.09266</link>
<description rdf:parseType="Literal">&lt;p&gt;Tool manipulation is vital for facilitating robots to complete challenging
task goals. It requires reasoning about the desired effect of the task and thus
properly grasping and manipulating the tool to achieve the task. Task-agnostic
grasping optimizes for grasp robustness while ignoring crucial task-specific
constraints. In this paper, we propose the Task-Oriented Grasping Network
(TOG-Net) to jointly optimize both task-oriented grasping of a tool and the
manipulation policy for that tool. The training process of the model is based
on large-scale simulated self-supervision with procedurally generated tool
objects. We perform both simulated and real-world experiments on two tool-based
manipulation tasks: sweeping and hammering. Our model achieves overall 71.1%
task success rate for sweeping and 80.0% task success rate for hammering.
Supplementary material is available at: bit.ly/task-oriented-grasp
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fang_K/0/1/0/all/0/1&quot;&gt;Kuan Fang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1&quot;&gt;Yuke Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garg_A/0/1/0/all/0/1&quot;&gt;Animesh Garg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kurenkov_A/0/1/0/all/0/1&quot;&gt;Andrey Kurenkov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mehta_V/0/1/0/all/0/1&quot;&gt;Viraj Mehta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fei_Fei_L/0/1/0/all/0/1&quot;&gt;Li Fei-Fei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Savarese_S/0/1/0/all/0/1&quot;&gt;Silvio Savarese&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.09385">
<title>An Unsupervised Learning Classifier with Competitive Error Performance. (arXiv:1806.09385v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.09385</link>
<description rdf:parseType="Literal">&lt;p&gt;An unsupervised learning classification model is described. It achieves
classification error probability competitive with that of state-of-the-art
supervised learning classifiers such as SVM or kNN. The model is based on the
incremental execution of small step shift and rotation operations upon selected
discriminative hyperplanes at the arrival of input samples. When applied, in
conjunction with a selected feature extractor, to a subset of the ImageNet
dataset benchmark, it yields 6.2 % Top 3 probability of error; this exceeds by
merely about 2 % the result achieved by (supervised) k-Nearest Neighbor, both
using same feature extractor. This result may also be contrasted with popular
unsupervised learning schemes such as k-Means which is shown to be practically
useless on same dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nissani_D/0/1/0/all/0/1&quot;&gt;Daniel N. Nissani&lt;/a&gt; (Nissensohn)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.09463">
<title>Target Contrastive Pessimistic Discriminant Analysis. (arXiv:1806.09463v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.09463</link>
<description rdf:parseType="Literal">&lt;p&gt;Domain-adaptive classifiers learn from a source domain and aim to generalize
to a target domain. If the classifier&apos;s assumptions on the relationship between
domains (e.g. covariate shift) are valid, then it will usually outperform a
non-adaptive source classifier. Unfortunately, it can perform substantially
worse when its assumptions are invalid. Validating these assumptions requires
labeled target samples, which are usually not available. We argue that, in
order to make domain-adaptive classifiers more practical, it is necessary to
focus on robust methods; robust in the sense that the model still achieves a
particular level of performance without making strong assumptions on the
relationship between domains. With this objective in mind, we formulate a
conservative parameter estimator that only deviates from the source classifier
when a lower or equal risk is guaranteed for all possible labellings of the
given target samples. We derive the corresponding estimator for a discriminant
analysis model, and show that its risk is actually strictly smaller than that
of the source classifier. Experiments indicate that our classifier outperforms
state-of-the-art classifiers for geographically biased samples.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kouw_W/0/1/0/all/0/1&quot;&gt;Wouter M. Kouw&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Loog_M/0/1/0/all/0/1&quot;&gt;Marco Loog&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.09471">
<title>Does data interpolation contradict statistical optimality?. (arXiv:1806.09471v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.09471</link>
<description rdf:parseType="Literal">&lt;p&gt;We show that learning methods interpolating the training data can achieve
optimal rates for the problems of nonparametric regression and prediction with
square loss.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Belkin_M/0/1/0/all/0/1&quot;&gt;Mikhail Belkin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rakhlin_A/0/1/0/all/0/1&quot;&gt;Alexander Rakhlin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tsybakov_A/0/1/0/all/0/1&quot;&gt;Alexandre B. Tsybakov&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.09533">
<title>Using NLP on news headlines to predict index trends. (arXiv:1806.09533v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1806.09533</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper attempts to provide a state of the art in trend prediction using
news headlines. We present the research done on predicting DJIA trends using
Natural Language Processing. We will explain the different algorithms we have
used as well as the various embedding techniques attempted. We rely on
statistical and deep learning models in order to extract information from the
corpuses.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Velay_M/0/1/0/all/0/1&quot;&gt;Marc Velay&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Daniel_F/0/1/0/all/0/1&quot;&gt;Fabrice Daniel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.09542">
<title>Mapping Unparalleled Clinical Professional and Consumer Languages with Embedding Alignment. (arXiv:1806.09542v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.09542</link>
<description rdf:parseType="Literal">&lt;p&gt;Mapping and translating professional but arcane clinical jargons to consumer
language is essential to improve the patient-clinician communication.
Researchers have used the existing biomedical ontologies and consumer health
vocabulary dictionary to translate between the languages. However, such
approaches are limited by expert efforts to manually build the dictionary,
which is hard to be generalized and scalable. In this work, we utilized the
embeddings alignment method for the word mapping between unparalleled clinical
professional and consumer language embeddings. To map semantically similar
words in two different word embeddings, we first independently trained word
embeddings on both the corpus with abundant clinical professional terms and the
other with mainly healthcare consumer terms. Then, we aligned the embeddings by
the Procrustes algorithm. We also investigated the approach with the
adversarial training with refinement. We evaluated the quality of the alignment
through the similar words retrieval both by computing the model precision and
as well as judging qualitatively by human. We show that the Procrustes
algorithm can be performant for the professional consumer language embeddings
alignment, whereas adversarial training with refinement may find some relations
between two languages.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Weng_W/0/1/0/all/0/1&quot;&gt;Wei-Hung Weng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Szolovits_P/0/1/0/all/0/1&quot;&gt;Peter Szolovits&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.03713">
<title>Optimization of ReLU Neural Networks using Quotient Stochastic Gradient Descent. (arXiv:1802.03713v5 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1802.03713</link>
<description rdf:parseType="Literal">&lt;p&gt;It has been well known that neural networks with rectified linear hidden
units (ReLU) as activation functions are positively scale invariant, which
results in severe redundancy in their weight space (i.e., many ReLU networks
with different weights are actually equivalent). In this paper, we formally
characterize this redundancy/equivalence using the language of quotient space
and discuss its negative impact on the optimization of ReLU neural networks.
Specifically, we show that all equivalent ReLU networks correspond to the same
vector in the quotient space, and each such vector can be characterized by the
so-called skeleton paths in the ReLU networks. With this, we prove that the
dimensionality of the quotient space is $\#$weight$-\#$(hidden nodes),
indicating that the redundancy of the weight space is huge. In this paper, we
propose to optimize ReLU neural networks directly in the quotient space,
instead of the original weight space. We represent the loss function in the
quotient space and design a new stochastic gradient descent algorithm to
iteratively learn the model, which we call \emph{Quotient stochastic gradient
descent } (abbreviated as Quotient SGD). We also develop efficient tricks to
ensure that the implementation of Quotient SGD almost requires no extra
computations as compared to standard SGD. According to the experiments on
benchmark datasets, our proposed Quotient SGD can significantly improve the
accuracy of the learned model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Meng_Q/0/1/0/all/0/1&quot;&gt;Qi Meng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chen_W/0/1/0/all/0/1&quot;&gt;Wei Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zheng_S/0/1/0/all/0/1&quot;&gt;Shuxin Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ye_Q/0/1/0/all/0/1&quot;&gt;Qiwei Ye&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Liu_T/0/1/0/all/0/1&quot;&gt;Tie-Yan Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05411">
<title>Selecting the Best in GANs Family: a Post Selection Inference Framework. (arXiv:1802.05411v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1802.05411</link>
<description rdf:parseType="Literal">&lt;p&gt;&quot;Which Generative Adversarial Networks (GANs) generates the most plausible
images?&quot; has been a frequently asked question among researchers. To address
this problem, we first propose an \emph{incomplete} U-statistics estimate of
maximum mean discrepancy $\mathrm{MMD}_{inc}$ to measure the distribution
discrepancy between generated and real images. $\mathrm{MMD}_{inc}$ enjoys the
advantages of asymptotic normality, computation efficiency, and model
agnosticity. We then propose a GANs analysis framework to select and test the
&quot;best&quot; member in GANs family using the Post Selection Inference (PSI) with
$\mathrm{MMD}_{inc}$. In the experiments, we adopt the proposed framework on 7
GANs variants and compare their $\mathrm{MMD}_{inc}$ scores.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tsai_Y/0/1/0/all/0/1&quot;&gt;Yao-Hung Hubert Tsai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yamada_M/0/1/0/all/0/1&quot;&gt;Makoto Yamada&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_D/0/1/0/all/0/1&quot;&gt;Denny Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Salakhutdinov_R/0/1/0/all/0/1&quot;&gt;Ruslan Salakhutdinov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Takeuchi_I/0/1/0/all/0/1&quot;&gt;Ichiro Takeuchi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fukumizu_K/0/1/0/all/0/1&quot;&gt;Kenji Fukumizu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.09522">
<title>A Provably Correct Algorithm for Deep Learning that Actually Works. (arXiv:1803.09522v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1803.09522</link>
<description rdf:parseType="Literal">&lt;p&gt;We describe a layer-by-layer algorithm for training deep convolutional
networks, where each step involves gradient updates for a two layer network
followed by a simple clustering algorithm. Our algorithm stems from a deep
generative model that generates mages level by level, where lower resolution
images correspond to latent semantic classes. We analyze the convergence rate
of our algorithm assuming that the data is indeed generated according to this
model (as well as additional assumptions). While we do not pretend to claim
that the assumptions are realistic for natural images, we do believe that they
capture some true properties of real data. Furthermore, we show that our
algorithm actually works in practice (on the CIFAR dataset), achieving results
in the same ballpark as that of vanilla convolutional neural networks that are
being trained by stochastic gradient descent. Finally, our proof techniques may
be of independent interest.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Malach_E/0/1/0/all/0/1&quot;&gt;Eran Malach&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shalev_Shwartz_S/0/1/0/all/0/1&quot;&gt;Shai Shalev-Shwartz&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.00108">
<title>Conditional molecular design with deep generative models. (arXiv:1805.00108v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.00108</link>
<description rdf:parseType="Literal">&lt;p&gt;Although machine learning has been successfully used to propose novel
molecules that satisfy desired properties, it is still challenging to explore a
large chemical space efficiently. In this paper, we present a conditional
molecular design method that facilitates generating new molecules with desired
properties. The proposed model, which simultaneously performs both property
prediction and molecule generation, is built as a semi-supervised variational
autoencoder trained on a set of existing molecules with only a partial
annotation. We generate new molecules with desired properties by sampling from
the generative distribution estimated by the model. We demonstrate the
effectiveness of the proposed model by evaluating it on drug-like molecules.
The model improves the performance of property prediction by exploiting
unlabeled molecules, and efficiently generates novel molecules fulfilling
various target conditions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kang_S/0/1/0/all/0/1&quot;&gt;Seokho Kang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cho_K/0/1/0/all/0/1&quot;&gt;Kyunghyun Cho&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.08079">
<title>GrCAN: Gradient Boost Convolutional Autoencoder with Neural Decision Forest. (arXiv:1806.08079v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1806.08079</link>
<description rdf:parseType="Literal">&lt;p&gt;Random forest and deep neural network are two schools of effective
classification methods in machine learning. While the random forest is robust
irrespective of the data domain, the deep neural network has advantages in
handling high dimensional data. In view that a differentiable neural decision
forest can be added to the neural network to fully exploit the benefits of both
models, in our work, we further combine convolutional autoencoder with neural
decision forest, where autoencoder has its advantages in finding the hidden
representations of the input data. We develop a gradient boost module and embed
it into the proposed convolutional autoencoder with neural decision forest to
improve the performance. The idea of gradient boost is to learn and use the
residual in the prediction. In addition, we design a structure to learn the
parameters of the neural decision forest and gradient boost module at
contiguous steps. The extensive experiments on several public datasets
demonstrate that our proposed model achieves good efficiency and prediction
performance compared with a series of baseline methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dong_M/0/1/0/all/0/1&quot;&gt;Manqing Dong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yao_L/0/1/0/all/0/1&quot;&gt;Lina Yao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;Xianzhi Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Benatallah_B/0/1/0/all/0/1&quot;&gt;Boualem Benatallah&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1&quot;&gt;Shuai Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.08240">
<title>InfoCatVAE: Representation Learning with Categorical Variational Autoencoders. (arXiv:1806.08240v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1806.08240</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper describes InfoCatVAE, an extension of the variational autoencoder
that enables unsupervised disentangled representation learning. InfoCatVAE uses
multimodal distributions for the prior and the inference network and then
maximizes the evidence lower bound objective (ELBO). We connect the new ELBO
derived for our model with a natural soft clustering objective which explains
the robustness of our approach. We then adapt the InfoGANs method to our
setting in order to maximize the mutual information between the categorical
code and the generated inputs and obtain an improved model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pineau_E/0/1/0/all/0/1&quot;&gt;Edouard Pineau&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lelarge_M/0/1/0/all/0/1&quot;&gt;Marc Lelarge&lt;/a&gt;</dc:creator>
</item></rdf:RDF>