<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Good papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Good Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-08-01T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.00260"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.00300"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.00033"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.00222"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.00265"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.02291"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.00098"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.00198"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.00200"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.00209"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.00245"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.00309"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.00380"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.00387"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.00408"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.00418"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.00423"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06167"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1808.00260">
<title>A Review on the Application of Natural Computing in Environmental Informatics. (arXiv:1808.00260v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1808.00260</link>
<description rdf:parseType="Literal">&lt;p&gt;Natural computing offers new opportunities to understand, model and analyze
the complexity of the physical and human-created environment. This paper
examines the application of natural computing in environmental informatics, by
investigating related work in this research field. Various nature-inspired
techniques are presented, which have been employed to solve different relevant
problems. Advantages and disadvantages of these techniques are discussed,
together with analysis of how natural computing is generally used in
environmental research.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kamilaris_A/0/1/0/all/0/1&quot;&gt;Andreas Kamilaris&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.00300">
<title>Learning Visual Question Answering by Bootstrapping Hard Attention. (arXiv:1808.00300v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1808.00300</link>
<description rdf:parseType="Literal">&lt;p&gt;Attention mechanisms in biological perception are thought to select subsets
of perceptual information for more sophisticated processing which would be
prohibitive to perform on all sensory inputs. In computer vision, however,
there has been relatively little exploration of hard attention, where some
information is selectively ignored, in spite of the success of soft attention,
where information is re-weighted and aggregated, but never filtered out. Here,
we introduce a new approach for hard attention and find it achieves very
competitive performance on a recently-released visual question answering
datasets, equalling and in some cases surpassing similar soft attention
architectures while entirely ignoring some features. Even though the hard
attention mechanism is thought to be non-differentiable, we found that the
feature magnitudes correlate with semantic relevance, and provide a useful
signal for our mechanism&apos;s attentional selection criterion. Because hard
attention selects important features of the input information, it can also be
more efficient than analogous soft attention mechanisms. This is especially
important for recent approaches that use non-local pairwise operations, whereby
computational and memory costs are quadratic in the size of the set of
features.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Malinowski_M/0/1/0/all/0/1&quot;&gt;Mateusz Malinowski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Doersch_C/0/1/0/all/0/1&quot;&gt;Carl Doersch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Santoro_A/0/1/0/all/0/1&quot;&gt;Adam Santoro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Battaglia_P/0/1/0/all/0/1&quot;&gt;Peter Battaglia&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.00033">
<title>Techniques for Interpretable Machine Learning. (arXiv:1808.00033v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1808.00033</link>
<description rdf:parseType="Literal">&lt;p&gt;Interpretable machine learning tackles the important problem that humans
cannot understand the behaviors of complex machine learning models and how
these classifiers arrive at a particular decision. Although many approaches
have been proposed, a comprehensive understanding of the achievements and
challenges is still lacking. This paper provides a survey covering existing
techniques and methods to increase the interpretability of machine learning
models and also discusses the crucial issues to consider in future work such as
interpretation design principles and evaluation metrics in order to push
forward the area of interpretable machine learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Du_M/0/1/0/all/0/1&quot;&gt;Mengnan Du&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_N/0/1/0/all/0/1&quot;&gt;Ninghao Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1&quot;&gt;Xia Hu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.00222">
<title>Experience, Imitation and Reflection; Confucius&apos; Conjecture and Machine Learning. (arXiv:1808.00222v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1808.00222</link>
<description rdf:parseType="Literal">&lt;p&gt;Artificial intelligence recently had a great advancements caused by the
emergence of new processing power and machine learning methods. Having said
that, the learning capability of artificial intelligence is still at its
infancy comparing to the learning capability of human and many animals. Many of
the current artificial intelligence applications can only operate in a very
orchestrated, specific environments with an extensive training set that exactly
describes the conditions that will occur during execution time. Having that in
mind, and considering the several existing machine learning methods this
question rises that &apos;What are some of the best ways for a machine to learn?&apos;
Regarding the learning methods of human, Confucius&apos; point of view is that they
are by experience, imitation and reflection. This paper tries to explore and
discuss regarding these three ways of learning and their implementations in
machines by having a look at how they happen in minds.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dooraki_A/0/1/0/all/0/1&quot;&gt;Amir Ramezani Dooraki&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.00265">
<title>Interpretable Visual Question Answering by Visual Grounding from Attention Supervision Mining. (arXiv:1808.00265v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1808.00265</link>
<description rdf:parseType="Literal">&lt;p&gt;A key aspect of VQA models that are interpretable is their ability to ground
their answers to relevant regions in the image. Current approaches with this
capability rely on supervised learning and human annotated groundings to train
attention mechanisms inside the VQA architecture. Unfortunately, obtaining
human annotations specific for visual grounding is difficult and expensive. In
this work, we demonstrate that we can effectively train a VQA architecture with
grounding supervision that can be automatically obtained from available region
descriptions and object annotations. We also show that our model trained with
this mined supervision generates visual groundings that achieve a higher
correlation with respect to manually-annotated groundings, meanwhile achieving
state-of-the-art VQA accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yundong Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Niebles_J/0/1/0/all/0/1&quot;&gt;Juan Carlos Niebles&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Soto_A/0/1/0/all/0/1&quot;&gt;Alvaro Soto&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.02291">
<title>Synthesizing Neural Network Controllers with Probabilistic Model based Reinforcement Learning. (arXiv:1803.02291v3 [cs.RO] UPDATED)</title>
<link>http://arxiv.org/abs/1803.02291</link>
<description rdf:parseType="Literal">&lt;p&gt;We present an algorithm for rapidly learning controllers for robotics
systems. The algorithm follows the model-based reinforcement learning paradigm,
and improves upon existing algorithms; namely Probabilistic learning in Control
(PILCO) and a sample-based version of PILCO with neural network dynamics
(Deep-PILCO). We propose training a neural network dynamics model using
variational dropout with truncated Log-Normal noise. This allows us to obtain a
dynamics model with calibrated uncertainty, which can be used to simulate
controller executions via rollouts. We also describe set of techniques,
inspired by viewing PILCO as a recurrent neural network model, that are crucial
to improve the convergence of the method. We test our method on a variety of
benchmark tasks, demonstrating data-efficiency that is competitive with PILCO,
while being able to optimize complex neural network controllers. Finally, we
assess the performance of the algorithm for learning motor controllers for a
six legged autonomous underwater vehicle. This demonstrates the potential of
the algorithm for scaling up the dimensionality and dataset sizes, in more
complex control tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Higuera_J/0/1/0/all/0/1&quot;&gt;Juan Camilo Gamboa Higuera&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meger_D/0/1/0/all/0/1&quot;&gt;David Meger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dudek_G/0/1/0/all/0/1&quot;&gt;Gregory Dudek&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.00098">
<title>Universal Approximation with Quadratic Deep Networks. (arXiv:1808.00098v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1808.00098</link>
<description rdf:parseType="Literal">&lt;p&gt;Recently, deep learning has been playing a central role in machine learning
research and applications. Since AlexNet, increasingly more advanced networks
have achieved state-of-the-art performance in computer vision, speech
recognition, language processing, game playing, medical imaging, and so on. In
our previous studies, we proposed quadratic/second-order neurons and deep
quadratic neural networks. In a quadratic neuron, the inner product of a vector
of data and the corresponding weights in a conventional neuron is replaced with
a quadratic function. The resultant second-order neuron enjoys an enhanced
expressive capability over the conventional neuron. However, how quadratic
neurons improve the expressing capability of a deep quadratic network has not
been studied up to now, preferably in relation to that of a conventional neural
network. In this paper, we ask three basic questions regarding the expressive
capability of a quadratic network: (1) for the one-hidden-layer network
structure, is there any function that a quadratic network can approximate much
more efficiently than a conventional network? (2) for the same multi-layer
network structure, is there any function that can be expressed by a quadratic
network but cannot be expressed with conventional neurons in the same
structure? (3) Does a quadratic network give a new insight into universal
approximation? Our main contributions are the three theorems shedding light
upon these three questions and demonstrating the merits of a quadratic network
in terms of expressive efficiency, unique capability, and compact architecture
respectively.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fan_F/0/1/0/all/0/1&quot;&gt;Fenglei Fan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1&quot;&gt;Ge Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.00198">
<title>Towards Machine Learning on data from Professional Cyclists. (arXiv:1808.00198v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1808.00198</link>
<description rdf:parseType="Literal">&lt;p&gt;Professional sports are developing towards increasingly scientific training
methods with increasing amounts of data being collected from laboratory tests,
training sessions and competitions. In cycling, it is standard to equip
bicycles with small computers recording data from sensors such as power-meters,
in addition to heart-rate, speed, altitude etc. Recently, machine learning
techniques have provided huge success in a wide variety of areas where large
amounts of data (big data) is available. In this paper, we perform a pilot
experiment on machine learning to model physical response in elite cyclists. As
a first experiment, we show that it is possible to train a LSTM machine
learning algorithm to predict the heart-rate response of a cyclist during a
training session. This work is a promising first step towards developing more
elaborate models based on big data and machine learning to capture performance
aspects of athletes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hilmkil_A/0/1/0/all/0/1&quot;&gt;Agrin Hilmkil&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ivarsson_O/0/1/0/all/0/1&quot;&gt;Oscar Ivarsson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Johansson_M/0/1/0/all/0/1&quot;&gt;Moa Johansson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kuylenstierna_D/0/1/0/all/0/1&quot;&gt;Dan Kuylenstierna&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Erp_T/0/1/0/all/0/1&quot;&gt;Teun van Erp&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.00200">
<title>Anomaly Detection via Minimum Likelihood Generative Adversarial Networks. (arXiv:1808.00200v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1808.00200</link>
<description rdf:parseType="Literal">&lt;p&gt;Anomaly detection aims to detect abnormal events by a model of normality. It
plays an important role in many domains such as network intrusion detection,
criminal activity identity and so on. With the rapidly growing size of
accessible training data and high computation capacities, deep learning based
anomaly detection has become more and more popular. In this paper, a new
domain-based anomaly detection method based on generative adversarial networks
(GAN) is proposed. Minimum likelihood regularization is proposed to make the
generator produce more anomalies and prevent it from converging to normal data
distribution. Proper ensemble of anomaly scores is shown to improve the
stability of discriminator effectively. The proposed method has achieved
significant improvement than other anomaly detection methods on Cifar10 and UCI
datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1&quot;&gt;Chu Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yan-Ming Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1&quot;&gt;Cheng-Lin Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.00209">
<title>Binarized Convolutional Neural Networks for Efficient Inference on GPUs. (arXiv:1808.00209v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1808.00209</link>
<description rdf:parseType="Literal">&lt;p&gt;Convolutional neural networks have recently achieved significant
breakthroughs in various image classification tasks. However, they are
computationally expensive,which can make their feasible mplementation on
embedded and low-power devices difficult. In this paper convolutional neural
network binarization is implemented on GPU-based platforms for real-time
inference on resource constrained devices. In binarized networks, all weights
and intermediate computations between layers are quantized to +1 and -1,
allowing multiplications and additions to be replaced with bit-wise operations
between 32-bit words. This representation completely eliminates the need for
floating point multiplications and additions and decreases both the
computational load and the memory footprint compared to a full-precision
network implemented in floating point, making it well-suited for
resource-constrained environments. We compare the performance of our
implementation with an equivalent floating point implementation on one desktop
and two embedded GPU platforms. Our implementation achieves a maximum speed up
of 7. 4X with only 4.4% loss in accuracy compared to a reference
implementation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khan_M/0/1/0/all/0/1&quot;&gt;Mir Khan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huttunen_H/0/1/0/all/0/1&quot;&gt;Heikki Huttunen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Boutellier_J/0/1/0/all/0/1&quot;&gt;Jani Boutellier&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.00245">
<title>Robbins-Mobro conditions for persistent exploration learning strategies. (arXiv:1808.00245v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1808.00245</link>
<description rdf:parseType="Literal">&lt;p&gt;We formulate simple assumptions, implying the Robbins-Monro conditions for
the $Q$-learning algorithm with the local learning rate, depending on the
number of visits of a particular state-action pair (local clock) and the number
of iteration (global clock). It is assumed that the Markov decision process is
communicating and the learning policy ensures the persistent exploration. The
restrictions are imposed on the functional dependence of the learning rate on
the local and global clocks. The result partially confirms the conjecture of
Bradkte (1994).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rokhlin_D/0/1/0/all/0/1&quot;&gt;Dmitry B. Rokhlin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.00309">
<title>Model-order selection in statistical shape models. (arXiv:1808.00309v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1808.00309</link>
<description rdf:parseType="Literal">&lt;p&gt;Statistical shape models enhance machine learning algorithms providing prior
information about deformation. A Point Distribution Model (PDM) is a popular
landmark-based statistical shape model for segmentation. It requires choosing a
model order, which determines how much of the variation seen in the training
data is accounted for by the PDM. A good choice of the model order depends on
the number of training samples and the noise level in the training data set.
Yet the most common approach for choosing the model order simply keeps a
predetermined percentage of the total shape variation. In this paper, we
present a technique for choosing the model order based on information-theoretic
criteria, and we show empirical evidence that the model order chosen by this
technique provides a good trade-off between over- and underfitting.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Eguizabal_A/0/1/0/all/0/1&quot;&gt;Alma Eguizabal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schreier_P/0/1/0/all/0/1&quot;&gt;Peter J. Schreier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ramirez_D/0/1/0/all/0/1&quot;&gt;David Ram&amp;#xed;rez&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.00380">
<title>A Differentially Private Kernel Two-Sample Test. (arXiv:1808.00380v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1808.00380</link>
<description rdf:parseType="Literal">&lt;p&gt;Kernel two-sample testing is a useful statistical tool in determining whether
data samples arise from different distributions without imposing any parametric
assumptions on those distributions. However, raw data samples can expose
sensitive information about individuals who participate in scientific studies,
which makes the current tests vulnerable to privacy breaches. Hence, we design
a new framework for kernel two-sample testing conforming to differential
privacy constraints, in order to guarantee the privacy of subjects in the data.
Unlike existing differentially private parametric tests that simply add noise
to data, kernel-based testing imposes a challenge due to a complex dependence
of test statistics on the raw data, as these statistics correspond to
estimators of distances between representations of probability measures in
Hilbert spaces. Our approach considers finite dimensional approximations to
those representations. As a result, a simple chi-squared test is obtained,
where a test statistic depends on a mean and covariance of empirical
differences between the samples, which we perturb for a privacy guarantee. We
investigate the utility of our framework in two realistic settings and conclude
that our method requires only a relatively modest increase in sample size to
achieve a similar level of power to the non-private tests in both settings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Raj_A/0/1/0/all/0/1&quot;&gt;Anant Raj&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Law_H/0/1/0/all/0/1&quot;&gt;Ho Chung Leon Law&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sejdinovic_D/0/1/0/all/0/1&quot;&gt;Dino Sejdinovic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Park_M/0/1/0/all/0/1&quot;&gt;Mijung Park&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.00387">
<title>Just Interpolate: Kernel &quot;Ridgeless&quot; Regression Can Generalize. (arXiv:1808.00387v1 [math.ST])</title>
<link>http://arxiv.org/abs/1808.00387</link>
<description rdf:parseType="Literal">&lt;p&gt;In the absence of explicit regularization, Kernel &quot;Ridgeless&quot; Regression with
nonlinear kernels has the potential to fit the training data perfectly. It has
been observed empirically, however, that such interpolated solutions can still
generalize well on test data. We isolate a phenomenon of implicit
regularization for minimum-norm interpolated solutions which is due to a
combination of high dimensionality of the input data, curvature of the kernel
function, and favorable geometric properties of the data such as an eigenvalue
decay of the empirical covariance and kernel matrices. In addition to deriving
a data-dependent upper bound on the out-of-sample error, we present
experimental evidence suggesting that the phenomenon occurs in the MNIST
dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Liang_T/0/1/0/all/0/1&quot;&gt;Tengyuan Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Rakhlin_A/0/1/0/all/0/1&quot;&gt;Alexander Rakhlin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.00408">
<title>Geometry of energy landscapes and the optimizability of deep neural networks. (arXiv:1808.00408v1 [cond-mat.dis-nn])</title>
<link>http://arxiv.org/abs/1808.00408</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep neural networks are workhorse models in machine learning with multiple
layers of non-linear functions composed in series. Their loss function is
highly non-convex, yet empirically even gradient descent minimisation is
sufficient to arrive at accurate and predictive models. It is hitherto unknown
why are deep neural networks easily optimizable. We analyze the energy
landscape of a spin glass model of deep neural networks using random matrix
theory and algebraic geometry. We analytically show that the multilayered
structure holds the key to optimizability: Fixing the number of parameters and
increasing network depth, the number of stationary points in the loss function
decreases, minima become more clustered in parameter space, and the tradeoff
between the depth and width of minima becomes less severe. Our analytical
results are numerically verified through comparison with neural networks
trained on a set of classical benchmark datasets. Our model uncovers generic
design principles of machine learning models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Becker_S/0/1/0/all/0/1&quot;&gt;Simon Becker&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yao Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Lee_A/0/1/0/all/0/1&quot;&gt;Alpha A. Lee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.00418">
<title>Stock Chart Pattern recognition with Deep Learning. (arXiv:1808.00418v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1808.00418</link>
<description rdf:parseType="Literal">&lt;p&gt;This study evaluates the performances of CNN and LSTM for recognizing common
charts patterns in a stock historical data. It presents two common patterns,
the method used to build the training set, the neural networks architectures
and the accuracies obtained.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Velay_M/0/1/0/all/0/1&quot;&gt;Marc Velay&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Daniel_F/0/1/0/all/0/1&quot;&gt;Fabrice Daniel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.00423">
<title>Seq2Seq and Multi-Task Learning for joint intent and content extraction for domain specific interpreters. (arXiv:1808.00423v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1808.00423</link>
<description rdf:parseType="Literal">&lt;p&gt;This study evaluates the performances of an LSTM network for detecting and
extracting the intent and content of com- mands for a financial chatbot. It
presents two techniques, sequence to sequence learning and Multi-Task Learning,
which might improve on the previous task.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Velay_M/0/1/0/all/0/1&quot;&gt;Marc Velay&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Daniel_F/0/1/0/all/0/1&quot;&gt;Fabrice Daniel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06167">
<title>CapsuleGAN: Generative Adversarial Capsule Network. (arXiv:1802.06167v4 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1802.06167</link>
<description rdf:parseType="Literal">&lt;p&gt;We present Generative Adversarial Capsule Network (CapsuleGAN), a framework
that uses capsule networks (CapsNets) instead of the standard convolutional
neural networks (CNNs) as discriminators within the generative adversarial
network (GAN) setting, while modeling image data. We provide guidelines for
designing CapsNet discriminators and the updated GAN objective function, which
incorporates the CapsNet margin loss, for training CapsuleGAN models. We show
that CapsuleGAN outperforms convolutional-GAN at modeling image data
distribution on MNIST and CIFAR-10 datasets, evaluated on the generative
adversarial metric and at semi-supervised image classification.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Jaiswal_A/0/1/0/all/0/1&quot;&gt;Ayush Jaiswal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+AbdAlmageed_W/0/1/0/all/0/1&quot;&gt;Wael AbdAlmageed&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wu_Y/0/1/0/all/0/1&quot;&gt;Yue Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Natarajan_P/0/1/0/all/0/1&quot;&gt;Premkumar Natarajan&lt;/a&gt;</dc:creator>
</item></rdf:RDF>