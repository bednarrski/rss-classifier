<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Good papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Good Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-04-22T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.07633"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.07663"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.07404"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.07464"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.07691"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1704.00045"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.06769"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.07353"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.07433"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.07481"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.07612"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.07645"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.07669"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.07729"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1702.07463"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.07944"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.06443"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.07068"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.06893"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1804.07633">
<title>A Simple Quantum Neural Net with a Periodic Activation Function. (arXiv:1804.07633v1 [quant-ph])</title>
<link>http://arxiv.org/abs/1804.07633</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we propose a simple neural net that requires only $O(nlog_2k)$
numbers of quantum gates and qubits: Here, $n$ is the number of input
parameters, and $k$ is the number of weights applied to these input parameters
in the proposed neural net. We describe the network in terms of a quantum
circuit, and then draw its equivalent classical neural net which involves
$O(k^n)$ nodes in the hidden layer. Then, we show that the network uses a
periodic activation function of cosine values of the linear combinations of the
inputs and weights. The steps of the gradient descent are described, and then
Iris and Breast cancer datasets are used for the numerical simulations. The
numerical results indicate the network can be used in machine learning problems
and it may provide exponential speedup over the same structured classical
neural net.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Daskin_A/0/1/0/all/0/1&quot;&gt;Ammar Daskin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.07663">
<title>An Investigation of Environmental Influence on the Benefits of Adaptation Mechanisms in Evolutionary Swarm Robotics. (arXiv:1804.07663v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1804.07663</link>
<description rdf:parseType="Literal">&lt;p&gt;A robotic swarm that is required to operate for long periods in a potentially
unknown environment can use both evolution and individual learning methods in
order to adapt. However, the role played by the environment in influencing the
effectiveness of each type of learning is not well understood. In this paper,
we address this question by analysing the performance of a swarm in a range of
simulated, dynamic environments where a distributed evolutionary algorithm for
evolving a controller is augmented with a number of different individual
learning mechanisms. The learning mechanisms themselves are defined by
parameters which can be either fixed or inherited. We conduct experiments in a
range of dynamic environments whose characteristics are varied so as to present
different opportunities for learning. Results enable us to map environmental
characteristics to the most effective learning algorithm.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Steyven_A/0/1/0/all/0/1&quot;&gt;Andreas Steyven&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hart_E/0/1/0/all/0/1&quot;&gt;Emma Hart&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Paechter_B/0/1/0/all/0/1&quot;&gt;Ben Paechter&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.07404">
<title>Preference-Guided Planning: An Active Elicitation Approach. (arXiv:1804.07404v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1804.07404</link>
<description rdf:parseType="Literal">&lt;p&gt;Planning with preferences has been employed extensively to quickly generate
high-quality plans. However, it may be difficult for the human expert to supply
this information without knowledge of the reasoning employed by the planner and
the distribution of planning problems. We consider the problem of actively
eliciting preferences from a human expert during the planning process.
Specifically, we study this problem in the context of the Hierarchical Task
Network (HTN) planning framework as it allows easy interaction with the human.
Our experimental results on several diverse planning domains show that the
preferences gathered using the proposed approach improve the quality and speed
of the planner, while reducing the burden on the human expert.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Das_M/0/1/0/all/0/1&quot;&gt;Mayukh Das&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Odom_P/0/1/0/all/0/1&quot;&gt;Phillip Odom&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Islam_M/0/1/0/all/0/1&quot;&gt;Md. Rakibul Islam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rao_J/0/1/0/all/0/1&quot;&gt;Janardhan Rao&lt;/a&gt; (Jana) &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Doppa/0/1/0/all/0/1&quot;&gt;Doppa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roth_D/0/1/0/all/0/1&quot;&gt;Dan Roth&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Natarajan_S/0/1/0/all/0/1&quot;&gt;Sriraam Natarajan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.07464">
<title>Delegating via Quitting Games. (arXiv:1804.07464v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1804.07464</link>
<description rdf:parseType="Literal">&lt;p&gt;Delegation allows an agent to request that another agent completes a task. In
many situations the task may be delegated onwards, and this process can repeat
until it is eventually, successfully or unsuccessfully, performed. We consider
policies to guide an agent in choosing who to delegate to when such recursive
interactions are possible. These policies, based on quitting games and
multi-armed bandits, were empirically tested for effectiveness. Our results
indicate that the quitting game based policies outperform those which do not
explicitly account for the recursive nature of delegation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Afanador_J/0/1/0/all/0/1&quot;&gt;Juan Afanador&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oren_N/0/1/0/all/0/1&quot;&gt;Nir Oren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Baptista_M/0/1/0/all/0/1&quot;&gt;Murilo S. Baptista&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.07691">
<title>Cross-domain Dialogue Policy Transfer via Simultaneous Speech-act and Slot Alignment. (arXiv:1804.07691v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1804.07691</link>
<description rdf:parseType="Literal">&lt;p&gt;Dialogue policy transfer enables us to build dialogue policies in a target
domain with little data by leveraging knowledge from a source domain with
plenty of data. Dialogue sentences are usually represented by speech-acts and
domain slots, and the dialogue policy transfer is usually achieved by assigning
a slot mapping matrix based on human heuristics. However, existing dialogue
policy transfer methods cannot transfer across dialogue domains with different
speech-acts, for example, between systems built by different companies. Also,
they depend on either common slots or slot entropy, which are not available
when the source and target slots are totally disjoint and no database is
available to calculate the slot entropy. To solve this problem, we propose a
Policy tRansfer across dOMaIns and SpEech-acts (PROMISE) model, which is able
to transfer dialogue policies across domains with different speech-acts and
disjoint slots. The PROMISE model can learn to align different speech-acts and
slots simultaneously, and it does not require common slots or the calculation
of the slot entropy. Experiments on both real-world dialogue data and
simulations demonstrate that PROMISE model can effectively transfer dialogue
policies across domains with different speech-acts and disjoint slots.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mo_K/0/1/0/all/0/1&quot;&gt;Kaixiang Mo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yu Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Q/0/1/0/all/0/1&quot;&gt;Qiang Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fung_P/0/1/0/all/0/1&quot;&gt;Pascale Fung&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1704.00045">
<title>Comparison of ontology alignment systems across single matching task via the McNemar&apos;s test. (arXiv:1704.00045v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1704.00045</link>
<description rdf:parseType="Literal">&lt;p&gt;Ontology alignment is widely-used to find the correspondences between
different ontologies in diverse fields.After discovering the alignments,several
performance scores are available to evaluate them.The scores typically require
the identified alignment and a reference containing the underlying actual
correspondences of the given ontologies.The current trend in the alignment
evaluation is to put forward a new score(e.g., precision, weighted precision,
etc.)and to compare various alignments by juxtaposing the obtained scores.
However,it is substantially provocative to select one measure among others for
comparison.On top of that, claiming if one system has a better performance than
one another cannot be substantiated solely by comparing two scalars.In this
paper,we propose the statistical procedures which enable us to theoretically
favor one system over one another.The McNemar&apos;s test is the statistical means
by which the comparison of two ontology alignment systems over one matching
task is drawn.The test applies to a 2x2 contingency table which can be
constructed in two different ways based on the alignments,each of which has
their own merits/pitfalls.The ways of the contingency table construction and
various apposite statistics from the McNemar&apos;s test are elaborated in minute
detail.In the case of having more than two alignment systems for comparison,
the family-wise error rate is expected to happen. Thus, the ways of preventing
such an error are also discussed.A directed graph visualizes the outcome of the
McNemar&apos;s test in the presence of multiple alignment systems.From this graph,
it is readily understood if one system is better than one another or if their
differences are imperceptible.The proposed statistical methodologies are
applied to the systems participated in the OAEI 2016 anatomy track, and also
compares several well-known similarity metrics for the same matching problem.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mohammadi_M/0/1/0/all/0/1&quot;&gt;Majid Mohammadi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Atashin_A/0/1/0/all/0/1&quot;&gt;Amir Ahooye Atashin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hofman_W/0/1/0/all/0/1&quot;&gt;Wout Hofman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tan_Y/0/1/0/all/0/1&quot;&gt;Yao-Hua Tan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.06769">
<title>CoNet: Collaborative Cross Networks for Cross-Domain Recommendation. (arXiv:1804.06769v2 [cs.IR] UPDATED)</title>
<link>http://arxiv.org/abs/1804.06769</link>
<description rdf:parseType="Literal">&lt;p&gt;The cross-domain recommendation technique is an effective way of alleviating
the data sparsity in recommender systems by leveraging the knowledge from
relevant domains. Transfer learning is a class of algorithms underlying these
techniques. In this paper, we propose a novel transfer learning approach for
cross-domain recommendation by using neural networks as the base model. We
assume that hidden layers in two base networks are connected by cross mappings,
leading to the collaborative cross networks (CoNet). CoNet enables dual
knowledge transfer across domains by introducing cross connections from one
base network to another and vice versa. CoNet is achieved in multi-layer
feedforward networks by adding dual connections and joint loss functions, which
can be trained efficiently by back-propagation. The proposed model is evaluated
on two real-world datasets and it outperforms baseline models by relative
improvements of 3.56\% in MRR and 8.94\% in NDCG, respectively.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_G/0/1/0/all/0/1&quot;&gt;Guangneng Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yu Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Q/0/1/0/all/0/1&quot;&gt;Qiang Yang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.07353">
<title>Unsupervised Representation Adversarial Learning Network: from Reconstruction to Generation. (arXiv:1804.07353v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1804.07353</link>
<description rdf:parseType="Literal">&lt;p&gt;A good representation for arbitrarily complicated data should have the
capability of semantic generation, clustering and reconstruction. Previous
research has already achieved impressive performance on either one. This paper
aims at learning a disentangled representation effective for all of them in an
unsupervised way. To achieve all the three tasks together, we learn the forward
and inverse mapping between data and representation on the basis of a symmetric
adversarial process. In theory, we minimize the upper bound of the two
conditional entropy loss between the latent variables and the observations
together to achieve the cycle consistency. The newly proposed RepGAN is tested
on MNIST, fashionMNIST, CelebA, and SVHN datasets to perform unsupervised or
semi-supervised classification, generation and reconstruction tasks. The result
demonstrates that RepGAN is able to learn a useful and competitive
representation. To the author&apos;s knowledge, our work is the first one to achieve
both a high unsupervised classification accuracy and low reconstruction error
on MNIST.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1&quot;&gt;Yuqian Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gu_K/0/1/0/all/0/1&quot;&gt;Kuangxiao Gu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_T/0/1/0/all/0/1&quot;&gt;Thomas Huang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.07433">
<title>Two Use Cases of Machine Learning for SDN-Enabled IP/Optical Networks: Traffic Matrix Prediction and Optical Path Performance Prediction. (arXiv:1804.07433v1 [cs.NI])</title>
<link>http://arxiv.org/abs/1804.07433</link>
<description rdf:parseType="Literal">&lt;p&gt;We describe two applications of machine learning in the context of IP/Optical
networks. The first one allows agile management of resources at a core
IP/Optical network by using machine learning for short-term and long-term
prediction of traffic flows and joint global optimization of IP and optical
layers using colorless/directionless (CD) flexible ROADMs. Multilayer
coordination allows for significant cost savings, flexible new services to meet
dynamic capacity needs, and improved robustness by being able to proactively
adapt to new traffic patterns and network conditions. The second application is
important as we migrate our metro networks to Open ROADM networks, to allow
physical routing without the need for detailed knowledge of optical parameters.
We discuss a proof-of-concept study, where detailed performance data for
wavelengths on a current flexible ROADM network is used for machine learning to
predict the optical performance of each wavelength. Both applications can be
efficiently implemented by using a SDN (Software Defined Network) controller.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Choudhury_G/0/1/0/all/0/1&quot;&gt;Gagan Choudhury&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lynch_D/0/1/0/all/0/1&quot;&gt;David Lynch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Thakur_G/0/1/0/all/0/1&quot;&gt;Gaurav Thakur&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tse_S/0/1/0/all/0/1&quot;&gt;Simon Tse&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.07481">
<title>Streaming Active Learning Strategies for Real-Life Credit Card Fraud Detection: Assessment and Visualization. (arXiv:1804.07481v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1804.07481</link>
<description rdf:parseType="Literal">&lt;p&gt;Credit card fraud detection is a very challenging problem because of the
specific nature of transaction data and the labeling process. The transaction
data is peculiar because they are obtained in a streaming fashion, they are
strongly imbalanced and prone to non-stationarity. The labeling is the outcome
of an active learning process, as every day human investigators contact only a
small number of cardholders (associated to the riskiest transactions) and
obtain the class (fraud or genuine) of the related transactions. An adequate
selection of the set of cardholders is therefore crucial for an efficient fraud
detection process. In this paper, we present a number of active learning
strategies and we investigate their fraud detection accuracies. We compare
different criteria (supervised, semi-supervised and unsupervised) to query
unlabeled transactions. Finally, we highlight the existence of an
exploitation/exploration trade-off for active learning in the context of fraud
detection, which has so far been overlooked in the literature.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Carcillo_F/0/1/0/all/0/1&quot;&gt;Fabirzio Carcillo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Borgne_Y/0/1/0/all/0/1&quot;&gt;Yann-A&amp;#xeb;l Le Borgne&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Caelen_O/0/1/0/all/0/1&quot;&gt;Olivier Caelen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bontempi_G/0/1/0/all/0/1&quot;&gt;Gianluca Bontempi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.07612">
<title>Revisiting Small Batch Training for Deep Neural Networks. (arXiv:1804.07612v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1804.07612</link>
<description rdf:parseType="Literal">&lt;p&gt;Modern deep neural network training is typically based on mini-batch
stochastic gradient optimization. While the use of large mini-batches increases
the available computational parallelism, small batch training has been shown to
provide improved generalization performance and allows a significantly smaller
memory footprint, which might also be exploited to improve machine throughput.
&lt;/p&gt;
&lt;p&gt;In this paper, we review common assumptions on learning rate scaling and
training duration, as a basis for an experimental comparison of test
performance for different mini-batch sizes. We adopt a learning rate that
corresponds to a constant average weight update per gradient calculation (i.e.,
per unit cost of computation), and point out that this results in a variance of
the weight updates that increases linearly with the mini-batch size $m$.
&lt;/p&gt;
&lt;p&gt;The collected experimental results for the CIFAR-10, CIFAR-100 and ImageNet
datasets show that increasing the mini-batch size progressively reduces the
range of learning rates that provide stable convergence and acceptable test
performance. On the other hand, small mini-batch sizes provide more up-to-date
gradient calculations, which yields more stable and reliable training. The best
performance has been consistently obtained for mini-batch sizes between $m = 2$
and $m = 32$, which contrasts with recent work advocating the use of mini-batch
sizes in the thousands.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Masters_D/0/1/0/all/0/1&quot;&gt;Dominic Masters&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luschi_C/0/1/0/all/0/1&quot;&gt;Carlo Luschi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.07645">
<title>One-Shot Learning using Mixture of Variational Autoencoders: a Generalization Learning approach. (arXiv:1804.07645v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1804.07645</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep learning, even if it is very successful nowadays, traditionally needs
very large amounts of labeled data to perform excellent on the classification
task. In an attempt to solve this problem, the one-shot learning paradigm,
which makes use of just one labeled sample per class and prior knowledge,
becomes increasingly important. In this paper, we propose a new one-shot
learning method, dubbed MoVAE (Mixture of Variational AutoEncoders), to perform
classification. Complementary to prior studies, MoVAE represents a shift of
paradigm in comparison with the usual one-shot learning methods, as it does not
use any prior knowledge. Instead, it starts from zero knowledge and one labeled
sample per class. Afterward, by using unlabeled data and the generalization
learning concept (in a way, more as humans do), it is capable to gradually
improve by itself its performance. Even more, if there are no unlabeled data
available MoVAE can still perform well in one-shot learning classification. We
demonstrate empirically the efficiency of our proposed approach on three
datasets, i.e. the handwritten digits (MNIST), fashion products
(Fashion-MNIST), and handwritten characters (Omniglot), showing that MoVAE
outperforms state-of-the-art one-shot learning algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mocanu_D/0/1/0/all/0/1&quot;&gt;Decebal Constantin Mocanu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mocanu_E/0/1/0/all/0/1&quot;&gt;Elena Mocanu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.07669">
<title>Modelling customer online behaviours with neural networks: applications to conversion prediction and advertising retargeting. (arXiv:1804.07669v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1804.07669</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we apply neural networks into digital marketing world for the
purpose of better targeting the potential customers. To do so, we model the
customer online behaviours using dedicated neural network architectures.
Starting from user searched keywords in a search engine to the landing page and
different following pages, until the user left the site, we model the whole
visited journey with a Recurrent Neural Network (RNN), together with
Convolution Neural Networks (CNN) that can take into account of the semantic
meaning of user searched keywords and different visited page names. With such
model, we use Monte Carlo simulation to estimate the conversion rates of each
potential customer in the future visiting. We believe our concept and the
preliminary promising results in this paper enable the use of largely available
customer online behaviours data for advanced digital marketing analysis.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cui_Y/0/1/0/all/0/1&quot;&gt;Yanwei Cui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tobossi_R/0/1/0/all/0/1&quot;&gt;Rogatien Tobossi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vigouroux_O/0/1/0/all/0/1&quot;&gt;Olivia Vigouroux&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.07729">
<title>ADef: an Iterative Algorithm to Construct Adversarial Deformations. (arXiv:1804.07729v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1804.07729</link>
<description rdf:parseType="Literal">&lt;p&gt;While deep neural networks have proven to be a powerful tool for many
recognition and classification tasks, their stability properties are still not
well understood. In the past, image classifiers have been shown to be
vulnerable to so-called adversarial attacks, which are created by additively
perturbing the correctly classified image.
&lt;/p&gt;
&lt;p&gt;In this paper, we propose the ADef algorithm to construct a different kind of
adversarial attack created by iteratively applying small deformations to the
image, found through a gradient descent step. We demonstrate our results on
MNIST with a convolutional neural network and on ImageNet with Inception-v3 and
ResNet-101.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alaifari_R/0/1/0/all/0/1&quot;&gt;Rima Alaifari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alberti_G/0/1/0/all/0/1&quot;&gt;Giovanni S. Alberti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gauksson_T/0/1/0/all/0/1&quot;&gt;Tandri Gauksson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1702.07463">
<title>Sequence Modeling via Segmentations. (arXiv:1702.07463v6 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1702.07463</link>
<description rdf:parseType="Literal">&lt;p&gt;Segmental structure is a common pattern in many types of sequences such as
phrases in human languages. In this paper, we present a probabilistic model for
sequences via their segmentations. The probability of a segmented sequence is
calculated as the product of the probabilities of all its segments, where each
segment is modeled using existing tools such as recurrent neural networks.
Since the segmentation of a sequence is usually unknown in advance, we sum over
all valid segmentations to obtain the final probability for the sequence. An
efficient dynamic programming algorithm is developed for forward and backward
computations without resorting to any approximation. We demonstrate our
approach on text segmentation and speech recognition tasks. In addition to
quantitative results, we also show that our approach can discover meaningful
segments in their respective application contexts.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wang_C/0/1/0/all/0/1&quot;&gt;Chong Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yining Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Huang_P/0/1/0/all/0/1&quot;&gt;Po-Sen Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mohamed_A/0/1/0/all/0/1&quot;&gt;Abdelrahman Mohamed&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhou_D/0/1/0/all/0/1&quot;&gt;Dengyong Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Deng_L/0/1/0/all/0/1&quot;&gt;Li Deng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.07944">
<title>MR Acquisition-Invariant Representation Learning. (arXiv:1709.07944v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1709.07944</link>
<description rdf:parseType="Literal">&lt;p&gt;Voxelwise classification approaches are popular and effective methods for
tissue quantification in brain magnetic resonance imaging (MRI) scans. However,
generalization of these approaches is hampered by large differences between
sets of MRI scans such as differences in field strength, vendor or acquisition
protocols. Due to this acquisition related variation, classifiers trained on
data from a specific scanner fail or under-perform when applied to data that
was acquired differently. In order to address this lack of generalization, we
propose a Siamese neural network (MRAI-net) to learn a representation that
minimizes the between-scanner variation, while maintaining the contrast between
brain tissues necessary for brain tissue quantification. The proposed MRAI-net
was evaluated on both simulated and real MRI data. After learning the MR
acquisition invariant representation, any supervised classification model that
uses feature vectors can be applied. In this paper, we provide a proof of
principle, which shows that a linear classifier applied on the MRAI
representation is able to outperform supervised convolutional neural network
classifiers for tissue classification when little target training data is
available.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kouw_W/0/1/0/all/0/1&quot;&gt;Wouter M. Kouw&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Loog_M/0/1/0/all/0/1&quot;&gt;Marco Loog&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bartels_L/0/1/0/all/0/1&quot;&gt;Lambertus W. Bartels&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mendrik_A/0/1/0/all/0/1&quot;&gt;Adri&amp;#xeb;nne M. Mendrik&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.06443">
<title>Decentralization Meets Quantization. (arXiv:1803.06443v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1803.06443</link>
<description rdf:parseType="Literal">&lt;p&gt;Optimizing distributed learning systems is an art of balancing between
computation and communication. There have been two lines of research that try
to deal with slower networks: {\em quantization} for low bandwidth networks,
and {\em decentralization} for high latency networks. In this paper, we explore
a natural question: {\em can the combination of both decentralization and
quantization lead to a system that is robust to both bandwidth and latency?}
&lt;/p&gt;
&lt;p&gt;Although the system implication of such combination is trivial, the
underlying theoretical principle and algorithm design is challenging: simply
quantizing data sent in a decentralized training algorithm would accumulate the
error. In this paper, we develop a framework of quantized, decentralized
training and propose two different strategies, which we call {\em extrapolation
compression} and {\em difference compression}. We analyze both algorithms and
prove both converge at the rate of $O(1/\sqrt{nT})$ where $n$ is the number of
workers and $T$ is the number of iterations, matching the {\rc convergence}
rate for full precision, centralized training. We evaluate our algorithms on
training deep learning models, and find that our proposed algorithm outperforms
the best of merely decentralized and merely quantized algorithm significantly
for networks with {\em both} high latency and low bandwidth.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_H/0/1/0/all/0/1&quot;&gt;Hanlin Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1&quot;&gt;Ce Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gan_S/0/1/0/all/0/1&quot;&gt;Shaoduo Gan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1&quot;&gt;Tong Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Ji Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.07068">
<title>D$^2$: Decentralized Training over Decentralized Data. (arXiv:1803.07068v2 [cs.DC] UPDATED)</title>
<link>http://arxiv.org/abs/1803.07068</link>
<description rdf:parseType="Literal">&lt;p&gt;While training a machine learning model using multiple workers, each of which
collects data from their own data sources, it would be most useful when the
data collected from different workers can be {\em unique} and {\em different}.
Ironically, recent analysis of decentralized parallel stochastic gradient
descent (D-PSGD) relies on the assumption that the data hosted on different
workers are {\em not too different}. In this paper, we ask the question: {\em
Can we design a decentralized parallel stochastic gradient descent algorithm
that is less sensitive to the data variance across workers?} In this paper, we
present D$^2$, a novel decentralized parallel stochastic gradient descent
algorithm designed for large data variance \xr{among workers} (imprecisely,
&quot;decentralized&quot; data). The core of D$^2$ is a variance blackuction extension of
the standard D-PSGD algorithm, which improves the convergence rate from
$O\left({\sigma \over \sqrt{nT}} + {(n\zeta^2)^{\frac{1}{3}} \over
T^{2/3}}\right)$ to $O\left({\sigma \over \sqrt{nT}}\right)$ where $\zeta^{2}$
denotes the variance among data on different workers. As a result, D$^2$ is
robust to data variance among workers. We empirically evaluated D$^2$ on image
classification tasks where each worker has access to only the data of a limited
set of labels, and find that D$^2$ significantly outperforms D-PSGD.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_H/0/1/0/all/0/1&quot;&gt;Hanlin Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lian_X/0/1/0/all/0/1&quot;&gt;Xiangru Lian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yan_M/0/1/0/all/0/1&quot;&gt;Ming Yan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1&quot;&gt;Ce Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Ji Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.06893">
<title>A Study on Overfitting in Deep Reinforcement Learning. (arXiv:1804.06893v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1804.06893</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent years have witnessed significant progresses in deep Reinforcement
Learning (RL). Empowered with large scale neural networks, carefully designed
architectures, novel training algorithms and massively parallel computing
devices, researchers are able to attack many challenging RL problems. However,
in machine learning, more training power comes with a potential risk of more
overfitting. As deep RL techniques are being applied to critical problems such
as healthcare and finance, it is important to understand the generalization
behaviors of the trained agents. In this paper, we conduct a systematic study
of standard RL agents and find that they could overfit in various ways.
Moreover, overfitting could happen &quot;robustly&quot;: commonly used techniques in RL
that add stochasticity do not necessarily prevent or detect overfitting. In
particular, the same agents and learning algorithms could have drastically
different test performance, even when all of them achieve optimal rewards
during training. The observations call for more principled and careful
evaluation protocols in RL. We conclude with a general discussion on
overfitting in RL and a study of the generalization behaviors from the
perspective of inductive bias.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1&quot;&gt;Chiyuan Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vinyals_O/0/1/0/all/0/1&quot;&gt;Oriol Vinyals&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Munos_R/0/1/0/all/0/1&quot;&gt;Remi Munos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bengio_S/0/1/0/all/0/1&quot;&gt;Samy Bengio&lt;/a&gt;</dc:creator>
</item></rdf:RDF>