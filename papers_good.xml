<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Good papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Good Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-05-29T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11144"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11236"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11359"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11604"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05405"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10255"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11090"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11154"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11199"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11234"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11350"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11546"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09496"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11195"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11202"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11222"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11233"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11240"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11317"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11327"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11365"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11380"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11386"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11504"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11505"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11565"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11614"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1705.09847"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.01421"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.03605"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10265"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10369"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1805.11144">
<title>NengoDL: Combining deep learning and neuromorphic modelling methods. (arXiv:1805.11144v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1805.11144</link>
<description rdf:parseType="Literal">&lt;p&gt;NengoDL is a software framework designed to combine the strengths of
neuromorphic modelling and deep learning. NengoDL allows users to construct
biologically detailed neural models, intermix those models with deep learning
elements (such as convolutional networks), and then efficiently simulate those
models in an easy-to-use, unified framework. In addition, NengoDL allows users
to apply deep learning training methods to optimize the parameters of
biological neural models. In this paper we present basic usage examples,
benchmarking, and details on the key implementation elements of NengoDL. More
details can be found at https://www.nengo.ai/nengo-dl.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rasmussen_D/0/1/0/all/0/1&quot;&gt;Daniel Rasmussen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11236">
<title>Review of Applications of Generalized Regression Neural Networks in Identification and Control of Dynamic Systems. (arXiv:1805.11236v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1805.11236</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper depicts a brief revision of Generalized Regression Neural Networks
(GRNN) applications in system identification and control of dynamic systems. In
addition, a comparison study between the performance of back-propagation neural
networks and GRNN is presented for system identification problems. The results
of the comparison confirm that GRNN has shorter training time and higher
accuracy than the counterpart back-propagation neural networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Al_Mahasneh_A/0/1/0/all/0/1&quot;&gt;Ahmad Jobran Al-Mahasneh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Anavatti_S/0/1/0/all/0/1&quot;&gt;Sreenatha G. Anavatti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garratt_M/0/1/0/all/0/1&quot;&gt;Matthew A. Garratt&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11359">
<title>Properties of interaction networks, structure coefficients, and benefit-to-cost ratios. (arXiv:1805.11359v1 [q-bio.PE])</title>
<link>http://arxiv.org/abs/1805.11359</link>
<description rdf:parseType="Literal">&lt;p&gt;In structured populations the spatial arrangement of cooperators and
defectors on the interaction graph together with the structure of the graph
itself determines the game dynamics and particularly whether or not fixation of
cooperation (or defection) is favored. For a single cooperator (or a single
defector) and a network described by a regular graph the question of fixation
can be addressed by a single parameter, the structure coefficient. As this
quantity is generic to any regular graph, we may call it the generic structure
coefficient. For two and more cooperators (or several defectors) fixation
properties can also be assigned by structure coefficients. These structure
coefficients, however, depend on the arrangement of cooperators and defectors
which we interpret as a configuration of the game. Moreover, the coefficients
are specific to a given interaction network modeled as regular graph, which is
why we may call them specific structure coefficients. In this paper, we study
how specific structure coefficients vary over interaction graphs and link the
distributions obtained over different graphs to spectral properties of
interaction networks. We also discuss implications for the benefit-to-cost
ratios of donation games.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Richter_H/0/1/0/all/0/1&quot;&gt;Hendrik Richter&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11604">
<title>How Does Batch Normalization Help Optimization? (No, It Is Not About Internal Covariate Shift). (arXiv:1805.11604v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.11604</link>
<description rdf:parseType="Literal">&lt;p&gt;Batch Normalization (BatchNorm) is a widely adopted technique that enables
faster and more stable training of deep neural networks (DNNs). Despite its
pervasiveness, the exact reasons for BatchNorm&apos;s effectiveness are still poorly
understood. The popular belief is that this effectiveness stems from
controlling the change of the layers&apos; input distributions during training to
reduce the so-called &quot;internal covariate shift&quot;. In this work, we demonstrate
that such distributional stability of layer inputs has little to do with the
success of BatchNorm. Instead, we uncover a more fundamental impact of
BatchNorm on the training process: it makes the optimization landscape
significantly smoother. This smoothness induces a more predictive and stable
behavior of the gradients, allowing for faster training. These findings bring
us closer to a true understanding of our DNN training toolkit.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Santurkar_S/0/1/0/all/0/1&quot;&gt;Shibani Santurkar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tsipras_D/0/1/0/all/0/1&quot;&gt;Dimitris Tsipras&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ilyas_A/0/1/0/all/0/1&quot;&gt;Andrew Ilyas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Madry_A/0/1/0/all/0/1&quot;&gt;Aleksander Madry&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05405">
<title>Putting a bug in ML: The moth olfactory network learns to read MNIST. (arXiv:1802.05405v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1802.05405</link>
<description rdf:parseType="Literal">&lt;p&gt;We seek to (i) characterize the learning architectures exploited in
biological neural networks for training on very few samples, and (ii) port
these algorithmic structures to a machine learning context. The Moth Olfactory
Network is among the simplest biological neural systems that can learn, and its
architecture includes key structural elements widespread in biological neural
nets, such as cascaded networks, competitive inhibition, high intrinsic noise,
sparsity, reward mechanisms, and Hebbian plasticity. The interactions of these
structural elements play a critical enabling role in rapid learning.
&lt;/p&gt;
&lt;p&gt;We assign a computational model of the Moth Olfactory Network the task of
learning to read the MNIST digits. This model, MothNet, is closely aligned with
the moth&apos;s known biophysics and with in vivo electrode data, including data
collected from moths learning new odors. We show that MothNet successfully
learns to read given very few training samples (1 to 20 samples per class). In
this few-samples regime, it substantially outperforms standard machine learning
methods such as nearest-neighbors, support-vector machines, and convolutional
neural networks (CNNs). The MothNet architecture illustrates how our proposed
algorithmic structures, derived from biological brains, can be used to build
alternative deep neural nets (DNNs) that may potentially avoid some of DNNs
current learning rate limitations. This novel, bio-inspired neural network
architecture offers a valuable complementary approach to DNN design.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Delahunt_C/0/1/0/all/0/1&quot;&gt;Charles B. Delahunt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kutz_J/0/1/0/all/0/1&quot;&gt;J. Nathan Kutz&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.10255">
<title>Parallel Architecture and Hyperparameter Search via Successive Halving and Classification. (arXiv:1805.10255v1 [cs.CV] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1805.10255</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a simple and powerful algorithm for parallel black box
optimization called Successive Halving and Classification (SHAC). The algorithm
operates in $K$ stages of parallel function evaluations and trains a cascade of
binary classifiers to iteratively cull the undesirable regions of the search
space. SHAC is easy to implement, requires no tuning of its own configuration
parameters, is invariant to the scale of the objective function and can be
built using any choice of binary classifier. We adopt tree-based classifiers
within SHAC and achieve competitive performance against several strong
baselines for optimizing synthetic functions, hyperparameters and
architectures.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kumar_M/0/1/0/all/0/1&quot;&gt;Manoj Kumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dahl_G/0/1/0/all/0/1&quot;&gt;George E. Dahl&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vasudevan_V/0/1/0/all/0/1&quot;&gt;Vijay Vasudevan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Norouzi_M/0/1/0/all/0/1&quot;&gt;Mohammad Norouzi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11090">
<title>GenAttack: Practical Black-box Attacks with Gradient-Free Optimization. (arXiv:1805.11090v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.11090</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep neural networks (DNNs) are vulnerable to adversarial examples, even in
the black-box case, where the attacker is limited to solely query access.
Existing blackbox approaches to generating adversarial examples typically
require a significant amount of queries, either for training a substitute
network or estimating gradients from the output scores. We introduce GenAttack,
a gradient-free optimization technique which uses genetic algorithms for
synthesizing adversarial examples in the black-box setting. Our experiments on
the MNIST, CIFAR-10, and ImageNet datasets show that GenAttack can successfully
generate visually imperceptible adversarial examples against state-of-the-art
image recognition models with orders of magnitude fewer queries than existing
approaches. For example, in our CIFAR-10 experiments, GenAttack required
roughly 2,568 times less queries than the current state-of-the-art black-box
attack. Furthermore, we show that GenAttack can successfully attack both the
state-of-the-art ImageNet defense, ensemble adversarial training, and
non-differentiable, randomized input transformation defenses. GenAttack&apos;s
success against ensemble adversarial training demonstrates that its query
efficiency enables it to exploit the defense&apos;s weakness to direct black-box
attacks. GenAttack&apos;s success against non-differentiable input transformations
indicates that its gradient-free nature enables it to be applicable against
defenses which perform gradient masking/obfuscation to confuse the attacker.
Our results suggest that population-based optimization opens up a promising
area of research into effective gradient-free black-box attacks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alzantot_M/0/1/0/all/0/1&quot;&gt;Moustafa Alzantot&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sharma_Y/0/1/0/all/0/1&quot;&gt;Yash Sharma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chakraborty_S/0/1/0/all/0/1&quot;&gt;Supriyo Chakraborty&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Srivastava_M/0/1/0/all/0/1&quot;&gt;Mani Srivastava&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11154">
<title>Refining Source Representations with Relation Networks for Neural Machine Translation. (arXiv:1805.11154v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1805.11154</link>
<description rdf:parseType="Literal">&lt;p&gt;Although neural machine translation (NMT) with the encoder-decoder framework
has achieved great success in recent times, it still suffers from some
drawbacks: RNNs tend to forget old information which is often useful in the
current step and the encoder only operates over words without considering word
relationship. To solve these problems, we introduce relation networks (RNs) to
learn better representations of the source. In our method RNs are used to
associate source words with each other so that the source representation can
memorize all the source words and also contain the relationship between them.
Then the source representations and all the relations are fed into the
attention component together while decoding, with the main encoder-decoder
architecture unchanged. Experiments on several data sets show that our method
can improve the translation performance significantly over the conventional
encoder-decoder model, and can even outperform the approach involving
supervised syntactic knowledge.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1&quot;&gt;Wen Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_J/0/1/0/all/0/1&quot;&gt;Jiawei Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1&quot;&gt;Yang Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1&quot;&gt;Qun Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11199">
<title>Value Propagation Networks. (arXiv:1805.11199v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1805.11199</link>
<description rdf:parseType="Literal">&lt;p&gt;We present Value Propagation (VProp), a parameter-efficient differentiable
planning module built on Value Iteration which can successfully be trained
using reinforcement learning to solve unseen tasks, has the capability to
generalize to larger map sizes, and can learn to navigate in dynamic
environments. Furthermore, we show that the module enables learning to plan
when the environment also includes stochastic elements, providing a
cost-efficient learning system to build low-level size-invariant planners for a
variety of interactive navigation problems. We evaluate on static and dynamic
configurations of MazeBase grid-worlds, with randomly generated environments of
several different sizes, and on a StarCraft navigation scenario, with more
complex dynamics, and pixels as input.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nardelli_N/0/1/0/all/0/1&quot;&gt;Nantas Nardelli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Synnaeve_G/0/1/0/all/0/1&quot;&gt;Gabriel Synnaeve&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1&quot;&gt;Zeming Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kohli_P/0/1/0/all/0/1&quot;&gt;Pushmeet Kohli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Torr_P/0/1/0/all/0/1&quot;&gt;Philip H. S. Torr&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Usunier_N/0/1/0/all/0/1&quot;&gt;Nicolas Usunier&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11234">
<title>Table-to-Text: Describing Table Region with Natural Language. (arXiv:1805.11234v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1805.11234</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we present a generative model to generate a natural language
sentence describing a table region, e.g., a row. The model maps a row from a
table to a continuous vector and then generates a natural language sentence by
leveraging the semantics of a table. To deal with rare words appearing in a
table, we develop a flexible copying mechanism that selectively replicates
contents from the table in the output sequence. Extensive experiments
demonstrate the accuracy of the model and the power of the copying mechanism.
On two synthetic datasets, WIKIBIO and SIMPLEQUESTIONS, our model improves the
current state-of-the-art BLEU-4 score from 34.70 to 40.26 and from 33.32 to
39.12, respectively. Furthermore, we introduce an open-domain dataset
WIKITABLETEXT including 13,318 explanatory sentences for 4,962 tables. Our
model achieves a BLEU-4 score of 38.23, which outperforms template based and
language model based approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bao_J/0/1/0/all/0/1&quot;&gt;Junwei Bao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_D/0/1/0/all/0/1&quot;&gt;Duyu Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Duan_N/0/1/0/all/0/1&quot;&gt;Nan Duan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yan_Z/0/1/0/all/0/1&quot;&gt;Zhao Yan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lv_Y/0/1/0/all/0/1&quot;&gt;Yuanhua Lv&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1&quot;&gt;Ming Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_T/0/1/0/all/0/1&quot;&gt;Tiejun Zhao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11350">
<title>Fully Statistical Neural Belief Tracking. (arXiv:1805.11350v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1805.11350</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper proposes an improvement to the existing data-driven Neural Belief
Tracking (NBT) framework for Dialogue State Tracking (DST). The existing NBT
model uses a hand-crafted belief state update mechanism which involves an
expensive manual retuning step whenever the model is deployed to a new dialogue
domain. We show that this update mechanism can be learned jointly with the
semantic decoding and context modelling parts of the NBT model, eliminating the
last rule-based module from this DST framework. We propose two different
statistical update mechanisms and show that dialogue dynamics can be modelled
with a very small number of additional model parameters. In our DST evaluation
over three languages, we show that this model achieves competitive performance
and provides a robust framework for building resource-light DST models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mrksic_N/0/1/0/all/0/1&quot;&gt;Nikola Mrk&amp;#x161;i&amp;#x107;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vulic_I/0/1/0/all/0/1&quot;&gt;Ivan Vuli&amp;#x107;&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11546">
<title>Visually Grounded, Situated Learning in Neural Models. (arXiv:1805.11546v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1805.11546</link>
<description rdf:parseType="Literal">&lt;p&gt;The theory of situated cognition postulates that language is inseparable from
its physical context--words, phrases, and sentences must be learned in the
context of the objects or concepts to which they refer. Yet, statistical
language models are trained on words alone. This makes it impossible for
language models to connect to the real world--the world described in the
sentences presented to the model. In this paper, we examine the generalization
ability of neural language models trained with a visual context. A multimodal
connectionist language architecture based on the Differential State Framework
is proposed, which outperforms its equivalent trained on language alone, even
when no visual context is available at test time. Superior performance for
language models trained with a visual context is robust across different
languages and models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ororbia_A/0/1/0/all/0/1&quot;&gt;Alexander G. Ororbia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mali_A/0/1/0/all/0/1&quot;&gt;Ankur Mali&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kelly_M/0/1/0/all/0/1&quot;&gt;Matthew A. Kelly&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Reitter_D/0/1/0/all/0/1&quot;&gt;David Reitter&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09496">
<title>Intelligent Trainer for Model-Based Reinforcement Learning. (arXiv:1805.09496v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.09496</link>
<description rdf:parseType="Literal">&lt;p&gt;Model-based deep reinforcement learning (DRL) algorithm uses the sampled data
from a real environment to learn the underlying system dynamics to construct an
approximate cyber environment. By using the synthesized data generated from the
cyber environment to train the target controller, the training cost can be
reduced significantly. In current research, issues such as the applicability of
approximate model and the strategy to sample and train from the real and cyber
environment have not been fully investigated. To address these issues, we
propose to utilize an intelligent trainer to properly use the approximate model
and control the sampling and training procedure in the model-based DRL. To do
so, we package the training process of a model-based DRL as a standard RL
environment, and design an RL trainer to control the training process. The
trainer has three control actions: the first action controls where to sample in
the real and cyber environment; the second action determines how many data
should be sampled from the cyber environment and the third action controls how
many times the cyber data should be used to train the target controller. These
actions would be controlled manually if without the trainer. The proposed
framework is evaluated on five different tasks of OpenAI gym and the test
results show that the proposed trainer achieves significant better performance
than a fixed parameter model-based RL baseline algorithm. In addition, we
compare the performance of the intelligent trainer to a random trainer and
prove that the intelligent trainer can indeed learn on the fly. The proposed
training framework can be extended to more control actions with more
sophisticated trainer design to further reduce the tweak cost of model-based RL
algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yuanlong Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dong_L/0/1/0/all/0/1&quot;&gt;Linsen Dong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wen_Y/0/1/0/all/0/1&quot;&gt;Yonggang Wen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guan_K/0/1/0/all/0/1&quot;&gt;Kyle Guan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11195">
<title>CapsNet comparative performance evaluation for image classification. (arXiv:1805.11195v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1805.11195</link>
<description rdf:parseType="Literal">&lt;p&gt;Image classification has become one of the main tasks in the field of
computer vision technologies. In this context, a recent algorithm called
CapsNet that implements an approach based on activity vectors and dynamic
routing between capsules may overcome some of the limitations of the current
state of the art artificial neural networks (ANN) classifiers, such as
convolutional neural networks (CNN). In this paper, we evaluated the
performance of the CapsNet algorithm in comparison with three well-known
classifiers (Fisher-faces, LeNet, and ResNet). We tested the classification
accuracy on four datasets with a different number of instances and classes,
including images of faces, traffic signs, and everyday objects. The evaluation
results show that even for simple architectures, training the CapsNet algorithm
requires significant computational resources and its classification performance
falls below the average accuracy values of the other three classifiers.
However, we argue that CapsNet seems to be a promising new technique for image
classification, and further experiments using more robust computation resources
and re-fined CapsNet architectures may produce better outcomes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mukhometzianov_R/0/1/0/all/0/1&quot;&gt;Rinat Mukhometzianov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Carrillo_J/0/1/0/all/0/1&quot;&gt;Juan Carrillo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11202">
<title>FairGAN: Fairness-aware Generative Adversarial Networks. (arXiv:1805.11202v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.11202</link>
<description rdf:parseType="Literal">&lt;p&gt;Fairness-aware learning is increasingly important in data mining.
Discrimination prevention aims to prevent discrimination in the training data
before it is used to conduct predictive analysis. In this paper, we focus on
fair data generation that ensures the generated data is discrimination free.
Inspired by generative adversarial networks (GAN), we present fairness-aware
generative adversarial networks, called FairGAN, which are able to learn a
generator producing fair data and also preserving good data utility. Compared
with the naive fair data generation models, FairGAN further ensures the
classifiers which are trained on generated data can achieve fair classification
on real data. Experiments on a real dataset show the effectiveness of FairGAN.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_D/0/1/0/all/0/1&quot;&gt;Depeng Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yuan_S/0/1/0/all/0/1&quot;&gt;Shuhan Yuan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1&quot;&gt;Lu Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_X/0/1/0/all/0/1&quot;&gt;Xintao Wu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11222">
<title>Unsupervised Alignment of Embeddings with Wasserstein Procrustes. (arXiv:1805.11222v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.11222</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the task of aligning two sets of points in high dimension, which
has many applications in natural language processing and computer vision. As an
example, it was recently shown that it is possible to infer a bilingual
lexicon, without supervised data, by aligning word embeddings trained on
monolingual data. These recent advances are based on adversarial training to
learn the mapping between the two embeddings. In this paper, we propose to use
an alternative formulation, based on the joint estimation of an orthogonal
matrix and a permutation matrix. While this problem is not convex, we propose
to initialize our optimization algorithm by using a convex relaxation,
traditionally considered for the graph isomorphism problem. We propose a
stochastic algorithm to minimize our cost function on large scale problems.
Finally, we evaluate our method on the problem of unsupervised word
translation, by aligning word embeddings trained on monolingual data. On this
task, our method obtains state of the art results, while requiring less
computational resources than competing approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grave_E/0/1/0/all/0/1&quot;&gt;Edouard Grave&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Joulin_A/0/1/0/all/0/1&quot;&gt;Armand Joulin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Berthet_Q/0/1/0/all/0/1&quot;&gt;Quentin Berthet&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11233">
<title>Retraining-Based Iterative Weight Quantization for Deep Neural Networks. (arXiv:1805.11233v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.11233</link>
<description rdf:parseType="Literal">&lt;p&gt;Model compression has gained a lot of attention due to its ability to reduce
hardware resource requirements significantly while maintaining accuracy of
DNNs. Model compression is especially useful for memory-intensive recurrent
neural networks because smaller memory footprint is crucial not only for
reducing storage requirement but also for fast inference operations.
Quantization is known to be an effective model compression method and
researchers are interested in minimizing the number of bits to represent
parameters. In this work, we introduce an iterative technique to apply
quantization, presenting high compression ratio without any modifications to
the training algorithm. In the proposed technique, weight quantization is
followed by retraining the model with full precision weights. We show that
iterative retraining generates new sets of weights which can be quantized with
decreasing quantization loss at each iteration. We also show that quantization
is efficiently able to leverage pruning, another effective model compression
method. Implementation issues on combining the two methods are also addressed.
Our experimental results demonstrate that an LSTM model using 1-bit quantized
weights is sufficient for PTB dataset without any accuracy degradation while
previous methods demand at least 2-4 bits for quantized weights.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1&quot;&gt;Dongsoo Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_B/0/1/0/all/0/1&quot;&gt;Byeongwook Kim&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11240">
<title>Truncated Horizon Policy Search: Combining Reinforcement Learning &amp; Imitation Learning. (arXiv:1805.11240v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.11240</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we propose to combine imitation and reinforcement learning via
the idea of reward shaping using an oracle. We study the effectiveness of the
near-optimal cost-to-go oracle on the planning horizon and demonstrate that the
cost-to-go oracle shortens the learner&apos;s planning horizon as function of its
accuracy: a globally optimal oracle can shorten the planning horizon to one,
leading to a one-step greedy Markov Decision Process which is much easier to
optimize, while an oracle that is far away from the optimality requires
planning over a longer horizon to achieve near-optimal performance. Hence our
new insight bridges the gap and interpolates between imitation learning and
reinforcement learning. Motivated by the above mentioned insights, we propose
Truncated HORizon Policy Search (THOR), a method that focuses on searching for
policies that maximize the total reshaped reward over a finite planning horizon
when the oracle is sub-optimal. We experimentally demonstrate that a
gradient-based implementation of THOR can achieve superior performance compared
to RL baselines and IL baselines even when the oracle is sub-optimal.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_W/0/1/0/all/0/1&quot;&gt;Wen Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bagnell_J/0/1/0/all/0/1&quot;&gt;J. Andrew Bagnell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Boots_B/0/1/0/all/0/1&quot;&gt;Byron Boots&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11317">
<title>Neural networks for stock price prediction. (arXiv:1805.11317v1 [q-fin.ST])</title>
<link>http://arxiv.org/abs/1805.11317</link>
<description rdf:parseType="Literal">&lt;p&gt;Due to the extremely volatile nature of financial markets, it is commonly
accepted that stock price prediction is a task full of challenge. However in
order to make profits or understand the essence of equity market, numerous
market participants or researchers try to forecast stock price using various
statistical, econometric or even neural network models. In this work, we survey
and compare the predictive power of five neural network models, namely, back
propagation (BP) neural network, radial basis function (RBF) neural network,
general regression neural network (GRNN), support vector machine regression
(SVMR), least squares support vector machine regresssion (LS-SVMR). We apply
the five models to make price prediction of three individual stocks, namely,
Bank of China, Vanke A and Kweichou Moutai. Adopting mean square error and
average absolute percentage error as criteria, we find BP neural network
consistently and robustly outperforms the other four models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-fin/1/au:+Song_Y/0/1/0/all/0/1&quot;&gt;Yue-Gang Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-fin/1/au:+Zhou_Y/0/1/0/all/0/1&quot;&gt;Yu-Long Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-fin/1/au:+Han_R/0/1/0/all/0/1&quot;&gt;Ren-Jie Han&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11327">
<title>Lightweight Probabilistic Deep Networks. (arXiv:1805.11327v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1805.11327</link>
<description rdf:parseType="Literal">&lt;p&gt;Even though probabilistic treatments of neural networks have a long history,
they have not found widespread use in practice. Sampling approaches are often
too slow already for simple networks. The size of the inputs and the depth of
typical CNN architectures in computer vision only compound this problem.
Uncertainty in neural networks has thus been largely ignored in practice,
despite the fact that it may provide important information about the
reliability of predictions and the inner workings of the network. In this
paper, we introduce two lightweight approaches to making supervised learning
with probabilistic deep networks practical: First, we suggest probabilistic
output layers for classification and regression that require only minimal
changes to existing networks. Second, we employ assumed density filtering and
show that activation uncertainties can be propagated in a practical fashion
through the entire network, again with minor changes. Both probabilistic
networks retain the predictive power of the deterministic counterpart, but
yield uncertainties that correlate well with the empirical error induced by
their predictions. Moreover, the robustness to adversarial examples is
significantly increased.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gast_J/0/1/0/all/0/1&quot;&gt;Jochen Gast&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roth_S/0/1/0/all/0/1&quot;&gt;Stefan Roth&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11365">
<title>Lovasz Convolutional Networks. (arXiv:1805.11365v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.11365</link>
<description rdf:parseType="Literal">&lt;p&gt;Semi-supervised learning on graph structured data has received significant
attention with the recent introduction of graph convolution networks (GCN).
While traditional methods have focused on optimizing a loss augmented with
Laplacian regularization framework, GCNs perform an implicit Laplacian type
regularization to capture local graph structure. In this work, we propose
Lovasz convolutional network (LCNs) which are capable of incorporating global
graph properties. LCNs achieve this by utilizing Lovasz&apos;s orthonormal
embeddings of the nodes. We analyse local and global properties of graphs and
demonstrate settings where LCNs tend to work better than GCNs. We validate the
proposed method on standard random graph models such as stochastic block models
(SBM) and certain community structure based graphs where LCNs outperform GCNs
and learn more intuitive embeddings. We also perform extensive binary and
multi-class classification experiments on real world datasets to demonstrate
LCN&apos;s effectiveness. In addition to simple graphs, we also demonstrate the use
of LCNs on hypergraphs by identifying settings where they are expected to work
better than GCNs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yadav_P/0/1/0/all/0/1&quot;&gt;Prateek Yadav&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nimishakavi_M/0/1/0/all/0/1&quot;&gt;Madhav Nimishakavi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yadati_N/0/1/0/all/0/1&quot;&gt;Naganand Yadati&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rajkumar_A/0/1/0/all/0/1&quot;&gt;Arun Rajkumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Talukdar_P/0/1/0/all/0/1&quot;&gt;Partha Talukdar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11380">
<title>Kernel embedding of maps for sequential Bayesian inference: The variational mapping particle filter. (arXiv:1805.11380v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.11380</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work, a novel sequential Monte Carlo filter is introduced which aims
at efficient sampling of high-dimensional state spaces with a limited number of
particles. Particles are pushed forward from the prior to the posterior density
using a sequence of mappings that minimizes the Kullback-Leibler divergence
between the posterior and the sequence of intermediate densities. The sequence
of mappings represents a gradient flow. A key ingredient of the mappings is
that they are embedded in a reproducing kernel Hilbert space, which allows for
a practical and efficient algorithm. The embedding provides a direct means to
calculate the gradient of the Kullback-Leibler divergence leading to quick
convergence using well-known gradient-based stochastic optimization algorithms.
Evaluation of the method is conducted in the chaotic Lorenz-63 system, the
Lorenz-96 system, which is a coarse prototype of atmospheric dynamics, and an
epidemic model that describes cholera dynamics. No resampling is required in
the mapping particle filter even for long recursive sequences. The number of
effective particles remains close to the total number of particles in all the
experiments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pulido_M/0/1/0/all/0/1&quot;&gt;Manuel Pulido&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+vanLeeuwen_P/0/1/0/all/0/1&quot;&gt;Peter Jan vanLeeuwen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11386">
<title>Uniform regret bounds over $R^d$ for the sequential linear regression problem with the square loss. (arXiv:1805.11386v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.11386</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the setting of online linear regression for arbitrary
deterministic sequences, with the square loss. We are interested in regret
bounds that hold uniformly over all vectors in $u $\in$ R^d$. Vovk (2001)
showed a d ln T lower bound on this uniform regret. We exhibit forecasters with
closed-form regret bounds that match this d ln T quantity. To the best of our
knowledge, earlier works only provided closed-form regret bounds of 2d ln T +
O(1).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gaillard_P/0/1/0/all/0/1&quot;&gt;Pierre Gaillard&lt;/a&gt; (SIERRA), &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gerchinovitz_S/0/1/0/all/0/1&quot;&gt;S&amp;#xe9;bastien Gerchinovitz&lt;/a&gt; (IMT), &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Huard_M/0/1/0/all/0/1&quot;&gt;Malo Huard&lt;/a&gt; (LMO), &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Stoltz_G/0/1/0/all/0/1&quot;&gt;Gilles Stoltz&lt;/a&gt; (LMO)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11504">
<title>Capturing Variabilities from Computed Tomography Images with Generative Adversarial Networks. (arXiv:1805.11504v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1805.11504</link>
<description rdf:parseType="Literal">&lt;p&gt;With the advent of Deep Learning (DL) techniques, especially Generative
Adversarial Networks (GANs), data augmentation and generation are quickly
evolving domains that have raised much interest recently. However, the DL
techniques are data demanding and since, medical data is not easily accessible,
they suffer from data insufficiency. To deal with this limitation, different
data augmentation techniques are used. Here, we propose a novel unsupervised
data-driven approach for data augmentation that can generate 2D Computed
Tomography (CT) images using a simple GAN. The generated CT images have good
global and local features of a real CT image and can be used to augment the
training datasets for effective learning. In this proof-of-concept study, we
show that our proposed solution using GANs is able to capture some of the
global and local CT variabilities. Our network is able to generate visually
realistic CT images and we aim to further enhance its output by scaling it to a
higher resolution and potentially from 2D to 3D.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Javaid_U/0/1/0/all/0/1&quot;&gt;Umair Javaid&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1&quot;&gt;John A. Lee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11505">
<title>Classification with imperfect training labels. (arXiv:1805.11505v1 [math.ST])</title>
<link>http://arxiv.org/abs/1805.11505</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the effect of imperfect training data labels on the performance of
classification methods. In a general setting, where the probability that an
observation in the training dataset is mislabelled may depend on both the
feature vector and the true label, we bound the excess risk of an arbitrary
classifier trained with imperfect labels in terms of its excess risk for
predicting a noisy label. This reveals conditions under which a classifier
trained with imperfect labels remains consistent for classifying uncorrupted
test data points. Furthermore, under stronger conditions, we derive detailed
asymptotic properties for the popular $k$-nearest neighbour ($k$nn), Support
Vector Machine (SVM) and Linear Discriminant Analysis (LDA) classifiers. One
consequence of these results is that the $k$nn and SVM classifiers are robust
to imperfect training labels, in the sense that the rate of convergence of the
excess risks of these classifiers remains unchanged; in fact, it even turns out
that in some cases, imperfect labels may improve the performance of these
methods. On the other hand, the LDA classifier is shown to be typically
inconsistent in the presence of label noise unless the prior probabilities of
each class are equal. Our theoretical results are supported by a simulation
study.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Cannings_T/0/1/0/all/0/1&quot;&gt;Timothy I. Cannings&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Fan_Y/0/1/0/all/0/1&quot;&gt;Yingying Fan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Samworth_R/0/1/0/all/0/1&quot;&gt;Richard J. Samworth&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11565">
<title>On gradient regularizers for MMD GANs. (arXiv:1805.11565v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.11565</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a principled method for gradient-based regularization of the
critic of GAN-like models trained by adversarially optimizing the kernel of a
Maximum Mean Discrepancy (MMD). Our method is based on studying the behavior of
the optimized MMD, and constrains the gradient based on analytical results
rather than an optimization penalty. Experimental results show that the
proposed regularization leads to stable training and outperforms state-of-the
art methods on image generation, including on $160 \times 160$ CelebA and $64
\times 64$ ImageNet.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Arbel_M/0/1/0/all/0/1&quot;&gt;Michael Arbel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sutherland_D/0/1/0/all/0/1&quot;&gt;Dougal J. Sutherland&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Binkowski_M/0/1/0/all/0/1&quot;&gt;Miko&amp;#x142;aj Bi&amp;#x144;kowski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gretton_A/0/1/0/all/0/1&quot;&gt;Arthur Gretton&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11614">
<title>Deep Learning under Privileged Information Using Heteroscedastic Dropout. (arXiv:1805.11614v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.11614</link>
<description rdf:parseType="Literal">&lt;p&gt;Unlike machines, humans learn through rapid, abstract model-building. The
role of a teacher is not simply to hammer home right or wrong answers, but
rather to provide intuitive comments, comparisons, and explanations to a pupil.
This is what the Learning Under Privileged Information (LUPI) paradigm
endeavors to model by utilizing extra knowledge only available during training.
We propose a new LUPI algorithm specifically designed for Convolutional Neural
Networks (CNNs) and Recurrent Neural Networks (RNNs). We propose to use a
heteroscedastic dropout (i.e. dropout with a varying variance) and make the
variance of the dropout a function of privileged information. Intuitively, this
corresponds to using the privileged information to control the uncertainty of
the model output. We perform experiments using CNNs and RNNs for the tasks of
image classification and machine translation. Our method significantly
increases the sample efficiency during learning, resulting in higher accuracy
with a large margin when the number of training examples is limited. We also
theoretically justify the gains in sample efficiency by providing a
generalization error bound decreasing with $O(\frac{1}{n})$, where $n$ is the
number of training examples, in an oracle case.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lambert_J/0/1/0/all/0/1&quot;&gt;John Lambert&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sener_O/0/1/0/all/0/1&quot;&gt;Ozan Sener&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Savarese_S/0/1/0/all/0/1&quot;&gt;Silvio Savarese&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1705.09847">
<title>Lifelong Generative Modeling. (arXiv:1705.09847v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1705.09847</link>
<description rdf:parseType="Literal">&lt;p&gt;Lifelong learning is the problem of learning multiple consecutive tasks in a
sequential manner where knowledge gained from previous tasks is retained and
used for future learning. It is essential towards the development of
intelligent machines that can adapt to their surroundings. In this work we
focus on a lifelong learning approach to generative modeling where we
continuously incorporate newly observed distributions into our learnt model. We
do so through a student-teacher Variational Autoencoder architecture which
allows us to learn and preserve all the distributions seen so far without the
need to retain the past data nor the past models. Through the introduction of a
novel cross-model regularizer, inspired by a Bayesian update rule, the student
model leverages the information learnt by the teacher, which acts as a summary
of everything seen till now. The regularizer has the additional benefit of
reducing the effect of catastrophic interference that appears when we learn
over sequences of distributions. We demonstrate its efficacy in learning
sequentially observed distributions as well as its ability to learn a common
latent representation across a complex transfer learning scenario.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ramapuram_J/0/1/0/all/0/1&quot;&gt;Jason Ramapuram&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gregorova_M/0/1/0/all/0/1&quot;&gt;Magda Gregorova&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kalousis_A/0/1/0/all/0/1&quot;&gt;Alexandros Kalousis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.01421">
<title>Adversarial Vulnerability of Neural Networks Increases With Input Dimension. (arXiv:1802.01421v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1802.01421</link>
<description rdf:parseType="Literal">&lt;p&gt;Over the past four years, neural networks have proven vulnerable to
adversarial images: targeted but imperceptible image perturbations lead to
drastically different predictions. We show that adversarial vulnerability
increases with the gradients of the training objective when seen as a function
of the inputs. For most current network architectures, we prove that the
$\ell_1$-norm of these gradients grows as the square root of the input-size.
These nets therefore become increasingly vulnerable with growing image size.
Over the course of our analysis we rediscover and generalize
double-backpropagation, a technique that penalizes large gradients in the loss
surface to reduce adversarial vulnerability and increase generalization
performance. We show that this regularization-scheme is equivalent at first
order to training with adversarial noise. Our proofs rely on the network&apos;s
weight-distribution at initialization, but extensive experiments confirm all
conclusions after training.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Simon_Gabriel_C/0/1/0/all/0/1&quot;&gt;Carl-Johann Simon-Gabriel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ollivier_Y/0/1/0/all/0/1&quot;&gt;Yann Ollivier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bottou_L/0/1/0/all/0/1&quot;&gt;L&amp;#xe9;on Bottou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Scholkopf_B/0/1/0/all/0/1&quot;&gt;Bernhard Sch&amp;#xf6;lkopf&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lopez_Paz_D/0/1/0/all/0/1&quot;&gt;David Lopez-Paz&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.03605">
<title>Combinets: Learning New Models via Recombination. (arXiv:1802.03605v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1802.03605</link>
<description rdf:parseType="Literal">&lt;p&gt;Modern machine learning methods struggle with problems with small amounts of
training data. One solution to is to reuse existing data through transfer
methods such as one-shot or transfer learning. However these approaches tend to
require an explicit hand-authored or learned definition of how reuse can occur.
We present a new representation called conceptual expansions that serves as a
general representation for reuse from existing machine-learned knowledge. We
evaluate our approach by building conceptual expansions for image classifiers
and Generative Adversarial Networks for new classes with as few as ten samples.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guzdial_M/0/1/0/all/0/1&quot;&gt;Matthew Guzdial&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Riedl_M/0/1/0/all/0/1&quot;&gt;Mark O. Riedl&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.10265">
<title>Training verified learners with learned verifiers. (arXiv:1805.10265v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.10265</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper proposes a new algorithmic framework, predictor-verifier training,
to train neural networks that are verifiable, i.e., networks that provably
satisfy some desired input-output properties. The key idea is to simultaneously
train two networks: a predictor network that performs the task at hand,e.g.,
predicting labels given inputs, and a verifier network that computes a bound on
how well the predictor satisfies the properties being verified. Both networks
can be trained simultaneously to optimize a weighted combination of the
standard data-fitting loss and a term that bounds the maximum violation of the
property. Experiments show that not only is the predictor-verifier architecture
able to train networks to achieve state of the art verified robustness to
adversarial examples with much shorter training times (outperforming previous
algorithms on small datasets like MNIST and SVHN), but it can also be scaled to
produce the first known (to the best of our knowledge) verifiably robust
networks for CIFAR-10.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dvijotham_K/0/1/0/all/0/1&quot;&gt;Krishnamurthy Dvijotham&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gowal_S/0/1/0/all/0/1&quot;&gt;Sven Gowal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stanforth_R/0/1/0/all/0/1&quot;&gt;Robert Stanforth&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Arandjelovic_R/0/1/0/all/0/1&quot;&gt;Relja Arandjelovic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+ODonoghue_B/0/1/0/all/0/1&quot;&gt;Brendan O&amp;#x27;Donoghue&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Uesato_J/0/1/0/all/0/1&quot;&gt;Jonathan Uesato&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kohli_P/0/1/0/all/0/1&quot;&gt;Pushmeet Kohli&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.10369">
<title>When Recurrent Models Don&apos;t Need To Be Recurrent. (arXiv:1805.10369v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.10369</link>
<description rdf:parseType="Literal">&lt;p&gt;We prove stable recurrent neural networks are well approximated by
feed-forward networks for the purpose of both inference and training by
gradient descent. Our result applies to a broad range of non-linear recurrent
neural networks under a natural stability condition, which we observe is also
necessary. Complementing our theoretical findings, we verify the conclusions of
our theory on both real and synthetic tasks. Furthermore, we demonstrate
recurrent models satisfying the stability assumption of our theory can have
excellent performance on real sequence learning tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Miller_J/0/1/0/all/0/1&quot;&gt;John Miller&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hardt_M/0/1/0/all/0/1&quot;&gt;Moritz Hardt&lt;/a&gt;</dc:creator>
</item></rdf:RDF>