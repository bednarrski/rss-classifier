<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Good papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Good Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-02-18T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.04248"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05800"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05844"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05875"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05883"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05944"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05992"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06024"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06070"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.03740"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.04309"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05756"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05779"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05792"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05799"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05842"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05846"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05957"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05981"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1703.05840"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.08864"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05283"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1712.04248">
<title>Decision-Based Adversarial Attacks: Reliable Attacks Against Black-Box Machine Learning Models. (arXiv:1712.04248v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1712.04248</link>
<description rdf:parseType="Literal">&lt;p&gt;Many machine learning algorithms are vulnerable to almost imperceptible
perturbations of their inputs. So far it was unclear how much risk adversarial
perturbations carry for the safety of real-world machine learning applications
because most methods used to generate such perturbations rely either on
detailed model information (gradient-based attacks) or on confidence scores
such as class probabilities (score-based attacks), neither of which are
available in most real-world scenarios. In many such cases one currently needs
to retreat to transfer-based attacks which rely on cumbersome substitute
models, need access to the training data and can be defended against. Here we
emphasise the importance of attacks which solely rely on the final model
decision. Such decision-based attacks are (1) applicable to real-world
black-box models such as autonomous cars, (2) need less knowledge and are
easier to apply than transfer-based attacks and (3) are more robust to simple
defences than gradient- or score-based attacks. Previous attacks in this
category were limited to simple models or simple datasets. Here we introduce
the Boundary Attack, a decision-based attack that starts from a large
adversarial perturbation and then seeks to reduce the perturbation while
staying adversarial. The attack is conceptually simple, requires close to no
hyperparameter tuning, does not rely on substitute models and is competitive
with the best gradient-based attacks in standard computer vision tasks like
ImageNet. We apply the attack on two black-box algorithms from Clarifai.com.
The Boundary Attack in particular and the class of decision-based attacks in
general open new avenues to study the robustness of machine learning models and
raise new questions regarding the safety of deployed machine learning systems.
An implementation of the attack is available as part of Foolbox at
https://github.com/bethgelab/foolbox .
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Brendel_W/0/1/0/all/0/1&quot;&gt;Wieland Brendel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rauber_J/0/1/0/all/0/1&quot;&gt;Jonas Rauber&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bethge_M/0/1/0/all/0/1&quot;&gt;Matthias Bethge&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05800">
<title>Tree-CNN: A Deep Convolutional Neural Network for Lifelong Learning. (arXiv:1802.05800v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1802.05800</link>
<description rdf:parseType="Literal">&lt;p&gt;In recent years, Convolutional Neural Networks (CNNs) have shown remarkable
performance in many computer vision tasks such as object recognition and
detection. However, complex training issues, such as &quot;catastrophic forgetting&quot;
and hyper-parameter tuning, make incremental learning in CNNs a difficult
challenge. In this paper, we propose a hierarchical deep neural network, with
CNNs at multiple levels, and a corresponding training method for lifelong
learning. The network grows in a tree-like manner to accommodate the new
classes of data without losing the ability to identify the previously trained
classes. The proposed network was tested on CIFAR-10 and CIFAR-100 datasets,
and compared against the method of fine tuning specific layers of a
conventional CNN. We obtained comparable accuracies and achieved 40% and 20%
reduction in training effort in CIFAR-10 and CIFAR 100 respectively. The
network was able to organize the incoming classes of data into feature-driven
super-classes. Our model improves upon existing hierarchical CNN models by
adding the capability of self-growth and also yields important observations on
feature selective classification.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roy_D/0/1/0/all/0/1&quot;&gt;Deboleena Roy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Panda_P/0/1/0/all/0/1&quot;&gt;Priyadarshini Panda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roy_K/0/1/0/all/0/1&quot;&gt;Kaushik Roy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05844">
<title>A Unified View of Causal and Non-causal Feature Selection. (arXiv:1802.05844v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.05844</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we unify causal and non-causal feature feature selection
methods based on the Bayesian network framework. We first show that the
objectives of causal and non-causal feature selection methods are equal and are
to find the Markov blanket of a class attribute, the theoretically optimal
feature set for classification. We demonstrate that causal and non-causal
feature selection take different assumptions of dependency among features to
find Markov blanket, and their algorithms are shown different level of
approximation for finding Markov blanket. In this framework, we are able to
analyze the sample and error bounds of casual and non-causal methods. We
conducted extensive experiments to show the correctness of our theoretical
analysis.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_K/0/1/0/all/0/1&quot;&gt;Kui Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1&quot;&gt;Lin Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jiuyong Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05875">
<title>Detecting truth on components. (arXiv:1802.05875v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.05875</link>
<description rdf:parseType="Literal">&lt;p&gt;We investigate and generalize to an extended framework the notion of &apos;true on
components&apos; introduced by Zhou, Wang and Sun in their paper &quot;Automated
Reducible Geometric Theorem Proving and Discovery by Gr\&quot;obner Basis Method&quot;,
J. Automat. Reasoning 59 (3), 331-344, 2017. A new, simple criterion is
presented for a statement to be simultaneously not generally true and not
generally false (i.e. true on components), and its performance is exemplified
through the implementation of this test in the dynamic geometry program
GeoGebra.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kovacs_Z/0/1/0/all/0/1&quot;&gt;Zolt&amp;#xe1;n Kov&amp;#xe1;cs&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Recio_T/0/1/0/all/0/1&quot;&gt;Tom&amp;#xe1;s Recio&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Velez_M/0/1/0/all/0/1&quot;&gt;M. Pilar V&amp;#xe9;lez&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05883">
<title>Deep Generative Model for Joint Alignment and Word Representation. (arXiv:1802.05883v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1802.05883</link>
<description rdf:parseType="Literal">&lt;p&gt;This work exploits translation data as a source of semantically relevant
learning signal for models of word representation. In particular, we exploit
equivalence through translation as a form of distributed context and jointly
learn how to embed and align with a deep generative model. Our EmbedAlign model
embeds words in their complete observed context and learns by marginalisation
of latent lexical alignments. Besides, it embeds words as posterior probability
densities, rather than point estimates, which allows us to compare words in
context using a measure of overlap between distributions (e.g. KL divergence).
We investigate our model&apos;s performance on a range of lexical semantics tasks
achieving competitive results on several standard benchmarks including natural
language inference, paraphrasing, and text similarity.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rios_M/0/1/0/all/0/1&quot;&gt;Miguel Rios&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aziz_W/0/1/0/all/0/1&quot;&gt;Wilker Aziz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Simaan_K/0/1/0/all/0/1&quot;&gt;Khalil Sima&amp;#x27;an&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05944">
<title>Monte Carlo Q-learning for General Game Playing. (arXiv:1802.05944v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.05944</link>
<description rdf:parseType="Literal">&lt;p&gt;Recently, the interest in reinforcement learning in game playing has been
renewed. This is evidenced by the groundbreaking results achieved by AlphaGo.
General Game Playing (GGP) provides a good testbed for reinforcement learning,
currently one of the hottest fields of AI. In GGP, a specification of games
rules is given. The description specifies a reinforcement learning problem,
leaving programs to find strategies for playing well. Q-learning is one of the
canonical reinforcement learning methods, which is used as baseline on some
previous work (Banerjee &amp;amp; Stone, IJCAI 2007). We implement Q-learning in GGP
for three small board games (Tic-Tac-Toe, Connect-Four, Hex). We find that
Q-learning converges, and thus that this general reinforcement learning method
is indeed applicable to General Game Playing. However, convergence is slow, in
comparison to MCTS (a reinforcement learning method reported to achieve good
results). We enhance Q-learning with Monte Carlo Search. This enhancement
improves performance of pure Q-learning, although it does not yet out-perform
MCTS. Future work is needed into the relation between MCTS and Q-learning, and
on larger problem instances.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1&quot;&gt;Hui Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Emmerich_M/0/1/0/all/0/1&quot;&gt;Michael Emmerich&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Plaat_A/0/1/0/all/0/1&quot;&gt;Aske Plaat&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05992">
<title>Improved GQ-CNN: Deep Learning Model for Planning Robust Grasps. (arXiv:1802.05992v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.05992</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent developments in the field of robot grasping have shown great
improvements in the grasp success rates when dealing with unknown objects. In
this work we improve on one of the most promising approaches, the Grasp Quality
Convolutional Neural Network (GQ-CNN) trained on the DexNet 2.0 dataset. We
propose a new architecture for the GQ-CNN and describe practical improvements
that increase the model validation accuracy from 92.2% to 95.8% and from 85.9%
to 88.0% on respectively image-wise and object-wise training and validation
splits.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jaskowski_M/0/1/0/all/0/1&quot;&gt;Maciej Ja&amp;#x15b;kowski&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Swiatkowski_J/0/1/0/all/0/1&quot;&gt;Jakub &amp;#x15a;wi&amp;#x105;tkowski&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zajac_M/0/1/0/all/0/1&quot;&gt;Micha&amp;#x142; Zaj&amp;#x105;c&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Klimek_M/0/1/0/all/0/1&quot;&gt;Maciej Klimek&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Potiuk_J/0/1/0/all/0/1&quot;&gt;Jarek Potiuk&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rybicki_P/0/1/0/all/0/1&quot;&gt;Piotr Rybicki&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Polatowski_P/0/1/0/all/0/1&quot;&gt;Piotr Polatowski&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Walczyk_P/0/1/0/all/0/1&quot;&gt;Przemys&amp;#x142;aw Walczyk&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nowicki_K/0/1/0/all/0/1&quot;&gt;Kacper Nowicki&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cygan_M/0/1/0/all/0/1&quot;&gt;Marek Cygan&lt;/a&gt; (1 and 2) ((1) NoMagic.AI, (2) Institute of Informatics, University of Warsaw)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06024">
<title>Towards an Engine for Lifelong Interactive Knowledge Learning in Human-Machine Conversations. (arXiv:1802.06024v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1802.06024</link>
<description rdf:parseType="Literal">&lt;p&gt;Although chatbots have been very popular in recent years, they still have
some serious weaknesses which limit the scope of their applications. One major
weakness is that they cannot learn new knowledge during the conversation
process, i.e., their knowledge is fixed beforehand and cannot be expanded or
updated during conversation. In this paper, we propose to build a general
knowledge learning engine for chatbots to enable them to continuously and
interactively learn new knowledge during conversations. As time goes by, they
become more and more knowledgeable and better and better at learning and
conversation. We model the task as an open-world knowledge base completion
problem and propose a novel technique called lifelong interactive learning and
inference (LiLi) to solve it. LiLi works by imitating how humans acquire
knowledge and perform inference during an interactive conversation. Our
experimental results show LiLi is highly promising.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mazumder_S/0/1/0/all/0/1&quot;&gt;Sahisnu Mazumder&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_N/0/1/0/all/0/1&quot;&gt;Nianzu Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1&quot;&gt;Bing Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06070">
<title>Diversity is All You Need: Learning Skills without a Reward Function. (arXiv:1802.06070v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.06070</link>
<description rdf:parseType="Literal">&lt;p&gt;Intelligent creatures can explore their environments and learn useful skills
without supervision. In this paper, we propose DIAYN (&quot;Diversity is All You
Need&quot;), a method for learning useful skills without a reward function. Our
proposed method learns skills by maximizing an information theoretic objective
using a maximum entropy policy. On a variety of simulated robotic tasks, we
show that this simple objective results in the unsupervised emergence of
diverse skills, such as walking and jumping. In a number of reinforcement
learning benchmark environments, our method is able to learn a skill that
solves the benchmark task despite never receiving the true task reward. In
these environments, some of the learned skills correspond to solving the task,
and each skill that solves the task does so in a distinct manner. Our results
suggest that unsupervised discovery of skills can serve as an effective
pretraining mechanism for overcoming challenges of exploration and data
efficiency in reinforcement learning
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Eysenbach_B/0/1/0/all/0/1&quot;&gt;Benjamin Eysenbach&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1&quot;&gt;Abhishek Gupta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ibarz_J/0/1/0/all/0/1&quot;&gt;Julian Ibarz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1&quot;&gt;Sergey Levine&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.03740">
<title>Mixed Precision Training. (arXiv:1710.03740v3 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1710.03740</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep neural networks have enabled progress in a wide variety of applications.
Growing the size of the neural network typically results in improved accuracy.
As model sizes grow, the memory and compute requirements for training these
models also increases. We introduce a technique to train deep neural networks
using half precision floating point numbers. In our technique, weights,
activations and gradients are stored in IEEE half-precision format.
Half-precision floating numbers have limited numerical range compared to
single-precision numbers. We propose two techniques to handle this loss of
information. Firstly, we recommend maintaining a single-precision copy of the
weights that accumulates the gradients after each optimizer step. This
single-precision copy is rounded to half-precision format during training.
Secondly, we propose scaling the loss appropriately to handle the loss of
information with half-precision gradients. We demonstrate that this approach
works for a wide variety of models including convolution neural networks,
recurrent neural networks and generative adversarial networks. This technique
works for large scale models with more than 100 million parameters trained on
large datasets. Using this approach, we can reduce the memory consumption of
deep learning models by nearly 2x. In future processors, we can also expect a
significant computation speedup using half-precision hardware units.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Micikevicius_P/0/1/0/all/0/1&quot;&gt;Paulius Micikevicius&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Narang_S/0/1/0/all/0/1&quot;&gt;Sharan Narang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alben_J/0/1/0/all/0/1&quot;&gt;Jonah Alben&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Diamos_G/0/1/0/all/0/1&quot;&gt;Gregory Diamos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Elsen_E/0/1/0/all/0/1&quot;&gt;Erich Elsen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garcia_D/0/1/0/all/0/1&quot;&gt;David Garcia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ginsburg_B/0/1/0/all/0/1&quot;&gt;Boris Ginsburg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Houston_M/0/1/0/all/0/1&quot;&gt;Michael Houston&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kuchaiev_O/0/1/0/all/0/1&quot;&gt;Oleksii Kuchaiev&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Venkatesh_G/0/1/0/all/0/1&quot;&gt;Ganesh Venkatesh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1&quot;&gt;Hao Wu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.04309">
<title>Self-Regulating Artificial General Intelligence. (arXiv:1711.04309v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1711.04309</link>
<description rdf:parseType="Literal">&lt;p&gt;Here we examine the paperclip apocalypse concern for artificial general
intelligence (or AGI) whereby a superintelligent AI with a simple goal (ie.,
producing paperclips) accumulates power so that all resources are devoted
towards that simple goal and are unavailable for any other use. We provide
conditions under which a paper apocalypse can arise but also show that, under
certain architectures for recursive self-improvement of AIs, that a paperclip
AI may refrain from allowing power capabilities to be developed. The reason is
that such developments pose the same control problem for the AI as they do for
humans (over AIs) and hence, threaten to deprive it of resources for its
primary goal.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gans_J/0/1/0/all/0/1&quot;&gt;Joshua S. Gans&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05756">
<title>Inferring relevant features: from QFT to PCA. (arXiv:1802.05756v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.05756</link>
<description rdf:parseType="Literal">&lt;p&gt;In many-body physics, renormalization techniques are used to extract aspects
of a statistical or quantum state that are relevant at large scale, or for low
energy experiments. Recent works have proposed that these features can be
formally identified as those perturbations of the states whose
distinguishability most resist coarse-graining. Here, we examine whether this
same strategy can be used to identify important features of an unlabeled
dataset. This approach indeed results in a technique very similar to kernel PCA
(principal component analysis), but with a kernel function that is
automatically adapted to the data, or &quot;learned&quot;. We test this approach on
handwritten digits, and find that the most relevant features are significantly
better for classification than those obtained from a simple gaussian kernel.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Beny_C/0/1/0/all/0/1&quot;&gt;C&amp;#xe9;dric B&amp;#xe9;ny&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05779">
<title>Quantum Variational Autoencoder. (arXiv:1802.05779v1 [quant-ph])</title>
<link>http://arxiv.org/abs/1802.05779</link>
<description rdf:parseType="Literal">&lt;p&gt;Variational autoencoders (VAEs) are powerful generative models with the
salient ability to perform inference. Here, we introduce a \emph{quantum
variational autoencoder} (QVAE): a VAE whose latent generative process is
implemented as a quantum Boltzmann machine (QBM). We show that our model can be
trained end-to-end by maximizing a well-defined loss-function: a &quot;quantum&quot;
lower-bound to a variational approximation of the log-likelihood. We use
quantum Monte Carlo (QMC) simulations to train and evaluate the performance of
QVAEs. To achieve the best performance, we first create a VAE platform with
discrete latent space generated by a restricted Boltzmann machine (RBM). Our
model achieves state-of-the-art performance on the MNIST dataset when compared
against similar approaches that only involve discrete variables in the
generative process. We consider QVAEs with a smaller number of latent units to
be able to perform QMC simulations, which are computationally expensive. We
show that QVAEs can be trained effectively in regimes where quantum effects are
relevant despite training via the quantum bound. Our findings open the way to
the use of quantum computers to train QVAEs to achieve competitive performance
for generative models. Placing a QBM in the latent space of a VAE leverages the
full potential of current and next-generation quantum computers as sampling
devices.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Khoshaman_A/0/1/0/all/0/1&quot;&gt;Amir Khoshaman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Vinci_W/0/1/0/all/0/1&quot;&gt;Walter Vinci&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Denis_B/0/1/0/all/0/1&quot;&gt;Brandon Denis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Andriyash_E/0/1/0/all/0/1&quot;&gt;Evgeny Andriyash&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Amin_M/0/1/0/all/0/1&quot;&gt;Mohammad H. Amin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05792">
<title>Masked Conditional Neural Networks for Automatic Sound Events Recognition. (arXiv:1802.05792v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.05792</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep neural network architectures designed for application domains other than
sound, especially image recognition, may not optimally harness the
time-frequency representation when adapted to the sound recognition problem. In
this work, we explore the ConditionaL Neural Network (CLNN) and the Masked
ConditionaL Neural Network (MCLNN) for multi-dimensional temporal signal
recognition. The CLNN considers the inter-frame relationship, and the MCLNN
enforces a systematic sparseness over the network&apos;s links to enable learning in
frequency bands rather than bins allowing the network to be frequency shift
invariant mimicking a filterbank. The mask also allows considering several
combinations of features concurrently, which is usually handcrafted through
exhaustive manual search. We applied the MCLNN to the environmental sound
recognition problem using the ESC-10 and ESC-50 datasets. MCLNN achieved
competitive performance, using 12% of the parameters and without augmentation,
compared to state-of-the-art Convolutional Neural Networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Medhat_F/0/1/0/all/0/1&quot;&gt;Fady Medhat&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chesmore_D/0/1/0/all/0/1&quot;&gt;David Chesmore&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Robinson_J/0/1/0/all/0/1&quot;&gt;John Robinson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05799">
<title>Horovod: fast and easy distributed deep learning in TensorFlow. (arXiv:1802.05799v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.05799</link>
<description rdf:parseType="Literal">&lt;p&gt;Training modern deep learning models requires large amounts of computation,
often provided by GPUs. Scaling computation from one GPU to many can enable
much faster training and research progress but entails two complications.
First, the training library must support inter-GPU communication. Depending on
the particular methods employed, this communication may entail anywhere from
negligible to significant overhead. Second, the user must modify his or her
training code to take advantage of inter-GPU communication. Depending on the
training library&apos;s API, the modification required may be either significant or
minimal.
&lt;/p&gt;
&lt;p&gt;Existing methods for enabling multi-GPU training under the TensorFlow library
entail non-negligible communication overhead and require users to heavily
modify their model-building code, leading many researchers to avoid the whole
mess and stick with slower single-GPU training. In this paper we introduce
Horovod, an open source library that improves on both obstructions to scaling:
it employs efficient inter-GPU communication via ring reduction and requires
only a few lines of modification to user code, enabling faster, easier
distributed training in TensorFlow. Horovod is available under the Apache 2.0
license at https://github.com/uber/horovod.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sergeev_A/0/1/0/all/0/1&quot;&gt;Alexander Sergeev&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Balso_M/0/1/0/all/0/1&quot;&gt;Mike Del Balso&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05842">
<title>Neural Granger Causality for Nonlinear Time Series. (arXiv:1802.05842v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.05842</link>
<description rdf:parseType="Literal">&lt;p&gt;While most classical approaches to Granger causality detection assume linear
dynamics, many interactions in applied domains, like neuroscience and genomics,
are inherently nonlinear. In these cases, using linear models may lead to
inconsistent estimation of Granger causal interactions. We propose a class of
nonlinear methods by applying structured multilayer perceptrons (MLPs) or
recurrent neural networks (RNNs) combined with sparsity-inducing penalties on
the weights. By encouraging specific sets of weights to be zero---in particular
through the use of convex group-lasso penalties---we can extract the Granger
causal structure. To further contrast with traditional approaches, our
framework naturally enables us to efficiently capture long-range dependencies
between series either via our RNNs or through an automatic lag selection in the
MLP. We show that our neural Granger causality methods outperform
state-of-the-art nonlinear Granger causality methods on the DREAM3 challenge
data. This data consists of nonlinear gene expression and regulation time
courses with only a limited number of time points. The successes we show in
this challenging dataset provide a powerful example of how deep learning can be
useful in cases that go beyond prediction on large datasets. We likewise
demonstrate our methods in detecting nonlinear interactions in a human motion
capture dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tank_A/0/1/0/all/0/1&quot;&gt;Alex Tank&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Covert_I/0/1/0/all/0/1&quot;&gt;Ian Covert&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Foti_N/0/1/0/all/0/1&quot;&gt;Nicholas Foti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Shojaie_A/0/1/0/all/0/1&quot;&gt;Ali Shojaie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Fox_E/0/1/0/all/0/1&quot;&gt;Emily Fox&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05846">
<title>Train on Validation: Squeezing the Data Lemon. (arXiv:1802.05846v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.05846</link>
<description rdf:parseType="Literal">&lt;p&gt;Model selection on validation data is an essential step in machine learning.
While the mixing of data between training and validation is considered taboo,
practitioners often violate it to increase performance. Here, we offer a
simple, practical method for using the validation set for training, which
allows for a continuous, controlled trade-off between performance and
overfitting of model selection. We define the notion of
on-average-validation-stable algorithms as one in which using small portions of
validation data for training does not overfit the model selection process. We
then prove that stable algorithms are also validation stable. Finally, we
demonstrate our method on the MNIST and CIFAR-10 datasets using stable
algorithms as well as state-of-the-art neural networks. Our results show
significant increase in test performance with a minor trade-off in bias
admitted to the model selection process.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tennenholtz_G/0/1/0/all/0/1&quot;&gt;Guy Tennenholtz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zahavy_T/0/1/0/all/0/1&quot;&gt;Tom Zahavy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mannor_S/0/1/0/all/0/1&quot;&gt;Shie Mannor&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05957">
<title>Spectral Normalization for Generative Adversarial Networks. (arXiv:1802.05957v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.05957</link>
<description rdf:parseType="Literal">&lt;p&gt;One of the challenges in the study of generative adversarial networks is the
instability of its training. In this paper, we propose a novel weight
normalization technique called spectral normalization to stabilize the training
of the discriminator. Our new normalization technique is computationally light
and easy to incorporate into existing implementations. We tested the efficacy
of spectral normalization on CIFAR10, STL-10, and ILSVRC2012 dataset, and we
experimentally confirmed that spectrally normalized GANs (SN-GANs) is capable
of generating images of better or equal quality relative to the previous
training stabilization techniques.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Miyato_T/0/1/0/all/0/1&quot;&gt;Takeru Miyato&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kataoka_T/0/1/0/all/0/1&quot;&gt;Toshiki Kataoka&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koyama_M/0/1/0/all/0/1&quot;&gt;Masanori Koyama&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yoshida_Y/0/1/0/all/0/1&quot;&gt;Yuichi Yoshida&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05981">
<title>Tensor-based Nonlinear Classifier for High-Order Data Analysis. (arXiv:1802.05981v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.05981</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper we propose a tensor-based nonlinear model for high-order data
classification. The advantages of the proposed scheme are that (i) it
significantly reduces the number of weight parameters, and hence of required
training samples, and (ii) it retains the spatial structure of the input
samples. The proposed model, called \textit{Rank}-1 FNN, is based on a
modification of a feedforward neural network (FNN), such that its weights
satisfy the {\it rank}-1 canonical decomposition. We also introduce a new
learning algorithm to train the model, and we evaluate the \textit{Rank}-1 FNN
on third-order hyperspectral data. Experimental results and comparisons
indicate that the proposed model outperforms state of the art classification
methods, including deep learning based ones, especially in cases with small
numbers of available training samples.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Makantasis_K/0/1/0/all/0/1&quot;&gt;Konstantinos Makantasis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Doulamis_A/0/1/0/all/0/1&quot;&gt;Anastasios Doulamis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Doulamis_N/0/1/0/all/0/1&quot;&gt;Nikolaos Doulamis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nikitakis_A/0/1/0/all/0/1&quot;&gt;Antonis Nikitakis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Voulodimos_A/0/1/0/all/0/1&quot;&gt;Athanasios Voulodimos&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1703.05840">
<title>Conditional Accelerated Lazy Stochastic Gradient Descent. (arXiv:1703.05840v5 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1703.05840</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work we introduce a conditional accelerated lazy stochastic gradient
descent algorithm with optimal number of calls to a stochastic first-order
oracle and convergence rate $O\left(\frac{1}{\varepsilon^2}\right)$ improving
over the projection-free, Online Frank-Wolfe based stochastic gradient descent
of Hazan and Kale [2012] with convergence rate
$O\left(\frac{1}{\varepsilon^4}\right)$.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lan_G/0/1/0/all/0/1&quot;&gt;Guanghui Lan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pokutta_S/0/1/0/all/0/1&quot;&gt;Sebastian Pokutta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1&quot;&gt;Yi Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zink_D/0/1/0/all/0/1&quot;&gt;Daniel Zink&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.08864">
<title>One pixel attack for fooling deep neural networks. (arXiv:1710.08864v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1710.08864</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent research has revealed that the output of Deep Neural Networks (DNN)
can be easily altered by adding relatively small perturbations to the input
vector. In this paper, we analyze an attack in an extremely limited scenario
where only one pixel can be modified. For that we propose a novel method for
generating one-pixel adversarial perturbations based on differential evolution.
It requires less adversarial information and can fool more types of networks.
The results show that 70.97% of the natural images can be perturbed to at least
one target class by modifying just one pixel with 97.47% confidence on average.
Thus, the proposed attack explores a different take on adversarial machine
learning in an extreme limited scenario, showing that current DNNs are also
vulnerable to such low dimension attacks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Su_J/0/1/0/all/0/1&quot;&gt;Jiawei Su&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vargas_D/0/1/0/all/0/1&quot;&gt;Danilo Vasconcellos Vargas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kouichi_S/0/1/0/all/0/1&quot;&gt;Sakurai Kouichi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05283">
<title>Designing Random Graph Models Using Variational Autoencoders With Applications to Chemical Design. (arXiv:1802.05283v1 [cs.LG] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1802.05283</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep generative models have been praised for their ability to learn smooth
latent representation of images, text, and audio, which can then be used to
generate new, plausible data. However, current generative models are unable to
work with graphs due to their unique characteristics--their underlying
structure is not Euclidean or grid-like, they remain isomorphic under
permutation of the nodes labels, and they come with a different number of nodes
and edges. In this paper, we propose a variational autoencoder for graphs,
whose encoder and decoder are specially designed to account for the above
properties by means of several technical innovations. Moreover, the decoder is
able to guarantee a set of local structural and functional properties in the
generated graphs. Experiments reveal that our model is able to learn and mimic
the generative process of several well-known random graph models and can be
used to create new molecules more effectively than several state of the art
methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Samanta_B/0/1/0/all/0/1&quot;&gt;Bidisha Samanta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+De_A/0/1/0/all/0/1&quot;&gt;Abir De&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ganguly_N/0/1/0/all/0/1&quot;&gt;Niloy Ganguly&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gomez_Rodriguez_M/0/1/0/all/0/1&quot;&gt;Manuel Gomez-Rodriguez&lt;/a&gt;</dc:creator>
</item></rdf:RDF>