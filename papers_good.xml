<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Good papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Good Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-05-22T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08340"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08394"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08522"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08574"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08654"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08747"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.06959"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08296"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08329"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08347"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08427"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08440"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08455"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08592"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08657"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.01244"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.06517"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.03885"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1309.3699"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08266"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08318"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08328"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08355"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08356"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08402"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08462"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08463"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08465"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08469"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08490"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08578"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08656"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08671"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08704"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08719"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08720"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08736"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08749"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1705.08292"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.07746"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08195"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.07729"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.04276"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07475"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07544"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1805.08340">
<title>Reducing Parameter Space for Neural Network Training. (arXiv:1805.08340v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.08340</link>
<description rdf:parseType="Literal">&lt;p&gt;For neural networks (NNs) with rectified linear unit (ReLU) or binary
activation functions, we show that their training can be accomplished in a
reduced parameter space. Specifically, the weights in each neuron can be
trained on the unit sphere, as opposed to the entire space, and the threshold
can be trained in a bounded interval, as opposed to the real line. We show that
the NNs in the reduced parameter space are mathematically equivalent to the
standard NNs with parameters in the whole space. The reduced parameter space
shall facilitate the optimization procedure for the network training, as the
search space becomes (much) smaller. We demonstrate the improved training
performance using numerical examples.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Qin_T/0/1/0/all/0/1&quot;&gt;Tong Qin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhou_L/0/1/0/all/0/1&quot;&gt;Ling Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Xiu_D/0/1/0/all/0/1&quot;&gt;Dongbin Xiu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08394">
<title>State-Denoised Recurrent Neural Networks. (arXiv:1805.08394v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1805.08394</link>
<description rdf:parseType="Literal">&lt;p&gt;Recurrent neural networks (RNNs) are difficult to train on sequence
processing tasks, not only because input noise may be amplified through
feedback, but also because any inaccuracy in the weights has similar
consequences as input noise. We describe a method for denoising the hidden
state during training to achieve more robust representations thereby improving
generalization performance. Attractor dynamics are incorporated into the hidden
state to `clean up&apos; representations at each step of a sequence. The attractor
dynamics are trained through an auxillary denoising loss to recover previously
experienced hidden states from noisy versions of those states. This
state-denoised recurrent neural network {SDRNN} performs multiple steps of
internal processing for each external sequence step. On a range of tasks, we
show that the SDRNN outperforms a generic RNN as well as a variant of the SDRNN
with attractor dynamics on the hidden state but without the auxillary loss. We
argue that attractor dynamics---and corresponding connectivity
constraints---are an essential component of the deep learning arsenal and
should be invoked not only for recurrent networks but also for improving deep
feedforward nets and intertask transfer.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mozer_M/0/1/0/all/0/1&quot;&gt;Michael C.Mozer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kazakov_D/0/1/0/all/0/1&quot;&gt;Denis Kazakov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lindsey_R/0/1/0/all/0/1&quot;&gt;Robert V. Lindsey&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08522">
<title>Deep learning generalizes because the parameter-function map is biased towards simple functions. (arXiv:1805.08522v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.08522</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep neural networks generalize remarkably well without explicit
regularization even in the strongly over-parametrized regime. This success
suggests that some form of implicit regularization must be at work. By applying
a modified version of the coding theorem from algorithmic information theory
and by performing extensive empirical analysis of random neural networks, we
argue that the parameter function map of deep neural networks is exponentially
biased towards functions with lower descriptional complexity. We show
explicitly for supervised learning of Boolean functions that the intrinsic
simplicity bias of deep neural networks means that they generalize
significantly better than an unbiased learning algorithm does. The superior
generalization due to simplicity bias can be explained using PAC-Bayes theory,
which yields useful generalization error bounds for learning Boolean functions
with a wide range of complexities. Finally, we provide evidence that deeper
neural networks trained on the CIFAR10 data set exhibit stronger simplicity
bias than shallow networks do, which may help explain why deeper networks
generalize better than shallow ones do.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Perez_G/0/1/0/all/0/1&quot;&gt;Guillermo Valle P&amp;#xe9;rez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Louis_A/0/1/0/all/0/1&quot;&gt;Ard A. Louis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Camargo_C/0/1/0/all/0/1&quot;&gt;Chico Q. Camargo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08574">
<title>Breaking the Activation Function Bottleneck through Adaptive Parameterization. (arXiv:1805.08574v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.08574</link>
<description rdf:parseType="Literal">&lt;p&gt;Standard neural network architectures are non-linear only by virtue of a
simple element-wise activation function, making them both brittle and
excessively large. In this paper, we consider methods for making the
feed-forward layer more flexible while preserving its basic structure. We
develop simple drop-in replacements that learn to adapt their parameterization
conditional on the input, thereby increasing statistical efficiency
significantly. We present an adaptive LSTM that advances the state of the art
for the Penn Treebank and Wikitext-2 word-modeling tasks while using fewer
parameters and converging in half as many iterations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Flennerhag_S/0/1/0/all/0/1&quot;&gt;Sebastian Flennerhag&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yin_H/0/1/0/all/0/1&quot;&gt;Hujun Yin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Keane_J/0/1/0/all/0/1&quot;&gt;John Keane&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Elliot_M/0/1/0/all/0/1&quot;&gt;Mark Elliot&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08654">
<title>Universal discriminative quantum neural networks. (arXiv:1805.08654v1 [quant-ph])</title>
<link>http://arxiv.org/abs/1805.08654</link>
<description rdf:parseType="Literal">&lt;p&gt;Quantum mechanics fundamentally forbids deterministic discrimination of
quantum states and processes. However, the ability to optimally distinguish
various classes of quantum data is an important primitive in quantum
information science. In this work, we train near-term quantum circuits to
classify data represented by non-orthogonal quantum probability distributions
using the Adam stochastic optimization algorithm. This is achieved by iterative
interactions of a classical device with a quantum processor to discover the
parameters of an unknown non-unitary quantum circuit. This circuit learns to
simulates the unknown structure of a generalized quantum measurement, or
Positive-Operator-Value-Measure (POVM), that is required to optimally
distinguish possible distributions of quantum inputs. Notably we use universal
circuit topologies, with a theoretically motivated circuit design, which
guarantees that our circuits can in principle learn to perform arbitrary
input-output mappings. Our numerical simulations show that shallow quantum
circuits could be trained to discriminate among various pure and mixed quantum
states exhibiting a trade-off between minimizing erroneous and inconclusive
outcomes with comparable performance to theoretically optimal POVMs. We train
the circuit on different classes of quantum data and evaluate the
generalization error on unseen mixed quantum states. This generalization power
hence distinguishes our work from standard circuit optimization and provides an
example of quantum machine learning for a task that has inherently no classical
analogue.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Chen_H/0/1/0/all/0/1&quot;&gt;Hongxiang Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Wossnig_L/0/1/0/all/0/1&quot;&gt;Leonard Wossnig&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Severini_S/0/1/0/all/0/1&quot;&gt;Simone Severini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Neven_H/0/1/0/all/0/1&quot;&gt;Hartmut Neven&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Mohseni_M/0/1/0/all/0/1&quot;&gt;Masoud Mohseni&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08747">
<title>EgoCoder: Intelligent Program Synthesis with Hierarchical Sequential Neural Network Model. (arXiv:1805.08747v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1805.08747</link>
<description rdf:parseType="Literal">&lt;p&gt;Programming has been an important skill for researchers and practitioners in
computer science and other related areas. To learn basic programing skills, a
long-time systematic training is usually required for beginners. According to a
recent market report, the computer software market is expected to continue
expanding at an accelerating speed, but the market supply of qualified software
developers can hardly meet such a huge demand. In recent years, the surge of
text generation research works provides the opportunities to address such a
dilemma through automatic program synthesis. In this paper, we propose to make
our try to solve the program synthesis problem from a data mining perspective.
To address the problem, a novel generative model, namely EgoCoder, will be
introduced in this paper. EgoCoder effectively parses program code into
abstract syntax trees (ASTs), where the tree nodes will contain the program
code/comment content and the tree structure can capture the program logic
flows. Based on a new unit model called Hsu, EgoCoder can effectively capture
both the hierarchical and sequential patterns in the program ASTs. Extensive
experiments will be done to compare EgoCoder with the state-of-the-art text
generation methods, and the experimental results have demonstrated the
effectiveness of EgoCoder in addressing the program synthesis problem.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Jiawei Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cui_L/0/1/0/all/0/1&quot;&gt;Limeng Cui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gouza_F/0/1/0/all/0/1&quot;&gt;Fisher B. Gouza&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.06959">
<title>On the importance of single directions for generalization. (arXiv:1803.06959v4 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1803.06959</link>
<description rdf:parseType="Literal">&lt;p&gt;Despite their ability to memorize large datasets, deep neural networks often
achieve good generalization performance. However, the differences between the
learned solutions of networks which generalize and those which do not remain
unclear. Additionally, the tuning properties of single directions (defined as
the activation of a single unit or some linear combination of units in response
to some input) have been highlighted, but their importance has not been
evaluated. Here, we connect these lines of inquiry to demonstrate that a
network&apos;s reliance on single directions is a good predictor of its
generalization performance, across networks trained on datasets with different
fractions of corrupted labels, across ensembles of networks trained on datasets
with unmodified labels, across different hyperparameters, and over the course
of training. While dropout only regularizes this quantity up to a point, batch
normalization implicitly discourages single direction reliance, in part by
decreasing the class selectivity of individual units. Finally, we find that
class selectivity is a poor predictor of task importance, suggesting not only
that networks which generalize well minimize their dependence on individual
units by reducing their selectivity, but also that individually selective units
may not be necessary for strong network performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Morcos_A/0/1/0/all/0/1&quot;&gt;Ari S. Morcos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Barrett_D/0/1/0/all/0/1&quot;&gt;David G.T. Barrett&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rabinowitz_N/0/1/0/all/0/1&quot;&gt;Neil C. Rabinowitz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Botvinick_M/0/1/0/all/0/1&quot;&gt;Matthew Botvinick&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08296">
<title>Data-Efficient Hierarchical Reinforcement Learning. (arXiv:1805.08296v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.08296</link>
<description rdf:parseType="Literal">&lt;p&gt;Hierarchical reinforcement learning (HRL) is a promising approach to extend
traditional reinforcement learning (RL) methods to solve more complex tasks.
Yet, the majority of current HRL methods require careful task-specific design
and on-policy training, making them difficult to apply in real-world scenarios.
In this paper, we study how we can develop HRL algorithms that are general, in
that they do not make onerous additional assumptions beyond standard RL
algorithms, and efficient, in the sense that they can be used with modest
numbers of interaction samples, making them suitable for real-world problems
such as robotic control. For generality, we develop a scheme where lower-level
controllers are supervised with goals that are learned and proposed
automatically by the higher-level controllers. To address efficiency, we
propose to use off-policy experience for both higher and lower-level training.
This poses a considerable challenge, since changes to the lower-level behaviors
change the action space for the higher-level policy, and we introduce an
off-policy correction to remedy this challenge. This allows us to take
advantage of recent advances in off-policy model-free RL to learn both higher-
and lower-level policies using substantially fewer environment interactions
than on-policy algorithms. We term the resulting HRL agent HIRO and find that
it is generally applicable and highly sample-efficient. Our experiments show
that HIRO can be used to learn highly complex behaviors for simulated robots,
such as pushing objects and utilizing them to reach target locations, learning
from only a few million samples, equivalent to a few days of real-time
interaction. In comparisons with a number of prior HRL methods, we find that
our approach substantially outperforms previous state-of-the-art techniques.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nachum_O/0/1/0/all/0/1&quot;&gt;Ofir Nachum&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gu_S/0/1/0/all/0/1&quot;&gt;Shane Gu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1&quot;&gt;Honglak Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1&quot;&gt;Sergey Levine&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08329">
<title>Guided Feature Transformation (GFT): A Neural Language Grounding Module for Embodied Agents. (arXiv:1805.08329v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1805.08329</link>
<description rdf:parseType="Literal">&lt;p&gt;Recently there has been a rising interest in training agents, embodied in
virtual environments, to perform language-directed tasks by deep reinforcement
learning. In this paper, we propose a simple but effective neural language
grounding module for embodied agents that can be trained end to end from
scratch taking raw pixels, unstructured linguistic commands, and sparse rewards
as the inputs. We model the language grounding process as a language-guided
transformation of visual features, where latent sentence embeddings are used as
the transformation matrices. In several language-directed navigation tasks that
feature challenging partial observation and require simple reasoning, our
module significantly outperforms the state of the arts. We also release XWORLD
3D, an easy-to-customize 3D environment that can potentially be modified to
evaluate a variety of embodied agents.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1&quot;&gt;Haonan Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lian_X/0/1/0/all/0/1&quot;&gt;Xiaochen Lian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1&quot;&gt;Haichao Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_W/0/1/0/all/0/1&quot;&gt;Wei Xu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08347">
<title>How To Solve Moral Conundrums with Computability Theory. (arXiv:1805.08347v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1805.08347</link>
<description rdf:parseType="Literal">&lt;p&gt;Various moral conundrums plague population ethics: The Non-Identity Problem,
The Procreation Asymmetry, The Repugnant Conclusion, and more. I argue that the
aforementioned moral conundrums have a structure neatly accounted for, and
solved by, some ideas in computability theory. I introduce a mathematical model
based on computability theory and show how previous arguments pertaining to
these conundrums fit into the model. This paper proceeds as follows. First, I
do a very brief survey of the history of computability theory in moral
philosophy. Second, I follow various papers, and show how their arguments fit
into, or don&apos;t fit into, our model. Third, I discuss the implications of our
model to the question why the human race should or should not continue to
exist. Finally, I show that our model ineluctably leads us to a Confucian moral
principle.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Baek_J/0/1/0/all/0/1&quot;&gt;Jongmin Jerome Baek&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08427">
<title>Bayesian Inference of Regular Expressions from Human-Generated Example Strings. (arXiv:1805.08427v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1805.08427</link>
<description rdf:parseType="Literal">&lt;p&gt;In programming by example, users &quot;write&quot; programs by generating a small
number of input-output examples and asking the computer to synthesize
consistent programs. We consider an unsolved problem in this domain: learning
regular expressions (regexes) from positive and negative example strings. This
problem is challenging, as (1) user-generated examples may not be informative
enough to sufficiently constrain the hypothesis space, and (2) even if
user-generated examples are in principle informative, there is still a massive
search space to examine. We frame regex induction as the problem of inferring a
probabilistic regular grammar and propose an efficient inference approach that
uses a novel stochastic process recognition model. This model incrementally
&quot;grows&quot; a grammar using positive examples as a scaffold. We show that this
approach is competitive with human ability to learn regexes from examples.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ouyang_L/0/1/0/all/0/1&quot;&gt;Long Ouyang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08440">
<title>Classification Uncertainty of Deep Neural Networks Based on Gradient Information. (arXiv:1805.08440v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.08440</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the quantification of uncertainty of Convolutional Neural Networks
(CNNs) based on gradient metrics. Unlike the classical softmax entropy, such
metrics gather information from all layers of the CNN. We show for the (E)MNIST
data set that for several such metrics we achieve the same meta classification
accuracy -- i.e. the task of classifying correctly predicted labels as correct
and incorrectly predicted ones as incorrect without knowing the actual label --
as for entropy thresholding. Meta classification rates for out of sample images
can be increased when using entropy together with several gradient based
metrics as input quantities for a meta-classifier. This proves that our
gradient based metrics do not contain the same information as the entropy. We
also apply meta classification to concepts not used during training:
EMNIST/Omniglot letters, CIFAR10 and noise. Meta classifiers only trained on
the uncertainty metrics of classes available during training usually do not
perform equally well for all the unknown concepts letters, CIFAR10 and uniform
noise. If we however allow the meta classifier to be trained on uncertainty
metrics including some samples of some or all of the categories, meta
classification for concepts remote from MNIST digits can be improved
considerably.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oberdiek_P/0/1/0/all/0/1&quot;&gt;Philipp Oberdiek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rottmann_M/0/1/0/all/0/1&quot;&gt;Matthias Rottmann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gottschalk_H/0/1/0/all/0/1&quot;&gt;Hanno Gottschalk&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08455">
<title>Context-Aware Sequence-to-Sequence Models for Conversational Systems. (arXiv:1805.08455v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1805.08455</link>
<description rdf:parseType="Literal">&lt;p&gt;This work proposes a novel approach based on sequence-to-sequence (seq2seq)
models for context-aware conversational systems. Exist- ing seq2seq models have
been shown to be good for generating natural responses in a data-driven
conversational system. However, they still lack mechanisms to incorporate
previous conversation turns. We investigate RNN-based methods that efficiently
integrate previous turns as a context for generating responses. Overall, our
experimental results based on human judgment demonstrate the feasibility and
effectiveness of the proposed approach.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Christensen_S/0/1/0/all/0/1&quot;&gt;Silje Christensen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Johnsrud_S/0/1/0/all/0/1&quot;&gt;Simen Johnsrud&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ruocco_M/0/1/0/all/0/1&quot;&gt;Massimiliano Ruocco&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ramampiaro_H/0/1/0/all/0/1&quot;&gt;Heri Ramampiaro&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08592">
<title>Computable Variants of AIXI which are More Powerful than AIXItl. (arXiv:1805.08592v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1805.08592</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents Unlimited Computable AI, or UCAI, that is a family of
computable variants of AIXI. UCAI is more powerful than AIXItl, that is a
conventional family of computable variants of AIXI, in the following ways: 1)
UCAI supports models of terminating computation, including typed lambda
calculus, while AIXItl only supports Turing machine with timeout t, which can
be simulated by typed lambda calculus for any t; 2) unlike UCAI, AIXItl limits
the program length to l.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Katayama_S/0/1/0/all/0/1&quot;&gt;Susumu Katayama&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08657">
<title>Robust Conditional Generative Adversarial Networks. (arXiv:1805.08657v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.08657</link>
<description rdf:parseType="Literal">&lt;p&gt;Conditional generative adversarial networks (cGAN) have led to large
improvements in the task of conditional image generation, which lies at the
heart of computer vision. The major focus so far has been on performance
improvement, while there has been little effort in making cGAN more robust to
noise or leveraging structure in the output space of the model. The end-to-end
regression (of the generator) might lead to arbitrarily large errors in the
output, which is unsuitable for the application of such networks to real-world
systems. In this work, we introduce a novel conditional GAN, called RoCGAN,
which adds implicit constraints to address the issue. Our proposed model
augments the generator with an unsupervised pathway, which encourages the
outputs of the generator to span the target manifold even in the presence of
large amounts of noise. We prove that RoCGAN shares similar theoretical
properties as GAN and experimentally verify that the proposed model outperforms
existing state-of-the-art cGAN architectures by a large margin in a variety of
domains including images from natural scenes and faces.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chrysos_G/0/1/0/all/0/1&quot;&gt;Grigorios G. Chrysos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kossaifi_J/0/1/0/all/0/1&quot;&gt;Jean Kossaifi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zafeiriou_S/0/1/0/all/0/1&quot;&gt;Stefanos Zafeiriou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.01244">
<title>Meta-Learning by Adjusting Priors Based on Extended PAC-Bayes Theory. (arXiv:1711.01244v5 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1711.01244</link>
<description rdf:parseType="Literal">&lt;p&gt;In meta-learning an agent extracts knowledge from observed tasks, aiming to
facilitate learning of novel future tasks. Under the assumption that future
tasks are &apos;related&apos; to previous tasks, representations should be learned in a
way which captures the common structure across learned tasks, while allowing
the learner sufficient flexibility to adapt to novel aspects of new tasks. We
present a framework for meta-learning that is based on generalization error
bounds, allowing us to extend various PAC-Bayes bounds to meta-learning.
Learning takes place through the construction of a distribution over hypotheses
based on the observed tasks, and its utilization for learning a new task. Thus,
prior knowledge is incorporated through setting an experience-dependent prior
for novel tasks. We develop a gradient-based algorithm which minimizes an
objective function derived from the bounds and demonstrate its effectiveness
numerically with deep neural networks. In addition to establishing the improved
performance available through meta-learning, we demonstrate the intuitive way
by which prior information is manifested at different levels of the network.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Amit_R/0/1/0/all/0/1&quot;&gt;Ron Amit&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Meir_R/0/1/0/all/0/1&quot;&gt;Ron Meir&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.06517">
<title>Wikipedia for Smart Machines and Double Deep Machine Learning. (arXiv:1711.06517v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1711.06517</link>
<description rdf:parseType="Literal">&lt;p&gt;Very important breakthroughs in data centric deep learning algorithms led to
impressive performance in transactional point applications of Artificial
Intelligence (AI) such as Face Recognition, or EKG classification. With all due
appreciation, however, knowledge blind data only machine learning algorithms
have severe limitations for non-transactional AI applications, such as medical
diagnosis beyond the EKG results. Such applications require deeper and broader
knowledge in their problem solving capabilities, e.g. integrating anatomy and
physiology knowledge with EKG results and other patient findings. Following a
review and illustrations of such limitations for several real life AI
applications, we point at ways to overcome them. The proposed Wikipedia for
Smart Machines initiative aims at building repositories of software structures
that represent humanity science &amp;amp; technology knowledge in various parts of
life; knowledge that we all learn in schools, universities and during our
professional life. Target readers for these repositories are smart machines;
not human. AI software developers will have these Reusable Knowledge structures
readily available, hence, the proposed name ReKopedia. Big Data is by now a
mature technology, it is time to focus on Big Knowledge. Some will be derived
from data, some will be obtained from mankind gigantic repository of knowledge.
Wikipedia for smart machines along with the new Double Deep Learning approach
offer a paradigm for integrating datacentric deep learning algorithms with
algorithms that leverage deep knowledge, e.g. evidential reasoning and
causality reasoning. For illustration, a project is described to produce
ReKopedia knowledge modules for medical diagnosis of about 1,000 disorders.
Data is important, but knowledge deep, basic, and commonsense is equally
important.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+BenBassat_M/0/1/0/all/0/1&quot;&gt;Moshe BenBassat&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.03885">
<title>OK Google, What Is Your Ontology? Or: Exploring Freebase Classification to Understand Google&apos;s Knowledge Graph. (arXiv:1805.03885v2 [cs.IR] UPDATED)</title>
<link>http://arxiv.org/abs/1805.03885</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper reconstructs the Freebase data dumps to understand the underlying
ontology behind Google&apos;s semantic search feature. The Freebase knowledge base
was a major Semantic Web and linked data technology that was acquired by Google
in 2010 to support the Google Knowledge Graph, the backend for Google search
results that include structured answers to queries instead of a series of links
to external resources. After its shutdown in 2016, Freebase is contained in a
data dump of 1.9 billion Resource Description Format (RDF) triples. A
recomposition of the Freebase ontology will be analyzed in relation to concepts
and insights from the literature on classification by Bowker and Star. This
paper will explore how the Freebase ontology is shaped by many of the forces
that also shape classification systems through a deep dive into the ontology
and a small correlational study. These findings will provide a glimpse into the
proprietary blackbox Knowledge Graph and what is meant by Google&apos;s mission to
&quot;organize the world&apos;s information and make it universally accessible and
useful&quot;.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chah_N/0/1/0/all/0/1&quot;&gt;Niel Chah&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1309.3699">
<title>Local Support Vector Machines:Formulation and Analysis. (arXiv:1309.3699v1 [stat.ML] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1309.3699</link>
<description rdf:parseType="Literal">&lt;p&gt;We provide a formulation for Local Support Vector Machines (LSVMs) that
generalizes previous formulations, and brings out the explicit connections to
local polynomial learning used in nonparametric estimation literature. We
investigate the simplest type of LSVMs called Local Linear Support Vector
Machines (LLSVMs). For the first time we establish conditions under which
LLSVMs make Bayes consistent predictions at each test point $x_0$. We also
establish rates at which the local risk of LLSVMs converges to the minimum
value of expected local risk at each point $x_0$. Using stability arguments we
establish generalization error bounds for LLSVMs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ganti_R/0/1/0/all/0/1&quot;&gt;Ravi Ganti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gray_A/0/1/0/all/0/1&quot;&gt;Alexander Gray&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08266">
<title>On the Selection of Initialization and Activation Function for Deep Neural Networks. (arXiv:1805.08266v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.08266</link>
<description rdf:parseType="Literal">&lt;p&gt;The weight initialization and the activation function of deep neural networks
have a crucial impact on the performance of the learning procedure. An
inappropriate selection can lead to the loss of information of the input during
forward propagation and the exponential vanishing/exploding of gradients during
back-propagation. Understanding the theoretical properties of untrained random
networks is key to identifying which deep networks may be trained successfully
as recently demonstrated by Schoenholz et al. (2017) who showed that for deep
feedforward neural networks only a specific choice of hyperparameters known as
the `edge of chaos&apos; can lead to good performance. We complete these recent
results by providing quantitative results showing that, for a class of
ReLU-like activation functions, the information propagates indeed deeper when
the network is initialized at the edge of chaos. By extending our analysis to a
larger class of functions, we then identify an activation function,
$\phi_{new}(x) = x \cdot \text{sigmoid}(x)$, which improves the information
propagation over ReLU-like functions and does not suffer from the vanishing
gradient problem. We demonstrate empirically that this activation function
combined to a random initialization on the edge of chaos outperforms standard
approaches. This complements recent independent work by Ramachandran et al.
(2017) who have observed empirically in extensive simulations that this
activation function performs better than many alternatives.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hayou_S/0/1/0/all/0/1&quot;&gt;Soufiane Hayou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Doucet_A/0/1/0/all/0/1&quot;&gt;Arnaud Doucet&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rousseau_J/0/1/0/all/0/1&quot;&gt;Judith Rousseau&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08318">
<title>Self-Attention Generative Adversarial Networks. (arXiv:1805.08318v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.08318</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we propose the Self-Attention Generative Adversarial Network
(SAGAN) which allows attention-driven, long-range dependency modeling for image
generation tasks. Traditional convolutional GANs generate high-resolution
details as a function of only spatially local points in lower-resolution
feature maps. In SAGAN, details can be generated using cues from all feature
locations. Moreover, the discriminator can check that highly detailed features
in distant portions of the image are consistent with each other. Furthermore,
recent work has shown that generator conditioning affects GAN performance.
Leveraging this insight, we apply spectral normalization to the GAN generator
and find that this improves training dynamics. The proposed SAGAN achieves the
state-of-the-art results, boosting the best published Inception score from 36.8
to 52.52 and reducing Frechet Inception distance from 27.62 to 18.65 on the
challenging ImageNet dataset. Visualization of the attention layers shows that
the generator leverages neighborhoods that correspond to object shapes rather
than local regions of fixed shape.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhang_H/0/1/0/all/0/1&quot;&gt;Han Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Goodfellow_I/0/1/0/all/0/1&quot;&gt;Ian Goodfellow&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Metaxas_D/0/1/0/all/0/1&quot;&gt;Dimitris Metaxas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Odena_A/0/1/0/all/0/1&quot;&gt;Augustus Odena&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08328">
<title>Verifiable Reinforcement Learning via Policy Extraction. (arXiv:1805.08328v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.08328</link>
<description rdf:parseType="Literal">&lt;p&gt;While deep reinforcement learning has successfully solved many challenging
control tasks, its real-world applicability has been limited by the inability
to ensure the safety of learned policies. We propose an approach to verifiable
reinforcement learning by training decision tree policies, which can represent
complex policies (since they are nonparametric), yet can be efficiently
verified using existing techniques (since they are highly structured). The
challenge is that decision tree policies are difficult to train. We propose
VIPER, an algorithm that combines ideas from model compression and imitation
learning to learn decision tree policies guided by a DNN policy (called the
oracle) and its Q-function, and show that it substantially outperforms two
baselines. We use VIPER to (i) learn a provably robust decision tree policy for
a variant of Atari Pong with a symbolic state space, (ii) learn a decision tree
policy for a toy game based on Pong that provably never loses, and (iii) learn
a provably stable decision tree policy for cart-pole. In each case, the
decision tree policy achieves performance equal to that of the original DNN
policy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bastani_O/0/1/0/all/0/1&quot;&gt;Osbert Bastani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pu_Y/0/1/0/all/0/1&quot;&gt;Yewen Pu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Solar_Lezama_A/0/1/0/all/0/1&quot;&gt;Armando Solar-Lezama&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08355">
<title>Opening the black box of deep learning. (arXiv:1805.08355v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.08355</link>
<description rdf:parseType="Literal">&lt;p&gt;The great success of deep learning shows that its technology contains
profound truth, and understanding its internal mechanism not only has important
implications for the development of its technology and effective application in
various fields, but also provides meaningful insights into the understanding of
human brain mechanism. At present, most of the theoretical research on deep
learning is based on mathematics. This dissertation proposes that the neural
network of deep learning is a physical system, examines deep learning from
three different perspectives: microscopic, macroscopic, and physical world
views, answers multiple theoretical puzzles in deep learning by using physics
principles. For example, from the perspective of quantum mechanics and
statistical physics, this dissertation presents the calculation methods for
convolution calculation, pooling, normalization, and Restricted Boltzmann
Machine, as well as the selection of cost functions, explains why deep learning
must be deep, what characteristics are learned in deep learning, why
Convolutional Neural Networks do not have to be trained layer by layer, and the
limitations of deep learning, etc., and proposes the theoretical direction and
basis for the further development of deep learning now and in the future. The
brilliance of physics flashes in deep learning, we try to establish the deep
learning technology based on the scientific theory of physics.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lei_D/0/1/0/all/0/1&quot;&gt;Dian Lei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1&quot;&gt;Xiaoxiao Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1&quot;&gt;Jianfei Zhao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08356">
<title>Improved Algorithms for Collaborative PAC Learning. (arXiv:1805.08356v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.08356</link>
<description rdf:parseType="Literal">&lt;p&gt;We study a recent model of collaborative PAC learning where $k$ players with
$k$ different tasks collaborate to learn a single classifier that works for all
tasks. Previous work showed that when there is a classifier that has very small
error on all tasks, there is a collaborative algorithm that finds a single
classifier for all tasks and it uses $O(\ln^2 (k))$ times the sample complexity
to learn a single task. In this work, we design new algorithms for both the
realizable and the non-realizable settings using only $O(\ln (k))$ times the
sample complexity to learn a single task. The sample complexity upper bounds of
our algorithms match previous lower bounds and in some range of parameters are
even better than previous algorithms that are allowed to output different
classifiers for different tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_H/0/1/0/all/0/1&quot;&gt;Huy L. Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zakynthinou_L/0/1/0/all/0/1&quot;&gt;Lydia Zakynthinou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08402">
<title>Adapted Deep Embeddings: A Synthesis of Methods for $k$-Shot Inductive Transfer Learning. (arXiv:1805.08402v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.08402</link>
<description rdf:parseType="Literal">&lt;p&gt;The focus in machine learning has branched beyond training classifiers on a
single task to investigating how previously acquired knowledge in a source
domain can be leveraged to facilitate learning in a related target domain,
known as inductive transfer learning. Three active lines of research have
independently explored transfer learning using neural networks. In weight
transfer, a model trained on the source domain is used as an initialization
point for a network to be trained on the target domain. In deep metric
learning, the source domain is used to construct an embedding that captures
class structure in both the source and target domains. In few-shot learning,
the focus is on generalizing well in the target domain based on a limited
number of labeled examples. We compare state-of-the-art methods from these
three paradigms and also explore hybrid adapted-embedding methods that use
limited target-domain data to fine tune embeddings constructed from
source-domain data. We conduct a systematic comparison of methods in a variety
of domains, varying the number of labeled instances available in the target
domain ($k$), as well as the number of target-domain classes. We reach three
principle conclusions: (1) Deep embeddings are far superior, compared to weight
transfer, as a starting point for inter-domain transfer or model re-use (2) Our
hybrid methods robustly outperform every few-shot learning and every deep
metric learning method previously proposed, with a mean error reduction of 30%
over state-of-the-art. (3) Among loss functions for discovering embeddings, the
histogram loss (Ustinova &amp;amp; Lempitsky, 2016) is most robust. We hope our results
will motivate a unification of research in weight transfer, deep metric
learning, and few-shot learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Scott_T/0/1/0/all/0/1&quot;&gt;Tyler R. Scott&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ridgeway_K/0/1/0/all/0/1&quot;&gt;Karl Ridgeway&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mozer_M/0/1/0/all/0/1&quot;&gt;Michael C. Mozer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08462">
<title>Meta-Learning with Hessian Free Approach in Deep Neural Nets Training. (arXiv:1805.08462v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.08462</link>
<description rdf:parseType="Literal">&lt;p&gt;Meta-learning is a promising method to achieve efficient training method
towards deep neural net and has been attracting increases interests in recent
years. But most of the current methods are still not capable to train complex
neuron net model with long-time training process. In this paper, a novel
second-order meta-optimizer, named Meta-learning with Hessian-Free(MLHF)
approach, is proposed based on the Hessian Free approach as the framework. Two
recurrent neural networks are established to generate the damping and the
precondition matrix of this Hessian free framework. A series of techniques to
meta-train the MLHF towards stable and reinforce the meta-training of this
optimizer, including the gradient calculation of $H$, and use experiment replay
on $w^0$. Numerical experiments on deep convolution neural nets, including
CUDA-convnet and resnet18(v2), with datasets of cifar10 and ILSVRC2012,
indicate that the MLHF shows good and continuous training performance during
the whole long-time training process, i.e., both the rapid-decreasing early
stage and the steadily-deceasing later stage, and so is a promising
meta-learning framework towards elevating the training efficiency in real-world
deep neural nets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1&quot;&gt;Boyu Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_W/0/1/0/all/0/1&quot;&gt;Wenlian Lu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08463">
<title>Variational Learning on Aggregate Outputs with Gaussian Processes. (arXiv:1805.08463v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.08463</link>
<description rdf:parseType="Literal">&lt;p&gt;While a typical supervised learning framework assumes that the inputs and the
outputs are measured at the same levels of granularity, many applications,
including global mapping of disease, only have access to outputs at a much
coarser level than that of the inputs. Aggregation of outputs makes
generalization to new inputs much more difficult. We consider an approach to
this problem based on variational learning with a model of output aggregation
and Gaussian processes, where aggregation leads to intractability of the
standard evidence lower bounds. We propose new bounds and tractable
approximations, leading to improved prediction accuracy and scalability to
large datasets, while explicitly taking uncertainty into account. We develop a
framework which extends to several types of likelihoods, including the Poisson
model for aggregated count data. We apply our framework to a challenging and
important problem, the fine-scale spatial modelling of malaria incidence, with
over 1 million observations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Law_H/0/1/0/all/0/1&quot;&gt;Ho Chung Leon Law&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sejdinovic_D/0/1/0/all/0/1&quot;&gt;Dino Sejdinovic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Cameron_E/0/1/0/all/0/1&quot;&gt;Ewan Cameron&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lucas_T/0/1/0/all/0/1&quot;&gt;Tim CD Lucas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Flaxman_S/0/1/0/all/0/1&quot;&gt;Seth Flaxman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Battle_K/0/1/0/all/0/1&quot;&gt;Katherine Battle&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Fukumizu_K/0/1/0/all/0/1&quot;&gt;Kenji Fukumizu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08465">
<title>Low-Rank Tensor Decomposition via Multiple Reshaping and Reordering Operations. (arXiv:1805.08465v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.08465</link>
<description rdf:parseType="Literal">&lt;p&gt;Tensor decomposition has been widely applied to find low-rank representations
for real-world data and more recently for neural-network parameters too. For
the latter, the unfolded matrices may not always be low-rank because the modes
of the parameter tensor do not usually have any physical meaning that can be
exploited for efficiency. This raises the following question: how can we find
low-rank structures when the tensor modes do not have any physical meaning
associated with them? For this purpose, we propose a new decomposition method
in this paper. Our method uses reshaping and reordering operations that are
strictly more general than the unfolding operation. These operations enable us
to discover new low-rank structures that are beyond the reach of existing
tensor methods. We prove an important theoretical result establishing
conditions under which our method results in a unique solution. The
experimental results confirm the correctness of our theoretical works and the
effectiveness of our methods for weight compression in deep neural networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1&quot;&gt;Chao Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khan_M/0/1/0/all/0/1&quot;&gt;Mohammad Emtiyaz Khan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_S/0/1/0/all/0/1&quot;&gt;Shengli Xie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_Q/0/1/0/all/0/1&quot;&gt;Qibin Zhao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08469">
<title>Gradient Energy Matching for Distributed Asynchronous Gradient Descent. (arXiv:1805.08469v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.08469</link>
<description rdf:parseType="Literal">&lt;p&gt;Distributed asynchronous SGD has become widely used for deep learning in
large-scale systems, but remains notorious for its instability when increasing
the number of workers. In this work, we study the dynamics of distributed
asynchronous SGD under the lens of Lagrangian mechanics. Using this
description, we introduce the concept of energy to describe the optimization
process and derive a sufficient condition ensuring its stability as long as the
collective energy induced by the active workers remains below the energy of a
target synchronous process. Making use of this criterion, we derive a stable
distributed asynchronous optimization procedure, GEM, that estimates and
maintains the energy of the asynchronous system below or equal to the energy of
sequential SGD with momentum. Experimental results highlight the stability and
speedup of GEM compared to existing schemes, even when scaling to one hundred
asynchronous workers. Results also indicate better generalization compared to
the targeted SGD with momentum.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hermans_J/0/1/0/all/0/1&quot;&gt;Joeri Hermans&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Louppe_G/0/1/0/all/0/1&quot;&gt;Gilles Louppe&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08490">
<title>Generative Code Modeling with Graphs. (arXiv:1805.08490v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.08490</link>
<description rdf:parseType="Literal">&lt;p&gt;Generative models for source code are an interesting structured prediction
problem, requiring to reason about both hard syntactic and semantic constraints
as well as about natural, likely programs. We present a novel model for this
problem that uses a graph to represent the intermediate state of the generated
output. The generative procedure interleaves grammar-driven expansion steps
with graph augmentation and neural message passing steps. An experimental
evaluation shows that our new model can generate semantically meaningful
expressions, outperforming a range of strong baselines.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brockschmidt_M/0/1/0/all/0/1&quot;&gt;Marc Brockschmidt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Allamanis_M/0/1/0/all/0/1&quot;&gt;Miltiadis Allamanis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gaunt_A/0/1/0/all/0/1&quot;&gt;Alexander L. Gaunt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Polozov_O/0/1/0/all/0/1&quot;&gt;Oleksandr Polozov&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08578">
<title>&quot;Why Should I Trust Interactive Learners?&quot; Explaining Interactive Queries of Classifiers to Users. (arXiv:1805.08578v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.08578</link>
<description rdf:parseType="Literal">&lt;p&gt;Although interactive learning puts the user into the loop, the learner
remains mostly a black box for the user. Understanding the reasons behind
queries and predictions is important when assessing how the learner works and,
in turn, trust. Consequently, we propose the novel framework of explanatory
interactive learning: in each step, the learner explains its interactive query
to the user, and she queries of any active classifier for visualizing
explanations of the corresponding predictions. We demonstrate that this can
boost the predictive and explanatory powers of and the trust into the learned
model, using text (e.g. SVMs) and image classification (e.g. neural networks)
experiments as well as a user study.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Teso_S/0/1/0/all/0/1&quot;&gt;Stefano Teso&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kersting_K/0/1/0/all/0/1&quot;&gt;Kristian Kersting&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08656">
<title>LMKL-Net: A Fast Localized Multiple Kernel Learning Solver via Deep Neural Networks. (arXiv:1805.08656v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.08656</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper we propose solving localized multiple kernel learning (LMKL)
using LMKL-Net, a feedforward deep neural network. In contrast to previous
works, as a learning principle we propose {\em parameterizing} both the gating
function for learning kernel combination weights and the multiclass classifier
in LMKL using an attentional network (AN) and a multilayer perceptron (MLP),
respectively. In this way we can learn the (nonlinear) decision function in
LMKL (approximately) by sequential applications of AN and MLP. Empirically on
benchmark datasets we demonstrate that overall LMKL-Net can not only outperform
the state-of-the-art MKL solvers in terms of accuracy, but also be trained
about {\em two orders of magnitude} faster with much smaller memory footprint
for large-scale learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhang_Z/0/1/0/all/0/1&quot;&gt;Ziming Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08671">
<title>Adding One Neuron Can Eliminate All Bad Local Minima. (arXiv:1805.08671v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.08671</link>
<description rdf:parseType="Literal">&lt;p&gt;One of the main difficulties in analyzing neural networks is the
non-convexity of the loss function which may have many bad local minima.
&lt;/p&gt;
&lt;p&gt;In this paper, we study the landscape of neural networks for binary
classification tasks. Under mild assumptions, we prove that after adding one
special neuron with a skip connection to the output, or one special neuron per
layer, every local minimum is a global minimum.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Liang_S/0/1/0/all/0/1&quot;&gt;Shiyu Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sun_R/0/1/0/all/0/1&quot;&gt;Ruoyu Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lee_J/0/1/0/all/0/1&quot;&gt;Jason D. Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Srikant_R/0/1/0/all/0/1&quot;&gt;R. Srikant&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08704">
<title>Replicating Active Appearance Model by Generator Network. (arXiv:1805.08704v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1805.08704</link>
<description rdf:parseType="Literal">&lt;p&gt;A recent Cell paper [Chang and Tsao, 2017] reports an interesting discovery.
For the face stimuli generated by a pre-trained active appearance model (AAM),
the responses of neurons in the areas of the primate brain that are responsible
for face recognition exhibit strong linear relationship with the shape
variables and appearance variables of the AAM that generates the face stimuli.
In this paper, we show that this behavior can be replicated by a deep
generative model called the generator network, which assumes that the observed
signals are generated by latent random variables via a top-down convolutional
neural network. Specifically, we learn the generator network from the face
images generated by a pre-trained AAM model using variational auto-encoder, and
we show that the inferred latent variables of the learned generator network
have strong linear relationship with the shape and appearance variables of the
AAM model that generates the face images. Unlike the AAM model that has an
explicit shape model where the shape variables generate the control points or
landmarks, the generator network has no such shape model and shape variables.
Yet the generator network can learn the shape knowledge in the sense that some
of the latent variables of the learned generator network capture the shape
variations in the face images generated by AAM.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Han_T/0/1/0/all/0/1&quot;&gt;Tian Han&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1&quot;&gt;Jiawen Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1&quot;&gt;Ying Nian Wu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08719">
<title>Parsimonious Bayesian deep networks. (arXiv:1805.08719v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.08719</link>
<description rdf:parseType="Literal">&lt;p&gt;Combining Bayesian nonparametrics and a forward model selection strategy, we
construct parsimonious Bayesian deep networks (PBDNs) that infer
capacity-regularized network architectures from the data and require neither
cross-validation nor fine-tuning when training the model. One of the two
essential components of a PBDN is the development of a special infinite-wide
single-hidden-layer neural network, whose number of active hidden units can be
inferred from the data. The other one is the construction of a greedy
layer-wise learning algorithm that uses a forward model selection criterion to
determine when to stop adding another hidden layer. We develop both Gibbs
sampling and stochastic gradient descent based maximum a posteriori inference
for PBDNs, providing state-of-the-art classification accuracy and interpretable
data subtypes near the decision boundaries, while maintaining low computational
complexity for out-of-sample prediction.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhou_M/0/1/0/all/0/1&quot;&gt;Mingyuan Zhou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08720">
<title>Adversarial Training of Word2Vec for Basket Completion. (arXiv:1805.08720v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.08720</link>
<description rdf:parseType="Literal">&lt;p&gt;In recent years, the Word2Vec model trained with the Negative Sampling loss
function has shown state-of-the-art results in a number of machine learning
tasks, including language modeling tasks, such as word analogy and word
similarity, and in recommendation tasks, through Prod2Vec, an extension that
applies to modeling user shopping activity and user preferences. Several
methods that aim to improve upon the standard Negative Sampling loss have been
proposed. In our paper we pursue more sophisticated Negative Sampling, by
leveraging ideas from the field of Generative Adversarial Networks (GANs), and
propose Adversarial Negative Sampling. We build upon the recent progress made
in stabilizing the training objective of GANs in the discrete data setting, and
introduce a new GAN-Word2Vec model.We evaluate our model on the task of basket
completion, and show significant improvements in performance over Word2Vec
trained using standard loss functions, including Noise Contrastive Estimation
and Negative Sampling.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tanielian_U/0/1/0/all/0/1&quot;&gt;Ugo Tanielian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gartrell_M/0/1/0/all/0/1&quot;&gt;Mike Gartrell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vasile_F/0/1/0/all/0/1&quot;&gt;Flavian Vasile&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08736">
<title>Adversarially Robust Training through Structured Gradient Regularization. (arXiv:1805.08736v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.08736</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a novel data-dependent structured gradient regularizer to increase
the robustness of neural networks vis-a-vis adversarial perturbations. Our
regularizer can be derived as a controlled approximation from first principles,
leveraging the fundamental link between training with noise and regularization.
It adds very little computational overhead during learning and is simple to
implement generically in standard deep learning frameworks. Our experiments
provide strong evidence that structured gradient regularization can act as an
effective first line of defense against attacks based on low-level signal
corruption.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Roth_K/0/1/0/all/0/1&quot;&gt;Kevin Roth&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lucchi_A/0/1/0/all/0/1&quot;&gt;Aurelien Lucchi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Nowozin_S/0/1/0/all/0/1&quot;&gt;Sebastian Nowozin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hofmann_T/0/1/0/all/0/1&quot;&gt;Thomas Hofmann&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08749">
<title>A Tropical Approach to Neural Networks with Piecewise Linear Activations. (arXiv:1805.08749v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.08749</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a new, unifying approach following some recent developments on the
complexity of neural networks with piecewise linear activations. We treat
neural network layers with piecewise linear activations, such as Maxout or ReLU
units, as polynomials in the $(\max, +)$ (or so-called tropical) algebra.
Following up on the work of Montufar et al. (&lt;a href=&quot;/abs/1402.1869&quot;&gt;arXiv:1402.1869&lt;/a&gt;), this approach
enables us to improve their upper bound on linear regions of layers with ReLU
or leaky ReLU activations to $\min \left\{ 2^m, 2 \cdot \sum_{j=0}^n \binom{m -
1}{j} \right\}$, where $n, m$ are the number of inputs and outputs,
respectively. Additionally, we recover their upper bounds on maxout layers. Our
work is parallel to the improvements reported in (&lt;a href=&quot;/abs/1711.02114&quot;&gt;arXiv:1711.02114&lt;/a&gt;,
&lt;a href=&quot;/abs/1611.01491&quot;&gt;arXiv:1611.01491&lt;/a&gt;), though exclusively under the lens of tropical geometry.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Charisopoulos_V/0/1/0/all/0/1&quot;&gt;Vasileios Charisopoulos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Maragos_P/0/1/0/all/0/1&quot;&gt;Petros Maragos&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1705.08292">
<title>The Marginal Value of Adaptive Gradient Methods in Machine Learning. (arXiv:1705.08292v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1705.08292</link>
<description rdf:parseType="Literal">&lt;p&gt;Adaptive optimization methods, which perform local optimization with a metric
constructed from the history of iterates, are becoming increasingly popular for
training deep neural networks. Examples include AdaGrad, RMSProp, and Adam. We
show that for simple overparameterized problems, adaptive methods often find
drastically different solutions than gradient descent (GD) or stochastic
gradient descent (SGD). We construct an illustrative binary classification
problem where the data is linearly separable, GD and SGD achieve zero test
error, and AdaGrad, Adam, and RMSProp attain test errors arbitrarily close to
half. We additionally study the empirical generalization capability of adaptive
methods on several state-of-the-art deep learning models. We observe that the
solutions found by adaptive methods generalize worse (often significantly
worse) than SGD, even when these solutions have better training performance.
These results suggest that practitioners should reconsider the use of adaptive
methods to train neural networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wilson_A/0/1/0/all/0/1&quot;&gt;Ashia C. Wilson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Roelofs_R/0/1/0/all/0/1&quot;&gt;Rebecca Roelofs&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Stern_M/0/1/0/all/0/1&quot;&gt;Mitchell Stern&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Srebro_N/0/1/0/all/0/1&quot;&gt;Nathan Srebro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Recht_B/0/1/0/all/0/1&quot;&gt;Benjamin Recht&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.07746">
<title>Stochastic Backward Euler: An Implicit Gradient Descent Algorithm for $k$-means Clustering. (arXiv:1710.07746v3 [math.OC] UPDATED)</title>
<link>http://arxiv.org/abs/1710.07746</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we propose an implicit gradient descent algorithm for the
classic $k$-means problem. The implicit gradient step or backward Euler is
solved via stochastic fixed-point iteration, in which we randomly sample a
mini-batch gradient in every iteration. It is the average of the fixed-point
trajectory that is carried over to the next gradient step. We draw connections
between the proposed stochastic backward Euler and the recent entropy
stochastic gradient descent (Entropy-SGD) for improving the training of deep
neural networks. Numerical experiments on various synthetic and real datasets
show that the proposed algorithm provides better clustering results compared to
$k$-means algorithms in the sense that it decreased the objective function (the
cluster) and is much more robust to initialization.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Yin_P/0/1/0/all/0/1&quot;&gt;Penghang Yin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Pham_M/0/1/0/all/0/1&quot;&gt;Minh Pham&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Oberman_A/0/1/0/all/0/1&quot;&gt;Adam Oberman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Osher_S/0/1/0/all/0/1&quot;&gt;Stanley Osher&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08195">
<title>Adversarial Examples that Fool both Computer Vision and Time-Limited Humans. (arXiv:1802.08195v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1802.08195</link>
<description rdf:parseType="Literal">&lt;p&gt;Machine learning models are vulnerable to adversarial examples: small changes
to images can cause computer vision models to make mistakes such as identifying
a school bus as an ostrich. However, it is still an open question whether
humans are prone to similar mistakes. Here, we address this question by
leveraging recent techniques that transfer adversarial examples from computer
vision models with known parameters and architecture to other models with
unknown parameters and architecture, and by matching the initial processing of
the human visual system. We find that adversarial examples that strongly
transfer across computer vision models influence the classifications made by
time-limited human observers.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Elsayed_G/0/1/0/all/0/1&quot;&gt;Gamaleldin F. Elsayed&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shankar_S/0/1/0/all/0/1&quot;&gt;Shreya Shankar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheung_B/0/1/0/all/0/1&quot;&gt;Brian Cheung&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Papernot_N/0/1/0/all/0/1&quot;&gt;Nicolas Papernot&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kurakin_A/0/1/0/all/0/1&quot;&gt;Alex Kurakin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goodfellow_I/0/1/0/all/0/1&quot;&gt;Ian Goodfellow&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sohl_Dickstein_J/0/1/0/all/0/1&quot;&gt;Jascha Sohl-Dickstein&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.07729">
<title>ADef: an Iterative Algorithm to Construct Adversarial Deformations. (arXiv:1804.07729v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1804.07729</link>
<description rdf:parseType="Literal">&lt;p&gt;While deep neural networks have proven to be a powerful tool for many
recognition and classification tasks, their stability properties are still not
well understood. In the past, image classifiers have been shown to be
vulnerable to so-called adversarial attacks, which are created by additively
perturbing the correctly classified image.
&lt;/p&gt;
&lt;p&gt;In this paper, we propose the ADef algorithm to construct a different kind of
adversarial attack created by iteratively applying small deformations to the
image, found through a gradient descent step. We demonstrate our results on
MNIST with a convolutional neural network and on ImageNet with Inception-v3 and
ResNet-101.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alaifari_R/0/1/0/all/0/1&quot;&gt;Rima Alaifari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alberti_G/0/1/0/all/0/1&quot;&gt;Giovanni S. Alberti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gauksson_T/0/1/0/all/0/1&quot;&gt;Tandri Gauksson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.04276">
<title>Leveraging Grammar and Reinforcement Learning for Neural Program Synthesis. (arXiv:1805.04276v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.04276</link>
<description rdf:parseType="Literal">&lt;p&gt;Program synthesis is the task of automatically generating a program
consistent with a specification. Recent years have seen proposal of a number of
neural approaches for program synthesis, many of which adopt a sequence
generation paradigm similar to neural machine translation, in which
sequence-to-sequence models are trained to maximize the likelihood of known
reference programs. While achieving impressive results, this strategy has two
key limitations. First, it ignores Program Aliasing: the fact that many
different programs may satisfy a given specification (especially with
incomplete specifications such as a few input-output examples). By maximizing
the likelihood of only a single reference program, it penalizes many
semantically correct programs, which can adversely affect the synthesizer
performance. Second, this strategy overlooks the fact that programs have a
strict syntax that can be efficiently checked. To address the first limitation,
we perform reinforcement learning on top of a supervised model with an
objective that explicitly maximizes the likelihood of generating semantically
correct programs. For addressing the second limitation, we introduce a training
procedure that directly maximizes the probability of generating syntactically
correct programs that fulfill the specification. We show that our contributions
lead to improved accuracy of the models, especially in cases where the training
data is limited.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bunel_R/0/1/0/all/0/1&quot;&gt;Rudy Bunel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hausknecht_M/0/1/0/all/0/1&quot;&gt;Matthew Hausknecht&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Devlin_J/0/1/0/all/0/1&quot;&gt;Jacob Devlin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singh_R/0/1/0/all/0/1&quot;&gt;Rishabh Singh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kohli_P/0/1/0/all/0/1&quot;&gt;Pushmeet Kohli&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07475">
<title>Learning to Repair Software Vulnerabilities with Generative Adversarial Networks. (arXiv:1805.07475v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1805.07475</link>
<description rdf:parseType="Literal">&lt;p&gt;Motivated by the problem of automated repair of software vulnerabilities, we
propose an adversarial learning approach that maps from one discrete source
domain to another target domain without requiring paired labeled examples or
source and target domains to be bijections. We demonstrate that the proposed
adversarial learning approach is an effective technique for repairing software
vulnerabilities, performing close to seq2seq approaches that require labeled
pairs. The proposed Generative Adversarial Network approach is
application-agnostic in that it can be applied to other problems similar to
code repair, such as grammar correction or sentiment translation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Harer_J/0/1/0/all/0/1&quot;&gt;Jacob Harer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ozdemir_O/0/1/0/all/0/1&quot;&gt;Onur Ozdemir&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lazovich_T/0/1/0/all/0/1&quot;&gt;Tomo Lazovich&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Reale_C/0/1/0/all/0/1&quot;&gt;Christopher P. Reale&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Russell_R/0/1/0/all/0/1&quot;&gt;Rebecca L. Russell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_L/0/1/0/all/0/1&quot;&gt;Louis Y. Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chin_P/0/1/0/all/0/1&quot;&gt;Peter Chin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07544">
<title>Conditional Network Embeddings. (arXiv:1805.07544v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1805.07544</link>
<description rdf:parseType="Literal">&lt;p&gt;Network embeddings map the nodes of a given network into $d$-dimensional
Euclidean space $\mathbb{R}^d$. Ideally, this mapping is such that `similar&apos;
nodes are mapped onto nearby points, such that the embedding can be used for
purposes such as link prediction (if `similar&apos; means being `more likely to be
connected&apos;) or classification (if `similar&apos; means `being more likely to have
the same label&apos;).
&lt;/p&gt;
&lt;p&gt;In recent years various methods for network embedding have been introduced.
These methods all follow a similar strategy, defining a notion of similarity
between nodes (typically deeming nodes more similar if they are nearby in the
network in some metric), a distance measure in the embedding space, and
minimizing a loss function that penalizes large distances for similar nodes or
small distances for dissimilar nodes.
&lt;/p&gt;
&lt;p&gt;A difficulty faced by existing methods is that certain networks are
fundamentally hard to embed due to their structural properties, such as
(approximate) multipartiteness, certain degree distributions, or certain kinds
of assortativity. Overcoming this difficulty, we introduce a conceptual
innovation to the literature on network embedding, proposing to create
embeddings that maximally add information with respect to such structural
properties (e.g. node degrees, block densities, etc.). We use a simple Bayesian
approach to achieve this, and propose a block stochastic gradient descent
algorithm for fitting it efficiently.
&lt;/p&gt;
&lt;p&gt;Finally, we demonstrate that the combination of information such structural
properties and a Euclidean embedding provides superior performance across a
range of link prediction tasks. Moreover, we demonstrate the potential of our
approach for network visualization.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kang_B/0/1/0/all/0/1&quot;&gt;Bo Kang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lijffijt_J/0/1/0/all/0/1&quot;&gt;Jefrey Lijffijt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bie_T/0/1/0/all/0/1&quot;&gt;Tijl De Bie&lt;/a&gt;</dc:creator>
</item></rdf:RDF>