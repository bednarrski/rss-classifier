<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Good papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Good Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-02-07T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.02172"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.02186"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.02209"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.02353"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.02511"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.02147"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.02212"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.02226"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.02436"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.02498"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.02547"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.02548"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1705.10843"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.01768"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.01448"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.01212"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1802.02172">
<title>Augmented Artificial Intelligence. (arXiv:1802.02172v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.02172</link>
<description rdf:parseType="Literal">&lt;p&gt;All artificial Intelligence (AI) systems make errors. These errors are
unexpected, and differ often from the typical human mistakes (&quot;non-human&quot;
errors). The AI errors should be corrected without damage of existing skills
and, hopefully, avoiding direct human expertise. This talk presents an initial
summary report of project taking new and systematic approach to improving the
intellectual effectiveness of the individual AI by communities of AIs. We
combine some ideas of learning in heterogeneous multiagent systems with new and
original mathematical approaches for non-iterative corrections of errors of
legacy AI systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gorban_A/0/1/0/all/0/1&quot;&gt;Alexander N. Gorban&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tyukin_I/0/1/0/all/0/1&quot;&gt;Ivan Y. Tyukin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.02186">
<title>FastNet. (arXiv:1802.02186v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1802.02186</link>
<description rdf:parseType="Literal">&lt;p&gt;Inception and the Resnet family of Convolutional Neural Network
archi-tectures have broken records in the past few years, but recent state of
the art models have also incurred very high computational cost in terms of
training, inference and model size. Making the deployment of these models on
Edge devices, impractical. In light of this, we present a new novel
architecture that is designed for high computational efficiency on both GPUs
and CPUs, and is highly suited for deployment on Mobile Applications, Smart
Cameras, Iot devices and controllers as well as low cost drones. Our
architecture boasts competitive accuracies on standard Datasets even
out-performing the original Resnet. We present below the motivation for this
research, the architecture of the network, single test accuracies on CIFAR 10
and CIFAR 100 , a detailed comparison with other well-known architectures and
link to an implementation in Keras.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Olafenwa_J/0/1/0/all/0/1&quot;&gt;John Olafenwa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Olafenwa_M/0/1/0/all/0/1&quot;&gt;Moses Olafenwa&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.02209">
<title>IONet: Learning to Cure the Curse of Drift in Inertial Odometry. (arXiv:1802.02209v1 [cs.RO])</title>
<link>http://arxiv.org/abs/1802.02209</link>
<description rdf:parseType="Literal">&lt;p&gt;Inertial sensors play a pivotal role in indoor localization, which in turn
lays the foundation for pervasive personal applications. However, low-cost
inertial sensors, as commonly found in smartphones, are plagued by bias and
noise, which leads to unbounded growth in error when accelerations are double
integrated to obtain displacement. Small errors in state estimation propagate
to make odometry virtually unusable in a matter of seconds. We propose to break
the cycle of continuous integration, and instead segment inertial data into
independent windows. The challenge becomes estimating the latent states of each
window, such as velocity and orientation, as these are not directly observable
from sensor data. We demonstrate how to formulate this as an optimization
problem, and show how deep recurrent neural networks can yield highly accurate
trajectories, outperforming state-of-the-art shallow techniques, on a wide
range of tests and attachments. In particular, we demonstrate that IONet can
generalize to estimate odometry for non-periodic motion, such as a shopping
trolley or baby-stroller, an extremely challenging task for existing
techniques.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1&quot;&gt;Changhao Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_X/0/1/0/all/0/1&quot;&gt;Xiaoxuan Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Markham_A/0/1/0/all/0/1&quot;&gt;Andrew Markham&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Trigoni_N/0/1/0/all/0/1&quot;&gt;Niki Trigoni&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.02353">
<title>Recent Advances in Neural Program Synthesis. (arXiv:1802.02353v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.02353</link>
<description rdf:parseType="Literal">&lt;p&gt;In recent years, deep learning has made tremendous progress in a number of
fields that were previously out of reach for artificial intelligence. The
successes in these problems has led researchers to consider the possibilities
for intelligent systems to tackle a problem that humans have only recently
themselves considered: program synthesis. This challenge is unlike others such
as object recognition and speech translation, since its abstract nature and
demand for rigor make it difficult even for human minds to attempt. While it is
still far from being solved or even competitive with most existing methods,
neural program synthesis is a rapidly growing discipline which holds great
promise if completely realized. In this paper, we start with exploring the
problem statement and challenges of program synthesis. Then, we examine the
fascinating evolution of program induction models, along with how they have
succeeded, failed and been reimagined since. Finally, we conclude with a
contrastive look at program synthesis and future research recommendations for
the field.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kant_N/0/1/0/all/0/1&quot;&gt;Neel Kant&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.02511">
<title>DeepHeart: Semi-Supervised Sequence Learning for Cardiovascular Risk Prediction. (arXiv:1802.02511v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.02511</link>
<description rdf:parseType="Literal">&lt;p&gt;We train and validate a semi-supervised, multi-task LSTM on 57,675
person-weeks of data from off-the-shelf wearable heart rate sensors, showing
high accuracy at detecting multiple medical conditions, including diabetes
(0.8451), high cholesterol (0.7441), high blood pressure (0.8086), and sleep
apnea (0.8298). We compare two semi-supervised train- ing methods,
semi-supervised sequence learning and heuristic pretraining, and show they
outperform hand-engineered biomarkers from the medical literature. We believe
our work suggests a new approach to patient risk stratification based on
cardiovascular risk scores derived from popular wearables such as Fitbit, Apple
Watch, or Android Wear.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ballinger_B/0/1/0/all/0/1&quot;&gt;Brandon Ballinger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hsieh_J/0/1/0/all/0/1&quot;&gt;Johnson Hsieh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1&quot;&gt;Avesh Singh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sohoni_N/0/1/0/all/0/1&quot;&gt;Nimit Sohoni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jack Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tison_G/0/1/0/all/0/1&quot;&gt;Geoffrey H. Tison&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Marcus_G/0/1/0/all/0/1&quot;&gt;Gregory M. Marcus&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sanchez_J/0/1/0/all/0/1&quot;&gt;Jose M. Sanchez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Maguire_C/0/1/0/all/0/1&quot;&gt;Carol Maguire&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Olgin_J/0/1/0/all/0/1&quot;&gt;Jeffrey E. Olgin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pletcher_M/0/1/0/all/0/1&quot;&gt;Mark J. Pletcher&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.02147">
<title>DeepTravel: a Neural Network Based Travel Time Estimation Model with Auxiliary Supervision. (arXiv:1802.02147v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.02147</link>
<description rdf:parseType="Literal">&lt;p&gt;Estimating the travel time of a path is of great importance to smart urban
mobility. Existing approaches are either based on estimating the time cost of
each road segment which are not able to capture many cross-segment complex
factors, or designed heuristically in a non-learning-based way which fail to
utilize the existing abundant temporal labels of the data, i.e., the time stamp
of each trajectory point. In this paper, we leverage on new development of deep
neural networks and propose a novel auxiliary supervision model, namely
DeepTravel, that can automatically and effectively extract different features,
as well as make full use of the temporal labels of the trajectory data. We have
conducted comprehensive experiments on real datasets to demonstrate the
out-performance of DeepTravel over existing approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1&quot;&gt;Hanyuan Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_H/0/1/0/all/0/1&quot;&gt;Hao Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_W/0/1/0/all/0/1&quot;&gt;Weiwei Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_B/0/1/0/all/0/1&quot;&gt;Baihua Zheng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.02212">
<title>Classification and Disease Localization in Histopathology Using Only Global Labels: A Weakly-Supervised Approach. (arXiv:1802.02212v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1802.02212</link>
<description rdf:parseType="Literal">&lt;p&gt;Analysis of histopathology slides is a critical step for many diagnoses, and
in particular in oncology where it defines the gold standard. In the case of
digital histopathological analysis, highly trained pathologists must review
vast whole-slide-images of extreme digital resolution ($100,000^2$ pixels)
across multiple zoom levels in order to locate abnormal regions of cells, or in
some cases single cells, out of millions. The application of deep learning to
this problem is hampered not only by small sample sizes, as typical datasets
contain only a few hundred samples, but also by the generation of ground-truth
localized annotations for training interpretable classification and
segmentation models. We propose a method for disease localization in the
context of weakly supervised learning, where only image-level labels are
available during training. Even without pixel-level annotations, we are able to
demonstrate performance comparable with models trained with strong annotations
on the Camelyon-16 lymph node metastases detection challenge. We accomplish
this through the use of pre-trained deep convolutional networks, feature
embedding, as well as learning via top instances and negative evidence, a
multiple instance learning technique from the field of semantic segmentation
and object detection.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Courtiol_P/0/1/0/all/0/1&quot;&gt;Pierre Courtiol&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tramel_E/0/1/0/all/0/1&quot;&gt;Eric W. Tramel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sanselme_M/0/1/0/all/0/1&quot;&gt;Marc Sanselme&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wainrib_G/0/1/0/all/0/1&quot;&gt;Gilles Wainrib&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.02226">
<title>Generative Adversarial Networks using Adaptive Convolution. (arXiv:1802.02226v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1802.02226</link>
<description rdf:parseType="Literal">&lt;p&gt;Most existing GANs architectures that generate images use transposed
convolution or resize-convolution as their upsampling algorithm from lower to
higher resolution feature maps in the generator. We argue that this kind of
fixed operation is problematic for GANs to model objects that have very
different visual appearances. We propose a novel adaptive convolution method
that learns the upsampling algorithm based on the local context at each
location to address this problem. We modify a baseline GANs architecture by
replacing normal convolutions with adaptive convolutions in the generator.
Experiments on CIFAR-10 dataset show that our modified models improve the
baseline model by a large margin. Furthermore, our models achieve
state-of-the-art performance on CIFAR-10 and STL-10 datasets in the
unsupervised setting.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_N/0/1/0/all/0/1&quot;&gt;Nhat M. Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ray_N/0/1/0/all/0/1&quot;&gt;Nilanjan Ray&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.02436">
<title>Stochastic Deconvolutional Neural Network Ensemble Training on Generative Pseudo-Adversarial Networks. (arXiv:1802.02436v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.02436</link>
<description rdf:parseType="Literal">&lt;p&gt;The training of Generative Adversarial Networks is a difficult task mainly
due to the nature of the networks. One such issue is when the generator and
discriminator start oscillating, rather than converging to a fixed point.
Another case can be when one agent becomes more adept than the other which
results in the decrease of the other agent&apos;s ability to learn, reducing the
learning capacity of the system as a whole. Additionally, there exists the
problem of Mode Collapse which involves the generators output collapsing to a
single sample or a small set of similar samples. To train GANs a careful
selection of the architecture that is used along with a variety of other
methods to improve training. Even when applying these methods there is low
stability of training in relation to the parameters that are chosen. Stochastic
ensembling is suggested as a method for improving the stability while training
GANs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chaplygin_A/0/1/0/all/0/1&quot;&gt;Alexey Chaplygin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chacksfield_J/0/1/0/all/0/1&quot;&gt;Joshua Chacksfield&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.02498">
<title>Spectral Learning of Binomial HMMs for DNA Methylation Data. (arXiv:1802.02498v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.02498</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider learning parameters of Binomial Hidden Markov Models, which may
be used to model DNA methylation data. The standard algorithm for the problem
is EM, which is computationally expensive for sequences of the scale of the
mammalian genome. Recently developed spectral algorithms can learn parameters
of latent variable models via tensor decomposition, and are highly efficient
for large data. However, these methods have only been applied to categorial
HMMs, and the main challenge is how to extend them to Binomial HMMs while still
retaining computational efficiency. We address this challenge by introducing a
new feature-map based approach that exploits specific properties of Binomial
HMMs. We provide theoretical performance guarantees for our algorithm and
evaluate it on real DNA methylation data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1&quot;&gt;Chicheng Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mukamel_E/0/1/0/all/0/1&quot;&gt;Eran A. Mukamel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chaudhuri_K/0/1/0/all/0/1&quot;&gt;Kamalika Chaudhuri&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.02547">
<title>Learning One Convolutional Layer with Overlapping Patches. (arXiv:1802.02547v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.02547</link>
<description rdf:parseType="Literal">&lt;p&gt;We give the first provably efficient algorithm for learning a one hidden
layer convolutional network with respect to a general class of (potentially
overlapping) patches. Additionally, our algorithm requires only mild conditions
on the underlying distribution. We prove that our framework captures commonly
used schemes from computer vision, including one-dimensional and
two-dimensional &quot;patch and stride&quot; convolutions.
&lt;/p&gt;
&lt;p&gt;Our algorithm-- $Convotron$ -- is inspired by recent work applying isotonic
regression to learning neural networks. Convotron uses a simple, iterative
update rule that is stochastic in nature and tolerant to noise (requires only
that the conditional mean function is a one layer convolutional network, as
opposed to the realizable setting). In contrast to gradient descent, Convotron
requires no special initialization or learning-rate tuning to converge to the
global optimum.
&lt;/p&gt;
&lt;p&gt;We also point out that learning one hidden convolutional layer with respect
to a Gaussian distribution and just $one$ disjoint patch $P$ (the other patches
may be arbitrary) is $easy$ in the following sense: Convotron can efficiently
recover the hidden weight vector by updating $only$ in the direction of $P$.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goel_S/0/1/0/all/0/1&quot;&gt;Surbhi Goel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Klivans_A/0/1/0/all/0/1&quot;&gt;Adam Klivans&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meka_R/0/1/0/all/0/1&quot;&gt;Raghu Meka&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.02548">
<title>Predicting Hurricane Trajectories using a Recurrent Neural Network. (arXiv:1802.02548v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.02548</link>
<description rdf:parseType="Literal">&lt;p&gt;Hurricanes are cyclones circulating about a defined center whose closed wind
speeds exceed 75 mph originating over tropical and subtropical waters. At
landfall, hurricanes can result in severe disasters. The accuracy of predicting
their trajectory paths is critical to reduce economic loss and save human
lives. Given the complexity and nonlinearity of weather data, a recurrent
neural network (RNN) could be beneficial in modeling hurricane behavior. We
propose the application of a fully connected RNN to predict the trajectory of
hurricanes. We employed the RNN over a fine grid to reduce typical truncation
errors. We utilized their latitude, longitude, wind speed, and pressure
publicly provided by the National Hurricane Center (NOAA) to predict the
trajectory of a hurricane at 6-hour intervals.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alemany_S/0/1/0/all/0/1&quot;&gt;Sheila Alemany&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Beltran_J/0/1/0/all/0/1&quot;&gt;Jonathan Beltran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Perez_A/0/1/0/all/0/1&quot;&gt;Adrian Perez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ganzfried_S/0/1/0/all/0/1&quot;&gt;Sam Ganzfried&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1705.10843">
<title>Objective-Reinforced Generative Adversarial Networks (ORGAN) for Sequence Generation Models. (arXiv:1705.10843v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1705.10843</link>
<description rdf:parseType="Literal">&lt;p&gt;In unsupervised data generation tasks, besides the generation of a sample
based on previous observations, one would often like to give hints to the model
in order to bias the generation towards desirable metrics. We propose a method
that combines Generative Adversarial Networks (GANs) and reinforcement learning
(RL) in order to accomplish exactly that. While RL biases the data generation
process towards arbitrary metrics, the GAN component of the reward function
ensures that the model still remembers information learned from data. We build
upon previous results that incorporated GANs and RL in order to generate
sequence data and test this model in several settings for the generation of
molecules encoded as text sequences (SMILES) and in the context of music
generation, showing for each case that we can effectively bias the generation
process towards desired metrics.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Guimaraes_G/0/1/0/all/0/1&quot;&gt;Gabriel Lima Guimaraes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sanchez_Lengeling_B/0/1/0/all/0/1&quot;&gt;Benjamin Sanchez-Lengeling&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Outeiral_C/0/1/0/all/0/1&quot;&gt;Carlos Outeiral&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Farias_P/0/1/0/all/0/1&quot;&gt;Pedro Luis Cunha Farias&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Aspuru_Guzik_A/0/1/0/all/0/1&quot;&gt;Al&amp;#xe1;n Aspuru-Guzik&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.01768">
<title>Whitening Black-Box Neural Networks. (arXiv:1711.01768v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1711.01768</link>
<description rdf:parseType="Literal">&lt;p&gt;Many deployed learned models are black boxes: given input, returns output.
Internal information about the model, such as the architecture, optimisation
procedure, or training data, is not disclosed explicitly as it might contain
proprietary information or make the system more vulnerable. This work shows
that such attributes of neural networks can be exposed from a sequence of
queries. This has multiple implications. On the one hand, our work exposes the
vulnerability of black-box neural networks to different types of attacks -- we
show that the revealed internal information helps generate more effective
adversarial examples against the black box model. On the other hand, this
technique can be used for better protection of private content from automatic
recognition models using adversarial examples. Our paper suggests that it is
actually hard to draw a line between white box and black box models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Oh_S/0/1/0/all/0/1&quot;&gt;Seong Joon Oh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Augustin_M/0/1/0/all/0/1&quot;&gt;Max Augustin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Schiele_B/0/1/0/all/0/1&quot;&gt;Bernt Schiele&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Fritz_M/0/1/0/all/0/1&quot;&gt;Mario Fritz&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.01448">
<title>Hardening Deep Neural Networks via Adversarial Model Cascades. (arXiv:1802.01448v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1802.01448</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep neural networks (DNNs) have been shown to be vulnerable to adversarial
examples - malicious inputs which are crafted by the adversary to induce the
trained model to produce erroneous outputs. This vulnerability has inspired a
lot of research on how to secure neural networks against these kinds of
attacks. Although existing techniques increase the robustness of the models
against white-box attacks, they are ineffective against black-box attacks.
&lt;/p&gt;
&lt;p&gt;To address the challenge of black-box adversarial attacks, we propose
Adversarial Model Cascades (AMC); a framework that performs better than
existing state-of-the-art defenses, in both black-box and white-box settings
and is easy to integrate into existing set-ups. Our approach trains a cascade
of models by injecting images crafted from an already defended proxy model, to
improve the robustness of the target models against multiple adversarial
attacks simultaneously, in both white-box and black-box settings. We conducted
an extensive experimental study to prove the efficiency of our method against
multiple attacks; comparing it to numerous defenses, both in white-box and
black-box setups.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vijaykeerthy_D/0/1/0/all/0/1&quot;&gt;Deepak Vijaykeerthy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Suri_A/0/1/0/all/0/1&quot;&gt;Anshuman Suri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mehta_S/0/1/0/all/0/1&quot;&gt;Sameep Mehta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kumaraguru_P/0/1/0/all/0/1&quot;&gt;Ponnurangam Kumaraguru&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.01212">
<title>Non-Gaussian information from weak lensing data via deep learning. (arXiv:1802.01212v2 [astro-ph.CO] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1802.01212</link>
<description rdf:parseType="Literal">&lt;p&gt;Weak lensing maps contain information beyond two-point statistics on small
scales. Much recent work has tried to extract this information through a range
of different observables or via nonlinear transformations of the lensing field.
Here we train and apply a 2D convolutional neural network to simulated
noiseless lensing maps covering 96 different cosmological models over a range
of {$\Omega_m,\sigma_8$}. Using the area of the confidence contour in the
{$\Omega_m,\sigma_8$} plane as a figure-of-merit, derived from simulated
convergence maps smoothed on a scale of 1.0 arcmin, we show that the neural
network yields $\approx 5 \times$ tighter constraints than the power spectrum,
and $\approx 4 \times$ tighter than the lensing peaks. Such gains illustrate
the extent to which weak lensing data encode cosmological information not
accessible to the power spectrum or even non-Gaussian statistics such as
lensing peaks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Gupta_A/0/1/0/all/0/1&quot;&gt;Arushi Gupta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Matilla_J/0/1/0/all/0/1&quot;&gt;Jos&amp;#xe9; Manuel Zorrilla Matilla&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Hsu_D/0/1/0/all/0/1&quot;&gt;Daniel Hsu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Haiman_Z/0/1/0/all/0/1&quot;&gt;Zolt&amp;#xe1;n Haiman&lt;/a&gt;</dc:creator>
</item></rdf:RDF>