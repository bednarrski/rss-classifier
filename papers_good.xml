<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Good papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Good Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-07-29T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.10698"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.10454"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.10511"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.10587"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.10643"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1707.08114"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.10363"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.10117"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.10422"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.10478"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.10570"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.10572"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.10574"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.10583"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.10634"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.10668"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.10675"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.10681"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.10695"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.08518"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.09902"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1807.10698">
<title>Quantized Hodgkin-Huxley Model for Quantum Neurons. (arXiv:1807.10698v1 [quant-ph])</title>
<link>http://arxiv.org/abs/1807.10698</link>
<description rdf:parseType="Literal">&lt;p&gt;The Hodgkin-Huxley model describes the behavior of the membrane voltage in
neurons, treating each element of the cell membrane as an electric circuit
element, namely capacitors, memristors and voltage sources. We focus on the
activation channel of potassium ions, since it is simpler, while keeping the
majority of the features identified with the original model. This
simplification is physiologically meaningful, since it is related to some
neurodegenerative and autoimmune diseases, which are associated with a process
of demyelination in neurons. This model reduces to a memristor, a resistor
whose resistance depends on the history of charges crossing it, coupled to a
voltage source and a capacitor. Here, we use the recent quantization of the
memristor to glance at the Hodgkin-Huxley model in the quantum regime. We
compare the behavior of the potassium channel conductance in both the classical
and quantum realm. In the latter, we firstly introduce classical sources to
study the quantum-classical transition, and afterwards we switch to coherent
quantum sources in order to study the effects of entanglement. Numerical
simulations show an increment and adaptation depending on the history of
signals. Additionally, the response to AC sources showcases hysteretic behavior
in the I-V characteristic curve due to the presence of the memristor. We
investigate the memory capacitance represented by the area of the I-V loops,
which we call memory persistence. We find that it grows with entanglement,
which can be interpreted in terms of the fundamental relation between
information and thermodynamic entropies established by Landauer&apos;s principle.
These results pave the way for the construction of quantum neuron networks
inspired in the brain but capable of dealing with quantum information, a step
forward towards the design of neuromorphic quantum architectures with
implications in quantum machine learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Cheng_X/0/1/0/all/0/1&quot;&gt;Xiao-Hang Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Gonzalez_Raya_T/0/1/0/all/0/1&quot;&gt;Tasio Gonzalez-Raya&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Chen_X/0/1/0/all/0/1&quot;&gt;Xi Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Sanz_M/0/1/0/all/0/1&quot;&gt;Mikel Sanz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Solano_E/0/1/0/all/0/1&quot;&gt;Enrique Solano&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.10454">
<title>From Adversarial Training to Generative Adversarial Networks. (arXiv:1807.10454v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.10454</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we are interested in two seemingly different concepts:
\textit{adversarial training} and \textit{generative adversarial networks
(GANs)}. Particularly, how these techniques help to improve each other. To this
end, we analyze the limitation of adversarial training as the defense method,
starting from questioning how well the robustness of a model can generalize.
Then, we successfully improve the generalizability via data augmentation by the
``fake&apos;&apos; images sampled from generative adversarial networks. After that, we
are surprised to see that the resulting robust classifier leads to a better
generator, for free. We intuitively explain this interesting phenomenon and
leave the theoretical analysis for future work. Motivated by these
observations, we propose a system that combines generator, discriminator, and
adversarial attacker in a single network. After end-to-end training and fine
tuning, our method can simultaneously improve the robustness of classifiers,
measured by accuracy under strong adversarial attacks; and the quality of
generators, evaluated both aesthetically and quantitatively. In terms of the
classifier, we achieve better robustness than the state-of-the-art adversarial
training algorithm proposed in (Madry etla., 2017), while our generator
achieves competitive performance compared with SN-GAN (Miyato and Koyama,
2018). Source code is publicly available online at
\url{https://github.com/anonymous}.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1&quot;&gt;Xuanqing Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hsieh_C/0/1/0/all/0/1&quot;&gt;Cho-Jui Hsieh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.10511">
<title>Global and local evaluation of link prediction tasks with neural embeddings. (arXiv:1807.10511v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1807.10511</link>
<description rdf:parseType="Literal">&lt;p&gt;We focus our attention on the link prediction problem for knowledge graphs,
which is treated herein as a binary classification task on neural embeddings of
the entities. By comparing, combining and extending different methodologies for
link prediction on graph-based data coming from different domains, we formalize
a unified methodology for the quality evaluation benchmark of neural embeddings
for knowledge graphs. This benchmark is then used to empirically investigate
the potential of training neural embeddings globally for the entire graph, as
opposed to the usual way of training embeddings locally for a specific
relation. This new way of testing the quality of the embeddings evaluates the
performance of binary classifiers for scalable link prediction with limited
data. Our evaluation pipeline is made open source, and with this we aim to draw
more attention of the community towards an important issue of transparency and
reproducibility of the neural embeddings evaluations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Agibetov_A/0/1/0/all/0/1&quot;&gt;Asan Agibetov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Samwald_M/0/1/0/all/0/1&quot;&gt;Matthias Samwald&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.10587">
<title>Finding any Waldo: zero-shot invariant and efficient visual search. (arXiv:1807.10587v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1807.10587</link>
<description rdf:parseType="Literal">&lt;p&gt;Searching for a target object in a cluttered scene constitutes a fundamental
challenge in daily vision. Visual search must be selective enough to
discriminate the target from distractors, invariant to changes in the
appearance of the target, efficient to avoid exhaustive exploration of the
image, and must generalize to locate novel target objects with zero-shot
training. Previous work has focused on searching for perfect matches of a
target after extensive category-specific training. Here we show for the first
time that humans can efficiently and invariantly search for natural objects in
complex scenes. To gain insight into the mechanisms that guide visual search,
we propose a biologically inspired computational model that can locate targets
without exhaustive sampling and generalize to novel objects. The model provides
an approximation to the mechanisms integrating bottom-up and top-down signals
during search in natural scenes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1&quot;&gt;Mengmi Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1&quot;&gt;Jiashi Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_K/0/1/0/all/0/1&quot;&gt;Keng Teck Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lim_J/0/1/0/all/0/1&quot;&gt;Joo Hwee Lim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_Q/0/1/0/all/0/1&quot;&gt;Qi Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kreiman_G/0/1/0/all/0/1&quot;&gt;Gabriel Kreiman&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.10643">
<title>Experimental Implementation of a Quantum Autoencoder via Quantum Adders. (arXiv:1807.10643v1 [quant-ph])</title>
<link>http://arxiv.org/abs/1807.10643</link>
<description rdf:parseType="Literal">&lt;p&gt;Quantum autoencoders allow for reducing the amount of resources in a quantum
computation by mapping the original Hilbert space onto a reduced space with the
relevant information. Recently, it was proposed to employ approximate quantum
adders to implement quantum autoencoders in quantum technologies. Here, we
carry out the experimental implementation of this proposal in the Rigetti cloud
quantum computer employing up to three qubits. The experimental fidelities are
in good agreement with the theoretical prediction, thus proving the feasibility
to realize quantum autoencoders via quantum adders in state-of-the-art
superconducting quantum technologies.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Ding_Y/0/1/0/all/0/1&quot;&gt;Yongcheng Ding&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Lamata_L/0/1/0/all/0/1&quot;&gt;Lucas Lamata&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Sanz_M/0/1/0/all/0/1&quot;&gt;Mikel Sanz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Chen_X/0/1/0/all/0/1&quot;&gt;Xi Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Solano_E/0/1/0/all/0/1&quot;&gt;Enrique Solano&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1707.08114">
<title>A Survey on Multi-Task Learning. (arXiv:1707.08114v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1707.08114</link>
<description rdf:parseType="Literal">&lt;p&gt;Multi-Task Learning (MTL) is a learning paradigm in machine learning and its
aim is to leverage useful information contained in multiple related tasks to
help improve the generalization performance of all the tasks. In this paper, we
give a survey for MTL. First, we classify different MTL algorithms into several
categories, including feature learning approach, low-rank approach, task
clustering approach, task relation learning approach, and decomposition
approach, and then discuss the characteristics of each approach. In order to
improve the performance of learning tasks further, MTL can be combined with
other learning paradigms including semi-supervised learning, active learning,
unsupervised learning, reinforcement learning, multi-view learning and
graphical models. When the number of tasks is large or the data dimensionality
is high, batch MTL models are difficult to handle this situation and online,
parallel and distributed MTL models as well as dimensionality reduction and
feature hashing are reviewed to reveal their computational and storage
advantages. Many real-world applications use MTL to boost their performance and
we review representative works. Finally, we present theoretical analyses and
discuss several future directions for MTL.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yu Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Q/0/1/0/all/0/1&quot;&gt;Qiang Yang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.10363">
<title>General Video Game AI: a Multi-Track Framework for Evaluating Agents, Games and Content Generation Algorithms. (arXiv:1802.10363v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1802.10363</link>
<description rdf:parseType="Literal">&lt;p&gt;General Video Game Playing (GVGP) aims at designing an agent that is capable
of playing multiple video games with no human intervention. In 2014, The
General Video Game AI (GVGAI) competition framework was created and released
with the purpose of providing researchers a common open-source and easy to use
platform for testing their AI methods with potentially infinity of games
created using Video Game Description Language (VGDL). The framework has been
expanded into several tracks during the last few years to meet the demand of
different research directions. The agents are required to either play multiples
unknown games with or without access to game simulations, or to design new game
levels or rules. This survey paper presents the VGDL, the GVGAI framework,
existing tracks, and reviews the wide use of GVGAI framework in research,
education and competitions five years after its birth. A future plan of
framework improvements is also described.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Perez_Liebana_D/0/1/0/all/0/1&quot;&gt;Diego Perez-Liebana&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Jialin Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khalifa_A/0/1/0/all/0/1&quot;&gt;Ahmed Khalifa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gaina_R/0/1/0/all/0/1&quot;&gt;Raluca D. Gaina&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Togelius_J/0/1/0/all/0/1&quot;&gt;Julian Togelius&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lucas_S/0/1/0/all/0/1&quot;&gt;Simon M. Lucas&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.10117">
<title>Effectiveness of Scaled Exponentially-Regularized Linear Units (SERLUs). (arXiv:1807.10117v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1807.10117</link>
<description rdf:parseType="Literal">&lt;p&gt;Recently, self-normalizing neural networks (SNNs) have been proposed with the
intention to avoid batch or weight normalization. The key step in SNNs is to
properly scale the exponential linear unit (referred to as SELU) to inherently
incorporate normalization based on central limit theory. SELU is a
monotonically increasing function, where it has an approximately constant
negative output for large negative input. In this work, we propose a new
activation function to break the monotonicity property of SELU while still
preserving the self-normalizing property. Differently from SELU, the new
function introduces a bump-shaped function in the region of negative input by
regularizing a linear function with a scaled exponential function, which is
referred to as a scaled exponentially-regularized linear unit (SERLU). The
bump-shaped function has approximately zero response to large negative input
while being able to push the output of SERLU towards zero mean statistically.
To effectively combat over-fitting, we develop a so-called shift-dropout for
SERLU, which includes standard dropout as a special case. Experimental results
on MNIST, CIFAR10 and CIFAR100 show that SERLU-based neural networks provide
consistently promising results in comparison to other 5 activation functions
including ELU, SELU, Swish, Leakly ReLU and ReLU.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1&quot;&gt;G. Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1&quot;&gt;H. Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.10422">
<title>Understanding V2V Driving Scenarios through Traffic Primitives. (arXiv:1807.10422v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.10422</link>
<description rdf:parseType="Literal">&lt;p&gt;Semantically understanding complex drivers&apos; encountering behavior, wherein
two or multiple vehicles are spatially close to each other, does potentially
benefit autonomous car&apos;s decision-making design. This paper presents a
framework of analyzing various encountering behaviors through decomposing
driving encounter data into small building blocks, called driving primitives,
using nonparametric Bayesian learning (NPBL) approaches, which offers a
flexible way to gain an insight into the complex driving encounters without any
prerequisite knowledge. The effectiveness of our proposed primitive-based
framework is validated based on 976 naturalistic driving encounters, from which
more than 4000 driving primitives are learned using NPBL - a sticky HDP-HMM,
combined a hidden Markov model (HMM) with a hierarchical Dirichlet process
(HDP). After that, a dynamic time warping method integrated with k-means
clustering is then developed to cluster all these extracted driving primitives
into groups. Experimental results find that there exist 20 kinds of driving
primitives capable of representing the basic components of driving encounters
in our database. This primitive-based analysis methodology potentially reveals
underlying information of vehicle-vehicle encounters for self-driving
applications.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1&quot;&gt;Wenshuo Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1&quot;&gt;Weiyang Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_D/0/1/0/all/0/1&quot;&gt;Ding Zhao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.10478">
<title>Interpreting RNN behaviour via excitable network attractors. (arXiv:1807.10478v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.10478</link>
<description rdf:parseType="Literal">&lt;p&gt;Machine learning has become a basic tool in scientific research and for the
development of technologies with significant impact on society. In fact, such
methods allow to discover regularities in data and make predictions without
explicit knowledge of the rules governing the system under analysis. However, a
price must be paid for exploiting such a modeling flexibility: machine learning
methods are usually black-box, meaning that it is difficult to fully understand
what the machine is doing and how. This poses constraints on the applicability
of such methods, neglecting the possibility to gather novel scientific insights
from experimental data. Our research aims to open the black-box of recurrent
neural networks, an important family of neural networks suitable to process
sequential data. Here, we propose a novel methodology that allows to provide a
mechanistic interpretation of their behaviour when used to solve computational
tasks. The methodology is based on mathematical constructs called excitable
network attractors, which are models represented as networks in phase space
composed by stable attractors and excitable connections between them. As the
behaviour of recurrent neural networks depends on training and inputs driving
the autonomous system, we introduce an algorithm to extract network attractors
directly from a trajectory generated by the neural network while solving tasks.
Simulations conducted on a controlled benchmark highlight the relevance of the
proposed methodology for interpreting the behaviour of recurrent neural
networks on tasks that involve learning a finite number of stable states.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ceni_A/0/1/0/all/0/1&quot;&gt;Andrea Ceni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ashwin_P/0/1/0/all/0/1&quot;&gt;Peter Ashwin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Livi_L/0/1/0/all/0/1&quot;&gt;Lorenzo Livi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.10570">
<title>Embedded Implementation of a Deep Learning Smile Detector. (arXiv:1807.10570v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1807.10570</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper we study the real time deployment of deep learning algorithms
in low resource computational environments. As the use case, we compare the
accuracy and speed of neural networks for smile detection using different
neural network architectures and their system level implementation on NVidia
Jetson embedded platform. We also propose an asynchronous multithreading scheme
for parallelizing the pipeline. Within this framework, we experimentally
compare thirteen widely used network topologies. The experiments show that low
complexity architectures can achieve almost equal performance as larger ones,
with a fraction of computation required.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghazi_P/0/1/0/all/0/1&quot;&gt;Pedram Ghazi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Happonen_A/0/1/0/all/0/1&quot;&gt;Antti P. Happonen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Boutellier_J/0/1/0/all/0/1&quot;&gt;Jani Boutellier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huttunen_H/0/1/0/all/0/1&quot;&gt;Heikki Huttunen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.10572">
<title>Two-Layer Mixture Network Ensemble for Apparel Attributes Classification. (arXiv:1807.10572v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1807.10572</link>
<description rdf:parseType="Literal">&lt;p&gt;Recognizing apparel attributes has recently drawn great interest in the
computer vision community. Methods based on various deep neural networks have
been proposed for image classification, which could be applied to apparel
attributes recognition. An interesting problem raised is how to ensemble these
methods to further improve the accuracy. In this paper, we propose a two-layer
mixture framework for ensemble different networks. In the first layer of this
framework, two types of ensemble learning methods, bagging and boosting, are
separately applied. Different from traditional methods, our bagging process
makes use of the whole training set, not random subsets, to train each model in
the ensemble, where several differentiated deep networks are used to promote
model variance. To avoid the bias of small-scale samples, the second layer only
adopts bagging to mix the results obtained with bagging and boosting in the
first layer. Experimental results demonstrate that the proposed mixture
framework outperforms any individual network model or either independent
ensemble method in apparel attributes classification.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Han_T/0/1/0/all/0/1&quot;&gt;Tianqi Han&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fu_Z/0/1/0/all/0/1&quot;&gt;Zhihui Fu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1&quot;&gt;Hongyu Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.10574">
<title>Deep Learning Hyperspectral Image Classification Using Multiple Class-based Denoising Autoencoders, Mixed Pixel Training Augmentation, and Morphological Operations. (arXiv:1807.10574v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1807.10574</link>
<description rdf:parseType="Literal">&lt;p&gt;Herein, we present a system for hyperspectral image segmentation that
utilizes multiple class--based denoising autoencoders which are efficiently
trained. Moreover, we present a novel hyperspectral data augmentation method
for labelled HSI data using linear mixtures of pixels from each class, which
helps the system with edge pixels which are almost always mixed pixels.
Finally, we utilize a deep neural network and morphological hole-filling to
provide robust image classification. Results run on the Salinas dataset verify
the high performance of the proposed algorithm.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ball_J/0/1/0/all/0/1&quot;&gt;John E. Ball&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wei_P/0/1/0/all/0/1&quot;&gt;Pan Wei&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.10583">
<title>EchoFusion: Tracking and Reconstruction of Objects in 4D Freehand Ultrasound Imaging without External Trackers. (arXiv:1807.10583v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1807.10583</link>
<description rdf:parseType="Literal">&lt;p&gt;Ultrasound (US) is the most widely used fetal imaging technique. However, US
images have limited capture range, and suffer from view dependent artefacts
such as acoustic shadows. Compounding of overlapping 3D US acquisitions into a
high-resolution volume can extend the field of view and remove image artefacts,
which is useful for retrospective analysis including population based studies.
However, such volume reconstructions require information about relative
transformations between probe positions from which the individual volumes were
acquired. In prenatal US scans, the fetus can move independently from the
mother, making external trackers such as electromagnetic or optical tracking
unable to track the motion between probe position and the moving fetus. We
provide a novel methodology for image-based tracking and volume reconstruction
by combining recent advances in deep learning and simultaneous localisation and
mapping (SLAM). Tracking semantics are established through the use of a
Residual 3D U-Net and the output is fed to the SLAM algorithm. As a proof of
concept, experiments are conducted on US volumes taken from a whole body fetal
phantom, and from the heads of real fetuses. For the fetal head segmentation,
we also introduce a novel weak annotation approach to minimise the required
manual effort for ground truth annotation. We evaluate our method
qualitatively, and quantitatively with respect to tissue discrimination
accuracy and tracking robustness.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khanal_B/0/1/0/all/0/1&quot;&gt;Bishesh Khanal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gomez_A/0/1/0/all/0/1&quot;&gt;Alberto Gomez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Toussaint_N/0/1/0/all/0/1&quot;&gt;Nicolas Toussaint&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+McDonagh_S/0/1/0/all/0/1&quot;&gt;Steven McDonagh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zimmer_V/0/1/0/all/0/1&quot;&gt;Veronika Zimmer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Skelton_E/0/1/0/all/0/1&quot;&gt;Emily Skelton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Matthew_J/0/1/0/all/0/1&quot;&gt;Jacqueline Matthew&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grzech_D/0/1/0/all/0/1&quot;&gt;Daniel Grzech&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wright_R/0/1/0/all/0/1&quot;&gt;Robert Wright&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gupta_C/0/1/0/all/0/1&quot;&gt;Chandni Gupta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hou_B/0/1/0/all/0/1&quot;&gt;Benjamin Hou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rueckert_D/0/1/0/all/0/1&quot;&gt;Daniel Rueckert&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schnabel_J/0/1/0/all/0/1&quot;&gt;Julia A.Schnabel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kainz_B/0/1/0/all/0/1&quot;&gt;Bernhard Kainz&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.10634">
<title>Revealing the Unobserved by Linking Collaborative Behavior and Side Knowledge. (arXiv:1807.10634v1 [cs.IR])</title>
<link>http://arxiv.org/abs/1807.10634</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a tensor-based model that fuses a more granular representation of
user preferences with the ability to take additional side information into
account. The model relies on the concept of ordinal nature of utility, which
better corresponds to actual user perception. In addition to that, unlike the
majority of hybrid recommenders, the model ties side information directly to
collaborative data, which not only addresses the problem of extreme data
sparsity, but also allows to naturally exploit patterns in the observed
behavior for a more meaningful representation of user intents. We demonstrate
the effectiveness of the proposed model on several standard benchmark datasets.
The general formulation of the approach imposes no restrictions on the type of
observed interactions and makes it potentially applicable for joint modelling
of context information along with side data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Frolov_E/0/1/0/all/0/1&quot;&gt;Evgeny Frolov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oseledets_I/0/1/0/all/0/1&quot;&gt;Ivan Oseledets&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.10668">
<title>On the overfly algorithm in deep learning of neural networks. (arXiv:1807.10668v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.10668</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper we investigate the supervised backpropagation training of
multilayer neural networks from a dynamical systems point of view. We discuss
some links with the qualitative theory of differential equations and introduce
the overfly algorithm to tackle the local minima problem. Our approach is based
on the existence of first integrals of the generalised gradient system with
build-in dissipation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tsygvintsev_A/0/1/0/all/0/1&quot;&gt;Alexei Tsygvintsev&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.10675">
<title>Resource-Size matters: Improving Neural Named Entity Recognition with Optimized Large Corpora. (arXiv:1807.10675v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1807.10675</link>
<description rdf:parseType="Literal">&lt;p&gt;This study improves the performance of neural named entity recognition by a
margin of up to 11% in F-score on the example of a low-resource language like
German, thereby outperforming existing baselines and establishing a new
state-of-the-art on each single open-source dataset. Rather than designing
deeper and wider hybrid neural architectures, we gather all available resources
and perform a detailed optimization and grammar-dependent morphological
processing consisting of lemmatization and part-of-speech tagging prior to
exposing the raw data to any training process. We test our approach in a
threefold monolingual experimental setup of a) single, b) joint, and c)
optimized training and shed light on the dependency of downstream-tasks on the
size of corpora used to compute word embeddings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ahmed_S/0/1/0/all/0/1&quot;&gt;Sajawel Ahmed&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mehler_A/0/1/0/all/0/1&quot;&gt;Alexander Mehler&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.10681">
<title>Learnable: Theory vs Applications. (arXiv:1807.10681v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.10681</link>
<description rdf:parseType="Literal">&lt;p&gt;Two different views on machine learning problem: Applied learning (machine
learning with business applications) and Agnostic PAC learning are formalized
and compared here. I show that, under some conditions, the theory of PAC
Learnable provides a way to solve the Applied learning problem. However, the
theory requires to have the training sets so large, that it would make the
learning practically useless. I suggest shedding some theoretical
misconceptions about learning to make the theory more aligned with the needs
and experience of practitioners.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sapir_M/0/1/0/all/0/1&quot;&gt;Marina Sapir&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.10695">
<title>FPGA-Based CNN Inference Accelerator Synthesized from Multi-Threaded C Software. (arXiv:1807.10695v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.10695</link>
<description rdf:parseType="Literal">&lt;p&gt;A deep-learning inference accelerator is synthesized from a C-language
software program parallelized with Pthreads. The software implementation uses
the well-known producer/consumer model with parallel threads interconnected by
FIFO queues. The LegUp high-level synthesis (HLS) tool synthesizes threads into
parallel FPGA hardware, translating software parallelism into spatial
parallelism. A complete system is generated where convolution, pooling and
padding are realized in the synthesized accelerator, with remaining tasks
executing on an embedded ARM processor. The accelerator incorporates reduced
precision, and a novel approach for zero-weight-skipping in convolution. On a
mid-sized Intel Arria 10 SoC FPGA, peak performance on VGG-16 is 138 effective
GOPS.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1&quot;&gt;Jin Hee Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grady_B/0/1/0/all/0/1&quot;&gt;Brett Grady&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lian_R/0/1/0/all/0/1&quot;&gt;Ruolong Lian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brothers_J/0/1/0/all/0/1&quot;&gt;John Brothers&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Anderson_J/0/1/0/all/0/1&quot;&gt;Jason H. Anderson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.08518">
<title>Implementing Neural Turing Machines. (arXiv:1807.08518v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1807.08518</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural Turing Machines (NTMs) are an instance of Memory Augmented Neural
Networks, a new class of recurrent neural networks which decouple computation
from memory by introducing an external memory unit. NTMs have demonstrated
superior performance over Long Short-Term Memory Cells in several sequence
learning tasks. A number of open source implementations of NTMs exist but are
unstable during training and/or fail to replicate the reported performance of
NTMs. This paper presents the details of our successful implementation of a
NTM. Our implementation learns to solve three sequential learning tasks from
the original NTM paper. We find that the choice of memory contents
initialization scheme is crucial in successfully implementing a NTM. Networks
with memory contents initialized to small constant values converge on average 2
times faster than the next best memory contents initialization scheme.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Collier_M/0/1/0/all/0/1&quot;&gt;Mark Collier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Beel_J/0/1/0/all/0/1&quot;&gt;Joeran Beel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.09902">
<title>General-purpose Tagging of Freesound Audio with AudioSet Labels: Task Description, Dataset, and Baseline. (arXiv:1807.09902v2 [cs.SD] UPDATED)</title>
<link>http://arxiv.org/abs/1807.09902</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper describes Task 2 of the DCASE 2018 Challenge, titled
&quot;General-purpose audio tagging of Freesound content with AudioSet labels&quot;. This
task was hosted on the Kaggle platform as &quot;Freesound General-Purpose Audio
Tagging Challenge&quot;. The goal of the task is to build an audio tagging system
that can recognize the category of an audio clip from a subset of 41
heterogeneous categories drawn from the AudioSet Ontology. We present the task,
the dataset prepared for the competition, and a baseline system.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fonseca_E/0/1/0/all/0/1&quot;&gt;Eduardo Fonseca&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Plakal_M/0/1/0/all/0/1&quot;&gt;Manoj Plakal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Font_F/0/1/0/all/0/1&quot;&gt;Frederic Font&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ellis_D/0/1/0/all/0/1&quot;&gt;Daniel P. W. Ellis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Favory_X/0/1/0/all/0/1&quot;&gt;Xavier Favory&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pons_J/0/1/0/all/0/1&quot;&gt;Jordi Pons&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Serra_X/0/1/0/all/0/1&quot;&gt;Xavier Serra&lt;/a&gt;</dc:creator>
</item></rdf:RDF>