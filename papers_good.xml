<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Good papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Good Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-05-31T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.12152"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.12368"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.01890"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11797"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1706.02257"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.12346"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.12393"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.12402"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.12475"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.12487"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.12514"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.12559"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.12565"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.04008"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.05402"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.06824"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.12164"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.12176"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.12233"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.12301"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.12338"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.12355"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.12369"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.12372"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.12375"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.12381"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.12507"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.01641"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.11347"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.09060"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.10846"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09039"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10451"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10561"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11046"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1805.12152">
<title>There Is No Free Lunch In Adversarial Robustness (But There Are Unexpected Benefits). (arXiv:1805.12152v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.12152</link>
<description rdf:parseType="Literal">&lt;p&gt;We provide a new understanding of the fundamental nature of adversarially
robust classifiers and how they differ from standard models. In particular, we
show that there provably exists a trade-off between the standard accuracy of a
model and its robustness to adversarial perturbations. We demonstrate an
intriguing phenomenon at the root of this tension: a certain dichotomy between
&quot;robust&quot; and &quot;non-robust&quot; features. We show that while robustness comes at a
price, it also has some surprising benefits. Robust models turn out to have
interpretable gradients and feature representations that align unusually well
with salient data characteristics. In fact, they yield striking feature
interpolations that have thus far been possible to obtain only using generative
models such as GANs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tsipras_D/0/1/0/all/0/1&quot;&gt;Dimitris Tsipras&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Santurkar_S/0/1/0/all/0/1&quot;&gt;Shibani Santurkar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Engstrom_L/0/1/0/all/0/1&quot;&gt;Logan Engstrom&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Turner_A/0/1/0/all/0/1&quot;&gt;Alexander Turner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Madry_A/0/1/0/all/0/1&quot;&gt;Aleksander Madry&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.12368">
<title>Forgetting Memories and their Attractiveness. (arXiv:1805.12368v1 [cond-mat.dis-nn])</title>
<link>http://arxiv.org/abs/1805.12368</link>
<description rdf:parseType="Literal">&lt;p&gt;We study numerically the memory which forgets, introduced in 1986 by Parisi
by bounding the synaptic strength, with a mechanism which avoid confusion,
allows to remember the pattern learned more recently and has a physiologically
very well defined meaning. We analyze a number of features of the learning at
finite number of neurons and finite number of patterns. We discuss how the
system behaves in the large but finite N limit. We analyze the basin of
attraction of the patterns that have been learned, and we show that it is
exponentially small in the age of the pattern. This is a clearly non
physiological feature of the model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Marinari_E/0/1/0/all/0/1&quot;&gt;Enzo Marinari&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.01890">
<title>RMDL: Random Multimodel Deep Learning for Classification. (arXiv:1805.01890v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.01890</link>
<description rdf:parseType="Literal">&lt;p&gt;The continually increasing number of complex datasets each year necessitates
ever improving machine learning methods for robust and accurate categorization
of these data. This paper introduces Random Multimodel Deep Learning (RMDL): a
new ensemble, deep learning approach for classification. Deep learning models
have achieved state-of-the-art results across many domains. RMDL solves the
problem of finding the best deep learning structure and architecture while
simultaneously improving robustness and accuracy through ensembles of deep
learning architectures. RDML can accept as input a variety data to include
text, video, images, and symbolic. This paper describes RMDL and shows test
results for image and text data including MNIST, CIFAR-10, WOS, Reuters, IMDB,
and 20newsgroup. These test results show that RDML produces consistently better
performance than standard methods over a broad range of data types and
classification problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kowsari_K/0/1/0/all/0/1&quot;&gt;Kamran Kowsari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Heidarysafa_M/0/1/0/all/0/1&quot;&gt;Mojtaba Heidarysafa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brown_D/0/1/0/all/0/1&quot;&gt;Donald E. Brown&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meimandi_K/0/1/0/all/0/1&quot;&gt;Kiana Jafari Meimandi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barnes_L/0/1/0/all/0/1&quot;&gt;Laura E. Barnes&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11797">
<title>Grow and Prune Compact, Fast, and Accurate LSTMs. (arXiv:1805.11797v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.11797</link>
<description rdf:parseType="Literal">&lt;p&gt;Long short-term memory (LSTM) has been widely used for sequential data
modeling. Researchers have increased LSTM depth by stacking LSTM cells to
improve performance. This incurs model redundancy, increases run-time delay,
and makes the LSTMs more prone to overfitting. To address these problems, we
propose a hidden-layer LSTM (H-LSTM) that adds hidden layers to LSTM&apos;s original
one level non-linear control gates. H-LSTM increases accuracy while employing
fewer external stacked layers, thus reducing the number of parameters and
run-time latency significantly. We employ grow-and-prune (GP) training to
iteratively adjust the hidden layers through gradient-based growth and
magnitude-based pruning of connections. This learns both the weights and the
compact architecture of H-LSTM control gates. We have GP-trained H-LSTMs for
image captioning and speech recognition applications. For the NeuralTalk
architecture on the MSCOCO dataset, our three models reduce the number of
parameters by 38.7x [floating-point operations (FLOPs) by 45.5x], run-time
latency by 4.5x, and improve the CIDEr score by 2.6. For the DeepSpeech2
architecture on the AN4 dataset, our two models reduce the number of parameters
by 19.4x (FLOPs by 23.5x), run-time latency by 15.7%, and the word error rate
from 12.9% to 8.7%. Thus, GP-trained H-LSTMs can be seen to be compact, fast,
and accurate.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dai_X/0/1/0/all/0/1&quot;&gt;Xiaoliang Dai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yin_H/0/1/0/all/0/1&quot;&gt;Hongxu Yin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jha_N/0/1/0/all/0/1&quot;&gt;Niraj K. Jha&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1706.02257">
<title>Driver Action Prediction Using Deep (Bidirectional) Recurrent Neural Network. (arXiv:1706.02257v1 [stat.ML] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1706.02257</link>
<description rdf:parseType="Literal">&lt;p&gt;Advanced driver assistance systems (ADAS) can be significantly improved with
effective driver action prediction (DAP). Predicting driver actions early and
accurately can help mitigate the effects of potentially unsafe driving
behaviors and avoid possible accidents. In this paper, we formulate driver
action prediction as a timeseries anomaly prediction problem. While the anomaly
(driver actions of interest) detection might be trivial in this context,
finding patterns that consistently precede an anomaly requires searching for or
extracting features across multi-modal sensory inputs. We present such a driver
action prediction system, including a real-time data acquisition, processing
and learning framework for predicting future or impending driver action. The
proposed system incorporates camera-based knowledge of the driving environment
and the driver themselves, in addition to traditional vehicle dynamics. It then
uses a deep bidirectional recurrent neural network (DBRNN) to learn the
correlation between sensory inputs and impending driver behavior achieving
accurate and high horizon action prediction. The proposed system performs
better than other existing systems on driver action prediction tasks and can
accurately predict key driver actions including acceleration, braking, lane
change and turning at durations of 5sec before the action is executed by the
driver.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Olabiyi_O/0/1/0/all/0/1&quot;&gt;Oluwatobi Olabiyi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Martinson_E/0/1/0/all/0/1&quot;&gt;Eric Martinson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chintalapudi_V/0/1/0/all/0/1&quot;&gt;Vijay Chintalapudi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Guo_R/0/1/0/all/0/1&quot;&gt;Rui Guo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.12346">
<title>Crowdsourcing for Reminiscence Chatbot Design. (arXiv:1805.12346v1 [cs.HC])</title>
<link>http://arxiv.org/abs/1805.12346</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work-in-progress paper we discuss the challenges in identifying
effective and scalable crowd-based strategies for designing content,
conversation logic, and meaningful metrics for a reminiscence chatbot targeted
at older adults. We formalize the problem and outline the main research
questions that drive the research agenda in chatbot design for reminiscence and
for relational agents for older adults in general.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nikitina_S/0/1/0/all/0/1&quot;&gt;Svetlana Nikitina&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Daniel_F/0/1/0/all/0/1&quot;&gt;Florian Daniel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Baez_M/0/1/0/all/0/1&quot;&gt;Marcos Baez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Casati_F/0/1/0/all/0/1&quot;&gt;Fabio Casati&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.12393">
<title>KG^2: Learning to Reason Science Exam Questions with Contextual Knowledge Graph Embeddings. (arXiv:1805.12393v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.12393</link>
<description rdf:parseType="Literal">&lt;p&gt;The AI2 Reasoning Challenge (ARC), a new benchmark dataset for question
answering (QA) has been recently released. ARC only contains natural science
questions authored for human exams, which are hard to answer and require
advanced logic reasoning. On the ARC Challenge Set, existing state-of-the-art
QA systems fail to significantly outperform random baseline, reflecting the
difficult nature of this task. In this paper, we propose a novel framework for
answering science exam questions, which mimics human solving process in an
open-book exam. To address the reasoning challenge, we construct contextual
knowledge graphs respectively for the question itself and supporting sentences.
Our model learns to reason with neural embeddings of both knowledge graphs.
Experiments on the ARC Challenge Set show that our model outperforms the
previous state-of-the-art QA systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yuyu Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dai_H/0/1/0/all/0/1&quot;&gt;Hanjun Dai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Toraman_K/0/1/0/all/0/1&quot;&gt;Kamil Toraman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_L/0/1/0/all/0/1&quot;&gt;Le Song&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.12402">
<title>Breaking-down the Ontology Alignment Task with a Lexical Index and Neural Embeddings. (arXiv:1805.12402v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1805.12402</link>
<description rdf:parseType="Literal">&lt;p&gt;Large ontologies still pose serious challenges to state-of-the-art ontology
alignment systems. In the paper we present an approach that combines a lexical
index, a neural embedding model and locality modules to effectively divide an
input ontology matching task into smaller and more tractable matching
(sub)tasks. We have conducted a comprehensive evaluation using the datasets of
the Ontology Alignment Evaluation Initiative. The results are encouraging and
suggest that the proposed methods are adequate in practice and can be
integrated within the workflow of state-of-the-art systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jimenez_Ruiz_E/0/1/0/all/0/1&quot;&gt;Ernesto Jimenez-Ruiz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Agibetov_A/0/1/0/all/0/1&quot;&gt;Asan Agibetov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Samwald_M/0/1/0/all/0/1&quot;&gt;Matthias Samwald&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cross_V/0/1/0/all/0/1&quot;&gt;Valerie Cross&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.12475">
<title>Data-driven Design: A Case for Maximalist Game Design. (arXiv:1805.12475v1 [cs.HC])</title>
<link>http://arxiv.org/abs/1805.12475</link>
<description rdf:parseType="Literal">&lt;p&gt;Maximalism in art refers to drawing on and combining multiple different
sources for art creation, embracing the resulting collisions and heterogeneity.
This paper discusses the use of maximalism in game design and particularly in
data games, which are games that are generated partly based on open data. Using
Data Adventures, a series of generators that create adventure games from data
sources such as Wikipedia and OpenStreetMap, as a lens we explore several
tradeoffs and issues in maximalist game design. This includes the tension
between transformation and fidelity, between decorative and functional content,
and legal and ethical issues resulting from this type of generativity. This
paper sketches out the design space of maximalist data-driven games, a design
space that is mostly unexplored.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barros_G/0/1/0/all/0/1&quot;&gt;Gabriella A. B. Barros&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Green_M/0/1/0/all/0/1&quot;&gt;Michael Cerny Green&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liapis_A/0/1/0/all/0/1&quot;&gt;Antonios Liapis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Togelius_J/0/1/0/all/0/1&quot;&gt;Julian Togelius&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.12487">
<title>Sequential Attacks on Agents for Long-Term Adversarial Goals. (arXiv:1805.12487v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.12487</link>
<description rdf:parseType="Literal">&lt;p&gt;Reinforcement learning (RL) has advanced greatly in the past few years with
the employment of effective deep neural networks (DNNs) on the policy networks.
With the great effectiveness came serious vulnerability issues with DNNs that
small adversarial perturbations on the input can change the output of the
network. Several works have pointed out that learned agents with a DNN policy
network can be manipulated against achieving the original task through a
sequence of small perturbations on the input states. In this paper, we
demonstrate furthermore that it is also possible to impose an arbitrary
adversarial reward on the victim policy network through a sequence of attacks.
Our method involves the latest adversarial attack technique, Adversarial
Transformer Network (ATN), that learns to generate the attack and is easy to
integrate into the policy network. As a result of our attack, the victim agent
is misguided to optimise for the adversarial reward over time. Our results
expose serious security threats for RL applications in safety-critical systems
including drones, medical analysis, and self-driving cars.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tretschk_E/0/1/0/all/0/1&quot;&gt;Edgar Tretschk&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oh_S/0/1/0/all/0/1&quot;&gt;Seong Joon Oh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fritz_M/0/1/0/all/0/1&quot;&gt;Mario Fritz&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.12514">
<title>Scaling provable adversarial defenses. (arXiv:1805.12514v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.12514</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent work has developed methods for learning deep network classifiers that
are provably robust to norm-bounded adversarial perturbation; however, these
methods are currently only possible for relatively small feedforward networks.
In this paper, in an effort to scale these approaches to substantially larger
models, we extend previous work in three main directions. First, we present a
technique for extending these training procedures to much more general
networks, with skip connections (such as ResNets) and general nonlinearities;
the approach is fully modular, and can be implemented automatically (analogous
to automatic differentiation). Second, in the specific case of $\ell_\infty$
adversarial perturbations and networks with ReLU nonlinearities, we adopt a
nonlinear random projection for training, which scales linearly in the number
of hidden units (previous approaches scaled quadratically). Third, we show how
to further improve robust error through cascade models. On both MNIST and CIFAR
data sets, we train classifiers that improve substantially on the state of the
art in provable robust adversarial error bounds: from 5.8% to 3.1% on MNIST
(with $\ell_\infty$ perturbations of $\epsilon=0.1$), and from 80% to 36.4% on
CIFAR (with $\ell_\infty$ perturbations of $\epsilon=2/255$). Code for all
experiments in the paper is available at
https://github.com/locuslab/convex_adversarial/.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wong_E/0/1/0/all/0/1&quot;&gt;Eric Wong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schmidt_F/0/1/0/all/0/1&quot;&gt;Frank Schmidt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Metzen_J/0/1/0/all/0/1&quot;&gt;Jan Hendrik Metzen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kolter_J/0/1/0/all/0/1&quot;&gt;J. Zico Kolter&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.12559">
<title>The Complexity of Splitting Necklaces and Bisecting Ham Sandwiches. (arXiv:1805.12559v1 [cs.CC])</title>
<link>http://arxiv.org/abs/1805.12559</link>
<description rdf:parseType="Literal">&lt;p&gt;We resolve the computational complexity of two problems known as
NECKLACE-SPLITTING and DISCRETE HAM SANDWICH, showing that they are
PPA-complete. We do this via a PPA-completeness result for an approximate
version of the CONSENSUS-HALVING problem, strengthening our recent result that
the problem is PPA-complete for inverse-exponential precision. At the heart of
our construction is a smooth embedding of the high-dimensional M\&quot;{o}bius strip
in the CONSENSUS-HALVING problem. These results settle the status of PPA as a
class that captures the complexity of &quot;natural&apos;&quot; problems whose definitions do
not incorporate a circuit.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Filos_Ratsikas_A/0/1/0/all/0/1&quot;&gt;Aris Filos-Ratsikas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goldberg_P/0/1/0/all/0/1&quot;&gt;Paul W. Goldberg&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.12565">
<title>Approximate Knowledge Compilation by Online Collapsed Importance Sampling. (arXiv:1805.12565v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1805.12565</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce collapsed compilation, a novel approximate inference algorithm
for discrete probabilistic graphical models. It is a collapsed sampling
algorithm that incrementally selects which variable to sample next based on the
partial sample obtained so far. This online collapsing, together with knowledge
compilation inference on the remaining variables, naturally exploits local
structure and context- specific independence in the distribution. These
properties are naturally exploited in exact inference, but are difficult to
harness for approximate inference. More- over, by having a partially compiled
circuit available during sampling, collapsed compilation has access to a highly
effective proposal distribution for importance sampling. Our experimental
evaluation shows that collapsed compilation performs well on standard
benchmarks. In particular, when the amount of exact inference is equally
limited, collapsed compilation is competitive with the state of the art, and
outperforms it on several benchmarks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Friedman_T/0/1/0/all/0/1&quot;&gt;Tal Friedman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Broeck_G/0/1/0/all/0/1&quot;&gt;Guy Van den Broeck&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.04008">
<title>Investigating the Impact of Data Volume and Domain Similarity on Transfer Learning Applications. (arXiv:1712.04008v4 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1712.04008</link>
<description rdf:parseType="Literal">&lt;p&gt;Transfer learning allows practitioners to recognize and apply knowledge
learned in previous tasks (source task) to new tasks or new domains (target
task), which share some commonality. The two important factors impacting the
performance of transfer learning models are: (a) the size of the target
dataset, and (b) the similarity in distribution between source and target
domains. Thus far, there has been little investigation into just how important
these factors are. In this paper, we investigate the impact of target dataset
size and source/target domain similarity on model performance through a series
of experiments. We find that more data is always beneficial, and model
performance improves linearly with the log of data size, until we are out of
data. As source/target domains differ, more data is required and fine tuning
will render better performance than feature extraction. When source/target
domains are similar and data size is small, fine tuning and feature extraction
renders equivalent performance. Our hope is that by beginning this quantitative
investigation on the effect of data volume and domain similarity in transfer
learning we might inspire others to explore the significance of data in
developing more accurate statistical models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bernico_M/0/1/0/all/0/1&quot;&gt;Michael Bernico&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yuntao Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1&quot;&gt;Dingchao Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.05402">
<title>Imitation Learning with Concurrent Actions in 3D Games. (arXiv:1803.05402v4 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1803.05402</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work we describe a novel deep reinforcement learning architecture
that allows multiple actions to be selected at every time-step in an efficient
manner. Multi-action policies allow complex behaviours to be learnt that would
otherwise be hard to achieve when using single action selection techniques. We
use both imitation learning and temporal difference (TD) reinforcement learning
(RL) to provide a 4x improvement in training time and 2.5x improvement in
performance over single action selection TD RL. We demonstrate the capabilities
of this network using a complex in-house 3D game. Mimicking the behavior of the
expert teacher significantly improves world state exploration and allows the
agents vision system to be trained more rapidly than TD RL alone. This initial
training technique kick-starts TD learning and the agent quickly learns to
surpass the capabilities of the expert.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Harmer_J/0/1/0/all/0/1&quot;&gt;Jack Harmer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gisslen_L/0/1/0/all/0/1&quot;&gt;Linus Gissl&amp;#xe9;n&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Val_J/0/1/0/all/0/1&quot;&gt;Jorge del Val&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Holst_H/0/1/0/all/0/1&quot;&gt;Henrik Holst&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bergdahl_J/0/1/0/all/0/1&quot;&gt;Joakim Bergdahl&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Olsson_T/0/1/0/all/0/1&quot;&gt;Tom Olsson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sjoo_K/0/1/0/all/0/1&quot;&gt;Kristoffer Sj&amp;#xf6;&amp;#xf6;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nordin_M/0/1/0/all/0/1&quot;&gt;Magnus Nordin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.06824">
<title>Learning Time-Sensitive Strategies in Space Fortress. (arXiv:1805.06824v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1805.06824</link>
<description rdf:parseType="Literal">&lt;p&gt;Although there has been remarkable progress and impressive performance on
reinforcement learning (RL) on Atari games, there are many problems with
challenging characteristics that have not yet been explored in Deep Learning
for RL. These include reward sparsity, abrupt context-dependent reversals of
strategy and time-sensitive game play. In this paper, we present Space
Fortress, a game that incorporates all these characteristics and experimentally
show that the presence of any of these renders state of the art Deep RL
algorithms incapable of learning. Then, we present our enhancements to an
existing algorithm and show big performance increases through each enhancement
through an ablation study. We discuss how each of these enhancements was able
to help and also argue that appropriate transfer learning boosts performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Agarwal_A/0/1/0/all/0/1&quot;&gt;Akshat Agarwal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sycara_K/0/1/0/all/0/1&quot;&gt;Katia Sycara&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.12164">
<title>What the Vec? Towards Probabilistically Grounded Embeddings. (arXiv:1805.12164v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1805.12164</link>
<description rdf:parseType="Literal">&lt;p&gt;Vector representation, or embedding, of words is commonly achieved with
neural network methods, in particular word2vec (W2V). It has been shown that
certain statistics of word co-occurrences are implicitly captured by properties
of W2V vectors, but much remains unknown of them, e.g. any meaning of length,
or more generally how it is that statistics can be reliably framed as vectors
at all. By deriving a mathematical link between probabilities and vectors, we
justify why W2V works and are able to create embeddings with probabilistically
interpretable properties.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Allen_C/0/1/0/all/0/1&quot;&gt;Carl Allen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Balazevic_I/0/1/0/all/0/1&quot;&gt;Ivana Bala&amp;#x17e;evi&amp;#x107;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hospedales_T/0/1/0/all/0/1&quot;&gt;Timothy Hospedales&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.12176">
<title>Deep Segment Hash Learning for Music Generation. (arXiv:1805.12176v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.12176</link>
<description rdf:parseType="Literal">&lt;p&gt;Music generation research has grown in popularity over the past decade,
thanks to the deep learning revolution that has redefined the landscape of
artificial intelligence. In this paper, we propose a novel approach to music
generation inspired by musical segment concatenation methods and hash learning
algorithms. Given a segment of music, we use a deep recurrent neural network
and ranking-based hash learning to assign a forward hash code to the segment to
retrieve candidate segments for continuation with matching backward hash codes.
The proposed method is thus called Deep Segment Hash Learning (DSHL). To the
best of our knowledge, DSHL is the first end-to-end segment hash learning
method for music generation, and the first to use pair-wise training with
segments of music. We demonstrate that this method is capable of generating
music which is both original and enjoyable, and that DSHL offers a promising
new direction for music generation research.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Joslyn_K/0/1/0/all/0/1&quot;&gt;Kevin Joslyn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhuang_N/0/1/0/all/0/1&quot;&gt;Naifan Zhuang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hua_K/0/1/0/all/0/1&quot;&gt;Kien A. Hua&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.12233">
<title>How Important Is a Neuron?. (arXiv:1805.12233v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.12233</link>
<description rdf:parseType="Literal">&lt;p&gt;The problem of attributing a deep network&apos;s prediction to its
\emph{input/base} features is well-studied. We introduce the notion of
\emph{conductance} to extend the notion of attribution to the understanding the
importance of \emph{hidden} units.
&lt;/p&gt;
&lt;p&gt;Informally, the conductance of a hidden unit of a deep network is the
\emph{flow} of attribution via this hidden unit. We use conductance to
understand the importance of a hidden unit to the prediction for a specific
input, or over a set of inputs. We evaluate the effectiveness of conductance in
multiple ways, including theoretical properties, ablation studies, and a
feature selection task. The empirical evaluations are done using the Inception
network over ImageNet data, and a sentiment analysis network over reviews. In
both cases, we demonstrate the effectiveness of conductance in identifying
interesting insights about the internal workings of these networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dhamdhere_K/0/1/0/all/0/1&quot;&gt;Kedar Dhamdhere&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sundararajan_M/0/1/0/all/0/1&quot;&gt;Mukund Sundararajan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yan_Q/0/1/0/all/0/1&quot;&gt;Qiqi Yan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.12301">
<title>Rotation Equivariance and Invariance in Convolutional Neural Networks. (arXiv:1805.12301v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.12301</link>
<description rdf:parseType="Literal">&lt;p&gt;Performance of neural networks can be significantly improved by encoding
known invariance for particular tasks. Many image classification tasks, such as
those related to cellular imaging, exhibit invariance to rotation. We present a
novel scheme using the magnitude response of the 2D-discrete-Fourier transform
(2D-DFT) to encode rotational invariance in neural networks, along with a new,
efficient convolutional scheme for encoding rotational equivariance throughout
convolutional layers. We implemented this scheme for several image
classification tasks and demonstrated improved performance, in terms of
classification accuracy, time required to train the model, and robustness to
hyperparameter selection, over a standard CNN and another state-of-the-art
method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chidester_B/0/1/0/all/0/1&quot;&gt;Benjamin Chidester&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Do_M/0/1/0/all/0/1&quot;&gt;Minh N. Do&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ma_J/0/1/0/all/0/1&quot;&gt;Jian Ma&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.12338">
<title>Hallucinating robots: Inferring obstacle distances from partial laser measurements. (arXiv:1805.12338v1 [cs.RO])</title>
<link>http://arxiv.org/abs/1805.12338</link>
<description rdf:parseType="Literal">&lt;p&gt;Many mobile robots rely on 2D laser scanners for localization, mapping, and
navigation. However, those sensors are unable to correctly provide distance to
obstacles such as glass panels and tables whose actual occupancy is invisible
at the height the sensor is measuring. In this work, instead of estimating the
distance to obstacles from richer sensor readings such as 3D lasers or RGBD
sensors, we present a method to estimate the distance directly from raw 2D
laser data. To learn a mapping from raw 2D laser distances to obstacle
distances we frame the problem as a learning task and train a neural network
formed as an autoencoder. A novel configuration of network hyperparameters is
proposed for the task at hand and is quantitatively validated on a test set.
Finally, we qualitatively demonstrate in real time on a Care-O-bot 4 that the
trained network can successfully infer obstacle distances from partial 2D laser
readings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lundell_J/0/1/0/all/0/1&quot;&gt;Jens Lundell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Verdoja_F/0/1/0/all/0/1&quot;&gt;Francesco Verdoja&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kyrki_V/0/1/0/all/0/1&quot;&gt;Ville Kyrki&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.12355">
<title>Deep Energy: Using Energy Functions for Unsupervised Training of DNNs. (arXiv:1805.12355v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.12355</link>
<description rdf:parseType="Literal">&lt;p&gt;The success of deep learning has been due in no small part to the
availability of large annotated datasets. Thus, a major bottleneck in the
current learning pipeline is the human annotation of data, which can be quite
time consuming. For a given problem setting, we aim to circumvent this issue
via the use of an externally specified energy function appropriate for that
setting; we call this the &quot;Deep Energy&quot; approach. We show how to train a
network on an entirely unlabelled dataset using such an energy function, and
apply this general technique to learn CNNs for two specific tasks: seeded
segmentation and image matting. Once the network parameters have been learned,
we obtain a high-quality solution in a fast feed-forward style, without the
need to repeatedly optimize the energy function for each image.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Golts_A/0/1/0/all/0/1&quot;&gt;Alona Golts&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Freedman_D/0/1/0/all/0/1&quot;&gt;Daniel Freedman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Elad_M/0/1/0/all/0/1&quot;&gt;Michael Elad&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.12369">
<title>Reinforced Continual Learning. (arXiv:1805.12369v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.12369</link>
<description rdf:parseType="Literal">&lt;p&gt;Most artificial intelligence models have limiting ability to solve new tasks
faster, without forgetting previously acquired knowledge. The recently emerging
paradigm of continual learning aims to solve this issue, in which the model
learns various tasks in a sequential fashion. In this work, a novel approach
for continual learning is proposed, which searches for the best neural
architecture for each coming task via sophisticatedly designed reinforcement
learning strategies. We name it as Reinforced Continual Learning. Our method
not only has good performance on preventing catastrophic forgetting but also
fits new tasks well. The experiments on sequential classification tasks for
variants of MNIST and CIFAR-100 datasets demonstrate that the proposed approach
outperforms existing continual learning alternatives for deep networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1&quot;&gt;Ju Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1&quot;&gt;Zhanxing Zhu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.12372">
<title>Learning Tree Distributions by Hidden Markov Models. (arXiv:1805.12372v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.12372</link>
<description rdf:parseType="Literal">&lt;p&gt;Hidden tree Markov models allow learning distributions for tree structured
data while being interpretable as nondeterministic automata. We provide a
concise summary of the main approaches in literature, focusing in particular on
the causality assumptions introduced by the choice of a specific tree visit
direction. We will then sketch a novel non-parametric generalization of the
bottom-up hidden tree Markov model with its interpretation as a
nondeterministic tree automaton with infinite states.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bacciu_D/0/1/0/all/0/1&quot;&gt;Davide Bacciu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Castellana_D/0/1/0/all/0/1&quot;&gt;Daniele Castellana&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.12375">
<title>Sample-Efficient Deep Reinforcement Learning via Episodic Backward Update. (arXiv:1805.12375v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.12375</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose Episodic Backward Update - a new algorithm to boost the
performance of a deep reinforcement learning agent by a fast reward
propagation. In contrast to the conventional use of the experience replay with
uniform random sampling, our agent samples a whole episode and successively
propagates the value of a state to its previous states. Our computationally
efficient recursive algorithm allows sparse and delayed rewards to propagate
efficiently through all transitions of a sampled episode. We evaluate our
algorithm on 2D MNIST Maze environment and 49 games of the Atari 2600
environment and show that our method improves sample efficiency with a
competitive amount of computational cost.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1&quot;&gt;Su Young Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Choi_S/0/1/0/all/0/1&quot;&gt;Sungik Choi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chung_S/0/1/0/all/0/1&quot;&gt;Sae-Young Chung&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.12381">
<title>Superensemble classifier for learning from imbalanced business school data set. (arXiv:1805.12381v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.12381</link>
<description rdf:parseType="Literal">&lt;p&gt;Private business schools in India face a common problem of selecting quality
students for their MBA programs to achieve desired placement percentage.
Business school data set is biased towards one class, i.e., imbalanced in
nature. And learning from imbalanced data set is a difficult proposition. Most
existing classification methods tend not to perform well on minority class
examples when the data set is extremely imbalanced, because they aim to
optimize the overall accuracy without considering the relative distribution of
each class. The aim of the paper is twofold. We first propose an integrated
sampling technique with an ensemble of classification tree (CT) and artificial
neural network (ANN) model as one of the methodologies which works better
compared to other similar methods. Further we propose a superensemble
imbalanced classifier which works better on the original business school data
set. Our proposed superensemble classifier not only handles the imbalance data
set but also achieves higher accuracy in case of feature selection cum
classification problems. The proposal has been compared with other
state-of-the-art classifiers and found to be very competitive.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chakraborty_T/0/1/0/all/0/1&quot;&gt;Tanujit Chakraborty&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chakraborty_A/0/1/0/all/0/1&quot;&gt;Ashis Kumar Chakraborty&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.12507">
<title>Asymptotic performance of regularized multi-task learning. (arXiv:1805.12507v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.12507</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper analyzes asymptotic performance of a regularized multi-task
learning model where task parameters are optimized jointly. If tasks are
closely related, empirical work suggests multi-task learning models to
outperform single-task ones in finite sample cases. As data size grows
indefinitely, we show the learned multi-classifier to optimize an average
misclassification error function which depicts the risk of applying multi-task
learning algorithm to making decisions. This technique conclusion demonstrates
the regularized multi-task learning model to be able to produce reliable
decision rule for each task in the sense that it will asymptotically converge
to the corresponding Bayes rule. Also, we find the interaction effect between
tasks vanishes as data size growing indefinitely, which is quite different from
the behavior in finite sample cases.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chen_S/0/1/0/all/0/1&quot;&gt;Shaohan Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gao_C/0/1/0/all/0/1&quot;&gt;Chuanhou Gao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.01641">
<title>Differentially Private Database Release via Kernel Mean Embeddings. (arXiv:1710.01641v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1710.01641</link>
<description rdf:parseType="Literal">&lt;p&gt;We lay theoretical foundations for new database release mechanisms that allow
third-parties to construct consistent estimators of population statistics,
while ensuring that the privacy of each individual contributing to the database
is protected. The proposed framework rests on two main ideas. First, releasing
(an estimate of) the kernel mean embedding of the data generating random
variable instead of the database itself still allows third-parties to construct
consistent estimators of a wide class of population statistics. Second, the
algorithm can satisfy the definition of differential privacy by basing the
released kernel mean embedding on entirely synthetic data points, while
controlling accuracy through the metric available in a Reproducing Kernel
Hilbert Space. We describe two instantiations of the proposed framework,
suitable under different scenarios, and prove theoretical results guaranteeing
differential privacy of the resulting algorithms and the consistency of
estimators constructed from their outputs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Balog_M/0/1/0/all/0/1&quot;&gt;Matej Balog&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tolstikhin_I/0/1/0/all/0/1&quot;&gt;Ilya Tolstikhin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Scholkopf_B/0/1/0/all/0/1&quot;&gt;Bernhard Sch&amp;#xf6;lkopf&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.11347">
<title>Learning to Adapt: Meta-Learning for Model-Based Control. (arXiv:1803.11347v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1803.11347</link>
<description rdf:parseType="Literal">&lt;p&gt;Although reinforcement learning methods can achieve impressive results in
simulation, the real world presents two major challenges: generating samples is
exceedingly expensive, and unexpected perturbations can cause proficient but
narrowly-learned policies to fail at test time. In this work, we propose to
learn how to quickly and effectively adapt online to new situations as well as
to perturbations. To enable sample-efficient meta-learning, we consider
learning online adaptation in the context of model-based reinforcement
learning. Our approach trains a global model such that, when combined with
recent data, the model can be be rapidly adapted to the local context. Our
experiments demonstrate that our approach can enable simulated agents to adapt
their behavior online to novel terrains, to a crippled leg, and in
highly-dynamic environments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Clavera_I/0/1/0/all/0/1&quot;&gt;Ignasi Clavera&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nagabandi_A/0/1/0/all/0/1&quot;&gt;Anusha Nagabandi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fearing_R/0/1/0/all/0/1&quot;&gt;Ronald S. Fearing&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1&quot;&gt;Pieter Abbeel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1&quot;&gt;Sergey Levine&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Finn_C/0/1/0/all/0/1&quot;&gt;Chelsea Finn&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.09060">
<title>An Information-Theoretic View for Deep Learning. (arXiv:1804.09060v6 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1804.09060</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep learning has transformed computer vision, natural language processing,
and speech recognition. However, two critical questions remain obscure: (1) why
do deep neural networks generalize better than shallow networks; and (2) does
it always hold that a deeper network leads to better performance? Specifically,
letting $L$ be the number of convolutional and pooling layers in a deep neural
network, and $n$ be the size of the training sample, we derive an upper bound
on the expected generalization error for this network, i.e.,
&lt;/p&gt;
&lt;p&gt;\begin{eqnarray*}
&lt;/p&gt;
&lt;p&gt;\mathbb{E}[R(W)-R_S(W)] \leq
\exp{\left(-\frac{L}{2}\log{\frac{1}{\eta}}\right)}\sqrt{\frac{2\sigma^2}{n}I(S,W)
}
&lt;/p&gt;
&lt;p&gt;\end{eqnarray*} where $\sigma &amp;gt;0$ is a constant depending on the loss
function, $0&amp;lt;\eta&amp;lt;1$ is a constant depending on the information loss for each
convolutional or pooling layer, and $I(S, W)$ is the mutual information between
the training sample $S$ and the output hypothesis $W$. This upper bound shows
that as the number of convolutional and pooling layers $L$ increases in the
network, the expected generalization error will decrease exponentially to zero.
Layers with strict information loss, such as the convolutional layers, reduce
the generalization error for the whole network; this answers the first
question. However, algorithms with zero expected generalization error does not
imply a small test error or $\mathbb{E}[R(W)]$. This is because
$\mathbb{E}[R_S(W)]$ is large when the information for fitting the data is lost
as the number of layers increases. This suggests that the claim `the deeper the
better&apos; is conditioned on a small training error or $\mathbb{E}[R_S(W)]$.
Finally, we show that deep learning satisfies a weak notion of stability and
the sample complexity of deep neural networks will decrease as $L$ increases.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Jingwei Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Liu_T/0/1/0/all/0/1&quot;&gt;Tongliang Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tao_D/0/1/0/all/0/1&quot;&gt;Dacheng Tao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.10846">
<title>Data science is science&apos;s second chance to get causal inference right: A classification of data science tasks. (arXiv:1804.10846v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1804.10846</link>
<description rdf:parseType="Literal">&lt;p&gt;Causal inference from observational data is the goal of many data analyses in
the health and social sciences. However, academic statistics has often frowned
upon data analyses with a causal objective. The introduction of the term &quot;data
science&quot; provides a historical opportunity to redefine data analysis in such a
way that it naturally accommodates causal inference from observational data.
Like others before, we organize the scientific contributions of data science
into three classes of tasks: description, prediction, and causal inference. An
explicit classification of data science tasks is necessary to discuss the data,
assumptions, and analytics required to successfully accomplish each task. We
argue that a failure to adequately describe the role of subject-matter expert
knowledge in data analysis is a source of widespread misunderstandings about
data science. Specifically, causal analyses typically require not only good
data and algorithms, but also domain expert knowledge. We discuss the
implications for the use of data science to guide decision-making in the real
world and to train data scientists.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hernan_M/0/1/0/all/0/1&quot;&gt;Miguel A. Hern&amp;#xe1;n&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hsu_J/0/1/0/all/0/1&quot;&gt;John Hsu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Healy_B/0/1/0/all/0/1&quot;&gt;Brian Healy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09039">
<title>Amortized Context Vector Inference for Sequence-to-Sequence Networks. (arXiv:1805.09039v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.09039</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural attention (NA) is an effective mechanism for inferring complex
structural data dependencies that span long temporal horizons. As a
consequence, it has become a key component of sequence-to-sequence models that
yield state-of-the-art performance in as hard tasks as abstractive document
summarization (ADS), machine translation (MT), and video captioning (VC). NA
mechanisms perform inference of context vectors; these constitute weighted sums
of deterministic input sequence encodings, adaptively sourced over long
temporal horizons. However, recent work in the field of amortized variational
inference (AVI) has shown that it is often useful to treat the representations
generated by deep networks as latent random variables. This allows for the
models to better explore the space of possible representations. Based on this
motivation, in this work we introduce a novel regard towards a popular NA
mechanism, namely soft-attention (SA). Our approach treats the context vectors
generated by SA models as latent variables, the posteriors of which are
inferred by employing AVI. Both the means and the covariance matrices of the
inferred posteriors are parameterized via deep network mechanisms similar to
those employed in the context of standard SA. To illustrate our method, we
implement it in the context of popular sequence-to-sequence model variants with
SA. We conduct an extensive experimental evaluation using challenging ADS, VC,
and MT benchmarks, and show how our approach compares to the baselines.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chatzis_S/0/1/0/all/0/1&quot;&gt;Sotirios Chatzis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Charalampous_A/0/1/0/all/0/1&quot;&gt;Aristotelis Charalampous&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tolias_K/0/1/0/all/0/1&quot;&gt;Kyriacos Tolias&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vassou_S/0/1/0/all/0/1&quot;&gt;Sotiris A. Vassou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.10451">
<title>Geometric Understanding of Deep Learning. (arXiv:1805.10451v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.10451</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep learning is the mainstream technique for many machine learning tasks,
including image recognition, machine translation, speech recognition, and so
on. It has outperformed conventional methods in various fields and achieved
great successes. Unfortunately, the understanding on how it works remains
unclear. It has the central importance to lay down the theoretic foundation for
deep learning.
&lt;/p&gt;
&lt;p&gt;In this work, we give a geometric view to understand deep learning: we show
that the fundamental principle attributing to the success is the manifold
structure in data, namely natural high dimensional data concentrates close to a
low-dimensional manifold, deep learning learns the manifold and the probability
distribution on it.
&lt;/p&gt;
&lt;p&gt;We further introduce the concepts of rectified linear complexity for deep
neural network measuring its learning capability, rectified linear complexity
of an embedding manifold describing the difficulty to be learned. Then we show
for any deep neural network with fixed architecture, there exists a manifold
that cannot be learned by the network. Finally, we propose to apply optimal
mass transportation theory to control the probability distribution in the
latent space.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lei_N/0/1/0/all/0/1&quot;&gt;Na Lei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_Z/0/1/0/all/0/1&quot;&gt;Zhongxuan Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yau_S/0/1/0/all/0/1&quot;&gt;Shing-Tung Yau&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gu_D/0/1/0/all/0/1&quot;&gt;David Xianfeng Gu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.10561">
<title>Adversarial Constraint Learning for Structured Prediction. (arXiv:1805.10561v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.10561</link>
<description rdf:parseType="Literal">&lt;p&gt;Constraint-based learning reduces the burden of collecting labels by having
users specify general properties of structured outputs, such as constraints
imposed by physical laws. We propose a novel framework for simultaneously
learning these constraints and using them for supervision, bypassing the
difficulty of using domain expertise to manually specify constraints. Learning
requires a black-box simulator of structured outputs, which generates valid
labels, but need not model their corresponding inputs or the input-label
relationship. At training time, we constrain the model to produce outputs that
cannot be distinguished from simulated labels by adversarial training.
Providing our framework with a small number of labeled inputs gives rise to a
new semi-supervised structured prediction model; we evaluate this model on
multiple tasks --- tracking, pose estimation and time series prediction --- and
find that it achieves high accuracy with only a small number of labeled inputs.
In some cases, no labels are required at all.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ren_H/0/1/0/all/0/1&quot;&gt;Hongyu Ren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stewart_R/0/1/0/all/0/1&quot;&gt;Russell Stewart&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_J/0/1/0/all/0/1&quot;&gt;Jiaming Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kuleshov_V/0/1/0/all/0/1&quot;&gt;Volodymyr Kuleshov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ermon_S/0/1/0/all/0/1&quot;&gt;Stefano Ermon&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11046">
<title>Scalable Methods for 8-bit Training of Neural Networks. (arXiv:1805.11046v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.11046</link>
<description rdf:parseType="Literal">&lt;p&gt;Quantized Neural Networks (QNNs) are often used to improve network efficiency
during the inference phase, i.e. after the network has been trained. Extensive
research in the field suggests many different quantization schemes. Still, the
number of bits required, as well as the best quantization scheme, are yet
unknown. Our theoretical analysis suggests that most of the training process is
robust to substantial precision reduction, and points to only a few specific
operations that require higher precision. Armed with this knowledge, we
quantize the model parameters, activations and layer gradients to 8-bit,
leaving at a higher precision only the final step in the computation of the
weight gradients. Additionally, as QNNs require batch-normalization to be
trained at high precision, we introduce Range Batch-Normalization (BN) which
has significantly higher tolerance to quantization noise and improved
computational complexity. Our simulations show that Range BN is equivalent to
the traditional batch norm if a precise scale adjustment, which can be
approximated analytically, is applied. To the best of the authors&apos; knowledge,
this work is the first to quantize the weights, activations, as well as a
substantial volume of the gradients stream, in all layers (including batch
normalization) to 8-bit while showing state-of-the-art results over the
ImageNet-1K dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Banner_R/0/1/0/all/0/1&quot;&gt;Ron Banner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hubara_I/0/1/0/all/0/1&quot;&gt;Itay Hubara&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hoffer_E/0/1/0/all/0/1&quot;&gt;Elad Hoffer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Soudry_D/0/1/0/all/0/1&quot;&gt;Daniel Soudry&lt;/a&gt;</dc:creator>
</item></rdf:RDF>