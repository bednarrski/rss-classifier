<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Good papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Good Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2017-12-10T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.03133"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.03166"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1611.01639"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.02820"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.02838"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.02861"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.02869"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.02975"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.03010"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.03043"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.03086"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.03132"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1707.09324"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.02865"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.08624"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1708.06850"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.02831"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.02854"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.02902"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.02903"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.02950"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.03134"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1605.03795"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1609.05820"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1701.00299"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1706.03922"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.09805"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.03946"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.05828"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.06100"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.08682"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1712.03133">
<title>Building competitive direct acoustics-to-word models for English conversational speech recognition. (arXiv:1712.03133v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1712.03133</link>
<description rdf:parseType="Literal">&lt;p&gt;Direct acoustics-to-word (A2W) models in the end-to-end paradigm have
received increasing attention compared to conventional sub-word based automatic
speech recognition models using phones, characters, or context-dependent hidden
Markov model states. This is because A2W models recognize words from speech
without any decoder, pronunciation lexicon, or externally-trained language
model, making training and decoding with such models simple. Prior work has
shown that A2W models require orders of magnitude more training data in order
to perform comparably to conventional models. Our work also showed this
accuracy gap when using the English Switchboard-Fisher data set. This paper
describes a recipe to train an A2W model that closes this gap and is at-par
with state-of-the-art sub-word based models. We achieve a word error rate of
8.8%/13.9% on the Hub5-2000 Switchboard/CallHome test sets without any decoder
or language model. We find that model initialization, training data order, and
regularization have the most impact on the A2W model performance. Next, we
present a joint word-character A2W model that learns to first spell the word
and then recognize it. This model provides a rich output to the user instead of
simple word hypotheses, making it especially useful in the case of words unseen
or rarely-seen during training.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Audhkhasi_K/0/1/0/all/0/1&quot;&gt;Kartik Audhkhasi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kingsbury_B/0/1/0/all/0/1&quot;&gt;Brian Kingsbury&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ramabhadran_B/0/1/0/all/0/1&quot;&gt;Bhuvana Ramabhadran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saon_G/0/1/0/all/0/1&quot;&gt;George Saon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Picheny_M/0/1/0/all/0/1&quot;&gt;Michael Picheny&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.03166">
<title>Improving Brain Storm Optimization Algorithm via Simplex Search. (arXiv:1712.03166v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1712.03166</link>
<description rdf:parseType="Literal">&lt;p&gt;Through modeling human&apos;s brainstorming process, the brain storm optimization
(BSO) algorithm has become a promising population based evolution algorithm.
However, BSO is often good at global exploration but not good enough at local
exploitation, just like most global optimization algorithms. In this paper, the
Nelder-Mead&apos;s Simplex (NMS) method is adopted in a simple version of BSO. Our
goal is to combine BSO&apos;s exploration ability and NMS&apos;s exploitation ability
together, and develop an enhanced BSO via a better balance between global
exploration and local exploitation. Large number of experimental results are
reported, and the proposed algorithm is shown to perform better than both BSO
and NMS.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1&quot;&gt;Wei Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1&quot;&gt;YingYing Cao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1&quot;&gt;Yifei Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1&quot;&gt;Qunfeng Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yun Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1611.01639">
<title>Robustly representing inferential uncertainty in deep neural networks through sampling. (arXiv:1611.01639v6 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1611.01639</link>
<description rdf:parseType="Literal">&lt;p&gt;As deep neural networks (DNNs) are applied to increasingly challenging
problems, they will need to be able to represent their own uncertainty.
Modeling uncertainty is one of the key features of Bayesian methods. Using
Bernoulli dropout with sampling at prediction time has recently been proposed
as an efficient and well performing variational inference method for DNNs.
However, sampling from other multiplicative noise based variational
distributions has not been investigated in depth. We evaluated Bayesian DNNs
trained with Bernoulli or Gaussian multiplicative masking of either the units
(dropout) or the weights (dropconnect). We tested the calibration of the
probabilistic predictions of Bayesian convolutional neural networks (CNNs) on
MNIST and CIFAR-10. Sampling at prediction time increased the calibration of
the DNNs&apos; probabalistic predictions. Sampling weights, whether Gaussian or
Bernoulli, led to more robust representation of uncertainty compared to
sampling of units. However, using either Gaussian or Bernoulli dropout led to
increased test set classification accuracy. Based on these findings we used
both Bernoulli dropout and Gaussian dropconnect concurrently, which we show
approximates the use of a spike-and-slab variational distribution without
increasing the number of learned parameters. We found that spike-and-slab
sampling had higher test set performance than Gaussian dropconnect and more
robustly represented its uncertainty compared to Bernoulli dropout.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+McClure_P/0/1/0/all/0/1&quot;&gt;Patrick McClure&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kriegeskorte_N/0/1/0/all/0/1&quot;&gt;Nikolaus Kriegeskorte&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.02820">
<title>A Deep Network Model for Paraphrase Detection in Short Text Messages. (arXiv:1712.02820v1 [cs.IR])</title>
<link>http://arxiv.org/abs/1712.02820</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper is concerned with paraphrase detection. The ability to detect
similar sentences written in natural language is crucial for several
applications, such as text mining, text summarization, plagiarism detection,
authorship authentication and question answering. Given two sentences, the
objective is to detect whether they are semantically identical. An important
insight from this work is that existing paraphrase systems perform well when
applied on clean texts, but they do not necessarily deliver good performance
against noisy texts. Challenges with paraphrase detection on user generated
short texts, such as Twitter, include language irregularity and noise. To cope
with these challenges, we propose a novel deep neural network-based approach
that relies on coarse-grained sentence modeling using a convolutional neural
network and a long short-term memory model, combined with a specific
fine-grained word-level similarity matching model. Our experimental results
show that the proposed approach outperforms existing state-of-the-art
approaches on user-generated noisy social media data, such as Twitter texts,
and achieves highly competitive performance on a cleaner corpus.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Agarwal_B/0/1/0/all/0/1&quot;&gt;Basant Agarwal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ramampiaro_H/0/1/0/all/0/1&quot;&gt;Heri Ramampiaro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Langseth_H/0/1/0/all/0/1&quot;&gt;Helge Langseth&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ruocco_M/0/1/0/all/0/1&quot;&gt;Massimiliano Ruocco&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.02838">
<title>End-to-End Offline Goal-Oriented Dialog Policy Learning via Policy Gradient. (arXiv:1712.02838v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1712.02838</link>
<description rdf:parseType="Literal">&lt;p&gt;Learning a goal-oriented dialog policy is generally performed offline with
supervised learning algorithms or online with reinforcement learning (RL).
Additionally, as companies accumulate massive quantities of dialog transcripts
between customers and trained human agents, encoder-decoder methods have gained
popularity as agent utterances can be directly treated as supervision without
the need for utterance-level annotations. However, one potential drawback of
such approaches is that they myopically generate the next agent utterance
without regard for dialog-level considerations. To resolve this concern, this
paper describes an offline RL method for learning from unannotated corpora that
can optimize a goal-oriented policy at both the utterance and dialog level. We
introduce a novel reward function and use both on-policy and off-policy policy
gradient to learn a policy offline without requiring online user interaction or
an explicit state space definition.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_L/0/1/0/all/0/1&quot;&gt;Li Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Small_K/0/1/0/all/0/1&quot;&gt;Kevin Small&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rokhlenko_O/0/1/0/all/0/1&quot;&gt;Oleg Rokhlenko&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Elkan_C/0/1/0/all/0/1&quot;&gt;Charles Elkan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.02861">
<title>Per-Pixel Feedback for improving Semantic Segmentation. (arXiv:1712.02861v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1712.02861</link>
<description rdf:parseType="Literal">&lt;p&gt;Semantic segmentation is the task of assigning a label to each pixel in the
image.In recent years, deep convolutional neural networks have been driving
advances in multiple tasks related to cognition. Although, DCNNs have resulted
in unprecedented visual recognition performances, they offer little
transparency. To understand how DCNN based models work at the task of semantic
segmentation, we try to analyze the DCNN models in semantic segmentation. We
try to find the importance of global image information for labeling pixels.
&lt;/p&gt;
&lt;p&gt;Based on the experiments on discriminative regions, and modeling of
fixations, we propose a set of new training loss functions for fine-tuning DCNN
based models. The proposed training regime has shown improvement in performance
of DeepLab Large FOV(VGG-16) Segmentation model for PASCAL VOC 2012 dataset.
However, further test remains to conclusively evaluate the benefits due to the
proposed loss functions across models, and data-sets.
&lt;/p&gt;
&lt;p&gt;Submitted in part fulfillment of the requirements for the degree of
Integrated Masters of Science in Applied Mathematics.
&lt;/p&gt;
&lt;p&gt;Update: Further Experiment showed minimal benefits.
&lt;/p&gt;
&lt;p&gt;Code Available [here](https://github.com/BardOfCodes/Seg-Unravel).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ganeshan_A/0/1/0/all/0/1&quot;&gt;Aditya Ganeshan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.02869">
<title>Perspectival Knowledge in PSOA RuleML: Representation, Model Theory, and Translation. (arXiv:1712.02869v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1712.02869</link>
<description rdf:parseType="Literal">&lt;p&gt;In Positional-Slotted Object-Applicative (PSOA) RuleML, a predicate
application (atom) can have an Object IDentifier (OID) and descriptors that may
be positional arguments (tuples) or attribute-value pairs (slots). PSOA RuleML
1.0 specifies for each descriptor whether it is to be interpreted under the
perspective of the predicate in whose scope it occurs. This perspectivity
dimension refines the space between oidless, positional atoms (relationships)
and oidful, slotted atoms (frames): While relationships use only a
predicate-scope-sensitive (predicate-dependent) tuple and frames use only
predicate-scope-insensitive (predicate-independent) slots, PSOA RuleML 1.0 uses
a systematics of orthogonal constructs also permitting atoms with
(predicate-)independent tuples and atoms with (predicate-)dependent slots. This
supports data and knowledge representation where a slot attribute can have
different values depending on the predicate. PSOA thus extends object-oriented
multi-membership and multiple inheritance. Based on objectification, PSOA laws
are given: Besides unscoping and centralization, the semantic restriction and
transformation of describution permits rescoping of one atom&apos;s independent
descriptors to another atom with the same OID but a different predicate. For
inheritance, default descriptors are realized by rules. On top of a metamodel
and a Grailog visualization, PSOA&apos;s atom systematics for facts, queries, and
rules is explained. The presentation and (XML-)serialization syntaxes of PSOA
RuleML 1.0 are introduced. Its model-theoretic semantics is formalized by
extending the earlier interpretation functions for dependent descriptors. The
open-source PSOATransRun 1.3 system realizes PSOA RuleML 1.0 by a translator to
runtime predicates, including for dependent tuples (prdtupterm) and slots
(prdsloterm). Our tests show efficiency advantages of dependent and tupled
modeling.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Boley_H/0/1/0/all/0/1&quot;&gt;Harold Boley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zou_G/0/1/0/all/0/1&quot;&gt;Gen Zou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.02975">
<title>Recruitment Market Trend Analysis with Sequential Latent Variable Models. (arXiv:1712.02975v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1712.02975</link>
<description rdf:parseType="Literal">&lt;p&gt;Recruitment market analysis provides valuable understanding of
industry-specific economic growth and plays an important role for both
employers and job seekers. With the rapid development of online recruitment
services, massive recruitment data have been accumulated and enable a new
paradigm for recruitment market analysis. However, traditional methods for
recruitment market analysis largely rely on the knowledge of domain experts and
classic statistical models, which are usually too general to model large-scale
dynamic recruitment data, and have difficulties to capture the fine-grained
market trends. To this end, in this paper, we propose a new research paradigm
for recruitment market analysis by leveraging unsupervised learning techniques
for automatically discovering recruitment market trends based on large-scale
recruitment data. Specifically, we develop a novel sequential latent variable
model, named MTLVM, which is designed for capturing the sequential dependencies
of corporate recruitment states and is able to automatically learn the latent
recruitment topics within a Bayesian generative framework. In particular, to
capture the variability of recruitment topics over time, we design hierarchical
dirichlet processes for MTLVM. These processes allow to dynamically generate
the evolving recruitment topics. Finally, we implement a prototype system to
empirically evaluate our approach based on real-world recruitment data in
China. Indeed, by visualizing the results from MTLVM, we can successfully
reveal many interesting findings, such as the popularity of LBS related jobs
reached the peak in the 2nd half of 2014, and decreased in 2015.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_C/0/1/0/all/0/1&quot;&gt;Chen Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1&quot;&gt;Hengshu Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiong_H/0/1/0/all/0/1&quot;&gt;Hui Xiong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ding_P/0/1/0/all/0/1&quot;&gt;Pengliang Ding&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_F/0/1/0/all/0/1&quot;&gt;Fang Xie&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.03010">
<title>Stochastic Dual Coordinate Descent with Bandit Sampling. (arXiv:1712.03010v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1712.03010</link>
<description rdf:parseType="Literal">&lt;p&gt;Coordinate descent methods minimize a cost function by updating a single
decision variable (corresponding to one coordinate) at a time. Ideally, one
would update the decision variable that yields the largest marginal decrease in
the cost function. However, finding this coordinate would require checking all
of them, which is not computationally practical. We instead propose a new
adaptive method for coordinate descent. First, we define a lower bound on the
decrease of the cost function when a coordinate is updated and, instead of
calculating this lower bound for all coordinates, we use a multi-armed bandit
algorithm to learn which coordinates result in the largest marginal decrease
while simultaneously performing coordinate descent. We show that our approach
improves the convergence of the coordinate methods (including parallel
versions) both theoretically and experimentally.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Salehi_F/0/1/0/all/0/1&quot;&gt;Farnood Salehi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Thiran_P/0/1/0/all/0/1&quot;&gt;Patrick Thiran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Celis_L/0/1/0/all/0/1&quot;&gt;L. Elisa Celis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.03043">
<title>A Heuristic Search Algorithm Using the Stability of Learning Algorithms as the Fitness Function in Certain Scenarios: An Artificial General Intelligence Engineering Approach. (arXiv:1712.03043v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1712.03043</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents a non-manual design engineering method based on heuristic
search algorithm to search for candidate agents in the solution space which
formed by artificial intelligence agents modeled on the base of
bionics.Compared with the artificial design method represented by meta-learning
and the bionics method represented by the neural architecture chip,this method
is more feasible for realizing artificial general intelligence,and it has a
much better interaction with cognitive neuroscience;at the same time,the
engineering method is based on the theoretical hypothesis that the final
learning algorithm is stable in certain scenarios,and has generalization
ability in various scenarios.The paper discusses the theory preliminarily and
proposes the possible correlation between the theory and the fixed-point
theorem in the field of mathematics.Limited by the author&apos;s knowledge
level,this correlation is proposed only as a kind of conjecture.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Zengkun Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.03086">
<title>FlagIt: A System for Minimally Supervised Human Trafficking Indicator Mining. (arXiv:1712.03086v1 [cs.CY])</title>
<link>http://arxiv.org/abs/1712.03086</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we describe and study the indicator mining problem in the
online sex advertising domain. We present an in-development system, FlagIt
(Flexible and adaptive generation of Indicators from text), which combines the
benefits of both a lightweight expert system and classical semi-supervision
(heuristic re-labeling) with recently released state-of-the-art unsupervised
text embeddings to tag millions of sentences with indicators that are highly
correlated with human trafficking. The FlagIt technology stack is open source.
On preliminary evaluations involving five indicators, FlagIt illustrates
promising performance compared to several alternatives. The system is being
actively developed, refined and integrated into a domain-specific search system
used by over 200 law enforcement agencies to combat human trafficking, and is
being aggressively extended to mine at least six more indicators with minimal
programming effort. FlagIt is a good example of a system that operates in
limited label settings, and that requires creative combinations of established
machine learning techniques to produce outputs that could be used by real-world
non-technical analysts.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kejriwal_M/0/1/0/all/0/1&quot;&gt;Mayank Kejriwal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ding_J/0/1/0/all/0/1&quot;&gt;Jiayuan Ding&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shao_R/0/1/0/all/0/1&quot;&gt;Runqi Shao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kumar_A/0/1/0/all/0/1&quot;&gt;Anoop Kumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Szekely_P/0/1/0/all/0/1&quot;&gt;Pedro Szekely&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.03132">
<title>A Class of Logistic Functions for Approximating State-Inclusive Koopman Operators. (arXiv:1712.03132v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1712.03132</link>
<description rdf:parseType="Literal">&lt;p&gt;An outstanding challenge in nonlinear systems theory is identification or
learning of a given nonlinear system&apos;s Koopman operator directly from data or
models. Advances in extended dynamic mode decomposition approaches and machine
learning methods have enabled data-driven discovery of Koopman operators, for
both continuous and discrete-time systems. Since Koopman operators are often
infinite-dimensional, they are approximated in practice using
finite-dimensional systems. The fidelity and convergence of a given
finite-dimensional Koopman approximation is a subject of ongoing research. In
this paper we introduce a class of Koopman observable functions that confer an
approximate closure property on their corresponding finite-dimensional
approximations of the Koopman operator. We derive error bounds for the fidelity
of this class of observable functions, as well as identify two key learning
parameters which can be used to tune performance. We illustrate our approach on
two classical nonlinear system models: the Van Der Pol oscillator and the
bistable toggle switch.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Johnson_C/0/1/0/all/0/1&quot;&gt;Charles A. Johnson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yeung_E/0/1/0/all/0/1&quot;&gt;Enoch Yeung&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1707.09324">
<title>Empirical Evaluation of Abstract Argumentation: Supporting the Need for Bipolar and Probabilistic Approaches. (arXiv:1707.09324v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1707.09324</link>
<description rdf:parseType="Literal">&lt;p&gt;In dialogical argumentation it is often assumed that the involved parties
always correctly identify the intended statements posited by each other,
realize all of the associated relations, conform to the three acceptability
states (accepted, rejected, undecided), adjust their views when new and correct
information comes in, and that a framework handling only attack relations is
sufficient to represent their opinions. Although it is natural to make these
assumptions as a starting point for further research, removing them or even
acknowledging that such removal should happen is more challenging for some of
these concepts than for others. Probabilistic argumentation is one of the
approaches that can be harnessed for more accurate user modelling. The
epistemic approach allows us to represent how much a given argument is believed
by a given person, offering us the possibility to express more than just three
agreement states. It is equipped with a wide range of postulates, including
those that do not make any restrictions concerning how initial arguments should
be viewed, thus potentially being more adequate for handling beliefs of the
people that have not fully disclosed their opinions in comparison to Dung&apos;s
semantics. The constellation approach can be used to represent the views of
different people concerning the structure of the framework we are dealing with,
including cases in which not all relations are acknowledged or when they are
seen differently than intended. Finally, bipolar argumentation frameworks can
be used to express both positive and negative relations between arguments. In
this paper we describe the results of an experiment in which participants
judged dialogues in terms of agreement and structure. We compare our findings
with the aforementioned assumptions as well as with the constellation and
epistemic approaches to probabilistic argumentation and bipolar argumentation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Polberg_S/0/1/0/all/0/1&quot;&gt;Sylwia Polberg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hunter_A/0/1/0/all/0/1&quot;&gt;Anthony Hunter&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.02865">
<title>Prosocial learning agents solve generalized Stag Hunts better than selfish ones. (arXiv:1709.02865v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1709.02865</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep reinforcement learning has become an important paradigm for constructing
agents that can enter complex multi-agent situations and improve their policies
through experience. One commonly used technique is reactive training - applying
standard RL methods while treating other agents as a part of the learner&apos;s
environment. It is known that in general-sum games reactive training can lead
groups of agents to converge to inefficient outcomes. We focus on one such
class of environments: Stag Hunt games. Here agents either choose a risky
cooperative policy (which leads to high payoffs if both choose it but low
payoffs to an agent who attempts it alone) or a safe one (which leads to a safe
payoff no matter what). We ask how we can change the learning rule of a single
agent to improve its outcomes in Stag Hunts that include other reactive
learners. We extend existing work on reward-shaping in multi-agent
reinforcement learning and show that that making a single agent prosocial, that
is, making them care about the rewards of their partners can increase the
probability that groups converge to good outcomes. Thus, even if we control a
single agent in a group making that agent prosocial can increase our agent&apos;s
long-run payoff. We show experimentally that this result carries over to a
variety of more complex environments with Stag Hunt-like dynamics including
ones where agents must learn from raw input pixels.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peysakhovich_A/0/1/0/all/0/1&quot;&gt;Alexander Peysakhovich&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lerer_A/0/1/0/all/0/1&quot;&gt;Adam Lerer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.08624">
<title>Long Text Generation via Adversarial Training with Leaked Information. (arXiv:1709.08624v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1709.08624</link>
<description rdf:parseType="Literal">&lt;p&gt;Automatically generating coherent and semantically meaningful text has many
applications in machine translation, dialogue systems, image captioning, etc.
Recently, by combining with policy gradient, Generative Adversarial Nets (GAN)
that use a discriminative model to guide the training of the generative model
as a reinforcement learning policy has shown promising results in text
generation. However, the scalar guiding signal is only available after the
entire text has been generated and lacks intermediate information about text
structure during the generative process. As such, it limits its success when
the length of the generated text samples is long (more than 20 words). In this
paper, we propose a new framework, called LeakGAN, to address the problem for
long text generation. We allow the discriminative net to leak its own
high-level extracted features to the generative net to further help the
guidance. The generator incorporates such informative signals into all
generation steps through an additional Manager module, which takes the
extracted features of current generated words and outputs a latent vector to
guide the Worker module for next-word generation. Our extensive experiments on
synthetic data and various real-world tasks with Turing test demonstrate that
LeakGAN is highly effective in long text generation and also improves the
performance in short text generation scenarios. More importantly, without any
supervision, LeakGAN would be able to implicitly learn sentence structures only
through the interaction between Manager and Worker.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1&quot;&gt;Jiaxian Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_S/0/1/0/all/0/1&quot;&gt;Sidi Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cai_H/0/1/0/all/0/1&quot;&gt;Han Cai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1&quot;&gt;Weinan Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1&quot;&gt;Yong Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jun Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1708.06850">
<title>Learning Deep Neural Network Representations for Koopman Operators of Nonlinear Dynamical Systems. (arXiv:1708.06850v2 [cs.LG] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1708.06850</link>
<description rdf:parseType="Literal">&lt;p&gt;The Koopman operator has recently garnered much attention for its value in
dynamical systems analysis and data-driven model discovery. However, its
application has been hindered by the computational complexity of extended
dynamic mode decomposition; this requires a combinatorially large basis set to
adequately describe many nonlinear systems of interest, e.g. cyber-physical
infrastructure systems, biological networks, social systems, and fluid
dynamics. Often the dictionaries generated for these problems are manually
curated, requiring domain-specific knowledge and painstaking tuning. In this
paper we introduce a deep learning framework for learning Koopman operators of
nonlinear dynamical systems. We show that this novel method automatically
selects efficient deep dictionaries, outperforming state-of-the-art methods. We
benchmark this method on partially observed nonlinear systems, including the
glycolytic oscillator and show it is able to predict quantitatively 100 steps
into the future, using only a single timepoint, and qualitative oscillatory
behavior 400 steps into the future.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yeung_E/0/1/0/all/0/1&quot;&gt;Enoch Yeung&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kundu_S/0/1/0/all/0/1&quot;&gt;Soumya Kundu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hodas_N/0/1/0/all/0/1&quot;&gt;Nathan Hodas&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.02831">
<title>RelNN: A Deep Neural Model for Relational Learning. (arXiv:1712.02831v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1712.02831</link>
<description rdf:parseType="Literal">&lt;p&gt;Statistical relational AI (StarAI) aims at reasoning and learning in noisy
domains described in terms of objects and relationships by combining
probability with first-order logic. With huge advances in deep learning in the
current years, combining deep networks with first-order logic has been the
focus of several recent studies. Many of the existing attempts, however, only
focus on relations and ignore object properties. The attempts that do consider
object properties are limited in terms of modelling power or scalability. In
this paper, we develop relational neural networks (RelNNs) by adding hidden
layers to relational logistic regression (the relational counterpart of
logistic regression). We learn latent properties for objects both directly and
through general rules. Back-propagation is used for training these models. A
modular, layer-wise architecture facilitates utilizing the techniques developed
within deep learning community to our architecture. Initial experiments on
eight tasks over three real-world datasets show that RelNNs are promising
models for relational learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kazemi_S/0/1/0/all/0/1&quot;&gt;Seyed Mehran Kazemi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Poole_D/0/1/0/all/0/1&quot;&gt;David Poole&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.02854">
<title>Stochastic reconstruction of an oolitic limestone by generative adversarial networks. (arXiv:1712.02854v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1712.02854</link>
<description rdf:parseType="Literal">&lt;p&gt;Stochastic image reconstruction is a key part of modern digital rock physics
and materials analysis that aims to create numerous representative samples of
material micro-structures for upscaling, numerical computation of effective
properties and uncertainty quantification. We present a method of
three-dimensional stochastic image reconstruction based on generative
adversarial neural networks (GANs). GANs represent a framework of unsupervised
learning methods that require no a priori inference of the probability
distribution associated with the training data. Using a fully convolutional
neural network allows fast sampling of large volumetric images.We apply a GAN
based workflow of network training and image generation to an oolitic Ketton
limestone micro-CT dataset. Minkowski functionals, effective permeability as
well as velocity distributions of simulated flow within the acquired images are
compared with the synthetic reconstructions generated by the deep neural
network. While our results show that GANs allow a fast and accurate
reconstruction of the evaluated image dataset, we address a number of open
questions and challenges involved in the evaluation of generative network-based
methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mosser_L/0/1/0/all/0/1&quot;&gt;Lukas Mosser&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dubrule_O/0/1/0/all/0/1&quot;&gt;Olivier Dubrule&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Blunt_M/0/1/0/all/0/1&quot;&gt;Martin J. Blunt&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.02902">
<title>Multiple Adaptive Bayesian Linear Regression for Scalable Bayesian Optimization with Warm Start. (arXiv:1712.02902v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1712.02902</link>
<description rdf:parseType="Literal">&lt;p&gt;Bayesian optimization (BO) is a model-based approach for gradient-free
black-box function optimization. Typically, BO is powered by a Gaussian process
(GP), whose algorithmic complexity is cubic in the number of evaluations.
Hence, GP-based BO cannot leverage large amounts of past or related function
evaluations, for example, to warm start the BO procedure. We develop a multiple
adaptive Bayesian linear regression model as a scalable alternative whose
complexity is linear in the number of observations. The multiple Bayesian
linear regression models are coupled through a shared feedforward neural
network, which learns a joint representation and transfers knowledge across
machine learning problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Perrone_V/0/1/0/all/0/1&quot;&gt;Valerio Perrone&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Jenatton_R/0/1/0/all/0/1&quot;&gt;Rodolphe Jenatton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Seeger_M/0/1/0/all/0/1&quot;&gt;Matthias Seeger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Archambeau_C/0/1/0/all/0/1&quot;&gt;Cedric Archambeau&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.02903">
<title>Blind Multi-class Ensemble Learning with Unequally Reliable Classifiers. (arXiv:1712.02903v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1712.02903</link>
<description rdf:parseType="Literal">&lt;p&gt;The rising interest in pattern recognition and data analytics has spurred the
development of innovative machine learning algorithms and tools. However, as
each algorithm has its strengths and limitations, one is motivated to
judiciously fuse multiple algorithms in order to find the &quot;best&quot; performing
one, for a given dataset. Ensemble learning aims at such high-performance
meta-algorithm, by combining the outputs from multiple algorithms. The present
work introduces a blind scheme for learning from ensembles of classifiers,
using a moment matching method that leverages joint tensor and matrix
factorization. Blind refers to the combiner who has no knowledge of the
ground-truth labels that each classifier has been trained on. A rigorous
performance analysis is derived and the proposed scheme is evaluated on
synthetic and real datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Traganitis_P/0/1/0/all/0/1&quot;&gt;Panagiotis A. Traganitis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pages_Zamora_A/0/1/0/all/0/1&quot;&gt;Alba Pag&amp;#xe8;s-Zamora&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Giannakis_G/0/1/0/all/0/1&quot;&gt;Georgios B. Giannakis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.02950">
<title>CycleGAN: a Master of Steganography. (arXiv:1712.02950v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1712.02950</link>
<description rdf:parseType="Literal">&lt;p&gt;CycleGAN is one of the latest successful approaches to learn a correspondence
between two image distributions. In a series of experiments, we demonstrate an
intriguing property of the model: CycleGAN learns to &quot;hide&quot; information about a
source image inside the generated image in nearly imperceptible, high-frequency
noise. This trick ensures that the complementary generator can recover the
original sample and thus satisfy the cyclic consistency requirement, but the
generated image remains realistic. We connect this phenomenon with adversarial
attacks by viewing CycleGAN&apos;s training procedure as training a generator of
adversarial examples, thereby showing that adversarial attacks are not limited
to classifiers but also may target generative models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chu_C/0/1/0/all/0/1&quot;&gt;Casey Chu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhmoginov_A/0/1/0/all/0/1&quot;&gt;Andrey Zhmoginov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sandler_M/0/1/0/all/0/1&quot;&gt;Mark Sandler&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.03134">
<title>On Adaptive Estimation for Dynamic Bernoulli Bandits. (arXiv:1712.03134v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1712.03134</link>
<description rdf:parseType="Literal">&lt;p&gt;The multi-armed bandit (MAB) problem is a classic example of the
exploration-exploitation dilemma. It is concerned with maximising the total
rewards for a gambler by sequentially pulling an arm from a multi-armed slot
machine where each arm is associated with a reward distribution. In static
MABs, the reward distributions do not change over time, while in dynamic MABs,
each arm&apos;s reward distribution can change, and the optimal arm can switch over
time. Motivated by many real applications where rewards are binary counts, we
focus on dynamic Bernoulli bandits. Standard methods like $\epsilon$-Greedy and
Upper Confidence Bound (UCB), which rely on the sample mean estimator, often
fail to track the changes in underlying reward for dynamic problems. In this
paper, we overcome the shortcoming of slow response to change by deploying
adaptive estimation in the standard methods and propose a new family of
algorithms, which are adaptive versions of $\epsilon$-Greedy, UCB, and Thompson
sampling. These new methods are simple and easy to implement. Moreover, they do
not require any prior knowledge about the data, which is important for real
applications. We examine the new algorithms numerically in different scenarios
and find out that the results show solid improvements of our algorithms in
dynamic environments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lu_X/0/1/0/all/0/1&quot;&gt;Xue Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Adams_N/0/1/0/all/0/1&quot;&gt;Niall Adams&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kantas_N/0/1/0/all/0/1&quot;&gt;Nikolas Kantas&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1605.03795">
<title>Exponential Machines. (arXiv:1605.03795v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1605.03795</link>
<description rdf:parseType="Literal">&lt;p&gt;Modeling interactions between features improves the performance of machine
learning solutions in many domains (e.g. recommender systems or sentiment
analysis). In this paper, we introduce Exponential Machines (ExM), a predictor
that models all interactions of every order. The key idea is to represent an
exponentially large tensor of parameters in a factorized format called Tensor
Train (TT). The Tensor Train format regularizes the model and lets you control
the number of underlying parameters. To train the model, we develop a
stochastic Riemannian optimization procedure, which allows us to fit tensors
with 2^160 entries. We show that the model achieves state-of-the-art
performance on synthetic data with high-order interactions and that it works on
par with high-order factorization machines on a recommender system dataset
MovieLens 100K.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Novikov_A/0/1/0/all/0/1&quot;&gt;Alexander Novikov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Trofimov_M/0/1/0/all/0/1&quot;&gt;Mikhail Trofimov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Oseledets_I/0/1/0/all/0/1&quot;&gt;Ivan Oseledets&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1609.05820">
<title>The Projected Power Method: An Efficient Algorithm for Joint Alignment from Pairwise Differences. (arXiv:1609.05820v3 [cs.IT] UPDATED)</title>
<link>http://arxiv.org/abs/1609.05820</link>
<description rdf:parseType="Literal">&lt;p&gt;Various applications involve assigning discrete label values to a collection
of objects based on some pairwise noisy data. Due to the discrete---and hence
nonconvex---structure of the problem, computing the optimal assignment
(e.g.~maximum likelihood assignment) becomes intractable at first sight. This
paper makes progress towards efficient computation by focusing on a concrete
joint alignment problem---that is, the problem of recovering $n$ discrete
variables $x_i \in \{1,\cdots, m\}$, $1\leq i\leq n$ given noisy observations
of their modulo differences $\{x_i - x_j~\mathsf{mod}~m\}$. We propose a
low-complexity and model-free procedure, which operates in a lifted space by
representing distinct label values in orthogonal directions, and which attempts
to optimize quadratic functions over hypercubes. Starting with a first guess
computed via a spectral method, the algorithm successively refines the iterates
via projected power iterations. We prove that for a broad class of statistical
models, the proposed projected power method makes no error---and hence
converges to the maximum likelihood estimate---in a suitable regime. Numerical
experiments have been carried out on both synthetic and real data to
demonstrate the practicality of our algorithm. We expect this algorithmic
framework to be effective for a broad range of discrete assignment problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yuxin Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Candes_E/0/1/0/all/0/1&quot;&gt;Emmanuel Candes&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1701.00299">
<title>Dynamic Deep Neural Networks: Optimizing Accuracy-Efficiency Trade-offs by Selective Execution. (arXiv:1701.00299v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1701.00299</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce Dynamic Deep Neural Networks (D2NN), a new type of feed-forward
deep neural network that allows selective execution. Given an input, only a
subset of D2NN neurons are executed, and the particular subset is determined by
the D2NN itself. By pruning unnecessary computation depending on input, D2NNs
provide a way to improve computational efficiency. To achieve dynamic selective
execution, a D2NN augments a feed-forward deep neural network (directed acyclic
graph of differentiable modules) with controller modules. Each controller
module is a sub-network whose output is a decision that controls whether other
modules can execute. A D2NN is trained end to end. Both regular and controller
modules in a D2NN are learnable and are jointly trained to optimize both
accuracy and efficiency. Such training is achieved by integrating
backpropagation with reinforcement learning. With extensive experiments of
various D2NN architectures on image classification tasks, we demonstrate that
D2NNs are general and flexible, and can effectively optimize
accuracy-efficiency trade-offs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1&quot;&gt;Lanlan Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deng_J/0/1/0/all/0/1&quot;&gt;Jia Deng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1706.03922">
<title>Analyzing the Robustness of Nearest Neighbors to Adversarial Examples. (arXiv:1706.03922v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1706.03922</link>
<description rdf:parseType="Literal">&lt;p&gt;Motivated by applications such as autonomous vehicles, test-time attacks via
adversarial examples have received a great deal of recent attention. In this
setting, an adversary is capable of making queries to a classifier, and
perturbs a test example by a small amount in order to force the classifier to
report an incorrect label. While a long line of work has explored a number of
attacks, not many reliable defenses are known, and there is an overall lack of
general understanding about the foundations of designing machine learning
algorithms robust to adversarial examples.
&lt;/p&gt;
&lt;p&gt;In this paper, we take a step towards addressing this challenging question by
introducing a new theoretical framework, analogous to bias-variance theory,
which we can use to tease out the causes of vulnerability. We apply our
framework to a simple classification algorithm: nearest neighbors, and analyze
its robustness to adversarial examples. Motivated by our analysis, we propose a
modified version of the nearest neighbor algorithm, and demonstrate both
theoretically and empirically that it has superior robustness to standard
nearest neighbors.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yizhen Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Jha_S/0/1/0/all/0/1&quot;&gt;Somesh Jha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chaudhuri_K/0/1/0/all/0/1&quot;&gt;Kamalika Chaudhuri&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.09805">
<title>Improving Negative Sampling for Word Representation using Self-embedded Features. (arXiv:1710.09805v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1710.09805</link>
<description rdf:parseType="Literal">&lt;p&gt;Although the word-popularity based negative sampler has shown superb
performance in the skip-gram model, the theoretical motivation behind
oversampling popular (non-observed) words as negative samples is still not well
understood. In this paper, we start from an investigation of the gradient
vanishing issue in the skip-gram model without a proper negative sampler. By
performing an insightful analysis from the stochastic gradient descent (SGD)
learning perspective, we demonstrate that, both theoretically and intuitively,
negative samples with larger inner product scores are more informative than
those with lower scores for the SGD learner in terms of both convergence rate
and accuracy. Understanding this, we propose an alternative sampling algorithm
that dynamically selects informative negative samples during each SGD update.
More importantly, the proposed sampler accounts for multi-dimensional
self-embedded features during the sampling process, which essentially makes it
more effective than the original popularity-based (one-dimensional) sampler.
Empirical experiments further verify our observations, and show that our
fine-grained samplers gain significant improvement over the existing ones
without increasing computational complexity.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1&quot;&gt;Long Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yuan_F/0/1/0/all/0/1&quot;&gt;Fajie Yuan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jose_J/0/1/0/all/0/1&quot;&gt;Joemon M. Jose&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1&quot;&gt;Weinan Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.03946">
<title>Bayesian Paragraph Vectors. (arXiv:1711.03946v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1711.03946</link>
<description rdf:parseType="Literal">&lt;p&gt;Word2vec (Mikolov et al., 2013) has proven to be successful in natural
language processing by capturing the semantic relationships between different
words. Built on top of single-word embeddings, paragraph vectors (Le and
Mikolov, 2014) find fixed-length representations for pieces of text with
arbitrary lengths, such as documents, paragraphs, and sentences. In this work,
we propose a novel interpretation for neural-network-based paragraph vectors by
developing an unsupervised generative model whose maximum likelihood solution
corresponds to traditional paragraph vectors. This probabilistic formulation
allows us to go beyond point estimates of parameters and to perform Bayesian
posterior inference. We find that the entropy of paragraph vectors decreases
with the length of documents, and that information about posterior uncertainty
improves performance in supervised learning tasks such as sentiment analysis
and paraphrase detection.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ji_G/0/1/0/all/0/1&quot;&gt;Geng Ji&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bamler_R/0/1/0/all/0/1&quot;&gt;Robert Bamler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sudderth_E/0/1/0/all/0/1&quot;&gt;Erik B. Sudderth&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mandt_S/0/1/0/all/0/1&quot;&gt;Stephan Mandt&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.05828">
<title>BoostJet: Towards Combining Statistical Aggregates with Neural Embeddings for Recommendations. (arXiv:1711.05828v2 [cs.IR] UPDATED)</title>
<link>http://arxiv.org/abs/1711.05828</link>
<description rdf:parseType="Literal">&lt;p&gt;Recommenders have become widely popular in recent years because of their
broader applicability in many e-commerce applications. These applications rely
on recommenders for generating advertisements for various offers or providing
content recommendations. However, the quality of the generated recommendations
depends on user features (like demography, temporality), offer features (like
popularity, price), and user-offer features (like implicit or explicit
feedback). Current state-of-the-art recommenders do not explore such diverse
features concurrently while generating the recommendations.
&lt;/p&gt;
&lt;p&gt;In this paper, we first introduce the notion of Trackers which enables us to
capture the above-mentioned features and thus incorporate users&apos; online
behaviour through statistical aggregates of different features (demography,
temporality, popularity, price). We also show how to capture offer-to-offer
relations, based on their consumption sequence, leveraging neural embeddings
for offers in our Offer2Vec algorithm. We then introduce BoostJet, a novel
recommender which integrates the Trackers along with the neural embeddings
using MatrixNet, an efficient distributed implementation of gradient boosted
decision tree, to improve the recommendation quality significantly. We provide
an in-depth evaluation of BoostJet on Yandex&apos;s dataset, collecting online
behaviour from tens of millions of online users, to demonstrate the
practicality of BoostJet in terms of recommendation quality as well as
scalability.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Patra_R/0/1/0/all/0/1&quot;&gt;Rhicheek Patra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Samosvat_E/0/1/0/all/0/1&quot;&gt;Egor Samosvat&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roizner_M/0/1/0/all/0/1&quot;&gt;Michael Roizner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mishchenko_A/0/1/0/all/0/1&quot;&gt;Andrei Mishchenko&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.06100">
<title>Sequences, Items And Latent Links: Recommendation With Consumed Item Packs. (arXiv:1711.06100v2 [cs.IR] UPDATED)</title>
<link>http://arxiv.org/abs/1711.06100</link>
<description rdf:parseType="Literal">&lt;p&gt;Recommenders personalize the web content by typically using collaborative
filtering to relate users (or items) based on explicit feedback, e.g., ratings.
The difficulty of collecting this feedback has recently motivated to consider
implicit feedback (e.g., item consumption along with the corresponding time).
&lt;/p&gt;
&lt;p&gt;In this paper, we introduce the notion of consumed item pack (CIP) which
enables to link users (or items) based on their implicit analogous consumption
behavior. Our proposal is generic, and we show that it captures three novel
implicit recommenders: a user-based (CIP-U), an item-based (CIP-I), and a word
embedding-based (DEEPCIP), as well as a state-of-the-art technique using
implicit feedback (FISM). We show that our recommenders handle incremental
updates incorporating freshly consumed items. We demonstrate that all three
recommenders provide a recommendation quality that is competitive with
state-of-the-art ones, including one incorporating both explicit and implicit
feedback.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guerraoui_R/0/1/0/all/0/1&quot;&gt;Rachid Guerraoui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Merrer_E/0/1/0/all/0/1&quot;&gt;Erwan Le Merrer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Patra_R/0/1/0/all/0/1&quot;&gt;Rhicheek Patra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vigouroux_J/0/1/0/all/0/1&quot;&gt;Jean-Ronan Vigouroux&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.08682">
<title>Deep Video Generation, Prediction and Completion of Human Action Sequences. (arXiv:1711.08682v3 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1711.08682</link>
<description rdf:parseType="Literal">&lt;p&gt;Current deep learning results on video generation are limited while there are
only a few first results on video prediction and no relevant significant
results on video completion. This is due to the severe ill-posedness inherent
in these three problems. In this paper, we focus on human action videos, and
propose a general, two-stage deep framework to generate human action videos
with no constraints or arbitrary number of constraints, which uniformly address
the three problems: video generation given no input frames, video prediction
given the first few frames, and video completion given the first and last
frames. To make the problem tractable, in the first stage we train a deep
generative model that generates a human pose sequence from random noise. In the
second stage, a skeleton-to-image network is trained, which is used to generate
a human action video given the complete human pose sequence generated in the
first stage. By introducing the two-stage strategy, we sidestep the original
ill-posed problems while producing for the first time high-quality video
generation/prediction/completion results of much longer duration. We present
quantitative and qualitative evaluation to show that our two-stage approach
outperforms state-of-the-art methods in video generation, prediction and video
completion. Our video result demonstration can be viewed at
https://iamacewhite.github.io/supp/index.html
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cai_H/0/1/0/all/0/1&quot;&gt;Haoye Cai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bai_C/0/1/0/all/0/1&quot;&gt;Chunyan Bai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tai_Y/0/1/0/all/0/1&quot;&gt;Yu-Wing Tai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_C/0/1/0/all/0/1&quot;&gt;Chi-Keung Tang&lt;/a&gt;</dc:creator>
</item></rdf:RDF>