<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Good papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Good Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-04-16T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.05374"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.05445"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1703.01780"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.04177"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.05283"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.05348"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.05560"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.05788"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.05796"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.04071"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08534"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.11256"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.02047"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.05120"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.05251"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.05271"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.05296"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.05464"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.05470"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.05497"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.05567"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.05806"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.05816"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.01664"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.04086"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.06905"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1804.05374">
<title>Twin Regularization for online speech recognition. (arXiv:1804.05374v1 [eess.AS])</title>
<link>http://arxiv.org/abs/1804.05374</link>
<description rdf:parseType="Literal">&lt;p&gt;Online speech recognition is crucial for developing natural human-machine
interfaces. This modality, however, is significantly more challenging than
off-line ASR, since real-time/low-latency constraints inevitably hinder the use
of future information, that is known to be very helpful to perform robust
predictions.
&lt;/p&gt;
&lt;p&gt;A popular solution to mitigate this issue consists of feeding neural acoustic
models with context windows that gather some future frames. This introduces a
latency which depends on the number of employed look-ahead features.
&lt;/p&gt;
&lt;p&gt;This paper explores a different approach, based on estimating the future
rather than waiting for it. Our technique encourages the hidden representations
of a unidirectional recurrent network to embed some useful information about
the future. Inspired by a recently proposed technique called Twin Networks, we
add a regularization term that forces forward hidden states to be as close as
possible to cotemporal backward ones, computed by a &quot;twin&quot; neural network
running backwards in time.
&lt;/p&gt;
&lt;p&gt;The experiments, conducted on a number of datasets, recurrent architectures,
input features, and acoustic conditions, have shown the effectiveness of this
approach. One important advantage is that our method does not introduce any
additional computation at test time if compared to standard unidirectional
recurrent networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Ravanelli_M/0/1/0/all/0/1&quot;&gt;Mirco Ravanelli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Serdyuk_D/0/1/0/all/0/1&quot;&gt;Dmitriy Serdyuk&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Bengio_Y/0/1/0/all/0/1&quot;&gt;Yoshua Bengio&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.05445">
<title>Evolving Event-driven Programs with SignalGP. (arXiv:1804.05445v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1804.05445</link>
<description rdf:parseType="Literal">&lt;p&gt;We present SignalGP, a new genetic programming (GP) technique designed to
incorporate the event-driven programming paradigm into computational
evolution&apos;s toolbox. Event-driven programming is a software design philosophy
that simplifies the development of reactive programs by automatically
triggering program modules (event-handlers) in response to external events,
such as signals from the environment or messages from other programs. SignalGP
incorporates these concepts by extending existing tag-based referencing
techniques into an event-driven context. Both events and functions are labeled
with evolvable tags; when an event occurs, the function with the closest
matching tag is triggered. In this work, we apply SignalGP in the context of
linear GP. We demonstrate the value of the event-driven paradigm using two
distinct test problems (an environment coordination problem and a distributed
leader election problem) by comparing SignalGP to variants that are otherwise
identical, but must actively use sensors to process events or messages. In each
of these problems, rapid interaction with the environment or other agents is
critical for maximizing fitness. We also discuss ways in which SignalGP can be
generalized beyond our linear GP implementation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lalejini_A/0/1/0/all/0/1&quot;&gt;Alexander Lalejini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ofria_C/0/1/0/all/0/1&quot;&gt;Charles Ofria&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1703.01780">
<title>Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results. (arXiv:1703.01780v6 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1703.01780</link>
<description rdf:parseType="Literal">&lt;p&gt;The recently proposed Temporal Ensembling has achieved state-of-the-art
results in several semi-supervised learning benchmarks. It maintains an
exponential moving average of label predictions on each training example, and
penalizes predictions that are inconsistent with this target. However, because
the targets change only once per epoch, Temporal Ensembling becomes unwieldy
when learning large datasets. To overcome this problem, we propose Mean
Teacher, a method that averages model weights instead of label predictions. As
an additional benefit, Mean Teacher improves test accuracy and enables training
with fewer labels than Temporal Ensembling. Without changing the network
architecture, Mean Teacher achieves an error rate of 4.35% on SVHN with 250
labels, outperforming Temporal Ensembling trained with 1000 labels. We also
show that a good network architecture is crucial to performance. Combining Mean
Teacher and Residual Networks, we improve the state of the art on CIFAR-10 with
4000 labels from 10.55% to 6.28%, and on ImageNet 2012 with 10% of the labels
from 35.24% to 9.11%.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tarvainen_A/0/1/0/all/0/1&quot;&gt;Antti Tarvainen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Valpola_H/0/1/0/all/0/1&quot;&gt;Harri Valpola&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.04177">
<title>Detecting Malicious PowerShell Commands using Deep Neural Networks. (arXiv:1804.04177v2 [cs.CR] UPDATED)</title>
<link>http://arxiv.org/abs/1804.04177</link>
<description rdf:parseType="Literal">&lt;p&gt;Microsoft&apos;s PowerShell is a command-line shell and scripting language that is
installed by default on Windows machines. While PowerShell can be configured by
administrators for restricting access and reducing vulnerabilities, these
restrictions can be bypassed. Moreover, PowerShell commands can be easily
generated dynamically, executed from memory, encoded and obfuscated, thus
making the logging and forensic analysis of code executed by PowerShell
challenging.For all these reasons, PowerShell is increasingly used by
cybercriminals as part of their attacks&apos; tool chain, mainly for downloading
malicious contents and for lateral movement. Indeed, a recent comprehensive
technical report by Symantec dedicated to PowerShell&apos;s abuse by cybercrimials
reported on a sharp increase in the number of malicious PowerShell samples they
received and in the number of penetration tools and frameworks that use
PowerShell. This highlights the urgent need of developing effective methods for
detecting malicious PowerShell commands.In this work, we address this challenge
by implementing several novel detectors of malicious PowerShell commands and
evaluating their performance. We implemented both &quot;traditional&quot; natural
language processing (NLP) based detectors and detectors based on
character-level convolutional neural networks (CNNs). Detectors&apos; performance
was evaluated using a large real-world dataset.Our evaluation results show
that, although our detectors individually yield high performance, an ensemble
detector that combines an NLP-based classifier with a CNN-based classifier
provides the best performance, since the latter classifier is able to detect
malicious commands that succeed in evading the former. Our analysis of these
evasive commands reveals that some obfuscation patterns automatically detected
by the CNN classifier are intrinsically difficult to detect using the NLP
techniques we applied.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hendler_D/0/1/0/all/0/1&quot;&gt;Danny Hendler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kels_S/0/1/0/all/0/1&quot;&gt;Shay Kels&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rubin_A/0/1/0/all/0/1&quot;&gt;Amir Rubin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.05283">
<title>OmicsMapNet: Transforming omics data to take advantage of Deep Convolutional Neural Network for discovery. (arXiv:1804.05283v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1804.05283</link>
<description rdf:parseType="Literal">&lt;p&gt;We developed OmicsMapNet approach to take advantage of existing deep leaning
frameworks to analyze high-dimensional omics data as 2-dimensional images. The
omics data of individual samples were first rearranged into 2D images in which
molecular features related in functions, ontologies, or other relationships
were organized in spatially adjacent and patterned locations. Deep learning
neural networks were trained to classify the images. Molecular features
informative of classes of different phenotypes were subsequently identified. As
an example, we used the KEGG BRITE database to rearrange RNA-Seq expression
data of TCGA diffuse glioma samples as treemaps to capture the functional
hierarchical structure of genes in 2D images. Deep Convolutional Neural
Networks (CNN) were derived using tools from TensorFlow to learn the grade of
TCGA LGG and GBM samples with relatively high accuracy. The most contributory
features in the trained CNN were confirmed in pathway analysis for their
plausible functional involvement.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ma_S/0/1/0/all/0/1&quot;&gt;Shiyong Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhang_Z/0/1/0/all/0/1&quot;&gt;Zhen Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.05348">
<title>Artificial Intelligence for Wireless Connectivity and Security of Cellular-Connected UAVs. (arXiv:1804.05348v1 [cs.IT])</title>
<link>http://arxiv.org/abs/1804.05348</link>
<description rdf:parseType="Literal">&lt;p&gt;Cellular-connected unmanned aerial vehicles (UAVs) will inevitably be
integrated into future cellular networks as new aerial mobile users. Providing
cellular connectivity to UAVs will enable a myriad of applications ranging from
online video streaming to medical delivery. However, to enable a reliable
wireless connectivity for the UAVs as well as a secure operation, various
challenges need to be addressed such as interference management, mobility
management and handover, cyber-physical attacks, and authentication. In this
paper, the goal is to expose the wireless and security challenges that arise in
the context of UAV-based delivery systems, UAV-based real-time multimedia
streaming, and UAV-enabled intelligent transportation systems. To address such
challenges, artificial neural network (ANN) based solution schemes are
introduced. The introduced approaches enable the UAVs to adaptively exploit the
wireless system resources while guaranteeing a secure operation, in real-time.
Preliminary simulation results show the benefits of the introduced solutions
for each of the aforementioned cellular-connected UAV application use case.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Challita_U/0/1/0/all/0/1&quot;&gt;Ursula Challita&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ferdowsi_A/0/1/0/all/0/1&quot;&gt;Aidin Ferdowsi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1&quot;&gt;Mingzhe Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saad_W/0/1/0/all/0/1&quot;&gt;Walid Saad&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.05560">
<title>Deep Bayesian Trust : A Dominant Strategy and Fair Reward Mechanism for Crowdsourcing. (arXiv:1804.05560v1 [cs.GT])</title>
<link>http://arxiv.org/abs/1804.05560</link>
<description rdf:parseType="Literal">&lt;p&gt;A common mechanism to assess trust in crowdworkers is to have them answer
gold tasks. However, assigning gold tasks to all workers reduces the efficiency
of the platform. We propose a mechanism that exploits transitivity so that a
worker can be certified as trusted by other trusted workers who solve common
tasks. Thus, trust can be derived from a smaller number of gold tasks
assignment through multiple layers of peer relationship among the workers, a
model we call deep trust. We use the derived trust to incentivize workers for
high quality work and show that the resulting mechanism is dominant strategy
incentive compatible. We also show that the mechanism satisfies a notion of
fairness in that the trust assessment (and thus the reward) of a worker in the
limit is independent of the quality of other workers.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goel_N/0/1/0/all/0/1&quot;&gt;Naman Goel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Faltings_B/0/1/0/all/0/1&quot;&gt;Boi Faltings&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.05788">
<title>Multi-Modal Emotion recognition on IEMOCAP Dataset using Deep Learning. (arXiv:1804.05788v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1804.05788</link>
<description rdf:parseType="Literal">&lt;p&gt;Emotion recognition has become an important field of research in Human
Computer Interactions as we improve upon the techniques for modelling the
various aspects of behaviour. With the advancement of technology our
understanding of emotions are advancing, there is a growing need for automatic
emotion recognition systems. One of the directions the research is heading is
the use of Neural Networks which are adept at estimating complex functions that
depend on a large number and diverse source of input data. In this paper we
attempt to exploit this effectiveness of Neural networks to enable us to
perform multimodal Emotion recognition on IEMOCAP dataset using data from
Speech, Text, and Motion capture data from face expressions, rotation and hand
movements. Prior research has concentrated on Emotion detection from Speech on
the IEMOCAP dataset, but our approach is the first that uses the multiple modes
of data offered by IEMOCAP for a more robust and accurate emotion detection.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tripathi_S/0/1/0/all/0/1&quot;&gt;Samarth Tripathi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Beigi_H/0/1/0/all/0/1&quot;&gt;Homayoon Beigi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.05796">
<title>An AI-driven Malfunction Detection Concept for NFV Instances in 5G. (arXiv:1804.05796v1 [cs.NI])</title>
<link>http://arxiv.org/abs/1804.05796</link>
<description rdf:parseType="Literal">&lt;p&gt;Efficient network management is one of the key challenges of the constantly
growing and increasingly complex wide area networks (WAN). The paradigm shift
towards virtualized (NFV) and software defined networks (SDN) in the next
generation of mobile networks (5G), as well as the latest scientific insights
in the field of Artificial Intelligence (AI) enable the transition from
manually managed networks nowadays to fully autonomic and dynamic
self-organized networks (SON). This helps to meet the KPIs and reduce at the
same time operational costs (OPEX). In this paper, an AI driven concept is
presented for the malfunction detection in NFV applications with the help of
semi-supervised learning. For this purpose, a profile of the application under
test is created. This profile then is used as a reference to detect abnormal
behaviour. For example, if there is a bug in the updated version of the app, it
is now possible to react autonomously and roll-back the NFV app to a previous
version in order to avoid network outages.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ahrens_J/0/1/0/all/0/1&quot;&gt;Julian Ahrens&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Strufe_M/0/1/0/all/0/1&quot;&gt;Mathias Strufe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ahrens_L/0/1/0/all/0/1&quot;&gt;Lia Ahrens&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schotten_H/0/1/0/all/0/1&quot;&gt;Hans D. Schotten&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.04071">
<title>KBGAN: Adversarial Learning for Knowledge Graph Embeddings. (arXiv:1711.04071v3 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1711.04071</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce KBGAN, an adversarial learning framework to improve the
performances of a wide range of existing knowledge graph embedding models.
Because knowledge graphs typically only contain positive facts, sampling useful
negative training examples is a non-trivial task. Replacing the head or tail
entity of a fact with a uniformly randomly selected entity is a conventional
method for generating negative facts, but the majority of the generated
negative facts can be easily discriminated from positive facts, and will
contribute little towards the training. Inspired by generative adversarial
networks (GANs), we use one knowledge graph embedding model as a negative
sample generator to assist the training of our desired model, which acts as the
discriminator in GANs. This framework is independent of the concrete form of
generator and discriminator, and therefore can utilize a wide variety of
knowledge graph embedding models as its building blocks. In experiments, we
adversarially train two translation-based models, TransE and TransD, each with
assistance from one of the two probability-based models, DistMult and ComplEx.
We evaluate the performances of KBGAN on the link prediction task, using three
knowledge base completion datasets: FB15k-237, WN18 and WN18RR. Experimental
results show that adversarial training substantially improves the performances
of target embedding models under various settings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cai_L/0/1/0/all/0/1&quot;&gt;Liwei Cai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1&quot;&gt;William Yang Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08534">
<title>Weighted Double Deep Multiagent Reinforcement Learning in Stochastic Cooperative Environments. (arXiv:1802.08534v2 [cs.MA] UPDATED)</title>
<link>http://arxiv.org/abs/1802.08534</link>
<description rdf:parseType="Literal">&lt;p&gt;Recently, multiagent deep reinforcement learning (DRL) has received
increasingly wide attention. Existing multiagent DRL algorithms are inefficient
when facing with the non-stationarity due to agents update their policies
simultaneously in stochastic cooperative environments. This paper extends the
recently proposed weighted double estimator to the multiagent domain and
propose a multiagent DRL framework, named weighted double deep Q-network
(WDDQN). By utilizing the weighted double estimator and the deep neural
network, WDDQN can not only reduce the bias effectively but also be extended to
scenarios with raw visual inputs. To achieve efficient cooperation in the
multiagent domain, we introduce the lenient reward network and the scheduled
replay strategy. Experiments show that the WDDQN outperforms the existing DRL
and multiaent DRL algorithms, i.e., double DQN and lenient Q-learning, in terms
of the average reward and the convergence rate in stochastic cooperative
environments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_Y/0/1/0/all/0/1&quot;&gt;Yan Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hao_J/0/1/0/all/0/1&quot;&gt;Jianye Hao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1&quot;&gt;Zongzhang Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.11256">
<title>Challenges and Characteristics of Intelligent Autonomy for Internet of Battle Things in Highly Adversarial Environments. (arXiv:1803.11256v2 [cs.CY] UPDATED)</title>
<link>http://arxiv.org/abs/1803.11256</link>
<description rdf:parseType="Literal">&lt;p&gt;Numerous, artificially intelligent, networked things will populate the
battlefield of the future, operating in close collaboration with human
warfighters, and fighting as teams in highly adversarial environments. This
paper explores the characteristics, capabilities and intelligence required of
such a network of intelligent things and humans - Internet of Battle Things
(IOBT). It will experience unique challenges that are not yet well addressed by
the current generation of AI and machine learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kott_A/0/1/0/all/0/1&quot;&gt;Alexander Kott&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.02047">
<title>Pedestrian-Synthesis-GAN: Generating Pedestrian Data in Real Scene and Beyond. (arXiv:1804.02047v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1804.02047</link>
<description rdf:parseType="Literal">&lt;p&gt;State-of-the-art pedestrian detection models have achieved great success in
many benchmarks. However, these models require lots of annotation information
and the labeling process usually takes much time and efforts. In this paper, we
propose a method to generate labeled pedestrian data and adapt them to support
the training of pedestrian detectors. The proposed framework is built on the
Generative Adversarial Network (GAN) with multiple discriminators, trying to
synthesize realistic pedestrians and learn the background context
simultaneously. To handle the pedestrians of different sizes, we adopt the
Spatial Pyramid Pooling (SPP) layer in the discriminator. We conduct
experiments on two benchmarks. The results show that our framework can smoothly
synthesize pedestrians on background images of variations and different levels
of details. To quantitatively evaluate our approach, we add the generated
samples into training data of the baseline pedestrian detectors and show the
synthetic images are able to improve the detectors&apos; performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ouyang_X/0/1/0/all/0/1&quot;&gt;Xi Ouyang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1&quot;&gt;Yu Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1&quot;&gt;Yifan Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1&quot;&gt;Chun-Liang Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_P/0/1/0/all/0/1&quot;&gt;Pan Zhou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.05120">
<title>Robust Dual View Depp Agent. (arXiv:1804.05120v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1804.05120</link>
<description rdf:parseType="Literal">&lt;p&gt;Motivated by recent advance of machine learning using Deep Reinforcement
Learning this paper proposes a modified architecture that produces more robust
agents and speeds up the training process. Our architecture is based on
Asynchronous Advantage Actor-Critic (A3C) algorithm where the total input
dimensionality is halved by dividing the input into two independent streams. We
use ViZDoom, 3D world software that is based on the classical first person
shooter video game, Doom, as a test case. The experiments show that in
comparison to single input agents, the proposed architecture succeeds to have
the same playing performance and shows more robust behavior, achieving
significant reduction in the number of training parameters of almost 30%.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sobh_I/0/1/0/all/0/1&quot;&gt;Ibrahim M. Sobh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Darwish_N/0/1/0/all/0/1&quot;&gt;Nevin M. Darwish&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.05251">
<title>An interpretable LSTM neural network for autoregressive exogenous model. (arXiv:1804.05251v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1804.05251</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we propose an interpretable LSTM recurrent neural network,
i.e., multi-variable LSTM for time series with exogenous variables. Currently,
widely used attention mechanism in recurrent neural networks mostly focuses on
the temporal aspect of data and falls short of characterizing variable
importance. To this end, our multi-variable LSTM equipped with tensorized
hidden states is developed to learn variable specific representations, which
give rise to both temporal and variable level attention. Preliminary
experiments demonstrate comparable prediction performance of multi-variable
LSTM w.r.t. encoder-decoder based baselines. More interestingly, variable
importance in real datasets characterized by the variable attention is highly
in line with that determined by statistical Granger causality test, which
exhibits the prospect of multi-variable LSTM as a simple and uniform end-to-end
framework for both forecasting and knowledge discovery.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_T/0/1/0/all/0/1&quot;&gt;Tian Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_T/0/1/0/all/0/1&quot;&gt;Tao Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1&quot;&gt;Yao Lu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.05271">
<title>When Edge Meets Learning: Adaptive Control for Resource-Constrained Distributed Machine Learning. (arXiv:1804.05271v1 [cs.DC])</title>
<link>http://arxiv.org/abs/1804.05271</link>
<description rdf:parseType="Literal">&lt;p&gt;Emerging technologies and applications including Internet of Things (IoT),
social networking, and crowd-sourcing generate large amounts of data at the
network edge. Machine learning models are often built from the collected data,
to enable the detection, classification, and prediction of future events. Due
to bandwidth, storage, and privacy concerns, it is often impractical to send
all the data to a centralized location. In this paper, we consider the problem
of learning model parameters from data distributed across multiple edge nodes,
without sending raw data to a centralized place. Our focus is on a generic
class of machine learning models that are trained using gradient-descent based
approaches. We analyze the convergence rate of distributed gradient descent
from a theoretical point of view, based on which we propose a control algorithm
that determines the best trade-off between local update and global parameter
aggregation to minimize the loss function under a given resource budget. The
performance of the proposed algorithm is evaluated via extensive experiments
with real datasets, both on a networked prototype system and in a larger-scale
simulated environment. The experimentation results show that our proposed
approach performs near to the optimum with various machine learning models and
different data distributions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1&quot;&gt;Shiqiang Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tuor_T/0/1/0/all/0/1&quot;&gt;Tiffany Tuor&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Salonidis_T/0/1/0/all/0/1&quot;&gt;Theodoros Salonidis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leung_K/0/1/0/all/0/1&quot;&gt;Kin K. Leung&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Makaya_C/0/1/0/all/0/1&quot;&gt;Christian Makaya&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_T/0/1/0/all/0/1&quot;&gt;Ting He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chan_K/0/1/0/all/0/1&quot;&gt;Kevin Chan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.05296">
<title>Adversarial Attacks Against Medical Deep Learning Systems. (arXiv:1804.05296v1 [cs.CR])</title>
<link>http://arxiv.org/abs/1804.05296</link>
<description rdf:parseType="Literal">&lt;p&gt;The discovery of adversarial examples has raised concerns about the practical
deployment of deep learning systems. In this paper, we argue that the field of
medicine may be uniquely susceptible to adversarial attacks, both in terms of
monetary incentives and technical vulnerability. To this end, we outline the
healthcare economy and the incentives it creates for fraud, we extend
adversarial attacks to three popular medical imaging tasks, and we provide
concrete examples of how and why such attacks could be realistically carried
out. For each of our representative medical deep learning classifiers, both
white and black box attacks were both effective and human-imperceptible. We
urge caution in employing deep learning systems in clinical settings, and
encourage research into domain-specific defense strategies.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Finlayson_S/0/1/0/all/0/1&quot;&gt;Samuel G. Finlayson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kohane_I/0/1/0/all/0/1&quot;&gt;Isaac S. Kohane&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Beam_A/0/1/0/all/0/1&quot;&gt;Andrew L. Beam&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.05464">
<title>On the Convergence of Competitive, Multi-Agent Gradient-Based Learning. (arXiv:1804.05464v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1804.05464</link>
<description rdf:parseType="Literal">&lt;p&gt;As learning algorithms are increasingly deployed in markets and other
competitive environments, understanding their dynamics is becoming increasingly
important. We study the limiting behavior of competitive agents employing
gradient-based learning algorithms. Specifically, we introduce a general
framework for competitive gradient-based learning that encompasses a wide
breadth of learning algorithms including policy gradient reinforcement
learning, gradient based bandits, and certain online convex optimization
algorithms. We show that unlike the single agent case, gradient learning
schemes in competitive settings do not necessarily correspond to gradient flows
and, hence, it is possible for limiting behaviors like periodic orbits to
exist. We introduce a new class of games, Morse-Smale games, that correspond to
gradient-like flows. We provide guarantees that competitive gradient-based
learning algorithms (both in the full information and gradient-free settings)
avoid linearly unstable critical points (i.e. strict saddle points and unstable
limit cycles). Since generic local Nash equilibria are not unstable critical
points---that is, in a formal mathematical sense, almost all Nash equilibria
are not strict saddles---these results imply that gradient-based learning
almost surely does not get stuck at critical points that do not correspond to
Nash equilibria. For Morse-Smale games, we show that competitive gradient
learning converges to linearly stable cycles (which includes stable Nash
equilibria) almost surely. Finally, we specialize these results to commonly
used multi-agent learning algorithms and provide illustrative examples that
demonstrate the wide range of limiting behaviors competitive gradient learning
exhibits.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mazumdar_E/0/1/0/all/0/1&quot;&gt;Eric Mazumdar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ratliff_L/0/1/0/all/0/1&quot;&gt;Lillian J. Ratliff&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.05470">
<title>Composable Unpaired Image to Image Translation. (arXiv:1804.05470v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1804.05470</link>
<description rdf:parseType="Literal">&lt;p&gt;There has been remarkable recent work in unpaired image-to-image translation.
However, they&apos;re restricted to translation on single pairs of distributions,
with some exceptions. In this study, we extend one of these works to a scalable
multidistribution translation mechanism. Our translation models not only
converts from one distribution to another but can be stacked to create
composite translation functions. We show that this composite property makes it
possible to generate images with characteristics not seen in the training set.
We also propose a decoupled training mechanism to train multiple distributions
separately, which we show, generates better samples than isolated joint
training. Further, we do a qualitative and quantitative analysis to assess the
plausibility of the samples. The code is made available at
https://github.com/lgraesser/im2im2im.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Graesser_L/0/1/0/all/0/1&quot;&gt;Laura Graesser&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1&quot;&gt;Anant Gupta&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.05497">
<title>Deep Learning on Key Performance Indicators for Predictive Maintenance in SAP HANA. (arXiv:1804.05497v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1804.05497</link>
<description rdf:parseType="Literal">&lt;p&gt;With a new era of cloud and big data, Database Management Systems (DBMSs)
have become more crucial in numerous enterprise business applications in all
the industries. Accordingly, the importance of their proactive and preventive
maintenance has also increased. However, detecting problems by predefined rules
or stochastic modeling has limitations, particularly when analyzing the data on
high-dimensional Key Performance Indicators (KPIs) from a DBMS. In recent
years, Deep Learning (DL) has opened new opportunities for this complex
analysis. In this paper, we present two complementary DL approaches to detect
anomalies in SAP HANA. A temporal learning approach is used to detect abnormal
patterns based on unlabeled historical data, whereas a spatial learning
approach is used to classify known anomalies based on labeled data. We
implement a system in SAP HANA integrated with Google TensorFlow. The
experimental results with real-world data confirm the effectiveness of the
system and models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1&quot;&gt;Jaekoo Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_B/0/1/0/all/0/1&quot;&gt;Byunghan Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_J/0/1/0/all/0/1&quot;&gt;Jongyoon Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yoon_J/0/1/0/all/0/1&quot;&gt;Jaesik Yoon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_Y/0/1/0/all/0/1&quot;&gt;Yongsik Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1&quot;&gt;Donghun Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yoon_S/0/1/0/all/0/1&quot;&gt;Sungroh Yoon&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.05567">
<title>Constant Step Size Stochastic Gradient Descent for Probabilistic Modeling. (arXiv:1804.05567v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1804.05567</link>
<description rdf:parseType="Literal">&lt;p&gt;Stochastic gradient methods enable learning probabilistic models from large
amounts of data. While large step-sizes (learning rates) have shown to be best
for least-squares (e.g., Gaussian noise) once combined with parameter
averaging, these are not leading to convergent algorithms in general. In this
paper, we consider generalized linear models, that is, conditional models based
on exponential families. We propose averaging moment parameters instead of
natural parameters for constant-step-size stochastic gradient descent. For
finite-dimensional models, we show that this can sometimes (and surprisingly)
lead to better predictions than the best linear model. For infinite-dimensional
models, we show that it always converges to optimal predictions, while
averaging natural parameters never does. We illustrate our findings with
simulations on synthetic data and classical benchmarks with many observations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Babichev_D/0/1/0/all/0/1&quot;&gt;Dmitry Babichev&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bach_F/0/1/0/all/0/1&quot;&gt;Francis Bach&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.05806">
<title>Deep Embedding Kernel. (arXiv:1804.05806v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1804.05806</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we propose a novel supervised learning method that is called
Deep Embedding Kernel (DEK). DEK combines the advantages of deep learning and
kernel methods in a unified framework. More specifically, DEK is a learnable
kernel represented by a newly designed deep architecture. Compared with
pre-defined kernels, this kernel can be explicitly trained to map data to an
optimized high-level feature space where data may have favorable features
toward the application. Compared with typical deep learning using SoftMax or
logistic regression as the top layer, DEK is expected to be more generalizable
to new data. Experimental results show that DEK has superior performance than
typical machine learning methods in identity detection, classification,
regression, dimension reduction, and transfer learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Le_L/0/1/0/all/0/1&quot;&gt;Linh Le&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Xie_Y/0/1/0/all/0/1&quot;&gt;Ying Xie&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.05816">
<title>Models for Capturing Temporal Smoothness in Evolving Networks for Learning Latent Representation of Nodes. (arXiv:1804.05816v1 [cs.SI])</title>
<link>http://arxiv.org/abs/1804.05816</link>
<description rdf:parseType="Literal">&lt;p&gt;In a dynamic network, the neighborhood of the vertices evolve across
different temporal snapshots of the network. Accurate modeling of this temporal
evolution can help solve complex tasks involving real-life social and
interaction networks. However, existing models for learning latent
representation are inadequate for obtaining the representation vectors of the
vertices for different time-stamps of a dynamic network in a meaningful way. In
this paper, we propose latent representation learning models for dynamic
networks which overcome the above limitation by considering two different kinds
of temporal smoothness: (i) retrofitted, and (ii) linear transformation. The
retrofitted model tracks the representation vector of a vertex over time,
facilitating vertex-based temporal analysis of a network. On the other hand,
linear transformation based model provides a smooth transition operator which
maps the representation vectors of all vertices from one temporal snapshot to
the next (unobserved) snapshot-this facilitates prediction of the state of a
network in a future time-stamp. We validate the performance of our proposed
models by employing them for solving the temporal link prediction task.
Experiments on 9 real-life networks from various domains validate that the
proposed models are significantly better than the existing models for
predicting the dynamics of an evolving network.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saha_T/0/1/0/all/0/1&quot;&gt;Tanay Kumar Saha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Williams_T/0/1/0/all/0/1&quot;&gt;Thomas Williams&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hasan_M/0/1/0/all/0/1&quot;&gt;Mohammad Al Hasan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Joty_S/0/1/0/all/0/1&quot;&gt;Shafiq Joty&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Varberg_N/0/1/0/all/0/1&quot;&gt;Nicholas K. Varberg&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.01664">
<title>Learning a Generative Model for Validity in Complex Discrete Structures. (arXiv:1712.01664v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1712.01664</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep generative models have been successfully used to learn representations
for high-dimensional discrete spaces by representing discrete objects as
sequences and employing powerful sequence-based deep models. Unfortunately,
these sequence-based models often produce invalid sequences: sequences which do
not represent any underlying discrete structure; invalid sequences hinder the
utility of such models. As a step towards solving this problem, we propose to
learn a deep recurrent validator model, which can estimate whether a partial
sequence can function as the beginning of a full, valid sequence. This
validator provides insight as to how individual sequence elements influence the
validity of the overall sequence, and can be used to constrain sequence based
models to generate valid sequences -- and thus faithfully model discrete
objects. Our approach is inspired by reinforcement learning, where an oracle
which can evaluate validity of complete sequences provides a sparse reward
signal. We demonstrate its effectiveness as a generative model of Python 3
source code for mathematical expressions, and in improving the ability of a
variational autoencoder trained on SMILES strings to decode valid molecular
structures.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Janz_D/0/1/0/all/0/1&quot;&gt;David Janz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Westhuizen_J/0/1/0/all/0/1&quot;&gt;Jos van der Westhuizen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Paige_B/0/1/0/all/0/1&quot;&gt;Brooks Paige&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kusner_M/0/1/0/all/0/1&quot;&gt;Matt J. Kusner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hernandez_Labato_J/0/1/0/all/0/1&quot;&gt;Jose Miguel Hernandez-Labato&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.04086">
<title>PacGAN: The power of two samples in generative adversarial networks. (arXiv:1712.04086v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1712.04086</link>
<description rdf:parseType="Literal">&lt;p&gt;Generative adversarial networks (GANs) are innovative techniques for learning
generative models of complex data distributions from samples. Despite
remarkable recent improvements in generating realistic images, one of their
major shortcomings is the fact that in practice, they tend to produce samples
with little diversity, even when trained on diverse datasets. This phenomenon,
known as mode collapse, has been the main focus of several recent advances in
GANs. Yet there is little understanding of why mode collapse happens and why
existing approaches are able to mitigate mode collapse. We propose a principled
approach to handling mode collapse, which we call packing. The main idea is to
modify the discriminator to make decisions based on multiple samples from the
same class, either real or artificially generated. We borrow analysis tools
from binary hypothesis testing---in particular the seminal result of Blackwell
[Bla53]---to prove a fundamental connection between packing and mode collapse.
We show that packing naturally penalizes generators with mode collapse, thereby
favoring generator distributions with less mode collapse during the training
process. Numerical experiments on benchmark datasets suggests that packing
provides significant improvements in practice as well.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1&quot;&gt;Zinan Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khetan_A/0/1/0/all/0/1&quot;&gt;Ashish Khetan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fanti_G/0/1/0/all/0/1&quot;&gt;Giulia Fanti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oh_S/0/1/0/all/0/1&quot;&gt;Sewoong Oh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.06905">
<title>TBD: Benchmarking and Analyzing Deep Neural Network Training. (arXiv:1803.06905v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1803.06905</link>
<description rdf:parseType="Literal">&lt;p&gt;The recent popularity of deep neural networks (DNNs) has generated a lot of
research interest in performing DNN-related computation efficiently. However,
the primary focus is usually very narrow and limited to (i) inference -- i.e.
how to efficiently execute already trained models and (ii) image classification
networks as the primary benchmark for evaluation.
&lt;/p&gt;
&lt;p&gt;Our primary goal in this work is to break this myopic view by (i) proposing a
new benchmark for DNN training, called TBD (TBD is short for Training Benchmark
for DNNs), that uses a representative set of DNN models that cover a wide range
of machine learning applications: image classification, machine translation,
speech recognition, object detection, adversarial networks, reinforcement
learning, and (ii) by performing an extensive performance analysis of training
these different applications on three major deep learning frameworks
(TensorFlow, MXNet, CNTK) across different hardware configurations (single-GPU,
multi-GPU, and multi-machine). TBD currently covers six major application
domains and eight different state-of-the-art models.
&lt;/p&gt;
&lt;p&gt;We present a new toolchain for performance analysis for these models that
combines the targeted usage of existing performance analysis tools, careful
selection of new and existing metrics and methodologies to analyze the results,
and utilization of domain specific characteristics of DNN training. We also
build a new set of tools for memory profiling in all three major frameworks;
much needed tools that can finally shed some light on precisely how much memory
is consumed by different data structures (weights, activations, gradients,
workspace) in DNN training. By using our tools and methodologies, we make
several important observations and recommendations on where the future research
and optimization of DNN training should be focused.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1&quot;&gt;Hongyu Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Akrout_M/0/1/0/all/0/1&quot;&gt;Mohamed Akrout&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_B/0/1/0/all/0/1&quot;&gt;Bojian Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pelegris_A/0/1/0/all/0/1&quot;&gt;Andrew Pelegris&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Phanishayee_A/0/1/0/all/0/1&quot;&gt;Amar Phanishayee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schroeder_B/0/1/0/all/0/1&quot;&gt;Bianca Schroeder&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pekhimenko_G/0/1/0/all/0/1&quot;&gt;Gennady Pekhimenko&lt;/a&gt;</dc:creator>
</item></rdf:RDF>