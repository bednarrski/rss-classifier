<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Good papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Good Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-06-14T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05298"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00149"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05234"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05299"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05421"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05594"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.03793"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04718"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05178"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05297"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05355"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05393"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05394"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05413"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05454"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05476"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05512"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05514"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05559"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05662"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1604.06749"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.05558"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.07301"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09298"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04000"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1806.05298">
<title>Apuntes de Redes Neuronales Artificiales. (arXiv:1806.05298v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1806.05298</link>
<description rdf:parseType="Literal">&lt;p&gt;These handouts are designed for people who is just starting involved with the
topic artificial neural networks. We show how it works a single artificial
neuron (McCulloch &amp;amp; Pitt model), mathematically and graphically. We do explain
the delta rule, a learning algorithm to find the neuron weights. We also
present some examples in MATLAB/Octave. There are examples for classification
task for lineal and non-lineal problems. At the end, we present an artificial
neural network, a feed-forward neural network along its learning algorithm
backpropagation.
&lt;/p&gt;
&lt;p&gt;-----
&lt;/p&gt;
&lt;p&gt;Estos apuntes est\&apos;an dise\~nados para personas que por primera vez se
introducen en el tema de las redes neuronales artificiales. Se muestra el
funcionamiento b\&apos;asico de una neurona, matem\&apos;aticamente y gr\&apos;aficamente. Se
explica la Regla Delta, algoritmo deaprendizaje para encontrar los pesos de una
neurona. Tambi\&apos;en se muestran ejemplos en MATLAB/Octave. Hay ejemplos para
problemas de clasificaci\&apos;on, para problemas lineales y no-lineales. En la
parte final se muestra la arquitectura de red neuronal artificial conocida como
backpropagation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cuevas_Tello_J/0/1/0/all/0/1&quot;&gt;J.C. Cuevas-Tello&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00149">
<title>q-Neurons: Neuron Activations based on Stochastic Jackson&apos;s Derivative Operators. (arXiv:1806.00149v2 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1806.00149</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a new generic type of stochastic neurons, called $q$-neurons, that
considers activation functions based on Jackson&apos;s $q$-derivatives with
stochastic parameters $q$. Our generalization of neural network architectures
with $q$-neurons is shown to be both scalable and very easy to implement. We
demonstrate experimentally consistently improved performances over
state-of-the-art standard activation functions, both on training and testing
loss functions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nielsen_F/0/1/0/all/0/1&quot;&gt;Frank Nielsen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_K/0/1/0/all/0/1&quot;&gt;Ke Sun&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05234">
<title>Understanding the Meaning of Understanding. (arXiv:1806.05234v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1806.05234</link>
<description rdf:parseType="Literal">&lt;p&gt;Can we train a machine to detect if another machine has understood a concept?
In principle, this is possible by conducting tests on the subject of that
concept. However we want this procedure to be done by avoiding direct
questions. In other words, we would like to isolate the absolute meaning of an
abstract idea by putting it into a class of equivalence, hence without adopting
straight definitions or showing how this idea &quot;works&quot; in practice. We discuss
the metaphysical implications hidden in the above question, with the aim of
providing a plausible reference framework.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Funaro_D/0/1/0/all/0/1&quot;&gt;Daniele Funaro&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05299">
<title>Shape Features Extraction Using a Partial Differential Equation. (arXiv:1806.05299v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1806.05299</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents a unified method for extraction of geometrical shape
features in binary image data using a linear partial differential equation
(PDE). The PDE and functions are formulated to extract geometrical shape
features, which are thickness, shape orientation and skeleton, all at once. The
main advantages of the proposed method are it is free of any computation with
respect to distance, it has no topological constraint of target image data and
surfaces do not have to be distinguished to inside or outside. A one
dimensional analytical solution is provided to validate the proposed method.
Additionally, two- and three-dimensional numerical examples are shown to
confirm the validity and usefulness of the proposed method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yamada_T/0/1/0/all/0/1&quot;&gt;Takayuki Yamada&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05421">
<title>Selfless Sequential Learning. (arXiv:1806.05421v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.05421</link>
<description rdf:parseType="Literal">&lt;p&gt;Sequential learning studies the problem of learning tasks in a sequence with
restricted access to only the data of the current task. In the setting with a
fixed model capacity, the learning process should not be selfish and account
for later tasks to be added and therefore aim at utilizing a minimum number of
neurons, leaving enough capacity for future needs. We explore different
regularization strategies and activation functions that could lead to less
interference between the different tasks. We show that learning a sparse
representation is more beneficial for sequential learning than encouraging
parameter sparsity regardless of their corresponding neurons. We particularly
propose a novel regularizer that encourages representation sparsity by means of
neural inhibition. It results in few active neurons which in turn leaves more
free neurons to be utilized by upcoming tasks. We combine our regularizer with
state-of-the-art lifelong learning methods that penalize changes on important
previously learned parts of the network. We show that increased sparsity
translates in a performance improvement on the different tasks that are learned
in a sequence.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Aljundi_R/0/1/0/all/0/1&quot;&gt;Rahaf Aljundi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rohrbach_M/0/1/0/all/0/1&quot;&gt;Marcus Rohrbach&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tuytelaars_T/0/1/0/all/0/1&quot;&gt;Tinne Tuytelaars&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05594">
<title>Improving Consistency-Based Semi-Supervised Learning with Weight Averaging. (arXiv:1806.05594v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.05594</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent advances in deep unsupervised learning have renewed interest in
semi-supervised methods, which can learn from both labeled and unlabeled data.
Presently the most successful approaches to semi-supervised learning are based
on consistency regularization, whereby a model is trained to be robust to small
perturbations of its inputs and parameters. We show that consistency
regularization leads to flatter but narrower optima. We also show that the test
error surface for these methods is approximately convex in regions of weight
space traversed by SGD. Inspired by these observations, we propose to train
consistency based semi-supervised models with stochastic weight averaging
(SWA), a recent method which averages weights along the trajectory of SGD. We
also develop fast-SWA, which further accelerates convergence by averaging
multiple points within each cycle of a cyclical learning rate schedule. With
fast-SWA we achieve the best known semi-supervised results on CIFAR-10 and
CIFAR-100 over many different numbers of observed training labels. For example,
we achieve 5.0% error on CIFAR-10 with only 4000 labels, compared to 6.28% of
the previous best result in the literature. We also improve the best known
result from 80% accuracy to 83% for domain adaptation from CIFAR-10 to STL.
Finally, we show that with fast-SWA the simple $\Pi$ model becomes
state-of-the-art for large labeled settings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Athiwaratkun_B/0/1/0/all/0/1&quot;&gt;Ben Athiwaratkun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Finzi_M/0/1/0/all/0/1&quot;&gt;Marc Finzi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Izmailov_P/0/1/0/all/0/1&quot;&gt;Pavel Izmailov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wilson_A/0/1/0/all/0/1&quot;&gt;Andrew Gordon Wilson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.03793">
<title>Context-Aware Policy Reuse. (arXiv:1806.03793v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1806.03793</link>
<description rdf:parseType="Literal">&lt;p&gt;Transfer learning can greatly speed up reinforcement learning for a new task
by leveraging policies of relevant tasks.
&lt;/p&gt;
&lt;p&gt;Existing works of policy reuse either focus on only selecting a single best
source policy for transfer without considering contexts, or cannot guarantee to
learn an optimal policy for a target task.
&lt;/p&gt;
&lt;p&gt;To improve transfer efficiency and guarantee optimality, we develop a novel
policy reuse method, called {\em Context-Aware Policy reuSe} (CAPS), that
enables multi-policy transfer. Our method learns when and which source policy
is best for reuse, as well as when to terminate its reuse. CAPS provides
theoretical guarantees in convergence and optimality for both source policy
selection and target task learning. Empirical results on a grid-based
navigation domain and the Pygame Learning Environment demonstrate that CAPS
significantly outperforms other state-of-the-art policy reuse methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1&quot;&gt;Siyuan Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gu_F/0/1/0/all/0/1&quot;&gt;Fangda Gu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_G/0/1/0/all/0/1&quot;&gt;Guangxiang Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1&quot;&gt;Chongjie Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04718">
<title>Talakat: Bullet Hell Generation through Constrained Map-Elites. (arXiv:1806.04718v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1806.04718</link>
<description rdf:parseType="Literal">&lt;p&gt;We describe a search-based approach to generating new levels for bullet hell
games, which are action games characterized by and requiring avoidance of a
very large amount of projectiles. Levels are represented using a
domain-specific description language, and search in the space defined by this
language is performed by a novel variant of the Map-Elites algorithm which
incorporates a feasible- infeasible approach to constraint satisfaction.
Simulation-based evaluation is used to gauge the fitness of levels, using an
agent based on best-first search. The performance of the agent can be tuned
according to the two dimensions of strategy and dexterity, making it possible
to search for level configurations that require a specific combination of both.
As far as we know, this paper describes the first generator for this game
genre, and includes several algorithmic innovations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khalifa_A/0/1/0/all/0/1&quot;&gt;Ahmed Khalifa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1&quot;&gt;Scott Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nealen_A/0/1/0/all/0/1&quot;&gt;Andy Nealen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Togelius_J/0/1/0/all/0/1&quot;&gt;Julian Togelius&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05178">
<title>Generating Sentences Using a Dynamic Canvas. (arXiv:1806.05178v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1806.05178</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce the Attentive Unsupervised Text (W)riter (AUTR), which is a word
level generative model for natural language. It uses a recurrent neural network
with a dynamic attention and canvas memory mechanism to iteratively construct
sentences. By viewing the state of the memory at intermediate stages and where
the model is placing its attention, we gain insight into how it constructs
sentences. We demonstrate that AUTR learns a meaningful latent representation
for each sentence, and achieves competitive log-likelihood lower bounds whilst
being computationally efficient. It is effective at generating and
reconstructing sentences, as well as imputing missing words.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shah_H/0/1/0/all/0/1&quot;&gt;Harshil Shah&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_B/0/1/0/all/0/1&quot;&gt;Bowen Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barber_D/0/1/0/all/0/1&quot;&gt;David Barber&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05297">
<title>Pattern Dependence Detection using n-TARP Clustering. (arXiv:1806.05297v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.05297</link>
<description rdf:parseType="Literal">&lt;p&gt;Consider an experiment involving a potentially small number of subjects. Some
random variables are observed on each subject: a high-dimensional one called
the &quot;observed&quot; random variable, and a one-dimensional one called the &quot;outcome&quot;
random variable. We are interested in the dependencies between the observed
random variable and the outcome random variable. We propose a method to
quantify and validate the dependencies of the outcome random variable on the
various patterns contained in the observed random variable. Different degrees
of relationship are explored (linear, quadratic, cubic, ...). This work is
motivated by the need to analyze educational data, which often involves
high-dimensional data representing a small number of students. Thus our
implementation is designed for a small number of subjects; however, it can be
easily modified to handle a very large dataset. As an illustration, the
proposed method is used to study the influence of certain skills on the course
grade of students in a signal processing class. A valid dependency of the grade
on the different skill patterns is observed in the data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yellamraju_T/0/1/0/all/0/1&quot;&gt;Tarun Yellamraju&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Boutin_M/0/1/0/all/0/1&quot;&gt;Mireille Boutin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05355">
<title>Scalable Neural Network Compression and Pruning Using Hard Clustering and L1 Regularization. (arXiv:1806.05355v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.05355</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a simple and easy to implement neural network compression
algorithm that achieves results competitive with more complicated
state-of-the-art methods. The key idea is to modify the original optimization
problem by adding K independent Gaussian priors (corresponding to the k-means
objective) over the network parameters to achieve parameter quantization, as
well as an L1 penalty to achieve pruning. Unlike many existing
quantization-based methods, our method uses hard clustering assignments of
network parameters, which adds minimal change or overhead to standard network
training. We also demonstrate experimentally that tying neural network
parameters provides less gain in generalization performance than changing
network architecture and connectivity patterns entirely.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yang_Y/0/1/0/all/0/1&quot;&gt;Yibo Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ruozzi_N/0/1/0/all/0/1&quot;&gt;Nicholas Ruozzi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gogate_V/0/1/0/all/0/1&quot;&gt;Vibhav Gogate&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05393">
<title>Dynamical Isometry and a Mean Field Theory of CNNs: How to Train 10,000-Layer Vanilla Convolutional Neural Networks. (arXiv:1806.05393v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.05393</link>
<description rdf:parseType="Literal">&lt;p&gt;In recent years, state-of-the-art methods in computer vision have utilized
increasingly deep convolutional neural network architectures (CNNs), with some
of the most successful models employing hundreds or even thousands of layers. A
variety of pathologies such as vanishing/exploding gradients make training such
deep networks challenging. While residual connections and batch normalization
do enable training at these depths, it has remained unclear whether such
specialized architecture designs are truly necessary to train deep CNNs. In
this work, we demonstrate that it is possible to train vanilla CNNs with ten
thousand layers or more simply by using an appropriate initialization scheme.
We derive this initialization scheme theoretically by developing a mean field
theory for signal propagation and by characterizing the conditions for
dynamical isometry, the equilibration of singular values of the input-output
Jacobian matrix. These conditions require that the convolution operator be an
orthogonal transformation in the sense that it is norm-preserving. We present
an algorithm for generating such random initial orthogonal convolution kernels
and demonstrate empirically that they enable efficient training of extremely
deep architectures.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Xiao_L/0/1/0/all/0/1&quot;&gt;Lechao Xiao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bahri_Y/0/1/0/all/0/1&quot;&gt;Yasaman Bahri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sohl_Dickstein_J/0/1/0/all/0/1&quot;&gt;Jascha Sohl-Dickstein&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Schoenholz_S/0/1/0/all/0/1&quot;&gt;Samuel S. Schoenholz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pennington_J/0/1/0/all/0/1&quot;&gt;Jeffrey Pennington&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05394">
<title>Dynamical Isometry and a Mean Field Theory of RNNs: Gating Enables Signal Propagation in Recurrent Neural Networks. (arXiv:1806.05394v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.05394</link>
<description rdf:parseType="Literal">&lt;p&gt;Recurrent neural networks have gained widespread use in modeling sequence
data across various domains. While many successful recurrent architectures
employ a notion of gating, the exact mechanism that enables such remarkable
performance is not well understood. We develop a theory for signal propagation
in recurrent networks after random initialization using a combination of mean
field theory and random matrix theory. To simplify our discussion, we introduce
a new RNN cell with a simple gating mechanism that we call the minimalRNN and
compare it with vanilla RNNs. Our theory allows us to define a maximum
timescale over which RNNs can remember an input. We show that this theory
predicts trainability for both recurrent architectures. We show that gated
recurrent networks feature a much broader, more robust, trainable region than
vanilla RNNs, which corroborates recent experimental findings. Finally, we
develop a closed-form critical initialization scheme that achieves dynamical
isometry in both vanilla RNNs and minimalRNNs. We show that this results in
significantly improvement in training dynamics. Finally, we demonstrate that
the minimalRNN achieves comparable performance to its more complex
counterparts, such as LSTMs or GRUs, on a language modeling task.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chen_M/0/1/0/all/0/1&quot;&gt;Minmin Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pennington_J/0/1/0/all/0/1&quot;&gt;Jeffrey Pennington&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Schoenholz_S/0/1/0/all/0/1&quot;&gt;Samuel S. Schoenholz&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05413">
<title>Learning Dynamics of Linear Denoising Autoencoders. (arXiv:1806.05413v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.05413</link>
<description rdf:parseType="Literal">&lt;p&gt;Denoising autoencoders (DAEs) have proven useful for unsupervised
representation learning, but a thorough theoretical understanding is still
lacking of how the input noise influences learning. Here we develop theory for
how noise influences learning in DAEs. By focusing on linear DAEs, we are able
to derive analytic expressions that exactly describe their learning dynamics.
We verify our theoretical predictions with simulations as well as experiments
on MNIST and CIFAR-10. The theory illustrates how, when tuned correctly, noise
allows DAEs to ignore low variance directions in the inputs while learning to
reconstruct them. Furthermore, in a comparison of the learning dynamics of DAEs
to standard regularised autoencoders, we show that noise has a similar
regularisation effect to weight decay, but with faster training dynamics. We
also show that our theoretical predictions approximate learning dynamics on
real-world data and qualitatively match observed dynamics in nonlinear DAEs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pretorius_A/0/1/0/all/0/1&quot;&gt;Arnu Pretorius&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kroon_S/0/1/0/all/0/1&quot;&gt;Steve Kroon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kamper_H/0/1/0/all/0/1&quot;&gt;Herman Kamper&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05454">
<title>Low-rank geometric mean metric learning. (arXiv:1806.05454v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.05454</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a low-rank approach to learning a Mahalanobis metric from data.
Inspired by the recent geometric mean metric learning (GMML) algorithm, we
propose a low-rank variant of the algorithm. This allows to jointly learn a
low-dimensional subspace where the data reside and the Mahalanobis metric that
appropriately fits the data. Our results show that we compete effectively with
GMML at lower ranks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bhutani_M/0/1/0/all/0/1&quot;&gt;Mukul Bhutani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jawanpuria_P/0/1/0/all/0/1&quot;&gt;Pratik Jawanpuria&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kasai_H/0/1/0/all/0/1&quot;&gt;Hiroyuki Kasai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mishra_B/0/1/0/all/0/1&quot;&gt;Bamdev Mishra&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05476">
<title>Copycat CNN: Stealing Knowledge by Persuading Confession with Random Non-Labeled Data. (arXiv:1806.05476v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1806.05476</link>
<description rdf:parseType="Literal">&lt;p&gt;In the past few years, Convolutional Neural Networks (CNNs) have been
achieving state-of-the-art performance on a variety of problems. Many companies
employ resources and money to generate these models and provide them as an API,
therefore it is in their best interest to protect them, i.e., to avoid that
someone else copies them. Recent studies revealed that state-of-the-art CNNs
are vulnerable to adversarial examples attacks, and this weakness indicates
that CNNs do not need to operate in the problem domain (PD). Therefore, we
hypothesize that they also do not need to be trained with examples of the PD in
order to operate in it.
&lt;/p&gt;
&lt;p&gt;Given these facts, in this paper, we investigate if a target black-box CNN
can be copied by persuading it to confess its knowledge through random
non-labeled data. The copy is two-fold: i) the target network is queried with
random data and its predictions are used to create a fake dataset with the
knowledge of the network; and ii) a copycat network is trained with the fake
dataset and should be able to achieve similar performance as the target
network.
&lt;/p&gt;
&lt;p&gt;This hypothesis was evaluated locally in three problems (facial expression,
object, and crosswalk classification) and against a cloud-based API. In the
copy attacks, images from both non-problem domain and PD were used. All copycat
networks achieved at least 93.7% of the performance of the original models with
non-problem domain data, and at least 98.6% using additional data from the PD.
Additionally, the copycat CNN successfully copied at least 97.3% of the
performance of the Microsoft Azure Emotion API. Our results show that it is
possible to create a copycat CNN by simply querying a target network as
black-box with random non-labeled data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Correia_Silva_J/0/1/0/all/0/1&quot;&gt;Jacson Rodrigues Correia-Silva&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Berriel_R/0/1/0/all/0/1&quot;&gt;Rodrigo F. Berriel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Badue_C/0/1/0/all/0/1&quot;&gt;Claudine Badue&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Souza_A/0/1/0/all/0/1&quot;&gt;Alberto F. de Souza&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oliveira_Santos_T/0/1/0/all/0/1&quot;&gt;Thiago Oliveira-Santos&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05512">
<title>NetScore: Towards Universal Metrics for Large-scale Performance Analysis of Deep Neural Networks for Practical Usage. (arXiv:1806.05512v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1806.05512</link>
<description rdf:parseType="Literal">&lt;p&gt;Much of the focus in the design of deep neural networks has been on improving
accuracy, leading to more powerful yet highly complex network architectures
that are difficult to deploy in practical scenarios, particularly on edge
devices such as mobile and other consumer devices, given their high
computational and memory requirements. As a result, there has been a recent
interest in the design of quantitative metrics for evaluating deep neural
networks that accounts for more than just model accuracy as the sole indicator
of network performance. In this study, we continue the conversation towards
universal metrics for evaluating the performance of deep neural networks for
practical usage. In particular, we propose a new balanced metric called
NetScore, which is designed specifically to provide a quantitative assessment
of the balance between accuracy, computational complexity, and network
architecture complexity of a deep neural network. In what is one of the largest
comparative analysis between deep neural networks in literature, the NetScore
metric, the top-1 accuracy metric, and the popular information density metric
were compared across a diverse set of 50 different deep convolutional neural
networks for image classification on the ImageNet Large Scale Visual
Recognition Challenge (ILSVRC 2012) dataset. The evaluation results across
these three metrics for this diverse set of networks are presented in this
study to act as a reference guide for practitioners in the field. The proposed
NetScore metric, along with the other tested metrics, are by no means perfect,
but the hope is to push the conversation towards better universal metrics for
evaluating deep neural networks for use in practical scenarios to help guide
practitioners in model design.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wong_A/0/1/0/all/0/1&quot;&gt;Alexander Wong&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05514">
<title>The Exact Equivalence of Distance and Kernel Methods for Hypothesis Testing. (arXiv:1806.05514v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.05514</link>
<description rdf:parseType="Literal">&lt;p&gt;Distance-based methods, also called &quot;energy statistics&quot;, are leading methods
for two-sample and independence tests from the statistics community. Kernel
methods, developed from &quot;kernel mean embeddings&quot;, are leading methods for
two-sample and independence tests from the machine learning community. Previous
works demonstrated the equivalence of distance and kernel methods only at the
population level, for each kind of test, requiring an embedding theory of
kernels. We propose a simple, bijective transformation between semimetrics and
nondegenerate kernels. We prove that for finite samples, two-sample tests are
special cases of independence tests, and the distance-based statistic is
equivalent to the kernel-based statistic, including the biased, unbiased, and
normalized versions. In other words, upon setting the kernel or metric to be
bijective of each other, running any of the four algorithms will yield the
exact same answer up to numerical precision. This deepens and unifies our
understanding of interpoint comparison based methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Shen_C/0/1/0/all/0/1&quot;&gt;Cencheng Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Vogelstein_J/0/1/0/all/0/1&quot;&gt;Joshua T. Vogelstein&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05559">
<title>Extracting Parallel Sentences with Bidirectional Recurrent Neural Networks to Improve Machine Translation. (arXiv:1806.05559v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1806.05559</link>
<description rdf:parseType="Literal">&lt;p&gt;Parallel sentence extraction is a task addressing the data sparsity problem
found in multilingual natural language processing applications. We propose a
bidirectional recurrent neural network based approach to extract parallel
sentences from collections of multilingual texts. Our experiments with noisy
parallel corpora show that we can achieve promising results against a
competitive baseline by removing the need of specific feature engineering or
additional external resources. To justify the utility of our approach, we
extract sentence pairs from Wikipedia articles to train machine translation
systems and show significant improvements in translation performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gregoire_F/0/1/0/all/0/1&quot;&gt;Francis Gr&amp;#xe9;goire&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Langlais_P/0/1/0/all/0/1&quot;&gt;Philippe Langlais&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05662">
<title>GLoMo: Unsupervisedly Learned Relational Graphs as Transferable Representations. (arXiv:1806.05662v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.05662</link>
<description rdf:parseType="Literal">&lt;p&gt;Modern deep transfer learning approaches have mainly focused on learning
generic feature vectors from one task that are transferable to other tasks,
such as word embeddings in language and pretrained convolutional features in
vision. However, these approaches usually transfer unary features and largely
ignore more structured graphical representations. This work explores the
possibility of learning generic latent relational graphs that capture
dependencies between pairs of data units (e.g., words or pixels) from
large-scale unlabeled data and transferring the graphs to downstream tasks. Our
proposed transfer learning framework improves performance on various tasks
including question answering, natural language inference, sentiment analysis,
and image classification. We also show that the learned graphs are generic
enough to be transferred to different embeddings on which the graphs have not
been trained (including GloVe embeddings, ELMo embeddings, and task-specific
RNN hidden unit), or embedding-free units such as image pixels.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1&quot;&gt;Zhilin Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jake/0/1/0/all/0/1&quot;&gt;Jake&lt;/a&gt; (Junbo) &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao/0/1/0/all/0/1&quot;&gt;Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dhingra_B/0/1/0/all/0/1&quot;&gt;Bhuwan Dhingra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_K/0/1/0/all/0/1&quot;&gt;Kaiming He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cohen_W/0/1/0/all/0/1&quot;&gt;William W. Cohen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Salakhutdinov_R/0/1/0/all/0/1&quot;&gt;Ruslan Salakhutdinov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+LeCun_Y/0/1/0/all/0/1&quot;&gt;Yann LeCun&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1604.06749">
<title>Learning a Tree-Structured Ising Model in Order to Make Predictions. (arXiv:1604.06749v3 [math.ST] UPDATED)</title>
<link>http://arxiv.org/abs/1604.06749</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the problem of learning a tree Ising model from samples such that
subsequent predictions made using the model are accurate. The prediction task
considered in this paper is that of predicting the values of a subset of
variables given values of some other subset of variables. Virtually all
previous work on graphical model learning has focused on recovering the true
underlying graph. We define a distance (&quot;small set TV&quot; or ssTV) between
distributions $P$ and $Q$ by taking the maximum, over all subsets $\mathcal{S}$
of a given size, of the total variation between the marginals of $P$ and $Q$ on
$\mathcal{S}$; this distance captures the accuracy of the prediction task of
interest. We derive non-asymptotic bounds on the number of samples needed to
get a distribution (from the same class) with small ssTV relative to the one
generating the samples. One of the main messages of this paper is that far
fewer samples are needed than for recovering the underlying tree, which means
that accurate predictions are possible using the wrong tree.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Bresler_G/0/1/0/all/0/1&quot;&gt;Guy Bresler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Karzand_M/0/1/0/all/0/1&quot;&gt;Mina Karzand&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.05558">
<title>Gradient-Based Meta-Learning with Learned Layerwise Metric and Subspace. (arXiv:1801.05558v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1801.05558</link>
<description rdf:parseType="Literal">&lt;p&gt;Gradient-based meta-learning methods leverage gradient descent to learn the
commonalities among various tasks. While previous such methods have been
successful in meta-learning tasks, they resort to simple gradient descent
during meta-testing. Our primary contribution is the {\em MT-net}, which
enables the meta-learner to learn on each layer&apos;s activation space a subspace
that the task-specific learner performs gradient descent on. Additionally, a
task-specific learner of an {\em MT-net} performs gradient descent with respect
to a meta-learned distance metric, which warps the activation space to be more
sensitive to task identity. We demonstrate that the dimension of this learned
subspace reflects the complexity of the task-specific learner&apos;s adaptation
task, and also that our model is less sensitive to the choice of initial
learning rates than previous gradient-based meta-learning methods. Our method
achieves state-of-the-art or comparable performance on few-shot classification
and regression tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lee_Y/0/1/0/all/0/1&quot;&gt;Yoonho Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Choi_S/0/1/0/all/0/1&quot;&gt;Seungjin Choi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.07301">
<title>On the Connection Between Learning Two-Layers Neural Networks and Tensor Decomposition. (arXiv:1802.07301v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1802.07301</link>
<description rdf:parseType="Literal">&lt;p&gt;We establish connections between the problem of learning a two-layers neural
network with good generalization error and tensor decomposition. We consider a
model with input $\boldsymbol x \in \mathbb R^d$, $r$ hidden units with weights
$\{\boldsymbol w_i\}_{1\le i \le r}$ and output $y\in \mathbb R$, i.e.,
$y=\sum_{i=1}^r\sigma(\langle\boldsymbol x, \boldsymbol w_i\rangle)$, where
$\langle\cdot, \cdot\rangle$ denotes the scalar product and $\sigma$ the
activation function. First, we show that, if we cannot learn the weights
$\{\boldsymbol w_i\}_{1\le i\le r}$ accurately, then the neural network does
not generalize well. More specifically, the generalization error is close to
that of a trivial predictor with access only to the norm of the input. We prove
this result in a model with separated isotropic weights and in a model with
random weights. In both settings, we assume that the input distribution is
Gaussian, which is common in the theoretical literature. Then, we show that the
problem of learning the weights $\{\boldsymbol w_i\}_{1\le i \le r}$ is at
least as hard as the problem of tensor decomposition. We prove this result for
any input distribution, and we assume that the activation function is a
polynomial whose degree is related to the order of the tensor to be decomposed.
Hence, we obtain that learning a two-layers neural network that generalizes
well is at least as hard as tensor decomposition. It has been observed that
neural network models with more parameters than training samples often
generalize well, even if the problem is highly underdetermined. This means that
the learning algorithm does not estimate the weights accurately and yet is able
to yield a good generalization error. This paper shows that such a phenomenon
cannot occur with a two-layers neural network when the input distribution is
Gaussian. We also provide numerical evidence supporting our theoretical
findings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mondelli_M/0/1/0/all/0/1&quot;&gt;Marco Mondelli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Montanari_A/0/1/0/all/0/1&quot;&gt;Andrea Montanari&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09298">
<title>Learning towards Minimum Hyperspherical Energy. (arXiv:1805.09298v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.09298</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural networks are a powerful class of nonlinear functions that can be
trained end-to-end on various applications. While the over-parametrization
nature in many neural networks renders the ability to fit complex functions and
the strong representation power to handle challenging tasks, it also leads to
highly correlated neurons that can hurt the generalization ability and incur
unnecessary computation cost. As a result, how to regularize the network to
avoid undesired representation redundancy becomes an important issue. To this
end, we draw inspiration from a well-known problem in physics -- Thomson
problem, where one seeks to find a state that distributes N electrons on a unit
sphere as even as possible with minimum potential energy. In light of this
intuition, we reduce the redundancy regularization problem to generic energy
minimization, and propose a minimum hyperspherical energy (MHE) objective as
generic regularization for neural networks. We also propose a few novel
variants of MHE, and provide some insights from a theoretical point of view.
Finally, we apply networks with MHE regularization to several challenging
tasks. Extensive experiments demonstrate the effectiveness of our method, by
showing the superior performance with MHE regularization.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1&quot;&gt;Weiyang Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_R/0/1/0/all/0/1&quot;&gt;Rongmei Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1&quot;&gt;Zhen Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1&quot;&gt;Lixin Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1&quot;&gt;Zhiding Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dai_B/0/1/0/all/0/1&quot;&gt;Bo Dai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_L/0/1/0/all/0/1&quot;&gt;Le Song&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04000">
<title>Aggregating Predictions on Multiple Non-disclosed Datasets using Conformal Prediction. (arXiv:1806.04000v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1806.04000</link>
<description rdf:parseType="Literal">&lt;p&gt;Conformal Prediction is a machine learning methodology that produces valid
prediction regions under mild conditions. In this paper, we explore the
application of making predictions over multiple data sources of different sizes
without disclosing data between the sources. We propose that each data source
applies a transductive conformal predictor independently using the local data,
and that the individual predictions are then aggregated to form a combined
prediction region. We demonstrate the method on several data sets, and show
that the proposed method produces conservatively valid predictions and reduces
the variance in the aggregated predictions. We also study the effect that the
number of data sources and size of each source has on aggregated predictions,
as compared with equally sized sources and pooled data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Spjuth_O/0/1/0/all/0/1&quot;&gt;Ola Spjuth&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Carlsson_L/0/1/0/all/0/1&quot;&gt;Lars Carlsson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gauraha_N/0/1/0/all/0/1&quot;&gt;Niharika Gauraha&lt;/a&gt;</dc:creator>
</item></rdf:RDF>