<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Good papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Good Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-07-09T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.02564"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.03001"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.03165"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.03215"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1603.03116"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1609.02226"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08574"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.01610"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.02572"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.02648"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.02799"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.03021"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.03052"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.03168"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.03224"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1707.06690"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.02393"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.01265"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.03417"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06208"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.10478"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.11463"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.02515"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.02547"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.02552"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.02567"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.02609"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.02653"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.02787"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.02919"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.02999"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.03046"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.03133"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.03142"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.03167"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.03179"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.03247"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.03257"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.07107"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06552"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.07569"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09031"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.07551"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05514"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.00560"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.01082"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1807.02564">
<title>Applications of Data Mining Techniques for Vehicular Ad hoc Networks. (arXiv:1807.02564v1 [cs.NI])</title>
<link>http://arxiv.org/abs/1807.02564</link>
<description rdf:parseType="Literal">&lt;p&gt;Due to the recent advances in vehicular ad hoc networks (VANETs), smart
applications have been incorporating the data generated from these networks to
provide quality of life services. In this paper, we have proposed taxonomy of
data mining techniques that have been applied in this domain in addition to a
classification of these techniques. Our contribution is to highlight the
research methodologies in the literature and allow for comparing among them
using different characteristics. The proposed taxonomy covers elementary data
mining techniques such as: preprocessing, outlier detection, clustering, and
classification of data. In addition, it covers centralized, distributed,
offline, and online techniques from the literature.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zamil_M/0/1/0/all/0/1&quot;&gt;Mohammed AL Zamil&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Samarah_S/0/1/0/all/0/1&quot;&gt;Samer Samarah&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.03001">
<title>Learning Functions in Large Networks requires Modularity and produces Multi-Agent Dynamics. (arXiv:1807.03001v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1807.03001</link>
<description rdf:parseType="Literal">&lt;p&gt;Networks are abundant in biological systems. Small sized over-represented
network motifs have been discovered, and it has been suggested that these
constitute functional building blocks. We ask whether larger dynamical network
motifs exist in biological networks, thus contributing to the higher-order
organization of a network. To end this, we introduce a gradient descent machine
learning (ML) approach and genetic algorithms to learn larger functional motifs
in contrast to an (unfeasible) exhaustive search. We use the French Flag (FF)
and Switch functional motif as case studies motivated from biology. While our
algorithm successfully learns large functional motifs, we identify a threshold
size of approximately 20 nodes beyond which learning breaks down. Therefore we
investigate the stability of the motifs. We find that the size of the real
negative eigenvalues of the Jacobian decreases with increasing system size,
thus conferring instability. Finally, without imposing learning an input-output
for all the components of the network, we observe that unconstrained middle
components of the network still learn the desired function, a form of
homogeneous team learning. We conclude that the size limitation of
learnability, most likely due to stability constraints, impose a definite
requirement for modularity in networked systems while enabling team learning
within unconstrained parts of the module. Thus, the observation that community
structures and modularity are abundant in biological networks could be
accounted for by a computational compositional network structure.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1&quot;&gt;C. H. Huck Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ooi_R/0/1/0/all/0/1&quot;&gt;Rise Ooi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hiscock_T/0/1/0/all/0/1&quot;&gt;Tom Hiscock&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Eguiluz_V/0/1/0/all/0/1&quot;&gt;Victor Eguiluz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tegner_J/0/1/0/all/0/1&quot;&gt;Jesper Tegner&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.03165">
<title>Sparse Deep Neural Network Exact Solutions. (arXiv:1807.03165v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.03165</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep neural networks (DNNs) have emerged as key enablers of machine learning.
Applying larger DNNs to more diverse applications is an important challenge.
The computations performed during DNN training and inference are dominated by
operations on the weight matrices describing the DNN. As DNNs incorporate more
layers and more neurons per layers, these weight matrices may be required to be
sparse because of memory limitations. Sparse DNNs are one possible approach,
but the underlying theory is in the early stages of development and presents a
number of challenges, including determining the accuracy of inference and
selecting nonzero weights for training. Associative array algebra has been
developed by the big data community to combine and extend database, matrix, and
graph/network concepts for use in large, sparse data problems. Applying this
mathematics to DNNs simplifies the formulation of DNN mathematics and reveals
that DNNs are linear over oscillating semirings. This work uses associative
array DNNs to construct exact solutions and corresponding perturbation models
to the rectified linear unit (ReLU) DNN equations that can be used to construct
test vectors for sparse DNN implementations over various precisions. These
solutions can be used for DNN verification, theoretical explorations of DNN
properties, and a starting point for the challenge of sparse training.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kepner_J/0/1/0/all/0/1&quot;&gt;Jeremy Kepner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gadepally_V/0/1/0/all/0/1&quot;&gt;Vijay Gadepally&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jananthan_H/0/1/0/all/0/1&quot;&gt;Hayden Jananthan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Milechin_L/0/1/0/all/0/1&quot;&gt;Lauren Milechin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Samsi_S/0/1/0/all/0/1&quot;&gt;Sid Samsi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.03215">
<title>Fuzzy Logic Interpretation of Artificial Neural Networks. (arXiv:1807.03215v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1807.03215</link>
<description rdf:parseType="Literal">&lt;p&gt;Over past several years, deep learning has achieved huge successes in various
applications. However, such a data-driven approach is often criticized for lack
of interpretability. Recently, we proposed artificial quadratic neural networks
consisting of second-order neurons in potentially many layers. In each
second-order neuron, a quadratic function is used in the place of the inner
product in a traditional neuron, and then undergoes a nonlinear activation.
With a single second-order neuron, any fuzzy logic operation, such as XOR, can
be implemented. In this sense, any deep network constructed with quadratic
neurons can be interpreted as a deep fuzzy logic system. Since traditional
neural networks and second-order counterparts can represent each other and
fuzzy logic operations are naturally implemented in second-order neural
networks, it is plausible to explain how a deep neural network works with a
second-order network as the system model. In this paper, we generalize and
categorize fuzzy logic operations implementable with individual second-order
neurons, and then perform statistical/information theoretic analyses of
exemplary quadratic neural networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fan_F/0/1/0/all/0/1&quot;&gt;Fenglei Fan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1&quot;&gt;Ge Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1603.03116">
<title>Low-rank passthrough neural networks. (arXiv:1603.03116v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1603.03116</link>
<description rdf:parseType="Literal">&lt;p&gt;Various common deep learning architectures, such as LSTMs, GRUs, Resnets and
Highway Networks, employ state passthrough connections that support training
with high feed-forward depth or recurrence over many time steps. These
&quot;Passthrough Networks&quot; architectures also enable the decoupling of the network
state size from the number of parameters of the network, a possibility has been
studied by \newcite{Sak2014} with their low-rank parametrization of the LSTM.
In this work we extend this line of research, proposing effective, low-rank and
low-rank plus diagonal matrix parametrizations for Passthrough Networks which
exploit this decoupling property, reducing the data complexity and memory
requirements of the network while preserving its memory capacity. This is
particularly beneficial in low-resource settings as it supports expressive
models with a compact parametrization less susceptible to overfitting. We
present competitive experimental results on several tasks, including language
modeling and a near state of the art result on sequential randomly-permuted
MNIST classification, a hard task on natural data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barone_A/0/1/0/all/0/1&quot;&gt;Antonio Valerio Miceli Barone&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1609.02226">
<title>Fitted Learning: Models with Awareness of their Limits. (arXiv:1609.02226v4 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1609.02226</link>
<description rdf:parseType="Literal">&lt;p&gt;Though deep learning has pushed the boundaries of classification forward, in
recent years hints of the limits of standard classification have begun to
emerge. Problems such as fooling, adding new classes over time, and the need to
retrain learning models only for small changes to the original problem all
point to a potential shortcoming in the classic classification regime, where a
comprehensive a priori knowledge of the possible classes or concepts is
critical. Without such knowledge, classifiers misjudge the limits of their
knowledge and overgeneralization therefore becomes a serious obstacle to
consistent performance. In response to these challenges, this paper extends the
classic regime by reframing classification instead with the assumption that
concepts present in the training set are only a sample of the hypothetical
final set of concepts. To bring learning models into this new paradigm, a novel
elaboration of standard architectures called the competitive overcomplete
output layer (COOL) neural network is introduced. Experiments demonstrate the
effectiveness of COOL by applying it to fooling, separable concept learning,
one-class neural networks, and standard classification benchmarks. The results
suggest that, unlike conventional classifiers, the amount of generalization in
COOL networks can be tuned to match the problem.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kardan_N/0/1/0/all/0/1&quot;&gt;Navid Kardan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stanley_K/0/1/0/all/0/1&quot;&gt;Kenneth O. Stanley&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08574">
<title>Breaking the Activation Function Bottleneck through Adaptive Parameterization. (arXiv:1805.08574v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.08574</link>
<description rdf:parseType="Literal">&lt;p&gt;Standard neural network architectures are non-linear only by virtue of a
simple element-wise activation function, making them both brittle and
excessively large. In this paper, we consider methods for making the
feed-forward layer more flexible while preserving its basic structure. We
develop simple drop-in replacements that learn to adapt their parameterization
conditional on the input, thereby increasing statistical efficiency
significantly. We present an adaptive LSTM that advances the state of the art
for the Penn Treebank and WikiText-2 word-modeling tasks while using fewer
parameters and converging in less than half as many iterations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Flennerhag_S/0/1/0/all/0/1&quot;&gt;Sebastian Flennerhag&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yin_H/0/1/0/all/0/1&quot;&gt;Hujun Yin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Keane_J/0/1/0/all/0/1&quot;&gt;John Keane&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Elliot_M/0/1/0/all/0/1&quot;&gt;Mark Elliot&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.01610">
<title>Training Generative Reversible Networks. (arXiv:1806.01610v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1806.01610</link>
<description rdf:parseType="Literal">&lt;p&gt;Generative models with an encoding component such as autoencoders currently
receive great interest. However, training of autoencoders is typically
complicated by the need to train a separate encoder and decoder model that have
to be enforced to be reciprocal to each other. To overcome this problem,
by-design reversible neural networks (RevNets) had been previously used as
generative models either directly optimizing the likelihood of the data under
the model or using an adversarial approach on the generated data. Here, we
instead investigate their performance using an adversary on the latent space in
the adversarial autoencoder framework. We investigate the generative
performance of RevNets on the CelebA dataset, showing that generative RevNets
can generate coherent faces with similar quality as Variational Autoencoders.
This first attempt to use RevNets inside the adversarial autoencoder framework
slightly underperformed relative to recent advanced generative models using an
autoencoder component on CelebA, but this gap may diminish with further
optimization of the training setup of generative RevNets. In addition to the
experiments on CelebA, we show a proof-of-principle experiment on the MNIST
dataset suggesting that adversary-free trained RevNets can discover meaningful
latent dimensions without pre-specifying the number of dimensions of the latent
sampling distribution. In summary, this study shows that RevNets can be
employed in different generative training settings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schirrmeister_R/0/1/0/all/0/1&quot;&gt;Robin Tibor Schirrmeister&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chrabaszcz_P/0/1/0/all/0/1&quot;&gt;Patryk Chrab&amp;#x105;szcz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hutter_F/0/1/0/all/0/1&quot;&gt;Frank Hutter&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ball_T/0/1/0/all/0/1&quot;&gt;Tonio Ball&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.02572">
<title>Quasi-Dilemmas for Artificial Moral Agents. (arXiv:1807.02572v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1807.02572</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper we describe moral quasi-dilemmas (MQDs): situations similar to
moral dilemmas, but in which an agent is unsure whether exploring the plan
space or the world may reveal a course of action that satisfies all moral
requirements. We argue that artificial moral agents (AMAs) should be built to
handle MQDs (in particular, by exploring the plan space rather than immediately
accepting the inevitability of the moral dilemma), and that MQDs may be useful
for evaluating AMA architectures.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kasenberg_D/0/1/0/all/0/1&quot;&gt;Daniel Kasenberg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sarathy_V/0/1/0/all/0/1&quot;&gt;Vasanth Sarathy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Arnold_T/0/1/0/all/0/1&quot;&gt;Thomas Arnold&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Scheutz_M/0/1/0/all/0/1&quot;&gt;Matthias Scheutz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Williams_T/0/1/0/all/0/1&quot;&gt;Tom Williams&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.02648">
<title>How game complexity affects the playing behavior of synthetic agents. (arXiv:1807.02648v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1807.02648</link>
<description rdf:parseType="Literal">&lt;p&gt;Agent based simulation of social organizations, via the investigation of
agents&apos; training and learning tactics and strategies, has been inspired by the
ability of humans to learn from social environments which are rich in agents,
interactions and partial or hidden information. Such richness is a source of
complexity that an effective learner has to be able to navigate. This paper
focuses on the investigation of the impact of the environmental complexity on
the game playing-and-learning behavior of synthetic agents. We demonstrate our
approach using two independent turn-based zero-sum games as the basis of
forming social events which are characterized both by competition and
cooperation. The paper&apos;s key highlight is that as the complexity of a social
environment changes, an effective player has to adapt its learning and playing
profile to maintain a given performance profile
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kiourt_C/0/1/0/all/0/1&quot;&gt;Chairi Kiourt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kalles_D/0/1/0/all/0/1&quot;&gt;Dimitris Kalles&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kanellopoulos_P/0/1/0/all/0/1&quot;&gt;Panagiotis Kanellopoulos&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.02799">
<title>Distillation Techniques for Pseudo-rehearsal Based Incremental Learning. (arXiv:1807.02799v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1807.02799</link>
<description rdf:parseType="Literal">&lt;p&gt;The ability to learn from incrementally arriving data is essential for any
life-long learning system. However, standard deep neural networks forget the
knowledge about the old tasks, a phenomenon called catastrophic forgetting,
when trained on incrementally arriving data. We discuss the biases in current
Generative Adversarial Networks (GAN) based approaches that learn the
classifier by knowledge distillation from previously trained classifiers. These
biases cause the trained classifier to perform poorly. We propose an approach
to remove these biases by distilling knowledge from the classifier of AC-GAN.
Experiments on MNIST and CIFAR10 show that this method is comparable to current
state of the art rehearsal based approaches. The code for this paper is
available at this
$\href{https://github.com/haseebs/Pseudo-rehearsal-Incremental-Learning}{link}$.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shah_H/0/1/0/all/0/1&quot;&gt;Haseeb Shah&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Javed_K/0/1/0/all/0/1&quot;&gt;Khurram Javed&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shafait_F/0/1/0/all/0/1&quot;&gt;Faisal Shafait&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.03021">
<title>Verisimilar Image Synthesis for Accurate Detection and Recognition of Texts in Scenes. (arXiv:1807.03021v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1807.03021</link>
<description rdf:parseType="Literal">&lt;p&gt;The requirement of large amounts of annotated images has become one grand
challenge while training deep neural network models for various visual
detection and recognition tasks. This paper presents a novel image synthesis
technique that aims to generate a large amount of annotated scene text images
for training accurate and robust scene text detection and recognition models.
The proposed technique consists of three innovative designs. First, it realizes
&quot;semantic coherent&quot; synthesis by embedding texts at semantically sensible
regions within the background image, where the semantic coherence is achieved
by leveraging the semantic annotations of objects and image regions that have
been created in the prior semantic segmentation research. Second, it exploits
visual saliency to determine the embedding locations within each semantic
sensible region, which coincides with the fact that texts are often placed
around homogeneous regions for better visibility in scenes. Third, it designs
an adaptive text appearance model that determines the color and brightness of
embedded texts by learning from the feature of real scene text images
adaptively. The proposed technique has been evaluated over five public datasets
and the experiments show its superior performance in training accurate and
robust scene text detection and recognition models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhan_F/0/1/0/all/0/1&quot;&gt;Fangneng Zhan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_S/0/1/0/all/0/1&quot;&gt;Shijian Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xue_C/0/1/0/all/0/1&quot;&gt;Chuhui Xue&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.03052">
<title>Position-aware Self-attention with Relative Positional Encodings for Slot Filling. (arXiv:1807.03052v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1807.03052</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper describes how to apply self-attention with relative positional
encodings to the task of relation extraction. We propose to use the
self-attention encoder layer together with an additional position-aware
attention layer that takes into account positions of the query and the object
in the sentence. The self-attention encoder also uses a custom implementation
of relative positional encodings which allow each word in the sentence to take
into account its left and right context. The evaluation of the model is done on
the TACRED dataset. The proposed model relies only on attention (no recurrent
or convolutional layers are used), while improving performance w.r.t. the
previous state of the art.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bilan_I/0/1/0/all/0/1&quot;&gt;Ivan Bilan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roth_B/0/1/0/all/0/1&quot;&gt;Benjamin Roth&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.03168">
<title>NAPS: Natural Program Synthesis Dataset. (arXiv:1807.03168v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.03168</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a program synthesis-oriented dataset consisting of human written
problem statements and solutions for these problems. The problem statements
were collected via crowdsourcing and the program solutions were extracted from
human-written solutions in programming competitions, accompanied by
input/output examples. We propose using this dataset for the program synthesis
tasks aimed for working with real user-generated data. As a baseline we present
few models, with the best model achieving 8.8% accuracy, showcasing both the
complexity of the dataset and large room for future research.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zavershynskyi_M/0/1/0/all/0/1&quot;&gt;Maksym Zavershynskyi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Skidanov_A/0/1/0/all/0/1&quot;&gt;Alex Skidanov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Polosukhin_I/0/1/0/all/0/1&quot;&gt;Illia Polosukhin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.03224">
<title>Design and Evaluation of a Tutor Platform for Personalized Vocabulary Learning. (arXiv:1807.03224v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1807.03224</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents our experiences in designing, implementing, and piloting
an intelligent vocabulary learning tutor. The design builds on several
intelligent tutoring design concepts, including graph-based knowledge
representation, learner modeling, and adaptive learning content and assessment
exposition. Specifically, we design a novel phased learner model approach to
enable systematic exposure to words during vocabulary instruction. We also
built an example application over the tutor platform that uses a learning
activity involving videos and an assessment activity involving word to
picture/image association. More importantly, the tutor adapts to the
significant variation in children&apos;s knowledge at the beginning of kindergarten,
and evolves the application at the speed of each individual learner. A pilot
study with 180 kindergarten learners allowed the tutor to collect various kinds
of activity information suitable for insights and interventions both at an
individual- and class-level. The effort also demonstrates that we can do A/B
testing for a variety of hypotheses at scale with such a framework.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kokku_R/0/1/0/all/0/1&quot;&gt;Ravi Kokku&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vempaty_A/0/1/0/all/0/1&quot;&gt;Aditya Vempaty&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abuelsaad_T/0/1/0/all/0/1&quot;&gt;Tamer Abuelsaad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dey_P/0/1/0/all/0/1&quot;&gt;Prasenjit Dey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Humphrey_T/0/1/0/all/0/1&quot;&gt;Tammy Humphrey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gibson_A/0/1/0/all/0/1&quot;&gt;Akimi Gibson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kotler_J/0/1/0/all/0/1&quot;&gt;Jennifer Kotler&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1707.06690">
<title>DeepPath: A Reinforcement Learning Method for Knowledge Graph Reasoning. (arXiv:1707.06690v3 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1707.06690</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the problem of learning to reason in large scale knowledge graphs
(KGs). More specifically, we describe a novel reinforcement learning framework
for learning multi-hop relational paths: we use a policy-based agent with
continuous states based on knowledge graph embeddings, which reasons in a KG
vector space by sampling the most promising relation to extend its path. In
contrast to prior work, our approach includes a reward function that takes the
accuracy, diversity, and efficiency into consideration. Experimentally, we show
that our proposed method outperforms a path-ranking based algorithm and
knowledge graph embedding methods on Freebase and Never-Ending Language
Learning datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiong_W/0/1/0/all/0/1&quot;&gt;Wenhan Xiong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hoang_T/0/1/0/all/0/1&quot;&gt;Thien Hoang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1&quot;&gt;William Yang Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.02393">
<title>Weakly-supervised Contextualization of Knowledge Graph Facts. (arXiv:1805.02393v2 [cs.IR] UPDATED)</title>
<link>http://arxiv.org/abs/1805.02393</link>
<description rdf:parseType="Literal">&lt;p&gt;Knowledge graphs (KGs) model facts about the world, they consist of nodes
(entities such as companies and people) that are connected by edges (relations
such as founderOf). Facts encoded in KGs are frequently used by search
applications to augment result pages. When presenting a KG fact to the user,
providing other facts that are pertinent to that main fact can enrich the user
experience and support exploratory information needs. KG fact contextualization
is the task of augmenting a given KG fact with additional and useful KG facts.
The task is challenging because of the large size of KGs, discovering other
relevant facts even in a small neighborhood of the given fact results in an
enormous amount of candidates. We introduce a neural fact contextualization
method (NFCM) to address the KG fact contextualization task. NFCM first
generates a set of candidate facts in the neighborhood of a given fact and then
ranks the candidate facts using a supervised learning to rank model. The
ranking model combines features that we automatically learn from data and that
represent the query-candidate facts with a set of hand-crafted features we
devised or adjusted for this task. In order to obtain the annotations required
to train the learning to rank model at scale, we generate training data
automatically using distant supervision on a large entity-tagged text corpus.
We show that ranking functions learned on this data are effective at
contextualizing KG facts. Evaluation using human assessors shows that it
significantly outperforms several competitive baselines.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Voskarides_N/0/1/0/all/0/1&quot;&gt;Nikos Voskarides&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meij_E/0/1/0/all/0/1&quot;&gt;Edgar Meij&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Reinanda_R/0/1/0/all/0/1&quot;&gt;Ridho Reinanda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khaitan_A/0/1/0/all/0/1&quot;&gt;Abhinav Khaitan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Osborne_M/0/1/0/all/0/1&quot;&gt;Miles Osborne&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stefanoni_G/0/1/0/all/0/1&quot;&gt;Giorgio Stefanoni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kambadur_P/0/1/0/all/0/1&quot;&gt;Prabhanjan Kambadur&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rijke_M/0/1/0/all/0/1&quot;&gt;Maarten de Rijke&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.01265">
<title>Equivalence Between Wasserstein and Value-Aware Loss for Model-based Reinforcement Learning. (arXiv:1806.01265v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1806.01265</link>
<description rdf:parseType="Literal">&lt;p&gt;Learning a generative model is a key component of model-based reinforcement
learning. Though learning a good model in the tabular setting is a simple task,
learning a useful model in the approximate setting is challenging. In this
context, an important question is the loss function used for model learning as
varying the loss function can have a remarkable impact on effectiveness of
planning. Recently Farahmand et al. (2017) proposed a value-aware model
learning (VAML) objective that captures the structure of value function during
model learning. Using tools from Asadi et al. (2018), we show that minimizing
the VAML objective is in fact equivalent to minimizing the Wasserstein metric.
This equivalence improves our understanding of value-aware models, and also
creates a theoretical foundation for applications of Wasserstein in model-based
reinforcement~learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Asadi_K/0/1/0/all/0/1&quot;&gt;Kavosh Asadi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cater_E/0/1/0/all/0/1&quot;&gt;Evan Cater&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Misra_D/0/1/0/all/0/1&quot;&gt;Dipendra Misra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Littman_M/0/1/0/all/0/1&quot;&gt;Michael L. Littman&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.03417">
<title>Learning Continuous Hierarchies in the Lorentz Model of Hyperbolic Geometry. (arXiv:1806.03417v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1806.03417</link>
<description rdf:parseType="Literal">&lt;p&gt;We are concerned with the discovery of hierarchical relationships from
large-scale unstructured similarity scores. For this purpose, we study
different models of hyperbolic space and find that learning embeddings in the
Lorentz model is substantially more efficient than in the Poincar\&apos;e-ball
model. We show that the proposed approach allows us to learn high-quality
embeddings of large taxonomies which yield improvements over Poincar\&apos;e
embeddings, especially in low dimensions. Lastly, we apply our model to
discover hierarchies in two real-world datasets: we show that an embedding in
hyperbolic space can reveal important aspects of a company&apos;s organizational
structure as well as reveal historical relationships between language families.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nickel_M/0/1/0/all/0/1&quot;&gt;Maximilian Nickel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kiela_D/0/1/0/all/0/1&quot;&gt;Douwe Kiela&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06208">
<title>Offline Extraction of Indic Regional Language from Natural Scene Image using Text Segmentation and Deep Convolutional Sequence. (arXiv:1806.06208v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1806.06208</link>
<description rdf:parseType="Literal">&lt;p&gt;Regional language extraction from a natural scene image is always a
challenging proposition due to its dependence on the text information extracted
from Image. Text Extraction on the other hand varies on different lighting
condition, arbitrary orientation, inadequate text information, heavy background
influence over text and change of text appearance. This paper presents a novel
unified method for tackling the above challenges. The proposed work uses an
image correction and segmentation technique on the existing Text Detection
Pipeline an Efficient and Accurate Scene Text Detector (EAST). EAST uses
standard PVAnet architecture to select features and non maximal suppression to
detect text from image. Text recognition is done using combined architecture of
MaxOut convolution neural network (CNN) and Bidirectional long short term
memory (LSTM) network. After recognizing text using the Deep Learning based
approach, the native Languages are translated to English and tokenized using
standard Text Tokenizers. The tokens that very likely represent a location is
used to find the Global Positioning System (GPS) coordinates of the location
and subsequently the regional languages spoken in that location is extracted.
The proposed method is tested on a self generated dataset collected from
Government of India dataset and experimented on Standard Dataset to evaluate
the performance of the proposed technique. Comparative study with a few
state-of-the-art methods on text detection, recognition and extraction of
regional language from images shows that the proposed method outperforms the
existing methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nag_S/0/1/0/all/0/1&quot;&gt;Sauradip Nag&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ganguly_P/0/1/0/all/0/1&quot;&gt;Pallab Kumar Ganguly&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roy_S/0/1/0/all/0/1&quot;&gt;Sumit Roy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jha_S/0/1/0/all/0/1&quot;&gt;Sourab Jha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bose_K/0/1/0/all/0/1&quot;&gt;Krishna Bose&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jha_A/0/1/0/all/0/1&quot;&gt;Abhishek Jha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dasgupta_K/0/1/0/all/0/1&quot;&gt;Kousik Dasgupta&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.10478">
<title>Neural Machine Translation for Query Construction and Composition. (arXiv:1806.10478v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1806.10478</link>
<description rdf:parseType="Literal">&lt;p&gt;Research on question answering with knowledge base has recently seen an
increasing use of deep architectures. In this extended abstract, we study the
application of the neural machine translation paradigm for question parsing. We
employ a sequence-to-sequence model to learn graph patterns in the SPARQL graph
query language and their compositions. Instead of inducing the programs through
question-answer pairs, we expect a semi-supervised approach, where alignments
between questions and queries are built through templates. We argue that the
coverage of language utterances can be expanded using late notable works in
natural language generation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Soru_T/0/1/0/all/0/1&quot;&gt;Tommaso Soru&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Marx_E/0/1/0/all/0/1&quot;&gt;Edgard Marx&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Valdestilhas_A/0/1/0/all/0/1&quot;&gt;Andr&amp;#xe9; Valdestilhas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Esteves_D/0/1/0/all/0/1&quot;&gt;Diego Esteves&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moussallem_D/0/1/0/all/0/1&quot;&gt;Diego Moussallem&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Publio_G/0/1/0/all/0/1&quot;&gt;Gustavo Publio&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.11463">
<title>Bayesian Deep Learning on a Quantum Computer. (arXiv:1806.11463v2 [quant-ph] UPDATED)</title>
<link>http://arxiv.org/abs/1806.11463</link>
<description rdf:parseType="Literal">&lt;p&gt;Bayesian methods in machine learning, such as Gaussian processes, have great
advantages compared to other techniques. In particular, they provide estimates
of the uncertainty associated with a prediction. Extending the Bayesian
approach to deep architectures has remained a major challenge. Recent results
connected deep feedforward neural networks with Gaussian processes, allowing
training without backpropagation. This connection enables us to leverage a
quantum algorithm designed for Gaussian processes and develop a new algorithm
for Bayesian deep learning on quantum computers. The properties of the kernel
matrix in the Gaussian process ensure the efficient execution of the core
component of the protocol, quantum matrix inversion, providing an at least
polynomial speedup over the classical algorithm. Furthermore, we demonstrate
the execution of the algorithm on contemporary quantum computers and analyze
its robustness with respect to realistic noise models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Zhao_Z/0/1/0/all/0/1&quot;&gt;Zhikuan Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Pozas_Kerstjens_A/0/1/0/all/0/1&quot;&gt;Alejandro Pozas-Kerstjens&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Rebentrost_P/0/1/0/all/0/1&quot;&gt;Patrick Rebentrost&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Wittek_P/0/1/0/all/0/1&quot;&gt;Peter Wittek&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.02515">
<title>Blockchain as a Service: An Autonomous, Privacy Preserving, Decentralized Architecture for Deep Learning. (arXiv:1807.02515v1 [cs.CR])</title>
<link>http://arxiv.org/abs/1807.02515</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep learning algorithms have recently gained attention due to their inherent
capabilities and the application opportunities that they provide. Two of the
main reasons for the success of deep learning methods are the availability of
processing power and big data. Both of these two are expensive and rare
commodities that present limitations to the usage and implementation of deep
learning. Decentralization of the processing and data is one of the most
prevalent solutions for these issues. This paper proposes a cooperative
decentralized deep learning architecture. The contributors can train deep
learning models with private data and share them to the cooperative data-driven
applications initiated elsewhere. Shared models are fused together to obtain a
better model. In this work, the contributors can both design their own models
or train the models provided by the initiator. In order to utilize an efficient
decentralized learning algorithm, blockchain technology is incorporated as a
method of creating an incentive-compatible market. In the proposed method,
Ethereum blockchain&apos;s scripting capabilities are employed to devise a
decentralized deep learning mechanism, which provides much higher, collective
processing power and grants access to large amounts of data, which would be
otherwise inaccessible. The technical description of the mechanism is described
and the simulation results are presented.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mendis_G/0/1/0/all/0/1&quot;&gt;Gihan J. Mendis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sabounchi_M/0/1/0/all/0/1&quot;&gt;Moein Sabounchi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wei_J/0/1/0/all/0/1&quot;&gt;Jin Wei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roche_R/0/1/0/all/0/1&quot;&gt;Rigoberto Roche&amp;#x27;&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.02547">
<title>3D Steerable CNNs: Learning Rotationally Equivariant Features in Volumetric Data. (arXiv:1807.02547v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.02547</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a convolutional network that is equivariant to rigid body motions.
The model uses scalar-, vector-, and tensor fields over 3D Euclidean space to
represent data, and equivariant convolutions to map between such
representations. These SE(3)-equivariant convolutions utilize kernels which are
parameterized as a linear combination of a complete steerable kernel basis,
which is derived in this paper. We prove that equivariant convolutions are the
most general equivariant linear maps between fields over R^3. Our experimental
results confirm the effectiveness of 3D Steerable CNNs for the problem of amino
acid propensity prediction and protein structure classification, both of which
have inherent SE(3) symmetry.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Weiler_M/0/1/0/all/0/1&quot;&gt;Maurice Weiler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Geiger_M/0/1/0/all/0/1&quot;&gt;Mario Geiger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Welling_M/0/1/0/all/0/1&quot;&gt;Max Welling&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Boomsma_W/0/1/0/all/0/1&quot;&gt;Wouter Boomsma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cohen_T/0/1/0/all/0/1&quot;&gt;Taco Cohen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.02552">
<title>M-ADDA: Unsupervised Domain Adaptation with Deep Metric Learning. (arXiv:1807.02552v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.02552</link>
<description rdf:parseType="Literal">&lt;p&gt;Unsupervised domain adaptation techniques have been successful for a wide
range of problems where supervised labels are limited. The task is to classify
an unlabeled `target&apos; dataset by leveraging a labeled `source&apos; dataset that
comes from a slightly similar distribution. We propose metric-based adversarial
discriminative domain adaptation (M-ADDA) which performs two main steps. First,
it uses a metric learning approach to train the source model on the source
dataset by optimizing the triplet loss function. This results in clusters where
embeddings of the same label are close to each other and those with different
labels are far from one another. Next, it uses the adversarial approach (as
that used in ADDA \cite{2017arXiv170205464T}) to make the extracted features
from the source and target datasets indistinguishable. Simultaneously, we
optimize a novel loss function that encourages the target dataset&apos;s embeddings
to form clusters. While ADDA and M-ADDA use similar architectures, we show that
M-ADDA performs significantly better on the digits adaptation datasets of MNIST
and USPS. This suggests that using metric-learning for domain adaptation can
lead to large improvements in classification accuracy for the domain adaptation
task. The code is available at \url{https://github.com/IssamLaradji/M-ADDA}.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Laradji_I/0/1/0/all/0/1&quot;&gt;Issam Laradji&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Babanezhad_R/0/1/0/all/0/1&quot;&gt;Reza Babanezhad&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.02567">
<title>Deep Learning for Launching and Mitigating Wireless Jamming Attacks. (arXiv:1807.02567v1 [cs.NI])</title>
<link>http://arxiv.org/abs/1807.02567</link>
<description rdf:parseType="Literal">&lt;p&gt;An adversarial machine learning approach is introduced to launch jamming
attacks on wireless communications and a defense strategy is provided. A
cognitive transmitter uses a pre-trained classifier to predict current channel
status based on recent sensing results and decides whether to transmit or not,
whereas a jammer collects channel status and ACKs to build a deep learning
classifier that reliably predicts whether there will be a successful
transmission next and effectively jams these transmissions. This jamming
approach is shown to reduce the performance of the transmitter much more
severely compared with randomized or sensing-based jamming. Next, a generative
adversarial network (GAN) is developed for the jammer to reduce the time to
collect the training dataset by augmenting it with synthetic samples. Then, a
defense scheme is introduced for the transmitter that prevents the jammer from
building a reliable classifier by deliberately taking a small number of wrong
actions (in form of a causative attack launched against the jammer) when it
accesses the spectrum. The transmitter systematically selects when to take
wrong actions and adapts the level of defense to machine learning-based or
conventional jamming behavior in order to mislead the jammer into making
prediction errors and consequently increase its throughput.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Erpek_T/0/1/0/all/0/1&quot;&gt;Tugba Erpek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sagduyu_Y/0/1/0/all/0/1&quot;&gt;Yalin E. Sagduyu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1&quot;&gt;Yi Shi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.02609">
<title>Anytime Neural Prediction via Slicing Networks Vertically. (arXiv:1807.02609v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.02609</link>
<description rdf:parseType="Literal">&lt;p&gt;The pioneer deep neural networks (DNNs) have emerged to be deeper or wider
for improving their accuracy in various applications of artificial
intelligence. However, DNNs are often too heavy to deploy in practice, and it
is often required to control their architectures dynamically given computing
resource budget, i.e., anytime prediction. While most existing approaches have
focused on training multiple shallow sub-networks jointly, we study training
thin sub-networks instead. To this end, we first build many inclusive thin
sub-networks (of the same depth) under a minor modification of existing
multi-branch DNNs, and found that they can significantly outperform the
state-of-art dense architecture for anytime prediction. This is remarkable due
to their simplicity and effectiveness, but training many thin sub-networks
jointly faces a new challenge on training complexity. To address the issue, we
also propose a novel DNN architecture by forcing a certain sparsity pattern on
multi-branch network parameters, making them train efficiently for the purpose
of anytime prediction. In our experiments on the ImageNet dataset, its
sub-networks have up to $43.3\%$ smaller sizes (FLOPs) compared to those of the
state-of-art anytime model with respect to the same accuracy. Finally, we also
propose an alternative task under the proposed architecture using a
hierarchical taxonomy, which brings a new angle for anytime prediction.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1&quot;&gt;Hankook Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shin_J/0/1/0/all/0/1&quot;&gt;Jinwoo Shin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.02653">
<title>When Work Matters: Transforming Classical Network Structures to Graph CNN. (arXiv:1807.02653v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.02653</link>
<description rdf:parseType="Literal">&lt;p&gt;Numerous pattern recognition applications can be formed as learning from
graph-structured data, including social network, protein-interaction network,
the world wide web data, knowledge graph, etc. While convolutional neural
network (CNN) facilitates great advances in gridded image/video understanding
tasks, very limited attention has been devoted to transform these successful
network structures (including Inception net, Residual net, Dense net, etc.) to
establish convolutional networks on graph, due to its irregularity and
complexity geometric topologies (unordered vertices, unfixed number of adjacent
edges/vertices). In this paper, we aim to give a comprehensive analysis of when
work matters by transforming different classical network structures to graph
CNN, particularly in the basic graph recognition problem. Specifically, we
firstly review the general graph CNN methods, especially in its spectral
filtering operation on the irregular graph data. We then introduce the basic
structures of ResNet, Inception and DenseNet into graph CNN and construct these
network structures on graph, named as G_ResNet, G_Inception, G_DenseNet. In
particular, it seeks to help graph CNNs by shedding light on how these
classical network structures work and providing guidelines for choosing
appropriate graph network frameworks. Finally, we comprehensively evaluate the
performance of these different network structures on several public graph
datasets (including social networks and bioinformatic datasets), and
demonstrate how different network structures work on graph CNN in the graph
recognition task.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1&quot;&gt;Wenting Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1&quot;&gt;Chunyan Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cui_Z/0/1/0/all/0/1&quot;&gt;Zhen Cui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1&quot;&gt;Tong Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1&quot;&gt;Jiatao Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1&quot;&gt;Zhenyu Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1&quot;&gt;Jian Yang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.02787">
<title>Financial Trading as a Game: A Deep Reinforcement Learning Approach. (arXiv:1807.02787v1 [q-fin.TR])</title>
<link>http://arxiv.org/abs/1807.02787</link>
<description rdf:parseType="Literal">&lt;p&gt;An automatic program that generates constant profit from the financial market
is lucrative for every market practitioner. Recent advance in deep
reinforcement learning provides a framework toward end-to-end training of such
trading agent. In this paper, we propose an Markov Decision Process (MDP) model
suitable for the financial trading task and solve it with the state-of-the-art
deep recurrent Q-network (DRQN) algorithm. We propose several modifications to
the existing learning algorithm to make it more suitable under the financial
trading setting, namely 1. We employ a substantially small replay memory (only
a few hundreds in size) compared to ones used in modern deep reinforcement
learning algorithms (often millions in size.) 2. We develop an action
augmentation technique to mitigate the need for random exploration by providing
extra feedback signals for all actions to the agent. This enables us to use
greedy policy over the course of learning and shows strong empirical
performance compared to more commonly used epsilon-greedy exploration. However,
this technique is specific to financial trading under a few market assumptions.
3. We sample a longer sequence for recurrent neural network training. A side
product of this mechanism is that we can now train the agent for every T steps.
This greatly reduces training time since the overall computation is down by a
factor of T. We combine all of the above into a complete online learning
algorithm and validate our approach on the spot foreign exchange market.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-fin/1/au:+Huang_C/0/1/0/all/0/1&quot;&gt;Chien Yi Huang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.02919">
<title>Domain2Vec: Deep Domain Generalization. (arXiv:1807.02919v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.02919</link>
<description rdf:parseType="Literal">&lt;p&gt;We address the problem of domain generalization where a decision function is
learned from the data of several related domains, and the goal is to apply it
on an unseen domain successfully. It is assumed that there is plenty of labeled
data available in source domains (also called as training domain), but no
labeled data is available for the unseen domain (also called a target domain or
test domain). We propose a novel neural network architecture, Domain2Vec (D2V)
that learns domain-specific embedding and then uses this embedding to
generalize the learning across related domains. The proposed algorithm, D2V
extends the idea of distribution regression and kernelized domain
generalization to the neural networks setting. We propose a neural network
architecture to learn domain-specific embedding and then use this embedding
along with the data point specific features to label it. We show the
effectiveness of the architecture by accurately estimating domain to domain
similarity. We evaluate our algorithm against standard domain generalization
datasets for image classification and outperform other state of the art
algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deshmukh_A/0/1/0/all/0/1&quot;&gt;Aniket Anand Deshmukh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bansal_A/0/1/0/all/0/1&quot;&gt;Ankit Bansal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rastogi_A/0/1/0/all/0/1&quot;&gt;Akash Rastogi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.02999">
<title>Decreasing the size of the Restricted Boltzmann machine. (arXiv:1807.02999v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.02999</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a method to decrease the number of hidden units of the restricted
Boltzmann machine while avoiding decrease of the performance measured by the
Kullback-Leibler divergence. Then, we demonstrate our algorithm by using
numerical simulations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saito_Y/0/1/0/all/0/1&quot;&gt;Yohei Saito&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kato_T/0/1/0/all/0/1&quot;&gt;Takuya Kato&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.03046">
<title>Deep Learning for Singing Processing: Achievements, Challenges and Impact on Singers and Listeners. (arXiv:1807.03046v1 [cs.SD])</title>
<link>http://arxiv.org/abs/1807.03046</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper summarizes some recent advances on a set of tasks related to the
processing of singing using state-of-the-art deep learning techniques. We
discuss their achievements in terms of accuracy and sound quality, and the
current challenges, such as availability of data and computing resources. We
also discuss the impact that these advances do and will have on listeners and
singers when they are integrated in commercial applications.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gomez_E/0/1/0/all/0/1&quot;&gt;Emilia G&amp;#xf3;mez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Blaauw_M/0/1/0/all/0/1&quot;&gt;Merlijn Blaauw&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bonada_J/0/1/0/all/0/1&quot;&gt;Jordi Bonada&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chandna_P/0/1/0/all/0/1&quot;&gt;Pritish Chandna&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cuesta_H/0/1/0/all/0/1&quot;&gt;Helena Cuesta&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.03133">
<title>Outfit Generation and Style Extraction via Bidirectional LSTM and Autoencoder. (arXiv:1807.03133v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1807.03133</link>
<description rdf:parseType="Literal">&lt;p&gt;When creating an outfit, style is a criterion in selecting each fashion item.
This means that style can be regarded as a feature of the overall outfit.
However, in various previous studies on outfit generation, there have been few
methods focusing on global information obtained from an outfit. To address this
deficiency, we have incorporated an unsupervised style extraction module into a
model to learn outfits. Using the style information of an outfit as a whole,
the proposed model succeeded in generating outfits more flexibly without
requiring additional information. Moreover, the style information extracted by
the proposed model is easy to interpret. The proposed model was evaluated on
two human-generated outfit datasets. In a fashion item prediction task (missing
prediction task), the proposed model outperformed a baseline method. In a style
extraction task, the proposed model extracted some easily distinguishable
styles. In an outfit generation task, the proposed model generated an outfit
while controlling its styles. This capability allows us to generate fashionable
outfits according to various preferences.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nakamura_T/0/1/0/all/0/1&quot;&gt;Takuma Nakamura&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goto_R/0/1/0/all/0/1&quot;&gt;Ryosuke Goto&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.03142">
<title>Faster Bounding Box Annotation for Object Detection in Indoor Scenes. (arXiv:1807.03142v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1807.03142</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper proposes an approach for rapid bounding box annotation for object
detection datasets. The procedure consists of two stages: The first step is to
annotate a part of the dataset manually, and the second step proposes
annotations for the remaining samples using a model trained with the first
stage annotations. We experimentally study which first/second stage split
minimizes to total workload. In addition, we introduce a new fully labeled
object detection dataset collected from indoor scenes. Compared to other indoor
datasets, our collection has more class categories, different backgrounds,
lighting conditions, occlusion and high intra-class differences. We train deep
learning based object detectors with a number of state-of-the-art models and
compare them in terms of speed and accuracy. The fully annotated dataset is
released freely available for the research community.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Adhikari_B/0/1/0/all/0/1&quot;&gt;Bishwo Adhikari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peltomaki_J/0/1/0/all/0/1&quot;&gt;Jukka Peltom&amp;#xe4;ki&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Puura_J/0/1/0/all/0/1&quot;&gt;Jussi Puura&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huttunen_H/0/1/0/all/0/1&quot;&gt;Heikki Huttunen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.03167">
<title>Data Augmentation for Detection of Architectural Distortion in Digital Mammography using Deep Learning Approach. (arXiv:1807.03167v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1807.03167</link>
<description rdf:parseType="Literal">&lt;p&gt;Early detection of breast cancer can increase treatment efficiency.
Architectural Distortion (AD) is a very subtle contraction of the breast tissue
and may represent the earliest sign of cancer. Since it is very likely to be
unnoticed by radiologists, several approaches have been proposed over the years
but none using deep learning techniques. To train a Convolutional Neural
Network (CNN), which is a deep neural architecture, is necessary a huge amount
of data. To overcome this problem, this paper proposes a data augmentation
approach applied to clinical image dataset to properly train a CNN. Results
using receiver operating characteristic analysis showed that with a very
limited dataset we could train a CNN to detect AD in digital mammography with
area under the curve (AUC = 0.74).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Costa_A/0/1/0/all/0/1&quot;&gt;Arthur C. Costa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oliveira_H/0/1/0/all/0/1&quot;&gt;Helder C. R. Oliveira&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Catani_J/0/1/0/all/0/1&quot;&gt;Juliana H. Catani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barros_N/0/1/0/all/0/1&quot;&gt;Nestor de Barros&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Melo_C/0/1/0/all/0/1&quot;&gt;Carlos F. E. Melo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vieira_M/0/1/0/all/0/1&quot;&gt;Marcelo A. C. Vieira&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.03179">
<title>YouTube for Patient Education: A Deep Learning Approach for Understanding Medical Knowledge from User-Generated Videos. (arXiv:1807.03179v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1807.03179</link>
<description rdf:parseType="Literal">&lt;p&gt;YouTube presents an unprecedented opportunity to explore how machine learning
methods can improve healthcare information dissemination. We propose an
interdisciplinary lens that synthesizes machine learning methods with
healthcare informatics themes to address the critical issue of developing a
scalable algorithmic solution to evaluate videos from a health literacy and
patient education perspective. We develop a deep learning method to understand
the level of medical knowledge encoded in YouTube videos. Preliminary results
suggest that we can extract medical knowledge from YouTube videos and classify
videos according to the embedded knowledge with satisfying performance. Deep
learning methods show great promise in knowledge extraction, natural language
understanding, and image classification, especially in an era of
patient-centric care and precision medicine.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1&quot;&gt;Xiao Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1&quot;&gt;Bin Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Susarla_A/0/1/0/all/0/1&quot;&gt;Anjana Susarla&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Padman_R/0/1/0/all/0/1&quot;&gt;Rema Padman&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.03247">
<title>An Intriguing Failing of Convolutional Neural Networks and the CoordConv Solution. (arXiv:1807.03247v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1807.03247</link>
<description rdf:parseType="Literal">&lt;p&gt;Few ideas have enjoyed as large an impact on deep learning as convolution.
For any problem involving pixels or spatial representations, common intuition
holds that convolutional neural networks may be appropriate. In this paper we
show a striking counterexample to this intuition via the seemingly trivial
coordinate transform problem, which simply requires learning a mapping between
coordinates in (x,y) Cartesian space and one-hot pixel space. Although
convolutional networks would seem appropriate for this task, we show that they
fail spectacularly. We demonstrate and carefully analyze the failure first on a
toy problem, at which point a simple fix becomes obvious. We call this solution
CoordConv, which works by giving convolution access to its own input
coordinates through the use of extra coordinate channels. Without sacrificing
the computational and parametric efficiency of ordinary convolution, CoordConv
allows networks to learn either perfect translation invariance or varying
degrees of translation dependence, as required by the task. CoordConv solves
the coordinate transform problem with perfect generalization and 150 times
faster with 10--100 times fewer parameters than convolution. This stark
contrast raises the question: to what extent has this inability of convolution
persisted insidiously inside other tasks, subtly hampering performance from
within? A complete answer to this question will require further investigation,
but we show preliminary evidence that swapping convolution for CoordConv can
improve models on a diverse set of tasks. Using CoordConv in a GAN produced
less mode collapse as the transform between high-level spatial latents and
pixels becomes easier to learn. A Faster R-CNN detection model trained on MNIST
detection showed 24% better IOU when using CoordConv, and in the RL domain
agents playing Atari games benefit significantly from the use of CoordConv
layers.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_R/0/1/0/all/0/1&quot;&gt;Rosanne Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lehman_J/0/1/0/all/0/1&quot;&gt;Joel Lehman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Molino_P/0/1/0/all/0/1&quot;&gt;Piero Molino&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Such_F/0/1/0/all/0/1&quot;&gt;Felipe Petroski Such&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Frank_E/0/1/0/all/0/1&quot;&gt;Eric Frank&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sergeev_A/0/1/0/all/0/1&quot;&gt;Alex Sergeev&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yosinski_J/0/1/0/all/0/1&quot;&gt;Jason Yosinski&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.03257">
<title>Data Efficient Lithography Modeling with Transfer Learning and Active Data Selection. (arXiv:1807.03257v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.03257</link>
<description rdf:parseType="Literal">&lt;p&gt;Lithography simulation is one of the key steps in physical verification,
enabled by the substantial optical and resist models. A resist model bridges
the aerial image simulation to printed patterns. While the effectiveness of
learning-based solutions for resist modeling has been demonstrated, they are
considerably data-demanding. Meanwhile, a set of manufactured data for a
specific lithography configuration is only valid for the training of one single
model, indicating low data efficiency. Due to the complexity of the
manufacturing process, obtaining enough data for acceptable accuracy becomes
very expensive in terms of both time and cost, especially during the evolution
of technology generations when the design space is intensively explored. In
this work, we propose a new resist modeling framework for contact layers,
utilizing existing data from old technology nodes and active selection of data
in a target technology node, to reduce the amount of data required from the
target lithography configuration. Our framework based on transfer learning and
active learning techniques is effective within a competitive range of accuracy,
i.e., 3-10X reduction on the amount of training data with comparable accuracy
to the state-of-the-art learning approach.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1&quot;&gt;Yibo Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1&quot;&gt;Meng Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Watanabe_Y/0/1/0/all/0/1&quot;&gt;Yuki Watanabe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kimura_T/0/1/0/all/0/1&quot;&gt;Taiki Kimura&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Matsunawa_T/0/1/0/all/0/1&quot;&gt;Tetsuaki Matsunawa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nojima_S/0/1/0/all/0/1&quot;&gt;Shigeki Nojima&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pan_D/0/1/0/all/0/1&quot;&gt;David Z. Pan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.07107">
<title>Adversarial Examples: Attacks and Defenses for Deep Learning. (arXiv:1712.07107v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1712.07107</link>
<description rdf:parseType="Literal">&lt;p&gt;With rapid progress and significant successes in a wide spectrum of
applications, deep learning is being applied in many safety-critical
environments. However, deep neural networks have been recently found vulnerable
to well-designed input samples, called adversarial examples. Adversarial
examples are imperceptible to human but can easily fool deep neural networks in
the testing/deploying stage. The vulnerability to adversarial examples becomes
one of the major risks for applying deep neural networks in safety-critical
environments. Therefore, attacks and defenses on adversarial examples draw
great attention. In this paper, we review recent findings on adversarial
examples for deep neural networks, summarize the methods for generating
adversarial examples, and propose a taxonomy of these methods. Under the
taxonomy, applications for adversarial examples are investigated. We further
elaborate on countermeasures for adversarial examples and explore the
challenges and the potential solutions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yuan_X/0/1/0/all/0/1&quot;&gt;Xiaoyong Yuan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_P/0/1/0/all/0/1&quot;&gt;Pan He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_Q/0/1/0/all/0/1&quot;&gt;Qile Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xiaolin Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06552">
<title>Are Generative Classifiers More Robust to Adversarial Attacks?. (arXiv:1802.06552v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1802.06552</link>
<description rdf:parseType="Literal">&lt;p&gt;There is a rising interest in studying the robustness of deep neural network
classifiers against adversaries, with both advanced attack and defence
techniques being actively developed. However, most recent work focuses on
discriminative classifiers, which only model the conditional distribution of
the labels given the inputs. In this paper we propose the deep Bayes
classifier, which improves classical naive Bayes with conditional deep
generative models. We further develop detection methods for adversarial
examples, which reject inputs that have negative log-likelihood under the
generative model exceeding a threshold pre-specified using training data.
Experimental results suggest that deep Bayes classifiers are more robust than
deep discriminative classifiers, and the proposed detection methods achieve
high detection rates against many recently proposed attacks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yingzhen Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bradshaw_J/0/1/0/all/0/1&quot;&gt;John Bradshaw&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sharma_Y/0/1/0/all/0/1&quot;&gt;Yash Sharma&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.07569">
<title>Continual Lifelong Learning with Neural Networks: A Review. (arXiv:1802.07569v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1802.07569</link>
<description rdf:parseType="Literal">&lt;p&gt;Humans and animals have the ability to continually acquire and fine-tune
knowledge throughout their lifespan. This ability, referred to as lifelong
learning, is mediated by a rich set of neurocognitive mechanisms that together
contribute to the development and specialization of our sensorimotor skills as
well as to the long-term memory consolidation and retrieval without
catastrophic forgetting. Consequently, lifelong learning capabilities are
crucial for computational learning systems and autonomous agents interacting in
the real world and processing continuous streams of information. However,
lifelong learning remains a long-standing challenge for machine learning and
neural network models since the continual acquisition of incrementally
available information from non-stationary data distributions generally leads to
catastrophic forgetting or interference. This limitation represents a major
drawback also for state-of-the-art deep and shallow neural network models that
typically learn representations from stationary batches of training data, thus
without accounting for situations in which the number of tasks is not known a
priori and the information becomes incrementally available over time. In this
review, we critically summarize the main challenges linked to lifelong learning
for artificial learning systems and compare existing neural network approaches
that alleviate, to different extents, catastrophic forgetting. Although
significant advances have been made in domain-specific learning with neural
networks, extensive research efforts are required for the development of robust
lifelong learning on autonomous agents and robots. We discuss well-established
and emerging research motivated by lifelong learning factors in biological
systems such as neurosynaptic plasticity, multi-task transfer learning,
intrinsically motivated exploration, and crossmodal learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Parisi_G/0/1/0/all/0/1&quot;&gt;German I. Parisi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kemker_R/0/1/0/all/0/1&quot;&gt;Ronald Kemker&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Part_J/0/1/0/all/0/1&quot;&gt;Jose L. Part&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kanan_C/0/1/0/all/0/1&quot;&gt;Christopher Kanan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wermter_S/0/1/0/all/0/1&quot;&gt;Stefan Wermter&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09031">
<title>Functional Gradient Boosting based on Residual Network Perception. (arXiv:1802.09031v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1802.09031</link>
<description rdf:parseType="Literal">&lt;p&gt;Residual Networks (ResNets) have become state-of-the-art models in deep
learning and several theoretical studies have been devoted to understanding why
ResNet works so well. One attractive viewpoint on ResNet is that it is
optimizing the risk in a functional space by combining an ensemble of effective
features. In this paper, we adopt this viewpoint to construct a new gradient
boosting method, which is known to be very powerful in data analysis. To do so,
we formalize the gradient boosting perspective of ResNet mathematically using
the notion of functional gradients and propose a new method called ResFGB for
classification tasks by leveraging ResNet perception. Two types of
generalization guarantees are provided from the optimization perspective: one
is the margin bound and the other is the expected risk bound by the
sample-splitting technique. Experimental results show superior performance of
the proposed method over state-of-the-art methods such as LightGBM.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Nitanda_A/0/1/0/all/0/1&quot;&gt;Atsushi Nitanda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Suzuki_T/0/1/0/all/0/1&quot;&gt;Taiji Suzuki&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.07551">
<title>Meta Reinforcement Learning with Latent Variable Gaussian Processes. (arXiv:1803.07551v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1803.07551</link>
<description rdf:parseType="Literal">&lt;p&gt;Learning from small data sets is critical in many practical applications
where data collection is time consuming or expensive, e.g., robotics, animal
experiments or drug design. Meta learning is one way to increase the data
efficiency of learning algorithms by generalizing learned concepts from a set
of training tasks to unseen, but related, tasks. Often, this relationship
between tasks is hard coded or relies in some other way on human expertise. In
this paper, we frame meta learning as a hierarchical latent variable model and
infer the relationship between tasks automatically from data. We apply our
framework in a model-based reinforcement learning setting and show that our
meta-learning model effectively generalizes to novel tasks by identifying how
new tasks relate to prior ones from minimal data. This results in up to a 60%
reduction in the average interaction time needed to solve tasks compared to
strong baselines.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Saemundsson_S/0/1/0/all/0/1&quot;&gt;Steind&amp;#xf3;r S&amp;#xe6;mundsson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hofmann_K/0/1/0/all/0/1&quot;&gt;Katja Hofmann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Deisenroth_M/0/1/0/all/0/1&quot;&gt;Marc Peter Deisenroth&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05514">
<title>The Exact Equivalence of Distance and Kernel Methods for Hypothesis Testing. (arXiv:1806.05514v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1806.05514</link>
<description rdf:parseType="Literal">&lt;p&gt;Distance-based methods, also called &quot;energy statistics&quot;, are leading methods
for two-sample and independence tests from the statistics community. Kernel
methods, developed from &quot;kernel mean embeddings&quot;, are leading methods for
two-sample and independence tests from the machine learning community. Previous
works demonstrated the equivalence of distance and kernel methods only at the
population level, for each kind of test, requiring an embedding theory of
kernels. We propose a simple, bijective transformation between semimetrics and
nondegenerate kernels. We prove that for finite samples, two-sample tests are
special cases of independence tests, and the distance-based statistic is
equivalent to the kernel-based statistic, including the biased, unbiased, and
normalized versions. In other words, upon setting the kernel or metric to be
bijective of each other, running any of the four algorithms will yield the
exact same answer up to numerical precision. This deepens and unifies our
understanding of interpoint comparison based methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Shen_C/0/1/0/all/0/1&quot;&gt;Cencheng Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Vogelstein_J/0/1/0/all/0/1&quot;&gt;Joshua T. Vogelstein&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.00560">
<title>Weight-importance sparse training in keyword spotting. (arXiv:1807.00560v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1807.00560</link>
<description rdf:parseType="Literal">&lt;p&gt;Large size models are implemented in recently ASR system to deal with complex
speech recognition problems. The num- ber of parameters in these models makes
them hard to deploy, especially on some resource-short devices such as car
tablet. Besides this, at most of time, ASR system is used to deal with
real-time problem such as keyword spotting (KWS). It is contradictory to the
fact that large model requires long com- putation time. To deal with this
problem, we apply some sparse algo- rithms to reduces number of parameters in
some widely used models, Deep Neural Network (DNN) KWS, which requires real
short computation time. We can prune more than 90 % even 95% of parameters in
the model with tiny effect decline. And the sparse model performs better than
baseline models which has same order number of parameters. Besides this, sparse
algorithm can lead us to find rational model size au- tomatically for certain
problem without concerning choosing an original model size.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xue_S/0/1/0/all/0/1&quot;&gt;Sihao Xue&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ying_Z/0/1/0/all/0/1&quot;&gt;Zhenyi Ying&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mo_F/0/1/0/all/0/1&quot;&gt;Fan Mo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1&quot;&gt;Min Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1&quot;&gt;Jue Sun&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.01082">
<title>Domain Aware Markov Logic Networks. (arXiv:1807.01082v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1807.01082</link>
<description rdf:parseType="Literal">&lt;p&gt;Combining logic and probability has been a long stand- ing goal of AI
research. Markov Logic Networks (MLNs) achieve this by attaching weights to
formulas in first-order logic, and can be seen as templates for constructing
features for ground Markov networks. Most techniques for learning weights of
MLNs are domain-size agnostic, i.e., the size of the domain is not explicitly
taken into account while learn- ing the parameters of the model. This often
results in ex- treme probabilities when testing on domain sizes different from
those seen during training. In this paper, we propose Domain Aware Markov logic
Networks (DA-MLNs) which present a principled solution to this problem. While
defin- ing the ground network distribution, DA-MLNs divide the ground feature
weight by a scaling factor which is a function of the number of connections the
ground atoms appearing in the feature are involved in. We show that standard
MLNs fall out as a special case of our formalism when this func- tion evaluates
to a constant equal to 1. Experiments on the benchmark Friends &amp;amp; Smokers domain
show that our ap- proach results in significantly higher accuracies compared to
existing methods when testing on domains whose sizes different from those seen
during training.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mittal_H/0/1/0/all/0/1&quot;&gt;Happy Mittal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bhardwaj_A/0/1/0/all/0/1&quot;&gt;Ayush Bhardwaj&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gogate_V/0/1/0/all/0/1&quot;&gt;Vibhav Gogate&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singla_P/0/1/0/all/0/1&quot;&gt;Parag Singla&lt;/a&gt;</dc:creator>
</item></rdf:RDF>