<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Good papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Good Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-05-08T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.02599"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.02686"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.02716"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.02983"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.03108"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.03138"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.03162"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1611.04363"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.04486"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.05348"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.07759"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.10938"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.01452"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.01890"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.02777"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.02788"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.02830"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.02855"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.02917"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.02958"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.06309"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.01553"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1805.02599">
<title>Superconducting Optoelectronic Neurons II: Receiver Circuits. (arXiv:1805.02599v2 [q-bio.NC] UPDATED)</title>
<link>http://arxiv.org/abs/1805.02599</link>
<description rdf:parseType="Literal">&lt;p&gt;Circuits using superconducting single-photon detectors and Josephson
junctions to perform signal reception, synaptic weighting, and integration are
investigated. The circuits convert photon-detection events into flux quanta,
the number of which is determined by the synaptic weight. The current from many
synaptic connections is inductively coupled to a superconducting loop that
implements the neuronal threshold operation. Designs are presented for synapses
and neurons that perform integration as well as detect coincidence events for
temporal coding. Both excitatory and inhibitory connections are demonstrated.
It is shown that a neuron with a single integration loop can receive input from
1000 such synaptic connections, and neurons of similar design could employ many
loops for dendritic processing.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Shainline_J/0/1/0/all/0/1&quot;&gt;Jeffrey M. Shainline&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Buckley_S/0/1/0/all/0/1&quot;&gt;Sonia M. Buckley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+McCaughan_A/0/1/0/all/0/1&quot;&gt;Adam N. McCaughan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Castellanos_Beltran_M/0/1/0/all/0/1&quot;&gt;Manuel Castellanos-Beltran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Donnelly_C/0/1/0/all/0/1&quot;&gt;Christine A. Donnelly&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Schneider_M/0/1/0/all/0/1&quot;&gt;Michael L. Schneider&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Mirin_R/0/1/0/all/0/1&quot;&gt;Richard P. Mirin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Nam_S/0/1/0/all/0/1&quot;&gt;Sae Woo Nam&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.02686">
<title>Holarchic Structures for Decentralized Deep Learning - A Performance Analysis. (arXiv:1805.02686v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.02686</link>
<description rdf:parseType="Literal">&lt;p&gt;Structure plays a key role in learning performance. In centralized
computational systems, hyperparameter optimization and regularization
techniques such as dropout are computational means to enhance learning
performance by adjusting the deep hierarchical structure. However, in
decentralized deep learning by the Internet of Things, the structure is an
actual network of autonomous interconnected devices such as smart phones that
interact via complex network protocols. Adjustments in the learning structure
are a challenge. Uncertainties such as network latency, node and link failures
or even bottlenecks by limited processing capacity and energy availability can
significantly downgrade learning performance. Network self-organization and
self-management is complex, while it requires additional computational and
network resources that hinder the feasibility of decentralized deep learning.
In contrast, this paper introduces reusable holarchic learning structures for
exploring, mitigating and boosting learning performance in distributed
environments with uncertainties. A large-scale performance analysis with 864000
experiments fed with synthetic and real-world data from smart grid and smart
city pilot projects confirm the cost-effectiveness of holarchic structures for
decentralized deep learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pournaras_E/0/1/0/all/0/1&quot;&gt;Evangelos Pournaras&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yadhunathan_S/0/1/0/all/0/1&quot;&gt;Srivatsan Yadhunathan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Diaconescu_A/0/1/0/all/0/1&quot;&gt;Ada Diaconescu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.02716">
<title>Real-time regression analysis with deep convolutional neural networks. (arXiv:1805.02716v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.02716</link>
<description rdf:parseType="Literal">&lt;p&gt;We discuss the development of novel deep learning algorithms to enable
real-time regression analysis for time series data. We showcase the application
of this new method with a timely case study, and then discuss the applicability
of this approach to tackle similar challenges across science domains.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huerta_E/0/1/0/all/0/1&quot;&gt;E. A. Huerta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+George_D/0/1/0/all/0/1&quot;&gt;Daniel George&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1&quot;&gt;Zhizhen Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Allen_G/0/1/0/all/0/1&quot;&gt;Gabrielle Allen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.02983">
<title>Augmenting Recurrent Neural Networks with High-Order User-Contextual Preference for Session-Based Recommendation. (arXiv:1805.02983v1 [cs.IR])</title>
<link>http://arxiv.org/abs/1805.02983</link>
<description rdf:parseType="Literal">&lt;p&gt;The recent adoption of recurrent neural networks (RNNs) for session modeling
has yielded substantial performance gains compared to previous approaches. In
terms of context-aware session modeling, however, the existing RNN-based models
are limited in that they are not designed to explicitly model rich static
user-side contexts (e.g., age, gender, location). Therefore, in this paper, we
explore the utility of explicit user-side context modeling for RNN session
models. Specifically, we propose an augmented RNN (ARNN) model that extracts
high-order user-contextual preference using the product-based neural network
(PNN) in order to augment any existing RNN session model. Evaluation results
show that our proposed model outperforms the baseline RNN session model by a
large margin when rich user-side contexts are available.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_Y/0/1/0/all/0/1&quot;&gt;Younghun Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1&quot;&gt;Jae-Gil Lee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.03108">
<title>FASK with Interventional Knowledge Recovers Edges from the Sachs Model. (arXiv:1805.03108v1 [q-bio.MN])</title>
<link>http://arxiv.org/abs/1805.03108</link>
<description rdf:parseType="Literal">&lt;p&gt;We report a procedure that, in one step from continuous data with minimal
preparation, recovers the graph found by Sachs et al. \cite{sachs2005causal},
with only a few edges different. The algorithm, Fast Adjacency Skewness (FASK),
relies on a mixture of linear reasoning and reasoning from the skewness of
variables; the Sachs data is a good candidate for this procedure since the
skewness of the variables is quite pronounced. We review the ground truth model
from Sachs et al. as well as some of the fluctuations seen in the protein
abundances in the system, give the Sachs model and the FASK model, and perform
a detailed comparison. Some variation in hyper-parameters is explored, though
the main result uses values at or near the defaults learned from work modeling
fMRI data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Ramsey_J/0/1/0/all/0/1&quot;&gt;Joseph Ramsey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Andrews_B/0/1/0/all/0/1&quot;&gt;Bryan Andrews&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.03138">
<title>A review of neuro-fuzzy systems based on intelligent control. (arXiv:1805.03138v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1805.03138</link>
<description rdf:parseType="Literal">&lt;p&gt;The system&apos;s ability to adapt and self-organize are two key factors when it
comes to how well the system can survive the changes to the environment and the
plant they work within. Intelligent control improves these two factors in
controllers. Considering the increasing complexity of dynamic systems along
with their need for feedback controls, using more complicated controls has
become necessary and intelligent control can be a suitable response to this
necessity. This paper briefly describes the structure of intelligent control
and provides a review on fuzzy logic and neural networks which are some of the
base methods for intelligent control. The different aspects of these two
methods are then compared together and an example of a combined method is
presented.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zahedi_F/0/1/0/all/0/1&quot;&gt;Fatemeh Zahedi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zahedi_Z/0/1/0/all/0/1&quot;&gt;Zahra Zahedi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.03162">
<title>Polite Dialogue Generation Without Parallel Data. (arXiv:1805.03162v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1805.03162</link>
<description rdf:parseType="Literal">&lt;p&gt;Stylistic dialogue response generation, with valuable applications in
personality-based conversational agents, is a challenging task because the
response needs to be fluent, contextually-relevant, as well as
paralinguistically accurate. Moreover, parallel datasets for
regular-to-stylistic pairs are usually unavailable. We present three
weakly-supervised models that can generate diverse polite (or rude) dialogue
responses without parallel data. Our late fusion model (Fusion) merges the
decoder of an encoder-attention-decoder dialogue model with a language model
trained on stand-alone polite utterances. Our label-fine-tuning (LFT) model
prepends to each source sequence a politeness-score scaled label (predicted by
our state-of-the-art politeness classifier) during training, and at test time
is able to generate polite, neutral, and rude responses by simply scaling the
label embedding by the corresponding score. Our reinforcement learning model
(Polite-RL) encourages politeness generation by assigning rewards proportional
to the politeness classifier score of the sampled response. We also present two
retrieval-based polite dialogue model baselines. Human evaluation validates
that while the Fusion and the retrieval-based models achieve politeness with
poorer context-relevance, the LFT and Polite-RL models can produce
significantly more polite responses without sacrificing dialogue quality.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Niu_T/0/1/0/all/0/1&quot;&gt;Tong Niu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bansal_M/0/1/0/all/0/1&quot;&gt;Mohit Bansal&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1611.04363">
<title>Weakly Learning to Match Experts in Online Community. (arXiv:1611.04363v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1611.04363</link>
<description rdf:parseType="Literal">&lt;p&gt;In online question-and-answer (QA) websites like Quora, one central issue is
to find (invite) users who are able to provide answers to a given question and
at the same time would be unlikely to say &quot;no&quot; to the invitation. The challenge
is how to trade off the matching degree between users&apos; expertise and the
question topic, and the likelihood of positive response from the invited users.
In this paper, we formally formulate the problem and develop a weakly
supervised factor graph (WeakFG) model to address the problem. The model
explicitly captures expertise matching degree between questions and users. To
model the likelihood that an invited user is willing to answer a specific
question, we incorporate a set of correlations based on social identity theory
into the WeakFG model. We use two different genres of datasets: QA-Expert and
Paper-Reviewer, to validate the proposed model. Our experimental results show
that the proposed model can significantly outperform (+1.5-10.7% by MAP) the
state-of-the-art algorithms for matching users (experts) with community
questions. We have also developed an online system to further demonstrate the
advantages of the proposed method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qian_Y/0/1/0/all/0/1&quot;&gt;Yujie Qian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1&quot;&gt;Jie Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_K/0/1/0/all/0/1&quot;&gt;Kan Wu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.04486">
<title>Can Computers Create Art?. (arXiv:1801.04486v6 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1801.04486</link>
<description rdf:parseType="Literal">&lt;p&gt;This essay discusses whether computers, using Artificial Intelligence (AI),
could create art. First, the history of technologies that automated aspects of
art is surveyed, including photography and animation. In each case, there were
initial fears and denial of the technology, followed by a blossoming of new
creative and professional opportunities for artists. The current hype and
reality of Artificial Intelligence (AI) tools for art making is then discussed,
together with predictions about how AI tools will be used. It is then
speculated about whether it could ever happen that AI systems could be credited
with authorship of artwork. It is theorized that art is something created by
social agents, and so computers cannot be credited with authorship of art in
our current understanding. A few ways that this could change are also
hypothesized.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hertzmann_A/0/1/0/all/0/1&quot;&gt;Aaron Hertzmann&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.05348">
<title>Artificial Intelligence for Wireless Connectivity and Security of Cellular-Connected UAVs. (arXiv:1804.05348v2 [cs.IT] UPDATED)</title>
<link>http://arxiv.org/abs/1804.05348</link>
<description rdf:parseType="Literal">&lt;p&gt;Cellular-connected unmanned aerial vehicles (UAVs) will inevitably be
integrated into future cellular networks as new aerial mobile users. Providing
cellular connectivity to UAVs will enable a myriad of applications ranging from
online video streaming to medical delivery. However, to enable a reliable
wireless connectivity for the UAVs as well as a secure operation, various
challenges need to be addressed such as interference management, mobility
management and handover, cyber-physical attacks, and authentication. In this
paper, the goal is to expose the wireless and security challenges that arise in
the context of UAV-based delivery systems, UAV-based real-time multimedia
streaming, and UAV-enabled intelligent transportation systems. To address such
challenges, artificial neural network (ANN) based solution schemes are
introduced. The introduced approaches enable the UAVs to adaptively exploit the
wireless system resources while guaranteeing a secure operation, in real-time.
Preliminary simulation results show the benefits of the introduced solutions
for each of the aforementioned cellular-connected UAV application use case.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Challita_U/0/1/0/all/0/1&quot;&gt;Ursula Challita&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ferdowsi_A/0/1/0/all/0/1&quot;&gt;Aidin Ferdowsi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1&quot;&gt;Mingzhe Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saad_W/0/1/0/all/0/1&quot;&gt;Walid Saad&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.07759">
<title>A Self-paced Regularization Framework for Partial-Label Learning. (arXiv:1804.07759v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1804.07759</link>
<description rdf:parseType="Literal">&lt;p&gt;Partial label learning (PLL) aims to solve the problem where each training
instance is associated with a set of candidate labels, one of which is the
correct label. Most PLL algorithms try to disambiguate the candidate label set,
by either simply treating each candidate label equally or iteratively
identifying the true label. Nonetheless, existing algorithms usually treat all
labels and instances equally, and the complexities of both labels and instances
are not taken into consideration during the learning stage. Inspired by the
successful application of self-paced learning strategy in machine learning
field, we integrate the self-paced regime into the partial label learning
framework and propose a novel Self-Paced Partial-Label Learning (SP-PLL)
algorithm, which could control the learning process to alleviate the problem by
ranking the priorities of the training examples together with their candidate
labels during each learning iteration. Extensive experiments and comparisons
with other baseline methods demonstrate the effectiveness and robustness of the
proposed method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lyu_G/0/1/0/all/0/1&quot;&gt;Gengyu Lyu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feng_S/0/1/0/all/0/1&quot;&gt;Songhe Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lang_C/0/1/0/all/0/1&quot;&gt;Congyang Lang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.10938">
<title>Deep Affect Prediction in-the-wild: Aff-Wild Database and Challenge, Deep Architectures, and Beyond. (arXiv:1804.10938v3 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1804.10938</link>
<description rdf:parseType="Literal">&lt;p&gt;Automatic understanding of human affect using visual signals is of great
importance in everyday human-machine interactions. Appraising human emotional
states, behaviors and reactions displayed in real-world settings, can be
accomplished using latent continuous dimensions (e.g., the circumplex model of
affect). Valence (i.e., how positive or negative is an emotion) and arousal
(i.e., power of the activation of the emotion) constitute the most popular and
effective affect representations. Nevertheless, the majority of collected
datasets this far, although containing naturalistic emotional states, have been
captured in highly controlled recording conditions. In this paper, we introduce
the Aff-Wild benchmark for training and evaluating affect recognition
algorithms. We also report on the results of the First Affect-in-the-wild
Challenge (Aff-Wild Challenge) that was recently organized on the Aff-Wild
database, and was the first ever challenge on the estimation of valence and
arousal in-the-wild. Furthermore, we design and extensively train an end-to-end
deep neural architecture which performs prediction of continuous emotion
dimensions based on visual cues. The proposed deep learning architecture,
AffWildNet, includes convolutional and recurrent neural network (CNN-RNN)
layers, exploiting the invariant properties of convolutional features, while
also modeling temporal dynamics that arise in human behavior via the recurrent
layers. The AffWildNet produced state-of-the-art results on the Aff-Wild
Challenge. We then exploit the AffWild database for learning features, which
can be used as priors for achieving best performances both for dimensional, as
well as categorical emotion recognition, using the RECOLA, AFEW-VA and EmotiW
2017 datasets, compared to all other methods designed for the same goal.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kollias_D/0/1/0/all/0/1&quot;&gt;Dimitrios Kollias&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tzirakis_P/0/1/0/all/0/1&quot;&gt;Panagiotis Tzirakis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nicolaou_M/0/1/0/all/0/1&quot;&gt;Mihalis A. Nicolaou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Papaioannou_A/0/1/0/all/0/1&quot;&gt;Athanasios Papaioannou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_G/0/1/0/all/0/1&quot;&gt;Guoying Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schuller_B/0/1/0/all/0/1&quot;&gt;Bj&amp;#xf6;rn Schuller&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kotsia_I/0/1/0/all/0/1&quot;&gt;Irene Kotsia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zafeiriou_S/0/1/0/all/0/1&quot;&gt;Stefanos Zafeiriou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.01452">
<title>A Multi-component CNN-RNN Approach for Dimensional Emotion Recognition in-the-wild. (arXiv:1805.01452v3 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1805.01452</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents our approach to the One-Minute Gradual-Emotion
Recognition (OMG-Emotion) Challenge, focusing on dimensional emotion
recognition through visual analysis of the provided emotion videos. The
approach is based on a Convolutional and Recurrent (CNN-RNN) deep neural
architecture we have developed for the relevant large AffWild Emotion Database.
We extended and adapted this architecture, by letting a combination of multiple
features generated in the CNN component be explored by RNN subnets. Our target
has been to obtain best performance on the OMG-Emotion visual validation data
set, while learning the respective visual training data set. Extended
experimentation has led to best architectures for the estimation of the values
of the valence and arousal emotion dimensions over these data sets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kollias_D/0/1/0/all/0/1&quot;&gt;Dimitrios Kollias&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zafeiriou_S/0/1/0/all/0/1&quot;&gt;Stefanos Zafeiriou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.01890">
<title>RMDL: Random Multimodel Deep Learning for Classification. (arXiv:1805.01890v1 [cs.LG] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1805.01890</link>
<description rdf:parseType="Literal">&lt;p&gt;The continually increasing number of complex datasets each year necessitates
ever improving machine learning methods for robust and accurate categorization
of these data. This paper introduces Random Multimodel Deep Learning (RMDL): a
new ensemble, deep learning approach for classification. Deep learning models
have achieved state-of-the-art results across many domains. RMDL solves the
problem of finding the best deep learning structure and architecture while
simultaneously improving robustness and accuracy through ensembles of deep
learning architectures. RDML can accept as input a variety data to include
text, video, images, and symbolic. This paper describes RMDL and shows test
results for image and text data including MNIST, CIFAR-10, WOS, Reuters, IMDB,
and 20newsgroup. These test results show that RDML produces consistently better
performance than standard methods over a broad range of data types and
classification problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kowsari_K/0/1/0/all/0/1&quot;&gt;Kamran Kowsari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Heidarysafa_M/0/1/0/all/0/1&quot;&gt;Mojtaba Heidarysafa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brown_D/0/1/0/all/0/1&quot;&gt;Donald E. Brown&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meimandi_K/0/1/0/all/0/1&quot;&gt;Kiana Jafari Meimandi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barnes_L/0/1/0/all/0/1&quot;&gt;Laura E. Barnes&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.02777">
<title>What game are we playing? End-to-end learning in normal and extensive form games. (arXiv:1805.02777v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.02777</link>
<description rdf:parseType="Literal">&lt;p&gt;Although recent work in AI has made great progress in solving large,
zero-sum, extensive-form games, the underlying assumption in most past work is
that the parameters of the game itself are known to the agents. This paper
deals with the relatively under-explored but equally important &quot;inverse&quot;
setting, where the parameters of the underlying game are not known to all
agents, but must be learned through observations. We propose a differentiable,
end-to-end learning framework for addressing this task. In particular, we
consider a regularized version of the game, equivalent to a particular form of
quantal response equilibrium, and develop 1) a primal-dual Newton method for
finding such equilibrium points in both normal and extensive form games; and 2)
a backpropagation method that lets us analytically compute gradients of all
relevant game parameters through the solution itself. This ultimately lets us
learn the game by training in an end-to-end fashion, effectively by integrating
a &quot;differentiable game solver&quot; into the loop of larger deep network
architectures. We demonstrate the effectiveness of the learning method in
several settings including poker and security game tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ling_C/0/1/0/all/0/1&quot;&gt;Chun Kai Ling&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fang_F/0/1/0/all/0/1&quot;&gt;Fei Fang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kolter_J/0/1/0/all/0/1&quot;&gt;J. Zico Kolter&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.02788">
<title>ReGAN: RE[LAX|BAR|INFORCE] based Sequence Generation using GANs. (arXiv:1805.02788v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.02788</link>
<description rdf:parseType="Literal">&lt;p&gt;Generative Adversarial Networks (GANs) have seen steep ascension to the peak
of ML research zeitgeist in recent years. Mostly catalyzed by its success in
the domain of image generation, the technique has seen wide range of adoption
in a variety of other problem domains. Although GANs have had a lot of success
in producing more realistic images than other approaches, they have only seen
limited use for text sequences. Generation of longer sequences compounds this
problem. Most recently, SeqGAN (Yu et al., 2017) has shown improvements in
adversarial evaluation and results with human evaluation compared to a MLE
based trained baseline. The main contributions of this paper are three-fold: 1.
We show results for sequence generation using a GAN architecture with efficient
policy gradient estimators, 2. We attain improved training stability, and 3. We
perform a comparative study of recent unbiased low variance gradient estimation
techniques such as REBAR (Tucker et al., 2017), RELAX (Grathwohl et al., 2018)
and REINFORCE (Williams, 1992). Using a simple grammar on synthetic datasets
with varying length, we indicate the quality of sequences generated by the
model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Balagopalan_A/0/1/0/all/0/1&quot;&gt;Aparna Balagopalan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gorti_S/0/1/0/all/0/1&quot;&gt;Satya Gorti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ravaut_M/0/1/0/all/0/1&quot;&gt;Mathieu Ravaut&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Saqur_R/0/1/0/all/0/1&quot;&gt;Raeid Saqur&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.02830">
<title>Several Tunable GMM Kernels. (arXiv:1805.02830v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.02830</link>
<description rdf:parseType="Literal">&lt;p&gt;While tree methods have been popular in practice, researchers and
practitioners are also looking for simple algorithms which can reach similar
accuracy of trees. In 2010, (Ping Li UAI&apos;10) developed the method of
&quot;abc-robust-logitboost&quot; and compared it with other supervised learning methods
on datasets used by the deep learning literature. In this study, we propose a
series of &quot;tunable GMM kernels&quot; which are simple and perform largely comparably
to tree methods on the same datasets. Note that &quot;abc-robust-logitboost&quot;
substantially improved the original &quot;GDBT&quot; in that (a) it developed a
tree-split formula based on second-order information of the derivatives of the
loss function; (b) it developed a new set of derivatives for multi-class
classification formulation.
&lt;/p&gt;
&lt;p&gt;In the prior study in 2017, the &quot;generalized min-max&quot; (GMM) kernel was shown
to have good performance compared to the &quot;radial-basis function&quot; (RBF) kernel.
However, as demonstrated in this paper, the original GMM kernel is often not as
competitive as tree methods on the datasets used in the deep learning
literature. Since the original GMM kernel has no parameters, we propose tunable
GMM kernels by adding tuning parameters in various ways. Three basic (i.e.,
with only one parameter) GMM kernels are the &quot;$e$GMM kernel&quot;, &quot;$p$GMM kernel&quot;,
and &quot;$\gamma$GMM kernel&quot;, respectively. Extensive experiments show that they
are able to produce good results for a large number of classification tasks.
Furthermore, the basic kernels can be combined to boost the performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1&quot;&gt;Ping Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.02855">
<title>Tile2Vec: Unsupervised representation learning for remote sensing data. (arXiv:1805.02855v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1805.02855</link>
<description rdf:parseType="Literal">&lt;p&gt;Remote sensing lacks methods like the word vector representations and
pre-trained networks that significantly boost performance across a wide range
of natural language and computer vision tasks. To fill this gap, we introduce
Tile2Vec, an unsupervised representation learning algorithm that extends the
distributional hypothesis from natural language -- words appearing in similar
contexts tend to have similar meanings -- to geospatial data. We demonstrate
empirically that Tile2Vec learns semantically meaningful representations on
three datasets. Our learned representations significantly improve performance
in downstream classification tasks and similarly to word vectors, visual
analogies can be obtained by simple arithmetic in the latent space.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jean_N/0/1/0/all/0/1&quot;&gt;Neal Jean&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1&quot;&gt;Sherrie Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Azzari_G/0/1/0/all/0/1&quot;&gt;George Azzari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lobell_D/0/1/0/all/0/1&quot;&gt;David Lobell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ermon_S/0/1/0/all/0/1&quot;&gt;Stefano Ermon&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.02917">
<title>Interpretable Adversarial Perturbation in Input Embedding Space for Text. (arXiv:1805.02917v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.02917</link>
<description rdf:parseType="Literal">&lt;p&gt;Following great success in the image processing field, the idea of
adversarial training has been applied to tasks in the natural language
processing (NLP) field. One promising approach directly applies adversarial
training developed in the image processing field to the input word embedding
space instead of the discrete input space of texts. However, this approach
abandons such interpretability as generating adversarial texts to significantly
improve the performance of NLP tasks. This paper restores interpretability to
such methods by restricting the directions of perturbations toward the existing
words in the input embedding space. As a result, we can straightforwardly
reconstruct each input with perturbations to an actual text by considering the
perturbations to be the replacement of words in the sentence while maintaining
or even improving the task performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sato_M/0/1/0/all/0/1&quot;&gt;Motoki Sato&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Suzuki_J/0/1/0/all/0/1&quot;&gt;Jun Suzuki&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shindo_H/0/1/0/all/0/1&quot;&gt;Hiroyuki Shindo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Matsumoto_Y/0/1/0/all/0/1&quot;&gt;Yuji Matsumoto&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.02958">
<title>A Regression Model of Recurrent Deep Neural Networks for Noise Robust Estimation of the Fundamental Frequency Contour of Speech. (arXiv:1805.02958v1 [eess.AS])</title>
<link>http://arxiv.org/abs/1805.02958</link>
<description rdf:parseType="Literal">&lt;p&gt;The fundamental frequency (F0) contour of speech is a key aspect to represent
speech prosody that finds use in speech and spoken language analysis such as
voice conversion and speech synthesis as well as speaker and language
identification. This work proposes new methods to estimate the F0 contour of
speech using deep neural networks (DNNs) and recurrent neural networks (RNNs).
They are trained using supervised learning with the ground truth of F0
contours. The latest prior research addresses this problem first as a
frame-by-frame-classification problem followed by sequence tracking using deep
neural network hidden Markov model (DNN-HMM) hybrid architecture. This study,
however, tackles the problem as a regression problem instead, in order to
obtain F0 contours with higher frequency resolution from clean and noisy
speech. Experiments using PTDB-TUG corpus contaminated with additive noise
(NOISEX-92) show the proposed method improves gross pitch error (GPE) by more
than 25 % at signal-to-noise ratios (SNRs) between -10 dB and +10 dB as
compared with one of the most noise-robust F0 trackers, PEFAC. Furthermore, the
performance on fine pitch error (FPE) is improved by approximately 20 % against
a state-of-the-art DNN-HMM-based approach.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Kato_A/0/1/0/all/0/1&quot;&gt;Akihiro Kato&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Kinnunen_T/0/1/0/all/0/1&quot;&gt;Tomi Kinnunen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.06309">
<title>On Improving Deep Reinforcement Learning for POMDPs. (arXiv:1804.06309v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1804.06309</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep Reinforcement Learning (RL) recently emerged as one of the most
competitive approaches for learning in sequential decision making problems with
fully observable environments, e.g., computer Go. However, very little work has
been done in deep RL to handle partially observable environments. We propose a
new architecture called Action-specific Deep Recurrent Q-Network (ADRQN) to
enhance learning performance in partially observable domains. Actions are
encoded by a fully connected layer and coupled with a convolutional observation
to form an action-observation pair. The time series of action-observation pairs
are then integrated by an LSTM layer that learns latent states based on which a
fully connected layer computes Q-values as in conventional Deep Q-Networks
(DQNs). We demonstrate the effectiveness of our new architecture in several
partially observable domains, including flickering Atari games.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_P/0/1/0/all/0/1&quot;&gt;Pengfei Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xin Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Poupart_P/0/1/0/all/0/1&quot;&gt;Pascal Poupart&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Miao_G/0/1/0/all/0/1&quot;&gt;Guanghui Miao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.01553">
<title>A Reinforcement Learning Approach to Interactive-Predictive Neural Machine Translation. (arXiv:1805.01553v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1805.01553</link>
<description rdf:parseType="Literal">&lt;p&gt;We present an approach to interactive-predictive neural machine translation
that attempts to reduce human effort from three directions: Firstly, instead of
requiring humans to select, correct, or delete segments, we employ the idea of
learning from human reinforcements in form of judgments on the quality of
partial translations. Secondly, human effort is further reduced by using the
entropy of word predictions as uncertainty criterion to trigger feedback
requests. Lastly, online updates of the model parameters after every
interaction allow the model to adapt quickly. We show in simulation experiments
that reward signals on partial translations significantly improve character
F-score and BLEU compared to feedback on full translations only, while human
effort can be reduced to an average number of $5$ feedback requests for every
input.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lam_T/0/1/0/all/0/1&quot;&gt;Tsz Kin Lam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kreutzer_J/0/1/0/all/0/1&quot;&gt;Julia Kreutzer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Riezler_S/0/1/0/all/0/1&quot;&gt;Stefan Riezler&lt;/a&gt;</dc:creator>
</item></rdf:RDF>