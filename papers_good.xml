<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Good papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Good Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-03-25T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.08554"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.08631"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.08635"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.08884"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.08625"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.08636"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.08885"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1704.05579"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.00138"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.09601"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.08584"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.08647"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.08773"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.08882"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08241"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.07612"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1803.08554">
<title>Neuronal Circuit Policies. (arXiv:1803.08554v1 [q-bio.NC])</title>
<link>http://arxiv.org/abs/1803.08554</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose an effective way to create interpretable control agents, by
re-purposing the function of a biological neural circuit model, to govern
simulated and real world reinforcement learning (RL) test-beds. We model the
tap-withdrawal (TW) neural circuit of the nematode, C. elegans, a circuit
responsible for the worm&apos;s reflexive response to external mechanical touch
stimulations, and learn its synaptic and neuronal parameters as a policy for
controlling basic RL tasks. We also autonomously park a real rover robot on a
pre-defined trajectory, by deploying such neuronal circuit policies learned in
a simulated environment. For reconfiguration of the purpose of the TW neural
circuit, we adopt a search-based RL algorithm. We show that our neuronal
policies perform as good as deep neural network policies with the advantage of
realizing interpretable dynamics at the cell level.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Lechner_M/0/1/0/all/0/1&quot;&gt;Mathias Lechner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Hasani_R/0/1/0/all/0/1&quot;&gt;Ramin M. Hasani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Grosu_R/0/1/0/all/0/1&quot;&gt;Radu Grosu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.08631">
<title>SEGEN: Sample-Ensemble Genetic Evolutional Network Model. (arXiv:1803.08631v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1803.08631</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep learning, a rebranding of deep neural network research works, has
achieved remarkable success in recent years. With multiple hidden layers, deep
learning models aim at computing hierarchical features or representations of
the observational data. Meanwhile, due to its severe disadvantages in data
consumption, computational resources, parameter tuning efforts and the lack of
result explainability, deep learning has also suffered from lots of criticism.
In this paper, we will introduce a new representation learning model, namely
&quot;Sample-Ensemble Genetic Evolutional Network&quot; (SEGEN), which can serve as an
alternative approach to deep learning models. Instead of building one single
deep model, based on a set of sampled sub-instances, SEGEN adopts a
genetic-evolutional learning strategy to build a group of unit models
generations by generations. The unit models incorporated in SEGEN can be either
traditional machine learning models or the recent deep learning models with a
much &quot;smaller&quot; and &quot;shallower&quot; architecture. The learning results of each
instance at the final generation will be effectively combined from each unit
model via diffusive propagation and ensemble learning strategies. From the
computational perspective, SEGEN requires far less data, fewer computational
resources and parameter tuning works, but has sound theoretic interpretability
of the learning process and results. Extensive experiments have been done on
real-world network structured datasets, and the experimental results obtained
by SEGEN have demonstrate its advantages over the other state-of-the-art
representation learning models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Jiawei Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cui_L/0/1/0/all/0/1&quot;&gt;Limeng Cui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gouza_F/0/1/0/all/0/1&quot;&gt;Fisher B. Gouza&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.08635">
<title>Hardware based Spatio-Temporal Neural Processing Backend for Imaging Sensors: Towards a Smart Camera. (arXiv:1803.08635v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1803.08635</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work we show how we can build a technology platform for cognitive
imaging sensors using recent advances in recurrent neural network architectures
and training methods inspired from biology. We demonstrate learning and
processing tasks specific to imaging sensors, including enhancement of
sensitivity and signal-to-noise ratio (SNR) purely through neural filtering
beyond the fundamental limits sensor materials, and inferencing and
spatio-temporal pattern recognition capabilities of these networks with
applications in object detection, motion tracking and prediction. We then show
designs of unit hardware cells built using complementary metal-oxide
semiconductor (CMOS) and emerging materials technologies for ultra-compact and
energy-efficient embedded neural processors for smart cameras.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ganguly_S/0/1/0/all/0/1&quot;&gt;Samiran Ganguly&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gu_Y/0/1/0/all/0/1&quot;&gt;Yunfei Gu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stan_M/0/1/0/all/0/1&quot;&gt;Mircea R. Stan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghosh_A/0/1/0/all/0/1&quot;&gt;Avik W. Ghosh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.08884">
<title>Inequity aversion resolves intertemporal social dilemmas. (arXiv:1803.08884v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1803.08884</link>
<description rdf:parseType="Literal">&lt;p&gt;Groups of humans are often able to find ways to cooperate with one another in
complex, temporally extended social dilemmas. Models based on behavioral
economics are only able to explain this phenomenon for unrealistic stateless
matrix games. Recently, multi-agent reinforcement learning has been applied to
generalize social dilemma problems to temporally and spatially extended Markov
games. However, this has not yet generated an agent that learns to cooperate in
social dilemmas as humans do. A key insight is that many, but not all, human
individuals have inequity averse social preferences. This promotes a particular
resolution of the matrix game social dilemma wherein inequity-averse
individuals are personally pro-social and punish defectors. Here we extend this
idea to Markov games and show that it promotes cooperation in several types of
sequential social dilemma, via a profitable interaction with policy
learnability. In particular, we find that inequity aversion improves temporal
credit assignment for the important class of intertemporal social dilemmas.
These results help explain how large-scale cooperation may emerge and persist.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hughes_E/0/1/0/all/0/1&quot;&gt;Edward Hughes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leibo_J/0/1/0/all/0/1&quot;&gt;Joel Z. Leibo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Philips_M/0/1/0/all/0/1&quot;&gt;Matthew G. Philips&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tuyls_K/0/1/0/all/0/1&quot;&gt;Karl Tuyls&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Duenez_Guzman_E/0/1/0/all/0/1&quot;&gt;Edgar A. Du&amp;#xe9;&amp;#xf1;ez-Guzm&amp;#xe1;n&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Castaneda_A/0/1/0/all/0/1&quot;&gt;Antonio Garc&amp;#xed;a Casta&amp;#xf1;eda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dunning_I/0/1/0/all/0/1&quot;&gt;Iain Dunning&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_T/0/1/0/all/0/1&quot;&gt;Tina Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+McKee_K/0/1/0/all/0/1&quot;&gt;Kevin R. McKee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koster_R/0/1/0/all/0/1&quot;&gt;Raphael Koster&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roff_H/0/1/0/all/0/1&quot;&gt;Heather Roff&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Graepel_T/0/1/0/all/0/1&quot;&gt;Thore Graepel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.08625">
<title>A Concept Learning Tool Based On Calculating Version Space Cardinality. (arXiv:1803.08625v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1803.08625</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we proposed VeSC-CoL (Version Space Cardinality based Concept
Learning) to deal with concept learning on extremely imbalanced datasets,
especially when cross-validation is not a viable option. VeSC-CoL uses version
space cardinality as a measure for model quality to replace cross-validation.
Instead of naive enumeration of the version space, Ordered Binary Decision
Diagram and Boolean Satisfiability are used to compute the version space.
Experiments show that VeSC-CoL can accurately learn the target concept when
computational resource is allowed.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hsieh_K/0/1/0/all/0/1&quot;&gt;Kuo-Kai Hsieh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1&quot;&gt;Li-C. Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.08636">
<title>PDNet: Prior-model Guided Depth-enhanced Network for Salient Object Detection. (arXiv:1803.08636v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1803.08636</link>
<description rdf:parseType="Literal">&lt;p&gt;Fully convolutional neural networks (FCNs) have shown outstanding performance
in many computer vision tasks including salient object detection. However,
there still remains two issues needed to be addressed in deep learning based
saliency detection. One is the lack of tremendous amount of annotated data to
train a network. The other is the lack of robustness for extracting salient
objects in images containing complex scenes. In this paper, we present a new
architecture$ - $PDNet, a robust prior-model guided depth-enhanced network for
RGB-D salient object detection. In contrast to existing works, in which RGB-D
values of image pixels are fed directly to a network, the proposed architecture
is composed of a master network for processing RGB values, and a sub-network
making full use of depth cues and incorporate depth-based features into the
master network. To overcome the limited size of the labeled RGB-D dataset for
training, we employ a large conventional RGB dataset to pre-train the master
network, which proves to contribute largely to the final accuracy. Extensive
evaluations over five benchmark datasets demonstrate that our proposed method
performs favorably against the state-of-the-art approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_C/0/1/0/all/0/1&quot;&gt;Chunbiao Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cai_X/0/1/0/all/0/1&quot;&gt;Xing Cai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1&quot;&gt;Kan Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1&quot;&gt;Thomas H Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1&quot;&gt;Ge Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.08885">
<title>Defeasible Reasoning in SROEL: from Rational Entailment to Rational Closure. (arXiv:1803.08885v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1803.08885</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work we study a rational extension $SROEL^R T$ of the low complexity
description logic SROEL, which underlies the OWL EL ontology language. The
extension involves a typicality operator T, whose semantics is based on Lehmann
and Magidor&apos;s ranked models and allows for the definition of defeasible
inclusions. We consider both rational entailment and minimal entailment. We
show that deciding instance checking under minimal entailment is in general
$\Pi^P_2$-hard, while, under rational entailment, instance checking can be
computed in polynomial time. We develop a Datalog calculus for instance
checking under rational entailment and exploit it, with stratified negation,
for computing the rational closure of simple KBs in polynomial time.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Giordano_L/0/1/0/all/0/1&quot;&gt;Laura Giordano&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dupre_D/0/1/0/all/0/1&quot;&gt;Daniele Theseider Dupr&amp;#xe9;&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1704.05579">
<title>A Large Self-Annotated Corpus for Sarcasm. (arXiv:1704.05579v4 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1704.05579</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce the Self-Annotated Reddit Corpus (SARC), a large corpus for
sarcasm research and for training and evaluating systems for sarcasm detection.
The corpus has 1.3 million sarcastic statements -- 10 times more than any
previous dataset -- and many times more instances of non-sarcastic statements,
allowing for learning in both balanced and unbalanced label regimes. Each
statement is furthermore self-annotated -- sarcasm is labeled by the author,
not an independent annotator -- and provided with user, topic, and conversation
context. We evaluate the corpus for accuracy, construct benchmarks for sarcasm
detection, and evaluate baseline methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khodak_M/0/1/0/all/0/1&quot;&gt;Mikhail Khodak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saunshi_N/0/1/0/all/0/1&quot;&gt;Nikunj Saunshi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vodrahalli_K/0/1/0/all/0/1&quot;&gt;Kiran Vodrahalli&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.00138">
<title>Visualizing and Understanding Atari Agents. (arXiv:1711.00138v4 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1711.00138</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep reinforcement learning (deep RL) agents have achieved remarkable success
in a broad range of game-playing and continuous control tasks. While these
agents are effective at maximizing rewards, it is often unclear what strategies
they use to do so. In this paper, we take a step toward explaining deep RL
agents through a case study using Atari 2600 environments. In particular, we
focus on using saliency maps to understand how an agent learns and executes a
policy. We introduce a method for generating useful saliency maps and use it to
show 1) what strong agents attend to, 2) whether agents are making decisions
for the right or wrong reasons, and 3) how agents evolve during learning. We
also test our method on non-expert human subjects and find that it improves
their ability to reason about these agents. Overall, our results show that
saliency information can provide significant insight into an RL agent&apos;s
decisions and learning behavior.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Greydanus_S/0/1/0/all/0/1&quot;&gt;Sam Greydanus&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koul_A/0/1/0/all/0/1&quot;&gt;Anurag Koul&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dodge_J/0/1/0/all/0/1&quot;&gt;Jonathan Dodge&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fern_A/0/1/0/all/0/1&quot;&gt;Alan Fern&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.09601">
<title>Memory Aware Synapses: Learning what (not) to forget. (arXiv:1711.09601v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1711.09601</link>
<description rdf:parseType="Literal">&lt;p&gt;Humans can learn in a continuous manner. Old rarely utilized knowledge can be
overwritten by new incoming information while important, frequently used
knowledge is prevented from being erased. In artificial learning systems,
lifelong learning so far has focused mainly on accumulating knowledge over
tasks and overcoming catastrophic forgetting. In this paper, we argue that,
given the limited model capacity and the unlimited new information to be
learned, knowledge has to be preserved or erased selectively. Inspired by
neuroplasticity, we propose a novel approach for lifelong learning, coined
Memory Aware Synapses (MAS). It computes the importance of the parameters of a
neural network in an unsupervised and online manner. Given a new sample which
is fed to the network, MAS accumulates an importance measure for each parameter
of the network, based on how sensitive the predicted output function is to a
change in this parameter. When learning a new task, changes to important
parameters can then be penalized, effectively preventing important knowledge
related to previous tasks from being overwritten. Further, we show an
interesting connection between a local version of our method and Hebb&apos;s
rule,which is a model for the learning process in the brain. We test our method
on a sequence of object recognition tasks and on the challenging problem of
learning an embedding for predicting $&amp;lt;$subject, predicate, object$&amp;gt;$ triplets.
We show state-of-the-art performance and, for the first time, the ability to
adapt the importance of the parameters based on unlabeled data towards what the
network needs (not) to forget, which may vary depending on test conditions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aljundi_R/0/1/0/all/0/1&quot;&gt;Rahaf Aljundi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Babiloni_F/0/1/0/all/0/1&quot;&gt;Francesca Babiloni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Elhoseiny_M/0/1/0/all/0/1&quot;&gt;Mohamed Elhoseiny&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rohrbach_M/0/1/0/all/0/1&quot;&gt;Marcus Rohrbach&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tuytelaars_T/0/1/0/all/0/1&quot;&gt;Tinne Tuytelaars&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.08584">
<title>Curvature of Hypergraphs via Multi-Marginal Optimal Transport. (arXiv:1803.08584v1 [cs.IT])</title>
<link>http://arxiv.org/abs/1803.08584</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce a novel definition of curvature for hypergraphs, a natural
generalization of graphs, by introducing a multi-marginal optimal transport
problem for a naturally defined random walk on the hypergraph. This curvature,
termed \emph{coarse scalar curvature}, generalizes a recent definition of Ricci
curvature for Markov chains on metric spaces by Ollivier [Journal of Functional
Analysis 256 (2009) 810-864], and is related to the scalar curvature when the
hypergraph arises naturally from a Riemannian manifold. We investigate basic
properties of the coarse scalar curvature and obtain several bounds. Empirical
experiments indicate that coarse scalar curvatures are capable of detecting
&quot;bridges&quot; across connected components in hypergraphs, suggesting it is an
appropriate generalization of curvature on simple graphs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Asoodeh_S/0/1/0/all/0/1&quot;&gt;Shahab Asoodeh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_T/0/1/0/all/0/1&quot;&gt;Tingran Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Evans_J/0/1/0/all/0/1&quot;&gt;James Evans&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.08647">
<title>Fictitious GAN: Training GANs with Historical Models. (arXiv:1803.08647v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1803.08647</link>
<description rdf:parseType="Literal">&lt;p&gt;Generative adversarial networks (GANs) are powerful tools for learning
generative models. In practice, the training may suffer from lack of
convergence. GANs are commonly viewed as a two-player zero-sum game between two
neural networks. Here, we leverage this game theoretic view to study the
convergence behavior of the training process. Inspired by the fictitious play
learning process, a novel training method, referred to as Fictitious GAN, is
introduced. Fictitious GAN trains the deep neural networks using a mixture of
historical models. Specifically, the discriminator (resp. generator) is updated
according to the best-response to the mixture outputs from a sequence of
previously trained generators (resp. discriminators). It is shown that
Fictitious GAN can effectively resolve some convergence issues that cannot be
resolved by the standard training approach. It is proved that asymptotically
the average of the generator outputs has the same distribution as the data
samples.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ge_H/0/1/0/all/0/1&quot;&gt;Hao Ge&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xia_Y/0/1/0/all/0/1&quot;&gt;Yin Xia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1&quot;&gt;Xu Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Berry_R/0/1/0/all/0/1&quot;&gt;Randall Berry&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1&quot;&gt;Ying Wu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.08773">
<title>Detecting Adversarial Perturbations with Saliency. (arXiv:1803.08773v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1803.08773</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper we propose a novel method for detecting adversarial examples by
training a binary classifier with both origin data and saliency data. In the
case of image classification model, saliency simply explain how the model make
decisions by identifying significant pixels for prediction. A model shows wrong
classification output always learns wrong features and shows wrong saliency as
well. Our approach shows good performance on detecting adversarial
perturbations. We quantitatively evaluate generalization ability of the
detector, showing that detectors trained with strong adversaries perform well
on weak adversaries.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1&quot;&gt;Chiliang Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1&quot;&gt;Zhimou Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ye_Z/0/1/0/all/0/1&quot;&gt;Zuochang Ye&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.08882">
<title>Trace your sources in large-scale data: one ring to find them all. (arXiv:1803.08882v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1803.08882</link>
<description rdf:parseType="Literal">&lt;p&gt;An important preprocessing step in most data analysis pipelines aims to
extract a small set of sources that explain most of the data. Currently used
algorithms for blind source separation (BSS), however, often fail to extract
the desired sources and need extensive cross-validation. In contrast, their
rarely used probabilistic counterparts can get away with little
cross-validation and are more accurate and reliable but no simple and scalable
implementations are available. Here we present a novel probabilistic BSS
framework (DECOMPOSE) that can be flexibly adjusted to the data, is extensible
and easy to use, adapts to individual sources and handles large-scale data
through algorithmic efficiency. DECOMPOSE encompasses and generalises many
traditional BSS algorithms such as PCA, ICA and NMF and we demonstrate
substantial improvements in accuracy and robustness on artificial and real
data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bottcher_A/0/1/0/all/0/1&quot;&gt;Alexander B&amp;#xf6;ttcher&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Brendel_W/0/1/0/all/0/1&quot;&gt;Wieland Brendel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Englitz_B/0/1/0/all/0/1&quot;&gt;Bernhard Englitz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bethge_M/0/1/0/all/0/1&quot;&gt;Matthias Bethge&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08241">
<title>Hessian-based Analysis of Large Batch Training and Robustness to Adversaries. (arXiv:1802.08241v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1802.08241</link>
<description rdf:parseType="Literal">&lt;p&gt;Large batch size training of Neural Networks has been shown to incur accuracy
loss when trained with the current methods. The precise underlying reasons for
this are still not completely understood. Here, we study large batch size
training through the lens of the Hessian operator and robust optimization. In
particular, we perform a Hessian based study to analyze how the landscape of
the loss functional is different for large batch size training. We compute the
true Hessian spectrum, without approximation, by back-propagating the second
derivative. Our results on multiple networks show that, when training at large
batch sizes, one tends to stop at points in the parameter space with noticeably
higher/larger Hessian spectrum, i.e., where the eigenvalues of the Hessian are
much larger. We then study how batch size affects robustness of the model in
the face of adversarial attacks. All the results show that models trained with
large batches are more susceptible to adversarial attacks, as compared to
models trained with small batch sizes. Furthermore, we prove a theoretical
result which shows that the problem of finding an adversarial perturbation is a
saddle-free optimization problem. Finally, we show empirical results that
demonstrate that adversarial training leads to areas with smaller Hessian
spectrum. We present detailed experiments with five different network
architectures tested on MNIST, CIFAR-10, and CIFAR-100 datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yao_Z/0/1/0/all/0/1&quot;&gt;Zhewei Yao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gholami_A/0/1/0/all/0/1&quot;&gt;Amir Gholami&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lei_Q/0/1/0/all/0/1&quot;&gt;Qi Lei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Keutzer_K/0/1/0/all/0/1&quot;&gt;Kurt Keutzer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mahoney_M/0/1/0/all/0/1&quot;&gt;Michael W. Mahoney&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.07612">
<title>Generative Multi-Agent Behavioral Cloning. (arXiv:1803.07612v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1803.07612</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose and study the problem of generative multi-agent behavioral
cloning, where the goal is to learn a generative multi-agent policy from
pre-collected demonstration data. Building upon advances in deep generative
models, we present a hierarchical policy framework that can tractably learn
complex mappings from input states to distributions over multi-agent action
spaces. Our framework is flexible and can incorporate high-level domain
knowledge into the structure of the underlying deep graphical model. For
instance, we can effectively learn low-dimensional structures, such as
long-term goals and team coordination, from data. Thus, an additional benefit
of our hierarchical approach is the ability to plan over multiple time scales
for effective long-term planning. We showcase our approach in an application of
modeling team offensive play from basketball tracking data. We show how to
instantiate our framework to effectively model complex interactions between
basketball players and generate realistic multi-agent trajectories of
basketball gameplay over long time periods. We validate our approach using both
quantitative and qualitative evaluations, including a user study comparison
conducted with professional sports analysts.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhan_E/0/1/0/all/0/1&quot;&gt;Eric Zhan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_S/0/1/0/all/0/1&quot;&gt;Stephan Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yue_Y/0/1/0/all/0/1&quot;&gt;Yisong Yue&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sha_L/0/1/0/all/0/1&quot;&gt;Long Sha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lucey_P/0/1/0/all/0/1&quot;&gt;Patrick Lucey&lt;/a&gt;</dc:creator>
</item></rdf:RDF>