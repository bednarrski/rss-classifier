<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Good papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Good Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-02-13T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04364"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.02779"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04051"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04253"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04289"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04325"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04335"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04425"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04451"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04544"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04675"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04765"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04780"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.10494"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.00108"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.01244"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.09547"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.03390"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04302"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04350"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04376"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04420"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04431"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04551"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04591"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04626"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04684"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1703.00607"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.00141"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.08277"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.02125"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.07756"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1802.04364">
<title>Junction Tree Variational Autoencoder for Molecular Graph Generation. (arXiv:1802.04364v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.04364</link>
<description rdf:parseType="Literal">&lt;p&gt;We seek to automate the design of molecules based on specific chemical
properties. In computational terms, this task involves continuous embedding and
generation of molecular graphs. Our primary contribution is the direct
realization of molecular graphs, a task previously approached by generating
linear SMILES strings instead of graphs. Our junction tree variational
autoencoder generates molecular graphs in two phases, by first generating a
tree-structured scaffold over chemical substructures, and then combining them
into a molecule with a graph message passing network. This approach allows us
to incrementally expand molecules while maintaining chemical validity at every
step. We evaluate our model on multiple tasks ranging from molecular generation
to optimization. Across these tasks, our model outperforms previous
state-of-the-art baselines by a significant margin.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jin_W/0/1/0/all/0/1&quot;&gt;Wengong Jin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barzilay_R/0/1/0/all/0/1&quot;&gt;Regina Barzilay&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jaakkola_T/0/1/0/all/0/1&quot;&gt;Tommi Jaakkola&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.02779">
<title>A Rotation and a Translation Suffice: Fooling CNNs with Simple Transformations. (arXiv:1712.02779v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1712.02779</link>
<description rdf:parseType="Literal">&lt;p&gt;We show that simple transformations, namely translations and rotations alone,
are sufficient to fool neural network-based vision models on a significant
fraction of inputs. This is in sharp contrast to previous work that relied on
more complicated optimization approaches that are unlikely to appear outside of
a truly adversarial setting. Moreover, fooling rotations and translations are
easy to find and require only a few black-box queries to the target model.
Overall, our findings emphasize the need for designing robust classifiers even
in natural, benign contexts.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Engstrom_L/0/1/0/all/0/1&quot;&gt;Logan Engstrom&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tran_B/0/1/0/all/0/1&quot;&gt;Brandon Tran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tsipras_D/0/1/0/all/0/1&quot;&gt;Dimitris Tsipras&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schmidt_L/0/1/0/all/0/1&quot;&gt;Ludwig Schmidt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Madry_A/0/1/0/all/0/1&quot;&gt;Aleksander Madry&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04051">
<title>One Deep Music Representation to Rule Them All? : A comparative analysis of different representation learning strategies. (arXiv:1802.04051v2 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1802.04051</link>
<description rdf:parseType="Literal">&lt;p&gt;Inspired by the success of deploying deep learning in the fields of Computer
Vision and Natural Language Processing, this learning paradigm has also found
its way into the field of Music Information Retrieval. In order to benefit from
deep learning in an effective, but also efficient manner, deep transfer
learning has become a common approach. In this approach, it is possible to
reuse the output of a pre-trained neural network as the basis for a new, yet
unseen learning task. The underlying hypothesis is that if the initial and new
learning tasks show commonalities and are applied to the same type of data
(e.g. music audio), the generated deep representation of the data is also
informative for the new task. Since, however, most of the networks used to
generate deep representations are trained using a single initial learning task,
the validity of the above hypothesis is questionable for an arbitrary new
learning task. In this paper we present the results of our investigation of
what the best ways are to generate deep representations for the data and
learning tasks in the music domain. We conducted this investigation via an
extensive empirical study that involves multiple learning tasks, as well as
multiple deep learning architectures with varying levels of information sharing
between tasks, in order to learn music representations. We then validate these
representations considering multiple unseen learning tasks for evaluation. The
results of our experiments yield several insights on how to approach the design
of methods for learning widely deployable deep data representations in the
music domain.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1&quot;&gt;Jaehun Kim&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Urbano_J/0/1/0/all/0/1&quot;&gt;Juli&amp;#xe1;n Urbano&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liem_C/0/1/0/all/0/1&quot;&gt;Cynthia C. S. Liem&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hanjalic_A/0/1/0/all/0/1&quot;&gt;Alan Hanjalic&lt;/a&gt; (1) ((1) Delft University of Technology)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04253">
<title>Global Model Interpretation via Recursive Partitioning. (arXiv:1802.04253v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.04253</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work, we propose a simple but effective method to interpret black-box
machine learning models globally. That is, we use a compact binary tree, the
interpretation tree, to explicitly represent the most important decision rules
that are implicitly contained in the black-box machine learning models. This
tree is learned from the contribution matrix which consists of the
contributions of input variables to predicted scores for each single
prediction. To generate the interpretation tree, a unified process recursively
partitions the input variable space by maximizing the difference in the average
contribution of the split variable between the divided spaces. We demonstrate
the effectiveness of our method in diagnosing machine learning models on
multiple tasks. Also, it is useful for new knowledge discovery as such insights
are not easily identifiable when only looking at single predictions. In
general, our work makes it easier and more efficient for human beings to
understand machine learning models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1&quot;&gt;Chengliang Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rangarajan_A/0/1/0/all/0/1&quot;&gt;Anand Rangarajan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ranka_S/0/1/0/all/0/1&quot;&gt;Sanjay Ranka&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04289">
<title>Deep Neural Networks for Bot Detection. (arXiv:1802.04289v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.04289</link>
<description rdf:parseType="Literal">&lt;p&gt;The problem of detecting bots, automated social media accounts governed by
software but disguising as human users, has strong implications. For example,
bots have been used to sway political elections by distorting online discourse,
to manipulate the stock market, or to push anti-vaccine conspiracy theories
that caused health epidemics. Most techniques proposed to date detect bots at
the account level, by processing large amount of social media posts, and
leveraging information from network structure, temporal dynamics, sentiment
analysis, etc.
&lt;/p&gt;
&lt;p&gt;In this paper, we propose a deep neural network based on contextual long
short-term memory (LSTM) architecture that exploits both content and metadata
to detect bots at the tweet level: contextual features are extracted from user
metadata and fed as auxiliary input to LSTM deep nets processing the tweet
text.
&lt;/p&gt;
&lt;p&gt;Another contribution that we make is proposing a technique based on synthetic
minority oversampling to generate a large labeled dataset, suitable for deep
nets training, from a minimal amount of labeled data (roughly 3,000 examples of
sophisticated Twitter bots). We demonstrate that, from just one single tweet,
our architecture can achieve high classification accuracy (AUC &amp;gt; 96%) in
separating bots from humans.
&lt;/p&gt;
&lt;p&gt;We apply the same architecture to account-level bot detection, achieving
nearly perfect classification accuracy (AUC &amp;gt; 99%). Our system outperforms
previous state of the art while leveraging a small and interpretable set of
features yet requiring minimal training data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kudugunta_S/0/1/0/all/0/1&quot;&gt;Sneha Kudugunta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ferrara_E/0/1/0/all/0/1&quot;&gt;Emilio Ferrara&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04325">
<title>Efficient Model-Based Deep Reinforcement Learning with Variational State Tabulation. (arXiv:1802.04325v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.04325</link>
<description rdf:parseType="Literal">&lt;p&gt;Modern reinforcement learning algorithms reach super-human performance in
many board and video games, but they are sample inefficient, i.e. they
typically require significantly more playing experience than humans to reach an
equal performance level. To improve sample efficiency, an agent may build a
model of the environment and use planning methods to update its policy. In this
article we introduce VaST (Variational State Tabulation), which maps an
environment with a high-dimensional state space (e.g. the space of visual
inputs) to an abstract tabular environment. Prioritized sweeping with small
backups, a highly efficient planning method, can then be used to update
state-action values. We show how VaST can rapidly learn to maximize reward in
tasks like 3D navigation and efficiently adapt to sudden changes in rewards or
transition probabilities.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Corneil_D/0/1/0/all/0/1&quot;&gt;Dane Corneil&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gerstner_W/0/1/0/all/0/1&quot;&gt;Wulfram Gerstner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brea_J/0/1/0/all/0/1&quot;&gt;Johanni Brea&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04335">
<title>Neural Program Search: Solving Programming Tasks from Description and Examples. (arXiv:1802.04335v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.04335</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a Neural Program Search, an algorithm to generate programs from
natural language description and a small number of input/output examples. The
algorithm combines methods from Deep Learning and Program Synthesis fields by
designing rich domain-specific language (DSL) and defining efficient search
algorithm guided by a Seq2Tree model on it. To evaluate the quality of the
approach we also present a semi-synthetic dataset of descriptions with test
examples and corresponding programs. We show that our algorithm significantly
outperforms a sequence-to-sequence model with attention baseline.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Polosukhin_I/0/1/0/all/0/1&quot;&gt;Illia Polosukhin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Skidanov_A/0/1/0/all/0/1&quot;&gt;Alexander Skidanov&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04425">
<title>&quot;How Was Your Weekend?&quot; A Generative Model of Phatic Conversation. (arXiv:1802.04425v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1802.04425</link>
<description rdf:parseType="Literal">&lt;p&gt;Unspoken social rules, such as those that govern choosing a proper discussion
topic and when to change discussion topics, guide conversational behaviors. We
propose a computational model of conversation that can follow or break such
rules, with participant agents that respond accordingly. Additionally, we
demonstrate an application of the model: the Experimental Social Tutor (EST), a
first step toward a social skills training tool that generates human-readable
conversation and a conversational guideline at each point in the dialogue.
Finally, we discuss the design and results of a pilot study evaluating the EST.
Results show that our model is capable of producing conversations that follow
social norms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Morrison_H/0/1/0/all/0/1&quot;&gt;Hannah Morrison&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Martens_C/0/1/0/all/0/1&quot;&gt;Chris Martens&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04451">
<title>Blockchain and Artificial Intelligence. (arXiv:1802.04451v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.04451</link>
<description rdf:parseType="Literal">&lt;p&gt;It is undeniable that artificial intelligence (AI) and blockchain concepts
are spreading at a phenomenal rate. Both technologies have distinct degree of
technological complexity and multi-dimensional business implications. However,
a common misunderstanding about blockchain concept, in particular, is that
blockchain is decentralized and is not controlled by anyone. But the underlying
development of a blockchain system is still attributed to a cluster of core
developers. Take smart contract as an example, it is essentially a collection
of codes (or functions) and data (or states) that are programmed and deployed
on a blockchain (say, Ethereum) by different human programmers. It is thus,
unfortunately, less likely to be free of loopholes and flaws. In this article,
through a brief overview about how artificial intelligence could be used to
deliver bug-free smart contract so as to achieve the goal of blockchain 2.0, we
to emphasize that the blockchain implementation can be assisted or enhanced via
various AI techniques. The alliance of AI and blockchain is expected to create
numerous possibilities.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Marwala_T/0/1/0/all/0/1&quot;&gt;Tshilidzi Marwala&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xing_B/0/1/0/all/0/1&quot;&gt;Bo Xing&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04544">
<title>On the Relative Succinctness of Sentential Decision Diagrams. (arXiv:1802.04544v1 [cs.CC])</title>
<link>http://arxiv.org/abs/1802.04544</link>
<description rdf:parseType="Literal">&lt;p&gt;Sentential decision diagrams (SDDs) introduced by Darwiche in 2011 are a
promising representation type used in knowledge compilation. The relative
succinctness of representation types is an important subject in this area. The
aim of the paper is to identify which kind of Boolean functions can be
represented by SDDs of small size with respect to the number of variables the
functions are defined on. For this reason the sets of Boolean functions
representable by different representation types in polynomial size are
investigated and SDDs are compared with representation types from the classical
knowledge compilation map of Darwiche and Marquis. Ordered binary decision
diagrams (OBDDs) which are a popular data structure for Boolean functions are
one of these representation types. SDDs are more general than OBDDs by
definition but only recently, a Boolean function was presented with polynomial
SDD size but exponential OBDD size. This result is strengthened in several
ways. The main result is a quasipolynomial simulation of SDDs by equivalent
unambiguous nondeterministic OBDDs, a nondeterministic variant where there
exists exactly one accepting computation for each satisfying input. As a side
effect an open problem about the relative succinctness between SDDs and free
binary decision diagrams (FBDDs) which are more general than OBDDs is answered.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bollig_B/0/1/0/all/0/1&quot;&gt;Beate Bollig&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Buttkus_M/0/1/0/all/0/1&quot;&gt;Matthias Buttkus&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04675">
<title>Attention based Sentence Extraction from Scientific Articles using Pseudo-Labeled data. (arXiv:1802.04675v1 [cs.IR])</title>
<link>http://arxiv.org/abs/1802.04675</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work, we present a weakly supervised sentence extraction technique
for identifying important sentences in scientific papers that are worthy of
inclusion in the abstract. We propose a new attention based deep learning
architecture that jointly learns to identify important content, as well as the
cue phrases that are indicative of summary worthy sentences. We propose a new
context embedding technique for determining the focus of a given paper using
topic models and use it jointly with an LSTM based sequence encoder to learn
attention weights across the sentence words. We use a collection of articles
publicly available through ACL anthology for our experiments. Our system
achieves a performance that is better, in terms of several ROUGE metrics, as
compared to several state of art extractive techniques. It also generates more
coherent summaries and preserves the overall structure of the document.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mehta_P/0/1/0/all/0/1&quot;&gt;Parth Mehta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Arora_G/0/1/0/all/0/1&quot;&gt;Gaurav Arora&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Majumder_P/0/1/0/all/0/1&quot;&gt;Prasenjit Majumder&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04765">
<title>Progressive Reinforcement Learning with Distillation for Multi-Skilled Motion Control. (arXiv:1802.04765v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.04765</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep reinforcement learning has demonstrated increasing capabilities for
continuous control problems, including agents that can move with skill and
agility through their environment. An open problem in this setting is that of
developing good strategies for integrating or merging policies for multiple
skills, where each individual skill is a specialist in a specific skill and its
associated state distribution. We extend policy distillation methods to the
continuous action setting and leverage this technique to combine expert
policies, as evaluated in the domain of simulated bipedal locomotion across
different classes of terrain. We also introduce an input injection method for
augmenting an existing policy network to exploit new input features. Lastly,
our method uses transfer learning to assist in the efficient acquisition of new
skills. The combination of these methods allows a policy to be incrementally
augmented with new skills. We compare our progressive learning and integration
via distillation (PLAID) method against three alternative baselines.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Berseth_G/0/1/0/all/0/1&quot;&gt;Glen Berseth&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_C/0/1/0/all/0/1&quot;&gt;Cheng Xie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cernek_P/0/1/0/all/0/1&quot;&gt;Paul Cernek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Panne_M/0/1/0/all/0/1&quot;&gt;Michiel Van de Panne&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04780">
<title>DataBright: Towards a Global Exchange for Decentralized Data Ownership and Trusted Computation. (arXiv:1802.04780v1 [cs.ET])</title>
<link>http://arxiv.org/abs/1802.04780</link>
<description rdf:parseType="Literal">&lt;p&gt;It is safe to assume that, for the foreseeable future, machine learning,
especially deep learning will remain both data- and computation-hungry. In this
paper, we ask: Can we build a global exchange where everyone can contribute
computation and data to train the next generation of machine learning
applications?
&lt;/p&gt;
&lt;p&gt;We present an early, but running prototype of DataBright, a system that turns
the creation of training examples and the sharing of computation into an
investment mechanism. Unlike most crowdsourcing platforms, where the
contributor gets paid when they submit their data, DataBright pays dividends
whenever a contributor&apos;s data or hardware is used by someone to train a machine
learning model. The contributor becomes a shareholder in the dataset they
created. To enable the measurement of usage, a computation platform that
contributors can trust is also necessary. DataBright thus merges both a data
market and a trusted computation market.
&lt;/p&gt;
&lt;p&gt;We illustrate that trusted computation can enable the creation of an AI
market, where each data point has an exact value that should be paid to its
creator. DataBright allows data creators to retain ownership of their
contribution and attaches to it a measurable value. The value of the data is
given by its utility in subsequent distributed computation done on the
DataBright computation market. The computation market allocates tasks and
subsequent payments to pooled hardware. This leads to the creation of a
decentralized AI cloud. Our experiments show that trusted hardware such as
Intel SGX can be added to the usual ML pipeline with no additional costs. We
use this setting to orchestrate distributed computation that enables the
creation of a computation market. DataBright is available for download at
https://github.com/ds3lab/databright.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dao_D/0/1/0/all/0/1&quot;&gt;David Dao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alistarh_D/0/1/0/all/0/1&quot;&gt;Dan Alistarh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Musat_C/0/1/0/all/0/1&quot;&gt;Claudiu Musat&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1&quot;&gt;Ce Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.10494">
<title>Human motion primitive discovery and recognition. (arXiv:1709.10494v3 [cs.RO] UPDATED)</title>
<link>http://arxiv.org/abs/1709.10494</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a novel framework for the automatic discovery and recognition of
human motion primitives from motion capture data. Human motion primitives are
discovered by optimizing the &apos;motion flux&apos;, a quantity which depends on the
motion of a group of skeletal joints. Models of each primitive category are
computed via non-parametric Bayes methods and recognition is performed based on
their geometric properties. A normalization of the primitives is proposed in
order to make them invariant with respect to anatomical variations and data
sampling rate. Using our framework we build a publicly available dataset of
human motion primitives based on motion capture sequences taken from well-known
datasets. We expect that our framework, by providing an objective way for
discovering and categorizing human motion, will be a useful tool in numerous
research fields related to Robotics including human inspired motion generation,
learning by demonstration, and intuitive human-robot interaction.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sanzari_M/0/1/0/all/0/1&quot;&gt;Marta Sanzari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ntouskos_V/0/1/0/all/0/1&quot;&gt;Valsamis Ntouskos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grazioso_S/0/1/0/all/0/1&quot;&gt;Simone Grazioso&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Puja_F/0/1/0/all/0/1&quot;&gt;Francesco Puja&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pirri_F/0/1/0/all/0/1&quot;&gt;Fiora Pirri&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.00108">
<title>Beyond Shared Hierarchies: Deep Multitask Learning through Soft Layer Ordering. (arXiv:1711.00108v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1711.00108</link>
<description rdf:parseType="Literal">&lt;p&gt;Existing deep multitask learning (MTL) approaches align layers shared between
tasks in a parallel ordering. Such an organization significantly constricts the
types of shared structure that can be learned. The necessity of parallel
ordering for deep MTL is first tested by comparing it with permuted ordering of
shared layers. The results indicate that a flexible ordering can enable more
effective sharing, thus motivating the development of a soft ordering approach,
which learns how shared layers are applied in different ways for different
tasks. Deep MTL with soft ordering outperforms parallel ordering methods across
a series of domains. These results suggest that the power of deep MTL comes
from learning highly general building blocks that can be assembled to meet the
demands of each task.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meyerson_E/0/1/0/all/0/1&quot;&gt;Elliot Meyerson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Miikkulainen_R/0/1/0/all/0/1&quot;&gt;Risto Miikkulainen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.01244">
<title>Meta-Learning by Adjusting Priors Based on Extended PAC-Bayes Theory. (arXiv:1711.01244v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1711.01244</link>
<description rdf:parseType="Literal">&lt;p&gt;In meta-learning an agent extracts knowledge from observed tasks, aiming to
facilitate learning of novel future tasks. Under the assumption that future
tasks are &apos;related&apos; to previous tasks, representations should be learned in a
way which captures the common structure across learned tasks, while allowing
the learner sufficient flexibility to adapt to novel aspects of new tasks. We
present a framework for meta-learning that is based on generalization error
bounds, allowing us to extend various PAC-Bayes bounds to meta-learning.
Learning takes place through the construction of a distribution over hypotheses
based on the observed tasks, and its utilization for learning a new task. Thus,
prior knowledge is incorporated through setting an experience-dependent prior
for novel tasks. We develop a gradient-based algorithm which minimizes an
objective function derived from the bounds and demonstrate its effectiveness
numerically with deep neural networks. In addition to establishing the improved
performance available through meta-learning, we demonstrate the intuitive way
by which prior information is manifested at different levels of the network.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Amit_R/0/1/0/all/0/1&quot;&gt;Ron Amit&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Meir_R/0/1/0/all/0/1&quot;&gt;Ron Meir&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.09547">
<title>An Improved Tabu Search Heuristics for Static Dial-A-Ride Problem. (arXiv:1801.09547v4 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1801.09547</link>
<description rdf:parseType="Literal">&lt;p&gt;Multi-vehicle routing has become increasingly important with the rapid
development of autonomous vehicle technology. Dial-a-ride problem, a variant of
vehicle routing problem (VRP), deals with the allocation of customer requests
to vehicles, scheduling the pick-up and drop-off times and the sequence of
serving those requests by ensuring high customer satisfaction with minimized
travel cost. In this paper, we propose an improved tabu search (ITS) heuristic
for static dial-a-ride problem (DARP) with the objective of obtaining
high-quality solutions in short time. Two new techniques, initialization
heuristic, and time window adjustment are proposed to achieve faster
convergence to the global optimum. Various numerical experiments are conducted
for the proposed solution methodology using DARP test instances from the
literature and the convergence speed up is validated.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ho_S/0/1/0/all/0/1&quot;&gt;Songguang Ho&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nagavarapu_S/0/1/0/all/0/1&quot;&gt;Sarat Chandra Nagavarapu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pandi_R/0/1/0/all/0/1&quot;&gt;Ramesh Ramasamy Pandi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dauwels_J/0/1/0/all/0/1&quot;&gt;Justin Dauwels&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.03390">
<title>Not-So-CLEVR: Visual Relations Strain Feedforward Neural Networks. (arXiv:1802.03390v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1802.03390</link>
<description rdf:parseType="Literal">&lt;p&gt;The robust and efficient recognition of visual relations in images is a
hallmark of biological vision. Here, we argue that, despite recent progress in
visual recognition, modern machine vision algorithms are severely limited in
their ability to learn visual relations. Through controlled experiments, we
demonstrate that visual-relation problems strain convolutional neural networks
(CNNs). The networks eventually break altogether when rote memorization becomes
impossible such as when the intra-class variability exceeds their capacity. We
further show that another type of feedforward network, called a relational
network (RN), which was shown to successfully solve seemingly difficult visual
question answering (VQA) problems on the CLEVR datasets, suffers similar
limitations. Motivated by the comparable success of biological vision, we argue
that feedback mechanisms including working memory and attention are the key
computational components underlying abstract visual reasoning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ricci_M/0/1/0/all/0/1&quot;&gt;Matthew Ricci&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1&quot;&gt;Junkyung Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Serre_T/0/1/0/all/0/1&quot;&gt;Thomas Serre&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04302">
<title>Evaluating Compositionality in Sentence Embeddings. (arXiv:1802.04302v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1802.04302</link>
<description rdf:parseType="Literal">&lt;p&gt;An important frontier in the quest for human-like AI is compositional
semantics: how do we design systems that understand an infinite number of
expressions built from a finite vocabulary? Recent research has attempted to
solve this problem by using deep neural networks to learn vector space
embeddings of sentences, which then serve as input to supervised learning
problems like paraphrase detection and sentiment analysis. Here we focus on
&apos;natural language inference&apos; (NLI) as a critical test of a system&apos;s capacity
for semantic compositionality. In the NLI task, sentence pairs are assigned one
of three categories: entailment, contradiction, or neutral. We present a new
set of NLI sentence pairs that cannot be solved using only word-level knowledge
and instead require some degree of compositionality. We use state of the art
sentence embeddings trained on NLI (InferSent, Conneau et al. (2017)), and find
that performance on our new dataset is poor, indicating that the
representations learned by this model fail to capture the needed
compositionality. We analyze some of the decision rules learned by InferSent
and find that they are largely driven by simple heuristics at the word level
that are ecologically valid in the SNLI dataset on which InferSent is trained.
Further, we find that augmenting the training dataset with our new dataset
improves performance on a held-out test set without loss of performance on the
SNLI test set. This highlights the importance of structured datasets in better
understanding, as well as improving the performance of, AI systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dasgupta_I/0/1/0/all/0/1&quot;&gt;Ishita Dasgupta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_D/0/1/0/all/0/1&quot;&gt;Demi Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stuhlmuller_A/0/1/0/all/0/1&quot;&gt;Andreas Stuhlm&amp;#xfc;ller&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gershman_S/0/1/0/all/0/1&quot;&gt;Samuel J. Gershman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goodman_N/0/1/0/all/0/1&quot;&gt;Noah D. Goodman&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04350">
<title>On the Sample Complexity of Learning from a Sequence of Experiments. (arXiv:1802.04350v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.04350</link>
<description rdf:parseType="Literal">&lt;p&gt;We analyze the sample complexity of a new problem: learning from a sequence
of experiments. In this problem, the learner should choose a hypothesis that
performs well with respect to an infinite sequence of experiments, and their
related data distributions. In practice, the learner can only perform m
experiments with a total of N samples drawn from those data distributions. By
using a Rademacher complexity approach, we show that the gap between the
training and generation error is O((m/N)^0.5). We also provide some examples
for linear prediction, two-layer neural networks and kernel methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_L/0/1/0/all/0/1&quot;&gt;Longyun Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Honorio_J/0/1/0/all/0/1&quot;&gt;Jean Honorio&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Morgan_J/0/1/0/all/0/1&quot;&gt;John Morgan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04376">
<title>Few-Shot Learning with Metric-Agnostic Conditional Embeddings. (arXiv:1802.04376v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.04376</link>
<description rdf:parseType="Literal">&lt;p&gt;Learning high quality class representations from few examples is a key
problem in metric-learning approaches to few-shot learning. To accomplish this,
we introduce a novel architecture where class representations are conditioned
for each few-shot trial based on a target image. We also deviate from
traditional metric-learning approaches by training a network to perform
comparisons between classes rather than relying on a static metric comparison.
This allows the network to decide what aspects of each class are important for
the comparison at hand. We find that this flexible architecture works well in
practice, achieving state-of-the-art performance on the Caltech-UCSD birds
fine-grained classification task.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hilliard_N/0/1/0/all/0/1&quot;&gt;Nathan Hilliard&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Phillips_L/0/1/0/all/0/1&quot;&gt;Lawrence Phillips&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Howland_S/0/1/0/all/0/1&quot;&gt;Scott Howland&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yankov_A/0/1/0/all/0/1&quot;&gt;Art&amp;#xeb;m Yankov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Corley_C/0/1/0/all/0/1&quot;&gt;Courtney D. Corley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hodas_N/0/1/0/all/0/1&quot;&gt;Nathan O. Hodas&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04420">
<title>Towards Understanding the Generalization Bias of Two Layer Convolutional Linear Classifiers with Gradient Descent. (arXiv:1802.04420v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.04420</link>
<description rdf:parseType="Literal">&lt;p&gt;A major challenge in understanding the generalization of deep learning is to
explain why (stochastic) gradient descent can exploit the network architecture
to find solutions that have good generalization performance when using high
capacity models. We find simple but realistic examples showing that this
phenomenon exists even when learning linear classifiers --- between two linear
networks with the same capacity, the one with a convolutional layer can
generalize better than the other when the data distribution has some underlying
spatial structure. We argue that this difference results from a combination of
the convolution architecture, data distribution and gradient descent, all of
which are necessary to be included in a meaningful analysis. We provide a
general analysis of the generalization performance as a function of data
distribution and convolutional filter size, given gradient descent as the
optimization algorithm, then interpret the results using concrete examples.
Experimental results show that our analysis is able to explain what happens in
our introduced examples.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1&quot;&gt;Yifan Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Poczos_B/0/1/0/all/0/1&quot;&gt;Barnabas Poczos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1&quot;&gt;Aarti Singh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04431">
<title>Detecting Spacecraft Anomalies Using LSTMs and Nonparametric Dynamic Thresholding. (arXiv:1802.04431v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.04431</link>
<description rdf:parseType="Literal">&lt;p&gt;As spacecraft send back increasing amounts of telemetry data, improved
anomaly detection systems are needed to lessen the monitoring burden placed on
operations engineers and reduce operational risk. Current spacecraft monitoring
systems only target a subset of anomaly types and often require costly expert
knowledge to develop and maintain due to challenges involving scale and
complexity. We demonstrate the effectiveness of Long Short-Term Memory (LSTMs)
networks, a type of Recurrent Neural Network (RNN), in overcoming these issues
using expert-labeled telemetry anomaly data from the Soil Moisture Active
Passive (SMAP) satellite and the Mars Science Laboratory (MSL) rover,
Curiosity. We also propose a complementary unsupervised and nonparametric
anomaly thresholding approach developed during a pilot implementation of an
anomaly detection system for SMAP, and offer false positive mitigation
strategies along with other key improvements and lessons learned during
development.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hundman_K/0/1/0/all/0/1&quot;&gt;Kyle Hundman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Constantinou_V/0/1/0/all/0/1&quot;&gt;Valentino Constantinou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Laporte_C/0/1/0/all/0/1&quot;&gt;Christopher Laporte&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Colwell_I/0/1/0/all/0/1&quot;&gt;Ian Colwell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Soderstrom_T/0/1/0/all/0/1&quot;&gt;Tom Soderstrom&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04551">
<title>Analysis of Minimax Error Rate for Crowdsourcing and Its Application to Worker Clustering Model. (arXiv:1802.04551v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.04551</link>
<description rdf:parseType="Literal">&lt;p&gt;While crowdsourcing has become an important means to label data, crowdworkers
are not always experts---sometimes they can even be adversarial. Therefore,
there is great interest in estimating the ground truth from unreliable labels
produced by crowdworkers. The Dawid and Skene (DS) model is one of the most
well-known models in the study of crowdsourcing. Despite its practical
popularity, theoretical error analysis for the DS model has been conducted only
under restrictive assumptions on, e.g., class priors, confusion matrices, and
the number of labels each worker provides. In this paper, we derive a minimax
error rate under more practical setting for a broader class of crowdsourcing
models that includes the DS model as a special case. We further propose the
worker clustering model, which is more practical than the DS model under real
crowdsourcing settings. Note that the wide applicability of our theoretical
analysis allows us to immediately investigate the behavior of this proposed
model. Experimental results showed that there is a strong similarity between
the lower bound of the minimax error rate derived by our theoretical analysis
and the empirical error of the estimated value.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Imamura_H/0/1/0/all/0/1&quot;&gt;Hideaki Imamura&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sato_I/0/1/0/all/0/1&quot;&gt;Issei Sato&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sugiyama_M/0/1/0/all/0/1&quot;&gt;Masashi Sugiyama&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04591">
<title>First Order Generative Adversarial Networks. (arXiv:1802.04591v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.04591</link>
<description rdf:parseType="Literal">&lt;p&gt;GANs excel at learning high dimensional distributions, but they can update
generator parameters in directions that do not correspond to the steepest
descent direction of the objective. Prominent examples of problematic update
directions include those used in both Goodfellow&apos;s original GAN and the
WGAN-GP. To formally describe an optimal update direction, we introduce a
theoretical framework which allows the derivation of requirements on both the
divergence and corresponding method for determining an update direction. These
requirements guarantee unbiased mini-batch updates in the direction of steepest
descent. We propose a novel divergence which approximates the Wasserstein
distance while regularizing the critic&apos;s first order information. Together with
an accompanying update direction, this divergence fulfills the requirements for
unbiased steepest descent updates. We verify our method, the First Order GAN,
with CelebA image generation and set a new state of the art on the One Billion
Word language generation task.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Seward_C/0/1/0/all/0/1&quot;&gt;Calvin Seward&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Unterthiner_T/0/1/0/all/0/1&quot;&gt;Thomas Unterthiner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bergmann_U/0/1/0/all/0/1&quot;&gt;Urs Bergmann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jetchev_N/0/1/0/all/0/1&quot;&gt;Nikolay Jetchev&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hochreiter_S/0/1/0/all/0/1&quot;&gt;Sepp Hochreiter&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04626">
<title>Barista - a Graphical Tool for Designing and Training Deep Neural Networks. (arXiv:1802.04626v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.04626</link>
<description rdf:parseType="Literal">&lt;p&gt;In recent years, the importance of deep learning has significantly increased
in pattern recognition, computer vision, and artificial intelligence research,
as well as in industry. However, despite the existence of multiple deep
learning frameworks, there is a lack of comprehensible and easy-to-use
high-level tools for the design, training, and testing of deep neural networks
(DNNs). In this paper, we introduce Barista, an open-source graphical
high-level interface for the Caffe deep learning framework. While Caffe is one
of the most popular frameworks for training DNNs, editing prototext files in
order to specify the net architecture and hyper parameters can become a
cumbersome and error-prone task. Instead, Barista offers a fully graphical user
interface with a graph-based net topology editor and provides an end-to-end
training facility for DNNs, which allows researchers to focus on solving their
problems without having to write code, edit text files, or manually parse
logged data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Klemm_S/0/1/0/all/0/1&quot;&gt;Soeren Klemm&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Scherzinger_A/0/1/0/all/0/1&quot;&gt;Aaron Scherzinger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Drees_D/0/1/0/all/0/1&quot;&gt;Dominik Drees&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_X/0/1/0/all/0/1&quot;&gt;Xiaoyi Jiang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04684">
<title>Unsupervised Evaluation and Weighted Aggregation of Ranked Predictions. (arXiv:1802.04684v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.04684</link>
<description rdf:parseType="Literal">&lt;p&gt;Learning algorithms that aggregate predictions from an ensemble of diverse
base classifiers consistently outperform individual methods. Many of these
strategies have been developed in a supervised setting, where the accuracy of
each base classifier can be empirically measured and this information is
incorporated in the training process. However, the reliance on labeled data
precludes the application of ensemble methods to many real world problems where
labeled data has not been curated. To this end we developed a new theoretical
framework for binary classification, the Strategy for Unsupervised Multiple
Method Aggregation (SUMMA), to estimate the performances of base classifiers
and an optimal strategy for ensemble learning from unlabeled data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ahsen_M/0/1/0/all/0/1&quot;&gt;Mehmet Eren Ahsen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Vogel_R/0/1/0/all/0/1&quot;&gt;Robert Vogel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Stolovitzky_G/0/1/0/all/0/1&quot;&gt;Gustavo Stolovitzky&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1703.00607">
<title>Dynamic Word Embeddings for Evolving Semantic Discovery. (arXiv:1703.00607v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1703.00607</link>
<description rdf:parseType="Literal">&lt;p&gt;Word evolution refers to the changing meanings and associations of words
throughout time, as a byproduct of human language evolution. By studying word
evolution, we can infer social trends and language constructs over different
periods of human history. However, traditional techniques such as word
representation learning do not adequately capture the evolving language
structure and vocabulary. In this paper, we develop a dynamic statistical model
to learn time-aware word vector representation. We propose a model that
simultaneously learns time-aware embeddings and solves the resulting &quot;alignment
problem&quot;. This model is trained on a crawled NYTimes dataset. Additionally, we
develop multiple intuitive evaluation strategies of temporal word embeddings.
Our qualitative and quantitative tests indicate that our method not only
reliably captures this evolution over time, but also consistently outperforms
state-of-the-art temporal embedding approaches on both semantic accuracy and
alignment quality.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yao_Z/0/1/0/all/0/1&quot;&gt;Zijun Yao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1&quot;&gt;Yifan Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ding_W/0/1/0/all/0/1&quot;&gt;Weicong Ding&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rao_N/0/1/0/all/0/1&quot;&gt;Nikhil Rao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiong_H/0/1/0/all/0/1&quot;&gt;Hui Xiong&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.00141">
<title>Training GANs with Optimism. (arXiv:1711.00141v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1711.00141</link>
<description rdf:parseType="Literal">&lt;p&gt;We address the issue of limit cycling behavior in training Generative
Adversarial Networks and propose the use of Optimistic Mirror Decent (OMD) for
training Wasserstein GANs. Recent theoretical results have shown that
optimistic mirror decent (OMD) can enjoy faster regret rates in the context of
zero-sum games. WGANs is exactly a context of solving a zero-sum game with
simultaneous no-regret dynamics. Moreover, we show that optimistic mirror
decent addresses the limit cycling problem in training WGANs. We formally show
that in the case of bi-linear zero-sum games the last iterate of OMD dynamics
converges to an equilibrium, in contrast to GD dynamics which are bound to
cycle. We also portray the huge qualitative difference between GD and OMD
dynamics with toy examples, even when GD is modified with many adaptations
proposed in the recent literature, such as gradient penalty or momentum. We
apply OMD WGAN training to a bioinformatics problem of generating DNA
sequences. We observe that models trained with OMD achieve consistently smaller
KL divergence with respect to the true underlying distribution, than models
trained with GD variants. Finally, we introduce a new algorithm, Optimistic
Adam, which is an optimistic variant of Adam. We apply it to WGAN training on
CIFAR10 and observe improved performance in terms of inception score as
compared to Adam.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Daskalakis_C/0/1/0/all/0/1&quot;&gt;Constantinos Daskalakis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ilyas_A/0/1/0/all/0/1&quot;&gt;Andrew Ilyas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Syrgkanis_V/0/1/0/all/0/1&quot;&gt;Vasilis Syrgkanis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zeng_H/0/1/0/all/0/1&quot;&gt;Haoyang Zeng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.08277">
<title>Few-shot Learning by Exploiting Visual Concepts within CNNs. (arXiv:1711.08277v3 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1711.08277</link>
<description rdf:parseType="Literal">&lt;p&gt;Convolutional neural networks (CNNs) are one of the driving forces for the
advancement of computer vision. Despite their promising performances on many
tasks, CNNs still face major obstacles on the road to achieving ideal machine
intelligence. One is that CNNs are complex and hard to interpret. Another is
that standard CNNs require large amounts of annotated data, which is sometimes
hard to obtain, and it is desirable to learn to recognize objects from few
examples. In this work, we address these limitations of CNNs by developing
novel, flexible, and interpretable models for few-shot learning. Our models are
based on the idea of encoding objects in terms of visual concepts (VCs), which
are interpretable visual cues represented by the feature vectors within CNNs.
We first adapt the learning of VCs to the few-shot setting, and then uncover
two key properties of feature encoding using VCs, which we call category
sensitivity and spatial pattern. Motivated by these properties, we present two
intuitive models for the problem of few-shot learning. Experiments show that
our models achieve competitive performances, while being more flexible and
interpretable than alternative state-of-the-art few-shot learning methods. We
conclude that using VCs helps expose the natural capability of CNNs for
few-shot learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deng_B/0/1/0/all/0/1&quot;&gt;Boyang Deng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1&quot;&gt;Qing Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qiao_S/0/1/0/all/0/1&quot;&gt;Siyuan Qiao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yuille_A/0/1/0/all/0/1&quot;&gt;Alan Yuille&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.02125">
<title>Threshold Auto-Tuning Metric Learning. (arXiv:1801.02125v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1801.02125</link>
<description rdf:parseType="Literal">&lt;p&gt;It has been reported repeatedly that discriminative learning of distance
metric boosts the pattern recognition performance. A weak point of ITML-based
methods is that the distance threshold for similarity/dissimilarity constraints
must be determined manually and it is sensitive to generalization performance,
although the ITML-based methods enjoy an advantage that the Bregman projection
framework can be applied for optimization of distance metric. In this paper, we
present a new formulation of metric learning algorithm in which the distance
threshold is optimized together. Since the optimization is still in the Bregman
projection framework, the Dykstra algorithm can be applied for optimization. A
nonlinear equation has to be solved to project the solution onto a half-space
in each iteration. Na\&quot;{i}ve method takes $O(LMn^{3})$ computational time to
solve the nonlinear equation. In this study, an efficient technique that can
solve the nonlinear equation in $O(Mn^{3})$ has been discovered. We have proved
that the root exists and is unique. We empirically show that the accuracy of
pattern recognition for the proposed metric learning algorithm is comparable to
the existing metric learning methods, yet the distance threshold is
automatically tuned for the proposed metric learning algorithm.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Onuma_Y/0/1/0/all/0/1&quot;&gt;Yuya Onuma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rivero_R/0/1/0/all/0/1&quot;&gt;Rachelle Rivero&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kato_T/0/1/0/all/0/1&quot;&gt;Tsuyoshi Kato&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.07756">
<title>Deep Learning for Electromyographic Hand Gesture Signal Classification by Leveraging Transfer Learning. (arXiv:1801.07756v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1801.07756</link>
<description rdf:parseType="Literal">&lt;p&gt;In recent years, the use of deep learning algorithms has become increasingly
more prominent. Within the field of electromyography-based gesture recognition
however, deep learning algorithms are seldom employed. This is due in part to
the large quantity of data required for the network to train on. The data
sparsity arises from the fact that it would take an unreasonable amount of time
for a single person to generate tens of thousands of examples for training such
algorithms. In this paper, two datasets are recorded with the Myo Armband
(Thalmic Labs), a low-cost, low-sampling rate (200Hz), 8-channel,
consumer-grade, dry electrode sEMG armband. These datasets, referred to as the
pre-training and evaluation dataset, are comprised of 19 and 17 able-bodied
participants respectively. A convolutional network (ConvNet) is augmented with
transfer learning techniques to leverage inter-user data from the first
dataset, alleviating the burden imposed on a single individual to generate a
vast quantity of training data for sEMG-based gesture recognition. This
transfer learning scheme is shown to outperform the current state-of-the-art in
gesture recognition achieving an average accuracy of 98.31% for 7 hand/wrist
gestures over 17 able-bodied participants. Finally, a use-case study of eight
able-bodied participants is presented to evaluate the impact of feedback on the
degradation accuracy normally experienced from a classifier over time.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cote_Allard_U/0/1/0/all/0/1&quot;&gt;Ulysse C&amp;#xf4;t&amp;#xe9;-Allard&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fall_C/0/1/0/all/0/1&quot;&gt;Cheikh Latyr Fall&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Drouin_A/0/1/0/all/0/1&quot;&gt;Alexandre Drouin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Campeau_Lecours_A/0/1/0/all/0/1&quot;&gt;Alexandre Campeau-Lecours&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gosselin_C/0/1/0/all/0/1&quot;&gt;Cl&amp;#xe9;ment Gosselin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Glette_K/0/1/0/all/0/1&quot;&gt;Kyrre Glette&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Laviolette_F/0/1/0/all/0/1&quot;&gt;Fran&amp;#xe7;ois Laviolette&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gosselin_B/0/1/0/all/0/1&quot;&gt;Benoit Gosselin&lt;/a&gt;</dc:creator>
</item></rdf:RDF>