<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Good papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Good Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-06-10T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02942"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02957"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02960"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02997"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1703.05051"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.04439"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02847"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02891"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02901"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.03256"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.01244"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05438"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.00094"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.07131"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.07090"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07039"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08877"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02825"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02863"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02865"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02924"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02934"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02978"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.03107"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.03168"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.03207"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.03190"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.03878"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.04062"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06403"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09128"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.03148"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.09050"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11921"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02338"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1806.02942">
<title>SupportNet: solving catastrophic forgetting in class incremental learning with support data. (arXiv:1806.02942v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1806.02942</link>
<description rdf:parseType="Literal">&lt;p&gt;A plain well-trained deep learning model often does not have the ability to
learn new knowledge without forgetting the previously learned knowledge, which
is known as the catastrophic forgetting. Here we propose a novel method,
SupportNet, to solve the catastrophic forgetting problem in class incremental
learning scenario efficiently and effectively. SupportNet combines the strength
of deep learning and support vector machine (SVM), where SVM is used to
identify the support data from the old data, which are fed to the deep learning
model together with the new data for further training so that the model can
review the essential information of the old data when learning the new
information. Two powerful consolidation regularizers are applied to ensure the
robustness of the learned model. Comprehensive experiments on various tasks,
including enzyme function prediction, subcellular structure classification and
breast tumor classification, show that SupportNet drastically outperforms the
state-of-the-art incremental learning methods and even reaches similar
performance as the deep learning model trained from scratch on both old and new
data. Our program is accessible at: https://github.com/lykaust15/SupportNet
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yu Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Zhongxiao Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ding_L/0/1/0/all/0/1&quot;&gt;Lizhong Ding&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_P/0/1/0/all/0/1&quot;&gt;Peng Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1&quot;&gt;Yuhui Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1&quot;&gt;Wei Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_X/0/1/0/all/0/1&quot;&gt;Xin Gao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02957">
<title>A Deep Neural Network Surrogate for High-Dimensional Random Partial Differential Equations. (arXiv:1806.02957v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.02957</link>
<description rdf:parseType="Literal">&lt;p&gt;Developing efficient numerical algorithms for high dimensional random Partial
Differential Equations (PDEs) has been a challenging task due to the well-known
curse of dimensionality problem. We present a new framework for solving
high-dimensional PDEs characterized by random parameters based on a deep
learning approach. The random PDE is approximated by a feed-forward
fully-connected deep neural network, with either strong or weak enforcement of
initial and boundary constraints. The framework is mesh-free, and can handle
irregular computational domains. Parameters of the approximating deep neural
network are determined iteratively using variants of the Stochastic Gradient
Descent (SGD) algorithm, which removes the memory issues that some existing
algorithms for random PDEs are currently experiencing. The performance of the
proposed framework in accurate estimation of solution to random PDEs is
examined by implementing it for diffusion and heat conduction problems. Results
are compared with the sampling-based finite element results, and suggest that
the proposed framework achieves satisfactory accuracy and can handle
high-dimensional random PDEs. A discussion on the advantages of the proposed
method is also provided.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nabian_M/0/1/0/all/0/1&quot;&gt;Mohammad Amin Nabian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meidani_H/0/1/0/all/0/1&quot;&gt;Hadi Meidani&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02960">
<title>Representation Learning of Entities and Documents from Knowledge Base Descriptions. (arXiv:1806.02960v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1806.02960</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we describe TextEnt, a neural network model that learns
distributed representations of entities and documents directly from a knowledge
base (KB). Given a document in a KB consisting of words and entity annotations,
we train our model to predict the entity that the document describes and map
the document and its target entity close to each other in a continuous vector
space. Our model is trained using a large number of documents extracted from
Wikipedia. The performance of the proposed model is evaluated using two tasks,
namely fine-grained entity typing and multiclass text classification. The
results demonstrate that our model achieves state-of-the-art performance on
both tasks. The code and the trained representations are made available online
for further academic research.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yamada_I/0/1/0/all/0/1&quot;&gt;Ikuya Yamada&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shindo_H/0/1/0/all/0/1&quot;&gt;Hiroyuki Shindo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Takefuji_Y/0/1/0/all/0/1&quot;&gt;Yoshiyasu Takefuji&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02997">
<title>q-Space Novelty Detection with Variational Autoencoders. (arXiv:1806.02997v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.02997</link>
<description rdf:parseType="Literal">&lt;p&gt;In machine learning, novelty detection is the task of identifying novel
unseen data. During training, only samples from the normal class are available.
Test samples are classified as normal or abnormal by assignment of a novelty
score. Here we propose novelty detection methods based on training variational
autoencoders (VAEs) on normal data. Since abnormal samples are not used during
training, we define novelty metrics based on the (partially complementary)
assumptions that the VAE is less capable of reconstructing abnormal samples
well; that abnormal samples more strongly violate the VAE regularizer; and that
abnormal samples differ from normal samples not only in input-feature space,
but also in the VAE latent space and VAE output. These approaches, combined
with various possibilities of using (e.g.~sampling) the probabilistic VAE to
obtain scalar novelty scores, yield a large family of methods. We apply these
methods to magnetic resonance imaging, namely to the detection of
diffusion-space (\mbox{q-space}) abnormalities in diffusion MRI scans of
multiple sclerosis patients, i.e.~to detect multiple sclerosis lesions without
using any lesion labels for training. Many of our methods outperform previously
proposed q-space novelty detection methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Vasilev_A/0/1/0/all/0/1&quot;&gt;Aleksei Vasilev&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Golkov_V/0/1/0/all/0/1&quot;&gt;Vladimir Golkov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lipp_I/0/1/0/all/0/1&quot;&gt;Ilona Lipp&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sgarlata_E/0/1/0/all/0/1&quot;&gt;Eleonora Sgarlata&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tomassini_V/0/1/0/all/0/1&quot;&gt;Valentina Tomassini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Jones_D/0/1/0/all/0/1&quot;&gt;Derek K. Jones&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Cremers_D/0/1/0/all/0/1&quot;&gt;Daniel Cremers&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1703.05051">
<title>Deep learning with convolutional neural networks for EEG decoding and visualization. (arXiv:1703.05051v5 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1703.05051</link>
<description rdf:parseType="Literal">&lt;p&gt;PLEASE READ AND CITE THE REVISED VERSION at Human Brain Mapping:
&lt;a href=&quot;http://onlinelibrary.wiley.com/doi/10.1002/hbm.23730/full&quot;&gt;this http URL&lt;/a&gt;
&lt;/p&gt;
&lt;p&gt;Code available here: https://github.com/robintibor/braindecode
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schirrmeister_R/0/1/0/all/0/1&quot;&gt;Robin Tibor Schirrmeister&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Springenberg_J/0/1/0/all/0/1&quot;&gt;Jost Tobias Springenberg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fiederer_L/0/1/0/all/0/1&quot;&gt;Lukas Dominique Josef Fiederer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Glasstetter_M/0/1/0/all/0/1&quot;&gt;Martin Glasstetter&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Eggensperger_K/0/1/0/all/0/1&quot;&gt;Katharina Eggensperger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tangermann_M/0/1/0/all/0/1&quot;&gt;Michael Tangermann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hutter_F/0/1/0/all/0/1&quot;&gt;Frank Hutter&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Burgard_W/0/1/0/all/0/1&quot;&gt;Wolfram Burgard&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ball_T/0/1/0/all/0/1&quot;&gt;Tonio Ball&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.04439">
<title>From Nodes to Networks: Evolving Recurrent Neural Networks. (arXiv:1803.04439v2 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1803.04439</link>
<description rdf:parseType="Literal">&lt;p&gt;Gated recurrent networks such as those composed of Long Short-Term Memory
(LSTM) nodes have recently been used to improve state of the art in many
sequential processing tasks such as speech recognition and machine translation.
However, the basic structure of the LSTM node is essentially the same as when
it was first conceived 25 years ago. Recently, evolutionary and reinforcement
learning mechanisms have been employed to create new variations of this
structure. This paper proposes a new method, evolution of a tree-based encoding
of the gated memory nodes, and shows that it makes it possible to explore new
variations more effectively than other methods. The method discovers nodes with
multiple recurrent paths and multiple memory cells, which lead to significant
improvement in the standard language modeling benchmark task. The paper also
shows how the search process can be speeded up by training an LSTM network to
estimate performance of candidate structures, and by encouraging exploration of
novel solutions. Thus, evolutionary design of complex neural network structures
promises to improve performance of deep learning architectures beyond human
ability to do so.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rawal_A/0/1/0/all/0/1&quot;&gt;Aditya Rawal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Miikkulainen_R/0/1/0/all/0/1&quot;&gt;Risto Miikkulainen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02847">
<title>A Simple Method for Commonsense Reasoning. (arXiv:1806.02847v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1806.02847</link>
<description rdf:parseType="Literal">&lt;p&gt;Commonsense reasoning is a long-standing challenge for deep learning. For
example, it is difficult to use neural networks to tackle the Winograd Schema
dataset~\cite{levesque2011winograd}. In this paper, we present a simple method
for commonsense reasoning with neural networks, using unsupervised learning.
Key to our method is the use of language models, trained on a massive amount of
unlabled data, to score multiple choice questions posed by commonsense
reasoning tests. On both Pronoun Disambiguation and Winograd Schema challenges,
our models outperform previous state-of-the-art methods by a large margin,
without using expensive annotated knowledge bases or hand-engineered features.
We train an array of large RNN language models that operate at word or
character level on LM-1-Billion, CommonCrawl, SQuAD, Gutenberg Books, and a
customized corpus for this task and show that diversity of training data plays
an important role in test performance. Further analysis also shows that our
system successfully discovers important features of the context that decide the
correct answer, indicating a good grasp of commonsense knowledge.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Trinh_T/0/1/0/all/0/1&quot;&gt;Trieu H. Trinh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Le_Q/0/1/0/all/0/1&quot;&gt;Quoc V. Le&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02891">
<title>Revisiting the Importance of Individual Units in CNNs via Ablation. (arXiv:1806.02891v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1806.02891</link>
<description rdf:parseType="Literal">&lt;p&gt;We revisit the importance of the individual units in Convolutional Neural
Networks (CNNs) for visual recognition. By conducting unit ablation experiments
on CNNs trained on large scale image datasets, we demonstrate that, though
ablating any individual unit does not hurt overall classification accuracy, it
does lead to significant damage on the accuracy of specific classes. This
result shows that an individual unit is specialized to encode information
relevant to a subset of classes. We compute the correlation between the
accuracy drop under unit ablation and various attributes of an individual unit
such as class selectivity and weight L1 norm. We confirm that unit attributes
such as class selectivity are a poor predictor for impact on overall accuracy
as found previously in recent work \cite{morcos2018importance}. However, our
results show that class selectivity along with other attributes are good
predictors of the importance of one unit to individual classes. We evaluate the
impact of random rotation, batch normalization, and dropout to the importance
of units to specific classes. Our results show that units with high selectivity
play an important role in network classification power at the individual class
level. Understanding and interpreting the behavior of these units is necessary
and meaningful.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_B/0/1/0/all/0/1&quot;&gt;Bolei Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1&quot;&gt;Yiyou Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bau_D/0/1/0/all/0/1&quot;&gt;David Bau&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Torralba_A/0/1/0/all/0/1&quot;&gt;Antonio Torralba&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02901">
<title>Probabilistic FastText for Multi-Sense Word Embeddings. (arXiv:1806.02901v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1806.02901</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce Probabilistic FastText, a new model for word embeddings that can
capture multiple word senses, sub-word structure, and uncertainty information.
In particular, we represent each word with a Gaussian mixture density, where
the mean of a mixture component is given by the sum of n-grams. This
representation allows the model to share statistical strength across sub-word
structures (e.g. Latin roots), producing accurate representations of rare,
misspelt, or even unseen words. Moreover, each component of the mixture can
capture a different word sense. Probabilistic FastText outperforms both
FastText, which has no probabilistic model, and dictionary-level probabilistic
embeddings, which do not incorporate subword structures, on several
word-similarity benchmarks, including English RareWord and foreign language
datasets. We also achieve state-of-art performance on benchmarks that measure
ability to discern different meanings. Thus, the proposed model is the first to
achieve multi-sense representations while having enriched semantics on rare
words.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Athiwaratkun_B/0/1/0/all/0/1&quot;&gt;Ben Athiwaratkun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wilson_A/0/1/0/all/0/1&quot;&gt;Andrew Gordon Wilson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Anandkumar_A/0/1/0/all/0/1&quot;&gt;Anima Anandkumar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.03256">
<title>Incorporating Features Learned by an Enhanced Deep Knowledge Tracing Model for STEM/Non-STEM Job Prediction. (arXiv:1806.03256v1 [cs.CY])</title>
<link>http://arxiv.org/abs/1806.03256</link>
<description rdf:parseType="Literal">&lt;p&gt;The 2017 ASSISTments Data Mining competition aims to use data from a
longitudinal study for predicting a brand-new outcome of students which had
never been studied before by the educational data mining research community.
Specifically, it facilitates research in developing predictive models that
predict whether the first job of a student out of college belongs to a STEM
(the acronym for science, technology, engineering, and mathematics) field. This
is based on the student&apos;s learning history on the ASSISTments blended learning
platform in the form of extensive clickstream data gathered during the middle
school years. To tackle this challenge, we first estimate the expected
knowledge state of students with respect to different mathematical skills using
a deep knowledge tracing (DKT) model and an enhanced DKT (DKT+) model. We then
combine the features corresponding to the DKT/DKT+ expected knowledge state
with other features extracted directly from the student profile in the dataset
to train several machine learning models for the STEM/non-STEM job prediction.
Our experiments show that models trained with the combined features generally
perform better than the models trained with the student profile alone. Detailed
analysis of the student&apos;s knowledge state reveals that, when compared with
non-STEM students, STEM students generally show a higher mastery level and a
higher learning gain in mathematics.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yeung_C/0/1/0/all/0/1&quot;&gt;Chun-kit Yeung&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1&quot;&gt;Zizheng Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_K/0/1/0/all/0/1&quot;&gt;Kai Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yeung_D/0/1/0/all/0/1&quot;&gt;Dit-yan Yeung&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.01244">
<title>Meta-Learning by Adjusting Priors Based on Extended PAC-Bayes Theory. (arXiv:1711.01244v6 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1711.01244</link>
<description rdf:parseType="Literal">&lt;p&gt;In meta-learning an agent extracts knowledge from observed tasks, aiming to
facilitate learning of novel future tasks. Under the assumption that future
tasks are &apos;related&apos; to previous tasks, representations should be learned in a
way which captures the common structure across learned tasks, while allowing
the learner sufficient flexibility to adapt to novel aspects of new tasks. We
present a framework for meta-learning that is based on generalization error
bounds, allowing us to extend various PAC-Bayes bounds to meta-learning.
Learning takes place through the construction of a distribution over hypotheses
based on the observed tasks, and its utilization for learning a new task. Thus,
prior knowledge is incorporated through setting an experience-dependent prior
for novel tasks. We develop a gradient-based algorithm which minimizes an
objective function derived from the bounds and demonstrate its effectiveness
numerically with deep neural networks. In addition to establishing the improved
performance available through meta-learning, we demonstrate the intuitive way
by which prior information is manifested at different levels of the network.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Amit_R/0/1/0/all/0/1&quot;&gt;Ron Amit&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Meir_R/0/1/0/all/0/1&quot;&gt;Ron Meir&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05438">
<title>Mean Field Multi-Agent Reinforcement Learning. (arXiv:1802.05438v2 [cs.MA] UPDATED)</title>
<link>http://arxiv.org/abs/1802.05438</link>
<description rdf:parseType="Literal">&lt;p&gt;Existing multi-agent reinforcement learning methods are limited typically to
a small number of agents. When the agent number increases largely, the learning
becomes intractable due to the curse of the dimensionality and the exponential
growth of agent interactions. In this paper, we present Mean Field
Reinforcement Learning where the interactions within the population of agents
are approximated by those between a single agent and the average effect from
the overall population or neighboring agents; the interplay between the two
entities is mutually reinforced: the learning of the individual agent&apos;s optimal
policy depends on the dynamics of the population, while the dynamics of the
population change according to the collective patterns of the individual
policies. We develop practical mean field Q-learning and mean field
Actor-Critic algorithms and analyze the convergence of the solution to Nash
equilibrium. Experiments on Gaussian squeeze, Ising model, and battle games
justify the learning effectiveness of our mean field approaches. In addition,
we report the first result to solve the Ising model via model-free
reinforcement learning methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1&quot;&gt;Yaodong Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_R/0/1/0/all/0/1&quot;&gt;Rui Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1&quot;&gt;Minne Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1&quot;&gt;Ming Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1&quot;&gt;Weinan Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jun Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.00094">
<title>Neural Networks Should Be Wide Enough to Learn Disconnected Decision Regions. (arXiv:1803.00094v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1803.00094</link>
<description rdf:parseType="Literal">&lt;p&gt;In the recent literature the important role of depth in deep learning has
been emphasized. In this paper we argue that sufficient width of a feedforward
network is equally important by answering the simple question under which
conditions the decision regions of a neural network are connected. It turns out
that for a class of activation functions including leaky ReLU, neural networks
having a pyramidal structure, that is no layer has more hidden units than the
input dimension, produce necessarily connected decision regions. This implies
that a sufficiently wide hidden layer is necessary to guarantee that the
network can produce disconnected decision regions. We discuss the implications
of this result for the construction of neural networks, in particular the
relation to the problem of adversarial manipulation of classifiers.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_Q/0/1/0/all/0/1&quot;&gt;Quynh Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mukkamala_M/0/1/0/all/0/1&quot;&gt;Mahesh Chandra Mukkamala&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hein_M/0/1/0/all/0/1&quot;&gt;Matthias Hein&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.07131">
<title>Automated Curriculum Learning by Rewarding Temporally Rare Events. (arXiv:1803.07131v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1803.07131</link>
<description rdf:parseType="Literal">&lt;p&gt;Reward shaping allows reinforcement learning (RL) agents to accelerate
learning by receiving additional reward signals. However, these signals can be
difficult to design manually, especially for complex RL tasks. We propose a
simple and general approach that determines the reward of pre-defined events by
their rarity alone. Here events become less rewarding as they are experienced
more often, which encourages the agent to continually explore new types of
events as it learns. The adaptiveness of this reward function results in a form
of automated curriculum learning that does not have to be specified by the
experimenter. We demonstrate that this \emph{Rarity of Events} (RoE) approach
enables the agent to succeed in challenging VizDoom scenarios without access to
the extrinsic reward from the environment. Furthermore, the results demonstrate
that RoE learns a more versatile policy that adapts well to critical changes in
the environment. Rewarding events based on their rarity could help in many
unsolved RL environments that are characterized by sparse extrinsic rewards but
a plethora of known event types.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Justesen_N/0/1/0/all/0/1&quot;&gt;Niels Justesen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Risi_S/0/1/0/all/0/1&quot;&gt;Sebastian Risi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.07090">
<title>Low Rank Structure of Learned Representations. (arXiv:1804.07090v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1804.07090</link>
<description rdf:parseType="Literal">&lt;p&gt;A key feature of neural networks, particularly deep convolutional neural
networks, is their ability to &quot;learn&quot; useful representations from data. The
very last layer of a neural network is then simply a linear model trained on
these &quot;learned&quot; representations. Despite their numerous applications in other
tasks such as classification, retrieval, clustering etc., a.k.a. transfer
learning, not much work has been published that investigates the structure of
these representations or indeed whether structure can be imposed on them during
the training process.
&lt;/p&gt;
&lt;p&gt;In this paper, we study the effective dimensionality of the learned
representations by models that have proved highly successful for image
classification. We focus on ResNet-18, ResNet-50 and VGG-19 and observe that
when trained on CIFAR10 or CIFAR100, the learned representations exhibit a
fairly low rank structure. We propose a modification to the training procedure,
which further encourages low rank structure on learned activations.
Empirically, we show that this has implications for robustness to
\emph{adversarial examples} and \emph{compression}.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sanyal_A/0/1/0/all/0/1&quot;&gt;Amartya Sanyal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kanade_V/0/1/0/all/0/1&quot;&gt;Varun Kanade&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Torr_P/0/1/0/all/0/1&quot;&gt;Philip H. S. Torr&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07039">
<title>A Theoretical Explanation for Perplexing Behaviors of Backpropagation-based Visualizations. (arXiv:1805.07039v3 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1805.07039</link>
<description rdf:parseType="Literal">&lt;p&gt;Backpropagation-based visualizations have been proposed to interpret
convolutional neural networks (CNNs), however a theory is missing to justify
their behaviors: Guided backpropagation (GBP) and deconvolutional network
(DeconvNet) generate more human-interpretable but less class-sensitive
visualizations than saliency map. Motivated by this, we develop a theoretical
explanation revealing that GBP and DeconvNet are essentially doing (partial)
image recovery which is unrelated to the network decisions. Specifically, our
analysis shows that the backward ReLU introduced by GBP and DeconvNet, and the
local connections in CNNs are the two main causes of compelling visualizations.
Extensive experiments are provided that support the theoretical analysis.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nie_W/0/1/0/all/0/1&quot;&gt;Weili Nie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yang Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Patel_A/0/1/0/all/0/1&quot;&gt;Ankit Patel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08877">
<title>Adversarial Labeling for Learning without Labels. (arXiv:1805.08877v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.08877</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the task of training classifiers without labels. We propose a
weakly supervised method---adversarial label learning---that trains classifiers
to perform well against an adversary that chooses labels for training data. The
weak supervision constrains what labels the adversary can choose. The method
therefore minimizes an upper bound of the classifier&apos;s error rate using
projected primal-dual subgradient descent. Minimizing this bound protects
against bias and dependencies in the weak supervision. Experiments on three
real datasets show that our method can train without labels and outperforms
other approaches for weakly supervised learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Arachie_C/0/1/0/all/0/1&quot;&gt;Chidubem Arachie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_B/0/1/0/all/0/1&quot;&gt;Bert Huang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02825">
<title>Estimating Train Delays in a Large Rail Network Using a Zero Shot Markov Model. (arXiv:1806.02825v1 [stat.AP])</title>
<link>http://arxiv.org/abs/1806.02825</link>
<description rdf:parseType="Literal">&lt;p&gt;India runs the fourth largest railway transport network size carrying over 8
billion passengers per year. However, the travel experience of passengers is
frequently marked by delays, i.e., late arrival of trains at stations, causing
inconvenience. In a first, we study the systemic delays in train arrivals using
n-order Markov frameworks and experiment with two regression based models.
Using train running-status data collected for two years, we report on an
efficient algorithm for estimating delays at railway stations with near
accurate results. This work can help railways to manage their resources, while
also helping passengers and businesses served by them to efficiently plan their
activities.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gaurav_R/0/1/0/all/0/1&quot;&gt;Ramashish Gaurav&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Srivastava_B/0/1/0/all/0/1&quot;&gt;Biplav Srivastava&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02863">
<title>Semi-supervised and Transfer learning approaches for low resource sentiment classification. (arXiv:1806.02863v1 [cs.IR])</title>
<link>http://arxiv.org/abs/1806.02863</link>
<description rdf:parseType="Literal">&lt;p&gt;Sentiment classification involves quantifying the affective reaction of a
human to a document, media item or an event. Although researchers have
investigated several methods to reliably infer sentiment from lexical, speech
and body language cues, training a model with a small set of labeled datasets
is still a challenge. For instance, in expanding sentiment analysis to new
languages and cultures, it may not always be possible to obtain comprehensive
labeled datasets. In this paper, we investigate the application of
semi-supervised and transfer learning methods to improve performances on low
resource sentiment classification tasks. We experiment with extracting dense
feature representations, pre-training and manifold regularization in enhancing
the performance of sentiment classification systems. Our goal is a coherent
implementation of these methods and we evaluate the gains achieved by these
methods in matched setting involving training and testing on a single corpus
setting as well as two cross corpora settings. In both the cases, our
experiments demonstrate that the proposed methods can significantly enhance the
model performance against a purely supervised approach, particularly in cases
involving a handful of training data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gupta_R/0/1/0/all/0/1&quot;&gt;Rahul Gupta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sahu_S/0/1/0/all/0/1&quot;&gt;Saurabh Sahu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Espy_Wilson_C/0/1/0/all/0/1&quot;&gt;Carol Espy-Wilson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Narayanan_S/0/1/0/all/0/1&quot;&gt;Shrikanth Narayanan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02865">
<title>Kernel Machines With Missing Responses. (arXiv:1806.02865v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.02865</link>
<description rdf:parseType="Literal">&lt;p&gt;Missing responses is a missing data format in which outcomes are not always
observed. In this work we develop kernel machines that can handle missing
responses. First, we propose a kernel machine family that uses mainly the
complete cases. For the quadratic loss, we then propose a family of
doubly-robust kernel machines. The proposed kernel-machine estimators can be
applied to both regression and classification problems. We prove oracle
inequalities for the finite-sample differences between the kernel machine risk
and Bayes risk. We use these oracle inequalities to prove consistency and to
calculate convergence rates. We demonstrate the performance of the two proposed
kernel machine families using both a simulation study and a real-world data
analysis.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Liu_T/0/1/0/all/0/1&quot;&gt;Tiantian Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Goldberg_Y/0/1/0/all/0/1&quot;&gt;Yair Goldberg&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02924">
<title>On Adversarial Risk and Training. (arXiv:1806.02924v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.02924</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work we formally define the notions of adversarial perturbations,
adversarial risk and adversarial training and analyze their properties. Our
analysis provides several interesting insights into adversarial risk,
adversarial training, and their relation to the classification risk,
&quot;traditional&quot; training. We also show that adversarial training can result in
models with better classification accuracy and can result in better explainable
models than traditional training. Although adversarial training is
computationally expensive, our results and insights suggest that one should
prefer adversarial training over traditional risk minimization for learning
complex models from data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Suggala_A/0/1/0/all/0/1&quot;&gt;Arun Sai Suggala&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Prasad_A/0/1/0/all/0/1&quot;&gt;Adarsh Prasad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Nagarajan_V/0/1/0/all/0/1&quot;&gt;Vaishnavh Nagarajan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ravikumar_P/0/1/0/all/0/1&quot;&gt;Pradeep Ravikumar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02934">
<title>Learn from Your Neighbor: Learning Multi-modal Mappings from Sparse Annotations. (arXiv:1806.02934v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.02934</link>
<description rdf:parseType="Literal">&lt;p&gt;Many structured prediction problems (particularly in vision and language
domains) are ambiguous, with multiple outputs being correct for an input - e.g.
there are many ways of describing an image, multiple ways of translating a
sentence; however, exhaustively annotating the applicability of all possible
outputs is intractable due to exponentially large output spaces (e.g. all
English sentences). In practice, these problems are cast as multi-class
prediction, with the likelihood of only a sparse set of annotations being
maximized - unfortunately penalizing for placing beliefs on plausible but
unannotated outputs. We make and test the following hypothesis - for a given
input, the annotations of its neighbors may serve as an additional supervisory
signal. Specifically, we propose an objective that transfers supervision from
neighboring examples. We first study the properties of our developed method in
a controlled toy setup before reporting results on multi-label classification
and two image-grounded sequence modeling tasks - captioning and question
generation. We evaluate using standard task-specific metrics and measures of
output diversity, finding consistent improvements over standard maximum
likelihood training and other baselines.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kalyan_A/0/1/0/all/0/1&quot;&gt;Ashwin Kalyan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lee_S/0/1/0/all/0/1&quot;&gt;Stefan Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kannan_A/0/1/0/all/0/1&quot;&gt;Anitha Kannan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Batra_D/0/1/0/all/0/1&quot;&gt;Dhruv Batra&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02978">
<title>JointGAN: Multi-Domain Joint Distribution Learning with Generative Adversarial Nets. (arXiv:1806.02978v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.02978</link>
<description rdf:parseType="Literal">&lt;p&gt;A new generative adversarial network is developed for joint distribution
matching. Distinct from most existing approaches, that only learn conditional
distributions, the proposed model aims to learn a joint distribution of
multiple random variables (domains). This is achieved by learning to sample
from conditional distributions between the domains, while simultaneously
learning to sample from the marginals of each individual domain. The proposed
framework consists of multiple generators and a single softmax-based critic,
all jointly trained via adversarial learning. From a simple noise source, the
proposed framework allows synthesis of draws from the marginals, conditional
draws given observations from a subset of random variables, or complete draws
from the full joint distribution. Most examples considered are for joint
analysis of two domains, with examples for three domains also presented.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pu_Y/0/1/0/all/0/1&quot;&gt;Yunchen Pu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dai_S/0/1/0/all/0/1&quot;&gt;Shuyang Dai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gan_Z/0/1/0/all/0/1&quot;&gt;Zhe Gan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1&quot;&gt;Weiyao Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1&quot;&gt;Guoyin Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yizhe Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Henao_R/0/1/0/all/0/1&quot;&gt;Ricardo Henao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Carin_L/0/1/0/all/0/1&quot;&gt;Lawrence Carin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.03107">
<title>Temporal Difference Variational Auto-Encoder. (arXiv:1806.03107v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.03107</link>
<description rdf:parseType="Literal">&lt;p&gt;One motivation for learning generative models of environments is to use them
as simulators for model-based reinforcement learning. Yet, it is intuitively
clear that when time horizons are long, rolling out single step transitions is
inefficient and often prohibitive. In this paper, we propose a generative model
that learns state representations containing explicit beliefs about states
several time steps in the future and that can be rolled out directly in these
states without executing single step transitions. The model is trained on pairs
of temporally separated time points, using an analogue of temporal difference
learning used in reinforcement learning, taking the belief about possible
futures at one time point as a bootstrap for training the belief at an earlier
time. While we focus purely on the study of the model rather than its use in
reinforcement learning, the model architecture we design respects agents&apos;
constraints as it builds the representation online.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gregor_K/0/1/0/all/0/1&quot;&gt;Karol Gregor&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Besse_F/0/1/0/all/0/1&quot;&gt;Frederic Besse&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.03168">
<title>Data-driven Analytics for Business Architectures: Proposed Use of Graph Theory. (arXiv:1806.03168v1 [cs.SE])</title>
<link>http://arxiv.org/abs/1806.03168</link>
<description rdf:parseType="Literal">&lt;p&gt;Business Architecture (BA) plays a significant role in helping organizations
understand enterprise structures and processes, and align them with strategic
objectives. However, traditional BAs are represented in fixed structure with
static model elements and fail to dynamically capture business insights based
on internal and external data. To solve this problem, this paper introduces the
graph theory into BAs with aim of building extensible data-driven analytics and
automatically generating business insights. We use IBM&apos;s Component Business
Model (CBM) as an example to illustrate various ways in which graph theory can
be leveraged for data-driven analytics, including what and how business
insights can be obtained. Future directions for applying graph theory to
business architecture analytics are discussed.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1&quot;&gt;Lei Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ren_G/0/1/0/all/0/1&quot;&gt;Guangjie Ren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_S/0/1/0/all/0/1&quot;&gt;Shun Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Arar_R/0/1/0/all/0/1&quot;&gt;Raphael Arar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_E/0/1/0/all/0/1&quot;&gt;Eric Young Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.03207">
<title>Learning in Integer Latent Variable Models with Nested Automatic Differentiation. (arXiv:1806.03207v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.03207</link>
<description rdf:parseType="Literal">&lt;p&gt;We develop nested automatic differentiation (AD) algorithms for exact
inference and learning in integer latent variable models. Recently, Winner,
Sujono, and Sheldon showed how to reduce marginalization in a class of integer
latent variable models to evaluating a probability generating function which
contains many levels of nested high-order derivatives. We contribute faster and
more stable AD algorithms for this challenging problem and a novel algorithm to
compute exact gradients for learning. These contributions lead to significantly
faster and more accurate learning algorithms, and are the first AD algorithms
whose running time is polynomial in the number of levels of nesting.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sheldon_D/0/1/0/all/0/1&quot;&gt;Daniel Sheldon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Winner_K/0/1/0/all/0/1&quot;&gt;Kevin Winner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sujono_D/0/1/0/all/0/1&quot;&gt;Debora Sujono&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.03190">
<title>Learning Credible Models. (arXiv:1711.03190v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1711.03190</link>
<description rdf:parseType="Literal">&lt;p&gt;In many settings, it is important that a model be capable of providing
reasons for its predictions (i.e., the model must be interpretable). However,
the model&apos;s reasoning may not conform with well-established knowledge. In such
cases, while interpretable, the model lacks \textit{credibility}. In this work,
we formally define credibility in the linear setting and focus on techniques
for learning models that are both accurate and credible. In particular, we
propose a regularization penalty, expert yielded estimates (EYE), that
incorporates expert knowledge about well-known relationships among covariates
and the outcome of interest. We give both theoretical and empirical results
comparing our proposed method to several other regularization techniques.
Across a range of settings, experiments on both synthetic and real data show
that models learned using the EYE penalty are significantly more credible than
those learned using other penalties. Applied to a large-scale patient risk
stratification task, our proposed technique results in a model whose top
features overlap significantly with known clinical risk factors, while still
achieving good predictive performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jiaxuan Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oh_J/0/1/0/all/0/1&quot;&gt;Jeeheh Oh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1&quot;&gt;Haozhu Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wiens_J/0/1/0/all/0/1&quot;&gt;Jenna Wiens&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.03878">
<title>Generalized Zero-Shot Learning via Synthesized Examples. (arXiv:1712.03878v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1712.03878</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a generative framework for generalized zero-shot learning where
the training and test classes are not necessarily disjoint. Built upon a
variational autoencoder based architecture, consisting of a probabilistic
encoder and a probabilistic conditional decoder, our model can generate novel
exemplars from seen/unseen classes, given their respective class attributes.
These exemplars can subsequently be used to train any off-the-shelf
classification model. One of the key aspects of our encoder-decoder
architecture is a feedback-driven mechanism in which a discriminator (a
multivariate regressor) learns to map the generated exemplars to the
corresponding class attribute vectors, leading to an improved generator. Our
model&apos;s ability to generate and leverage examples from unseen classes to train
the classification model naturally helps to mitigate the bias towards
predicting seen classes in generalized zero-shot learning settings. Through a
comprehensive set of experiments, we show that our model outperforms several
state-of-the-art methods, on several benchmark datasets, for both standard as
well as generalized zero-shot learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Arora_G/0/1/0/all/0/1&quot;&gt;Gundeep Arora&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Verma_V/0/1/0/all/0/1&quot;&gt;Vinay Kumar Verma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mishra_A/0/1/0/all/0/1&quot;&gt;Ashish Mishra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rai_P/0/1/0/all/0/1&quot;&gt;Piyush Rai&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.04062">
<title>MINE: Mutual Information Neural Estimation. (arXiv:1801.04062v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1801.04062</link>
<description rdf:parseType="Literal">&lt;p&gt;We argue that the estimation of mutual information between high dimensional
continuous random variables can be achieved by gradient descent over neural
networks. We present a Mutual Information Neural Estimator (MINE) that is
linearly scalable in dimensionality as well as in sample size, trainable
through back-prop, and strongly consistent. We present a handful of
applications on which MINE can be used to minimize or maximize mutual
information. We apply MINE to improve adversarially trained generative models.
We also use MINE to implement Information Bottleneck, applying it to supervised
classification; our results demonstrate substantial improvement in flexibility
and performance in these settings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Belghazi_M/0/1/0/all/0/1&quot;&gt;Mohamed Ishmael Belghazi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Baratin_A/0/1/0/all/0/1&quot;&gt;Aristide Baratin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rajeswar_S/0/1/0/all/0/1&quot;&gt;Sai Rajeswar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ozair_S/0/1/0/all/0/1&quot;&gt;Sherjil Ozair&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bengio_Y/0/1/0/all/0/1&quot;&gt;Yoshua Bengio&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Courville_A/0/1/0/all/0/1&quot;&gt;Aaron Courville&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hjelm_R/0/1/0/all/0/1&quot;&gt;R Devon Hjelm&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06403">
<title>RadialGAN: Leveraging multiple datasets to improve target-specific predictive models using Generative Adversarial Networks. (arXiv:1802.06403v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1802.06403</link>
<description rdf:parseType="Literal">&lt;p&gt;Training complex machine learning models for prediction often requires a
large amount of data that is not always readily available. Leveraging these
external datasets from related but different sources is therefore an important
task if good predictive models are to be built for deployment in settings where
data can be rare. In this paper we propose a novel approach to the problem in
which we use multiple GAN architectures to learn to translate from one dataset
to another, thereby allowing us to effectively enlarge the target dataset, and
therefore learn better predictive models than if we simply used the target
dataset. We show the utility of such an approach, demonstrating that our method
improves the prediction performance on the target domain over using just the
target dataset and also show that our framework outperforms several other
benchmarks on a collection of real-world medical datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yoon_J/0/1/0/all/0/1&quot;&gt;Jinsung Yoon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jordon_J/0/1/0/all/0/1&quot;&gt;James Jordon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schaar_M/0/1/0/all/0/1&quot;&gt;Mihaela van der Schaar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09128">
<title>Averaging Stochastic Gradient Descent on Riemannian Manifolds. (arXiv:1802.09128v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1802.09128</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the minimization of a function defined on a Riemannian manifold
$\mathcal{M}$ accessible only through unbiased estimates of its gradients. We
develop a geometric framework to transform a sequence of slowly converging
iterates generated from stochastic gradient descent (SGD) on $\mathcal{M}$ to
an averaged iterate sequence with a robust and fast $O(1/n)$ convergence rate.
We then present an application of our framework to geodesically-strongly-convex
(and possibly Euclidean non-convex) problems. Finally, we demonstrate how these
ideas apply to the case of streaming $k$-PCA, where we show how to accelerate
the slow rate of the randomized power method (without requiring knowledge of
the eigengap) into a robust algorithm achieving the optimal rate of
convergence.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tripuraneni_N/0/1/0/all/0/1&quot;&gt;Nilesh Tripuraneni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Flammarion_N/0/1/0/all/0/1&quot;&gt;Nicolas Flammarion&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bach_F/0/1/0/all/0/1&quot;&gt;Francis Bach&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jordan_M/0/1/0/all/0/1&quot;&gt;Michael I. Jordan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.03148">
<title>Generating Artificial Data for Private Deep Learning. (arXiv:1803.03148v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1803.03148</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we propose generating artificial data that retain statistical
properties of real data as the means of providing privacy with respect to the
original dataset. We use generative adversarial network to draw
privacy-preserving artificial data samples and derive an empirical method to
assess the risk of information disclosure in a differential-privacy-like way.
Our experiments show that we are able to generate artificial data of high
quality and successfully train and validate machine learning models on this
data while limiting potential privacy loss.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Triastcyn_A/0/1/0/all/0/1&quot;&gt;Aleksei Triastcyn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Faltings_B/0/1/0/all/0/1&quot;&gt;Boi Faltings&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.09050">
<title>Learning to Reweight Examples for Robust Deep Learning. (arXiv:1803.09050v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1803.09050</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep neural networks have been shown to be very powerful modeling tools for
many supervised learning tasks involving complex input patterns. However, they
can also easily overfit to training set biases and label noises. In addition to
various regularizers, example reweighting algorithms are popular solutions to
these problems, but they require careful tuning of additional hyperparameters,
such as example mining schedules and regularization hyperparameters. In
contrast to past reweighting methods, which typically consist of functions of
the cost value of each example, in this work we propose a novel meta-learning
algorithm that learns to assign weights to training examples based on their
gradient directions. To determine the example weights, our method performs a
meta gradient descent step on the current mini-batch example weights (which are
initialized from zero) to minimize the loss on a clean unbiased validation set.
Our proposed method can be easily implemented on any type of deep network, does
not require any additional hyperparameter tuning, and achieves impressive
performance on class imbalance and corrupted label problems where only a small
amount of clean validation data is available.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ren_M/0/1/0/all/0/1&quot;&gt;Mengye Ren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zeng_W/0/1/0/all/0/1&quot;&gt;Wenyuan Zeng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_B/0/1/0/all/0/1&quot;&gt;Bin Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Urtasun_R/0/1/0/all/0/1&quot;&gt;Raquel Urtasun&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11921">
<title>Anonymous Walk Embeddings. (arXiv:1805.11921v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.11921</link>
<description rdf:parseType="Literal">&lt;p&gt;The task of representing entire graphs has seen a surge of prominent results,
mainly due to learning convolutional neural networks (CNNs) on graph-structured
data. While CNNs demonstrate state-of-the-art performance in graph
classification task, such methods are supervised and therefore steer away from
the original problem of network representation in task-agnostic manner. Here,
we coherently propose an approach for embedding entire graphs and show that our
feature representations with SVM classifier increase classification accuracy of
CNN algorithms and traditional graph kernels. For this we describe a recently
discovered graph object, anonymous walk, on which we design task-independent
algorithms for learning graph representations in explicit and distributed way.
Overall, our work represents a new scalable unsupervised learning of
state-of-the-art representations of entire graphs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ivanov_S/0/1/0/all/0/1&quot;&gt;Sergey Ivanov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Burnaev_E/0/1/0/all/0/1&quot;&gt;Evgeny Burnaev&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02338">
<title>Towards Dependability Metrics for Neural Networks. (arXiv:1806.02338v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1806.02338</link>
<description rdf:parseType="Literal">&lt;p&gt;Artificial neural networks (NN) are instrumental in realizing
highly-automated driving functionality. An overarching challenge is to identify
best safety engineering practices for NN and other learning-enabled components.
In particular, there is an urgent need for an adequate set of metrics for
measuring all-important NN dependability attributes. We address this challenge
by proposing a number of NN-specific and efficiently computable metrics for
measuring NN dependability attributes including robustness, interpretability,
completeness, and correctness.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_C/0/1/0/all/0/1&quot;&gt;Chih-Hong Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nuhrenberg_G/0/1/0/all/0/1&quot;&gt;Georg N&amp;#xfc;hrenberg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_C/0/1/0/all/0/1&quot;&gt;Chung-Hao Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ruess_H/0/1/0/all/0/1&quot;&gt;Harald Ruess&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yasuoka_H/0/1/0/all/0/1&quot;&gt;Hirotoshi Yasuoka&lt;/a&gt;</dc:creator>
</item></rdf:RDF>