<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Good papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Good Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-02-20T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.07133"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.07239"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06767"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06769"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06821"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06829"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06895"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.07228"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1511.04798"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1705.07368"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.10207"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.04071"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06070"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06412"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06901"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.07007"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.07088"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.07124"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.07176"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.07229"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1607.02665"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.04168"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.03360"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05351"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05799"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06384"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06309"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1802.07133">
<title>Towards Deep Representation Learning with Genetic Programming. (arXiv:1802.07133v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1802.07133</link>
<description rdf:parseType="Literal">&lt;p&gt;Genetic Programming (GP) is an evolutionary algorithm commonly used for
machine learning tasks. In this paper we present a method that allows GP to
transform the representation of a large-scale machine learning dataset into a
more compact representation, by means of processing features from the original
representation at individual level. We develop as a proof of concept of this
method an autoencoder. We tested a preliminary version of our approach in a
variety of well-known machine learning image datasets. We speculate that this
method, used in an iterative manner, can produce results competitive with
state-of-art deep neural networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rodriguez_Coayahuitl_L/0/1/0/all/0/1&quot;&gt;Lino Rodriguez-Coayahuitl&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Morales_Reyes_A/0/1/0/all/0/1&quot;&gt;Alicia Morales-Reyes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Escalante_H/0/1/0/all/0/1&quot;&gt;Hugo Jair Escalante&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.07239">
<title>Continual Reinforcement Learning with Complex Synapses. (arXiv:1802.07239v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.07239</link>
<description rdf:parseType="Literal">&lt;p&gt;Unlike humans, who are capable of continual learning over their lifetimes,
artificial neural networks have long been known to suffer from a phenomenon
known as catastrophic forgetting, whereby new learning can lead to abrupt
erasure of previously acquired knowledge. Whereas in a neural network the
parameters are typically modelled as scalar values, an individual synapse in
the brain comprises a complex network of interacting biochemical components
that evolve at different timescales. In this paper, we show that by equipping
tabular and deep reinforcement learning agents with a synaptic model that
incorporates this biological complexity (Benna &amp;amp; Fusi, 2016), catastrophic
forgetting can be mitigated at multiple timescales. In particular, we find that
as well as enabling continual learning across sequential training of two simple
tasks, it can also be used to overcome within-task forgetting by reducing the
need for an experience replay database.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kaplanis_C/0/1/0/all/0/1&quot;&gt;Christos Kaplanis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shanahan_M/0/1/0/all/0/1&quot;&gt;Murray Shanahan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Clopath_C/0/1/0/all/0/1&quot;&gt;Claudia Clopath&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06767">
<title>The problem of the development ontology-driven architecture of intellectual software systems. (arXiv:1802.06767v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.06767</link>
<description rdf:parseType="Literal">&lt;p&gt;The paper describes the architecture of the intelligence system for automated
design of ontological knowledge bases of domain areas and the software model of
the management GUI (Graphical User Interface) subsystem
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Palagin_A/0/1/0/all/0/1&quot;&gt;A. V. Palagin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Petrenko_N/0/1/0/all/0/1&quot;&gt;N.G. Petrenko&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Velychko_V/0/1/0/all/0/1&quot;&gt;V.Yu. Velychko&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Malakhov_K/0/1/0/all/0/1&quot;&gt;K.S. Malakhov&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06769">
<title>Technique for designing a domain ontology. (arXiv:1802.06769v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.06769</link>
<description rdf:parseType="Literal">&lt;p&gt;The article describes the technique for designing a domain ontology, shows
the flowchart of algorithm design and example of constructing a fragment of the
ontology of the subject area of Computer Science is considered.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Palagin_A/0/1/0/all/0/1&quot;&gt;A. V. Palagin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Petrenko_N/0/1/0/all/0/1&quot;&gt;N. G. Petrenko&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Malakhov_K/0/1/0/all/0/1&quot;&gt;K. S. Malakhov&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06821">
<title>Integrated Tools for Engineering Ontologies. (arXiv:1802.06821v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.06821</link>
<description rdf:parseType="Literal">&lt;p&gt;The article presents an overview of current specialized ontology engineering
tools, as well as texts&apos; annotation tools based on ontologies. The main
functions and features of these tools, their advantages and disadvantages are
discussed. A systematic comparative analysis of means for engineering
ontologies is presented.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Velychko_V/0/1/0/all/0/1&quot;&gt;V. Yu. Velychko&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Malakhov_K/0/1/0/all/0/1&quot;&gt;K. S. Malakhov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Semenkov_V/0/1/0/all/0/1&quot;&gt;V. V. Semenkov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Strizhak_A/0/1/0/all/0/1&quot;&gt;A. E. Strizhak&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06829">
<title>Principles of design and software development models of ontological-driven computer systems. (arXiv:1802.06829v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.06829</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper describes the design principles of methodology of
knowledge-oriented information systems based on ontological approach. Such
systems implement technology subject-oriented extraction of knowledge from the
set of natural language texts and their formal and logical presentation and
application processing
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Palagin_A/0/1/0/all/0/1&quot;&gt;A. V. Palagin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Petrenko_N/0/1/0/all/0/1&quot;&gt;N. G. Petrenko&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Velychko_V/0/1/0/all/0/1&quot;&gt;V. Yu. Velychko&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Malakhov_K/0/1/0/all/0/1&quot;&gt;K. S. Malakhov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Karun_O/0/1/0/all/0/1&quot;&gt;O. V. Karun&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06895">
<title>Hierarchical Expertise-Level Modeling for User Specific Robot-Behavior Explanations. (arXiv:1802.06895v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.06895</link>
<description rdf:parseType="Literal">&lt;p&gt;There is a growing interest within the AI research community to develop
autonomous systems capable of explaining their behavior to users. One aspect of
the explanation generation problem that has yet to receive much attention is
the task of explaining plans to users whose level of expertise differ from that
of the explainer. We propose an approach for addressing this problem by
representing the user&apos;s model as an abstraction of the domain model that the
planner uses. We present algorithms for generating minimal explanations in
cases where this abstract human model is not known. We reduce the problem of
generating explanation to a search over the space of abstract models and
investigate possible greedy approximations for minimal explanations. We also
empirically show that our approach can efficiently compute explanations for a
variety of problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sreedharan_S/0/1/0/all/0/1&quot;&gt;Sarath Sreedharan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Srivastava_S/0/1/0/all/0/1&quot;&gt;Siddharth Srivastava&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kambhampati_S/0/1/0/all/0/1&quot;&gt;Subbarao Kambhampati&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.07228">
<title>The Malicious Use of Artificial Intelligence: Forecasting, Prevention, and Mitigation. (arXiv:1802.07228v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.07228</link>
<description rdf:parseType="Literal">&lt;p&gt;This report surveys the landscape of potential security threats from
malicious uses of AI, and proposes ways to better forecast, prevent, and
mitigate these threats. After analyzing the ways in which AI may influence the
threat landscape in the digital, physical, and political domains, we make four
high-level recommendations for AI researchers and other stakeholders. We also
suggest several promising areas for further research that could expand the
portfolio of defenses, or make attacks less effective or harder to execute.
Finally, we discuss, but do not conclusively resolve, the long-term equilibrium
of attackers and defenders.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brundage_M/0/1/0/all/0/1&quot;&gt;Miles Brundage&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Avin_S/0/1/0/all/0/1&quot;&gt;Shahar Avin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Clark_J/0/1/0/all/0/1&quot;&gt;Jack Clark&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Toner_H/0/1/0/all/0/1&quot;&gt;Helen Toner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Eckersley_P/0/1/0/all/0/1&quot;&gt;Peter Eckersley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garfinkel_B/0/1/0/all/0/1&quot;&gt;Ben Garfinkel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dafoe_A/0/1/0/all/0/1&quot;&gt;Allan Dafoe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Scharre_P/0/1/0/all/0/1&quot;&gt;Paul Scharre&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zeitzoff_T/0/1/0/all/0/1&quot;&gt;Thomas Zeitzoff&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Filar_B/0/1/0/all/0/1&quot;&gt;Bobby Filar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Anderson_H/0/1/0/all/0/1&quot;&gt;Hyrum Anderson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roff_H/0/1/0/all/0/1&quot;&gt;Heather Roff&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Allen_G/0/1/0/all/0/1&quot;&gt;Gregory C. Allen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Steinhardt_J/0/1/0/all/0/1&quot;&gt;Jacob Steinhardt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Flynn_C/0/1/0/all/0/1&quot;&gt;Carrick Flynn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+hEigeartaigh_S/0/1/0/all/0/1&quot;&gt;Se&amp;#xe1;n &amp;#xd3; h&amp;#xc9;igeartaigh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Beard_S/0/1/0/all/0/1&quot;&gt;Simon Beard&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Belfield_H/0/1/0/all/0/1&quot;&gt;Haydn Belfield&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Farquhar_S/0/1/0/all/0/1&quot;&gt;Sebastian Farquhar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lyle_C/0/1/0/all/0/1&quot;&gt;Clare Lyle&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Crootof_R/0/1/0/all/0/1&quot;&gt;Rebecca Crootof&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Evans_O/0/1/0/all/0/1&quot;&gt;Owain Evans&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Page_M/0/1/0/all/0/1&quot;&gt;Michael Page&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bryson_J/0/1/0/all/0/1&quot;&gt;Joanna Bryson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yampolskiy_R/0/1/0/all/0/1&quot;&gt;Roman Yampolskiy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Amodei_D/0/1/0/all/0/1&quot;&gt;Dario Amodei&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1511.04798">
<title>Heterogeneous Knowledge Transfer in Video Emotion Recognition, Attribution and Summarization. (arXiv:1511.04798v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1511.04798</link>
<description rdf:parseType="Literal">&lt;p&gt;Emotion is a key element in user-generated videos. However, it is difficult
to understand emotions conveyed in such videos due to the complex and
unstructured nature of user-generated content and the sparsity of video frames
expressing emotion. In this paper, for the first time, we study the problem of
transferring knowledge from heterogeneous external sources, including image and
textual data, to facilitate three related tasks in understanding video emotion:
emotion recognition, emotion attribution and emotion-oriented summarization.
Specifically, our framework (1) learns a video encoding from an auxiliary
emotional image dataset in order to improve supervised video emotion
recognition, and (2) transfers knowledge from an auxiliary textual corpora for
zero-shot recognition of emotion classes unseen during training. The proposed
technique for knowledge transfer facilitates novel applications of emotion
attribution and emotion-oriented summarization. A comprehensive set of
experiments on multiple datasets demonstrate the effectiveness of our
framework.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_B/0/1/0/all/0/1&quot;&gt;Baohan Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1&quot;&gt;Yanwei Fu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1&quot;&gt;Yu-Gang Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1&quot;&gt;Boyang Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sigal_L/0/1/0/all/0/1&quot;&gt;Leonid Sigal&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1705.07368">
<title>Mixed Membership Word Embeddings for Computational Social Science. (arXiv:1705.07368v3 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1705.07368</link>
<description rdf:parseType="Literal">&lt;p&gt;Word embeddings improve the performance of NLP systems by revealing the
hidden structural relationships between words. Despite their success in many
applications, word embeddings have seen very little use in computational social
science NLP tasks, presumably due to their reliance on big data, and to a lack
of interpretability. I propose a probabilistic model-based word embedding
method which can recover interpretable embeddings, without big data. The key
insight is to leverage mixed membership modeling, in which global
representations are shared, but individual entities (i.e. dictionary words) are
free to use these representations to uniquely differing degrees. I show how to
train the model using a combination of state-of-the-art training techniques for
word embeddings and topic models. The experimental results show an improvement
in predictive language modeling of up to 63% in MRR over the skip-gram, and
demonstrate that the representations are beneficial for supervised learning. I
illustrate the interpretability of the models with computational social science
case studies on State of the Union addresses and NIPS articles.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Foulds_J/0/1/0/all/0/1&quot;&gt;James Foulds&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.10207">
<title>Provably Minimally-Distorted Adversarial Examples. (arXiv:1709.10207v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1709.10207</link>
<description rdf:parseType="Literal">&lt;p&gt;The ability to deploy neural networks in real-world, safety-critical systems
is severely limited by the presence of adversarial examples: slightly perturbed
inputs that are misclassified by the network. In recent years, several
techniques have been proposed for increasing robustness to adversarial examples
--- and yet most of these have been quickly shown to be vulnerable to future
attacks. For example, over half of the defenses proposed by papers accepted at
ICLR 2018 have already been broken. We propose to address this difficulty
through formal verification techniques. We show how to construct provably
minimally distorted adversarial examples: given an arbitrary neural network and
input sample, we can construct adversarial examples which we prove are of
minimal distortion. Using this approach, we demonstrate that one of the recent
ICLR defense proposals, adversarial retraining, provably succeeds at increasing
the distortion required to construct adversarial examples by a factor of 4.2.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Carlini_N/0/1/0/all/0/1&quot;&gt;Nicholas Carlini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Katz_G/0/1/0/all/0/1&quot;&gt;Guy Katz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barrett_C/0/1/0/all/0/1&quot;&gt;Clark Barrett&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dill_D/0/1/0/all/0/1&quot;&gt;David L. Dill&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.04071">
<title>KBGAN: Adversarial Learning for Knowledge Graph Embeddings. (arXiv:1711.04071v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1711.04071</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce KBGAN, an adversarial learning framework to improve the
performances of a wide range of existing knowledge graph embedding models.
Because knowledge graphs typically only contain positive facts, sampling useful
negative training examples is a non-trivial task. Replacing the head or tail
entity of a fact with a uniformly randomly selected entity is a conventional
method for generating negative facts, but the majority of the generated
negative facts can be easily discriminated from positive facts, and will
contribute little towards the training. Inspired by generative adversarial
networks (GANs), we use one knowledge graph embedding model as a negative
sample generator to assist the training of our desired model, which acts as the
discriminator in GANs. This framework is independent of the concrete form of
generator and discriminator, and therefore can utilize a wide variety of
knowledge graph embedding models as its building blocks. In experiments, we
adversarially train two translation-based models, TransE and TransD, each with
assistance from one of the two probability-based models, DistMult and ComplEx.
We evaluate the performances of KBGAN on the link prediction task, using three
knowledge base completion datasets: FB15k-237, WN18 and WN18RR. Experimental
results show that adversarial training substantially improves the performances
of target embedding models under various settings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cai_L/0/1/0/all/0/1&quot;&gt;Liwei Cai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1&quot;&gt;William Yang Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06070">
<title>Diversity is All You Need: Learning Skills without a Reward Function. (arXiv:1802.06070v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1802.06070</link>
<description rdf:parseType="Literal">&lt;p&gt;Intelligent creatures can explore their environments and learn useful skills
without supervision. In this paper, we propose DIAYN (&quot;Diversity is All You
Need&quot;), a method for learning useful skills without a reward function. Our
proposed method learns skills by maximizing an information theoretic objective
using a maximum entropy policy. On a variety of simulated robotic tasks, we
show that this simple objective results in the unsupervised emergence of
diverse skills, such as walking and jumping. In a number of reinforcement
learning benchmark environments, our method is able to learn a skill that
solves the benchmark task despite never receiving the true task reward. In
these environments, some of the learned skills correspond to solving the task,
and each skill that solves the task does so in a distinct manner. Our results
suggest that unsupervised discovery of skills can serve as an effective
pretraining mechanism for overcoming challenges of exploration and data
efficiency in reinforcement learning
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Eysenbach_B/0/1/0/all/0/1&quot;&gt;Benjamin Eysenbach&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1&quot;&gt;Abhishek Gupta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ibarz_J/0/1/0/all/0/1&quot;&gt;Julian Ibarz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1&quot;&gt;Sergey Levine&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06412">
<title>Improved TDNNs using Deep Kernels and Frequency Dependent Grid-RNNs. (arXiv:1802.06412v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1802.06412</link>
<description rdf:parseType="Literal">&lt;p&gt;Time delay neural networks (TDNNs) are an effective acoustic model for large
vocabulary speech recognition. The strength of the model can be attributed to
its ability to effectively model long temporal contexts. However, current TDNN
models are relatively shallow, which limits the modelling capability. This
paper proposes a method of increasing the network depth by deepening the kernel
used in the TDNN temporal convolutions. The best performing kernel consists of
three fully connected layers with a residual (ResNet) connection from the
output of the first to the output of the third. The addition of
spectro-temporal processing as the input to the TDNN in the form of a
convolutional neural network (CNN) and a newly designed Grid-RNN was
investigated. The Grid-RNN strongly outperforms a CNN if different sets of
parameters for different frequency bands are used and can be further enhanced
by using a bi-directional Grid-RNN. Experiments using the multi-genre broadcast
(MGB3) English data (275h) show that deep kernel TDNNs reduces the word error
rate (WER) by 6% relative and when combined with the frequency dependent
Grid-RNN gives a relative WER reduction of 9%.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kreyssig_F/0/1/0/all/0/1&quot;&gt;Florian Kreyssig&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1&quot;&gt;Chao Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Woodland_P/0/1/0/all/0/1&quot;&gt;Philip Woodland&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06901">
<title>Deterministic Non-Autoregressive Neural Sequence Modeling by Iterative Refinement. (arXiv:1802.06901v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.06901</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a conditional non-autoregressive neural sequence model based on
iterative refinement. The proposed model is designed based on the principles of
latent variable models and denoising autoencoders, and is generally applicable
to any sequence generation task. We extensively evaluate the proposed model on
machine translation (En-De and En-Ro) and image caption generation, and observe
that it significantly speeds up decoding while maintaining the generation
quality comparable to the autoregressive counterpart.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1&quot;&gt;Jason Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mansimov_E/0/1/0/all/0/1&quot;&gt;Elman Mansimov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cho_K/0/1/0/all/0/1&quot;&gt;Kyunghyun Cho&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.07007">
<title>High-Order Graph Convolutional Recurrent Neural Network: A Deep Learning Framework for Network-Scale Traffic Learning and Forecasting. (arXiv:1802.07007v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.07007</link>
<description rdf:parseType="Literal">&lt;p&gt;Traffic forecasting is a challenging task, due to the complicated spatial
dependencies on roadway networks and the time-varying traffic patterns. To
address this challenge, we learn the traffic network as a graph and propose a
novel deep learning framework, High-Order Graph Convolutional Long Short-Term
Memory Neural Network (HGC-LSTM), to learn the interactions between links in
the traffic network and forecast the network-wide traffic state. We define the
high-order traffic graph convolution based on the physical network topology.
The proposed framework employs L1-norms on the graph convolution weights and
L2-norms on the graph convolution features to identify the most influential
links in the traffic network. We propose a novel Real-Time Branching Learning
(RTBL) algorithm for the HGC-LSTM framework to accelerate the training process
for spatio-temporal data. Experiments show that our HGC-LSTM network is able to
capture the complex spatio-temporal dependencies efficiently present in the
traffic network and consistently outperforms state-of-the-art baseline methods
on two heterogeneous real-world traffic datasets. The visualization of graph
convolution weights shows that the proposed framework can accurately recognize
the most influential roadway segments in real-world traffic networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cui_Z/0/1/0/all/0/1&quot;&gt;Zhiyong Cui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Henrickson_K/0/1/0/all/0/1&quot;&gt;Kristian Henrickson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ke_R/0/1/0/all/0/1&quot;&gt;Ruimin Ke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yinhai Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.07088">
<title>i-RevNet: Deep Invertible Networks. (arXiv:1802.07088v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.07088</link>
<description rdf:parseType="Literal">&lt;p&gt;It is widely believed that the success of deep convolutional networks is
based on progressively discarding uninformative variability about the input
with respect to the problem at hand. This is supported empirically by the
difficulty of recovering images from their hidden representations, in most
commonly used network architectures. In this paper we show via a one-to-one
mapping that this loss of information is not a necessary condition to learn
representations that generalize well on complicated problems, such as ImageNet.
Via a cascade of homeomorphic layers, we build the i-RevNet, a network that can
be fully inverted up to the final projection onto the classes, i.e. no
information is discarded. Building an invertible architecture is difficult, for
one, because the local inversion is ill-conditioned, we overcome this by
providing an explicit inverse. An analysis of i-RevNets learned representations
suggests an alternative explanation for the success of deep networks by a
progressive contraction and linear separation with depth. To shed light on the
nature of the model learned by the i-RevNet we reconstruct linear
interpolations between natural image representations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jacobsen_J/0/1/0/all/0/1&quot;&gt;J&amp;#xf6;rn-Henrik Jacobsen&lt;/a&gt; (IvI), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Smeulders_A/0/1/0/all/0/1&quot;&gt;Arnold Smeulders&lt;/a&gt; (IvI), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oyallon_E/0/1/0/all/0/1&quot;&gt;Edouard Oyallon&lt;/a&gt; (CVN, GALEN, SEQUEL, DI-ENS)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.07124">
<title>Out-distribution training confers robustness to deep neural networks. (arXiv:1802.07124v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.07124</link>
<description rdf:parseType="Literal">&lt;p&gt;The easiness at which adversarial instances can be generated in deep neural
networks raises some fundamental questions on their functioning and concerns on
their use in critical systems. In this paper, we draw a connection between
over-generalization and adversaries: a possible cause of adversaries lies in
models designed to make decisions all over the input space, leading to
inappropriate high-confidence decisions in parts of the input space not
represented in the training set. We empirically show an augmented neural
network, which is not trained on any types of adversaries, can increase the
robustness by detecting black-box one-step adversaries, i.e. assimilated to
out-distribution samples, and making generation of white-box one-step
adversaries harder.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abbasi_M/0/1/0/all/0/1&quot;&gt;Mahdieh Abbasi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gagne_C/0/1/0/all/0/1&quot;&gt;Christian Gagn&amp;#xe8;&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.07176">
<title>Adaptive Sampling for Coarse Ranking. (arXiv:1802.07176v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.07176</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the problem of active coarse ranking, where the goal is to sort
items according to their means into clusters of pre-specified sizes, by
adaptively sampling from their reward distributions. This setting is useful in
many social science applications involving human raters and the approximate
rank of every item is desired. Approximate or coarse ranking can significantly
reduce the number of ratings required in comparison to the number needed to
find an exact ranking. We propose a computationally efficient PAC algorithm
LUCBRank for coarse ranking, and derive an upper bound on its sample
complexity. We also derive a nearly matching distribution-dependent lower
bound. Experiments on synthetic as well as real-world data show that LUCBRank
performs better than state-of-the-art baseline methods, even when these methods
have the advantage of knowing the underlying parametric model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Katariya_S/0/1/0/all/0/1&quot;&gt;Sumeet Katariya&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jain_L/0/1/0/all/0/1&quot;&gt;Lalit Jain&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sengupta_N/0/1/0/all/0/1&quot;&gt;Nandana Sengupta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Evans_J/0/1/0/all/0/1&quot;&gt;James Evans&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nowak_R/0/1/0/all/0/1&quot;&gt;Robert Nowak&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.07229">
<title>Actively Avoiding Nonsense in Generative Models. (arXiv:1802.07229v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.07229</link>
<description rdf:parseType="Literal">&lt;p&gt;A generative model may generate utter nonsense when it is fit to maximize the
likelihood of observed data. This happens due to &quot;model error,&quot; i.e., when the
true data generating distribution does not fit within the class of generative
models being learned. To address this, we propose a model of active
distribution learning using a binary invalidity oracle that identifies some
examples as clearly invalid, together with random positive examples sampled
from the true distribution. The goal is to maximize the likelihood of the
positive examples subject to the constraint of (almost) never generating
examples labeled invalid by the oracle. Guarantees are agnostic compared to a
class of probability distributions. We show that, while proper learning often
requires exponentially many queries to the invalidity oracle, improper
distribution learning can be done using polynomially many queries.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hanneke_S/0/1/0/all/0/1&quot;&gt;Steve Hanneke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kalai_A/0/1/0/all/0/1&quot;&gt;Adam Kalai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kamath_G/0/1/0/all/0/1&quot;&gt;Gautam Kamath&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tzamos_C/0/1/0/all/0/1&quot;&gt;Christos Tzamos&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1607.02665">
<title>Classifier Risk Estimation under Limited Labeling Resources. (arXiv:1607.02665v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1607.02665</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper we propose strategies for estimating performance of a
classifier when labels cannot be obtained for the whole test set. The number of
test instances which can be labeled is very small compared to the whole test
data size. The goal then is to obtain a precise estimate of classifier
performance using as little labeling resource as possible. Specifically, we try
to answer, how to select a subset of the large test set for labeling such that
the performance of a classifier estimated on this subset is as close as
possible to the one on the whole test set. We propose strategies based on
stratified sampling for selecting this subset. We show that these strategies
can reduce the variance in estimation of classifier accuracy by a significant
amount compared to simple random sampling (over 65% in several cases). Hence,
our proposed methods are much more precise compared to random sampling for
accuracy estimation under restricted labeling resources. The reduction in
number of samples required (compared to random sampling) to estimate the
classifier accuracy with only 1% error is high as 60% in some cases.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kumar_A/0/1/0/all/0/1&quot;&gt;Anurag Kumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Raj_B/0/1/0/all/0/1&quot;&gt;Bhiksha Raj&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.04168">
<title>Unsupervised Document Embedding With CNNs. (arXiv:1711.04168v3 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1711.04168</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a new model for unsupervised document embedding. Leading existing
approaches either require complex inference or use recurrent neural networks
(RNN) that are difficult to parallelize. We take a different route and develop
a convolutional neural network (CNN) embedding model. Our CNN architecture is
fully parallelizable resulting in over 10x speedup in inference time over RNN
models. Parallelizable architecture enables to train deeper models where each
successive layer has increasingly larger receptive field and models longer
range semantic structure within the document. We additionally propose a fully
unsupervised learning algorithm to train this model based on stochastic forward
prediction. Empirical results on two public benchmarks show that our approach
produces comparable to state-of-the-art accuracy at a fraction of computational
cost.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1&quot;&gt;Chundi Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_S/0/1/0/all/0/1&quot;&gt;Shunan Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Volkovs_M/0/1/0/all/0/1&quot;&gt;Maksims Volkovs&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.03360">
<title>Information Planning for Text Data. (arXiv:1802.03360v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1802.03360</link>
<description rdf:parseType="Literal">&lt;p&gt;Information planning enables faster learning with fewer training examples. It
is particularly applicable when training examples are costly to obtain. This
work examines the advantages of information planning for text data by focusing
on three supervised models: Naive Bayes, supervised LDA and deep neural
networks. We show that planning based on entropy and mutual information
outperforms random selection baseline and therefore accelerates learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Smolyakov_V/0/1/0/all/0/1&quot;&gt;Vadim Smolyakov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Fisher_J/0/1/0/all/0/1&quot;&gt;John W. Fisher III&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05351">
<title>Stealing Hyperparameters in Machine Learning. (arXiv:1802.05351v2 [cs.CR] UPDATED)</title>
<link>http://arxiv.org/abs/1802.05351</link>
<description rdf:parseType="Literal">&lt;p&gt;Hyperparameters are critical in machine learning, as different
hyperparameters often result in models with significantly different
performance. Hyperparameters may be deemed confidential because of their
commercial value and the confidentiality of the proprietary algorithms that the
learner uses to learn them. In this work, we propose attacks on stealing the
hyperparameters that are learned by a learner. We call our attacks
hyperparameter stealing attacks. Our attacks are applicable to a variety of
popular machine learning algorithms such as ridge regression, logistic
regression, support vector machine, and neural network. We evaluate the
effectiveness of our attacks both theoretically and empirically. For instance,
we evaluate our attacks on Amazon Machine Learning. Our results demonstrate
that our attacks can accurately steal hyperparameters. We also study
countermeasures. Our results highlight the need for new defenses against our
hyperparameter stealing attacks for certain machine learning algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1&quot;&gt;Binghui Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gong_N/0/1/0/all/0/1&quot;&gt;Neil Zhenqiang Gong&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05799">
<title>Horovod: fast and easy distributed deep learning in TensorFlow. (arXiv:1802.05799v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1802.05799</link>
<description rdf:parseType="Literal">&lt;p&gt;Training modern deep learning models requires large amounts of computation,
often provided by GPUs. Scaling computation from one GPU to many can enable
much faster training and research progress but entails two complications.
First, the training library must support inter-GPU communication. Depending on
the particular methods employed, this communication may entail anywhere from
negligible to significant overhead. Second, the user must modify his or her
training code to take advantage of inter-GPU communication. Depending on the
training library&apos;s API, the modification required may be either significant or
minimal.
&lt;/p&gt;
&lt;p&gt;Existing methods for enabling multi-GPU training under the TensorFlow library
entail non-negligible communication overhead and require users to heavily
modify their model-building code, leading many researchers to avoid the whole
mess and stick with slower single-GPU training. In this paper we introduce
Horovod, an open source library that improves on both obstructions to scaling:
it employs efficient inter-GPU communication via ring reduction and requires
only a few lines of modification to user code, enabling faster, easier
distributed training in TensorFlow. Horovod is available under the Apache 2.0
license at https://github.com/uber/horovod
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sergeev_A/0/1/0/all/0/1&quot;&gt;Alexander Sergeev&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Balso_M/0/1/0/all/0/1&quot;&gt;Mike Del Balso&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06384">
<title>Neural Networks with Finite Intrinsic Dimension have no Spurious Valleys. (arXiv:1802.06384v2 [math.OC] UPDATED)</title>
<link>http://arxiv.org/abs/1802.06384</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural networks provide a rich class of high-dimensional, non-convex
optimization problems. Despite their non-convexity, gradient-descent methods
often successfully optimize these models. This has motivated a recent spur in
research attempting to characterize properties of their loss surface that may
be responsible for such success. In particular, several authors have noted that
over-parametrization appears to act as a remedy against non-convexity.
&lt;/p&gt;
&lt;p&gt;In this paper, we address this phenomenon by studying key topological
properties of the loss, such as the presence or absence of &quot;spurious valleys&quot;,
defined as connected components of sub-level sets that do not include a global
minimum. Focusing on a class of two-layer neural networks defined by smooth
(but generally non-linear) activation functions, our main contribution is to
prove that as soon as the hidden layer size matches the intrinsic dimension of
the reproducing space, defined as the linear functional space generated by the
activations, no spurious valleys exist, thus allowing the existence of descent
directions. Our setup includes smooth activations such as polynomials, both in
the empirical and population risk, and generic activations in the empirical
risk case.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Venturi_L/0/1/0/all/0/1&quot;&gt;Luca Venturi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Bandeira_A/0/1/0/all/0/1&quot;&gt;Afonso S. Bandeira&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Bruna_J/0/1/0/all/0/1&quot;&gt;Joan Bruna&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06309">
<title>Learning Adversarially Fair and Transferable Representations. (arXiv:1802.06309v1 [cs.LG] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1802.06309</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work, we advocate for representation learning as the key to
mitigating unfair prediction outcomes downstream. We envision a scenario where
learned representations may be handed off to other entities with unknown
objectives. We propose and explore adversarial representation learning as a
natural method of ensuring those entities will act fairly, and connect group
fairness (demographic parity, equalized odds, and equal opportunity) to
different adversarial objectives. Through worst-case theoretical guarantees and
experimental validation, we show that the choice of this objective is crucial
to fair prediction. Furthermore, we present the first in-depth experimental
demonstration of fair transfer learning, by showing that our learned
representations admit fair predictions on new tasks while maintaining utility,
an essential goal of fair representation learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Madras_D/0/1/0/all/0/1&quot;&gt;David Madras&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Creager_E/0/1/0/all/0/1&quot;&gt;Elliot Creager&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pitassi_T/0/1/0/all/0/1&quot;&gt;Toniann Pitassi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zemel_R/0/1/0/all/0/1&quot;&gt;Richard Zemel&lt;/a&gt;</dc:creator>
</item></rdf:RDF>