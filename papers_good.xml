<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Good papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Good Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-06-03T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00149"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.10380"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.01563"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.10492"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00050"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00175"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00258"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00340"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00354"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1704.01074"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.06662"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.00144"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00003"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00007"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00035"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00081"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00088"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00101"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00145"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00148"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00166"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00179"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00195"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00250"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00338"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00381"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00388"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00400"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00420"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00421"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00428"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00463"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00468"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1708.00489"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.09090"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.05690"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.00816"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07892"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09921"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11016"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1806.00149">
<title>q-Neurons: Neuron Activations based on Stochastic Jackson&apos;s Derivative Operators. (arXiv:1806.00149v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1806.00149</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a new generic type of stochastic neurons, called $q$-neurons, that
considers activation functions based on Jackson&apos;s $q$-derivatives with
stochastic parameters $q$. Our generalization of neural network architectures
with $q$-neurons is shown to be both scalable and very easy to implement. We
demonstrate experimentally consistently improved performances over
state-of-the-art standard activation functions, both on training and testing
loss functions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nielsen_F/0/1/0/all/0/1&quot;&gt;Frank Nielsen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_K/0/1/0/all/0/1&quot;&gt;Ke Sun&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.10380">
<title>Speeding up Context-based Sentence Representation Learning with Non-autoregressive Convolutional Decoding. (arXiv:1710.10380v3 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1710.10380</link>
<description rdf:parseType="Literal">&lt;p&gt;Context plays an important role in human language understanding, thus it may
also be useful for machines learning vector representations of language. In
this paper, we explore an asymmetric encoder-decoder structure for unsupervised
context-based sentence representation learning. We carefully designed
experiments to show that neither an autoregressive decoder nor an RNN decoder
is required. After that, we designed a model which still keeps an RNN as the
encoder, while using a non-autoregressive convolutional decoder. We further
combine a suite of effective designs to significantly improve model efficiency
while also achieving better performance. Our model is trained on two different
large unlabelled corpora, and in both cases the transferability is evaluated on
a set of downstream NLP tasks. We empirically show that our model is simple and
fast while producing rich sentence representations that excel in downstream
tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_S/0/1/0/all/0/1&quot;&gt;Shuai Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jin_H/0/1/0/all/0/1&quot;&gt;Hailin Jin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fang_C/0/1/0/all/0/1&quot;&gt;Chen Fang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zhaowen Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sa_V/0/1/0/all/0/1&quot;&gt;Virginia R. de Sa&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.01563">
<title>DENSER: Deep Evolutionary Network Structured Representation. (arXiv:1801.01563v3 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1801.01563</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep Evolutionary Network Structured Representation (DENSER) is a novel
approach to automatically design Artificial Neural Networks (ANNs) using
Evolutionary Computation. The algorithm not only searches for the best network
topology (e.g., number of layers, type of layers), but also tunes
hyper-parameters, such as, learning parameters or data augmentation parameters.
The automatic design is achieved using a representation with two distinct
levels, where the outer level encodes the general structure of the network,
i.e., the sequence of layers, and the inner level encodes the parameters
associated with each layer. The allowed layers and range of the
hyper-parameters values are defined by means of a human-readable Context-Free
Grammar. DENSER was used to evolve ANNs for CIFAR-10, obtaining an average test
accuracy of 94.13%. The networks evolved for the CIFA--10 are tested on the
MNIST, Fashion-MNIST, and CIFAR-100; the results are highly competitive, and on
the CIFAR-100 we report a test accuracy of 78.75%. To the best of our
knowledge, our CIFAR-100 results are the highest performing models generated by
methods that aim at the automatic design of Convolutional Neural Networks
(CNNs), and are amongst the best for manually designed and fine-tuned CNNs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Assuncao_F/0/1/0/all/0/1&quot;&gt;Filipe Assun&amp;#xe7;&amp;#xe3;o&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lourenco_N/0/1/0/all/0/1&quot;&gt;Nuno Louren&amp;#xe7;o&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Machado_P/0/1/0/all/0/1&quot;&gt;Penousal Machado&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ribeiro_B/0/1/0/all/0/1&quot;&gt;Bernardete Ribeiro&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.10492">
<title>Deep Predictive Models in Interactive Music. (arXiv:1801.10492v2 [cs.SD] UPDATED)</title>
<link>http://arxiv.org/abs/1801.10492</link>
<description rdf:parseType="Literal">&lt;p&gt;Musical performance requires prediction to operate instruments, to perform in
groups and to improvise. We argue, with reference to a number of digital music
instruments (DMIs), including two of our own, that predictive machine learning
models can help interactive systems to understand their temporal context and
ensemble behaviour. We also discuss how recent advances in deep learning
highlight the role of prediction in DMIs, by allowing data-driven predictive
models with a long memory of past states.
&lt;/p&gt;
&lt;p&gt;We advocate for predictive musical interaction, where a predictive model is
embedded in a musical interface, assisting users by predicting unknown states
of musical processes. We propose a framework for characterising prediction as
relating to the instrumental sound, ongoing musical process, or between members
of an ensemble. Our framework shows that different musical interface design
configurations lead to different types of prediction. We show that our
framework accommodates deep generative models, as well as models for predicting
gestural states, or other high-level musical information. We apply our
framework to examples from our recent work and the literature, and discuss the
benefits and challenges revealed by these systems as well as musical use-cases
where prediction is a necessary component.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Martin_C/0/1/0/all/0/1&quot;&gt;Charles P. Martin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ellefsen_K/0/1/0/all/0/1&quot;&gt;Kai Olav Ellefsen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Torresen_J/0/1/0/all/0/1&quot;&gt;Jim Torresen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00050">
<title>Interpretable Set Functions. (arXiv:1806.00050v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.00050</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose learning flexible but interpretable functions that aggregate a
variable-length set of permutation-invariant feature vectors to predict a
label. We use a deep lattice network model so we can architect the model
structure to enhance interpretability, and add monotonicity constraints between
inputs-and-outputs. We then use the proposed set function to automate the
engineering of dense, interpretable features from sparse categorical features,
which we call semantic feature engine. Experiments on real-world data show the
achieved accuracy is similar to deep sets or deep neural networks, and is
easier to debug and understand.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cotter_A/0/1/0/all/0/1&quot;&gt;Andrew Cotter&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gupta_M/0/1/0/all/0/1&quot;&gt;Maya Gupta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1&quot;&gt;Heinrich Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Muller_J/0/1/0/all/0/1&quot;&gt;James Muller&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Narayan_T/0/1/0/all/0/1&quot;&gt;Taman Narayan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1&quot;&gt;Serena Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_T/0/1/0/all/0/1&quot;&gt;Tao Zhu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00175">
<title>Strategic Object Oriented Reinforcement Learning. (arXiv:1806.00175v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1806.00175</link>
<description rdf:parseType="Literal">&lt;p&gt;Humans learn to play video games significantly faster than state-of-the-art
reinforcement learning (RL) algorithms. Inspired by this, we introduce
strategic object oriented reinforcement learning (SOORL) to learn simple
dynamics model through automatic model selection and perform efficient planning
with strategic exploration. We compare different exploration strategies in a
model-based setting in which exact planning is impossible. Additionally, we
test our approach on perhaps the hardest Atari game Pitfall! and achieve
significantly improved exploration and performance over prior methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Keramati_R/0/1/0/all/0/1&quot;&gt;Ramtin Keramati&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Whang_J/0/1/0/all/0/1&quot;&gt;Jay Whang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cho_P/0/1/0/all/0/1&quot;&gt;Patrick Cho&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brunskill_E/0/1/0/all/0/1&quot;&gt;Emma Brunskill&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00258">
<title>A Survey of Domain Adaptation for Neural Machine Translation. (arXiv:1806.00258v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1806.00258</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural machine translation (NMT) is a deep learning based approach for
machine translation, which yields the state-of-the-art translation performance
in scenarios where large-scale parallel corpora are available. Although the
high-quality and domain-specific translation is crucial in the real world,
domain-specific corpora are usually scarce or nonexistent, and thus vanilla NMT
performs poorly in such scenarios. Domain adaptation that leverages both
out-of-domain parallel corpora as well as monolingual corpora for in-domain
translation, is very important for domain-specific translation. In this paper,
we give a comprehensive survey of the state-of-the-art domain adaptation
techniques for NMT.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chu_C/0/1/0/all/0/1&quot;&gt;Chenhui Chu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1&quot;&gt;Rui Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00340">
<title>Producing radiologist-quality reports for interpretable artificial intelligence. (arXiv:1806.00340v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1806.00340</link>
<description rdf:parseType="Literal">&lt;p&gt;Current approaches to explaining the decisions of deep learning systems for
medical tasks have focused on visualising the elements that have contributed to
each decision. We argue that such approaches are not enough to &quot;open the black
box&quot; of medical decision making systems because they are missing a key
component that has been used as a standard communication tool between doctors
for centuries: language. We propose a model-agnostic interpretability method
that involves training a simple recurrent neural network model to produce
descriptive sentences to clarify the decision of deep learning classifiers.
&lt;/p&gt;
&lt;p&gt;We test our method on the task of detecting hip fractures from frontal pelvic
x-rays. This process requires minimal additional labelling despite producing
text containing elements that the original deep learning classification model
was not specifically trained to detect.
&lt;/p&gt;
&lt;p&gt;The experimental results show that: 1) the sentences produced by our method
consistently contain the desired information, 2) the generated sentences are
preferred by doctors compared to current tools that create saliency maps, and
3) the combination of visualisations and generated text is better than either
alone.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gale_W/0/1/0/all/0/1&quot;&gt;William Gale&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oakden_Rayner_L/0/1/0/all/0/1&quot;&gt;Luke Oakden-Rayner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Carneiro_G/0/1/0/all/0/1&quot;&gt;Gustavo Carneiro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bradley_A/0/1/0/all/0/1&quot;&gt;Andrew P Bradley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Palmer_L/0/1/0/all/0/1&quot;&gt;Lyle J Palmer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00354">
<title>Some of Them Can be Guessed! Exploring the Effect of Linguistic Context in Predicting Quantifiers. (arXiv:1806.00354v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1806.00354</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the role of linguistic context in predicting quantifiers (`few&apos;,
`all&apos;). We collect crowdsourced data from human participants and test various
models in a local (single-sentence) and a global context (multi-sentence)
condition. Models significantly out-perform humans in the former setting and
are only slightly better in the latter. While human performance improves with
more linguistic context (especially on proportional quantifiers), model
performance suffers. Models are very effective in exploiting lexical and
morpho-syntactic patterns; humans are better at genuinely understanding the
meaning of the (global) context.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pezzelle_S/0/1/0/all/0/1&quot;&gt;Sandro Pezzelle&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Steinert_Threlkeld_S/0/1/0/all/0/1&quot;&gt;Shane Steinert-Threlkeld&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bernardi_R/0/1/0/all/0/1&quot;&gt;Raffaela Bernardi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Szymanik_J/0/1/0/all/0/1&quot;&gt;Jakub Szymanik&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1704.01074">
<title>Emotional Chatting Machine: Emotional Conversation Generation with Internal and External Memory. (arXiv:1704.01074v4 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1704.01074</link>
<description rdf:parseType="Literal">&lt;p&gt;Perception and expression of emotion are key factors to the success of
dialogue systems or conversational agents. However, this problem has not been
studied in large-scale conversation generation so far. In this paper, we
propose Emotional Chatting Machine (ECM) that can generate appropriate
responses not only in content (relevant and grammatical) but also in emotion
(emotionally consistent). To the best of our knowledge, this is the first work
that addresses the emotion factor in large-scale conversation generation. ECM
addresses the factor using three new mechanisms that respectively (1) models
the high-level abstraction of emotion expressions by embedding emotion
categories, (2) captures the change of implicit internal emotion states, and
(3) uses explicit emotion expressions with an external emotion vocabulary.
Experiments show that the proposed model can generate responses appropriate not
only in content but also in emotion.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1&quot;&gt;Hao Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_M/0/1/0/all/0/1&quot;&gt;Minlie Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1&quot;&gt;Tianyang Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1&quot;&gt;Xiaoyan Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1&quot;&gt;Bing Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.06662">
<title>Verifying Properties of Binarized Deep Neural Networks. (arXiv:1709.06662v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1709.06662</link>
<description rdf:parseType="Literal">&lt;p&gt;Understanding properties of deep neural networks is an important challenge in
deep learning. In this paper, we take a step in this direction by proposing a
rigorous way of verifying properties of a popular class of neural networks,
Binarized Neural Networks, using the well-developed means of Boolean
satisfiability. Our main contribution is a construction that creates a
representation of a binarized neural network as a Boolean formula. Our encoding
is the first exact Boolean representation of a deep neural network. Using this
encoding, we leverage the power of modern SAT solvers along with a proposed
counterexample-guided search procedure to verify various properties of these
networks. A particular focus will be on the critical property of robustness to
adversarial perturbations. For this property, our experimental results
demonstrate that our approach scales to medium-size deep neural networks used
in image classification tasks. To the best of our knowledge, this is the first
work on verifying properties of deep neural networks using an exact Boolean
encoding of the network.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Narodytska_N/0/1/0/all/0/1&quot;&gt;Nina Narodytska&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kasiviswanathan_S/0/1/0/all/0/1&quot;&gt;Shiva Prasad Kasiviswanathan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ryzhyk_L/0/1/0/all/0/1&quot;&gt;Leonid Ryzhyk&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sagiv_M/0/1/0/all/0/1&quot;&gt;Mooly Sagiv&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Walsh_T/0/1/0/all/0/1&quot;&gt;Toby Walsh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.00144">
<title>Learning Longer-term Dependencies in RNNs with Auxiliary Losses. (arXiv:1803.00144v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1803.00144</link>
<description rdf:parseType="Literal">&lt;p&gt;Despite recent advances in training recurrent neural networks (RNNs),
capturing long-term dependencies in sequences remains a fundamental challenge.
Most approaches use backpropagation through time (BPTT), which is difficult to
scale to very long sequences. This paper proposes a simple method that improves
the ability to capture long term dependencies in RNNs by adding an unsupervised
auxiliary loss to the original objective. This auxiliary loss forces RNNs to
either reconstruct previous events or predict next events in a sequence, making
truncated backpropagation feasible for long sequences and also improving full
BPTT. We evaluate our method on a variety of settings, including pixel-by-pixel
image classification with sequence lengths up to 16\,000, and a real document
classification benchmark. Our results highlight good performance and resource
efficiency of this approach over competitive baselines, including other
recurrent models and a comparable sized Transformer. Further analyses reveal
beneficial effects of the auxiliary loss on optimization and regularization, as
well as extreme cases where there is little to no backpropagation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Trinh_T/0/1/0/all/0/1&quot;&gt;Trieu H. Trinh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dai_A/0/1/0/all/0/1&quot;&gt;Andrew M. Dai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luong_M/0/1/0/all/0/1&quot;&gt;Minh-Thang Luong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Le_Q/0/1/0/all/0/1&quot;&gt;Quoc V. Le&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00003">
<title>A mixture model for aggregation of multiple pre-trained weak classifiers. (arXiv:1806.00003v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.00003</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep networks have gained immense popularity in Computer Vision and other
fields in the past few years due to their remarkable performance on
recognition/classification tasks surpassing the state-of-the art. One of the
keys to their success lies in the richness of the automatically learned
features. In order to get very good accuracy, one popular option is to increase
the depth of the network. Training such a deep network is however infeasible or
impractical with moderate computational resources and budget. The other
alternative to increase the performance is to learn multiple weak classifiers
and boost their performance using a boosting algorithm or a variant thereof.
But, one of the problems with boosting algorithms is that they require a
re-training of the networks based on the misclassified samples. Motivated by
these problems, in this work we propose an aggregation technique which combines
the output of multiple weak classifiers. We formulate the aggregation problem
using a mixture model fitted to the trained classifier outputs. Our model does
not require any re-training of the `weak&apos; networks and is computationally very
fast (takes $&amp;lt;30$ seconds to run in our experiments). Thus, using a less
expensive training stage and without doing any re-training of networks, we
experimentally demonstrate that it is possible to boost the performance by
$12\%$. Furthermore, we present experiments using hand-crafted features and
improved the classification performance using the proposed aggregation
technique. One of the major advantages of our framework is that our framework
allows one to combine features that are very likely to be of distinct
dimensions since they are extracted using different networks/algorithms. Our
experimental results demonstrate a significant performance gain from the use of
our aggregation technique at a very small computational cost.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chakraborty_R/0/1/0/all/0/1&quot;&gt;Rudrasis Chakraborty&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1&quot;&gt;Chun-Hao Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vemuri_B/0/1/0/all/0/1&quot;&gt;Baba C. Vemuri&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00007">
<title>Multi-Layered Gradient Boosting Decision Trees. (arXiv:1806.00007v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.00007</link>
<description rdf:parseType="Literal">&lt;p&gt;Multi-layered representation is believed to be the key ingredient of deep
neural networks especially in cognitive tasks like computer vision. While
non-differentiable models such as gradient boosting decision trees (GBDTs) are
the dominant methods for modeling discrete or tabular data, they are hard to
incorporate with such representation learning ability. In this work, we propose
the multi-layered GBDT forest (mGBDTs), with an explicit emphasis on exploring
the ability to learn hierarchical representations by stacking several layers of
regression GBDTs as its building block. The model can be jointly trained by a
variant of target propagation across layers, without the need to derive
back-propagation nor differentiability. Experiments and visualizations
confirmed the effectiveness of the model in terms of performance and
representation learning ability.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1&quot;&gt;Ji Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1&quot;&gt;Yang Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1&quot;&gt;Zhi-Hua Zhou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00035">
<title>Assessing Generative Models via Precision and Recall. (arXiv:1806.00035v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.00035</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent advances in generative modeling have led to an increased interest in
the study of statistical divergences as means of model comparison. Commonly
used evaluation methods, such as Fr\&apos;echet Inception Distance (FID), correlate
well with the perceived quality of samples and are sensitive to mode dropping.
However, these metrics are unable to distinguish between different failure
cases since they yield one-dimensional scores. We propose a novel definition of
precision and recall for distributions which disentangles the divergence into
two separate dimensions. The proposed notion is intuitive, retains desirable
properties, and naturally leads to an efficient algorithm that can be used to
evaluate generative models. We relate this notion to total variation as well as
to recent evaluation metrics such as Inception Score and FID. To demonstrate
the practical utility of the proposed approach we perform an empirical study on
several variants of Generative Adversarial Networks and the Variational
Autoencoder. In an extensive set of experiments we show that the proposed
metric is able to disentangle the quality of generated samples from the
coverage of the target distribution.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sajjadi_M/0/1/0/all/0/1&quot;&gt;Mehdi S. M. Sajjadi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bachem_O/0/1/0/all/0/1&quot;&gt;Olivier Bachem&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lucic_M/0/1/0/all/0/1&quot;&gt;Mario Lucic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bousquet_O/0/1/0/all/0/1&quot;&gt;Olivier Bousquet&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gelly_S/0/1/0/all/0/1&quot;&gt;Sylvain Gelly&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00081">
<title>Resisting Adversarial Attacks using Gaussian Mixture Variational Autoencoders. (arXiv:1806.00081v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.00081</link>
<description rdf:parseType="Literal">&lt;p&gt;Susceptibility of deep neural networks to adversarial attacks poses a major
theoretical and practical challenge. All efforts to harden classifiers against
such attacks have seen limited success. Two distinct categories of samples to
which deep networks are vulnerable, &quot;adversarial samples&quot; and &quot;fooling
samples&quot;, have been tackled separately so far due to the difficulty posed when
considered together. In this work, we show how one can address them both under
one unified framework. We tie a discriminative model with a generative model,
rendering the adversarial objective to entail a conflict. Our model has the
form of a variational autoencoder, with a Gaussian mixture prior on the latent
vector. Each mixture component of the prior distribution corresponds to one of
the classes in the data. This enables us to perform selective classification,
leading to the rejection of adversarial samples instead of misclassification.
Our method inherently provides a way of learning a selective classifier in a
semi-supervised scenario as well, which can resist adversarial attacks. We also
show how one can reclassify the rejected adversarial samples.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghosh_P/0/1/0/all/0/1&quot;&gt;Partha Ghosh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Losalka_A/0/1/0/all/0/1&quot;&gt;Arpan Losalka&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Black_M/0/1/0/all/0/1&quot;&gt;Michael J Black&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00088">
<title>PeerNets: Exploiting Peer Wisdom Against Adversarial Attacks. (arXiv:1806.00088v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.00088</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep learning systems have become ubiquitous in many aspects of our lives.
Unfortunately, it has been shown that such systems are vulnerable to
adversarial attacks, making them prone to potential unlawful uses. Designing
deep neural networks that are robust to adversarial attacks is a fundamental
step in making such systems safer and deployable in a broader variety of
applications (e.g. autonomous driving), but more importantly is a necessary
step to design novel and more advanced architectures built on new computational
paradigms rather than marginally building on the existing ones. In this paper
we introduce PeerNets, a novel family of convolutional networks alternating
classical Euclidean convolutions with graph convolutions to harness information
from a graph of peer samples. This results in a form of non-local forward
propagation in the model, where latent features are conditioned on the global
structure induced by the graph, that is up to 3 times more robust to a variety
of white- and black-box adversarial attacks compared to conventional
architectures with almost no drop in accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Svoboda_J/0/1/0/all/0/1&quot;&gt;Jan Svoboda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Masci_J/0/1/0/all/0/1&quot;&gt;Jonathan Masci&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Monti_F/0/1/0/all/0/1&quot;&gt;Federico Monti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bronstein_M/0/1/0/all/0/1&quot;&gt;Michael M. Bronstein&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guibas_L/0/1/0/all/0/1&quot;&gt;Leonidas Guibas&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00101">
<title>Ratio Matching MMD Nets: Low dimensional projections for effective deep generative models. (arXiv:1806.00101v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.00101</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep generative models can learn to generate realistic-looking images on
several natural image datasets, but many of the most effective methods are
adversarial methods, which require careful balancing of training between a
generator network and a discriminator network. Maximum mean discrepancy
networks (MMD-nets) avoid this issue using the kernel trick, but unfortunately
they have not on their own been able to match the performance of adversarial
training. We present a new method of training MMD-nets, based on learning a
mapping of samples from the data and from the model into a lower dimensional
space, in which MMD training can be more effective. We call these networks
ratio matching MMD networks (RMMMDnets). We train the mapping to preserve
density ratios between the densities over the low-dimensional space and the
original space. This ensures that matching the model distribution to the data
in the low-dimensional space will also match the original distributions. We
show that RM-MMDnets have better performance and better stability than recent
adversarial methods for training MMD-nets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Srivastava_A/0/1/0/all/0/1&quot;&gt;Akash Srivastava&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Xu_K/0/1/0/all/0/1&quot;&gt;Kai Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gutmann_M/0/1/0/all/0/1&quot;&gt;Michael U. Gutmann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sutton_C/0/1/0/all/0/1&quot;&gt;Charles Sutton&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00145">
<title>Tandem Blocks in Deep Convolutional Neural Networks. (arXiv:1806.00145v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.00145</link>
<description rdf:parseType="Literal">&lt;p&gt;Due to the success of residual networks (resnets) and related architectures,
shortcut connections have quickly become standard tools for building
convolutional neural networks. The explanations in the literature for the
apparent effectiveness of shortcuts are varied and often contradictory. We
hypothesize that shortcuts work primarily because they act as linear
counterparts to nonlinear layers. We test this hypothesis by using several
variations on the standard residual block, with different types of linear
connections, to build small image classification networks. Our experiments show
that other kinds of linear connections can be even more effective than the
identity shortcuts. Our results also suggest that the best type of linear
connection for a given application may depend on both network width and depth.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hettinger_C/0/1/0/all/0/1&quot;&gt;Chris Hettinger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Christensen_T/0/1/0/all/0/1&quot;&gt;Tanner Christensen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Humpherys_J/0/1/0/all/0/1&quot;&gt;Jeffrey Humpherys&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Jarvis_T/0/1/0/all/0/1&quot;&gt;Tyler J. Jarvis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00148">
<title>Interpreting Deep Learning: The Machine Learning Rorschach Test?. (arXiv:1806.00148v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.00148</link>
<description rdf:parseType="Literal">&lt;p&gt;Theoretical understanding of deep learning is one of the most important tasks
facing the statistics and machine learning communities. While deep neural
networks (DNNs) originated as engineering methods and models of biological
networks in neuroscience and psychology, they have quickly become a centerpiece
of the machine learning toolbox. Unfortunately, DNN adoption powered by recent
successes combined with the open-source nature of the machine learning
community, has outpaced our theoretical understanding. We cannot reliably
identify when and why DNNs will make mistakes. In some applications like text
translation these mistakes may be comical and provide for fun fodder in
research talks, a single error can be very costly in tasks like medical
imaging. As we utilize DNNs in increasingly sensitive applications, a better
understanding of their properties is thus imperative. Recent advances in DNN
theory are numerous and include many different sources of intuition, such as
learning theory, sparse signal analysis, physics, chemistry, and psychology. An
interesting pattern begins to emerge in the breadth of possible
interpretations. The seemingly limitless approaches are mostly constrained by
the lens with which the mathematical operations are viewed. Ultimately, the
interpretation of DNNs appears to mimic a type of Rorschach test --- a
psychological test wherein subjects interpret a series of seemingly ambiguous
ink-blots. Validation for DNN theory requires a convergence of the literature.
We must distinguish between universal results that are invariant to the
analysis perspective and those that are specific to a particular network
configuration. Simultaneously we must deal with the fact that many standard
statistical tools for quantifying generalization or empirically assessing
important network features are difficult to apply to DNNs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Charles_A/0/1/0/all/0/1&quot;&gt;Adam S. Charles&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00166">
<title>Training LSTM Networks with Resistive Cross-Point Devices. (arXiv:1806.00166v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.00166</link>
<description rdf:parseType="Literal">&lt;p&gt;In our previous work we have shown that resistive cross point devices, so
called Resistive Processing Unit (RPU) devices, can provide significant power
and speed benefits when training deep fully connected networks as well as
convolutional neural networks. In this work, we further extend the RPU concept
for training recurrent neural networks (RNNs) namely LSTMs. We show that the
mapping of recurrent layers is very similar to the mapping of fully connected
layers and therefore the RPU concept can potentially provide large acceleration
factors for RNNs as well. In addition, we study the effect of various device
imperfections and system parameters on training performance. Symmetry of
updates becomes even more crucial for RNNs; already a few percent asymmetry
results in an increase in the test error compared to the ideal case trained
with floating point numbers. Furthermore, the input signal resolution to device
arrays needs to be at least 7 bits for successful training. However, we show
that a stochastic rounding scheme can reduce the input signal resolution back
to 5 bits. Further, we find that RPU device variations and hardware noise are
enough to mitigate overfitting, so that there is less need for using dropout.
We note that the models trained here are roughly 1500 times larger than the
fully connected network trained on MNIST dataset in terms of the total number
of multiplication and summation operations performed per epoch. Thus, here we
attempt to study the validity of the RPU approach for large scale networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gokmen_T/0/1/0/all/0/1&quot;&gt;Tayfun Gokmen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rasch_M/0/1/0/all/0/1&quot;&gt;Malte Rasch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Haensch_W/0/1/0/all/0/1&quot;&gt;Wilfried Haensch&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00179">
<title>The Nonlinearity Coefficient - Predicting Overfitting in Deep Neural Networks. (arXiv:1806.00179v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.00179</link>
<description rdf:parseType="Literal">&lt;p&gt;For a long time, designing neural architectures that exhibit high performance
was considered a dark art that required expert hand-tuning. One of the few
well-known guidelines for architecture design is the avoidance of exploding
gradients, though even this guideline has remained relatively vague and
circumstantial. We introduce the nonlinearity coefficient (NLC), a measurement
of the complexity of the function computed by a neural network that is based on
the magnitude of the gradient. Via an extensive empirical study, we show that
the NLC is a powerful predictor of test error and that attaining a right-sized
NLC is essential for optimal performance.
&lt;/p&gt;
&lt;p&gt;The NLC exhibits a range of intriguing and important properties. It is
closely tied to the amount of information gained from computing a single
network gradient. It is tied to the error incurred when replacing the
nonlinearity operations in the network with linear operations. It is not
susceptible to the confounders of multiplicative scaling, additive bias and
layer width. It is stable from layer to layer. Hence, we argue that the NLC is
the first robust predictor of overfitting in deep networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Philipp_G/0/1/0/all/0/1&quot;&gt;George Philipp&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Carbonell_J/0/1/0/all/0/1&quot;&gt;Jaime G. Carbonell&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00195">
<title>Learning a Latent Space of Multitrack Measures. (arXiv:1806.00195v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.00195</link>
<description rdf:parseType="Literal">&lt;p&gt;Discovering and exploring the underlying structure of multi-instrumental
music using learning-based approaches remains an open problem. We extend the
recent MusicVAE model to represent multitrack polyphonic measures as vectors in
a latent space. Our approach enables several useful operations such as
generating plausible measures from scratch, interpolating between measures in a
musically meaningful way, and manipulating specific musical attributes. We also
introduce chord conditioning, which allows all of these operations to be
performed while keeping harmony fixed, and allows chords to be changed while
maintaining musical &quot;style&quot;. By generating a sequence of measures over a
predefined chord progression, our model can produce music with convincing
long-term structure. We demonstrate that our latent space model makes it
possible to intuitively control and generate musical sequences with rich
instrumentation (see https://goo.gl/s2N7dV for generated audio).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Simon_I/0/1/0/all/0/1&quot;&gt;Ian Simon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Roberts_A/0/1/0/all/0/1&quot;&gt;Adam Roberts&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Raffel_C/0/1/0/all/0/1&quot;&gt;Colin Raffel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Engel_J/0/1/0/all/0/1&quot;&gt;Jesse Engel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hawthorne_C/0/1/0/all/0/1&quot;&gt;Curtis Hawthorne&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Eck_D/0/1/0/all/0/1&quot;&gt;Douglas Eck&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00250">
<title>TAPAS: Train-less Accuracy Predictor for Architecture Search. (arXiv:1806.00250v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.00250</link>
<description rdf:parseType="Literal">&lt;p&gt;In recent years an increasing number of researchers and practitioners have
been suggesting algorithms for large-scale neural network architecture search:
genetic algorithms, reinforcement learning, learning curve extrapolation, and
accuracy predictors. None of them, however, demonstrated high-performance
without training new experiments in the presence of unseen datasets. We propose
a new deep neural network accuracy predictor, that estimates in fractions of a
second classification performance for unseen input datasets, without training.
In contrast to previously proposed approaches, our prediction is not only
calibrated on the topological network information, but also on the
characterization of the dataset-difficulty which allows us to re-tune the
prediction without any training. Our predictor achieves a performance which
exceeds 100 networks per second on a single GPU, thus creating the opportunity
to perform large-scale architecture search within a few minutes. We present
results of two searches performed in 400 seconds on a single GPU. Our best
discovered networks reach 93.67% accuracy for CIFAR-10 and 81.01% for
CIFAR-100, verified by training. These networks are performance competitive
with other automatically discovered state-of-the-art networks however we only
needed a small fraction of the time to solution and computational resources.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Istrate_R/0/1/0/all/0/1&quot;&gt;R. Istrate&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Scheidegger_F/0/1/0/all/0/1&quot;&gt;F. Scheidegger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mariani_G/0/1/0/all/0/1&quot;&gt;G. Mariani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nikolopoulos_D/0/1/0/all/0/1&quot;&gt;D. Nikolopoulos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bekas_C/0/1/0/all/0/1&quot;&gt;C. Bekas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Malossi_A/0/1/0/all/0/1&quot;&gt;A. C. I. Malossi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00338">
<title>Structured Local Optima in Sparse Blind Deconvolution. (arXiv:1806.00338v1 [eess.SP])</title>
<link>http://arxiv.org/abs/1806.00338</link>
<description rdf:parseType="Literal">&lt;p&gt;Blind deconvolution is a ubiquitous problem of recovering two unknown signals
from their convolution. Unfortunately, this is an ill-posed problem in general.
This paper focuses on the {\em short and sparse} blind deconvolution problem,
where the one unknown signal is short and the other one is sparsely and
randomly supported. This variant captures the structure of the unknown signals
in several important applications. We assume the short signal to have unit
$\ell^2$ norm and cast the blind deconvolution problem as a nonconvex
optimization problem over the sphere. We demonstrate that (i) in a certain
region of the sphere, every local optimum is close to some shift truncation of
the ground truth, and (ii) for a generic short signal of length $k$, when the
sparsity of activation signal $\theta\lesssim k^{-2/3}$ and number of
measurements $m\gtrsim poly(k)$, a simple initialization method together with a
descent algorithm which escapes strict saddle points recovers a near shift
truncation of the ground truth kernel.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yuqian Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Kuo_H/0/1/0/all/0/1&quot;&gt;Han-Wen Kuo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Wright_J/0/1/0/all/0/1&quot;&gt;John Wright&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00381">
<title>Persistence paths and signature features in topological data analysis. (arXiv:1806.00381v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.00381</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce a new feature map for barcodes that arise in persistent homology
computation. The main idea is to first realize each barcode as a path in a
convenient vector space, and to then compute its path signature which takes
values in the tensor algebra of that vector space. The composition of these two
operations - barcode to path, path to tensor series - results in a feature map
that has several desirable properties for statistical learning, such as
universality and characteristicness, and achieves state-of-the-art results on
common classification benchmarks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chevyrev_I/0/1/0/all/0/1&quot;&gt;Ilya Chevyrev&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Nanda_V/0/1/0/all/0/1&quot;&gt;Vidit Nanda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Oberhauser_H/0/1/0/all/0/1&quot;&gt;Harald Oberhauser&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00388">
<title>Opportunities in Machine Learning for Healthcare. (arXiv:1806.00388v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.00388</link>
<description rdf:parseType="Literal">&lt;p&gt;Healthcare is a natural arena for the application of machine learning,
especially as modern electronic health records (EHRs) provide increasingly
large amounts of data to answer clinically meaningful questions. However,
clinical data and practice present unique challenges that complicate the use of
common methodologies. This article serves as a primer on addressing these
challenges and highlights opportunities for members of the machine learning and
data science communities to contribute to this growing domain.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghassemi_M/0/1/0/all/0/1&quot;&gt;Marzyeh Ghassemi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Naumann_T/0/1/0/all/0/1&quot;&gt;Tristan Naumann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schulam_P/0/1/0/all/0/1&quot;&gt;Peter Schulam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Beam_A/0/1/0/all/0/1&quot;&gt;Andrew L. Beam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ranganath_R/0/1/0/all/0/1&quot;&gt;Rajesh Ranganath&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00400">
<title>Inverting Supervised Representations with Autoregressive Neural Density Models. (arXiv:1806.00400v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.00400</link>
<description rdf:parseType="Literal">&lt;p&gt;Understanding the nature of representations learned by supervised machine
learning models is a significant goal in the machine learning community. We
present a method for feature interpretation that makes use of recent advances
in autoregressive density estimation models to invert model representations. We
train generative inversion models to express a distribution over input features
conditioned on intermediate model representations. Insights into the
invariances learned by supervised models can be gained by viewing samples from
these inversion models. In addition, we can use these inversion models to
estimate the mutual information between a model&apos;s inputs and its intermediate
representations, thus quantifying the amount of information preserved by the
network at different stages. Using this method we examine the types of
information preserved at different layers of convolutional neural networks, and
explore the invariances induced by different architectural choices. Finally we
show that the mutual information between inputs and network layers decreases
over the course of training, supporting recent work by Shwartz-Ziv and Tishby
(2017) on the information bottleneck theory of deep learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Nash_C/0/1/0/all/0/1&quot;&gt;Charlie Nash&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kushman_N/0/1/0/all/0/1&quot;&gt;Nate Kushman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Williams_C/0/1/0/all/0/1&quot;&gt;Christopher K. I. Williams&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00420">
<title>Whitening and Coloring transform for GANs. (arXiv:1806.00420v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.00420</link>
<description rdf:parseType="Literal">&lt;p&gt;Batch Normalization (BN) is a common technique used both in discriminative
and generative networks in order to speed-up training. On the other hand, the
learnable parameters of BN are commonly used in conditional Generative
Adversarial Networks for representing class-specific information using
conditional Batch Normalization (cBN). In this paper we propose to generalize
both BN and cBN using a Whitening and Coloring based batch normalization. We
apply our method to conditional and unconditional image generation tasks and we
show that replacing the BN feature standardization and scaling with our feature
whitening and coloring improves the final qualitative results and the training
speed. We test our approach on different datasets and we show a consistent
improvement orthogonal to different GAN frameworks. Our CIFAR-10 supervised
results are higher than all previous works on this dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Siarohin_A/0/1/0/all/0/1&quot;&gt;Aliaksandr Siarohin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sangineto_E/0/1/0/all/0/1&quot;&gt;Enver Sangineto&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sebe_N/0/1/0/all/0/1&quot;&gt;Nicu Sebe&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00421">
<title>Solving stochastic differential equations and Kolmogorov equations by means of deep learning. (arXiv:1806.00421v1 [math.NA])</title>
<link>http://arxiv.org/abs/1806.00421</link>
<description rdf:parseType="Literal">&lt;p&gt;Stochastic differential equations (SDEs) and the Kolmogorov partial
differential equations (PDEs) associated to them have been widely used in
models from engineering, finance, and the natural sciences. In particular, SDEs
and Kolmogorov PDEs, respectively, are highly employed in models for the
approximative pricing of financial derivatives. Kolmogorov PDEs and SDEs,
respectively, can typically not be solved explicitly and it has been and still
is an active topic of research to design and analyze numerical methods which
are able to approximately solve Kolmogorov PDEs and SDEs, respectively. Nearly
all approximation methods for Kolmogorov PDEs in the literature suffer under
the curse of dimensionality or only provide approximations of the solution of
the PDE at a single fixed space-time point. In this paper we derive and propose
a numerical approximation method which aims to overcome both of the above
mentioned drawbacks and intends to deliver a numerical approximation of the
Kolmogorov PDE on an entire region $[a,b]^d$ without suffering from the curse
of dimensionality. Numerical results on examples including the heat equation,
the Black-Scholes model, the stochastic Lorenz equation, and the Heston model
suggest that the proposed approximation algorithm is quite effective in high
dimensions in terms of both accuracy and speed.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Beck_C/0/1/0/all/0/1&quot;&gt;Christian Beck&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Becker_S/0/1/0/all/0/1&quot;&gt;Sebastian Becker&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Grohs_P/0/1/0/all/0/1&quot;&gt;Philipp Grohs&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Jaafari_N/0/1/0/all/0/1&quot;&gt;Nor Jaafari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Jentzen_A/0/1/0/all/0/1&quot;&gt;Arnulf Jentzen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00428">
<title>A Classification approach towards Unsupervised Learning of Visual Representations. (arXiv:1806.00428v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1806.00428</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we present a technique for unsupervised learning of visual
representations. Specifically, we train a model for foreground and background
classification task, in the process of which it learns visual representations.
Foreground and background patches for training come af- ter mining for such
patches from hundreds and thousands of unlabelled videos available on the web
which we ex- tract using a proposed patch extraction algorithm. With- out using
any supervision, with just using 150, 000 unla- belled videos and the PASCAL
VOC 2007 dataset, we train a object recognition model that achieves 45.3 mAP
which is close to the best performing unsupervised feature learn- ing technique
whereas better than many other proposed al- gorithms. The code for patch
extraction is implemented in Matlab and available open source at the following
link .
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vora_A/0/1/0/all/0/1&quot;&gt;Aditya Vora&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00463">
<title>Adversarial quantum circuit learning for pure state approximation. (arXiv:1806.00463v1 [quant-ph])</title>
<link>http://arxiv.org/abs/1806.00463</link>
<description rdf:parseType="Literal">&lt;p&gt;Adversarial learning is one of the most successful approaches to modelling
high-dimensional probability distributions from data. The quantum computing
community has recently begun to generalize this idea and to look for potential
applications. In this work, we derive an adversarial algorithm for the problem
of approximating an unknown quantum pure state. Although this could be done on
error-corrected quantum computers, the adversarial formulation enables us to
execute the algorithm on near-term quantum computers. Two ansatz circuits are
optimized in tandem: One tries to approximate the target state, the other tries
to distinguish between target and approximated state. Supported by numerical
simulations, we show that resilient backpropagation algorithms perform
remarkably well in optimizing the two circuits. We use the bipartite
entanglement entropy to design an efficient heuristic for the stopping
criteria. Our approach may find application in quantum state tomography.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Benedetti_M/0/1/0/all/0/1&quot;&gt;Marcello Benedetti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Grant_E/0/1/0/all/0/1&quot;&gt;Edward Grant&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Wossnig_L/0/1/0/all/0/1&quot;&gt;Leonard Wossnig&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Severini_S/0/1/0/all/0/1&quot;&gt;Simone Severini&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00468">
<title>Implicit Bias of Gradient Descent on Linear Convolutional Networks. (arXiv:1806.00468v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.00468</link>
<description rdf:parseType="Literal">&lt;p&gt;We show that gradient descent on full-width linear convolutional networks of
depth $L$ converges to a linear predictor related to the $\ell_{2/L}$ bridge
penalty in the frequency domain. This is in contrast to linearly fully
connected networks, where gradient descent converges to the hard margin linear
support vector machine solution, regardless of depth.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gunasekar_S/0/1/0/all/0/1&quot;&gt;Suriya Gunasekar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1&quot;&gt;Jason Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Soudry_D/0/1/0/all/0/1&quot;&gt;Daniel Soudry&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Srebro_N/0/1/0/all/0/1&quot;&gt;Nathan Srebro&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1708.00489">
<title>Active Learning for Convolutional Neural Networks: A Core-Set Approach. (arXiv:1708.00489v4 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1708.00489</link>
<description rdf:parseType="Literal">&lt;p&gt;Convolutional neural networks (CNNs) have been successfully applied to many
recognition and learning tasks using a universal recipe; training a deep model
on a very large dataset of supervised examples. However, this approach is
rather restrictive in practice since collecting a large set of labeled images
is very expensive. One way to ease this problem is coming up with smart ways
for choosing images to be labelled from a very large collection (ie. active
learning).
&lt;/p&gt;
&lt;p&gt;Our empirical study suggests that many of the active learning heuristics in
the literature are not effective when applied to CNNs in batch setting.
Inspired by these limitations, we define the problem of active learning as
core-set selection, ie. choosing set of points such that a model learned over
the selected subset is competitive for the remaining data points. We further
present a theoretical result characterizing the performance of any selected
subset using the geometry of the datapoints. As an active learning algorithm,
we choose the subset which is expected to yield best result according to our
characterization. Our experiments show that the proposed method significantly
outperforms existing approaches in image classification experiments by a large
margin.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sener_O/0/1/0/all/0/1&quot;&gt;Ozan Sener&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Savarese_S/0/1/0/all/0/1&quot;&gt;Silvio Savarese&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.09090">
<title>Invariance of Weight Distributions in Rectified MLPs. (arXiv:1711.09090v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1711.09090</link>
<description rdf:parseType="Literal">&lt;p&gt;An interesting approach to analyzing neural networks that has received
renewed attention is to examine the equivalent kernel of the neural network.
This is based on the fact that a fully connected feedforward network with one
hidden layer, a certain weight distribution, an activation function, and an
infinite number of neurons can be viewed as a mapping into a Hilbert space. We
derive the equivalent kernels of MLPs with ReLU or Leaky ReLU activations for
all rotationally-invariant weight distributions, generalizing a previous result
that required Gaussian weight distributions. Additionally, the Central Limit
Theorem is used to show that for certain activation functions, kernels
corresponding to layers with weight distributions having $0$ mean and finite
absolute third moment are asymptotically universal, and are well approximated
by the kernel corresponding to layers with spherical Gaussian weights. In deep
networks, as depth increases the equivalent kernel approaches a pathological
fixed point, which can be used to argue why training randomly initialized
networks can be difficult. Our results also have implications for weight
initialization.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tsuchida_R/0/1/0/all/0/1&quot;&gt;Russell Tsuchida&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roosta_Khorasani_F/0/1/0/all/0/1&quot;&gt;Farbod Roosta-Khorasani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gallagher_M/0/1/0/all/0/1&quot;&gt;Marcus Gallagher&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.05690">
<title>Sockeye: A Toolkit for Neural Machine Translation. (arXiv:1712.05690v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1712.05690</link>
<description rdf:parseType="Literal">&lt;p&gt;We describe Sockeye (version 1.12), an open-source sequence-to-sequence
toolkit for Neural Machine Translation (NMT). Sockeye is a production-ready
framework for training and applying models as well as an experimental platform
for researchers. Written in Python and built on MXNet, the toolkit offers
scalable training and inference for the three most prominent encoder-decoder
architectures: attentional recurrent neural networks, self-attentional
transformers, and fully convolutional networks. Sockeye also supports a wide
range of optimizers, normalization and regularization techniques, and inference
improvements from current NMT literature. Users can easily run standard
training recipes, explore different model settings, and incorporate new ideas.
In this paper, we highlight Sockeye&apos;s features and benchmark it against other
NMT toolkits on two language arcs from the 2017 Conference on Machine
Translation (WMT): English-German and Latvian-English. We report competitive
BLEU scores across all three architectures, including an overall best score for
Sockeye&apos;s transformer implementation. To facilitate further comparison, we
release all system outputs and training scripts used in our experiments. The
Sockeye toolkit is free software released under the Apache 2.0 license.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hieber_F/0/1/0/all/0/1&quot;&gt;Felix Hieber&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Domhan_T/0/1/0/all/0/1&quot;&gt;Tobias Domhan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Denkowski_M/0/1/0/all/0/1&quot;&gt;Michael Denkowski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vilar_D/0/1/0/all/0/1&quot;&gt;David Vilar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sokolov_A/0/1/0/all/0/1&quot;&gt;Artem Sokolov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Clifton_A/0/1/0/all/0/1&quot;&gt;Ann Clifton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Post_M/0/1/0/all/0/1&quot;&gt;Matt Post&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.00816">
<title>NetGAN: Generating Graphs via Random Walks. (arXiv:1803.00816v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1803.00816</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose NetGAN - the first implicit generative model for graphs able to
mimic real-world networks. We pose the problem of graph generation as learning
the distribution of biased random walks over the input graph. The proposed
model is based on a stochastic neural network that generates discrete output
samples and is trained using the Wasserstein GAN objective. NetGAN is able to
produce graphs that exhibit well-known network patterns without explicitly
specifying them in the model definition. At the same time, our model exhibits
strong generalization properties, as highlighted by its competitive link
prediction performance, despite not being trained specifically for this task.
Being the first approach to combine both of these desirable properties, NetGAN
opens exciting avenues for further research.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bojchevski_A/0/1/0/all/0/1&quot;&gt;Aleksandar Bojchevski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Shchur_O/0/1/0/all/0/1&quot;&gt;Oleksandr Shchur&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zugner_D/0/1/0/all/0/1&quot;&gt;Daniel Z&amp;#xfc;gner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gunnemann_S/0/1/0/all/0/1&quot;&gt;Stephan G&amp;#xfc;nnemann&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07892">
<title>Localized Multiple Kernel Learning for Anomaly Detection: One-class Classification. (arXiv:1805.07892v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.07892</link>
<description rdf:parseType="Literal">&lt;p&gt;Multi-kernel learning has been well explored in the recent past and has
exhibited promising outcomes for multi-class classification and regression
tasks. In this paper, we present a multiple kernel learning approach for the
One-class Classification (OCC) task and employ it for anomaly detection.
Recently, the basic multi-kernel approach has been proposed to solve the OCC
problem, which is simply a convex combination of different kernels with equal
weights. This paper proposes a Localized Multiple Kernel learning approach for
Anomaly Detection (LMKAD) using OCC, where the weight for each kernel is
assigned locally. Proposed LMKAD approach adapts the weight for each kernel
using a gating function. The parameters of the gating function and one-class
classifier are optimized simultaneously through a two-step optimization
process. We present the empirical results of the performance of LMKAD on 25
benchmark datasets from various disciplines. This performance is evaluated
against existing Multi Kernel Anomaly Detection (MKAD) algorithm, and four
other existing kernel-based one-class classifiers to showcase the credibility
of our approach. Our algorithm achieves significantly better Gmean scores while
using a lesser number of support vectors compared to MKAD. Friedman test is
also performed to verify the statistical significance of the results claimed in
this paper.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gautam_C/0/1/0/all/0/1&quot;&gt;Chandan Gautam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Balaji_R/0/1/0/all/0/1&quot;&gt;Ramesh Balaji&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+K_S/0/1/0/all/0/1&quot;&gt;Sudharsan K&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tiwari_A/0/1/0/all/0/1&quot;&gt;Aruna Tiwari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ahuja_K/0/1/0/all/0/1&quot;&gt;Kapil Ahuja&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09921">
<title>Decision-Theoretic Meta-Learning: Versatile and Efficient Amortization of Few-Shot Learning. (arXiv:1805.09921v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1805.09921</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper develops a general framework for data efficient and versatile deep
learning. The new framework comprises three elements: 1) Discriminative
probabilistic models from multi-task learning that leverage shared statistical
information across tasks. 2) A novel Bayesian decision theoretic approach to
meta-learning probabilistic inference across many tasks. 3) A fast, flexible,
and simple to train amortization network that can automatically generalize and
extrapolate to a wide range of settings. The VERSA algorithm, a particular
instance of the framework, is evaluated on a suite of supervised few-shot
learning tasks. VERSA achieves state-of-the-art performance in one-shot
learning on Omniglot and miniImagenet, and produces compelling results on a
one-shot ShapeNet view reconstruction challenge.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gordon_J/0/1/0/all/0/1&quot;&gt;Jonathan Gordon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bronskill_J/0/1/0/all/0/1&quot;&gt;John Bronskill&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bauer_M/0/1/0/all/0/1&quot;&gt;Matthias Bauer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Nowozin_S/0/1/0/all/0/1&quot;&gt;Sebastian Nowozin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Turner_R/0/1/0/all/0/1&quot;&gt;Richard E. Turner&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11016">
<title>Memory Augmented Self-Play. (arXiv:1805.11016v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.11016</link>
<description rdf:parseType="Literal">&lt;p&gt;Self-play is an unsupervised training procedure which enables the
reinforcement learning agents to explore the environment without requiring any
external rewards. We augment the self-play setting by providing an external
memory where the agent can store experience from the previous tasks. This
enables the agent to come up with more diverse self-play tasks resulting in
faster exploration of the environment. The agent pretrained in the memory
augmented self-play setting easily outperforms the agent pretrained in
no-memory self-play setting.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sodhani_S/0/1/0/all/0/1&quot;&gt;Shagun Sodhani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pahuja_V/0/1/0/all/0/1&quot;&gt;Vardaan Pahuja&lt;/a&gt;</dc:creator>
</item></rdf:RDF>