<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Good papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Good Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-04-10T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.03313"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.03235"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.03301"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.03317"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.03342"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.03396"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.03424"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.03487"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.03592"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.05948"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.00532"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.03142"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.03176"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.03193"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.03286"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.03308"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.03334"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.03429"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.03515"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.03567"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.03629"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.03635"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1706.02216"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.07746"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1804.03313">
<title>Cortex Neural Network: learning with Neural Network groups. (arXiv:1804.03313v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1804.03313</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural Network has been successfully applied to many real-world problems,
such as image recognition and machine translation. However, for the current
architecture of neural networks, it is hard to perform complex cognitive tasks,
for example, to process the image and audio inputs together. Cortex, as an
important architecture in the brain, is important for animals to perform the
complex cognitive task. We view the architecture of Cortex in the brain as a
missing part in the design of the current artificial neural network. In this
paper, we purpose Cortex Neural Network (CrtxNN). The Cortex Neural Network is
an upper architecture of neural networks which motivated from cerebral cortex
in the brain to handle different tasks in the same learning system. It is able
to identify different tasks and solve them with different methods. In our
implementation, the Cortex Neural Network is able to process different
cognitive tasks and perform reflection to get a higher accuracy. We provide a
series of experiments to examine the capability of the cortex architecture on
traditional neural networks. Our experiments proved its ability on the Cortex
Neural Network can reach accuracy by 98.32% on MNIST and 62% on CIFAR10 at the
same time, which can promisingly reduce the loss by 40%.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_L/0/1/0/all/0/1&quot;&gt;Liyao Gao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.03235">
<title>Large scale distributed neural network training through online distillation. (arXiv:1804.03235v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1804.03235</link>
<description rdf:parseType="Literal">&lt;p&gt;Techniques such as ensembling and distillation promise model quality
improvements when paired with almost any base model. However, due to increased
test-time cost (for ensembles) and increased complexity of the training
pipeline (for distillation), these techniques are challenging to use in
industrial settings. In this paper we explore a variant of distillation which
is relatively straightforward to use as it does not require a complicated
multi-stage setup or many new hyperparameters. Our first claim is that online
distillation enables us to use extra parallelism to fit very large datasets
about twice as fast. Crucially, we can still speed up training even after we
have already reached the point at which additional parallelism provides no
benefit for synchronous or asynchronous stochastic gradient descent. Two neural
networks trained on disjoint subsets of the data can share knowledge by
encouraging each model to agree with the predictions the other model would have
made. These predictions can come from a stale version of the other model so
they can be safely computed using weights that only rarely get transmitted. Our
second claim is that online distillation is a cost-effective way to make the
exact predictions of a model dramatically more reproducible. We support our
claims using experiments on the Criteo Display Ad Challenge dataset, ImageNet,
and the largest to-date dataset used for neural language modeling, containing
$6\times 10^{11}$ tokens and based on the Common Crawl repository of web data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Anil_R/0/1/0/all/0/1&quot;&gt;Rohan Anil&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pereyra_G/0/1/0/all/0/1&quot;&gt;Gabriel Pereyra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Passos_A/0/1/0/all/0/1&quot;&gt;Alexandre Passos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ormandi_R/0/1/0/all/0/1&quot;&gt;Robert Ormandi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dahl_G/0/1/0/all/0/1&quot;&gt;George E. Dahl&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hinton_G/0/1/0/all/0/1&quot;&gt;Geoffrey E. Hinton&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.03301">
<title>A Mathematical Framework for Superintelligent Machines. (arXiv:1804.03301v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1804.03301</link>
<description rdf:parseType="Literal">&lt;p&gt;We describe a class calculus that is expressive enough to describe and
improve its own learning process. It can design and debug programs that satisfy
given input/output constraints, based on its ontology of previously learned
programs. It can improve its own model of the world by checking the actual
results of the actions of its robotic activators. For instance, it could check
the black box of a car crash to determine if it was probably caused by electric
failure, a stuck electronic gate, dark ice, or some other condition that it
must add to its ontology in order to meet its sub-goal of preventing such
crashes in the future. Class algebra basically defines the eval/eval-1 Galois
connection between the residuated Boolean algebras of 1. equivalence classes
and super/sub classes of class algebra type expressions, and 2. a residual
Boolean algebra of biclique relationships. It distinguishes which formulas are
equivalent, entailed, or unrelated, based on a simplification algorithm that
may be thought of as producing a unique pair of Karnaugh maps that describe the
rough sets of maximal bicliques of relations. Such maps divide the
n-dimensional space of up to 2n-1 conjunctions of up to n propositions into
clopen (i.e. a closed set of regions and their boundaries) causal sets. This
class algebra is generalized to type-2 fuzzy class algebra by using relative
frequencies as probabilities. It is also generalized to a class calculus
involving assignments that change the states of programs.
&lt;/p&gt;
&lt;p&gt;INDEX TERMS 4-valued Boolean Logic, Artificial Intelligence, causal sets,
class algebra, consciousness, intelligent design, IS-A hierarchy, mathematical
logic, meta-theory, pointless topological space, residuated lattices, rough
sets, type-2 fuzzy sets
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Buehrer_D/0/1/0/all/0/1&quot;&gt;Daniel J. Buehrer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.03317">
<title>Question Answering over Freebase via Attentive RNN with Similarity Matrix based CNN. (arXiv:1804.03317v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1804.03317</link>
<description rdf:parseType="Literal">&lt;p&gt;With the rapid growth of knowledge bases (KBs), question answering over
knowledge base, a.k.a. KBQA has drawn huge attention in recent years. Most of
the existing KBQA methods follow so called encoder-compare framework. They map
the question and the KB facts to a common embedding space, in which the
similarity between the question vector and the fact vectors can be conveniently
computed. This, however, inevitably loses original words interaction
information. To preserve more original information, we propose an attentive
recurrent neural network with similarity matrix based convolutional neural
network (AR-SMCNN) model, which is able to capture comprehensive hierarchical
information utilizing the advantages of both RNN and CNN. We use RNN to capture
semantic-level correlation by its sequential modeling nature, and use an
attention mechanism to keep track of the entities and relations simultaneously.
Meanwhile, we use a similarity matrix based CNN with two-directions pooling to
extract literal-level words interaction matching utilizing CNNs strength of
modeling spatial correlation among data. Moreover, we have developed a new
heuristic extension method for entity detection, which significantly decreases
the effect of noise. Our method has outperformed the state-of-the-arts on
SimpleQuestion benchmark in both accuracy and efficiency.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qu_Y/0/1/0/all/0/1&quot;&gt;Yingqi Qu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Jie Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kang_L/0/1/0/all/0/1&quot;&gt;Liangyi Kang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_Q/0/1/0/all/0/1&quot;&gt;Qinfeng Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ye_D/0/1/0/all/0/1&quot;&gt;Dan Ye&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.03342">
<title>Toward Formalizing Teleportation of Pedagogical Artificial Agents. (arXiv:1804.03342v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1804.03342</link>
<description rdf:parseType="Literal">&lt;p&gt;Our paradigm for the use of artificial agents to teach requires among other
things that they persist through time in their interaction with human students,
in such a way that they &quot;teleport&quot; or &quot;migrate&quot; from an embodiment at one time
t to a different embodiment at later time t&apos;. In this short paper, we report on
initial steps toward the formalization of such teleportation, in order to
enable an overseeing AI system to establish, mechanically, and verifiably, that
the human students in question will likely believe that the very same
artificial agent has persisted across such times despite the different
embodiments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Angel_J/0/1/0/all/0/1&quot;&gt;John Angel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Govindarajulu_N/0/1/0/all/0/1&quot;&gt;Naveen Sundar Govindarajulu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bringsjord_S/0/1/0/all/0/1&quot;&gt;Selmer Bringsjord&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.03396">
<title>QA4IE: A Question Answering based Framework for Information Extraction. (arXiv:1804.03396v1 [cs.IR])</title>
<link>http://arxiv.org/abs/1804.03396</link>
<description rdf:parseType="Literal">&lt;p&gt;Information Extraction (IE) refers to automatically extracting structured
relation tuples from unstructured texts. Common IE solutions, including
Relation Extraction (RE) and open IE systems, can hardly handle cross-sentence
tuples, and are severely restricted by limited relation types as well as
informal relation specifications (e.g., free-text based relation tuples). In
order to overcome these weaknesses, we propose a novel IE framework named
QA4IE, which leverages the flexible question answering (QA) approaches to
produce high quality relation triples across sentences. Based on the framework,
we develop a large IE benchmark with high quality human evaluation. This
benchmark contains 293K documents, 2M golden relation triples, and 636 relation
types. We compare our system with some IE baselines on our benchmark and the
results show that our system achieves great improvements.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qiu_L/0/1/0/all/0/1&quot;&gt;Lin Qiu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1&quot;&gt;Hao Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qu_Y/0/1/0/all/0/1&quot;&gt;Yanru Qu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1&quot;&gt;Weinan Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1&quot;&gt;Suoheng Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rong_S/0/1/0/all/0/1&quot;&gt;Shu Rong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ru_D/0/1/0/all/0/1&quot;&gt;Dongyu Ru&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qian_L/0/1/0/all/0/1&quot;&gt;Lihua Qian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tu_K/0/1/0/all/0/1&quot;&gt;Kewei Tu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1&quot;&gt;Yong Yu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.03424">
<title>A Hierarchical Latent Structure for Variational Conversation Modeling. (arXiv:1804.03424v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1804.03424</link>
<description rdf:parseType="Literal">&lt;p&gt;Variational autoencoders (VAE) combined with hierarchical RNNs have emerged
as a powerful framework for conversation modeling. However, they suffer from
the notorious degeneration problem, where the decoders learn to ignore latent
variables and reduce to vanilla RNNs. We empirically show that this degeneracy
occurs mostly due to two reasons. First, the expressive power of hierarchical
RNN decoders is often high enough to model the data using only its decoding
distributions without relying on the latent variables. Second, the conditional
VAE structure whose generation process is conditioned on a context, makes the
range of training targets very sparse; that is, the RNN decoders can easily
overfit to the training data ignoring the latent variables. To solve the
degeneration problem, we propose a novel model named Variational Hierarchical
Conversation RNNs (VHCR), involving two key ideas of (1) using a hierarchical
structure of latent variables, and (2) exploiting an utterance drop
regularization. With evaluations on two datasets of Cornell Movie Dialog and
Ubuntu Dialog Corpus, we show that our VHCR successfully utilizes latent
variables and outperforms state-of-the-art models for conversation generation.
Moreover, it can perform several new utterance control tasks, thanks to its
hierarchical latent structure.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Park_Y/0/1/0/all/0/1&quot;&gt;Yookoon Park&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cho_J/0/1/0/all/0/1&quot;&gt;Jaemin Cho&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_G/0/1/0/all/0/1&quot;&gt;Gunhee Kim&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.03487">
<title>Exploring Disentangled Feature Representation Beyond Face Identification. (arXiv:1804.03487v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1804.03487</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper proposes learning disentangled but complementary face features
with minimal supervision by face identification. Specifically, we construct an
identity Distilling and Dispelling Autoencoder (D2AE) framework that
adversarially learns the identity-distilled features for identity verification
and the identity-dispelled features to fool the verification system. Thanks to
the design of two-stream cues, the learned disentangled features represent not
only the identity or attribute but the complete input image. Comprehensive
evaluations further demonstrate that the proposed features not only maintain
state-of-the-art identity verification performance on LFW, but also acquire
competitive discriminative power for face attribute recognition on CelebA and
LFWA. Moreover, the proposed system is ready to semantically control the face
generation/editing based on various identities and attributes in an
unsupervised manner.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yu Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1&quot;&gt;Fangyin Wei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shao_J/0/1/0/all/0/1&quot;&gt;Jing Shao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sheng_L/0/1/0/all/0/1&quot;&gt;Lu Sheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1&quot;&gt;Junjie Yan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;Xiaogang Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.03592">
<title>Personalization of Health Interventions using Cluster-Based Reinforcement Learning. (arXiv:1804.03592v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1804.03592</link>
<description rdf:parseType="Literal">&lt;p&gt;Research has shown that personalization of health interventions can
contribute to an improved effectiveness. Reinforcement learning algorithms can
be used to perform such tailoring using data that is collected about users.
Learning is however very fragile for health interventions as only limited time
is available to learn from the user before disengagement takes place, or before
the opportunity to intervene passes. In this paper, we present a cluster-based
reinforcement learning approach which learns across groups of users. Such an
approach can speed up the learning process while still giving a level of
personalization. The clustering algorithm uses a distance metric over traces of
states and rewards. We apply both online and batch learning to learn policies
over the clusters and introduce a publicly available simulator which we have
developed to evaluate the approach. The results show batch learning clearly
outperforms online learning. Furthermore, clustering can be beneficial provided
that a proper clustering is found.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hassouni_A/0/1/0/all/0/1&quot;&gt;Ali el Hassouni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hoogendoorn_M/0/1/0/all/0/1&quot;&gt;Mark Hoogendoorn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Otterlo_M/0/1/0/all/0/1&quot;&gt;Martijn van Otterlo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barbaro_E/0/1/0/all/0/1&quot;&gt;Eduardo Barbaro&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.05948">
<title>The shortest way to visit all metro lines in a city. (arXiv:1709.05948v3 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1709.05948</link>
<description rdf:parseType="Literal">&lt;p&gt;What if $\{$a tourist, a train addict, Dr. Sheldon Cooper, somebody who likes
to waste time$\}$ wants to visit all metro lines or carriages in a given
network in a minimum number of steps? We study this problem with an application
to the metro network of Paris and Tokyo, proposing optimal solutions thanks to
mathematical programming tools. Quite surprisingly, it appears that you can
visit all 16 Parisian metro lines in only 26 steps (we denote by a step the act
of taking the metro from one station to an adjacent one). Perhaps even more
surprisingly, adding the 5 RER lines to these 16 lines does not increase the
size of the best solution. It is also possible to visit the 13 lines of (the
dense network of) Tokyo with only 15 steps.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sikora_F/0/1/0/all/0/1&quot;&gt;Florian Sikora&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.00532">
<title>SCDA: School Compatibility Decomposition Algorithm for Solving the Multi-School Bus Routing and Scheduling Problem. (arXiv:1711.00532v3 [math.OC] UPDATED)</title>
<link>http://arxiv.org/abs/1711.00532</link>
<description rdf:parseType="Literal">&lt;p&gt;Safely serving the school transportation demand with the minimum number of
buses is one of the highest financial goals of school transportation directors.
To achieve that objective, a good and efficient way to solve the routing and
scheduling problem is required. Due to the growth of the computing power, the
spotlight has been shed on solving the combined problem of the school bus
routing and scheduling problem. We show that an integrated multi-school bus
routing and scheduling can be formulated with the help of trip compatibility. A
novel decomposition algorithm is proposed to solve the integrated model. The
merit of this integrated model and the decomposition method is that with the
consideration of the trip compatibility, the interrelationship between the
routing and scheduling sub-problems will not be lost in the process of
decomposition. Results show the proposed decomposed problem could provide the
solutions using the same number of buses as the integrated model in much
shorter time (as little as 0.6%) and that the proposed method can save up to
26% number of buses from existing research.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zhongxiang Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Shafahi_A/0/1/0/all/0/1&quot;&gt;Ali Shafahi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Haghani_A/0/1/0/all/0/1&quot;&gt;Ali Haghani&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.03142">
<title>Markerless tracking of user-defined features with deep learning. (arXiv:1804.03142v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1804.03142</link>
<description rdf:parseType="Literal">&lt;p&gt;Quantifying behavior is crucial for many applications in neuroscience.
Videography provides easy methods for the observation and recording of animal
behavior in diverse settings, yet extracting particular aspects of a behavior
for further analysis can be highly time consuming. In motor control studies,
humans or other animals are often marked with reflective markers to assist with
computer-based tracking, yet markers are intrusive (especially for smaller
animals), and the number and location of the markers must be determined a
priori. Here, we present a highly efficient method for markerless tracking
based on transfer learning with deep neural networks that achieves excellent
results with minimal training data. We demonstrate the versatility of this
framework by tracking various body parts in a broad collection of experimental
settings: mice odor trail-tracking, egg-laying behavior in drosophila, and
mouse hand articulation in a skilled forelimb task. For example, during the
skilled reaching behavior, individual joints can be automatically tracked (and
a confidence score is reported). Remarkably, even when a small number of frames
are labeled ($\approx 200$), the algorithm achieves excellent tracking
performance on test frames that is comparable to human accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mathis_A/0/1/0/all/0/1&quot;&gt;Alexander Mathis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mamidanna_P/0/1/0/all/0/1&quot;&gt;Pranav Mamidanna&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abe_T/0/1/0/all/0/1&quot;&gt;Taiga Abe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cury_K/0/1/0/all/0/1&quot;&gt;Kevin M. Cury&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Murthy_V/0/1/0/all/0/1&quot;&gt;Venkatesh N. Murthy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mathis_M/0/1/0/all/0/1&quot;&gt;Mackenzie W. Mathis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bethge_M/0/1/0/all/0/1&quot;&gt;Matthias Bethge&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.03176">
<title>Frank-Wolfe Splitting via Augmented Lagrangian Method. (arXiv:1804.03176v1 [math.OC])</title>
<link>http://arxiv.org/abs/1804.03176</link>
<description rdf:parseType="Literal">&lt;p&gt;Minimizing a function over an intersection of convex sets is an important
task in optimization that is often much more challenging than minimizing it
over each individual constraint set. While traditional methods such as
Frank-Wolfe (FW) or proximal gradient descent assume access to a linear or
quadratic oracle on the intersection, splitting techniques take advantage of
the structure of each sets, and only require access to the oracle on the
individual constraints. In this work, we develop and analyze the Frank-Wolfe
Augmented Lagrangian (FW-AL) algorithm, a method for minimizing a smooth
function over convex compact sets related by a &quot;linear consistency&quot; constraint
that only requires access to a linear minimization oracle over the individual
constraints. It is based on the Augmented Lagrangian Method (ALM), also known
as Method of Multipliers, but unlike most existing splitting methods, it only
requires access to linear (instead of quadratic) minimization oracles. We use
recent advances in the analysis of Frank-Wolfe and the alternating direction
method of multipliers algorithms to prove a sublinear convergence rate for
FW-AL over general convex compact sets and a linear convergence rate for
polytopes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Gidel_G/0/1/0/all/0/1&quot;&gt;Gauthier Gidel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Pedregosa_F/0/1/0/all/0/1&quot;&gt;Fabian Pedregosa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Lacoste_Julien_S/0/1/0/all/0/1&quot;&gt;Simon Lacoste-Julien&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.03193">
<title>An ADMM-Based Universal Framework for Adversarial Attacks on Deep Neural Networks. (arXiv:1804.03193v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1804.03193</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep neural networks (DNNs) are known vulnerable to adversarial attacks. That
is, adversarial examples, obtained by adding delicately crafted distortions
onto original legal inputs, can mislead a DNN to classify them as any target
labels. In a successful adversarial attack, the targeted mis-classification
should be achieved with the minimal distortion added. In the literature, the
added distortions are usually measured by L0, L1, L2, and L infinity norms,
namely, L0, L1, L2, and L infinity attacks, respectively. However, there lacks
a versatile framework for all types of adversarial attacks.
&lt;/p&gt;
&lt;p&gt;This work for the first time unifies the methods of generating adversarial
examples by leveraging ADMM (Alternating Direction Method of Multipliers), an
operator splitting optimization approach, such that L0, L1, L2, and L infinity
attacks can be effectively implemented by this general framework with little
modifications. Comparing with the state-of-the-art attacks in each category,
our ADMM-based attacks are so far the strongest, achieving both the 100% attack
success rate and the minimal distortion.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_P/0/1/0/all/0/1&quot;&gt;Pu Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1&quot;&gt;Sijia Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yanzhi Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_X/0/1/0/all/0/1&quot;&gt;Xue Lin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.03286">
<title>On the Robustness of the CVPR 2018 White-Box Adversarial Example Defenses. (arXiv:1804.03286v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1804.03286</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural networks are known to be vulnerable to adversarial examples. In this
note, we evaluate the two white-box defenses that appeared at CVPR 2018 and
find they are ineffective: when applying existing techniques, we can reduce the
accuracy of the defended models to 0%.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Athalye_A/0/1/0/all/0/1&quot;&gt;Anish Athalye&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Carlini_N/0/1/0/all/0/1&quot;&gt;Nicholas Carlini&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.03308">
<title>Adversarial Training Versus Weight Decay. (arXiv:1804.03308v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1804.03308</link>
<description rdf:parseType="Literal">&lt;p&gt;Performance-critical machine learning models should be robust to input
perturbations not seen during training. Adversarial training is a method for
improving a model&apos;s robustness to some perturbations by including them in the
training process, but this tends to exacerbate other vulnerabilities of the
model. The adversarial training framework has the effect of translating the
data with respect to the cost function, while weight decay has a scaling
effect. Although weight decay could be considered a crude regularization
technique, it appears superior to adversarial training as it remains stable
over a broader range of regimes and reduces all generalization errors. Equipped
with these abstractions, we provide key baseline results and methodology for
characterizing robustness. The two approaches can be combined to yield one
small model that demonstrates good robustness to several white-box attacks
associated with different metrics.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Galloway_A/0/1/0/all/0/1&quot;&gt;Angus Galloway&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tanay_T/0/1/0/all/0/1&quot;&gt;Thomas Tanay&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Taylor_G/0/1/0/all/0/1&quot;&gt;Graham W. Taylor&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.03334">
<title>TIDBD: Adapting Temporal-difference Step-sizes Through Stochastic Meta-descent. (arXiv:1804.03334v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1804.03334</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we introduce a method for adapting the step-sizes of temporal
difference (TD) learning. The performance of TD methods often depends on well
chosen step-sizes, yet few algorithms have been developed for setting the
step-size automatically for TD learning. An important limitation of current
methods is that they adapt a single step-size shared by all the weights of the
learning system. A vector step-size enables greater optimization by specifying
parameters on a per-feature basis. Furthermore, adapting parameters at
different rates has the added benefit of being a simple form of representation
learning. We generalize Incremental Delta Bar Delta (IDBD)---a vectorized
adaptive step-size method for supervised learning---to TD learning, which we
name TIDBD. We demonstrate that TIDBD is able to find appropriate step-sizes in
both stationary and non-stationary prediction tasks, outperforming ordinary TD
methods and TD methods with scalar step-size adaptation; we demonstrate that it
can differentiate between features which are relevant and irrelevant for a
given task, performing representation learning; and we show on a real-world
robot prediction task that TIDBD is able to outperform ordinary TD methods and
TD methods augmented with AlphaBound and RMSprop.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kearney_A/0/1/0/all/0/1&quot;&gt;Alex Kearney&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Veeriah_V/0/1/0/all/0/1&quot;&gt;Vivek Veeriah&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Travnik_J/0/1/0/all/0/1&quot;&gt;Jaden B. Travnik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sutton_R/0/1/0/all/0/1&quot;&gt;Richard S. Sutton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pilarski_P/0/1/0/all/0/1&quot;&gt;Patrick M. Pilarski&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.03429">
<title>Graphical Generative Adversarial Networks. (arXiv:1804.03429v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1804.03429</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose Graphical Generative Adversarial Networks (Graphical-GAN) to model
structured data. Graphical-GAN conjoins the power of Bayesian networks on
compactly representing the dependency structures among random variables and
that of generative adversarial networks on learning expressive dependency
functions. We introduce a structured recognition model to infer the posterior
distribution of latent variables given observations. We propose two alternative
divergence minimization approaches to learn the generative model and
recognition model jointly. The first one treats all variables as a whole, while
the second one utilizes the structural information by checking the individual
local factors defined by the generative model and works better in practice.
Finally, we present two important instances of Graphical-GAN, i.e. Gaussian
Mixture GAN (GMGAN) and State Space GAN (SSGAN), which can successfully learn
the discrete and temporal structures on visual datasets, respectively.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1&quot;&gt;Chongxuan Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Welling_M/0/1/0/all/0/1&quot;&gt;Max Welling&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1&quot;&gt;Jun Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1&quot;&gt;Bo Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.03515">
<title>Hyperparameters and Tuning Strategies for Random Forest. (arXiv:1804.03515v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1804.03515</link>
<description rdf:parseType="Literal">&lt;p&gt;The random forest algorithm (RF) has several hyperparameters that have to be
set by the user, e.g., the number of observations drawn randomly for each tree
and whether they are drawn with or without replacement, the number of variables
drawn randomly for each split, the splitting rule, the minimum number of
samples that a node must contain and the number of trees. In this paper, we
first provide a literature review on the parameters&apos; influence on the
prediction performance and on variable importance measures, also considering
interactions between hyperparameters.
&lt;/p&gt;
&lt;p&gt;It is well known that in most cases RF works reasonably well with the default
values of the hyperparameters specified in software packages. Nevertheless,
tuning the hyperparameters can improve the performance of RF. In the second
part of this paper, after a brief overview of tuning strategies we demonstrate
the application of one of the most established tuning strategies, model-based
optimization (MBO). To make it easier to use, we provide the tuneRanger R
package that tunes RF with MBO automatically. In a benchmark study on several
datasets, we compare the prediction performance and runtime of tuneRanger with
other tuning implementations in R and RF with default hyperparameters.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Probst_P/0/1/0/all/0/1&quot;&gt;Philipp Probst&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wright_M/0/1/0/all/0/1&quot;&gt;Marvin Wright&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Boulesteix_A/0/1/0/all/0/1&quot;&gt;Anne-Laure Boulesteix&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.03567">
<title>Enhancing Cybersecurity Skills by Creating Serious Games. (arXiv:1804.03567v1 [cs.CY])</title>
<link>http://arxiv.org/abs/1804.03567</link>
<description rdf:parseType="Literal">&lt;p&gt;Adversary thinking is an essential skill for cybersecurity experts, enabling
them to understand cyber attacks and set up effective defenses. While this
skill is commonly exercised by Capture the Flag games and hands-on activities,
we complement these approaches with a key innovation: undergraduate students
learn methods of network attack and defense by creating educational games in a
cyber range. In this paper, we present the design of two courses, instruction
and assessment techniques, as well as our observations over the last three
semesters. The students report they had a unique opportunity to deeply
understand the topic and practice their soft skills, as they presented their
results at a faculty open day event. Their peers, who played the created games,
rated the quality and educational value of the games overwhelmingly positively.
Moreover, the open day raised awareness about cybersecurity and research and
development in this field at our faculty. We believe that sharing our teaching
experience will be valuable for instructors planning to introduce active
learning of cybersecurity and adversary thinking.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Svabensky_V/0/1/0/all/0/1&quot;&gt;Valdemar &amp;#x160;v&amp;#xe1;bensk&amp;#xfd;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vykopal_J/0/1/0/all/0/1&quot;&gt;Jan Vykopal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cermak_M/0/1/0/all/0/1&quot;&gt;Milan Cermak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lastovicka_M/0/1/0/all/0/1&quot;&gt;Martin La&amp;#x161;tovi&amp;#x10d;ka&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.03629">
<title>Probabilistic Prediction of Vehicle Semantic Intention and Motion. (arXiv:1804.03629v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1804.03629</link>
<description rdf:parseType="Literal">&lt;p&gt;Accurately predicting the possible behaviors of traffic participants is an
essential capability for future autonomous vehicles. The majority of current
researches fix the number of driving intentions by considering only a specific
scenario. However, distinct driving environments usually contain various
possible driving maneuvers. Therefore, a intention prediction method that can
adapt to different traffic scenarios is needed. To further improve the overall
vehicle prediction performance, motion information is usually incorporated with
classified intentions. As suggested in some literature, the methods that
directly predict possible goal locations can achieve better performance for
long-term motion prediction than other approaches due to their automatic
incorporation of environment constraints. Moreover, by obtaining the temporal
information of the predicted destinations, the optimal trajectories for
predicted vehicles as well as the desirable path for ego autonomous vehicle
could be easily generated. In this paper, we propose a Semantic-based Intention
and Motion Prediction (SIMP) method, which can be adapted to any driving
scenarios by using semantic-defined vehicle behaviors. It utilizes a
probabilistic framework based on deep neural network to estimate the
intentions, final locations, and the corresponding time information for
surrounding vehicles. An exemplar real-world scenario was used to implement and
examine the proposed method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1&quot;&gt;Yeping Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhan_W/0/1/0/all/0/1&quot;&gt;Wei Zhan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tomizuka_M/0/1/0/all/0/1&quot;&gt;Masayoshi Tomizuka&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.03635">
<title>Semantic embeddings for program behavior patterns. (arXiv:1804.03635v1 [cs.CR])</title>
<link>http://arxiv.org/abs/1804.03635</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we propose a new feature extraction technique for program
execution logs. First, we automatically extract complex patterns from a
program&apos;s behavior graph. Then, we embed these patterns into a continuous space
by training an autoencoder. We evaluate the proposed features on a real-world
malicious software detection task. We also find that the embedding space
captures interpretable structures in the space of pattern parts.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chistyakov_A/0/1/0/all/0/1&quot;&gt;Alexander Chistyakov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lobacheva_E/0/1/0/all/0/1&quot;&gt;Ekaterina Lobacheva&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kuznetsov_A/0/1/0/all/0/1&quot;&gt;Arseny Kuznetsov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Romanenko_A/0/1/0/all/0/1&quot;&gt;Alexey Romanenko&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1706.02216">
<title>Inductive Representation Learning on Large Graphs. (arXiv:1706.02216v3 [cs.SI] UPDATED)</title>
<link>http://arxiv.org/abs/1706.02216</link>
<description rdf:parseType="Literal">&lt;p&gt;Low-dimensional embeddings of nodes in large graphs have proved extremely
useful in a variety of prediction tasks, from content recommendation to
identifying protein functions. However, most existing approaches require that
all nodes in the graph are present during training of the embeddings; these
previous approaches are inherently transductive and do not naturally generalize
to unseen nodes. Here we present GraphSAGE, a general, inductive framework that
leverages node feature information (e.g., text attributes) to efficiently
generate node embeddings for previously unseen data. Instead of training
individual embeddings for each node, we learn a function that generates
embeddings by sampling and aggregating features from a node&apos;s local
neighborhood. Our algorithm outperforms strong baselines on three inductive
node-classification benchmarks: we classify the category of unseen nodes in
evolving information graphs based on citation and Reddit post data, and we show
that our algorithm generalizes to completely unseen graphs using a multi-graph
dataset of protein-protein interactions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hamilton_W/0/1/0/all/0/1&quot;&gt;William L. Hamilton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ying_R/0/1/0/all/0/1&quot;&gt;Rex Ying&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leskovec_J/0/1/0/all/0/1&quot;&gt;Jure Leskovec&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.07746">
<title>Stochastic Backward Euler: An Implicit Gradient Descent Algorithm for $k$-means Clustering. (arXiv:1710.07746v2 [math.OC] UPDATED)</title>
<link>http://arxiv.org/abs/1710.07746</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we propose an implicit gradient descent algorithm for the
classic $k$-means problem. The implicit gradient step or backward Euler is
solved via stochastic fixed-point iteration, in which we randomly sample a
mini-batch gradient in every iteration. It is the average of the fixed-point
trajectory that is carried over to the next gradient step. We draw connections
between the proposed stochastic backward Euler and the recent entropy
stochastic gradient descent (Entropy-SGD) for improving the training of deep
neural networks. Numerical experiments on various synthetic and real datasets
show that the proposed algorithm provides better clustering results compared to
$k$-means algorithms in the sense that it decreased the objective function (the
cluster) and is much more robust to initialization.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Yin_P/0/1/0/all/0/1&quot;&gt;Penghang Yin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Pham_M/0/1/0/all/0/1&quot;&gt;Minh Pham&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Oberman_A/0/1/0/all/0/1&quot;&gt;Adam Oberman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Osher_S/0/1/0/all/0/1&quot;&gt;Stanley Osher&lt;/a&gt;</dc:creator>
</item></rdf:RDF>