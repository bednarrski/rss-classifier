<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Good papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Good Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-04-04T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.01128"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.01186"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.01256"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.01396"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.01503"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.00538"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.00645"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.00823"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.01155"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.01382"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.02780"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.08010"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1804.01128">
<title>Probing Physics Knowledge Using Tools from Developmental Psychology. (arXiv:1804.01128v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1804.01128</link>
<description rdf:parseType="Literal">&lt;p&gt;In order to build agents with a rich understanding of their environment, one
key objective is to endow them with a grasp of intuitive physics; an ability to
reason about three-dimensional objects, their dynamic interactions, and
responses to forces. While some work on this problem has taken the approach of
building in components such as ready-made physics engines, other research aims
to extract general physical concepts directly from sensory data. In the latter
case, one challenge that arises is evaluating the learning system. Research on
intuitive physics knowledge in children has long employed a violation of
expectations (VOE) method to assess children&apos;s mastery of specific physical
concepts. We take the novel step of applying this method to artificial learning
systems. In addition to introducing the VOE technique, we describe a set of
probe datasets inspired by classic test stimuli from developmental psychology.
We test a baseline deep learning system on this battery, as well as on a
physics learning dataset (&quot;IntPhys&quot;) recently posed by another research group.
Our results show how the VOE technique may provide a useful tool for tracking
physics knowledge in future research.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Piloto_L/0/1/0/all/0/1&quot;&gt;Luis Piloto&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Weinstein_A/0/1/0/all/0/1&quot;&gt;Ari Weinstein&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+TB_D/0/1/0/all/0/1&quot;&gt;Dhruva TB&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ahuja_A/0/1/0/all/0/1&quot;&gt;Arun Ahuja&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mirza_M/0/1/0/all/0/1&quot;&gt;Mehdi Mirza&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wayne_G/0/1/0/all/0/1&quot;&gt;Greg Wayne&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Amos_D/0/1/0/all/0/1&quot;&gt;David Amos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hung_C/0/1/0/all/0/1&quot;&gt;Chia-chun Hung&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Botvinick_M/0/1/0/all/0/1&quot;&gt;Matt Botvinick&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.01186">
<title>Neural-Guided Deductive Search for Real-Time Program Synthesis from Examples. (arXiv:1804.01186v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1804.01186</link>
<description rdf:parseType="Literal">&lt;p&gt;Synthesizing user-intended programs from a small number of input-output
examples is a challenging problem with several important applications like
spreadsheet manipulation, data wrangling and code refactoring. Existing
synthesis systems either completely rely on deductive logic techniques that are
extensively hand-engineered or on purely statistical models that need massive
amounts of data, and in general fail to provide real-time synthesis on
challenging benchmarks. In this work, we propose Neural Guided Deductive Search
(NGDS), a hybrid synthesis technique that combines the best of both symbolic
logic techniques and statistical models. Thus, it produces programs that
satisfy the provided specifications by construction and generalize well on
unseen examples, similar to data-driven systems. Our technique effectively
utilizes the deductive search framework to reduce the learning problem of the
neural component to a simple supervised learning setup. Further, this allows us
to both train on sparingly available real-world data and still leverage
powerful recurrent neural network encoders. We demonstrate the effectiveness of
our method by evaluating on real-world customer scenarios by synthesizing
accurate programs with up to 12x speed-up compared to state-of-the-art systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vijayakumar_A/0/1/0/all/0/1&quot;&gt;Ashwin J. Vijayakumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mohta_A/0/1/0/all/0/1&quot;&gt;Abhishek Mohta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Polozov_O/0/1/0/all/0/1&quot;&gt;Oleksandr Polozov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Batra_D/0/1/0/all/0/1&quot;&gt;Dhruv Batra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jain_P/0/1/0/all/0/1&quot;&gt;Prateek Jain&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gulwani_S/0/1/0/all/0/1&quot;&gt;Sumit Gulwani&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.01256">
<title>NegPSpan: efficient extraction of negative sequential patterns with embedding constraints. (arXiv:1804.01256v1 [cs.DB])</title>
<link>http://arxiv.org/abs/1804.01256</link>
<description rdf:parseType="Literal">&lt;p&gt;Mining frequent sequential patterns consists in extracting recurrent
behaviors, modeled as patterns, in a big sequence dataset. Such patterns inform
about which events are frequently observed in sequences, i.e. what does really
happen. Sometimes, knowing that some specific event does not happen is more
informative than extracting a lot of observed events. Negative sequential
patterns (NSP) formulate recurrent behaviors by patterns containing both
observed events and absent events. Few approaches have been proposed to mine
such NSPs. In addition, the syntax and semantics of NSPs differ in the
different methods which makes it difficult to compare them. This article
provides a unified framework for the formulation of the syntax and the
semantics of NSPs. Then, we introduce a new algorithm, NegPSpan, that extracts
NSPs using a PrefixSpan depth-first scheme and enabling maxgap constraints that
other approaches do not take into account. The formal framework allows for
highlighting the differences between the proposed approach wrt to the methods
from the literature, especially wrt the state of the art approach eNSP.
Intensive experiments on synthetic and real datasets show that NegPSpan can
extract meaningful NSPs and that it can process bigger datasets than eNSP
thanks to significantly lower memory requirements and better computation times.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guyet_T/0/1/0/all/0/1&quot;&gt;Thomas Guyet&lt;/a&gt; (LACODAM), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Quiniou_R/0/1/0/all/0/1&quot;&gt;Ren&amp;#xe9; Quiniou&lt;/a&gt; (LACODAM)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.01396">
<title>Artificial Intelligence and its Role in Near Future. (arXiv:1804.01396v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1804.01396</link>
<description rdf:parseType="Literal">&lt;p&gt;AI technology has a long history which is actively and constantly changing
and growing. It focuses on intelligent agents, which contain devices that
perceive the environment and based on which takes actions in order to maximize
goal success chances. In this paper, we will explain the modern AI basics and
various representative applications of AI. In the context of the modern
digitalized world, AI is the property of machines, computer programs, and
systems to perform the intellectual and creative functions of a person,
independently find ways to solve problems, be able to draw conclusions and make
decisions. Most artificial intelligence systems have the ability to learn,
which allows people to improve their performance over time. The recent research
on AI tools, including machine learning, deep learning and predictive analysis
intended toward increasing the planning, learning, reasoning, thinking and
action taking ability. Based on which, the proposed research intends towards
exploring on how the human intelligence differs from the artificial
intelligence. Moreover, we critically analyze what AI of today is capable of
doing, why it still cannot reach human intelligence and what are the open
challenges existing in front of AI to reach and outperform human level of
intelligence. Furthermore, it will explore the future predictions for
artificial intelligence and based on which potential solution will be
recommended to solve it within next decades.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shabbir_J/0/1/0/all/0/1&quot;&gt;Jahanzaib Shabbir&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Anwer_T/0/1/0/all/0/1&quot;&gt;Tarique Anwer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.01503">
<title>Abstractive Tabular Dataset Summarization via Knowledge BaseSemantic Embeddings. (arXiv:1804.01503v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1804.01503</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper describes an abstractive summarization method for tabular data
which employs a knowledge base semantic embedding to generate the summary.
Assuming the dataset contains descriptive text in headers, columns and/or some
augmenting metadata, the system employs the embedding to recommend a
subject/type for each text segment. Recommendations are aggregated into a small
collection of super types considered to be descriptive of the dataset by
exploiting the hierarchy of types in a pre-specified ontology. Using February
2015 Wikipedia as the knowledge base, and a corresponding DBpedia ontology as
types, we present experimental results on open data taken from several
sources--OpenML, CKAN and data.world--to illustrate the effectiveness of the
approach.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Azunre_P/0/1/0/all/0/1&quot;&gt;Paul Azunre&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Corcoran_C/0/1/0/all/0/1&quot;&gt;Craig Corcoran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sullivan_D/0/1/0/all/0/1&quot;&gt;David Sullivan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Honke_G/0/1/0/all/0/1&quot;&gt;Garrett Honke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ruppel_R/0/1/0/all/0/1&quot;&gt;Rebecca Ruppel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Verma_S/0/1/0/all/0/1&quot;&gt;Sandeep Verma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Morgan_J/0/1/0/all/0/1&quot;&gt;Jonathon Morgan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.00538">
<title>Investigating Capsule Networks with Dynamic Routing for Text Classification. (arXiv:1804.00538v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1804.00538</link>
<description rdf:parseType="Literal">&lt;p&gt;In this study, we explore capsule networks with dynamic routing for text
classification. We propose three strategies to stabilize the dynamic routing
process to alleviate the disturbance of some noise capsules which may contain
&quot;background&quot; information or have not been successfully trained. A series of
experiments are conducted with capsule networks on six text classification
benchmarks. Capsule networks achieve state of the art on 4 out of 6 datasets,
which shows the effectiveness of capsule networks for text classification. We
additionally show that capsule networks exhibit significant improvement when
transfer single-label to multi-label text classification over strong baseline
methods. To the best of our knowledge, this is the first work that capsule
networks have been empirically investigated for text modeling.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1&quot;&gt;Wei Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1&quot;&gt;Jianbo Ye&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1&quot;&gt;Min Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lei_Z/0/1/0/all/0/1&quot;&gt;Zeyang Lei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1&quot;&gt;Suofei Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1&quot;&gt;Zhou Zhao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.00645">
<title>Universal Planning Networks. (arXiv:1804.00645v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1804.00645</link>
<description rdf:parseType="Literal">&lt;p&gt;A key challenge in complex visuomotor control is learning abstract
representations that are effective for specifying goals, planning, and
generalization. To this end, we introduce universal planning networks (UPN).
UPNs embed differentiable planning within a goal-directed policy. This planning
computation unrolls a forward model in a latent space and infers an optimal
action plan through gradient descent trajectory optimization. The
plan-by-gradient-descent process and its underlying representations are learned
end-to-end to directly optimize a supervised imitation learning objective. We
find that the representations learned are not only effective for goal-directed
visual imitation via gradient-based trajectory optimization, but can also
provide a metric for specifying goals using images. The learned representations
can be leveraged to specify distance-based rewards to reach new target states
for model-free reinforcement learning, resulting in substantially more
effective learning when solving new tasks described via image-based goals. We
were able to achieve successful transfer of visuomotor planning strategies
across robots with significantly different morphologies and actuation
capabilities.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Srinivas_A/0/1/0/all/0/1&quot;&gt;Aravind Srinivas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jabri_A/0/1/0/all/0/1&quot;&gt;Allan Jabri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1&quot;&gt;Pieter Abbeel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1&quot;&gt;Sergey Levine&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Finn_C/0/1/0/all/0/1&quot;&gt;Chelsea Finn&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.00823">
<title>Graph2Seq: Graph to Sequence Learning with Attention-based Neural Networks. (arXiv:1804.00823v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1804.00823</link>
<description rdf:parseType="Literal">&lt;p&gt;Celebrated \emph{Sequence to Sequence learning (Seq2Seq)} and its fruitful
variants are powerful models to achieve excellent performance on the tasks that
map sequences to sequences. However, these are many machine learning tasks with
inputs naturally represented in a form of graphs, which imposes significant
challenges to existing Seq2Seq models for lossless conversion from its graph
form to the sequence. In this work, we present a general end-to-end approach to
map the input graph to a sequence of vectors, and then another attention-based
LSTM to decode the target sequence from these vectors. Specifically, to address
inevitable information loss for data conversion, we introduce a novel
graph-to-sequence neural network model that follows the encoder-decoder
architecture. Our method first uses an improved graph-based neural network to
generate the node and graph embeddings by a novel aggregation strategy to
incorporate the edge direction information into the node embeddings. We also
propose an attention based mechanism that aligns node embeddings and decoding
sequence to better cope with large graphs. Experimental results on bAbI task,
Shortest Path Task, and Natural Language Generation Task demonstrate that our
model achieves the state-of-the-art performance and significantly outperforms
other baselines. We also show that with the proposed aggregation strategy, our
proposed model is able to quickly converge to good performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_K/0/1/0/all/0/1&quot;&gt;Kun Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1&quot;&gt;Lingfei Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zhiguo Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1&quot;&gt;Yansong Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sheinin_V/0/1/0/all/0/1&quot;&gt;Vadim Sheinin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.01155">
<title>Socioeconomic Dependencies of Linguistic Patterns in Twitter: A Multivariate Analysis. (arXiv:1804.01155v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1804.01155</link>
<description rdf:parseType="Literal">&lt;p&gt;Our usage of language is not solely reliant on cognition but is arguably
determined by myriad external factors leading to a global variability of
linguistic patterns. This issue, which lies at the core of sociolinguistics and
is backed by many small-scale studies on face-to-face communication, is
addressed here by constructing a dataset combining the largest French Twitter
corpus to date with detailed socioeconomic maps obtained from national census
in France. We show how key linguistic variables measured in individual Twitter
streams depend on factors like socioeconomic status, location, time, and the
social network of individuals. We found that (i) people of higher socioeconomic
status, active to a greater degree during the daytime, use a more standard
language; (ii) the southern part of the country is more prone to use more
standard language than the northern one, while locally the used variety or
dialect is determined by the spatial distribution of socioeconomic status; and
(iii) individuals connected in the social network are closer linguistically
than disconnected ones, even after the effects of status homophily have been
removed. Our results inform sociolinguistic theory and may inspire novel
learning methods for the inference of socioeconomic status of people from the
way they tweet.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abitbol_J/0/1/0/all/0/1&quot;&gt;Jacob Levy Abitbol&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Karsai_M/0/1/0/all/0/1&quot;&gt;M&amp;#xe1;rton Karsai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mague_J/0/1/0/all/0/1&quot;&gt;Jean-Philippe Magu&amp;#xe9;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chevrot_J/0/1/0/all/0/1&quot;&gt;Jean-Pierre Chevrot&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fleury_E/0/1/0/all/0/1&quot;&gt;Eric Fleury&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.01382">
<title>Vanlearning: A Machine Learning SaaS Application for People Without Programming Backgrounds. (arXiv:1804.01382v1 [cs.HC])</title>
<link>http://arxiv.org/abs/1804.01382</link>
<description rdf:parseType="Literal">&lt;p&gt;Although we have tons of machine learning tools to analyze data, most of them
require users have some programming backgrounds. Here we introduce a SaaS
application which allows users analyze their data without any coding and even
without any knowledge of machine learning. Users can upload, train, predict and
download their data by simply clicks their mouses. Our system uses data
pre-processor and validator to relieve the computational cost of our server.
The simple architecture of Vanlearning helps developers can easily maintain and
extend it.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1&quot;&gt;Chaochen Wu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.02780">
<title>Transfer Automatic Machine Learning. (arXiv:1803.02780v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1803.02780</link>
<description rdf:parseType="Literal">&lt;p&gt;Building effective neural networks requires many design choices. These
include the network topology, optimization procedure, regularization, stability
methods, and choice of pre-trained parameters. This design is time consuming
and requires expert input. Automatic Machine Learning aims automate this
process using hyperparameter optimization. However, automatic model building
frameworks optimize performance on each task independently, whereas human
experts leverage prior knowledge when designing a new network. We propose
Transfer Automatic Machine Learning, a method to accelerate network design
using knowledge of prior tasks. For this, we build upon reinforcement learning
architecture design methods to support parallel training on multiple tasks and
transfer the search strategy to new tasks. Tested on NLP and Image
classification tasks, Transfer Automatic Machine Learning reduces convergence
time over single-task methods by almost an order of magnitude on 13 out of 14
tasks. It achieves better test set accuracy on 10 out of 13 tasks NLP tasks and
improves performance on CIFAR-10 image recognition from 95.3% to 97.1%.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wong_C/0/1/0/all/0/1&quot;&gt;Catherine Wong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Houlsby_N/0/1/0/all/0/1&quot;&gt;Neil Houlsby&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1&quot;&gt;Yifeng Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gesmundo_A/0/1/0/all/0/1&quot;&gt;Andrea Gesmundo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.08010">
<title>Social Media Would Not Lie: Prediction of the 2016 Taiwan Election via Online Heterogeneous Data. (arXiv:1803.08010v2 [cs.SI] UPDATED)</title>
<link>http://arxiv.org/abs/1803.08010</link>
<description rdf:parseType="Literal">&lt;p&gt;The prevalence of online media has attracted researchers from various domains
to explore human behavior and make interesting predictions. In this research,
we leverage heterogeneous social media data collected from various online
platforms to predict Taiwan&apos;s 2016 presidential election. In contrast to most
existing research, we take a &quot;signal&quot; view of heterogeneous information and
adopt the Kalman filter to fuse multiple signals into daily vote predictions
for the candidates. We also consider events that influenced the election in a
quantitative manner based on the so-called event study model that originated in
the field of financial research. We obtained the following interesting
findings. First, public opinions in online media dominate traditional polls in
Taiwan election prediction in terms of both predictive power and timeliness.
But offline polls can still function on alleviating the sample bias of online
opinions. Second, although online signals converge as election day approaches,
the simple Facebook &quot;Like&quot; is consistently the strongest indicator of the
election result. Third, most influential events have a strong connection to
cross-strait relations, and the Chou Tzu-yu flag incident followed by the
apology video one day before the election increased the vote share of Tsai
Ing-Wen by 3.66%. This research justifies the predictive power of online media
in politics and the advantages of information fusion. The combined use of the
Kalman filter and the event study method contributes to the data-driven
political analytics paradigm for both prediction and attribution purposes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_Z/0/1/0/all/0/1&quot;&gt;Zheng Xie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1&quot;&gt;Guannan Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1&quot;&gt;Junjie Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tan_Y/0/1/0/all/0/1&quot;&gt;Yong Tan&lt;/a&gt;</dc:creator>
</item></rdf:RDF>