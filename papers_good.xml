<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Good papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Good Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2017-12-06T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.01977"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.01990"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.02316"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.02328"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.01930"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.01949"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.01996"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.02034"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.02046"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.02047"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.02224"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.02225"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1003.3967"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1703.03453"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1704.03627"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1704.04683"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.03339"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.00929"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.01856"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.01864"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.01887"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.01934"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.02009"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.02029"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.02083"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.02154"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.02162"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.02195"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.02259"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.02270"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.02311"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.02330"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1705.05950"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.08873"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.02838"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.05610"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.06346"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.10678"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1712.01977">
<title>Single-trial P300 Classification using PCA with LDA, QDA and Neural Networks. (arXiv:1712.01977v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1712.01977</link>
<description rdf:parseType="Literal">&lt;p&gt;The P300 event-related potential (ERP), evoked in scalp-recorded
electroencephalography (EEG) by external stimuli, has proven to be a reliable
response for controlling a BCI. The P300 component of an event related
potential is thus widely used in brain-computer interfaces to translate the
subjects&apos; intent by mere thoughts into commands to control artificial devices.
The main challenge in the classification of P300 trials in
electroencephalographic (EEG) data is the low signal-to-noise ratio (SNR) of
the P300 response. To overcome the low SNR of individual trials, it is common
practice to average together many consecutive trials, which effectively
diminishes the random noise. Unfortunately, when more repeated trials are
required for applications such as the P300 speller, the communication rate is
greatly reduced. This has resulted in a need for better methods to improve
single-trial classification accuracy of P300 response. In this work, we use
Principal Component Analysis (PCA) as a preprocessing method and use Linear
Discriminant Analysis (LDA)and neural networks for classification. The results
show that a combination of PCA with these methods provided as high as 13\%
accuracy gain for single-trial classification while using only 3 to 4 principal
components.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sharma_N/0/1/0/all/0/1&quot;&gt;Nand Sharma&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.01990">
<title>A Scalable Deep Neural Network Architecture for Multi-Building and Multi-Floor Indoor Localization Based on Wi-Fi Fingerprinting. (arXiv:1712.01990v1 [cs.NI])</title>
<link>http://arxiv.org/abs/1712.01990</link>
<description rdf:parseType="Literal">&lt;p&gt;One of the key technologies for future large-scale location-aware services
covering a complex of multi-story buildings --- e.g., a big shopping mall and a
university campus --- is a scalable indoor localization technique. In this
paper, we report the current status of our investigation on the use of deep
neural networks (DNNs) for scalable building/floor classification and
floor-level position estimation based on Wi-Fi fingerprinting. Exploiting the
hierarchical nature of the building/floor estimation and floor-level
coordinates estimation of a location, we propose a new DNN architecture
consisting of a stacked autoencoder for the reduction of feature space
dimension and a feed-forward classifier for multi-label classification of
building/floor/location, on which the multi-building and multi-floor indoor
localization system based on Wi-Fi fingerprinting is built. Experimental
results for the performance of building/floor estimation and floor-level
coordinates estimation of a given location demonstrate the feasibility of the
proposed DNN-based indoor localization system, which can provide near
state-of-the-art performance using a single DNN, for the implementation with
lower complexity and energy consumption at mobile devices.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_K/0/1/0/all/0/1&quot;&gt;Kyeong Soo Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1&quot;&gt;Sanghyuk Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1&quot;&gt;Kaizhu Huang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.02316">
<title>Named Entity Sequence Classification. (arXiv:1712.02316v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1712.02316</link>
<description rdf:parseType="Literal">&lt;p&gt;Named Entity Recognition (NER) aims at locating and classifying named
entities in text. In some use cases of NER, including cases where detected
named entities are used in creating content recommendations, it is crucial to
have a reliable confidence level for the detected named entities. In this work
we study the problem of finding confidence levels for detected named entities.
We refer to this problem as Named Entity Sequence Classification (NESC). We
frame NESC as a binary classification problem and we use NER as well as
recurrent neural networks to find the probability of candidate named entity is
a real named entity. We apply this approach to Tweet texts and we show how we
could find named entities with high confidence levels from Tweets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Namazifar_M/0/1/0/all/0/1&quot;&gt;Mahdi Namazifar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.02328">
<title>Generative Adversarial Perturbations. (arXiv:1712.02328v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1712.02328</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we propose novel generative models for creating adversarial
examples, slightly perturbed images resembling natural images but maliciously
crafted to fool pre-trained models. We present trainable deep neural networks
for transforming images to adversarial perturbations. Our proposed models can
produce image-agnostic and image-dependent perturbations for both targeted and
non-targeted attacks. We also demonstrate that similar architectures can
achieve impressive results in fooling classification and semantic segmentation
models, obviating the need for hand-crafting attack methods for each task.
Using extensive experiments on challenging high-resolution datasets such as
ImageNet and Cityscapes, we show that our perturbations achieve high fooling
rates with small perturbation norms. Moreover, our attacks are considerably
faster than current iterative methods at inference time.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Poursaeed_O/0/1/0/all/0/1&quot;&gt;Omid Poursaeed&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Katsman_I/0/1/0/all/0/1&quot;&gt;Isay Katsman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_B/0/1/0/all/0/1&quot;&gt;Bicheng Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Belongie_S/0/1/0/all/0/1&quot;&gt;Serge Belongie&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.01930">
<title>Predicting Demographics, Moral Foundations, and Human Values from Digital Behaviors. (arXiv:1712.01930v1 [cs.CY])</title>
<link>http://arxiv.org/abs/1712.01930</link>
<description rdf:parseType="Literal">&lt;p&gt;Personal electronic devices such as smartphones give access to a broad range
of behavioral signals that can be used to learn about the characteristics and
preferences of individuals. In this study we explore the connection between
demographic and psychological attributes and digital records for a cohort of
7,633 people, closely representative of the US population with respect to
gender, age, geographical distribution, education, and income. We collected
self-reported assessments on validated psychometric questionnaires based on
both the Moral Foundations and Basic Human Values theories, and combined this
information with passively-collected multi-modal digital data from web browsing
behavior, smartphone usage and demographic data. Then, we designed a machine
learning framework to infer both the demographic and psychological attributes
from the behavioral data. In a cross-validated setting, our model is found to
predict demographic attributes with good accuracy (weighted AUC scores of 0.90
for gender, 0.71 for age, 0.74 for ethnicity). Our weighted AUC scores for
Moral Foundation attributes (0.66) and Human Values attributes (0.60) suggest
that accurate prediction of complex psychometric attributes is more challenging
but feasible. This connection might prove useful for designing personalized
services, communication strategies, and interventions, and can be used to
sketch a portrait of people with similar worldviews.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kalimeri_K/0/1/0/all/0/1&quot;&gt;Kyriaki Kalimeri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Beiro_M/0/1/0/all/0/1&quot;&gt;Mariano G. Beiro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Delfino_M/0/1/0/all/0/1&quot;&gt;Matteo Delfino&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Raleigh_R/0/1/0/all/0/1&quot;&gt;Robert Raleigh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cattuto_C/0/1/0/all/0/1&quot;&gt;Ciro Cattuto&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.01949">
<title>Recognizing Plans by Learning Embeddings from Observed Action Distributions. (arXiv:1712.01949v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1712.01949</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent advances in visual activity recognition have raised the possibility of
applications such as automated video surveillance. Effective approaches for
such problems however require the ability to recognize the plans of the agents
from video information. Although traditional plan recognition algorithms depend
on access to sophisticated domain models, one recent promising direction
involves learning shallow models directly from the observed activity sequences,
and using them to recognize/predict plans. One limitation of such approaches is
that they expect observed action sequences as training data. In many cases
involving vision or sensing from raw data, there is considerably uncertainty
about the specific action at any given time point. The most we can expect in
such cases is probabilistic information about the action at that point. The
training data will then be sequences of such observed action distributions. In
this paper, we focus on doing effective plan recognition with such uncertain
observations. Our contribution is a novel extension of word vector embedding
techniques to directly handle such observation distributions as input. This
involves computing embeddings by minimizing the distance between distributions
(measured as KL-divergence). We will show that our approach has superior
performance when the perception error rate (PER) is higher, and competitive
performance when the PER is lower. We will also explore the possibility of
using importance sampling techniques to handle observed action distributions
with traditional word vector embeddings. We will show that although such
approaches can give good recognition accuracy, they take significantly longer
training time and their performance will degrade significantly at higher
perception error rate.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zha_Y/0/1/0/all/0/1&quot;&gt;Yantian Zha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yikang Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gopalakrishnan_S/0/1/0/all/0/1&quot;&gt;Sriram Gopalakrishnan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1&quot;&gt;Baoxin Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kambhampati_S/0/1/0/all/0/1&quot;&gt;Subbarao Kambhampati&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.01996">
<title>An analysis of incorporating an external language model into a sequence-to-sequence model. (arXiv:1712.01996v1 [eess.AS])</title>
<link>http://arxiv.org/abs/1712.01996</link>
<description rdf:parseType="Literal">&lt;p&gt;Attention-based sequence-to-sequence models for automatic speech recognition
jointly train an acoustic model, language model, and alignment mechanism. Thus,
the language model component is only trained on transcribed audio-text pairs.
This leads to the use of shallow fusion with an external language model at
inference time. Shallow fusion refers to log-linear interpolation with a
separately trained language model at each step of the beam search. In this
work, we investigate the behavior of shallow fusion across a range of
conditions: different types of language models, different decoding units, and
different tasks. On Google Voice Search, we demonstrate that the use of shallow
fusion with a neural LM with wordpieces yields a 9.1% relative word error rate
reduction (WERR) over our competitive attention-based sequence-to-sequence
model, obviating the need for second-pass rescoring.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Kannan_A/0/1/0/all/0/1&quot;&gt;Anjuli Kannan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Wu_Y/0/1/0/all/0/1&quot;&gt;Yonghui Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Nguyen_P/0/1/0/all/0/1&quot;&gt;Patrick Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Sainath_T/0/1/0/all/0/1&quot;&gt;Tara N. Sainath&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Chen_Z/0/1/0/all/0/1&quot;&gt;Zhifeng Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Prabhavalkar_R/0/1/0/all/0/1&quot;&gt;Rohit Prabhavalkar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.02034">
<title>SMILES2Vec: An Interpretable General-Purpose Deep Neural Network for Predicting Chemical Properties. (arXiv:1712.02034v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1712.02034</link>
<description rdf:parseType="Literal">&lt;p&gt;Chemical databases store information in text representations, and the SMILES
format is a universal standard used in many cheminformatics software. Encoded
in each SMILES string is structural information that can be used to predict
complex chemical properties. In this work, we develop SMILES2Vec, a deep RNN
that automatically learns features from SMILES strings to predict chemical
properties, without the need for additional explicit chemical information, or
the &quot;grammar&quot; of how SMILES encode structural data. Using Bayesian optimization
methods to tune the network architecture, we show that an optimized SMILES2Vec
model can serve as a general-purpose neural network for learning a range of
distinct chemical properties including toxicity, activity, solubility and
solvation energy, while outperforming contemporary MLP networks that uses
engineered features. Furthermore, we demonstrate proof-of-concept of
interpretability by developing an explanation mask that localizes on the most
important characters used in making a prediction. When tested on the solubility
dataset, this localization identifies specific parts of a chemical that is
consistent with established first-principles knowledge of solubility with an
accuracy of 88%, demonstrating that neural networks can learn technically
accurate chemical concepts. The fact that SMILES2Vec validates established
chemical facts, while providing state-of-the-art accuracy, makes it a potential
tool for widespread adoption of interpretable deep learning by the chemistry
community.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Goh_G/0/1/0/all/0/1&quot;&gt;Garrett B. Goh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hodas_N/0/1/0/all/0/1&quot;&gt;Nathan O. Hodas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Siegel_C/0/1/0/all/0/1&quot;&gt;Charles Siegel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Vishnu_A/0/1/0/all/0/1&quot;&gt;Abhinav Vishnu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.02046">
<title>Learning General Latent-Variable Graphical Models with Predictive Belief Propagation and Hilbert Space Embeddings. (arXiv:1712.02046v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1712.02046</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we propose a new algorithm for learning general
latent-variable probabilistic graphical models using the techniques of
predictive state representation, instrumental variable regression, and
reproducing-kernel Hilbert space embeddings of distributions. Under this new
learning framework, we first convert latent-variable graphical models into
corresponding latent-variable junction trees, and then reduce the hard
parameter learning problem into a pipeline of supervised learning problems,
whose results will then be used to perform predictive belief propagation over
the latent junction tree during the actual inference procedure. We then give
proofs of our algorithm&apos;s correctness, and demonstrate its good performance in
experiments on one synthetic dataset and two real-world tasks from
computational biology and computer vision - classifying DNA splice junctions
and recognizing human actions in videos.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1&quot;&gt;Borui Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gordon_G/0/1/0/all/0/1&quot;&gt;Geoffrey Gordon&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.02047">
<title>Distance-based Self-Attention Network for Natural Language Inference. (arXiv:1712.02047v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1712.02047</link>
<description rdf:parseType="Literal">&lt;p&gt;Attention mechanism has been used as an ancillary means to help RNN or CNN.
However, the Transformer (Vaswani et al., 2017) recently recorded the
state-of-the-art performance in machine translation with a dramatic reduction
in training time by solely using attention. Motivated by the Transformer,
Directional Self Attention Network (Shen et al., 2017), a fully attention-based
sentence encoder, was proposed. It showed good performance with various data by
using forward and backward directional information in a sentence. But in their
study, not considered at all was the distance between words, an important
feature when learning the local dependency to help understand the context of
input text. We propose Distance-based Self-Attention Network, which considers
the word distance by using a simple distance mask in order to model the local
dependency without losing the ability of modeling global dependency which
attention has inherent. Our model shows good performance with NLI data, and it
records the new state-of-the-art result with SNLI data. Additionally, we show
that our model has a strength in long sentences or documents.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Im_J/0/1/0/all/0/1&quot;&gt;Jinbae Im&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cho_S/0/1/0/all/0/1&quot;&gt;Sungzoon Cho&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.02224">
<title>Human Perception of Performance. (arXiv:1712.02224v1 [physics.soc-ph])</title>
<link>http://arxiv.org/abs/1712.02224</link>
<description rdf:parseType="Literal">&lt;p&gt;Humans are routinely asked to evaluate the performance of other individuals,
separating success from failure and affecting outcomes from science to
education and sports. Yet, in many contexts, the metrics driving the human
evaluation process remain unclear. Here we analyse a massive dataset capturing
players&apos; evaluations by human judges to explore human perception of performance
in soccer, the world&apos;s most popular sport. We use machine learning to design an
artificial judge which accurately reproduces human evaluation, allowing us to
demonstrate how human observers are biased towards diverse contextual features.
By investigating the structure of the artificial judge, we uncover the aspects
of the players&apos; behavior which attract the attention of human judges,
demonstrating that human evaluation is based on a noticeability heuristic where
only feature values far from the norm are considered to rate an individual&apos;s
performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Pappalardo_L/0/1/0/all/0/1&quot;&gt;Luca Pappalardo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Cintia_P/0/1/0/all/0/1&quot;&gt;Paolo Cintia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Pedreschi_D/0/1/0/all/0/1&quot;&gt;Dino Pedreschi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Giannotti_F/0/1/0/all/0/1&quot;&gt;Fosca Giannotti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Barabasi_A/0/1/0/all/0/1&quot;&gt;Albert-Laszlo Barabasi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.02225">
<title>Pose-Normalized Image Generation for Person Re-identification. (arXiv:1712.02225v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1712.02225</link>
<description rdf:parseType="Literal">&lt;p&gt;Person Re-identification (re-id) faces two major challenges: the lack of
cross-view paired training data and learning discriminative identity-sensitive
and view-invariant features in the presence of large pose variations. In this
work, we address both problems by proposing a novel deep person image
generation model for synthesizing realistic person images conditional on pose.
The model is based on a generative adversarial network (GAN) and used
specifically for pose normalization in re-id, thus termed pose-normalization
GAN (PN-GAN). With the synthesized images, we can learn a new type of deep
re-id feature free of the influence of pose variations. We show that this
feature is strong on its own and highly complementary to features learned with
the original images. Importantly, we now have a model that generalizes to any
new re-id dataset without the need for collecting any training data for model
fine-tuning, thus making a deep re-id model truly scalable. Extensive
experiments on five benchmarks show that our model outperforms the
state-of-the-art models, often significantly. In particular, the features
learned on Market-1501 can achieve a Rank-1 accuracy of 68.67% on VIPeR without
any model fine-tuning, beating almost all existing models fine-tuned on the
dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qian_X/0/1/0/all/0/1&quot;&gt;Xuelin Qian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1&quot;&gt;Yanwei Fu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1&quot;&gt;Wenxuan Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiang_T/0/1/0/all/0/1&quot;&gt;Tao Xiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1&quot;&gt;Yang Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1&quot;&gt;Yu-Gang Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xue_X/0/1/0/all/0/1&quot;&gt;Xiangyang Xue&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1003.3967">
<title>Adaptive Submodularity: Theory and Applications in Active Learning and Stochastic Optimization. (arXiv:1003.3967v5 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1003.3967</link>
<description rdf:parseType="Literal">&lt;p&gt;Solving stochastic optimization problems under partial observability, where
one needs to adaptively make decisions with uncertain outcomes, is a
fundamental but notoriously difficult challenge. In this paper, we introduce
the concept of adaptive submodularity, generalizing submodular set functions to
adaptive policies. We prove that if a problem satisfies this property, a simple
adaptive greedy algorithm is guaranteed to be competitive with the optimal
policy. In addition to providing performance guarantees for both stochastic
maximization and coverage, adaptive submodularity can be exploited to
drastically speed up the greedy algorithm by using lazy evaluations. We
illustrate the usefulness of the concept by giving several examples of adaptive
submodular objectives arising in diverse applications including sensor
placement, viral marketing and active learning. Proving adaptive submodularity
for these problems allows us to recover existing results in these applications
as special cases, improve approximation guarantees and handle natural
generalizations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Golovin_D/0/1/0/all/0/1&quot;&gt;Daniel Golovin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Krause_A/0/1/0/all/0/1&quot;&gt;Andreas Krause&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1703.03453">
<title>Using Options and Covariance Testing for Long Horizon Off-Policy Policy Evaluation. (arXiv:1703.03453v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1703.03453</link>
<description rdf:parseType="Literal">&lt;p&gt;Evaluating a policy by deploying it in the real world can be risky and
costly. Off-policy policy evaluation (OPE) algorithms use historical data
collected from running a previous policy to evaluate a new policy, which
provides a means for evaluating a policy without requiring it to ever be
deployed. Importance sampling is a popular OPE method because it is robust to
partial observability and works with continuous states and actions. However,
the amount of historical data required by importance sampling can scale
exponentially with the horizon of the problem: the number of sequential
decisions that are made. We propose using policies over temporally extended
actions, called options, and show that combining these policies with importance
sampling can significantly improve performance for long-horizon problems. In
addition, we can take advantage of special cases that arise due to
options-based policies to further improve the performance of importance
sampling. We further generalize these special cases to a general covariance
testing rule that can be used to decide which weights to drop in an IS
estimate, and derive a new IS algorithm called Incremental Importance Sampling
that can provide significantly more accurate estimates for a broad class of
domains.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_Z/0/1/0/all/0/1&quot;&gt;Zhaohan Daniel Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Thomas_P/0/1/0/all/0/1&quot;&gt;Philip S. Thomas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brunskill_E/0/1/0/all/0/1&quot;&gt;Emma Brunskill&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1704.03627">
<title>Real-time On-Demand Crowd-powered Entity Extraction. (arXiv:1704.03627v2 [cs.HC] UPDATED)</title>
<link>http://arxiv.org/abs/1704.03627</link>
<description rdf:parseType="Literal">&lt;p&gt;Output-agreement mechanisms such as ESP Game have been widely used in human
computation to obtain reliable human-generated labels. In this paper, we argue
that a &quot;time-limited&quot; output-agreement mechanism can be used to create a fast
and robust crowd-powered component in interactive systems, particularly
dialogue systems, to extract key information from user utterances on the fly.
Our experiments on Amazon Mechanical Turk using the Airline Travel Information
System (ATIS) dataset showed that the proposed approach achieves high-quality
results with an average response time shorter than 9 seconds.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_T/0/1/0/all/0/1&quot;&gt;Ting-Hao &amp;#x27;Kenneth&amp;#x27; Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yun-Nung Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bigham_J/0/1/0/all/0/1&quot;&gt;Jeffrey P. Bigham&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1704.04683">
<title>RACE: Large-scale ReAding Comprehension Dataset From Examinations. (arXiv:1704.04683v5 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1704.04683</link>
<description rdf:parseType="Literal">&lt;p&gt;We present RACE, a new dataset for benchmark evaluation of methods in the
reading comprehension task. Collected from the English exams for middle and
high school Chinese students in the age range between 12 to 18, RACE consists
of near 28,000 passages and near 100,000 questions generated by human experts
(English instructors), and covers a variety of topics which are carefully
designed for evaluating the students&apos; ability in understanding and reasoning.
In particular, the proportion of questions that requires reasoning is much
larger in RACE than that in other benchmark datasets for reading comprehension,
and there is a significant gap between the performance of the state-of-the-art
models (43%) and the ceiling human performance (95%). We hope this new dataset
can serve as a valuable resource for research and evaluation in machine
comprehension. The dataset is freely available at
&lt;a href=&quot;http://www.cs.cmu.edu/~glai1/data/race/&quot;&gt;this http URL&lt;/a&gt; and the code is available at
https://github.com/qizhex/RACE_AR_baselines.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lai_G/0/1/0/all/0/1&quot;&gt;Guokun Lai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_Q/0/1/0/all/0/1&quot;&gt;Qizhe Xie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1&quot;&gt;Hanxiao Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1&quot;&gt;Yiming Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hovy_E/0/1/0/all/0/1&quot;&gt;Eduard Hovy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.03339">
<title>Autonomous Quadrotor Landing using Deep Reinforcement Learning. (arXiv:1709.03339v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1709.03339</link>
<description rdf:parseType="Literal">&lt;p&gt;Landing an unmanned aerial vehicle (UAV) on a ground marker is an open
problem despite the effort of the research community. Previous attempts mostly
focused on the analysis of hand-crafted geometric features and the use of
external sensors in order to allow the vehicle to approach the land-pad. In
this article, we propose a method based on deep reinforcement learning that
only requires low-resolution images taken from a down-looking camera in order
to identify the position of the marker and land the UAV on it. The proposed
approach is based on a hierarchy of Deep Q-Networks (DQNs) used as high-level
control policy for the navigation toward the marker. We implemented different
technical solutions, such as the combination of vanilla and double DQNs trained
using a partitioned buffer replay.The results show that policies trained on
uniform textures can accomplish autonomous landing on a large variety of
simulated environments. The overall performance is comparable with a
state-of-the-art algorithm and human pilots.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Polvara_R/0/1/0/all/0/1&quot;&gt;Riccardo Polvara&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Patacchiola_M/0/1/0/all/0/1&quot;&gt;Massimiliano Patacchiola&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sharma_S/0/1/0/all/0/1&quot;&gt;Sanjay Sharma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wan_J/0/1/0/all/0/1&quot;&gt;Jian Wan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Manning_A/0/1/0/all/0/1&quot;&gt;Andrew Manning&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sutton_R/0/1/0/all/0/1&quot;&gt;Robert Sutton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cangelosi_A/0/1/0/all/0/1&quot;&gt;Angelo Cangelosi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.00929">
<title>SERKET: An Architecture for Connecting Stochastic Models to Realize a Large-Scale Cognitive Model. (arXiv:1712.00929v3 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1712.00929</link>
<description rdf:parseType="Literal">&lt;p&gt;To realize human-like robot intelligence, a large-scale cognitive
architecture is required for robots to understand the environment through a
variety of sensors with which they are equipped. In this paper, we propose a
novel framework named Serket that enables the construction of a large-scale
generative model and its inference easily by connecting sub-modules to allow
the robots to acquire various capabilities through interaction with their
environments and others. We consider that large-scale cognitive models can be
constructed by connecting smaller fundamental models hierarchically while
maintaining their programmatic independence. Moreover, connected modules are
dependent on each other, and parameters are required to be optimized as a
whole. Conventionally, the equations for parameter estimation have to be
derived and implemented depending on the models. However, it becomes harder to
derive and implement those of a larger scale model. To solve these problems, in
this paper, we propose a method for parameter estimation by communicating the
minimal parameters between various modules while maintaining their programmatic
independence. Therefore, Serket makes it easy to construct large-scale models
and estimate their parameters via the connection of modules. Experimental
results demonstrated that the model can be constructed by connecting modules,
the parameters can be optimized as a whole, and they are comparable with the
original models that we have proposed.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nakamura_T/0/1/0/all/0/1&quot;&gt;Tomoaki Nakamura&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nagai_T/0/1/0/all/0/1&quot;&gt;Takayuki Nagai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Taniguchi_T/0/1/0/all/0/1&quot;&gt;Tadahiro Taniguchi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.01856">
<title>Optimizing Human Learning. (arXiv:1712.01856v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1712.01856</link>
<description rdf:parseType="Literal">&lt;p&gt;Spaced repetition is a technique for efficient memorization which uses
repeated, spaced review of content to improve long-term retention. Can we find
the optimal reviewing schedule to maximize the benefits of spaced repetition?
In this paper, we introduce a novel, flexible representation of spaced
repetition using the framework of marked temporal point processes and then
address the above question as an optimal control problem for stochastic
differential equations with jumps. For two well-known human memory models, we
show that the optimal reviewing schedule is given by the recall probability of
the content to be learned. As a result, we can then develop a simple, scalable
online algorithm, Memorize, to sample the optimal reviewing times. Experiments
on both synthetic and real data gathered from Duolingo, a popular
language-learning online platform, show that our algorithm may be able to help
learners memorize more effectively than alternatives.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tabibian_B/0/1/0/all/0/1&quot;&gt;Behzad Tabibian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Upadhyay_U/0/1/0/all/0/1&quot;&gt;Utkarsh Upadhyay&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+De_A/0/1/0/all/0/1&quot;&gt;Abir De&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zarezade_A/0/1/0/all/0/1&quot;&gt;Ali Zarezade&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Schoelkopf_B/0/1/0/all/0/1&quot;&gt;Bernhard Schoelkopf&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gomez_Rodriguez_M/0/1/0/all/0/1&quot;&gt;Manuel Gomez-Rodriguez&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.01864">
<title>No Need for a Lexicon? Evaluating the Value of the Pronunciation Lexica in End-to-End Models. (arXiv:1712.01864v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1712.01864</link>
<description rdf:parseType="Literal">&lt;p&gt;For decades, context-dependent phonemes have been the dominant sub-word unit
for conventional acoustic modeling systems. This status quo has begun to be
challenged recently by end-to-end models which seek to combine acoustic,
pronunciation, and language model components into a single neural network. Such
systems, which typically predict graphemes or words, simplify the recognition
process since they remove the need for a separate expert-curated pronunciation
lexicon to map from phoneme-based units to words. However, there has been
little previous work comparing phoneme-based versus grapheme-based sub-word
units in the end-to-end modeling framework, to determine whether the gains from
such approaches are primarily due to the new probabilistic model, or from the
joint learning of the various components with grapheme-based units.
&lt;/p&gt;
&lt;p&gt;In this work, we conduct detailed experiments which are aimed at quantifying
the value of phoneme-based pronunciation lexica in the context of end-to-end
models. We examine phoneme-based end-to-end models, which are contrasted
against grapheme-based ones on a large vocabulary English Voice-search task,
where we find that graphemes do indeed outperform phonemes. We also compare
grapheme and phoneme-based approaches on a multi-dialect English task, which
once again confirm the superiority of graphemes, greatly simplifying the system
for recognizing multiple dialects.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sainath_T/0/1/0/all/0/1&quot;&gt;Tara N. Sainath&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Prabhavalkar_R/0/1/0/all/0/1&quot;&gt;Rohit Prabhavalkar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1&quot;&gt;Shankar Kumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1&quot;&gt;Seungji Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kannan_A/0/1/0/all/0/1&quot;&gt;Anjuli Kannan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rybach_D/0/1/0/all/0/1&quot;&gt;David Rybach&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schogol_V/0/1/0/all/0/1&quot;&gt;Vlad Schogol&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_P/0/1/0/all/0/1&quot;&gt;Patrick Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1&quot;&gt;Bo Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1&quot;&gt;Yonghui Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1&quot;&gt;Zhifeng Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chiu_C/0/1/0/all/0/1&quot;&gt;Chung-Cheng Chiu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.01887">
<title>Deep Gradient Compression: Reducing the Communication Bandwidth for Distributed Training. (arXiv:1712.01887v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1712.01887</link>
<description rdf:parseType="Literal">&lt;p&gt;Large-scale distributed training requires significant communication bandwidth
for gradient exchange that limits the scalability of multi-node training, and
requires expensive high-bandwidth network infrastructure. The situation gets
even worse with distributed training on mobile devices (federated learning),
which suffers from higher latency, lower throughput, and intermittent poor
connections. In this paper, we find 99.9% of the gradient exchange in
distributed SGD is redundant, and propose Deep Gradient Compression (DGC) to
greatly reduce the communication bandwidth. To preserve accuracy during
compression, DGC employs four methods: momentum correction, local gradient
clipping, momentum factor masking, and warm-up training. We have applied Deep
Gradient Compression to image classification, speech recognition, and language
modeling with multiple datasets including Cifar10, ImageNet, Penn Treebank, and
Librispeech Corpus. On these scenarios, Deep Gradient Compression achieves a
gradient compression ratio from 270x to 600x without losing accuracy, cutting
the gradient size of ResNet-50 from 97MB to 0.35MB, and for DeepSpeech from
488MB to 0.74MB. Deep gradient compression enables large-scale distributed
training on inexpensive commodity 1Gbps Ethernet and facilitates distributed
training on mobile.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1&quot;&gt;Yujun Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1&quot;&gt;Song Han&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mao_H/0/1/0/all/0/1&quot;&gt;Huizi Mao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yu Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dally_W/0/1/0/all/0/1&quot;&gt;William J. Dally&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.01934">
<title>Concentration of weakly dependent Banach-valued sums and applications to kernel learning methods. (arXiv:1712.01934v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1712.01934</link>
<description rdf:parseType="Literal">&lt;p&gt;We obtain a new Bernstein-type inequality for sums of Banach-valued random
variables satisfying a weak dependence assumption of general type and under
certain smoothness assumptions of the underlying Banach norm. We use this
inequality in order to investigate in asymptotical regime the error upper
bounds for the broad family of spectral regularization methods for reproducing
kernel decision rules, when trained on a sample coming from a $\tau-$mixing
process.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Blanchard_G/0/1/0/all/0/1&quot;&gt;Gilles Blanchard&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zadorozhnyi_O/0/1/0/all/0/1&quot;&gt;Oleksandr Zadorozhnyi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.02009">
<title>On the nonparametric maximum likelihood estimator for Gaussian location mixture densities with application to Gaussian denoising. (arXiv:1712.02009v1 [math.ST])</title>
<link>http://arxiv.org/abs/1712.02009</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the Nonparametric Maximum Likelihood Estimator (NPMLE) for
estimating Gaussian location mixture densities in $d$-dimensions from
independent observations. Unlike usual likelihood-based methods for fitting
mixtures, NPMLEs are based on convex optimization. We prove finite sample
results on the Hellinger accuracy of every NPMLE. Our results imply, in
particular, that every NPMLE achieves near parametric risk (up to logarithmic
multiplicative factors) when the true density is a discrete Gaussian mixture
without any prior information on the number of mixture components. NPMLEs can
naturally be used to yield empirical Bayes estimates of the Oracle Bayes
estimator in the Gaussian denoising problem. We prove bounds for the accuracy
of the empirical Bayes estimate as an approximation to the Oracle Bayes
estimator. Here our results imply that the empirical Bayes estimator performs
at nearly the optimal level (up to logarithmic multiplicative factors) for
denoising in clustering situations without any prior knowledge of the number of
clusters.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Saha_S/0/1/0/all/0/1&quot;&gt;Sujayam Saha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Guntuboyina_A/0/1/0/all/0/1&quot;&gt;Adityanand Guntuboyina&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.02029">
<title>AdaBatch: Adaptive Batch Sizes for Training Deep Neural Networks. (arXiv:1712.02029v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1712.02029</link>
<description rdf:parseType="Literal">&lt;p&gt;Training deep neural networks with Stochastic Gradient Descent, or its
variants, requires careful choice of both learning rate and batch size. While
smaller batch sizes generally converge in fewer training epochs, larger batch
sizes offer more parallelism and hence better computational efficiency. We have
developed a new training approach that, rather than statically choosing a
single batch size for all epochs, adaptively increases the batch size during
the training process. Our method delivers the convergence rate of small batch
sizes while achieving performance similar to large batch sizes. We analyse our
approach using the standard AlexNet, ResNet, and VGG networks operating on the
popular CIFAR-10, CIFAR-100, and ImageNet datasets. Our results demonstrate
that learning with adaptive batch sizes can improve performance by factors of
up to 6.25 on 4 NVIDIA Tesla P100 GPUs while changing accuracy by less than 1%
relative to training with fixed batch sizes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Devarakonda_A/0/1/0/all/0/1&quot;&gt;Aditya Devarakonda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Naumov_M/0/1/0/all/0/1&quot;&gt;Maxim Naumov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garland_M/0/1/0/all/0/1&quot;&gt;Michael Garland&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.02083">
<title>A Local Analysis of Block Coordinate Descent for Gaussian Phase Retrieval. (arXiv:1712.02083v1 [cs.IT])</title>
<link>http://arxiv.org/abs/1712.02083</link>
<description rdf:parseType="Literal">&lt;p&gt;While convergence of the Alternating Direction Method of Multipliers (ADMM)
on convex problems is well studied, convergence on nonconvex problems is only
partially understood. In this paper, we consider the Gaussian phase retrieval
problem, formulated as a linear constrained optimization problem with a
biconvex objective. The particular structure allows for a novel application of
the ADMM. It can be shown that the dual variable is zero at the global
minimizer. This motivates the analysis of a block coordinate descent algorithm,
which is equivalent to the ADMM with the dual variable fixed to be zero. We
show that the block coordinate descent algorithm converges to the global
minimizer at a linear rate, when starting from a deterministically achievable
initialization point.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barmherzig_D/0/1/0/all/0/1&quot;&gt;David Barmherzig&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1&quot;&gt;Ju Sun&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.02154">
<title>Guided Labeling using Convolutional Neural Networks. (arXiv:1712.02154v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1712.02154</link>
<description rdf:parseType="Literal">&lt;p&gt;Over the last couple of years, deep learning and especially convolutional
neural networks have become one of the work horses of computer vision. One
limiting factor for the applicability of supervised deep learning to more areas
is the need for large, manually labeled datasets. In this paper we propose an
easy to implement method we call guided labeling, which automatically
determines which samples from an unlabeled dataset should be labeled. We show
that using this procedure, the amount of samples that need to be labeled is
reduced considerably in comparison to labeling images arbitrarily.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stabinger_S/0/1/0/all/0/1&quot;&gt;Sebastian Stabinger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rodriguez_Sanchez_A/0/1/0/all/0/1&quot;&gt;Antonio Rodriguez-Sanchez&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.02162">
<title>A trans-disciplinary review of deep learning research for water resources scientists. (arXiv:1712.02162v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1712.02162</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep learning (DL), a new-generation artificial neural network research, has
made profound strides in recent years. This review paper is intended to provide
hydrologists with a simple technical overview, trans-disciplinary progress
update, and potentially inspirations about DL. Novel architectures, large and
more accessible data, and new computing power enabled the success of DL. The
review reveals that DL is rapidly transforming myriad scientific disciplines
including high-energy physics, astronomy, chemistry, genomics and remote
sensing, where systematic DL toolkits, innovative customizations, and
sub-disciplines have emerged. However, with a few exceptions, its adoption in
hydrology has so far been gradual. The literature suggests that novel
regularization techniques can effectively prevent high-capacity deep networks
from overfitting. As a result, in most scientific disciplines, DL models
demonstrated superior predictive and generalization performance to conventional
methods. Meanwhile, less noticed is that DL may also serve as a scientific
exploratory tool. A new area termed &quot;AI neuroscience&quot;, has been born. This
budding sub-discipline is accumulating a significant body of work, e.g.,
distilling knowledge obtained in DL networks to interpretable models,
attributing decisions to inputs via back-propagation of relevance, or
visualization of activations. These methods are designed to interpret the
decision process of deep networks and derive insights. While scientists so far
have mostly been using customized, ad-hoc methods for interpretation, vast
opportunities await for DL to propel science advancement, along with greatly
enhanced predictive capability.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Shen_C/0/1/0/all/0/1&quot;&gt;Chaopeng Shen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.02195">
<title>Fast spatial inference in the homogeneous Ising model. (arXiv:1712.02195v1 [stat.ME])</title>
<link>http://arxiv.org/abs/1712.02195</link>
<description rdf:parseType="Literal">&lt;p&gt;The Ising model is important in statistical modeling and inference in many
applications, however its normalizing constant, mean number of active vertices
and mean spin interaction are intractable. We provide accurate approximations
that make it possible to calculate these quantities numerically. Simulation
studies indicate good performance when compared to Markov Chain Monte Carlo
methods and at a tiny fraction of the time. The methodology is also used to
perform Bayesian inference in a functional Magnetic Resonance Imaging
activation detection experiment.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Murua_A/0/1/0/all/0/1&quot;&gt;Alejandro Murua&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Maitra_R/0/1/0/all/0/1&quot;&gt;Ranjan Maitra&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.02259">
<title>An innovative solution for breast cancer textual big data analysis. (arXiv:1712.02259v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1712.02259</link>
<description rdf:parseType="Literal">&lt;p&gt;The digitalization of stored information in hospitals now allows for the
exploitation of medical data in text format, as electronic health records
(EHRs), initially gathered for other purposes than epidemiology. Manual search
and analysis operations on such data become tedious. In recent years, the use
of natural language processing (NLP) tools was highlighted to automatize the
extraction of information contained in EHRs, structure it and perform
statistical analysis on this structured information. The main difficulties with
the existing approaches is the requirement of synonyms or ontology
dictionaries, that are mostly available in English only and do not include
local or custom notations. In this work, a team composed of oncologists as
domain experts and data scientists develop a custom NLP-based system to process
and structure textual clinical reports of patients suffering from breast
cancer. The tool relies on the combination of standard text mining techniques
and an advanced synonym detection method. It allows for a global analysis by
retrieval of indicators such as medical history, tumor characteristics,
therapeutic responses, recurrences and prognosis. The versatility of the method
allows to obtain easily new indicators, thus opening up the way for
retrospective studies with a substantial reduction of the amount of manual
work. With no need for biomedical annotators or pre-defined ontologies, this
language-agnostic method reached an good extraction accuracy for several
concepts of interest, according to a comparison with a manually structured
file, without requiring any existing corpus with local or new notations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Thiebaut_N/0/1/0/all/0/1&quot;&gt;Nicolas Thiebaut&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Simoulin_A/0/1/0/all/0/1&quot;&gt;Antoine Simoulin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Neuberger_K/0/1/0/all/0/1&quot;&gt;Karl Neuberger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ibnouhsein_I/0/1/0/all/0/1&quot;&gt;Issam Ibnouhsein&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bousquet_N/0/1/0/all/0/1&quot;&gt;Nicolas Bousquet&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Reix_N/0/1/0/all/0/1&quot;&gt;Nathalie Reix&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Moliere_S/0/1/0/all/0/1&quot;&gt;S&amp;#xe9;bastien Moli&amp;#xe8;re&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mathelin_C/0/1/0/all/0/1&quot;&gt;Carole Mathelin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.02270">
<title>Attention based convolutional neural network for predicting RNA-protein binding sites. (arXiv:1712.02270v1 [q-bio.GN])</title>
<link>http://arxiv.org/abs/1712.02270</link>
<description rdf:parseType="Literal">&lt;p&gt;RNA-binding proteins (RBPs) play crucial roles in many biological processes,
e.g. gene regulation. Computational identification of RBP binding sites on RNAs
are urgently needed. In particular, RBPs bind to RNAs by recognizing sequence
motifs. Thus, fast locating those motifs on RNA sequences is crucial and
time-efficient for determining whether the RNAs interact with the RBPs or not.
In this study, we present an attention based convolutional neural network,
iDeepA, to predict RNA-protein binding sites from raw RNA sequences. We first
encode RNA sequences into one-hot encoding. Next, we design a deep learning
model with a convolutional neural network (CNN) and an attention mechanism,
which automatically search for important positions, e.g. binding motifs, to
learn discriminant high-level features for predicting RBP binding sites. We
evaluate iDeepA on publicly gold-standard RBP binding sites derived from
CLIP-seq data. The results demonstrate iDeepA achieves comparable performance
with other state-of-the-art methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Pan_X/0/1/0/all/0/1&quot;&gt;Xiaoyong Pan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Yan_J/0/1/0/all/0/1&quot;&gt;Junchi Yan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.02311">
<title>Exchangeable modelling of relational data: checking sparsity, train-test splitting, and sparse exchangeable Poisson matrix factorization. (arXiv:1712.02311v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1712.02311</link>
<description rdf:parseType="Literal">&lt;p&gt;A variety of machine learning tasks---e.g., matrix factorization, topic
modelling, and feature allocation---can be viewed as learning the parameters of
a probability distribution over bipartite graphs. Recently, a new class of
models for networks, the sparse exchangeable graphs, have been introduced to
resolve some important pathologies of traditional approaches to statistical
network modelling; most notably, the inability to model sparsity (in the
asymptotic sense). The present paper explains some practical insights arising
from this work. We first show how to check if sparsity is relevant for
modelling a given (fixed size) dataset by using network subsampling to identify
a simple signature of sparsity. We discuss the implications of the (sparse)
exchangeable subsampling theory for test-train dataset splitting; we argue
common approaches can lead to biased results, and we propose a principled
alternative. Finally, we study sparse exchangeable Poisson matrix factorization
as a worked example. In particular, we show how to adapt mean field variational
inference to the sparse exchangeable setting, allowing us to scale inference to
huge datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Veitch_V/0/1/0/all/0/1&quot;&gt;Victor Veitch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sharma_E/0/1/0/all/0/1&quot;&gt;Ekansh Sharma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Naulet_Z/0/1/0/all/0/1&quot;&gt;Zacharie Naulet&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Roy_D/0/1/0/all/0/1&quot;&gt;Daniel M. Roy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.02330">
<title>SGAN: An Alternative Training of Generative Adversarial Networks. (arXiv:1712.02330v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1712.02330</link>
<description rdf:parseType="Literal">&lt;p&gt;The Generative Adversarial Networks (GANs) have demonstrated impressive
performance for data synthesis, and are now used in a wide range of computer
vision tasks. In spite of this success, they gained a reputation for being
difficult to train, what results in a time-consuming and human-involved
development process to use them.
&lt;/p&gt;
&lt;p&gt;We consider an alternative training process, named SGAN, in which several
adversarial &quot;local&quot; pairs of networks are trained independently so that a
&quot;global&quot; supervising pair of networks can be trained against them. The goal is
to train the global pair with the corresponding ensemble opponent for improved
performances in terms of mode coverage. This approach aims at increasing the
chances that learning will not stop for the global pair, preventing both to be
trapped in an unsatisfactory local minimum, or to face oscillations often
observed in practice. To guarantee the latter, the global pair never affects
the local ones.
&lt;/p&gt;
&lt;p&gt;The rules of SGAN training are thus as follows: the global generator and
discriminator are trained using the local discriminators and generators,
respectively, whereas the local networks are trained with their fixed local
opponent.
&lt;/p&gt;
&lt;p&gt;Experimental results on both toy and real-world problems demonstrate that
this approach outperforms standard training in terms of better mitigating mode
collapse, stability while converging and that it surprisingly, increases the
convergence speed as well.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chavdarova_T/0/1/0/all/0/1&quot;&gt;Tatjana Chavdarova&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Fleuret_F/0/1/0/all/0/1&quot;&gt;Fran&amp;#xe7;ois Fleuret&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1705.05950">
<title>Kernel clustering: density biases and solutions. (arXiv:1705.05950v5 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1705.05950</link>
<description rdf:parseType="Literal">&lt;p&gt;Kernel methods are popular in clustering due to their generality and
discriminating power. However, we show that many kernel clustering criteria
have density biases theoretically explaining some practically significant
artifacts empirically observed in the past. For example, we provide conditions
and formally prove the density mode isolation bias in kernel K-means for a
common class of kernels. We call it Breiman&apos;s bias due to its similarity to the
histogram mode isolation previously discovered by Breiman in decision tree
learning with Gini impurity. We also extend our analysis to other popular
kernel clustering methods, e.g. average/normalized cut or dominant sets, where
density biases can take different forms. For example, splitting isolated points
by cut-based criteria is essentially the sparsest subset bias, which is the
opposite of the density mode bias. Our findings suggest that a principled
solution for density biases in kernel clustering should directly address data
inhomogeneity. We show that density equalization can be implicitly achieved
using either locally adaptive weights or locally adaptive kernels. Moreover,
density equalization makes many popular kernel clustering objectives
equivalent. Our synthetic and real data experiments illustrate density biases
and proposed solutions. We anticipate that theoretical understanding of kernel
clustering limitations and their principled solutions will be important for a
broad spectrum of data analysis applications across the disciplines.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Marin_D/0/1/0/all/0/1&quot;&gt;Dmitrii Marin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tang_M/0/1/0/all/0/1&quot;&gt;Meng Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ayed_I/0/1/0/all/0/1&quot;&gt;Ismail Ben Ayed&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Boykov_Y/0/1/0/all/0/1&quot;&gt;Yuri Boykov&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.08873">
<title>Robust Photometric Stereo via Dictionary Learning. (arXiv:1710.08873v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1710.08873</link>
<description rdf:parseType="Literal">&lt;p&gt;Photometric stereo is a method that seeks to reconstruct the normal vectors
of an object from a set of images of the object illuminated under different
light sources. While effective in some situations, classical photometric stereo
relies on a diffuse surface model that cannot handle objects with complex
reflectance patterns, and it is sensitive to non-idealities in the images. In
this work, we propose a novel approach to photometric stereo that relies on
dictionary learning to produce robust normal vector reconstructions.
Specifically, we develop three formulations for applying dictionary learning to
photometric stereo. We propose a preprocessing step that utilizes dictionary
learning to denoise the images. We also present a model that applies dictionary
learning to regularize and reconstruct the normal vectors from the images under
the classic Lambertian reflectance model. Finally, we generalize the latter
model to explicitly model non-Lambertian objects. We investigate all three
approaches through extensive experimentation on synthetic and real benchmark
datasets and observe state-of-the-art performance compared to existing robust
photometric stereo methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wagenmaker_A/0/1/0/all/0/1&quot;&gt;Andrew J. Wagenmaker&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moore_B/0/1/0/all/0/1&quot;&gt;Brian E. Moore&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nadakuditi_R/0/1/0/all/0/1&quot;&gt;Raj Rao Nadakuditi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.02838">
<title>Stochastic Cubic Regularization for Fast Nonconvex Optimization. (arXiv:1711.02838v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1711.02838</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper proposes a stochastic variant of a classic algorithm---the
cubic-regularized Newton method [Nesterov and Polyak 2006]. The proposed
algorithm efficiently escapes saddle points and finds approximate local minima
for general smooth, nonconvex functions in only
$\mathcal{\tilde{O}}(\epsilon^{-3.5})$ stochastic gradient and stochastic
Hessian-vector product evaluations. The latter can be computed as efficiently
as stochastic gradients. This improves upon the
$\mathcal{\tilde{O}}(\epsilon^{-4})$ rate of stochastic gradient descent. Our
rate matches the best-known result for finding local minima without requiring
any delicate acceleration or variance-reduction techniques.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tripuraneni_N/0/1/0/all/0/1&quot;&gt;Nilesh Tripuraneni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stern_M/0/1/0/all/0/1&quot;&gt;Mitchell Stern&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jin_C/0/1/0/all/0/1&quot;&gt;Chi Jin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Regier_J/0/1/0/all/0/1&quot;&gt;Jeffrey Regier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jordan_M/0/1/0/all/0/1&quot;&gt;Michael I. Jordan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.05610">
<title>On consistent vertex nomination schemes. (arXiv:1711.05610v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1711.05610</link>
<description rdf:parseType="Literal">&lt;p&gt;Given a vertex of interest in a network $G_1$, the vertex nomination problem
seeks to find the corresponding vertex of interest (if it exists) in a second
network $G_2$. Although the vertex nomination problem and related tasks have
attracted much attention in the machine learning literature, with applications
to social and biological networks, the framework has so far been confined to a
comparatively small class of network models, and the concept of statistically
consistent vertex nomination schemes has been only shallowly explored. In this
paper, we extend the vertex nomination problem to a very general statistical
model of graphs. Further, drawing inspiration from the long-established
classification framework in the pattern recognition literature, we provide
definitions for the key notions of Bayes optimality and consistency in our
extended vertex nomination framework, including a derivation of the Bayes
optimal vertex nomination scheme. In addition, we prove that no universally
consistent vertex nomination schemes exist. Illustrative examples are provided
throughout.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lyzinski_V/0/1/0/all/0/1&quot;&gt;Vince Lyzinski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Levin_K/0/1/0/all/0/1&quot;&gt;Keith Levin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Priebe_C/0/1/0/all/0/1&quot;&gt;Carey E. Priebe&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.06346">
<title>Mosquito detection with low-cost smartphones: data acquisition for malaria research. (arXiv:1711.06346v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1711.06346</link>
<description rdf:parseType="Literal">&lt;p&gt;Mosquitoes are a major vector for malaria, causing hundreds of thousands of
deaths in the developing world each year. Not only is the prevention of
mosquito bites of paramount importance to the reduction of malaria transmission
cases, but understanding in more forensic detail the interplay between malaria,
mosquito vectors, vegetation, standing water and human populations is crucial
to the deployment of more effective interventions. Typically the presence and
detection of malaria-vectoring mosquitoes is only quantified by hand-operated
insect traps or signified by the diagnosis of malaria. If we are to gather
timely, large-scale data to improve this situation, we need to automate the
process of mosquito detection and classification as much as possible. In this
paper, we present a candidate mobile sensing system that acts as both a
portable early warning device and an automatic acoustic data acquisition
pipeline to help fuel scientific inquiry and policy. The machine learning
algorithm that powers the mobile system achieves excellent off-line
multi-species detection performance while remaining computationally efficient.
Further, we have conducted preliminary live mosquito detection tests using
low-cost mobile phones and achieved promising results. The deployment of this
system for field usage in Southeast Asia and Africa is planned in the near
future. In order to accelerate processing of field recordings and labelling of
collected data, we employ a citizen science platform in conjunction with
automated methods, the former implemented using the Zooniverse platform,
allowing crowdsourcing on a grand scale.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yunpeng Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zilli_D/0/1/0/all/0/1&quot;&gt;Davide Zilli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chan_H/0/1/0/all/0/1&quot;&gt;Henry Chan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kiskin_I/0/1/0/all/0/1&quot;&gt;Ivan Kiskin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sinka_M/0/1/0/all/0/1&quot;&gt;Marianne Sinka&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Roberts_S/0/1/0/all/0/1&quot;&gt;Stephen Roberts&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Willis_K/0/1/0/all/0/1&quot;&gt;Kathy Willis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.10678">
<title>Arbitrary Facial Attribute Editing: Only Change What You Want. (arXiv:1711.10678v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1711.10678</link>
<description rdf:parseType="Literal">&lt;p&gt;Facial attribute editing aims to modify either single or multiple attributes
on a face image. Since it is practically infeasible to collect images with
arbitrarily specified attributes for each person, the generative adversarial
net (GAN) and the encoder-decoder architecture are usually incorporated to
handle this task. With the encoder-decoder architecture, arbitrary attribute
editing can then be conducted by decoding the latent representation of the face
image conditioned on the specified attributes. A few existing methods attempt
to establish attribute-independent latent representation for arbitrarily
changing the attributes. However, since the attributes portray the
characteristics of the face image, the attribute-independent constraint on the
latent representation is excessive. Such constraint may result in information
loss and unexpected distortion on the generated images (e.g. over-smoothing),
especially for those identifiable attributes such as gender, race etc. Instead
of imposing the attribute-independent constraint on the latent representation,
we introduce an attribute classification constraint on the generated image,
just requiring the correct change of the attributes. Meanwhile, reconstruction
learning is introduced in order to guarantee the preservation of all other
attribute-excluding details on the generated image, and adversarial learning is
employed for visually realistic generation. Moreover, our method can be
naturally extended to attribute intensity manipulation. Experiments on the
CelebA dataset show that our method outperforms the state-of-the-arts on
generating realistic attribute editing results with facial details well
preserved.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_Z/0/1/0/all/0/1&quot;&gt;Zhenliang He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zuo_W/0/1/0/all/0/1&quot;&gt;Wangmeng Zuo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kan_M/0/1/0/all/0/1&quot;&gt;Meina Kan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shan_S/0/1/0/all/0/1&quot;&gt;Shiguang Shan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1&quot;&gt;Xilin Chen&lt;/a&gt;</dc:creator>
</item></rdf:RDF>