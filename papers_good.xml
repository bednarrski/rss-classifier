<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Good papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Good Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-06-26T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.09664"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.09819"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07249"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.08216"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.08760"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.09771"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.09777"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.09785"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.09954"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.09959"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.10019"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.10071"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.10095"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.03471"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02091"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.03536"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.07377"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1702.06253"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1702.06820"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.10402"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.09730"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.09737"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.09783"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.09856"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.09919"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.09976"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.09981"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.10064"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.10077"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1601.01345"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1606.03802"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.09805"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.09111"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.08647"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1806.09664">
<title>Artificial Quantum Neural Network: quantum neurons, logical elements and tests of convolutional nets. (arXiv:1806.09664v1 [quant-ph])</title>
<link>http://arxiv.org/abs/1806.09664</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider a model of an artificial neural network that uses
quantum-mechanical particles in a two-humped potential as a neuron. To simulate
such a quantum-mechanical system the Monte-Carlo integration method is used. A
form of the self-potential of a particle and two potentials (exciting and
inhibiting) interaction are proposed. The possibility of implementing the
simplest logical elements, (such as AND, OR and NOT) based on introduced
quantum particles is shown. Further we show implementation of a simplest
convolutional network. Finally we construct a network that recognizes
handwritten symbols, which shows that in the case of simple architectures, it
is possible to transfer weights from a classical network to a quantum one.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Dorozhinsky_V/0/1/0/all/0/1&quot;&gt;V.I. Dorozhinsky&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Pavlovsky_O/0/1/0/all/0/1&quot;&gt;O.V. Pavlovsky&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.09819">
<title>Limited Evaluation Evolutionary Optimization of Large Neural Networks. (arXiv:1806.09819v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1806.09819</link>
<description rdf:parseType="Literal">&lt;p&gt;Stochastic gradient descent is the most prevalent algorithm to train neural
networks. However, other approaches such as evolutionary algorithms are also
applicable to this task. Evolutionary algorithms bring unique trade-offs that
are worth exploring, but computational demands have so far restricted
exploration to small networks with few parameters. We implement an evolutionary
algorithm that executes entirely on the GPU, which allows to efficiently
batch-evaluate a whole population of networks. Within this framework, we
explore the limited evaluation evolutionary algorithm for neural network
training and find that its batch evaluation idea comes with a large accuracy
trade-off. In further experiments, we explore crossover operators and find that
unprincipled random uniform crossover performs extremely well. Finally, we
train a network with 92k parameters on MNIST using an EA and achieve 97.6 %
test accuracy compared to 98 % test accuracy on the same network trained with
Adam. Code is available at https://github.com/jprellberg/gpuea.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Prellberg_J/0/1/0/all/0/1&quot;&gt;Jonas Prellberg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kramer_O/0/1/0/all/0/1&quot;&gt;Oliver Kramer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07249">
<title>Dynamic learning rate using Mutual Information. (arXiv:1805.07249v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.07249</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper demonstrates dynamic hyper-parameter setting, for deep neural
network training, using Mutual Information (MI). The specific hyper-parameter
studied in this paper is the learning rate. MI between the output layer and
true outcomes is used to dynamically set the learning rate of the network
through the training cycle; the idea is also extended to layer-wise setting of
learning rate. Two approaches are demonstrated - tracking relative change in
mutual information and, additionally tracking its value relative to a reference
measure. The paper does not attempt to recommend a specific learning rate
policy. Experiments demonstrate that mutual information may be effectively used
to dynamically set learning rate and achieve competitive to better outcomes in
competitive to better time.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vasudevan_S/0/1/0/all/0/1&quot;&gt;Shrihari Vasudevan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.08216">
<title>Autoencoders for Multi-Label Prostate MR Segmentation. (arXiv:1806.08216v2 [eess.IV] UPDATED)</title>
<link>http://arxiv.org/abs/1806.08216</link>
<description rdf:parseType="Literal">&lt;p&gt;Organ image segmentation can be improved by implementing prior knowledge
about the anatomy. One way of doing this is by training an autoencoder to learn
a lowdimensional representation of the segmentation. In this paper, this is
applied in multi-label prostate MR segmentation, with some positive results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Gelder_A/0/1/0/all/0/1&quot;&gt;Ard de Gelder&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Huisman_H/0/1/0/all/0/1&quot;&gt;Henkjan Huisman&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.08760">
<title>Combination of Domain Knowledge and Deep Learning for Sentiment Analysis. (arXiv:1806.08760v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1806.08760</link>
<description rdf:parseType="Literal">&lt;p&gt;The emerging technique of deep learning has been widely applied in many
different areas. However, when adopted in a certain specific domain, this
technique should be combined with domain knowledge to improve efficiency and
accuracy. In particular, when analyzing the applications of deep learning in
sentiment analysis, we found that the current approaches are suffering from the
following drawbacks: (i) the existing works have not paid much attention to the
importance of different types of sentiment terms, which is an important concept
in this area; and (ii) the loss function currently employed does not well
reflect the degree of error of sentiment misclassification. To overcome such
problem, we propose to combine domain knowledge with deep learning. Our
proposal includes using sentiment scores, learnt by regression, to augment
training data; and introducing penalty matrix for enhancing the loss function
of cross entropy. When experimented, we achieved a significant improvement in
classification results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vo_K/0/1/0/all/0/1&quot;&gt;Khuong Vo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pham_D/0/1/0/all/0/1&quot;&gt;Dang Pham&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_M/0/1/0/all/0/1&quot;&gt;Mao Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mai_T/0/1/0/all/0/1&quot;&gt;Trung Mai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Quan_T/0/1/0/all/0/1&quot;&gt;Tho Quan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.09771">
<title>Q-DeckRec: A Fast Deck Recommendation System for Collectible Card Games. (arXiv:1806.09771v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1806.09771</link>
<description rdf:parseType="Literal">&lt;p&gt;Deck building is a crucial component in playing Collectible Card Games
(CCGs). The goal of deck building is to choose a fixed-sized subset of cards
from a large card pool, so that they work well together in-game against
specific opponents. Existing methods either lack flexibility to adapt to
different opponents or require large computational resources, still making them
unsuitable for any real-time or large-scale application. We propose a new deck
recommendation system, named Q-DeckRec, which learns a deck search policy
during a training phase and uses it to solve deck building problem instances.
Our experimental results demonstrate Q-DeckRec requires less computational
resources to build winning-effective decks after a training phase compared to
several baseline methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1&quot;&gt;Zhengxing Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Amato_C/0/1/0/all/0/1&quot;&gt;Chris Amato&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1&quot;&gt;Truong-Huy Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cooper_S/0/1/0/all/0/1&quot;&gt;Seth Cooper&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1&quot;&gt;Yizhou Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+El_Nasr_M/0/1/0/all/0/1&quot;&gt;Magy Seif El-Nasr&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.09777">
<title>On the Implicit Bias of Dropout. (arXiv:1806.09777v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.09777</link>
<description rdf:parseType="Literal">&lt;p&gt;Algorithmic approaches endow deep learning systems with implicit bias that
helps them generalize even in over-parametrized settings. In this paper, we
focus on understanding such a bias induced in learning through dropout, a
popular technique to avoid overfitting in deep learning. For single
hidden-layer linear neural networks, we show that dropout tends to make the
norm of incoming/outgoing weight vectors of all the hidden nodes equal. In
addition, we provide a complete characterization of the optimization landscape
induced by dropout.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mianjy_P/0/1/0/all/0/1&quot;&gt;Poorya Mianjy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Arora_R/0/1/0/all/0/1&quot;&gt;Raman Arora&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vidal_R/0/1/0/all/0/1&quot;&gt;Rene Vidal&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.09785">
<title>Theory of Machine Networks: A Case Study. (arXiv:1806.09785v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1806.09785</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a simplification of the Theory-of-Mind Network architecture, which
focuses on modeling complex, deterministic machines as a proxy for modeling
nondeterministic, conscious entities. We then validate this architecture in the
context of understanding engines, which, we argue, meet the required internal
and external complexity to yield meaningful abstractions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mahdavian_R/0/1/0/all/0/1&quot;&gt;Rooz Mahdavian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Martinez_R/0/1/0/all/0/1&quot;&gt;Richard Diehl Martinez&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.09954">
<title>A Constraint-based Encoding for Domain-Independent Temporal Planning. (arXiv:1806.09954v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1806.09954</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a general constraint-based encoding for domain-independent task
planning. Task planning is characterized by causal relationships expressed as
conditions and effects of optional actions. Possible actions are typically
represented by templates, where each template can be instantiated into a number
of primitive actions. While most previous work for domain-independent task
planning has focused on primitive actions in a state-oriented view, our
encoding uses a fully lifted representation at the level of action templates.
It follows a time-oriented view in the spirit of previous work in
constraint-based scheduling. As a result, the proposed encoding is simple and
compact as it grows with the number of actions in a solution plan rather than
the number of possible primitive actions. When solved with an SMT solver, we
show that the proposed encoding is slightly more efficient than
state-of-the-art methods on temporally constrained planning benchmarks while
clearly outperforming other fully constraint-based approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bit_Monnot_A/0/1/0/all/0/1&quot;&gt;Arthur Bit-Monnot&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.09959">
<title>Independence of Sources in Social Networks. (arXiv:1806.09959v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1806.09959</link>
<description rdf:parseType="Literal">&lt;p&gt;Online social networks are more and more studied. The links between users of
a social network are important and have to be well qualified in order to detect
communities and find influencers for example. In this paper, we present an
approach based on the theory of belief functions to estimate the degrees of
cognitive independence between users in a social network. We experiment the
proposed method on a large amount of data gathered from the Twitter social
network.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chehibi_M/0/1/0/all/0/1&quot;&gt;Manel Chehibi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chebbah_M/0/1/0/all/0/1&quot;&gt;Mouna Chebbah&lt;/a&gt; (LARODEC), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Martin_A/0/1/0/all/0/1&quot;&gt;Arnaud Martin&lt;/a&gt; (DRUID)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.10019">
<title>Adversarial Exploration Strategy for Self-Supervised Imitation Learning. (arXiv:1806.10019v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.10019</link>
<description rdf:parseType="Literal">&lt;p&gt;We present an adversarial exploration strategy, a simple yet effective
imitation learning scheme that incentivizes exploration of an environment
without any extrinsic reward or human demonstration. Our framework consists of
a deep reinforcement learning (DRL) agent and an inverse dynamics model
contesting with each other. The former collects training samples for the
latter, and its objective is to maximize the error of the latter. The latter is
trained with samples collected by the former, and generates rewards for the
former when it fails to predict the actual action taken by the former. In such
a competitive setting, the DRL agent learns to generate samples that the
inverse dynamics model fails to predict correctly, and the inverse dynamics
model learns to adapt to the challenging samples. We further propose a reward
structure that ensures the DRL agent collects only moderately hard samples and
not overly hard ones that prevent the inverse model from imitating effectively.
We evaluate the effectiveness of our method on several OpenAI gym robotic arm
and hand manipulation tasks against a number of baseline models. Experimental
results show that our method is comparable to that directly trained with expert
demonstrations, and superior to the other baselines even without any human
priors.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hong_Z/0/1/0/all/0/1&quot;&gt;Zhang-Wei Hong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fu_T/0/1/0/all/0/1&quot;&gt;Tsu-Jui Fu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shann_T/0/1/0/all/0/1&quot;&gt;Tzu-Yun Shann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chang_Y/0/1/0/all/0/1&quot;&gt;Yi-Hsiang Chang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_C/0/1/0/all/0/1&quot;&gt;Chun-Yi Lee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.10071">
<title>Learning Social Conventions in Markov Games. (arXiv:1806.10071v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1806.10071</link>
<description rdf:parseType="Literal">&lt;p&gt;Social conventions - arbitrary ways to organize group behavior - are an
important part of social life. Any agent that wants to enter an existing
society must be able to learn its conventions (e.g. which side of the road to
drive on, which language to speak) from relatively few observations or risk
being unable to coordinate with everyone else. We consider the game theoretic
framework of David Lewis which views the selection of a social convention as
the selection of an equilibrium in a coordination game. We ask how to construct
reinforcement learning based agents that can solve the convention learning task
in the self-play paradigm: at training time the agent has access to a good
model of the environment and a small amount of observations about how
individuals in society act. The agent then has to construct a policy that is
compatible with the test-time social convention. We study three environments
from the literature which have multiple conventions: traffic, communication,
and risky coordination. In each of these we observe that adding a small amount
of imitation learning during self-play training greatly increases the
probability that the strategy found by self-play fits well with the social
convention the agent will face at test time. We show that this works even in an
environment where standard independent multi-agent RL very rarely finds the
correct test-time equilibrium.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lerer_A/0/1/0/all/0/1&quot;&gt;Adam Lerer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peysakhovich_A/0/1/0/all/0/1&quot;&gt;Alexander Peysakhovich&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.10095">
<title>Research on Artificial Intelligence Ethics Based on the Evolution of Population Knowledge Base. (arXiv:1806.10095v1 [cs.OH])</title>
<link>http://arxiv.org/abs/1806.10095</link>
<description rdf:parseType="Literal">&lt;p&gt;The unclear development direction of human society is a deep reason for that
it is difficult to form a uniform ethical standard for human society and
artificial intelligence. Since the 21st century, the latest advances in the
Internet, brain science and artificial intelligence have brought new
inspiration to the research on the development direction of human society.
Through the study of the Internet brain model, AI IQ evaluation, and the
evolution of the brain, this paper proposes that the evolution of population
knowledge base is the key for judging the development direction of human
society, thereby discussing the standards and norms for the construction of
artificial intelligence ethics.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1&quot;&gt;Feng Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1&quot;&gt;Yong Shi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.03471">
<title>Certified Robustness to Adversarial Examples with Differential Privacy. (arXiv:1802.03471v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1802.03471</link>
<description rdf:parseType="Literal">&lt;p&gt;Adversarial examples that fool machine learning models, particularly deep
neural networks, have been a topic of intense research interest, with attacks
and defenses being developed in a tight back-and-forth. Most past defenses are
best-effort and have been shown to be vulnerable to sophisticated attacks.
Recently a set of certified defenses have been introduced, which provide
guarantees of robustness to norm-bounded attacks, but they either do not scale
to large datasets or are limited in the types of models they can support. This
paper presents the first certified defense that both scales to large networks
and datasets (such as Google&apos;s Inception network for ImageNet) and applies
broadly to arbitrary model types. Our defense is based on a novel connection
between robustness against adversarial examples and differential privacy, a
cryptographically-inspired technique, that provides a rigorous, generic, and
flexible foundation for defense.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lecuyer_M/0/1/0/all/0/1&quot;&gt;Mathias Lecuyer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Atlidakis_V/0/1/0/all/0/1&quot;&gt;Vaggelis Atlidakis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Geambasu_R/0/1/0/all/0/1&quot;&gt;Roxana Geambasu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hsu_D/0/1/0/all/0/1&quot;&gt;Daniel Hsu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Jana_S/0/1/0/all/0/1&quot;&gt;Suman Jana&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02091">
<title>Can Machines Design? An Artificial General Intelligence Approach. (arXiv:1806.02091v4 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1806.02091</link>
<description rdf:parseType="Literal">&lt;p&gt;Can machines design? Can they come up with creative solutions to problems and
build tools and artifacts across a wide range of domains? Recent advances in
the field of computational creativity and formal Artificial General
Intelligence (AGI) provide frameworks for machines with the general ability to
design. In this paper we propose to integrate a formal computational creativity
framework into the G\&quot;odel machine framework. We call the resulting framework
design G\&quot;odel machine. Such a machine could solve a variety of design problems
by generating novel concepts. In addition, it could change the way these
concepts are generated by modifying itself. The design G\&quot;odel machine is able
to improve its initial design program, once it has proven that a modification
would increase its return on the utility function. Finally, we sketch out a
specific version of the design G\&quot;odel machine which specifically addresses the
design of complex software and hardware systems. Future work aims at the
development of a more formal version of the design G\&quot;odel machine and a proof
of concept implementation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hein_A/0/1/0/all/0/1&quot;&gt;Andreas Makoto Hein&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Condat_H/0/1/0/all/0/1&quot;&gt;H&amp;#xe9;l&amp;#xe8;ne Condat&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.03536">
<title>Representation Learning on Graphs with Jumping Knowledge Networks. (arXiv:1806.03536v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1806.03536</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent deep learning approaches for representation learning on graphs follow
a neighborhood aggregation procedure. We analyze some important properties of
these models, and propose a strategy to overcome those. In particular, the
range of &quot;neighboring&quot; nodes that a node&apos;s representation draws from strongly
depends on the graph structure, analogous to the spread of a random walk. To
adapt to local neighborhood properties and tasks, we explore an architecture --
jumping knowledge (JK) networks -- that flexibly leverages, for each node,
different neighborhood ranges to enable better structure-aware representation.
In a number of experiments on social, bioinformatics and citation networks, we
demonstrate that our model achieves state-of-the-art performance. Furthermore,
combining the JK framework with models like Graph Convolutional Networks,
GraphSAGE and Graph Attention Networks consistently improves those models&apos;
performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_K/0/1/0/all/0/1&quot;&gt;Keyulu Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1&quot;&gt;Chengtao Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1&quot;&gt;Yonglong Tian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sonobe_T/0/1/0/all/0/1&quot;&gt;Tomohiro Sonobe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kawarabayashi_K/0/1/0/all/0/1&quot;&gt;Ken-ichi Kawarabayashi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jegelka_S/0/1/0/all/0/1&quot;&gt;Stefanie Jegelka&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.07377">
<title>Transfer Learning for Related Reinforcement Learning Tasks via Image-to-Image Translation. (arXiv:1806.07377v3 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1806.07377</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep Reinforcement Learning has managed to achieve state-of-the-art results
in learning control policies directly from raw pixels. However, despite its
remarkable success, it fails to generalize, a fundamental component required in
a stable Artificial Intelligence system. Using the Atari game Breakout, we
demonstrate the difficulty of a trained agent in adjusting to simple
modifications in the raw image, ones that a human could adapt to trivially. In
transfer learning, the goal is to use the knowledge gained from the source task
to make the training of the target task faster and better. We show that using
various forms of fine-tuning, a common method for transfer learning, is not
effective for adapting to such small visual changes. In fact, it is often
easier to re-train the agent from scratch than to fine-tune a trained agent. We
suggest that in some cases transfer learning can be improved by adding a
dedicated component whose goal is to learn to visually map between the known
domain and the new one. Concretely, we use Generative Adversarial Networks
(GANs) to create a mapping function to translate images in the target task to
corresponding images in the source task, allowing us to transform between the
different tasks. We show that learning this mapping is substantially more
efficient than re-training. A visualization of a trained agent playing in a
modified condition, with and without the GAN transfer, can be seen in
https://youtu.be/e2TwjduPT8g .
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gamrian_S/0/1/0/all/0/1&quot;&gt;Shani Gamrian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goldberg_Y/0/1/0/all/0/1&quot;&gt;Yoav Goldberg&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1702.06253">
<title>Player Skill Decomposition in Multiplayer Online Battle Arenas. (arXiv:1702.06253v1 [cs.SI] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1702.06253</link>
<description rdf:parseType="Literal">&lt;p&gt;Successful analysis of player skills in video games has important impacts on
the process of enhancing player experience without undermining their continuous
skill development. Moreover, player skill analysis becomes more intriguing in
team-based video games because such form of study can help discover useful
factors in effective team formation. In this paper, we consider the problem of
skill decomposition in MOBA (MultiPlayer Online Battle Arena) games, with the
goal to understand what player skill factors are essential for the outcome of a
game match. To understand the construct of MOBA player skills, we utilize
various skill-based predictive models to decompose player skills into
interpretative parts, the impact of which are assessed in statistical terms. We
apply this analysis approach on two widely known MOBAs, namely League of
Legends (LoL) and Defense of the Ancients 2 (DOTA2). The finding is that base
skills of in-game avatars, base skills of players, and players&apos;
champion-specific skills are three prominent skill components influencing LoL&apos;s
match outcomes, while those of DOTA2 are mainly impacted by in-game avatars&apos;
base skills but not much by the other two.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1&quot;&gt;Zhengxing Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1&quot;&gt;Yizhou Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+El_nasr_M/0/1/0/all/0/1&quot;&gt;Magy Seif El-nasr&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1&quot;&gt;Truong-Huy D. Nguyen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1702.06820">
<title>EOMM: An Engagement Optimized Matchmaking Framework. (arXiv:1702.06820v1 [cs.SI] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1702.06820</link>
<description rdf:parseType="Literal">&lt;p&gt;Matchmaking connects multiple players to participate in online
player-versus-player games. Current matchmaking systems depend on a single core
strategy: create fair games at all times. These systems pair similarly skilled
players on the assumption that a fair game is best player experience. We will
demonstrate, however, that this intuitive assumption sometimes fails and that
matchmaking based on fairness is not optimal for engagement.
&lt;/p&gt;
&lt;p&gt;In this paper, we propose an Engagement Optimized Matchmaking (EOMM)
framework that maximizes overall player engagement. We prove that equal-skill
based matchmaking is a special case of EOMM on a highly simplified assumption
that rarely holds in reality. Our simulation on real data from a popular game
made by Electronic Arts, Inc. (EA) supports our theoretical results, showing
significant improvement in enhancing player engagement compared to existing
matchmaking methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1&quot;&gt;Zhengxing Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xue_S/0/1/0/all/0/1&quot;&gt;Su Xue&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kolen_J/0/1/0/all/0/1&quot;&gt;John Kolen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aghdaie_N/0/1/0/all/0/1&quot;&gt;Navid Aghdaie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zaman_K/0/1/0/all/0/1&quot;&gt;Kazi A. Zaman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1&quot;&gt;Yizhou Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+El_Nasr_M/0/1/0/all/0/1&quot;&gt;Magy Seif El-Nasr&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.10402">
<title>Modeling Game Avatar Synergy and Opposition through Embedding in Multiplayer Online Battle Arena Games. (arXiv:1803.10402v1 [cs.SI] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1803.10402</link>
<description rdf:parseType="Literal">&lt;p&gt;Multiplayer Online Battle Arena (MOBA) games have received increasing
worldwide popularity recently. In such games, players compete in teams against
each other by controlling selected game avatars, each of which is designed with
different strengths and weaknesses. Intuitively, putting together game avatars
that complement each other (synergy) and suppress those of opponents
(opposition) would result in a stronger team. In-depth understanding of synergy
and opposition relationships among game avatars benefits player in making
decisions in game avatar drafting and gaining better prediction of match
events. However, due to intricate design and complex interactions between game
avatars, thorough understanding of their relationships is not a trivial task.
&lt;/p&gt;
&lt;p&gt;In this paper, we propose a latent variable model, namely Game Avatar
Embedding (GAE), to learn avatars&apos; numerical representations which encode
synergy and opposition relationships between pairs of avatars. The merits of
our model are twofold: (1) the captured synergy and opposition relationships
are sensible to experienced human players&apos; perception; (2) the learned
numerical representations of game avatars allow many important downstream
tasks, such as similar avatar search, match outcome prediction, and avatar pick
recommender. To our best knowledge, no previous model is able to simultaneously
support both features. Our quantitative and qualitative evaluations on real
match data from three commercial MOBA games illustrate the benefits of our
model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1&quot;&gt;Zhengxing Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1&quot;&gt;Yuyu Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1&quot;&gt;Truong-Huy D. Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1&quot;&gt;Yizhou Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+El_Nasr_M/0/1/0/all/0/1&quot;&gt;Magy Seif El-Nasr&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.09730">
<title>Analysis of Invariance and Robustness via Invertibility of ReLU-Networks. (arXiv:1806.09730v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.09730</link>
<description rdf:parseType="Literal">&lt;p&gt;Studying the invertibility of deep neural networks (DNNs) provides a
principled approach to better understand the behavior of these powerful models.
Despite being a promising diagnostic tool, a consistent theory on their
invertibility is still lacking. We derive a theoretically motivated approach to
explore the preimages of ReLU-layers and mechanisms affecting the stability of
the inverse. Using the developed theory, we numerically show how this approach
uncovers characteristic properties of the network.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Behrmann_J/0/1/0/all/0/1&quot;&gt;Jens Behrmann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dittmer_S/0/1/0/all/0/1&quot;&gt;S&amp;#xf6;ren Dittmer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fernsel_P/0/1/0/all/0/1&quot;&gt;Pascal Fernsel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Maass_P/0/1/0/all/0/1&quot;&gt;Peter Maa&amp;#xdf;&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.09737">
<title>The NIPS&apos;17 Competition: A Multi-View Ensemble Classification Model for Clinically Actionable Genetic Mutations. (arXiv:1806.09737v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.09737</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents details of our winning solutions to the task IV of NIPS
2017 Competition Track entitled Classifying Clinically Actionable Genetic
Mutations. The machine learning task aims to classify genetic mutations based
on text evidence from clinical literature with promising performance. We
develop a novel multi-view machine learning framework with ensemble
classification models to solve the problem. During the Challenge, feature
combinations derived from three views including document view, entity text
view, and entity name view, which complements each other, are comprehensively
explored. As the final solution, we submitted an ensemble of nine basic
gradient boosting models which shows the best performance in the evaluation.
The approach scores 0.5506 and 0.6694 in terms of logarithmic loss on a fixed
split in stage-1 testing phase and 5-fold cross validation respectively, which
also makes us ranked as a top-1 team out of more than 1,300 solutions in NIPS
2017 Competition Track IV.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xi Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1&quot;&gt;Dandi Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1&quot;&gt;Yongjun Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Che_C/0/1/0/all/0/1&quot;&gt;Chao Che&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Su_C/0/1/0/all/0/1&quot;&gt;Chang Su&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_S/0/1/0/all/0/1&quot;&gt;Sendong Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Min_X/0/1/0/all/0/1&quot;&gt;Xu Min&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1&quot;&gt;Fei Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.09783">
<title>Gradient Acceleration in Activation Functions. (arXiv:1806.09783v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.09783</link>
<description rdf:parseType="Literal">&lt;p&gt;Dropout has been one of standard approaches to train deep neural networks,
and it is known to regularize large models to avoid overfitting. The effect of
dropout has been explained by avoiding co-adaptation. In this paper, however,
we propose a new explanation of why dropout works and propose a new technique
to design better activation functions. First, we show that dropout is an
optimization technique to push the input towards the saturation area of
nonlinear activation function by accelerating gradient information flowing even
in the saturation area in backpropagation. Based on this explanation, we
propose a new technique for activation functions, gradient acceleration in
activation function (GAAF), that accelerates gradients to flow even in the
saturation area. Then, input to the activation function can climb onto the
saturation area which makes the network more robust because the model converges
on a flat region. Experiment results support our explanation of dropout and
confirm that the proposed GAAF technique improves performances with expected
properties.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hahn_S/0/1/0/all/0/1&quot;&gt;Sangchul Hahn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Choi_H/0/1/0/all/0/1&quot;&gt;Heeyoul Choi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.09856">
<title>Dropout-based Active Learning for Regression. (arXiv:1806.09856v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.09856</link>
<description rdf:parseType="Literal">&lt;p&gt;Active learning is relevant and challenging for high-dimensional regression
models when the annotation of the samples is expensive. Yet most of the
existing sampling methods cannot be applied to large-scale problems, consuming
too much time for data processing. In this paper, we propose a fast active
learning algorithm for regression, tailored for neural network models. It is
based on uncertainty estimation from stochastic dropout output of the network.
Experiments on both synthetic and real-world datasets show comparable or better
performance (depending on the accuracy metric) as compared to the baselines.
This approach can be generalized to other deep learning architectures. It can
be used to systematically improve a machine-learning model as it offers a
computationally efficient way of sampling additional data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tsymbalov_E/0/1/0/all/0/1&quot;&gt;Evgenii Tsymbalov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Panov_M/0/1/0/all/0/1&quot;&gt;Maxim Panov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shapeev_A/0/1/0/all/0/1&quot;&gt;Alexander Shapeev&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.09919">
<title>Tangent-Space Regularization for Neural-Network Models of Dynamical Systems. (arXiv:1806.09919v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.09919</link>
<description rdf:parseType="Literal">&lt;p&gt;This work introduces the concept of tangent space regularization for
neural-network models of dynamical systems. The tangent space to the dynamics
function of many physical systems of interest in control applications exhibits
useful properties, e.g., smoothness, motivating regularization of the model
Jacobian along system trajectories using assumptions on the tangent space of
the dynamics. Without assumptions, large amounts of training data are required
for a neural network to learn the full non-linear dynamics without overfitting.
We compare different network architectures on one-step prediction and
simulation performance and investigate the propensity of different
architectures to learn models with correct input-output Jacobian. Furthermore,
the influence of $L_2$ weight regularization on the learned Jacobian eigenvalue
spectrum, and hence system stability, is investigated.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Carlson_F/0/1/0/all/0/1&quot;&gt;Fredrik Bagge Carlson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Johansson_R/0/1/0/all/0/1&quot;&gt;Rolf Johansson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Robertsson_A/0/1/0/all/0/1&quot;&gt;Anders Robertsson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.09976">
<title>The decoupled extended Kalman filter for dynamic exponential-family factorization models. (arXiv:1806.09976v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.09976</link>
<description rdf:parseType="Literal">&lt;p&gt;We specialize the decoupled extended Kalman filter (DEKF) for online
parameter learning in factorization models, including factorization machines,
matrix and tensor factorization, and illustrate the effectiveness of the
approach through simulations. Learning model parameters through the DEKF makes
factorization models more broadly useful by allowing for more flexible
observations through the entire exponential family, modeling parameter drift,
and producing parameter uncertainty estimates that can enable explore/exploit
and other applications. We use a more general dynamics of the parameters than
the standard DEKF, allowing parameter drift while encouraging reasonable
values. We also present an alternate derivation of the regular extended Kalman
filter and DEKF that connects these methods to natural gradient methods, and
suggests a similarly decoupled version of the iterated extended Kalman filter.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gomez_Uribe_C/0/1/0/all/0/1&quot;&gt;Carlos Alberto Gomez-Uribe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Karrer_B/0/1/0/all/0/1&quot;&gt;Brian Karrer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.09981">
<title>Dynamic Spectrum Matching with One-shot Learning. (arXiv:1806.09981v1 [eess.SP])</title>
<link>http://arxiv.org/abs/1806.09981</link>
<description rdf:parseType="Literal">&lt;p&gt;Convolutional neural networks (CNN) have been shown to provide a good
solution for classification problems that utilize data obtained from
vibrational spectroscopy. Moreover, CNNs are capable of identification from
noisy spectra without the need for additional preprocessing. However, their
application in practical spectroscopy is limited due to two shortcomings. The
effectiveness of the classification using CNNs drops rapidly when only a small
number of spectra per substance are available for training (which is a typical
situation in real applications). Additionally, to accommodate new, previously
unseen substance classes, the network must be retrained which is
computationally intensive. Here we address these issues by reformulating a
multi-class classification problem with a large number of classes, but a small
number of samples per class, to a binary classification problem with sufficient
data available for representation learning. Namely, we define the learning task
as identifying pairs of inputs as belonging to the same or different classes.
We achieve this using a Siamese convolutional neural network. A novel sampling
strategy is proposed to address the imbalance problem in training the Siamese
Network. The trained network can effectively classify samples of unseen
substance classes using just a single reference sample (termed as one-shot
learning in the machine learning community). Our results demonstrate better
accuracy than other practical systems to date, while allowing effortless
updates of the system&apos;s database with novel substance classes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Jinchao Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Gibson_S/0/1/0/all/0/1&quot;&gt;Stuart J. Gibson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Mills_J/0/1/0/all/0/1&quot;&gt;James Mills&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Osadchy_M/0/1/0/all/0/1&quot;&gt;Margarita Osadchy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.10064">
<title>Adaptive Blending Units: Trainable Activation Functions for Deep Neural Networks. (arXiv:1806.10064v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.10064</link>
<description rdf:parseType="Literal">&lt;p&gt;The most widely used activation functions in current deep feed-forward neural
networks are rectified linear units (ReLU), and many alternatives have been
successfully applied, as well. However, none of the alternatives have managed
to consistently outperform the rest and there is no unified theory connecting
properties of the task and network with properties of activation functions for
most efficient training. A possible solution is to have the network learn its
preferred activation functions. In this work, we introduce Adaptive Blending
Units (ABUs), a trainable linear combination of a set of activation functions.
Since ABUs learn the shape, as well as the overall scaling of the activation
function, we also analyze the effects of adaptive scaling in common activation
functions. We experimentally demonstrate advantages of both adaptive scaling
and ABUs over common activation functions across a set of systematically varied
network specifications. We further show that adaptive scaling works by
mitigating covariate shifts during training, and that the observed advantages
in performance of ABUs likewise rely largely on the activation function&apos;s
ability to adapt over the course of training.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sutfeld_L/0/1/0/all/0/1&quot;&gt;Leon Ren&amp;#xe9; S&amp;#xfc;tfeld&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brieger_F/0/1/0/all/0/1&quot;&gt;Flemming Brieger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Finger_H/0/1/0/all/0/1&quot;&gt;Holger Finger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fullhase_S/0/1/0/all/0/1&quot;&gt;Sonja F&amp;#xfc;llhase&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pipa_G/0/1/0/all/0/1&quot;&gt;Gordon Pipa&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.10077">
<title>Random Shuffling Beats SGD after Finite Epochs. (arXiv:1806.10077v1 [math.OC])</title>
<link>http://arxiv.org/abs/1806.10077</link>
<description rdf:parseType="Literal">&lt;p&gt;A long-standing problem in the theory of stochastic gradient descent (SGD) is
to prove that its without-replacement version RandomShuffle converges faster
than the usual with-replacement version. We present the first (to our
knowledge) non-asymptotic solution to this problem, which shows that after a
&quot;reasonable&quot; number of epochs RandomShuffle indeed converges faster than SGD.
Specifically, we prove that under strong convexity and second-order smoothness,
the sequence generated by RandomShuffle converges to the optimal solution at
the rate O(1/T^2 + n^3/T^3), where n is the number of components in the
objective, and T is the total number of iterations. This result shows that
after a reasonable number of epochs RandomShuffle is strictly better than SGD
(which converges as O(1/T)). The key step toward showing this better dependence
on T is the introduction of n into the bound; and as our analysis will show, in
general a dependence on n is unavoidable without further changes to the
algorithm. We show that for sparse data RandomShuffle has the rate O(1/T^2),
again strictly better than SGD. Furthermore, we discuss extensions to nonconvex
gradient dominated functions, as well as non-strongly convex settings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+HaoChen_J/0/1/0/all/0/1&quot;&gt;Jeffery Z. HaoChen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Sra_S/0/1/0/all/0/1&quot;&gt;Suvrit Sra&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1601.01345">
<title>An Oracle Inequality for Quasi-Bayesian Non-Negative Matrix Factorization. (arXiv:1601.01345v4 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1601.01345</link>
<description rdf:parseType="Literal">&lt;p&gt;The aim of this paper is to provide some theoretical understanding of
quasi-Bayesian aggregation methods non-negative matrix factorization. We derive
an oracle inequality for an aggregated estimator. This result holds for a very
general class of prior distributions and shows how the prior affects the rate
of convergence.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Alquier_P/0/1/0/all/0/1&quot;&gt;Pierre Alquier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Guedj_B/0/1/0/all/0/1&quot;&gt;Benjamin Guedj&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1606.03802">
<title>Specialized Support Vector Machines for open-set recognition. (arXiv:1606.03802v5 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1606.03802</link>
<description rdf:parseType="Literal">&lt;p&gt;Often, when dealing with real-world recognition problems, we do not need, and
often cannot have, knowledge of the entire set of possible classes that might
appear during operational testing. Moreover, sometimes some of these classes
may be ill-sampled, not sampled at all or undefined. In such cases, we need to
think of robust classification methods able to deal with the &quot;unknown&quot; and
properly reject samples belonging to classes never seen during training.
Notwithstanding, almost all existing classifiers to date were mostly developed
for the closed-set scenario, i.e., the classification setup in which it is
assumed that all test samples belong to one of the classes with which the
classifier was trained. In the open-set scenario, however, a test sample can
belong to none of the known classes and the classifier must properly reject it
by classifying it as unknown. In this work, we extend upon the well-known
Support Vector Machines (SVM) classifier and introduce the Specialized Support
Vector Machines (SSVM), which is suitable for recognition in open-set setups.
SSVM balances the empirical risk and the risk of the unknown and ensures that
the region of the feature space in which a test sample would be classified as
known (one of the known classes) is always bounded, ensuring a finite risk of
the unknown. The same cannot be guaranteed by the traditional SVM formulation,
even when using the Radial Basis Function (RBF) kernel. In this work, we also
highlight the properties of the SVM classifier related to the open-set
scenario, and provide necessary and sufficient conditions for an RBF SVM to
have bounded open-space risk. An extensive set of experiments compares the
proposed method with existing solutions in the literature for open-set
recognition and the reported results show its effectiveness.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Junior_P/0/1/0/all/0/1&quot;&gt;Pedro Ribeiro Mendes J&amp;#xfa;nior&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Boult_T/0/1/0/all/0/1&quot;&gt;Terrance E. Boult&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wainer_J/0/1/0/all/0/1&quot;&gt;Jacques Wainer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rocha_A/0/1/0/all/0/1&quot;&gt;Anderson Rocha&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.09805">
<title>Improving Negative Sampling for Word Representation using Self-embedded Features. (arXiv:1710.09805v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1710.09805</link>
<description rdf:parseType="Literal">&lt;p&gt;Although the word-popularity based negative sampler has shown superb
performance in the skip-gram model, the theoretical motivation behind
oversampling popular (non-observed) words as negative samples is still not well
understood. In this paper, we start from an investigation of the gradient
vanishing issue in the skipgram model without a proper negative sampler. By
performing an insightful analysis from the stochastic gradient descent (SGD)
learning perspective, we demonstrate that, both theoretically and intuitively,
negative samples with larger inner product scores are more informative than
those with lower scores for the SGD learner in terms of both convergence rate
and accuracy. Understanding this, we propose an alternative sampling algorithm
that dynamically selects informative negative samples during each SGD update.
More importantly, the proposed sampler accounts for multi-dimensional
self-embedded features during the sampling process, which essentially makes it
more effective than the original popularity-based (one-dimensional) sampler.
Empirical experiments further verify our observations, and show that our
fine-grained samplers gain significant improvement over the existing ones
without increasing computational complexity.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1&quot;&gt;Long Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yuan_F/0/1/0/all/0/1&quot;&gt;Fajie Yuan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jose_J/0/1/0/all/0/1&quot;&gt;Joemon M. Jose&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1&quot;&gt;Weinan Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.09111">
<title>Entanglement-guided architectures of machine learning by quantum tensor network. (arXiv:1803.09111v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1803.09111</link>
<description rdf:parseType="Literal">&lt;p&gt;It is a fundamental, but still elusive question whether the schemes based on
quantum mechanics, in particular on quantum entanglement, can be used for
classical information processing and machine learning. Even partial answer to
this question would bring important insights to both fields of machine learning
and quantum mechanics. In this work, we implement simple numerical experiments,
related to pattern/images classification, in which we represent the classifiers
by many-qubit quantum states written in the matrix product states (MPS).
Classical machine learning algorithm is applied to these quantum states to
learn the classical data. We explicitly show how quantum entanglement (i.e.,
single-site and bipartite entanglement) can emerge in such represented images.
Entanglement characterizes here the importance of data, and such information
are practically used to guide the architecture of MPS, and improve the
efficiency. The number of needed qubits can be reduced to less than 1/10 of the
original number, which is within the access of the state-of-the-art quantum
computers. We expect such numerical experiments could open new paths in
charactering classical machine learning algorithms, and at the same time shed
lights on the generic quantum simulations/computations of machine learning
tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yuhan Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xiao Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lewenstein_M/0/1/0/all/0/1&quot;&gt;Maciej Lewenstein&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ran_S/0/1/0/all/0/1&quot;&gt;Shi-Ju Ran&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.08647">
<title>Matrix Completion and Performance Guarantees for Single Individual Haplotyping. (arXiv:1806.08647v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1806.08647</link>
<description rdf:parseType="Literal">&lt;p&gt;Single individual haplotyping is an NP-hard problem that emerges when
attempting to reconstruct an organism&apos;s inherited genetic variations using data
typically generated by high-throughput DNA sequencing platforms. Genomes of
diploid organisms, including humans, are organized into homologous pairs of
chromosomes that differ from each other in a relatively small number of variant
positions. Haplotypes are ordered sequences of the nucleotides in the variant
positions of the chromosomes in a homologous pair; for diploids, haplotypes
associated with a pair of chromosomes may be conveniently represented by means
of complementary binary sequences. In this paper, we consider a binary matrix
factorization formulation of the single individual haplotyping problem and
efficiently solve it by means of alternating minimization. We analyze the
convergence properties of the alternating minimization algorithm and establish
theoretical bounds for the achievable haplotype reconstruction error. The
proposed technique is shown to outperform existing methods when applied to
synthetic as well as real-world Fosmid-based HapMap NA12878 datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barik_S/0/1/0/all/0/1&quot;&gt;Somsubhra Barik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vikalo_H/0/1/0/all/0/1&quot;&gt;Haris Vikalo&lt;/a&gt;</dc:creator>
</item></rdf:RDF>