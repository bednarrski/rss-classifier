<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Good papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Good Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-02-15T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05405"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05415"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05594"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05642"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05668"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.11622"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05312"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05438"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1706.03471"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.06451"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.01694"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.04520"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05319"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05335"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05351"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05394"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05411"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05550"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05666"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05694"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1705.08415"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.06853"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04784"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1802.05405">
<title>Putting a bug in ML: The moth olfactory network learns to read MNIST. (arXiv:1802.05405v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.05405</link>
<description rdf:parseType="Literal">&lt;p&gt;We seek to (i) characterize the learning architectures exploited in
biological neural networks for training on very few samples, and (ii) port
these algorithmic structures to a machine learning context. The Moth Olfactory
Network is among the simplest biological neural systems that can learn, and its
architecture includes key structural elements widespread in biological neural
nets, such as cascaded networks, competitive inhibition, high intrinsic noise,
sparsity, reward mechanisms, and Hebbian plasticity. The interactions of these
structural elements play a critical enabling role in rapid learning.
&lt;/p&gt;
&lt;p&gt;We assign a computational model of the Moth Olfactory Network the task of
learning to read the MNIST digits. This model, MothNet, is closely aligned with
the moth&apos;s known biophysics and with in vivo electrode data, including data
collected from moths learning new odors. We show that MothNet successfully
learns to read given very few training samples (1 to 20 samples per class). In
this few-samples regime, it substantially outperforms standard machine learning
methods such as nearest-neighbors, support-vector machines, and convolutional
neural networks (CNNs). The MothNet architecture illustrates how our proposed
algorithmic structures, derived from biological brains, can be used to build
alternative deep neural nets (DNNs) that may potentially avoid some of DNNs
current learning rate limitations. This novel, bio-inspired neural network
architecture offers a valuable complementary approach to DNN design.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Delahunt_C/0/1/0/all/0/1&quot;&gt;Charles B. Delahunt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kutz_J/0/1/0/all/0/1&quot;&gt;J. Nathan Kutz&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05415">
<title>Teaching Machines to Code: Neural Markup Generation with Visual Attention. (arXiv:1802.05415v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.05415</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a deep recurrent neural network model with soft visual attention
that learns to generate LaTeX markup of real-world math formulas given their
images. Applying neural sequence generation techniques that have been very
successful in the fields of machine translation and image/handwriting/speech
captioning, recognition, transcription and synthesis, we construct an
image-to-markup model that learns to produce syntactically and semantically
correct LaTeX markup code of over 150 words long and achieves a BLEU score of
89%; the best reported so far for the Im2Latex problem. We also visually
demonstrate that the model learns to scan the image left-right / up-down much
as a human would read it.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1&quot;&gt;Sumeet S. Singh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05594">
<title>Prioritized Sweeping Neural DynaQ with Multiple Predecessors, and Hippocampal Replays. (arXiv:1802.05594v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.05594</link>
<description rdf:parseType="Literal">&lt;p&gt;During sleep and awake rest, the hippocampus replays sequences of place cells
that have been activated during prior experiences. These have been interpreted
as a memory consolidation process, but recent results suggest a possible
interpretation in terms of reinforcement learning. The Dyna reinforcement
learning algorithms use off-line replays to improve learning. Under limited
replay budget, a prioritized sweeping approach, which requires a model of the
transitions to the predecessors, can be used to improve performance. We
investigate whether such algorithms can explain the experimentally observed
replays. We propose a neural network version of prioritized sweeping
Q-learning, for which we developed a growing multiple expert algorithm, able to
cope with multiple predecessors. The resulting architecture is able to improve
the learning of simulated agents confronted to a navigation task. We predict
that, in animals, learning the world model should occur during rest periods,
and that the corresponding replays should be shuffled.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aubin_L/0/1/0/all/0/1&quot;&gt;Lise Aubin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khamassi_M/0/1/0/all/0/1&quot;&gt;Mehdi Khamassi&lt;/a&gt; (ISIR), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Girard_B/0/1/0/all/0/1&quot;&gt;Beno&amp;#xee;t Girard&lt;/a&gt; (ISIR)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05642">
<title>The Mechanics of n-Player Differentiable Games. (arXiv:1802.05642v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.05642</link>
<description rdf:parseType="Literal">&lt;p&gt;The cornerstone underpinning deep learning is the guarantee that gradient
descent on an objective converges to local minima. Unfortunately, this
guarantee fails in settings, such as generative adversarial nets, where there
are multiple interacting losses. The behavior of gradient-based methods in
games is not well understood -- and is becoming increasingly important as
adversarial and multi-objective architectures proliferate. In this paper, we
develop new techniques to understand and control the dynamics in general games.
The key result is to decompose the second-order dynamics into two components.
The first is related to potential games, which reduce to gradient descent on an
implicit function; the second relates to Hamiltonian games, a new class of
games that obey a conservation law, akin to conservation laws in classical
mechanical systems. The decomposition motivates Symplectic Gradient Adjustment
(SGA), a new algorithm for finding stable fixed points in general games. Basic
experiments show SGA is competitive with recently proposed algorithms for
finding local Nash equilibria in GANs -- whilst at the same time being
applicable to -- and having guarantees in -- much more general games.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Balduzzi_D/0/1/0/all/0/1&quot;&gt;David Balduzzi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Racaniere_S/0/1/0/all/0/1&quot;&gt;Sebastien Racaniere&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Martens_J/0/1/0/all/0/1&quot;&gt;James Martens&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Foerster_J/0/1/0/all/0/1&quot;&gt;Jakob Foerster&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tuyls_K/0/1/0/all/0/1&quot;&gt;Karl Tuyls&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Graepel_T/0/1/0/all/0/1&quot;&gt;Thore Graepel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05668">
<title>Model compression via distillation and quantization. (arXiv:1802.05668v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1802.05668</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep neural networks (DNNs) continue to make significant advances, solving
tasks from image classification to translation or reinforcement learning. One
aspect of the field receiving considerable attention is efficiently executing
deep models in resource-constrained environments, such as mobile or embedded
devices. This paper focuses on this problem, and proposes two new compression
methods, which jointly leverage weight quantization and distillation of larger
teacher networks into smaller student networks. The first method we propose is
called quantized distillation and leverages distillation during the training
process, by incorporating distillation loss, expressed with respect to the
teacher, into the training of a student network whose weights are quantized to
a limited set of levels. The second method, differentiable quantization,
optimizes the location of quantization points through stochastic gradient
descent, to better fit the behavior of the teacher model. We validate both
methods through experiments on convolutional and recurrent architectures. We
show that quantized shallow students can reach similar accuracy levels to
full-precision teacher models, while providing order of magnitude compression,
and inference speedup that is linear in the depth reduction. In sum, our
results enable DNNs for resource-constrained environments to leverage
architecture and accuracy advances developed on more powerful devices.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Polino_A/0/1/0/all/0/1&quot;&gt;Antonio Polino&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pascanu_R/0/1/0/all/0/1&quot;&gt;Razvan Pascanu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alistarh_D/0/1/0/all/0/1&quot;&gt;Dan Alistarh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.11622">
<title>Meta-Learning and Universality: Deep Representations and Gradient Descent can Approximate any Learning Algorithm. (arXiv:1710.11622v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1710.11622</link>
<description rdf:parseType="Literal">&lt;p&gt;Learning to learn is a powerful paradigm for enabling models to learn from
data more effectively and efficiently. A popular approach to meta-learning is
to train a recurrent model to read in a training dataset as input and output
the parameters of a learned model, or output predictions for new test inputs.
Alternatively, a more recent approach to meta-learning aims to acquire deep
representations that can be effectively fine-tuned, via standard gradient
descent, to new tasks. In this paper, we consider the meta-learning problem
from the perspective of universality, formalizing the notion of learning
algorithm approximation and comparing the expressive power of the
aforementioned recurrent models to the more recent approaches that embed
gradient descent into the meta-learner. In particular, we seek to answer the
following question: does deep representation combined with standard gradient
descent have sufficient capacity to approximate any learning algorithm? We find
that this is indeed true, and further find, in our experiments, that
gradient-based meta-learning consistently leads to learning strategies that
generalize more widely compared to those represented by recurrent models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Finn_C/0/1/0/all/0/1&quot;&gt;Chelsea Finn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1&quot;&gt;Sergey Levine&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05312">
<title>Learning Deep Disentangled Embeddings with the F-Statistic Loss. (arXiv:1802.05312v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.05312</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep-embedding methods aim to discover representations of a domain that make
explicit the domain&apos;s class structure. Disentangling methods aim to make
explicit compositional or factorial structure. We combine these two active but
independent lines of research and propose a new paradigm for discovering
disentangled representations of class structure; these representations reveal
the underlying factors that jointly determine class. We propose and evaluate a
novel loss function based on the $F$ statistic, which describes the separation
of two or more distributions. By ensuring that distinct classes are well
separated on a subset of embedding dimensions, we obtain embeddings that are
useful for few-shot learning. By not requiring separation on all dimensions, we
encourage the discovery of disentangled representations. Our embedding
procedure matches or beats state-of-the-art procedures on deep embeddings, as
evaluated by performance on recall@$k$ and few-shot learning tasks. To evaluate
alternative approaches on disentangling, we formalize two key properties of a
disentangled representation: modularity and explicitness. By these criteria,
our procedure yields disentangled representations, whereas traditional
procedures fail. The goal of our work is to obtain more interpretable,
manipulable, and generalizable deep representations of concepts and categories.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ridgeway_K/0/1/0/all/0/1&quot;&gt;Karl Ridgeway&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mozer_M/0/1/0/all/0/1&quot;&gt;Michael C. Mozer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05438">
<title>Mean Field Multi-Agent Reinforcement Learning. (arXiv:1802.05438v1 [cs.MA])</title>
<link>http://arxiv.org/abs/1802.05438</link>
<description rdf:parseType="Literal">&lt;p&gt;Existing multi-agent reinforcement learning methods are limited typically to
a small number of agents. When the agent number increases largely, the learning
becomes intractable due to the curse of the dimensionality and the exponential
growth of user interactions. In this paper, we present Mean Field Reinforcement
Learning where the interactions within the population of agents are
approximated by those between a single agent and the average effect from the
overall population or neighboring agents; the interplay between the two
entities is mutually reinforced: the learning of the individual agent&apos;s optimal
policy depends on the dynamics of the population, while the dynamics of the
population change according to the collective patterns of the individual
policies. We develop practical mean field Q-learning and mean field
Actor-Critic algorithms and analyze the convergence of the solution.
Experiments on resource allocation, Ising model estimation, and battle game
tasks verify the learning effectiveness of our mean field approaches in
handling many-agent interactions in population.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1&quot;&gt;Yaodong Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_R/0/1/0/all/0/1&quot;&gt;Rui Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1&quot;&gt;Minne Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1&quot;&gt;Ming Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1&quot;&gt;Weinan Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jun Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1706.03471">
<title>YellowFin and the Art of Momentum Tuning. (arXiv:1706.03471v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1706.03471</link>
<description rdf:parseType="Literal">&lt;p&gt;Hyperparameter tuning is one of the most time-consuming workloads in deep
learning. State-of-the-art optimizers, such as AdaGrad, RMSProp and Adam,
reduce this labor by adaptively tuning an individual learning rate for each
variable. Recently researchers have shown renewed interest in simpler methods
like momentum SGD as they may yield better test metrics. Motivated by this
trend, we ask: can simple adaptive methods based on SGD perform as well or
better? We revisit the momentum SGD algorithm and show that hand-tuning a
single learning rate and momentum makes it competitive with Adam. We then
analyze its robustness to learning rate misspecification and objective
curvature variation. Based on these insights, we design YellowFin, an automatic
tuner for momentum and learning rate in SGD. YellowFin optionally uses a
negative-feedback loop to compensate for the momentum dynamics in asynchronous
settings on the fly. We empirically show that YellowFin can converge in fewer
iterations than Adam on ResNets and LSTMs for image recognition, language
modeling and constituency parsing, with a speedup of up to 3.28x in synchronous
and up to 2.69x in asynchronous settings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Jian Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mitliagkas_I/0/1/0/all/0/1&quot;&gt;Ioannis Mitliagkas&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.06451">
<title>A Bayesian Perspective on Generalization and Stochastic Gradient Descent. (arXiv:1710.06451v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1710.06451</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider two questions at the heart of machine learning; how can we
predict if a minimum will generalize to the test set, and why does stochastic
gradient descent find minima that generalize well? Our work responds to Zhang
et al. (2016), who showed deep neural networks can easily memorize randomly
labeled training data, despite generalizing well on real labels of the same
inputs. We show that the same phenomenon occurs in small linear models. These
observations are explained by the Bayesian evidence, which penalizes sharp
minima but is invariant to model parameterization. We also demonstrate that,
when one holds the learning rate fixed, there is an optimum batch size which
maximizes the test set accuracy. We propose that the noise introduced by small
mini-batches drives the parameters towards minima whose evidence is large.
Interpreting stochastic gradient descent as a stochastic differential equation,
we identify the &quot;noise scale&quot; $g = \epsilon (\frac{N}{B} - 1) \approx \epsilon
N/B$, where $\epsilon$ is the learning rate, $N$ the training set size and $B$
the batch size. Consequently the optimum batch size is proportional to both the
learning rate and the size of the training set, $B_{opt} \propto \epsilon N$.
We verify these predictions empirically.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Smith_S/0/1/0/all/0/1&quot;&gt;Samuel L. Smith&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Le_Q/0/1/0/all/0/1&quot;&gt;Quoc V. Le&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.01694">
<title>Multilingual Speech Recognition With A Single End-To-End Model. (arXiv:1711.01694v2 [eess.AS] UPDATED)</title>
<link>http://arxiv.org/abs/1711.01694</link>
<description rdf:parseType="Literal">&lt;p&gt;Training a conventional automatic speech recognition (ASR) system to support
multiple languages is challenging because the sub-word unit, lexicon and word
inventories are typically language specific. In contrast, sequence-to-sequence
models are well suited for multilingual ASR because they encapsulate an
acoustic, pronunciation and language model jointly in a single network. In this
work we present a single sequence-to-sequence ASR model trained on 9 different
Indian languages, which have very little overlap in their scripts.
Specifically, we take a union of language-specific grapheme sets and train a
grapheme-based sequence-to-sequence model jointly on data from all languages.
We find that this model, which is not explicitly given any information about
language identity, improves recognition performance by 21% relative compared to
analogous sequence-to-sequence models trained on each language individually. By
modifying the model to accept a language identifier as an additional input
feature, we further improve performance by an additional 7% relative and
eliminate confusion between different languages.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Toshniwal_S/0/1/0/all/0/1&quot;&gt;Shubham Toshniwal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Sainath_T/0/1/0/all/0/1&quot;&gt;Tara N. Sainath&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Weiss_R/0/1/0/all/0/1&quot;&gt;Ron J. Weiss&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Li_B/0/1/0/all/0/1&quot;&gt;Bo Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Moreno_P/0/1/0/all/0/1&quot;&gt;Pedro Moreno&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Weinstein_E/0/1/0/all/0/1&quot;&gt;Eugene Weinstein&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Rao_K/0/1/0/all/0/1&quot;&gt;Kanishka Rao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.04520">
<title>Non-Parametric Transformation Networks. (arXiv:1801.04520v3 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1801.04520</link>
<description rdf:parseType="Literal">&lt;p&gt;ConvNets, through their architecture, only enforce invariance to translation.
In this paper, we introduce a new class of deep convolutional architectures
called Non-Parametric Transformation Networks (NPTNs) which can learn
\textit{general} invariances and symmetries directly from data. NPTNs are a
natural generalization of ConvNets and can be optimized directly using gradient
descent. Unlike almost all previous works in deep architectures, they make no
assumption regarding the structure of the invariances present in the data and
in that aspect are flexible and powerful. We also model ConvNets and NPTNs
under a unified framework called Transformation Networks (TN), which yields a
better understanding of the connection between the two. We demonstrate the
efficacy of NPTNs on data such as MNIST and CIFAR10 where they outperform
ConvNet baselines with the same number of parameters. We show it is more
effective than ConvNets in modelling symmetries from data, without the explicit
knowledge of the added arbitrary nuisance transformations. Finally, we replace
ConvNets with NPTNs within Capsule Networks and show that this enables Capsule
Nets to perform even better.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pal_D/0/1/0/all/0/1&quot;&gt;Dipan K. Pal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Savvides_M/0/1/0/all/0/1&quot;&gt;Marios Savvides&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05319">
<title>500+ Times Faster Than Deep Learning (A Case Study Exploring Faster Methods for Text Mining StackOverflow). (arXiv:1802.05319v1 [cs.SE])</title>
<link>http://arxiv.org/abs/1802.05319</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep learning methods are useful for high-dimensional data and are becoming
widely used in many areas of software engineering. Deep learners utilizes
extensive computational power and can take a long time to train-- making it
difficult to widely validate and repeat and improve their results. Further,
they are not the best solution in all domains. For example, recent results show
that for finding related Stack Overflow posts, a tuned SVM performs similarly
to a deep learner, but is significantly faster to train. This paper extends
that recent result by clustering the dataset, then tuning very learners within
each cluster. This approach is over 500 times faster than deep learning (and
over 900 times faster if we use all the cores on a standard laptop computer).
Significantly, this faster approach generates classifiers nearly as good
(within 2\% F1 Score) as the much slower deep learning method. Hence we
recommend this faster methods since it is much easier to reproduce and utilizes
far fewer CPU resources. More generally, we recommend that before researchers
release research results, that they compare their supposedly sophisticated
methods against simpler alternatives (e.g applying simpler learners to build
local models).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Majumder_S/0/1/0/all/0/1&quot;&gt;Suvodeep Majumder&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Balaji_N/0/1/0/all/0/1&quot;&gt;Nikhila Balaji&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brey_K/0/1/0/all/0/1&quot;&gt;Katie Brey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fu_W/0/1/0/all/0/1&quot;&gt;Wei Fu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Menzies_T/0/1/0/all/0/1&quot;&gt;Tim Menzies&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05335">
<title>Multimodal Generative Models for Scalable Weakly-Supervised Learning. (arXiv:1802.05335v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.05335</link>
<description rdf:parseType="Literal">&lt;p&gt;Multiple modalities often co-occur when describing natural phenomena.
Learning a joint representation of these modalities should yield deeper and
more useful representations. Previous work have proposed generative models to
handle multi-modal input. However, these models either do not learn a joint
distribution or require complex additional computations to handle missing data.
Here, we introduce a multimodal variational autoencoder that uses a
product-of-experts inference network and a sub-sampled training paradigm to
solve the multi-modal inference problem. Notably, our model shares parameters
to efficiently learn under any combination of missing modalities, thereby
enabling weakly-supervised learning. We apply our method on four datasets and
show that we match state-of-the-art performance using many fewer parameters. In
each case our approach yields strong weakly-supervised results. We then
consider a case study of learning image transformations---edge detection,
colorization, facial landmark segmentation, etc.---as a set of modalities. We
find appealing results across this range of tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_M/0/1/0/all/0/1&quot;&gt;Mike Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goodman_N/0/1/0/all/0/1&quot;&gt;Noah Goodman&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05351">
<title>Stealing Hyperparameters in Machine Learning. (arXiv:1802.05351v1 [cs.CR])</title>
<link>http://arxiv.org/abs/1802.05351</link>
<description rdf:parseType="Literal">&lt;p&gt;Hyperparameters are critical in machine learning, as different
hyperparameters often result in models with significantly different
performance. Hyperparameters may be deemed confidential because of their
commercial value and the confidentiality of the proprietary algorithms that the
learner uses to learn them. In this work, we propose attacks on stealing the
hyperparameters that are learned by a learner. We call our attacks
hyperparameter stealing attacks. Our attacks are applicable to a variety of
popular machine learning algorithms such as ridge regression, logistic
regression, support vector machine, and neural network. We evaluate the
effectiveness of our attacks both theoretically and empirically. For instance,
we evaluate our attacks on Amazon Machine Learning. Our results demonstrate
that our attacks can accurately steal hyperparameters. We also study
countermeasures. Our results highlight the need for new defenses against our
hyperparameter stealing attacks for certain machine learning algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1&quot;&gt;Binghui Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gong_N/0/1/0/all/0/1&quot;&gt;Neil Zhenqiang Gong&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05394">
<title>Cost-Effective Training of Deep CNNs with Active Model Adaptation. (arXiv:1802.05394v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.05394</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep convolutional neural networks have achieved great success in various
applications. However, training an effective DNN model for a specific task is
rather challenging because it requires a prior knowledge or experience to
design the network architecture, repeated trial-and-error process to tune the
parameters, and a large set of labeled data to train the model. In this paper,
we propose to overcome these challenges by actively adapting a pre-trained
model to a new task with less labeled examples. Specifically, the pre-trained
model is iteratively fine tuned based on the most useful examples. The examples
are actively selected based on a novel criterion, which jointly estimates the
potential contribution of an instance on optimizing the feature representation
as well as improving the classification model for the target task. On one hand,
the pre-trained model brings plentiful information from its original task,
avoiding redesign of the network architecture or training from scratch; and on
the other hand, the labeling cost can be significantly reduced by active label
querying. Experiments on multiple datasets and different pre-trained models
demonstrate that the proposed approach can achieve cost-effective training of
DNNs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1&quot;&gt;Sheng-Jun Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1&quot;&gt;Jia-Wei Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1&quot;&gt;Zhao-Yang Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05411">
<title>Selecting the Best in GANs Family: a Post Selection Inference Framework. (arXiv:1802.05411v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.05411</link>
<description rdf:parseType="Literal">&lt;p&gt;&quot;Which Generative Adversarial Networks (GANs) generates the most plausible
images?&quot; has been a frequently asked question among researchers. To address
this problem, we first propose an \emph{incomplete} U-statistics estimate of
maximum mean discrepancy $\mathrm{MMD}_{inc}$ to measure the distribution
discrepancy between generated and real images. $\mathrm{MMD}_{inc}$ enjoys the
advantages of asymptotic normality, computation efficiency, and model
agnosticity. We then propose a GANs analysis framework to select and test the
&quot;best&quot; member in GANs family using the Post Selection Inference (PSI) with
$\mathrm{MMD}_{inc}$. In the experiments, we adopt the proposed framework on 7
GANs variants and compare their $\mathrm{MMD}_{inc}$ scores.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tsai_Y/0/1/0/all/0/1&quot;&gt;Yao-Hung Hubert Tsai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yamada_M/0/1/0/all/0/1&quot;&gt;Makoto Yamada&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_D/0/1/0/all/0/1&quot;&gt;Denny Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Salakhutdinov_R/0/1/0/all/0/1&quot;&gt;Ruslan Salakhutdinov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Takeuchi_I/0/1/0/all/0/1&quot;&gt;Ichiro Takeuchi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fukumizu_K/0/1/0/all/0/1&quot;&gt;Kenji Fukumizu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05550">
<title>ICA based on Split Generalized Gaussian. (arXiv:1802.05550v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.05550</link>
<description rdf:parseType="Literal">&lt;p&gt;Independent Component Analysis (ICA) - one of the basic tools in data
analysis - aims to find a coordinate system in which the components of the data
are independent. Most popular ICA methods use kurtosis as a metric of
non-Gaussianity to maximize, such as FastICA and JADE. However, their
assumption of fourth-order moment (kurtosis) may not always be satisfied in
practice. One of the possible solution is to use third-order moment (skewness)
instead of kurtosis, which was applied in $ICA_{SG}$ and EcoICA.
&lt;/p&gt;
&lt;p&gt;In this paper we present a competitive approach to ICA based on the Split
Generalized Gaussian distribution (SGGD), which is well adapted to heavy-tailed
as well as asymmetric data. Consequently, we obtain a method which works better
than the classical approaches, in both cases: heavy tails and non-symmetric
data. \end{abstract}
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Spurek_P/0/1/0/all/0/1&quot;&gt;P. Spurek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rola_P/0/1/0/all/0/1&quot;&gt;P. Rola&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tabor_J/0/1/0/all/0/1&quot;&gt;J. Tabor&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Czechowski_A/0/1/0/all/0/1&quot;&gt;A. Czechowski&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05666">
<title>Adversarial Risk and the Dangers of Evaluating Against Weak Attacks. (arXiv:1802.05666v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.05666</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper investigates recently proposed approaches for defending against
adversarial examples and evaluating adversarial robustness. The existence of
adversarial examples in trained neural networks reflects the fact that expected
risk alone does not capture the model&apos;s performance against worst-case inputs.
We motivate the use of adversarial risk as an objective, although it cannot
easily be computed exactly. We then frame commonly used attacks and evaluation
metrics as defining a tractable surrogate objective to the true adversarial
risk. This suggests that models may be obscured to adversaries, by optimizing
this surrogate rather than the true adversarial risk. We demonstrate that this
is a significant problem in practice by repurposing gradient-free optimization
techniques into adversarial attacks, which we use to decrease the accuracy of
several recently proposed defenses to near zero. Our hope is that our
formulations and results will help researchers to develop more powerful
defenses.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Uesato_J/0/1/0/all/0/1&quot;&gt;Jonathan Uesato&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+ODonoghue_B/0/1/0/all/0/1&quot;&gt;Brendan O&amp;#x27;Donoghue&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oord_A/0/1/0/all/0/1&quot;&gt;Aaron van den Oord&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kohli_P/0/1/0/all/0/1&quot;&gt;Pushmeet Kohli&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05694">
<title>Multinomial Adversarial Networks for Multi-Domain Text Classification. (arXiv:1802.05694v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1802.05694</link>
<description rdf:parseType="Literal">&lt;p&gt;Many text classification tasks are known to be highly domain-dependent.
Unfortunately, the availability of training data can vary drastically across
domains. Worse still, for some domains there may not be any annotated data at
all. In this work, we propose a multinomial adversarial network (MAN) to tackle
the text classification problem in this real-world multidomain setting (MDTC).
We provide theoretical justifications for the MAN framework, proving that
different instances of MANs are essentially minimizers of various f-divergence
metrics (Ali and Silvey, 1966) among multiple probability distributions. MANs
are thus a theoretically sound generalization of traditional adversarial
networks that discriminate over two distributions. More specifically, for the
MDTC task, MAN learns features that are invariant across multiple domains by
resorting to its ability to reduce the divergence among the feature
distributions of each domain. We present experimental results showing that MANs
significantly outperform the prior art on the MDTC task. We also show that MANs
achieve state-of-the-art performance for domains with no labeled data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1&quot;&gt;Xilun Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cardie_C/0/1/0/all/0/1&quot;&gt;Claire Cardie&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1705.08415">
<title>Community Detection with Graph Neural Networks. (arXiv:1705.08415v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1705.08415</link>
<description rdf:parseType="Literal">&lt;p&gt;We study data-driven methods for community detection in graphs. This
estimation problem is typically formulated in terms of the spectrum of certain
operators, as well as via posterior inference under certain probabilistic
graphical models. Focusing on random graph families such as the Stochastic
Block Model, recent research has unified these two approaches, and identified
both statistical and computational signal-to-noise detection thresholds.
&lt;/p&gt;
&lt;p&gt;We embed the resulting class of algorithms within a generic family of graph
neural networks and show that they can reach those detection thresholds in a
purely data-driven manner, without access to the underlying generative models
and with no parameter assumptions. The resulting model is also tested on real
datasets, requiring less computational steps and performing significantly
better than rigid parametric models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bruna_J/0/1/0/all/0/1&quot;&gt;Joan Bruna&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xiang Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.06853">
<title>Bandits with Delayed, Aggregated Anonymous Feedback. (arXiv:1709.06853v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1709.06853</link>
<description rdf:parseType="Literal">&lt;p&gt;We study a variant of the stochastic $K$-armed bandit problem, which we call
&quot;bandits with delayed, aggregated anonymous feedback&quot;. In this problem, when
the player pulls an arm, a reward is generated, however it is not immediately
observed. Instead, at the end of each round the player observes only the sum of
a number of previously generated rewards which happen to arrive in the given
round. The rewards are stochastically delayed and due to the aggregated nature
of the observations, the information of which arm led to a particular reward is
lost. The question is what is the cost of the information loss due to this
delayed, aggregated anonymous feedback? Previous works have studied bandits
with stochastic, non-anonymous delays and found that the regret increases only
by an additive factor relating to the expected delay. In this paper, we show
that this additive regret increase can be maintained in the harder delayed,
aggregated anonymous feedback setting when the expected delay (or a bound on
it) is known. We provide an algorithm that matches the worst case regret of the
non-anonymous problem exactly when the delays are bounded, and up to
logarithmic factors or an additive variance term, for unbounded delays.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pike_Burke_C/0/1/0/all/0/1&quot;&gt;Ciara Pike-Burke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Agrawal_S/0/1/0/all/0/1&quot;&gt;Shipra Agrawal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Szepesvari_C/0/1/0/all/0/1&quot;&gt;Csaba Szepesvari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Grunewalder_S/0/1/0/all/0/1&quot;&gt;Steffen Grunewalder&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04784">
<title>MONK -- Outlier-Robust Mean Embedding Estimation by Median-of-Means. (arXiv:1802.04784v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1802.04784</link>
<description rdf:parseType="Literal">&lt;p&gt;Mean embeddings provide an extremely flexible and powerful tool in machine
learning and statistics to represent probability distributions and define a
semi-metric (MMD, maximum mean discrepancy; also called N-distance or energy
distance), with numerous successful applications. The representation is
constructed as the expectation of the feature map defined by a kernel. As a
mean, its classical empirical estimator, however, can be arbitrary severely
affected even by a single outlier in case of unbounded features. To the best of
our knowledge, unfortunately even the consistency of the existing few
techniques trying to alleviate this serious sensitivity bottleneck is unknown.
In this paper, we show how the recently emerged principle of median-of-means
can be used to design minimax-optimal estimators for kernel mean embedding and
MMD, with finite-sample strong outlier-robustness guarantees.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lerasle_M/0/1/0/all/0/1&quot;&gt;Matthieu Lerasle&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Szabo_Z/0/1/0/all/0/1&quot;&gt;Zoltan Szabo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lecue_G/0/1/0/all/0/1&quot;&gt;Guillaume Lecue&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Massiot_G/0/1/0/all/0/1&quot;&gt;Gaspar Massiot&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Moulines_E/0/1/0/all/0/1&quot;&gt;Eric Moulines&lt;/a&gt;</dc:creator>
</item></rdf:RDF>