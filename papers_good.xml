<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Good papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Good Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-07-10T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.03478"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.03486"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.03487"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.03523"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.03367"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.03395"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.03399"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.03418"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.03490"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.03586"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.03653"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.01270"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.01763"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.02799"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.03402"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.03610"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.03625"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.03697"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.03750"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.03756"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1705.06262"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06309"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.04775"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07813"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.01547"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05393"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1807.03478">
<title>An Adaptive Learning Method of Restricted Boltzmann Machine by Neuron Generation and Annihilation Algorithm. (arXiv:1807.03478v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1807.03478</link>
<description rdf:parseType="Literal">&lt;p&gt;Restricted Boltzmann Machine (RBM) is a generative stochastic energy-based
model of artificial neural network for unsupervised learning. Recently, RBM is
well known to be a pre-training method of Deep Learning. In addition to visible
and hidden neurons, the structure of RBM has a number of parameters such as the
weights between neurons and the coefficients for them. Therefore, we may meet
some difficulties to determine an optimal network structure to analyze big
data. In order to evade the problem, we investigated the variance of parameters
to find an optimal structure during learning. For the reason, we should check
the variance of parameters to cause the fluctuation for energy function in RBM
model. In this paper, we propose the adaptive learning method of RBM that can
discover an optimal number of hidden neurons according to the training
situation by applying the neuron generation and annihilation algorithm. In this
method, a new hidden neuron is generated if the energy function is not still
converged and the variance of the parameters is large. Moreover, the
inactivated hidden neuron will be annihilated if the neuron does not affect the
learning situation. The experimental results for some benchmark data sets were
discussed in this paper.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kamada_S/0/1/0/all/0/1&quot;&gt;Shin Kamada&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ichimura_T/0/1/0/all/0/1&quot;&gt;Takumi Ichimura&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.03486">
<title>An Adaptive Learning Method of Deep Belief Network by Layer Generation Algorithm. (arXiv:1807.03486v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1807.03486</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep Belief Network (DBN) has a deep architecture that represents multiple
features of input patterns hierarchically with the pre-trained Restricted
Boltzmann Machines (RBM). A traditional RBM or DBN model cannot change its
network structure during the learning phase. Our proposed adaptive learning
method can discover the optimal number of hidden neurons and weights and/or
layers according to the input space. The model is an important method to take
account of the computational cost and the model stability. The regularities to
hold the sparse structure of network is considerable problem, since the
extraction of explicit knowledge from the trained network should be required.
In our previous research, we have developed the hybrid method of adaptive
structural learning method of RBM and Learning Forgetting method to the trained
RBM. In this paper, we propose the adaptive learning method of DBN that can
determine the optimal number of layers during the learning. We evaluated our
proposed model on some benchmark data sets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kamada_S/0/1/0/all/0/1&quot;&gt;Shin Kamada&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ichimura_T/0/1/0/all/0/1&quot;&gt;Takumi Ichimura&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.03487">
<title>Fine Tuning Method by using Knowledge Acquisition from Deep Belief Network. (arXiv:1807.03487v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1807.03487</link>
<description rdf:parseType="Literal">&lt;p&gt;We developed an adaptive structure learning method of Restricted Boltzmann
Machine (RBM) which can generate/annihilate neurons by self-organizing learning
method according to input patterns. Moreover, the adaptive Deep Belief Network
(DBN) in the assemble process of pre-trained RBM layer was developed. The
proposed method presents to score a great success to the training data set for
big data benchmark test such as CIFAR-10. However, the classification
capability of the test data set, which are included unknown patterns, is high,
but does not lead perfect correct solution. We investigated the wrong specified
data and then some characteristic patterns were found. In this paper, the
knowledge related to the patterns is embedded into the classification algorithm
of trained DBN. As a result, the classification capability can achieve a great
success (97.1\% to unknown data set).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kamada_S/0/1/0/all/0/1&quot;&gt;Shin Kamada&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ichimura_T/0/1/0/all/0/1&quot;&gt;Takumi Ichimura&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.03523">
<title>DLOPT: Deep Learning Optimization Library. (arXiv:1807.03523v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.03523</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep learning hyper-parameter optimization is a tough task. Finding an
appropriate network configuration is a key to success, however most of the
times this labor is roughly done. In this work we introduce a novel library to
tackle this problem, the Deep Learning Optimization Library: DLOPT. We briefly
describe its architecture and present a set of use examples. This is an open
source project developed under the GNU GPL v3 license and it is freely
available at https://github.com/acamero/dlopt
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Camero_A/0/1/0/all/0/1&quot;&gt;Andr&amp;#xe9;s Camero&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Toutouh_J/0/1/0/all/0/1&quot;&gt;Jamal Toutouh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alba_E/0/1/0/all/0/1&quot;&gt;Enrique Alba&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.03367">
<title>Talk the Walk: Navigating New York City through Grounded Dialogue. (arXiv:1807.03367v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1807.03367</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce &quot;Talk The Walk&quot;, the first large-scale dialogue dataset grounded
in action and perception. The task involves two agents (a &quot;guide&quot; and a
&quot;tourist&quot;) that communicate via natural language in order to achieve a common
goal: having the tourist navigate to a given target location. The task and
dataset, which are described in detail, are challenging and their full solution
is an open problem that we pose to the community. We (i) focus on the task of
tourist localization and develop the novel Masked Attention for Spatial
Convolutions (MASC) mechanism that allows for grounding tourist utterances into
the guide&apos;s map, (ii) show it yields significant improvements for both emergent
and natural language communication, and (iii) using this method, we establish
non-trivial baselines on the full task.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vries_H/0/1/0/all/0/1&quot;&gt;Harm de Vries&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shuster_K/0/1/0/all/0/1&quot;&gt;Kurt Shuster&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Batra_D/0/1/0/all/0/1&quot;&gt;Dhruv Batra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Parikh_D/0/1/0/all/0/1&quot;&gt;Devi Parikh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Weston_J/0/1/0/all/0/1&quot;&gt;Jason Weston&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kiela_D/0/1/0/all/0/1&quot;&gt;Douwe Kiela&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.03395">
<title>Towards Non-Parametric Learning to Rank. (arXiv:1807.03395v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.03395</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper studies a stylized, yet natural, learning-to-rank problem and
points out the critical incorrectness of a widely used nearest neighbor
algorithm. We consider a model with $n$ agents (users) $\{x_i\}_{i \in [n]}$
and $m$ alternatives (items) $\{y_j\}_{j \in [m]}$, each of which is associated
with a latent feature vector. Agents rank items nondeterministically according
to the Plackett-Luce model, where the higher the utility of an item to the
agent, the more likely this item will be ranked high by the agent. Our goal is
to find neighbors of an arbitrary agent or alternative in the latent space.
&lt;/p&gt;
&lt;p&gt;We first show that the Kendall-tau distance based kNN produces incorrect
results in our model. Next, we fix the problem by introducing a new algorithm
with features constructed from &quot;global information&quot; of the data matrix. Our
approach is in sharp contrast to most existing feature engineering methods.
Finally, we design another new algorithm identifying similar alternatives. The
construction of alternative features can be done using &quot;local information,&quot;
highlighting the algorithmic difference between finding similar agents and
similar alternatives.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_A/0/1/0/all/0/1&quot;&gt;Ao Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Q/0/1/0/all/0/1&quot;&gt;Qiong Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1&quot;&gt;Zhenming Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xia_L/0/1/0/all/0/1&quot;&gt;Lirong Xia&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.03399">
<title>Jointly Embedding Entities and Text with Distant Supervision. (arXiv:1807.03399v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1807.03399</link>
<description rdf:parseType="Literal">&lt;p&gt;Learning representations for knowledge base entities and concepts is becoming
increasingly important for NLP applications. However, recent entity embedding
methods have relied on structured resources that are expensive to create for
new domains and corpora. We present a distantly-supervised method for jointly
learning embeddings of entities and text from an unnanotated corpus, using only
a list of mappings between entities and surface forms. We learn embeddings from
open-domain and biomedical corpora, and compare against prior methods that rely
on human-annotated text or large knowledge graph structure. Our embeddings
capture entity similarity and relatedness better than prior work, both in
existing biomedical datasets and a new Wikipedia-based dataset that we release
to the community. Results on analogy completion and entity sense disambiguation
indicate that entities and words capture complementary information that can be
effectively combined for downstream use.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Newman_Griffis_D/0/1/0/all/0/1&quot;&gt;Denis Newman-Griffis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lai_A/0/1/0/all/0/1&quot;&gt;Albert M. Lai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fosler_Lussier_E/0/1/0/all/0/1&quot;&gt;Eric Fosler-Lussier&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.03418">
<title>Interpreting and Explaining Deep Neural Networks for Classification of Audio Signals. (arXiv:1807.03418v1 [cs.SD])</title>
<link>http://arxiv.org/abs/1807.03418</link>
<description rdf:parseType="Literal">&lt;p&gt;Interpretability of deep neural networks is a recently emerging area of
machine learning research targeting a better understanding of how models
perform feature selection and derive their classification decisions. In this
paper, two neural network architectures are trained on spectrogram and raw
waveform data for audio classification tasks on a newly created audio dataset
and layer-wise relevance propagation (LRP), a previously proposed
interpretability method, is applied to investigate the models&apos; feature
selection and decision making. It is demonstrated that the networks are highly
reliant on feature marked as relevant by LRP through systematic manipulation of
the input data. Our results show that by making deep audio classifiers
interpretable, one can analyze and compare the properties and strategies of
different models beyond classification accuracy, which potentially opens up new
ways for model improvements.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Becker_S/0/1/0/all/0/1&quot;&gt;S&amp;#xf6;ren Becker&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ackermann_M/0/1/0/all/0/1&quot;&gt;Marcel Ackermann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lapuschkin_S/0/1/0/all/0/1&quot;&gt;Sebastian Lapuschkin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Muller_K/0/1/0/all/0/1&quot;&gt;Klaus-Robert M&amp;#xfc;ller&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Samek_W/0/1/0/all/0/1&quot;&gt;Wojciech Samek&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.03490">
<title>Easing Embedding Learning by Comprehensive Transcription of Heterogeneous Information Networks. (arXiv:1807.03490v1 [cs.SI])</title>
<link>http://arxiv.org/abs/1807.03490</link>
<description rdf:parseType="Literal">&lt;p&gt;Heterogeneous information networks (HINs) are ubiquitous in real-world
applications. In the meantime, network embedding has emerged as a convenient
tool to mine and learn from networked data. As a result, it is of interest to
develop HIN embedding methods. However, the heterogeneity in HINs introduces
not only rich information but also potentially incompatible semantics, which
poses special challenges to embedding learning in HINs. With the intention to
preserve the rich yet potentially incompatible information in HIN embedding, we
propose to study the problem of comprehensive transcription of heterogeneous
information networks. The comprehensive transcription of HINs also provides an
easy-to-use approach to unleash the power of HINs, since it requires no
additional supervision, expertise, or feature engineering. To cope with the
challenges in the comprehensive transcription of HINs, we propose the HEER
algorithm, which embeds HINs via edge representations that are further coupled
with properly-learned heterogeneous metrics. To corroborate the efficacy of
HEER, we conducted experiments on two large-scale real-words datasets with an
edge reconstruction task and multiple case studies. Experiment results
demonstrate the effectiveness of the proposed HEER model and the utility of
edge representations and heterogeneous metrics. The code and data are available
at https://github.com/GentleZhu/HEER.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1&quot;&gt;Yu Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_Q/0/1/0/all/0/1&quot;&gt;Qi Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_F/0/1/0/all/0/1&quot;&gt;Fang Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1&quot;&gt;Chao Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1&quot;&gt;Jiawei Han&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.03586">
<title>Difficulty Controllable Question Generation for Reading Comprehension. (arXiv:1807.03586v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1807.03586</link>
<description rdf:parseType="Literal">&lt;p&gt;Question generation aims to generate natural language questions from a range
of data sources such as free text and image. In this paper, we investigate the
difficulty levels of questions, and propose a new task called Difficulty
Controllable Question Generation (Dico-QG). Taking as input a reading
comprehension paragraph and some text fragments (i.e. answers) in the paragraph
that we want to ask about, a Dico-QG method needs to generate questions each of
which has a given text fragment as its answer and is associated with a
difficulty label. To solve this task, we proposed a two-step approach. The
first step estimates what difficulty level of question could be generated for a
given answer. After that, in the generation step, the estimated difficulty is
employed together with other information as input to generate a question. For
evaluation, we prepared the first dataset of reading comprehension questions
with difficulty labels. The results show that our approach not only generates
questions of better quality under the metrics like BLEU, but also has the
capability of difficulty awareness to generate questions complying with the
difficulty label.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1&quot;&gt;Yifan Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jianan Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bing_L/0/1/0/all/0/1&quot;&gt;Lidong Bing&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+King_I/0/1/0/all/0/1&quot;&gt;Irwin King&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lyu_M/0/1/0/all/0/1&quot;&gt;Michael R. Lyu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.03653">
<title>Handling Incomplete Heterogeneous Data using VAEs. (arXiv:1807.03653v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.03653</link>
<description rdf:parseType="Literal">&lt;p&gt;Variational autoencoders (VAEs), as well as other generative models, have
been shown to be efficient and accurate to capture the latent structure of vast
amounts of complex high-dimensional data. However, existing VAEs can still not
directly handle data that are heterogenous (mixed continuous and discrete) or
incomplete (with missing data at random), which is indeed common in real-world
applications.
&lt;/p&gt;
&lt;p&gt;In this paper, we propose a general framework to design VAEs, suitable for
fitting incomplete heterogenous data. The proposed HI-VAE includes likelihood
models for real-valued, positive real valued, interval, categorical, ordinal
and count data, and allows to estimate (and potentially impute) missing data
accurately. Furthermore, HI-VAE presents competitive predictive performance in
supervised tasks, outperforming supervised models when trained on incomplete
data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nazabal_A/0/1/0/all/0/1&quot;&gt;Alfredo Nazabal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Olmos_P/0/1/0/all/0/1&quot;&gt;Pablo M. Olmos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghahramani_Z/0/1/0/all/0/1&quot;&gt;Zoubin Ghahramani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Valera_I/0/1/0/all/0/1&quot;&gt;Isabel Valera&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.01270">
<title>Reaching Human-level Performance in Automatic Grammatical Error Correction: An Empirical Study. (arXiv:1807.01270v4 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1807.01270</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural sequence-to-sequence (seq2seq) approaches have proven to be successful
in grammatical error correction (GEC). Based on the seq2seq framework, we
propose a novel fluency boost learning and inference mechanism. Fluency
boosting learning generates diverse error-corrected sentence pairs during
training, enabling the error correction model to learn how to improve a
sentence&apos;s fluency from more instances, while fluency boosting inference allows
the model to correct a sentence incrementally with multiple inference steps.
Combining fluency boost learning and inference with convolutional seq2seq
models, our approach achieves the state-of-the-art performance: 75.72 (F_{0.5})
on CoNLL-2014 10 annotation dataset and 62.42 (GLEU) on JFLEG test set
respectively, becoming the first GEC system that reaches human-level
performance (72.58 for CoNLL and 62.37 for JFLEG) on both of the benchmarks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ge_T/0/1/0/all/0/1&quot;&gt;Tao Ge&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1&quot;&gt;Furu Wei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1&quot;&gt;Ming Zhou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.01763">
<title>Seq2RDF: An end-to-end application for deriving Triples from Natural Language Text. (arXiv:1807.01763v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1807.01763</link>
<description rdf:parseType="Literal">&lt;p&gt;We present an end-to-end approach that takes unstructured textual input and
generates structured output compliant with a given vocabulary. Inspired by
recent successes in neural machine translation, we treat the triples within a
given knowledge graph as an independent graph language and propose an
encoder-decoder framework with an attention mechanism that leverages knowledge
graph embeddings. Our model learns the mapping from natural language text to
triple representation in the form of subject-predicate-object using the
selected knowledge graph vocabulary. Experiments on three different data sets
show that we achieve competitive F1-Measures over the baselines using our
simple yet effective approach. A demo video is included.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yue Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1&quot;&gt;Tongtao Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_Z/0/1/0/all/0/1&quot;&gt;Zhicheng Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ji_H/0/1/0/all/0/1&quot;&gt;Heng Ji&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+McGuinness_D/0/1/0/all/0/1&quot;&gt;Deborah L. McGuinness&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.02799">
<title>Distillation Techniques for Pseudo-rehearsal Based Incremental Learning. (arXiv:1807.02799v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1807.02799</link>
<description rdf:parseType="Literal">&lt;p&gt;The ability to learn from incrementally arriving data is essential for any
life-long learning system. However, standard deep neural networks forget the
knowledge about the old tasks, a phenomenon called catastrophic forgetting,
when trained on incrementally arriving data. We discuss the biases in current
Generative Adversarial Networks (GAN) based approaches that learn the
classifier by knowledge distillation from previously trained classifiers. These
biases cause the trained classifier to perform poorly. We propose an approach
to remove these biases by distilling knowledge from the classifier of AC-GAN.
Experiments on MNIST and CIFAR10 show that this method is comparable to current
state of the art rehearsal based approaches. The code for this paper is
available at &lt;a href=&quot;http://bit.ly/incremental-learning.&quot;&gt;this http URL&lt;/a&gt;
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shah_H/0/1/0/all/0/1&quot;&gt;Haseeb Shah&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Javed_K/0/1/0/all/0/1&quot;&gt;Khurram Javed&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shafait_F/0/1/0/all/0/1&quot;&gt;Faisal Shafait&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.03402">
<title>IGLOO: Slicing the Features Space to Represent Long Sequences. (arXiv:1807.03402v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.03402</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce a new neural network architecture, IGLOO, which aims at
providing a representation for long sequences where RNNs fail to converge. The
structure uses the relationships between random patches sliced out of the
features space of some backbone 1 dimensional CNN to find a representation.
This paper explains the implementation of the method and provides benchmark
results commonly used for RNNs and compare IGLOO to other structures recently
published. It is found that IGLOO can deal with sequences of up to 25,000 time
steps. For shorter sequences it is also found to be effective and we find that
it achieves the highest score in the literature for the permuted MNIST task.
Benchmarks also show that IGLOO can run at the speed of the CuDNN optimised GRU
or LSTM without being tied to any specific hardware.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sourkov_V/0/1/0/all/0/1&quot;&gt;Vsevolod Sourkov&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.03610">
<title>Window Opening Model using Deep Learning Methods. (arXiv:1807.03610v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.03610</link>
<description rdf:parseType="Literal">&lt;p&gt;Occupant behavior (OB) and in particular window openings need to be
considered in building performance simulation (BPS), in order to realistically
model the indoor climate and energy consumption for heating ventilation and air
conditioning (HVAC). However, the proposed OB window opening models are often
biased towards the over-represented class where windows remained closed. In
addition, they require tuning for each occupant which can not be efficiently
scaled to the increased number of occupants. This paper presents a window
opening model for commercial buildings using deep learning methods. The model
is trained using data from occupants from an office building in Germany. In
total the model is evaluated using almost 20 mio. data points from 3
independent buildings, located in Aachen, Frankfurt and Philadelphia.
Eventually, the results of 3100 core hours of model development are summarized,
which makes this study the largest of its kind in window states modeling.
Additionally, the practical potential of the proposed model was tested by
incorporating it in the Modelica-based thermal building simulation. The
resulting evaluation accuracy and F1 scores on the office buildings ranged
between 86-89 % and 0.53-0.65 respectively. The performance dropped around 15 %
points in case of sparse input data, while the F1 score remained high.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Markovic_R/0/1/0/all/0/1&quot;&gt;Romana Markovic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grintal_E/0/1/0/all/0/1&quot;&gt;Eva Grintal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wolki_D/0/1/0/all/0/1&quot;&gt;Daniel W&amp;#xf6;lki&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Frisch_J/0/1/0/all/0/1&quot;&gt;J&amp;#xe9;r&amp;#xf4;me Frisch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Treeck_C/0/1/0/all/0/1&quot;&gt;Christoph van Treeck&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.03625">
<title>Foreign English Accent Adjustment by Learning Phonetic Patterns. (arXiv:1807.03625v1 [cs.SD])</title>
<link>http://arxiv.org/abs/1807.03625</link>
<description rdf:parseType="Literal">&lt;p&gt;State-of-the-art automatic speech recognition (ASR) systems struggle with the
lack of data for rare accents. For sufficiently large datasets, neural engines
tend to outshine statistical models in most natural language processing
problems. However, a speech accent remains a challenge for both approaches.
Phonologists manually create general rules describing a speaker&apos;s accent, but
their results remain underutilized. In this paper, we propose a model that
automatically retrieves phonological generalizations from a small dataset. This
method leverages the difference in pronunciation between a particular dialect
and General American English (GAE) and creates new accented samples of words.
The proposed model is able to learn all generalizations that previously were
manually obtained by phonologists. We use this statistical method to generate a
million phonological variations of words from the CMU Pronouncing Dictionary
and train a sequence-to-sequence RNN to recognize accented words with 59%
accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kitashov_F/0/1/0/all/0/1&quot;&gt;Fedor Kitashov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Svitanko_E/0/1/0/all/0/1&quot;&gt;Elizaveta Svitanko&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dutta_D/0/1/0/all/0/1&quot;&gt;Debojyoti Dutta&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.03697">
<title>Deep Learning on Low-Resource Datasets. (arXiv:1807.03697v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.03697</link>
<description rdf:parseType="Literal">&lt;p&gt;In training a deep learning system to perform audio transcription, two
practical problems may arise. Firstly, most datasets are weakly labelled,
having only a list of events present in each recording without any temporal
information for training. Secondly, deep neural networks need a very large
amount of labelled training data to achieve good quality performance, yet in
practice it is difficult to collect enough samples for most classes of
interest. In this paper, we propose factorising the final task of audio
transcription into multiple intermediate tasks in order to improve the training
performance when dealing with this kind of low-resource datasets. We evaluate
three data-efficient approaches of training a stacked convolutional and
recurrent neural network for the intermediate tasks. Our results show that
different methods of training have different advantages and disadvantages.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Morfi_V/0/1/0/all/0/1&quot;&gt;Veronica Morfi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stowell_D/0/1/0/all/0/1&quot;&gt;Dan Stowell&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.03750">
<title>Navigating Diverse Data Science Learning: Critical Reflections Towards Future Practice. (arXiv:1807.03750v1 [cs.GL])</title>
<link>http://arxiv.org/abs/1807.03750</link>
<description rdf:parseType="Literal">&lt;p&gt;Data Science is currently a popular field of science attracting expertise
from very diverse backgrounds. Current learning practices need to acknowledge
this and adapt to it. This paper summarises some experiences relating to such
learning approaches from teaching a postgraduate Data Science module, and draws
some learned lessons that are of relevance to others teaching Data Science.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Elkhatib_Y/0/1/0/all/0/1&quot;&gt;Yehia Elkhatib&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.03756">
<title>Latent Alignment and Variational Attention. (arXiv:1807.03756v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1807.03756</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural attention has become central to many state-of-the-art models in
natural language processing and related domains. Attention networks are an
easy-to-train and effective method for softly simulating alignment; however,
the approach does not marginalize over latent alignments in a probabilistic
sense. This property makes it difficult to compare attention to other alignment
approaches, to compose it with probabilistic models, and to perform posterior
inference conditioned on observed data. A related latent approach, hard
attention, fixes these issues, but is generally harder to train and less
accurate. This work considers variational attention networks, alternatives to
soft and hard attention for learning latent variable alignment models, with
tighter approximation bounds based on amortized variational inference. We
further propose methods for reducing the variance of gradients to make these
approaches computationally feasible. Experiments show that for machine
translation and visual question answering, inefficient exact latent variable
models outperform standard neural attention, but these gains go away when using
hard attention based training. On the other hand, variational attention retains
most of the performance gain but with training speed comparable to neural
attention.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Deng_Y/0/1/0/all/0/1&quot;&gt;Yuntian Deng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kim_Y/0/1/0/all/0/1&quot;&gt;Yoon Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chiu_J/0/1/0/all/0/1&quot;&gt;Justin Chiu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Guo_D/0/1/0/all/0/1&quot;&gt;Demi Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rush_A/0/1/0/all/0/1&quot;&gt;Alexander M. Rush&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1705.06262">
<title>Utility of General and Specific Word Embeddings for Classifying Translational Stages of Research. (arXiv:1705.06262v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1705.06262</link>
<description rdf:parseType="Literal">&lt;p&gt;Conventional text classification models make a bag-of-words assumption
reducing text into word occurrence counts per document. Recent algorithms such
as word2vec are capable of learning semantic meaning and similarity between
words in an entirely unsupervised manner using a contextual window and doing so
much faster than previous methods. Each word is projected into vector space
such that similar meaning words such as &quot;strong&quot; and &quot;powerful&quot; are projected
into the same general Euclidean space. Open questions about these embeddings
include their utility across classification tasks and the optimal properties
and source of documents to construct broadly functional embeddings. In this
work, we demonstrate the usefulness of pre-trained embeddings for
classification in our task and demonstrate that custom word embeddings, built
in the domain and for the tasks, can improve performance over word embeddings
learnt on more general data including news articles or Wikipedia.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Major_V/0/1/0/all/0/1&quot;&gt;Vincent Major&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Surkis_A/0/1/0/all/0/1&quot;&gt;Alisa Surkis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aphinyanaphongs_Y/0/1/0/all/0/1&quot;&gt;Yindalon Aphinyanaphongs&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06309">
<title>Learning Adversarially Fair and Transferable Representations. (arXiv:1802.06309v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1802.06309</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we advocate for representation learning as the key to
mitigating unfair prediction outcomes downstream. Motivated by a scenario where
learned representations are used by third parties with unknown objectives, we
propose and explore adversarial representation learning as a natural method of
ensuring those parties act fairly. We connect group fairness (demographic
parity, equalized odds, and equal opportunity) to different adversarial
objectives. Through worst-case theoretical guarantees and experimental
validation, we show that the choice of this objective is crucial to fair
prediction. Furthermore, we present the first in-depth experimental
demonstration of fair transfer learning and demonstrate empirically that our
learned representations admit fair predictions on new tasks while maintaining
utility, an essential goal of fair representation learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Madras_D/0/1/0/all/0/1&quot;&gt;David Madras&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Creager_E/0/1/0/all/0/1&quot;&gt;Elliot Creager&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pitassi_T/0/1/0/all/0/1&quot;&gt;Toniann Pitassi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zemel_R/0/1/0/all/0/1&quot;&gt;Richard Zemel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.04775">
<title>A Compact Network Learning Model for Distribution Regression. (arXiv:1804.04775v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1804.04775</link>
<description rdf:parseType="Literal">&lt;p&gt;Despite the superior performance of deep learning in many applications,
challenges remain in the area of regression on function spaces. In particular,
neural networks are unable to encode function inputs compactly as each node
encodes just a real value. We propose a novel idea to address this shortcoming:
to encode an entire function in a single network node. To that end, we design a
compact network representation that encodes and propagates functions in single
nodes for the distribution regression task. Our proposed Distribution
Regression Network (DRN) achieves higher prediction accuracies while being much
more compact and uses fewer parameters than traditional neural networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kou_C/0/1/0/all/0/1&quot;&gt;Connie Kou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1&quot;&gt;Hwee Kuan Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ng_T/0/1/0/all/0/1&quot;&gt;Teck Khim Ng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07813">
<title>Learning Real-World Robot Policies by Dreaming. (arXiv:1805.07813v2 [cs.RO] UPDATED)</title>
<link>http://arxiv.org/abs/1805.07813</link>
<description rdf:parseType="Literal">&lt;p&gt;Learning to control robots directly based on images is a primary challenge in
robotics. However, many existing reinforcement learning approaches require
iteratively obtaining millions of samples to learn a policy which can take
significant time. In this paper, we focus on the problem of learning real-world
robot action policies solely based on a few random off-policy samples. We learn
a realistic dreaming model that can emulate samples equivalent to a sequence of
images from the actual environment, and make the agent learn action policies by
interacting with the dreaming model rather than the real world. We
experimentally confirm that our dreaming model can learn realistic policies
that transfer to the real-world.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Piergiovanni_A/0/1/0/all/0/1&quot;&gt;AJ Piergiovanni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_A/0/1/0/all/0/1&quot;&gt;Alan Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ryoo_M/0/1/0/all/0/1&quot;&gt;Michael S. Ryoo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.01547">
<title>Semi-Supervised Clustering with Neural Networks. (arXiv:1806.01547v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1806.01547</link>
<description rdf:parseType="Literal">&lt;p&gt;Clustering using neural networks has recently demonstrated promising
performance in machine learning and computer vision applications. However, the
performance of current approaches is limited either by unsupervised learning or
their dependence on large set of labeled data samples. In this paper, we
propose ClusterNet that uses pairwise semantic constraints from very few
labeled data samples (&amp;lt;5% of total data) and exploits the abundant unlabeled
data to drive the clustering approach. We define a new loss function that uses
pairwise semantic similarity between objects combined with constrained k-means
clustering to efficiently utilize both labeled and unlabeled data in the same
framework. The proposed network uses convolution autoencoder to learn a latent
representation that groups data into k specified clusters, while also learning
the cluster centers simultaneously. We evaluate and compare the performance of
ClusterNet on several datasets and state of the art deep clustering approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shukla_A/0/1/0/all/0/1&quot;&gt;Ankita Shukla&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheema_G/0/1/0/all/0/1&quot;&gt;Gullal Singh Cheema&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Anand_S/0/1/0/all/0/1&quot;&gt;Saket Anand&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05393">
<title>Dynamical Isometry and a Mean Field Theory of CNNs: How to Train 10,000-Layer Vanilla Convolutional Neural Networks. (arXiv:1806.05393v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1806.05393</link>
<description rdf:parseType="Literal">&lt;p&gt;In recent years, state-of-the-art methods in computer vision have utilized
increasingly deep convolutional neural network architectures (CNNs), with some
of the most successful models employing hundreds or even thousands of layers. A
variety of pathologies such as vanishing/exploding gradients make training such
deep networks challenging. While residual connections and batch normalization
do enable training at these depths, it has remained unclear whether such
specialized architecture designs are truly necessary to train deep CNNs. In
this work, we demonstrate that it is possible to train vanilla CNNs with ten
thousand layers or more simply by using an appropriate initialization scheme.
We derive this initialization scheme theoretically by developing a mean field
theory for signal propagation and by characterizing the conditions for
dynamical isometry, the equilibration of singular values of the input-output
Jacobian matrix. These conditions require that the convolution operator be an
orthogonal transformation in the sense that it is norm-preserving. We present
an algorithm for generating such random initial orthogonal convolution kernels
and demonstrate empirically that they enable efficient training of extremely
deep architectures.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Xiao_L/0/1/0/all/0/1&quot;&gt;Lechao Xiao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bahri_Y/0/1/0/all/0/1&quot;&gt;Yasaman Bahri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sohl_Dickstein_J/0/1/0/all/0/1&quot;&gt;Jascha Sohl-Dickstein&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Schoenholz_S/0/1/0/all/0/1&quot;&gt;Samuel S. Schoenholz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pennington_J/0/1/0/all/0/1&quot;&gt;Jeffrey Pennington&lt;/a&gt;</dc:creator>
</item></rdf:RDF>