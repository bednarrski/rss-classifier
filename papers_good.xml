<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Good papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Good Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-07-17T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.06230"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.06399"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.07633"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.06046"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.06072"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.06078"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.06107"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.06142"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.06228"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.06333"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.06397"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1503.01334"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1705.06366"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.06085"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.05924"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.06007"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.06054"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.06302"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.06538"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.06540"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.06576"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1704.03581"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07892"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.05936"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.05979"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1502.05767"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1807.06230">
<title>Genetic algorithms in Forth. (arXiv:1807.06230v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1807.06230</link>
<description rdf:parseType="Literal">&lt;p&gt;A method for automatically finding a program (bytecode) realizing the given
algorithm is developed. The algorithm is specified as a set of tests
(input\_data) $ \rightarrow $ (output\_data). Genetic methods made it possible
to find the implementation of relatively complex algorithms: sorting, decimal
digits, GCD, LCM, factorial, prime divisors, binomial coefficients, and others.
The algorithms are implemented on a highly simplified version of Forth
language.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khashin_S/0/1/0/all/0/1&quot;&gt;S. I. Khashin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vaganov_S/0/1/0/all/0/1&quot;&gt;S. E. Vaganov&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.06399">
<title>Are Efficient Deep Representations Learnable?. (arXiv:1807.06399v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.06399</link>
<description rdf:parseType="Literal">&lt;p&gt;Many theories of deep learning have shown that a deep network can require
dramatically fewer resources to represent a given function compared to a
shallow network. But a question remains: can these efficient representations be
learned using current deep learning techniques? In this work, we test whether
standard deep learning methods can in fact find the efficient representations
posited by several theories of deep representation. Specifically, we train deep
neural networks to learn two simple functions with known efficient solutions:
the parity function and the fast Fourier transform. We find that using
gradient-based optimization, a deep network does not learn the parity function,
unless initialized very close to a hand-coded exact solution. We also find that
a deep linear neural network does not learn the fast Fourier transform, even in
the best-case scenario of infinite training data, unless the weights are
initialized very close to the exact hand-coded solution. Our results suggest
that not every element of the class of compositional functions can be learned
efficiently by a deep network, and further restrictions are necessary to
understand what functions are both efficiently representable and learnable.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nye_M/0/1/0/all/0/1&quot;&gt;Maxwell Nye&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saxe_A/0/1/0/all/0/1&quot;&gt;Andrew Saxe&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.07633">
<title>A Simple Quantum Neural Net with a Periodic Activation Function. (arXiv:1804.07633v3 [quant-ph] UPDATED)</title>
<link>http://arxiv.org/abs/1804.07633</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we propose a simple neural net that requires only $O(nlog_2k)$
number of qubits and $O(nk)$ quantum gates: Here, $n$ is the number of input
parameters, and $k$ is the number of weights applied to these parameters in the
proposed neural net. We describe the network in terms of a quantum circuit, and
then draw its equivalent classical neural net which involves $O(k^n)$ nodes in
the hidden layer. Then, we show that the network uses a periodic activation
function of cosine values of the linear combinations of the inputs and weights.
The backpropagation is described through the gradient descent, and then iris
and breast cancer datasets are used for the simulations. The numerical results
indicate the network can be used in machine learning problems and it may
provide exponential speedup over the same structured classical neural net.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Daskin_A/0/1/0/all/0/1&quot;&gt;Ammar Daskin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.06046">
<title>Zap: Making Predictions Based on Online User Behavior. (arXiv:1807.06046v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.06046</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper introduces Zap, a generic machine learning pipeline for making
predictions based on online user behavior. Zap combines well known techniques
for processing sequential data with more obscure techniques such as Bloom
filters, bucketing, and model calibration into an end-to-end solution. The
pipeline creates website- and task-specific models without knowing anything
about the structure of the website. It is designed to minimize the amount of
website-specific code, which is realized by factoring all website-specific
logic into example generators. New example generators can typically be written
up in a few lines of code.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chervonyi_Y/0/1/0/all/0/1&quot;&gt;Yuri Chervonyi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Harabor_D/0/1/0/all/0/1&quot;&gt;Dragos Harabor&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1&quot;&gt;Brian Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sacks_J/0/1/0/all/0/1&quot;&gt;Josh Sacks&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.06072">
<title>Leveraging Pre-Trained 3D Object Detection Models For Fast Ground Truth Generation. (arXiv:1807.06072v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.06072</link>
<description rdf:parseType="Literal">&lt;p&gt;Training 3D object detectors for autonomous driving has been limited to small
datasets due to the effort required to generate annotations. Reducing both task
complexity and the amount of task switching done by annotators is key to
reducing the effort and time required to generate 3D bounding box annotations.
This paper introduces a novel ground truth generation method that combines
human supervision with pretrained neural networks to generate per-instance 3D
point cloud segmentation, 3D bounding boxes, and class annotations. The
annotators provide object anchor clicks which behave as a seed to generate
instance segmentation results in 3D. The points belonging to each instance are
then used to regress object centroids, bounding box dimensions, and object
orientation. Our proposed annotation scheme requires 30x lower human annotation
time. We use the KITTI 3D object detection dataset to evaluate the efficiency
and the quality of our annotation scheme. We also test the the proposed scheme
on previously unseen data from the Autonomoose self-driving vehicle to
demonstrate generalization capabilities of the network.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1&quot;&gt;Jungwook Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Walsh_S/0/1/0/all/0/1&quot;&gt;Sean Walsh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Harakeh_A/0/1/0/all/0/1&quot;&gt;Ali Harakeh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Waslander_S/0/1/0/all/0/1&quot;&gt;Steven L. Waslander&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.06078">
<title>Gnirut: The Trouble With Being Born Human In An Autonomous World. (arXiv:1807.06078v1 [cs.CY])</title>
<link>http://arxiv.org/abs/1807.06078</link>
<description rdf:parseType="Literal">&lt;p&gt;What if we delegated so much to autonomous AI and intelligent machines that
They passed a law that forbids humans to carry out a number of professions? We
conceive the plot of a new episode of Black Mirror to reflect on what might
await us and how we can deal with such a future.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vigano_L/0/1/0/all/0/1&quot;&gt;Luca Vigan&amp;#xf3;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sempreboni_D/0/1/0/all/0/1&quot;&gt;Diego Sempreboni&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.06107">
<title>Don&apos;t get Lost in Negation: An Effective Negation Handled Dialogue Acts Prediction Algorithm for Twitter Customer Service Conversations. (arXiv:1807.06107v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1807.06107</link>
<description rdf:parseType="Literal">&lt;p&gt;In the last several years, Twitter is being adopted by the companies as an
alternative platform to interact with the customers to address their concerns.
With the abundance of such unconventional conversation resources, push for
developing effective virtual agents is more than ever. To address this
challenge, a better understanding of such customer service conversations is
required. Lately, there have been several works proposing a novel taxonomy for
fine-grained dialogue acts as well as develop algorithms for automatic
detection of these acts. The outcomes of these works are providing stepping
stones for the ultimate goal of building efficient and effective virtual
agents. But none of these works consider handling the notion of negation into
the proposed algorithms. In this work, we developed an SVM-based dialogue acts
prediction algorithm for Twitter customer service conversations where negation
handling is an integral part of the end-to-end solution. For negation handling,
we propose several efficient heuristics as well as adopt recent state-of- art
third party machine learning based solutions. Empirically we show model&apos;s
performance gain while handling negation compared to when we don&apos;t. Our
experiments show that for the informal text such as tweets, the heuristic-based
approach is more effective.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bhuiyan_M/0/1/0/all/0/1&quot;&gt;Mansurul Bhuiyan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Misra_A/0/1/0/all/0/1&quot;&gt;Amita Misra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tripathy_S/0/1/0/all/0/1&quot;&gt;Saurabh Tripathy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mahmud_J/0/1/0/all/0/1&quot;&gt;Jalal Mahmud&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Akkiraju_R/0/1/0/all/0/1&quot;&gt;Rama Akkiraju&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.06142">
<title>Introducing Quantum-Like Influence Diagrams for Violations of the Sure Thing Principle. (arXiv:1807.06142v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1807.06142</link>
<description rdf:parseType="Literal">&lt;p&gt;It is the focus of this work to extend and study the previously proposed
quantum-like Bayesian networks to deal with decision-making scenarios by
incorporating the notion of maximum expected utility in influence diagrams. The
general idea is to take advantage of the quantum interference terms produced in
the quantum-like Bayesian Network to influence the probabilities used to
compute the expected utility of some action. This way, we are not proposing a
new type of expected utility hypothesis. On the contrary, we are keeping it
under its classical definition. We are only incorporating it as an extension of
a probabilistic graphical model in a compact graphical representation called an
influence diagram in which the utility function depends on the probabilistic
influences of the quantum-like Bayesian network.
&lt;/p&gt;
&lt;p&gt;Our findings suggest that the proposed quantum-like influence digram can
indeed take advantage of the quantum interference effects of quantum-like
Bayesian Networks to maximise the utility of a cooperative behaviour in
detriment of a fully rational defect behaviour under the prisoner&apos;s dilemma
game.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moreira_C/0/1/0/all/0/1&quot;&gt;Catarina Moreira&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wichert_A/0/1/0/all/0/1&quot;&gt;Andreas Wichert&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.06228">
<title>RuleMatrix: Visualizing and Understanding Classifiers with Rules. (arXiv:1807.06228v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.06228</link>
<description rdf:parseType="Literal">&lt;p&gt;With the growing adoption of machine learning techniques, there is a surge of
research interest towards making machine learning systems more transparent and
interpretable. Various visualizations have been developed to help model
developers understand, diagnose, and refine machine learning models. However, a
large number of potential but neglected users are the domain experts with
little knowledge of machine learning but are expected to work with machine
learning systems. In this paper, we present an interactive visualization
technique to help users with little expertise in machine learning to
understand, explore and validate predictive models. By viewing the model as a
black box, we extract a standardized rule-based knowledge representation from
its input-output behavior. We design RuleMatrix, a matrix-based visualization
of rules to help users navigate and verify the rules and the black-box model.
We evaluate the effectiveness of RuleMatrix via two use cases and a usability
study.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ming_Y/0/1/0/all/0/1&quot;&gt;Yao Ming&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qu_H/0/1/0/all/0/1&quot;&gt;Huamin Qu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bertini_E/0/1/0/all/0/1&quot;&gt;Enrico Bertini&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.06333">
<title>Reinforcement Learning for LTLf/LDLf Goals. (arXiv:1807.06333v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.06333</link>
<description rdf:parseType="Literal">&lt;p&gt;MDPs extended with LTLf/LDLf non-Markovian rewards have recently attracted
interest as a way to specify rewards declaratively. In this paper, we discuss
how a reinforcement learning agent can learn policies fulfilling LTLf/LDLf
goals. In particular we focus on the case where we have two separate
representations of the world: one for the agent, using the (predefined,
possibly low-level) features available to it, and one for the goal, expressed
in terms of high-level (human-understandable) fluents. We formally define the
problem and show how it can be solved. Moreover, we provide experimental
evidence that keeping the RL agent feature space separated from the goal&apos;s can
work in practice, showing interesting cases where the agent can indeed learn a
policy that fulfills the LTLf/LDLf goal using only its features (augmented with
additional memory).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Giacomo_G/0/1/0/all/0/1&quot;&gt;Giuseppe De Giacomo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Iocchi_L/0/1/0/all/0/1&quot;&gt;Luca Iocchi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Favorito_M/0/1/0/all/0/1&quot;&gt;Marco Favorito&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Patrizi_F/0/1/0/all/0/1&quot;&gt;Fabio Patrizi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.06397">
<title>Expressing Linear Orders Requires Exponential-Size DNNFs. (arXiv:1807.06397v1 [cs.CC])</title>
<link>http://arxiv.org/abs/1807.06397</link>
<description rdf:parseType="Literal">&lt;p&gt;We show that any DNNF circuit that expresses the set of linear orders over a
set of $n$ candidates must be of size $2^{\Omega(n)}$.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Haan_R/0/1/0/all/0/1&quot;&gt;Ronald de Haan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1503.01334">
<title>Faster quantum mixing for slowly evolving sequences of Markov chains. (arXiv:1503.01334v3 [quant-ph] UPDATED)</title>
<link>http://arxiv.org/abs/1503.01334</link>
<description rdf:parseType="Literal">&lt;p&gt;Markov chain methods are remarkably successful in computational physics,
machine learning, and combinatorial optimization. The cost of such methods
often reduces to the mixing time, i.e. \ the time required to reach the steady
state of the Markov chain, which scales as $\delta^{-1}$, the inverse of the
spectral gap. It has long been conjectured that quantum computers offer nearly
generic quadratic improvements for mixing problems. However, except in special
cases, quantum algorithms achieve a run-time of $\O(\sqrt{\delta^{-1}}
\sqrt{N})$, which introduces a costly dependence on the Markov chain size $N,$
not present in the classical case. Here, we re-address the problem of mixing of
Markov chains when these form a slowly evolving sequence. This setting is akin
to the simulated annealing setting, and is commonly encountered in physics,
material sciences and machine learning. We provide a quantum memory-efficient
algorithm with a run-time of $\O(\sqrt{\delta^{-1}} \sqrt[4]{N})$, neglecting
logarithmic terms, which is an important improvement for large state spaces.
Further our algorithms output quantum encodings of distributions, which has
advantages over classical outputs. Finally, we discuss the run-time bounds of
mixing algorithms and show that, under certain assumptions, our algorithms are
optimal.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Orsucci_D/0/1/0/all/0/1&quot;&gt;Davide Orsucci&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Briegel_H/0/1/0/all/0/1&quot;&gt;Hans J. Briegel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Dunjko_V/0/1/0/all/0/1&quot;&gt;Vedran Dunjko&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1705.06366">
<title>Automatic Goal Generation for Reinforcement Learning Agents. (arXiv:1705.06366v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1705.06366</link>
<description rdf:parseType="Literal">&lt;p&gt;Reinforcement learning is a powerful technique to train an agent to perform a
task. However, an agent that is trained using reinforcement learning is only
capable of achieving the single task that is specified via its reward function.
Such an approach does not scale well to settings in which an agent needs to
perform a diverse set of tasks, such as navigating to varying positions in a
room or moving objects to varying locations. Instead, we propose a method that
allows an agent to automatically discover the range of tasks that it is capable
of performing. We use a generator network to propose tasks for the agent to try
to achieve, specified as goal states. The generator network is optimized using
adversarial training to produce tasks that are always at the appropriate level
of difficulty for the agent. Our method thus automatically produces a
curriculum of tasks for the agent to learn. We show that, by using this
framework, an agent can efficiently and automatically learn to perform a wide
set of tasks without requiring any prior knowledge of its environment. Our
method can also learn to achieve tasks with sparse rewards, which traditionally
pose significant challenges.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Florensa_C/0/1/0/all/0/1&quot;&gt;Carlos Florensa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Held_D/0/1/0/all/0/1&quot;&gt;David Held&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Geng_X/0/1/0/all/0/1&quot;&gt;Xinyang Geng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1&quot;&gt;Pieter Abbeel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.06085">
<title>PACT: Parameterized Clipping Activation for Quantized Neural Networks. (arXiv:1805.06085v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1805.06085</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep learning algorithms achieve high classification accuracy at the expense
of significant computation cost. To address this cost, a number of quantization
schemes have been proposed - but most of these techniques focused on quantizing
weights, which are relatively smaller in size compared to activations. This
paper proposes a novel quantization scheme for activations during training -
that enables neural networks to work well with ultra low precision weights and
activations without any significant accuracy degradation. This technique,
PArameterized Clipping acTivation (PACT), uses an activation clipping parameter
$\alpha$ that is optimized during training to find the right quantization
scale. PACT allows quantizing activations to arbitrary bit precisions, while
achieving much better accuracy relative to published state-of-the-art
quantization schemes. We show, for the first time, that both weights and
activations can be quantized to 4-bits of precision while still achieving
accuracy comparable to full precision networks across a range of popular models
and datasets. We also show that exploiting these reduced-precision
computational units in hardware can enable a super-linear improvement in
inferencing performance due to a significant reduction in the area of
accelerator compute engines coupled with the ability to retain the quantized
model and activation data in on-chip memories.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1&quot;&gt;Jungwook Choi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zhuo Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Venkataramani_S/0/1/0/all/0/1&quot;&gt;Swagath Venkataramani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chuang_P/0/1/0/all/0/1&quot;&gt;Pierce I-Jen Chuang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Srinivasan_V/0/1/0/all/0/1&quot;&gt;Vijayalakshmi Srinivasan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gopalakrishnan_K/0/1/0/all/0/1&quot;&gt;Kailash Gopalakrishnan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.05924">
<title>Bipedal Walking Robot using Deep Deterministic Policy Gradient. (arXiv:1807.05924v2 [cs.RO] UPDATED)</title>
<link>http://arxiv.org/abs/1807.05924</link>
<description rdf:parseType="Literal">&lt;p&gt;Machine learning algorithms have found several applications in the field of
robotics and control systems. The control systems community has started to show
interest towards several machine learning algorithms from the sub-domains such
as supervised learning, imitation learning and reinforcement learning to
achieve autonomous control and intelligent decision making. Amongst many
complex control problems, stable bipedal walking has been the most challenging
problem. In this paper, we present an architecture to design and simulate a
planar bipedal walking robot(BWR) using a realistic robotics simulator, Gazebo.
The robot demonstrates successful walking behaviour by learning through several
of its trial and errors, without any prior knowledge of itself or the world
dynamics. The autonomous walking of the BWR is achieved using reinforcement
learning algorithm called Deep Deterministic Policy Gradient(DDPG). DDPG is one
of the algorithms for learning controls in continuous action spaces. After
training the model in simulation, it was observed that, with a proper shaped
reward function, the robot achieved faster walking or even rendered a running
gait with an average speed of 0.83 m/s. The gait pattern of the bipedal walker
was compared with the actual human walking pattern. The results show that the
bipedal walking pattern had similar characteristics to that of a human walking
pattern. The video presenting our experiment is available at
https://goo.gl/NHXKqR.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kumar_A/0/1/0/all/0/1&quot;&gt;Arun Kumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Paul_N/0/1/0/all/0/1&quot;&gt;Navneet Paul&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Omkar_S/0/1/0/all/0/1&quot;&gt;S N Omkar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.06007">
<title>On Lebesgue Integral Quadrature. (arXiv:1807.06007v1 [math.NA])</title>
<link>http://arxiv.org/abs/1807.06007</link>
<description rdf:parseType="Literal">&lt;p&gt;A new type of quadrature is developed. For a given measure Gauss quadrature
finds optimal values of function argument (nodes) and corresponding weights.
Developed in this paper Lebesgue quadrature instead find optimal values of
function values (value-nodes) and corresponding weights. Gauss quadrature group
sums by function argument, it can be viewed as $n$-point discrete measure,
producing Riemann integral. Lebesgue quadrature group sums by function value,
it can be viewed as $n$-point discrete distribution, producing Lebesgue
integral. Mathematically the problem is reduced to generalized eigenvalues
problem, Lebesgue quadrature value-nodes are the eigenvalues and corresponding
weights are the square of averaged eigenvector. Numerical estimation of
integral as Lebesgue integral is especially advantageous when analyzing
irregular and stochastic processes. The approach separates the outcome
(value-nodes) and the probability of outcome (weight), for this reason it is
especially well suited for non-Gaussian processes study. Implementing the
theory software is available from authors.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Malyshkin_V/0/1/0/all/0/1&quot;&gt;Vladislav Gennadievich Malyshkin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.06054">
<title>On the Information Theoretic Distance Measures and Bidirectional Helmholtz Machines. (arXiv:1807.06054v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.06054</link>
<description rdf:parseType="Literal">&lt;p&gt;By establishing a connection between bi-directional Helmholtz machines and
information theory, we propose a generalized Helmholtz machine. Theoretical and
experimental results show that given \textit{shallow} architectures, the
generalized model outperforms the previous ones substantially.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Azarafrooz_M/0/1/0/all/0/1&quot;&gt;Mahdi Azarafrooz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1&quot;&gt;Xuan Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Akhavan_Masouleh_S/0/1/0/all/0/1&quot;&gt;Sepehr Akhavan-Masouleh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.06302">
<title>Learning Neuron Non-Linearities with Kernel-Based Deep Neural Networks. (arXiv:1807.06302v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.06302</link>
<description rdf:parseType="Literal">&lt;p&gt;The effectiveness of deep neural architectures has been widely supported in
terms of both experimental and foundational principles. There is also clear
evidence that the activation function (e.g. the rectifier and the LSTM units)
plays a crucial role in the complexity of learning. Based on this remark, this
paper discusses an optimal selection of the neuron non-linearity in a
functional framework that is inspired from classic regularization arguments. It
is shown that the best activation function is represented by a kernel expansion
in the training set, that can be effectively approximated over an opportune set
of points modeling 1-D clusters. The idea can be naturally extended to
recurrent networks, where the expressiveness of kernel-based activation
functions turns out to be a crucial ingredient to capture long-term
dependencies. We give experimental evidence of this property by a set of
challenging experiments, where we compare the results with neural architectures
based on state of the art LSTM cells.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Marra_G/0/1/0/all/0/1&quot;&gt;Giuseppe Marra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zanca_D/0/1/0/all/0/1&quot;&gt;Dario Zanca&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Betti_A/0/1/0/all/0/1&quot;&gt;Alessandro Betti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gori_M/0/1/0/all/0/1&quot;&gt;Marco Gori&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.06538">
<title>Pseudo-Feature Generation for Imbalanced Data Analysis in Deep Learning. (arXiv:1807.06538v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.06538</link>
<description rdf:parseType="Literal">&lt;p&gt;We generate pseudo-features by multivariate probability distributions
obtained from feature maps in a low layer of trained deep neural networks.
Then, we virtually augment the data of minor classes by the pseudo-features in
order to overcome imbalanced data problems. Because all the wild data are
imbalanced, the proposed method has the possibility to improve the ability of
DNN in a broad range of problems
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Konno_T/0/1/0/all/0/1&quot;&gt;Tomohiko Konno&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Iwazume_M/0/1/0/all/0/1&quot;&gt;Michiaki Iwazume&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.06540">
<title>Icing on the Cake: An Easy and Quick Post-Learnig Method You Can Try After Deep Learning. (arXiv:1807.06540v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.06540</link>
<description rdf:parseType="Literal">&lt;p&gt;We found an easy and quick post-learning method named &quot;Icing on the Cake&quot; to
enhance a classification performance in deep learning. The method is that we
train only the final classifier again after an ordinary training is done.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Konno_T/0/1/0/all/0/1&quot;&gt;Tomohiko Konno&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Iwazume_M/0/1/0/all/0/1&quot;&gt;Michiaki Iwazume&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.06576">
<title>Comparison of RNN Encoder-Decoder Models for Anomaly Detection. (arXiv:1807.06576v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.06576</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we compare different types of Recurrent Neural Network (RNN)
Encoder-Decoders in anomaly detection viewpoint. We focused on finding the
model what can learn the same data more effectively. We compared multiple
models under the same conditions, such as the number of parameters, optimizer,
and learning rate. However, the difference is whether to predict the future
sequence or restore the current sequence. We constructed the dataset with
simple vectors and used them for the experiment. Finally, we experimentally
confirmed that the model performs better when the model restores the current
sequence, rather than predict the future sequence.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Park_Y/0/1/0/all/0/1&quot;&gt;YeongHyeon Park&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yun_I/0/1/0/all/0/1&quot;&gt;Il Dong Yun&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1704.03581">
<title>Polya Urn Latent Dirichlet Allocation: a doubly sparse massively parallel sampler. (arXiv:1704.03581v5 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1704.03581</link>
<description rdf:parseType="Literal">&lt;p&gt;Latent Dirichlet Allocation (LDA) is a topic model widely used in natural
language processing and machine learning. Most approaches to training the model
rely on iterative algorithms, which makes it difficult to run LDA on big
corpora that are best analyzed in parallel and distributed computational
environments. Indeed, current approaches to parallel inference either don&apos;t
converge to the correct posterior or require storage of large dense matrices in
memory. We present a novel sampler that overcomes both problems, and we show
that this sampler is faster, both empirically and theoretically, than previous
Gibbs samplers for LDA. We do so by employing a novel P\&apos;olya-urn-based
approximation in the sparse partially collapsed sampler for LDA. We prove that
the approximation error vanishes with data size, making our algorithm
asymptotically exact, a property of importance for large-scale topic models. In
addition, we show, via an explicit example, that -- contrary to popular belief
in the topic modeling literature -- partially collapsed samplers can be more
efficient than fully collapsed samplers. We conclude by comparing the
performance of our algorithm with that of other approaches on well-known
corpora.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Terenin_A/0/1/0/all/0/1&quot;&gt;Alexander Terenin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Magnusson_M/0/1/0/all/0/1&quot;&gt;M&amp;#xe5;ns Magnusson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Jonsson_L/0/1/0/all/0/1&quot;&gt;Leif Jonsson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Draper_D/0/1/0/all/0/1&quot;&gt;David Draper&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07892">
<title>Localized Multiple Kernel Learning for Anomaly Detection: One-class Classification. (arXiv:1805.07892v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.07892</link>
<description rdf:parseType="Literal">&lt;p&gt;Multi-kernel learning has been well explored in the recent past and has
exhibited promising outcomes for multi-class classification and regression
tasks. In this paper, we present a multiple kernel learning approach for the
One-class Classification (OCC) task and employ it for anomaly detection.
Recently, the basic multi-kernel approach has been proposed to solve the OCC
problem, which is simply a convex combination of different kernels with equal
weights. This paper proposes a Localized Multiple Kernel learning approach for
Anomaly Detection (LMKAD) using OCC, where the weight for each kernel is
assigned locally. Proposed LMKAD approach adapts the weight for each kernel
using a gating function. The parameters of the gating function and one-class
classifier are optimized simultaneously through a two-step optimization
process. We present the empirical results of the performance of LMKAD on 25
benchmark datasets from various disciplines. This performance is evaluated
against existing Multi Kernel Anomaly Detection (MKAD) algorithm, and four
other existing kernel-based one-class classifiers to showcase the credibility
of our approach. Our algorithm achieves significantly better Gmean scores while
using a lesser number of support vectors compared to MKAD. Friedman test is
also performed to verify the statistical significance of the results claimed in
this paper.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gautam_C/0/1/0/all/0/1&quot;&gt;Chandan Gautam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Balaji_R/0/1/0/all/0/1&quot;&gt;Ramesh Balaji&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sudharsan_K/0/1/0/all/0/1&quot;&gt;K Sudharsan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tiwari_A/0/1/0/all/0/1&quot;&gt;Aruna Tiwari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ahuja_K/0/1/0/all/0/1&quot;&gt;Kapil Ahuja&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.05936">
<title>Variational Inference: A Unified Framework of Generative Models and Some Revelations. (arXiv:1807.05936v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1807.05936</link>
<description rdf:parseType="Literal">&lt;p&gt;We reinterpreting the variational inference in a new perspective. Via this
way, we can easily prove that EM algorithm, VAE, GAN, AAE, ALI(BiGAN) are all
special cases of variational inference. The proof also reveals the loss of
standard GAN is incomplete and it explains why we need to train GAN cautiously.
From that, we find out a regularization term to improve stability of GAN
training.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Su_J/0/1/0/all/0/1&quot;&gt;Jianlin Su&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.05979">
<title>Lesion Analysis and Diagnosis with Mask-RCNN. (arXiv:1807.05979v2 [eess.IV] UPDATED)</title>
<link>http://arxiv.org/abs/1807.05979</link>
<description rdf:parseType="Literal">&lt;p&gt;This project applies Mask R-CNN method to ISIC 2018 challenge tasks: lesion
boundary segmentation (task1), lesion attributes detection (task 2), lesion
diagnosis (task 3), a solution to the latter is using a trained model for task
1 and a simple voting procedure.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Sorokin_A/0/1/0/all/0/1&quot;&gt;Andrey Sorokin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1502.05767">
<title>Automatic differentiation in machine learning: a survey. (arXiv:1502.05767v4 [cs.SC] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1502.05767</link>
<description rdf:parseType="Literal">&lt;p&gt;Derivatives, mostly in the form of gradients and Hessians, are ubiquitous in
machine learning. Automatic differentiation (AD), also called algorithmic
differentiation or simply &quot;autodiff&quot;, is a family of techniques similar to but
more general than backpropagation for efficiently and accurately evaluating
derivatives of numeric functions expressed as computer programs. AD is a small
but established field with applications in areas including computational fluid
dynamics, atmospheric sciences, and engineering design optimization. Until very
recently, the fields of machine learning and AD have largely been unaware of
each other and, in some cases, have independently discovered each other&apos;s
results. Despite its relevance, general-purpose AD has been missing from the
machine learning toolbox, a situation slowly changing with its ongoing adoption
under the names &quot;dynamic computational graphs&quot; and &quot;differentiable
programming&quot;. We survey the intersection of AD and machine learning, cover
applications where AD has direct relevance, and address the main implementation
techniques. By precisely defining the main differentiation techniques and their
interrelationships, we aim to bring clarity to the usage of the terms
&quot;autodiff&quot;, &quot;automatic differentiation&quot;, and &quot;symbolic differentiation&quot; as
these are encountered more and more in machine learning settings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Baydin_A/0/1/0/all/0/1&quot;&gt;Atilim Gunes Baydin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pearlmutter_B/0/1/0/all/0/1&quot;&gt;Barak A. Pearlmutter&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Radul_A/0/1/0/all/0/1&quot;&gt;Alexey Andreyevich Radul&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Siskind_J/0/1/0/all/0/1&quot;&gt;Jeffrey Mark Siskind&lt;/a&gt;</dc:creator>
</item></rdf:RDF>