<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Good papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Good Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-06-24T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.08568"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.08760"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05759"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.07073"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.07917"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.08479"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.08544"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.08554"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.08561"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.08616"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.08694"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.08730"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.08781"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09980"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.01910"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.08462"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.08541"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.08647"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.08648"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.08672"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.08727"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.08748"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.01312"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.03334"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.00236"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.07528"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.07537"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1806.08568">
<title>Continuous Learning in Single-Incremental-Task Scenarios. (arXiv:1806.08568v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.08568</link>
<description rdf:parseType="Literal">&lt;p&gt;It was recently shown that architectural, regularization and rehearsal
strategies can be used to train deep models sequentially on a number of
disjoint tasks without forgetting previously acquired knowledge. However, these
strategies are still unsatisfactory if the tasks are not disjoint but
constitute a single incremental task (e.g., class-incremental learning). In
this paper we point out the differences between multi-task and
single-incremental-task scenarios and show that well-known approaches such as
LWF, EWC and SI are not ideal for incremental task scenarios. A new approach,
denoted as AR1, combining architectural and regularization strategies is then
specifically proposed. AR1 overhead (in term of memory and computation) is very
small thus making it suitable for online learning. When tested on CORe50 and
iCIFAR-100, AR1 outperformed existing regularization strategies by a good
margin.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Maltoni_D/0/1/0/all/0/1&quot;&gt;Davide Maltoni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lomonaco_V/0/1/0/all/0/1&quot;&gt;Vincenzo Lomonaco&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.08760">
<title>Combination of Domain Knowledge and Deep Learning for Sentiment Analysis. (arXiv:1806.08760v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1806.08760</link>
<description rdf:parseType="Literal">&lt;p&gt;The emerging technique of deep learning has been widely applied in many
different areas. However, when adopted in a certain specific domain, this
technique should be combined with domain knowledge to improve efficiency and
accuracy. In particular, when analyzing the applications of deep learning in
sentiment analysis, we found that the current approaches are suffering from the
following drawbacks: (i) the existing works have not paid much attention to the
importance of different types of sentiment terms, which is an important concept
in this area; and (ii) the loss function currently employed does not well
reflect the degree of error of sentiment misclassification. To overcome such
problem, we propose to combine domain knowledge with deep learning. Our
proposal includes using sentiment scores, learnt by regression, to augment
training data; and introducing penalty matrix for enhancing the loss function
of cross entropy. When experimented, we achieved a significant improvement in
classification results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vo_K/0/1/0/all/0/1&quot;&gt;Khuong Vo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pham_D/0/1/0/all/0/1&quot;&gt;Dang Pham&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_M/0/1/0/all/0/1&quot;&gt;Mao Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mai_T/0/1/0/all/0/1&quot;&gt;Trung Mai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Quan_T/0/1/0/all/0/1&quot;&gt;Tho Quan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05759">
<title>Insights on representational similarity in neural networks with canonical correlation. (arXiv:1806.05759v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1806.05759</link>
<description rdf:parseType="Literal">&lt;p&gt;Comparing different neural network representations and determining how
representations evolve over time remain challenging open questions in our
understanding of the function of neural networks. Comparing representations in
neural networks is fundamentally difficult as the structure of representations
varies greatly, even across groups of networks trained on identical tasks, and
over the course of training. Here, we develop projection weighted CCA
(Canonical Correlation Analysis) as a tool for understanding neural networks,
building off of SVCCA, a recently proposed method. We first improve the core
method, showing how to differentiate between signal and noise, and then apply
this technique to compare across a group of CNNs, demonstrating that networks
which generalize converge to more similar representations than networks which
memorize, that wider networks converge to more similar solutions than narrow
networks, and that trained networks with identical topology but different
learning rates converge to distinct clusters with diverse representations. We
also investigate the representational dynamics of RNNs, across both training
and sequential timesteps, finding that RNNs converge in a bottom-up pattern
over the course of training and that the hidden state is highly variable over
the course of a sequence, even when accounting for linear transforms. Together,
these results provide new insights into the function of CNNs and RNNs, and
demonstrate the utility of using CCA to understand representations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Morcos_A/0/1/0/all/0/1&quot;&gt;Ari S. Morcos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Raghu_M/0/1/0/all/0/1&quot;&gt;Maithra Raghu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bengio_S/0/1/0/all/0/1&quot;&gt;Samy Bengio&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.07073">
<title>Transfer Learning with Human Corneal Tissues: An Analysis of Optimal Cut-Off Layer. (arXiv:1806.07073v2 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1806.07073</link>
<description rdf:parseType="Literal">&lt;p&gt;Transfer learning is a powerful tool to adapt trained neural networks to new
tasks. Depending on the similarity of the original task to the new task, the
selection of the cut-off layer is critical. For medical applications like
tissue classification, the last layers of an object classification network
might not be optimal. We found that on real data of human corneal tissues the
best feature representation can be found in the middle layers of the
Inception-v3 and in the rear layers of the VGG-19 architecture.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Prodanova_N/0/1/0/all/0/1&quot;&gt;Nadezhda Prodanova&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stegmaier_J/0/1/0/all/0/1&quot;&gt;Johannes Stegmaier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Allgeier_S/0/1/0/all/0/1&quot;&gt;Stephan Allgeier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bohn_S/0/1/0/all/0/1&quot;&gt;Sebastian Bohn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stachs_O/0/1/0/all/0/1&quot;&gt;Oliver Stachs&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kohler_B/0/1/0/all/0/1&quot;&gt;Bernd K&amp;#xf6;hler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mikut_R/0/1/0/all/0/1&quot;&gt;Ralf Mikut&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bartschat_A/0/1/0/all/0/1&quot;&gt;Andreas Bartschat&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.07917">
<title>Meta-Learning by the Baldwin Effect. (arXiv:1806.07917v2 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1806.07917</link>
<description rdf:parseType="Literal">&lt;p&gt;The scope of the Baldwin effect was recently called into question by two
papers that closely examined the seminal work of Hinton and Nowlan. To this
date there has been no demonstration of its necessity in empirically
challenging tasks. Here we show that the Baldwin effect is capable of evolving
few-shot supervised and reinforcement learning mechanisms, by shaping the
hyperparameters and the initial parameters of deep learning algorithms.
Furthermore it can genetically accommodate strong learning biases on the same
set of problems as a recent machine learning algorithm called MAML &quot;Model
Agnostic Meta-Learning&quot; which uses second-order gradients instead of evolution
to learn a set of reference parameters (initial weights) that can allow rapid
adaptation to tasks sampled from a distribution. Whilst in simple cases MAML is
more data efficient than the Baldwin effect, the Baldwin effect is more general
in that it does not require gradients to be backpropagated to the reference
parameters or hyperparameters, and permits effectively any number of gradient
updates in the inner loop. The Baldwin effect learns strong learning dependent
biases, rather than purely genetically accommodating fixed behaviours in a
learning independent manner.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fernando_C/0/1/0/all/0/1&quot;&gt;Chrisantha Thomas Fernando&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sygnowski_J/0/1/0/all/0/1&quot;&gt;Jakub Sygnowski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Osindero_S/0/1/0/all/0/1&quot;&gt;Simon Osindero&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jane Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schaul_T/0/1/0/all/0/1&quot;&gt;Tom Schaul&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Teplyashin_D/0/1/0/all/0/1&quot;&gt;Denis Teplyashin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sprechmann_P/0/1/0/all/0/1&quot;&gt;Pablo Sprechmann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pritzel_A/0/1/0/all/0/1&quot;&gt;Alexander Pritzel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rusu_A/0/1/0/all/0/1&quot;&gt;Andrei A. Rusu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.08479">
<title>Human-Interactive Subgoal Supervision for Efficient Inverse Reinforcement Learning. (arXiv:1806.08479v1 [cs.HC])</title>
<link>http://arxiv.org/abs/1806.08479</link>
<description rdf:parseType="Literal">&lt;p&gt;Humans are able to understand and perform complex tasks by strategically
structuring the tasks into incremental steps or subgoals. For a robot
attempting to learn to perform a sequential task with critical subgoal states,
such states can provide a natural opportunity for interaction with a human
expert. This paper analyzes the benefit of incorporating a notion of subgoals
into Inverse Reinforcement Learning (IRL) with a Human-In-The-Loop (HITL)
framework. The learning process is interactive, with a human expert first
providing input in the form of full demonstrations along with some subgoal
states. These subgoal states define a set of subtasks for the learning agent to
complete in order to achieve the final goal. The learning agent queries for
partial demonstrations corresponding to each subtask as needed when the agent
struggles with the subtask. The proposed Human Interactive IRL (HI-IRL)
framework is evaluated on several discrete path-planning tasks. We demonstrate
that subgoal-based interactive structuring of the learning task results in
significantly more efficient learning, requiring only a fraction of the
demonstration data needed for learning the underlying reward function with the
baseline IRL model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pan_X/0/1/0/all/0/1&quot;&gt;Xinlei Pan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ohn_Bar_E/0/1/0/all/0/1&quot;&gt;Eshed Ohn-Bar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rhinehart_N/0/1/0/all/0/1&quot;&gt;Nicholas Rhinehart&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1&quot;&gt;Yan Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1&quot;&gt;Yilin Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kitani_K/0/1/0/all/0/1&quot;&gt;Kris M. Kitani&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.08544">
<title>Game AI Research with Fast Planet Wars Variants. (arXiv:1806.08544v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1806.08544</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper describes a new implementation of Planet Wars, designed from the
outset for Game AI research. The skill-depth of the game makes it a challenge
for game-playing agents, and the speed of more than 1 million game ticks per
second enables rapid experimentation and prototyping. The parameterised nature
of the game together with an interchangeable actuator model make it well suited
to automated game tuning. The game is designed to be fun to play for humans,
and is directly playable by General Video Game AI agents.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lucas_S/0/1/0/all/0/1&quot;&gt;Simon M. Lucas&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.08554">
<title>Learning-to-Ask: Knowledge Acquisition via 20 Questions. (arXiv:1806.08554v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1806.08554</link>
<description rdf:parseType="Literal">&lt;p&gt;Almost all the knowledge empowered applications rely upon accurate knowledge,
which has to be either collected manually with high cost, or extracted
automatically with unignorable errors. In this paper, we study 20 Questions, an
online interactive game where each question-response pair corresponds to a fact
of the target entity, to acquire highly accurate knowledge effectively with
nearly zero labor cost. Knowledge acquisition via 20 Questions predominantly
presents two challenges to the intelligent agent playing games with human
players. The first one is to seek enough information and identify the target
entity with as few questions as possible, while the second one is to leverage
the remaining questioning opportunities to acquire valuable knowledge
effectively, both of which count on good questioning strategies. To address
these challenges, we propose the Learning-to-Ask (LA) framework, within which
the agent learns smart questioning strategies for information seeking and
knowledge acquisition by means of deep reinforcement learning and generalized
matrix factorization respectively. In addition, a Bayesian approach to
represent knowledge is adopted to ensure robustness to noisy user responses.
Simulating experiments on real data show that LA is able to equip the agent
with effective questioning strategies, which result in high winning rates and
rapid knowledge acquisition. Moreover, the questioning strategies for
information seeking and knowledge acquisition boost the performance of each
other, allowing the agent to start with a relatively small knowledge set and
quickly improve its knowledge base in the absence of constant human
supervision.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yihong Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1&quot;&gt;Bei Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Duan_X/0/1/0/all/0/1&quot;&gt;Xuguang Duan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lou_J/0/1/0/all/0/1&quot;&gt;Jian-Guang Lou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yue Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_W/0/1/0/all/0/1&quot;&gt;Wenwu Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1&quot;&gt;Yong Cao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.08561">
<title>The Temporal Singularity: time-accelerated simulated civilizations and their implications. (arXiv:1806.08561v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1806.08561</link>
<description rdf:parseType="Literal">&lt;p&gt;Provided significant future progress in artificial intelligence and
computing, it may ultimately be possible to create multiple Artificial General
Intelligences (AGIs), and possibly entire societies living within simulated
environments. In that case, it should be possible to improve the problem
solving capabilities of the system by increasing the speed of the simulation.
If a minimal simulation with sufficient capabilities is created, it might
manage to increase its own speed by accelerating progress in science and
technology, in a way similar to the Technological Singularity. This may
ultimately lead to large simulated civilizations unfolding at extreme temporal
speedups, achieving what from the outside would look like a Temporal
Singularity. Here we discuss the feasibility of the minimal simulation and the
potential advantages, dangers, and connection to the Fermi paradox of the
Temporal Singularity. The medium-term importance of the topic derives from the
amount of computational power required to start the process, which could be
available within the next decades, making the Temporal Singularity
theoretically possible before the end of the century.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Spigler_G/0/1/0/all/0/1&quot;&gt;Giacomo Spigler&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.08616">
<title>Deploying Deep Neural Networks in the Embedded Space. (arXiv:1806.08616v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1806.08616</link>
<description rdf:parseType="Literal">&lt;p&gt;Recently, Deep Neural Networks (DNNs) have emerged as the dominant model
across various AI applications. In the era of IoT and mobile systems, the
efficient deployment of DNNs on embedded platforms is vital to enable the
development of intelligent applications. This paper summarises our recent work
on the optimised mapping of DNNs on embedded settings. By covering such diverse
topics as DNN-to-accelerator toolflows, high-throughput cascaded classifiers
and domain-specific model design, the presented set of works aim to enable the
deployment of sophisticated deep learning models on cutting-edge mobile and
embedded systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Venieris_S/0/1/0/all/0/1&quot;&gt;Stylianos I. Venieris&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kouris_A/0/1/0/all/0/1&quot;&gt;Alexandros Kouris&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bouganis_C/0/1/0/all/0/1&quot;&gt;Christos-Savvas Bouganis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.08694">
<title>Learning to Rank from Samples of Variable Quality. (arXiv:1806.08694v1 [cs.IR])</title>
<link>http://arxiv.org/abs/1806.08694</link>
<description rdf:parseType="Literal">&lt;p&gt;Training deep neural networks requires many training samples, but in
practice, training labels are expensive to obtain and may be of varying
quality, as some may be from trusted expert labelers while others might be from
heuristics or other sources of weak supervision such as crowd-sourcing. This
creates a fundamental quality-versus quantity trade-off in the learning
process. Do we learn from the small amount of high-quality data or the
potentially large amount of weakly-labeled data? We argue that if the learner
could somehow know and take the label-quality into account when learning the
data representation, we could get the best of both worlds. To this end, we
introduce &quot;fidelity-weighted learning&quot; (FWL), a semi-supervised student-teacher
approach for training deep neural networks using weakly-labeled data. FWL
modulates the parameter updates to a student network (trained on the task we
care about) on a per-sample basis according to the posterior confidence of its
label-quality estimated by a teacher (who has access to the high-quality
labels). Both student and teacher are learned from the data. We evaluate FWL on
document ranking where we outperform state-of-the-art alternative
semi-supervised methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dehghani_M/0/1/0/all/0/1&quot;&gt;Mostafa Dehghani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kamps_J/0/1/0/all/0/1&quot;&gt;Jaap Kamps&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.08730">
<title>The Natural Language Decathlon: Multitask Learning as Question Answering. (arXiv:1806.08730v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1806.08730</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep learning has improved performance on many natural language processing
(NLP) tasks individually. However, general NLP models cannot emerge within a
paradigm that focuses on the particularities of a single metric, dataset, and
task. We introduce the Natural Language Decathlon (decaNLP), a challenge that
spans ten tasks: question answering, machine translation, summarization,
natural language inference, sentiment analysis, semantic role labeling,
zero-shot relation extraction, goal-oriented dialogue, semantic parsing, and
commonsense pronoun resolution. We cast all tasks as question answering over a
context. Furthermore, we present a new Multitask Question Answering Network
(MQAN) jointly learns all tasks in decaNLP without any task-specific modules or
parameters in the multitask setting. MQAN shows improvements in transfer
learning for machine translation and named entity recognition, domain
adaptation for sentiment analysis and natural language inference, and zero-shot
capabilities for text classification. We demonstrate that the MQAN&apos;s
multi-pointer-generator decoder is key to this success and performance further
improves with an anti-curriculum training strategy. Though designed for
decaNLP, MQAN also achieves state of the art results on the WikiSQL semantic
parsing task in the single-task setting. We also release code for procuring and
processing data, training and evaluating models, and reproducing all
experiments for decaNLP.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+McCann_B/0/1/0/all/0/1&quot;&gt;Bryan McCann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Keskar_N/0/1/0/all/0/1&quot;&gt;Nitish Shirish Keskar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiong_C/0/1/0/all/0/1&quot;&gt;Caiming Xiong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Socher_R/0/1/0/all/0/1&quot;&gt;Richard Socher&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.08781">
<title>Quantum Codes from Neural Networks. (arXiv:1806.08781v1 [quant-ph])</title>
<link>http://arxiv.org/abs/1806.08781</link>
<description rdf:parseType="Literal">&lt;p&gt;We report on the usefulness of using neural networks as a variational state
ansatz for many-body quantum systems in the context of quantum
information-processing tasks. In the neural network state ansatz, the complex
amplitude function of a quantum state is computed by a neural network. The
resulting multipartite entanglement structure captured by this ansatz has
proven rich enough to describe the ground states and unitary dynamics of
various physical systems of interest.
&lt;/p&gt;
&lt;p&gt;In the present paper, we supply further evidence for the usefulness of neural
network states to describe multipartite entanglement. We demonstrate that
neural network states are capable of efficiently representing quantum codes for
quantum information transmission and quantum error correction. In particular,
we show that a) neural network states yield quantum codes with a high coherent
information for two important quantum channels, the depolarizing channel and
the dephrasure channel; b) neural network states can be used to represent
absolutely maximally entangled states, a special type of quantum error
correction codes. In both cases, the neural network state ansatz provides an
efficient and versatile means as variational parametrization of these states.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Bausch_J/0/1/0/all/0/1&quot;&gt;Johannes Bausch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Leditzky_F/0/1/0/all/0/1&quot;&gt;Felix Leditzky&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09980">
<title>Deep Graph Translation. (arXiv:1805.09980v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.09980</link>
<description rdf:parseType="Literal">&lt;p&gt;Inspired by the tremendous success of deep generative models on generating
continuous data like image and audio, in the most recent year, few deep graph
generative models have been proposed to generate discrete data such as graphs.
They are typically unconditioned generative models which has no control on
modes of the graphs being generated. Differently, in this paper, we are
interested in a new problem named \emph{Deep Graph Translation}: given an input
graph, we want to infer a target graph based on their underlying (both global
and local) translation mapping. Graph translation could be highly desirable in
many applications such as disaster management and rare event forecasting, where
the rare and abnormal graph patterns (e.g., traffic congestions and terrorism
events) will be inferred prior to their occurrence even without historical data
on the abnormal patterns for this graph (e.g., a road network or human contact
network). To achieve this, we propose a novel Graph-Translation-Generative
Adversarial Networks (GT-GAN) which will generate a graph translator from input
to target graphs. GT-GAN consists of a graph translator where we propose new
graph convolution and deconvolution layers to learn the global and local
translation mapping. A new conditional graph discriminator has also been
proposed to classify target graphs by conditioning on input graphs. Extensive
experiments on multiple synthetic and real-world datasets demonstrate the
effectiveness and scalability of the proposed GT-GAN.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_X/0/1/0/all/0/1&quot;&gt;Xiaojie Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1&quot;&gt;Lingfei Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_L/0/1/0/all/0/1&quot;&gt;Liang Zhao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.01910">
<title>Probabilistic Deep Learning using Random Sum-Product Networks. (arXiv:1806.01910v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1806.01910</link>
<description rdf:parseType="Literal">&lt;p&gt;The need for consistent treatment of uncertainty has recently triggered
increased interest in probabilistic deep learning methods. However, most
current approaches have severe limitations when it comes to inference, since
many of these models do not even permit to evaluate exact data likelihoods.
Sum-product networks (SPNs), on the other hand, are an excellent architecture
in that regard, as they allow to efficiently evaluate likelihoods, as well as
arbitrary marginalization and conditioning tasks. Nevertheless, SPNs have not
been fully explored as serious deep learning models, likely due to their
special structural requirements, which complicate learning. In this paper, we
make a drastic simplification and use random SPN structures which are trained
in a &quot;classical deep learning manner&quot;, i.e. employing automatic
differentiation, SGD, and GPU support. The resulting models, called RAT-SPNs,
yield prediction results comparable to deep neural networks, while still being
interpretable as generative model and maintaining well-calibrated
uncertainties. This property makes them highly robust under missing input
features and enables them to naturally detect outliers and peculiar samples.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peharz_R/0/1/0/all/0/1&quot;&gt;Robert Peharz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vergari_A/0/1/0/all/0/1&quot;&gt;Antonio Vergari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stelzner_K/0/1/0/all/0/1&quot;&gt;Karl Stelzner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Molina_A/0/1/0/all/0/1&quot;&gt;Alejandro Molina&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Trapp_M/0/1/0/all/0/1&quot;&gt;Martin Trapp&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kersting_K/0/1/0/all/0/1&quot;&gt;Kristian Kersting&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghahramani_Z/0/1/0/all/0/1&quot;&gt;Zoubin Ghahramani&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.08462">
<title>Probabilistic Natural Language Generation with Wasserstein Autoencoders. (arXiv:1806.08462v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1806.08462</link>
<description rdf:parseType="Literal">&lt;p&gt;Probabilistic generation of natural language sentences is an important task
in NLP. Existing models such as variational autoencoders (VAE) for sequence
generation are extremely difficult to train due to the issues associated with
the Kullback-Leibler (KL) loss collapsing to zero. One has to implement various
heuristics such as KL weight annealing and word dropout in a carefully
engineered manner to successfully train a text VAE. In this paper, we propose
the use of Wasserstein autoencoders (WAE) for probabilistic natural language
sentence generation. We show that sequence-to-sequence WAEs are more robust
towards hyperparameters and can be trained in a straightforward manner without
the need for any weight annealing. Empirical evidence shows that the latent
space learned by WAEs exhibits properties of continuity and smoothness as in
VAEs, while simultaneously achieving much higher BLEU scores for sentence
reconstruction.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bahuleyan_H/0/1/0/all/0/1&quot;&gt;Hareesh Bahuleyan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mou_L/0/1/0/all/0/1&quot;&gt;Lili Mou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vamaraju_K/0/1/0/all/0/1&quot;&gt;Kartik Vamaraju&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1&quot;&gt;Hao Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vechtomova_O/0/1/0/all/0/1&quot;&gt;Olga Vechtomova&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.08541">
<title>Visualizing and Understanding Deep Neural Networks in CTR Prediction. (arXiv:1806.08541v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.08541</link>
<description rdf:parseType="Literal">&lt;p&gt;Although deep learning techniques have been successfully applied to many
tasks, interpreting deep neural network models is still a big challenge to us.
Recently, many works have been done on visualizing and analyzing the mechanism
of deep neural networks in the areas of image processing and natural language
processing. In this paper, we present our approaches to visualize and
understand deep neural networks for a very important commercial task--CTR
(Click-through rate) prediction. We conduct experiments on the productive data
from our online advertising system with daily varying distribution. To
understand the mechanism and the performance of the model, we inspect the
model&apos;s inner status at neuron level. Also, a probe approach is implemented to
measure the layer-wise performance of the model. Moreover, to measure the
influence from the input features, we calculate saliency scores based on the
back-propagated gradients. Practical applications are also discussed, for
example, in understanding, monitoring, diagnosing and refining models and
algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Guo_L/0/1/0/all/0/1&quot;&gt;Lin Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ye_H/0/1/0/all/0/1&quot;&gt;Hui Ye&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Su_W/0/1/0/all/0/1&quot;&gt;Wenbo Su&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Liu_H/0/1/0/all/0/1&quot;&gt;Henhuan Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sun_K/0/1/0/all/0/1&quot;&gt;Kai Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Xiang_H/0/1/0/all/0/1&quot;&gt;Hang Xiang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.08647">
<title>Matrix Completion and Performance Guarantees for Single Individual Haplotyping. (arXiv:1806.08647v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.08647</link>
<description rdf:parseType="Literal">&lt;p&gt;Single individual haplotyping is an NP-hard problem that emerges when
attempting to reconstruct an organism&apos;s inherited genetic variations using data
typically generated by high-throughput DNA sequencing platforms. Genomes of
diploid organisms, including humans, are organized into homologous pairs of
chromosomes that differ from each other in a relatively small number of variant
positions. Haplotypes are ordered sequences of the nucleotides in the variant
positions of the chromosomes in a homologous pair; for diploids, haplotypes
associated with a pair of chromosomes may conveniently represented by means of
complementary binary sequences. In this paper, we consider a binary matrix
factorization formulation of the single individual haplotyping problem and
efficiently solve it by means of alternating minimization. We analyze the
convergence properties of the alternating minimization algorithm and establish
theoretical bounds for the achievable haplotype reconstruction error. The
proposed technique is shown to outperform existing methods when applied to
synthetic as well as real-world Fosmid-based HapMap NA12878 datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barik_S/0/1/0/all/0/1&quot;&gt;Somsubhra Barik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vikalo_H/0/1/0/all/0/1&quot;&gt;Haris Vikalo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.08648">
<title>Francy - An Interactive Discrete Mathematics Framework for GAP. (arXiv:1806.08648v1 [cs.HC])</title>
<link>http://arxiv.org/abs/1806.08648</link>
<description rdf:parseType="Literal">&lt;p&gt;Data visualization and interaction with large data sets is known to be
essential and critical in many businesses today, and the same applies to
research and teaching, in this case, when exploring large and complex
mathematical objects. GAP is a computer algebra system for computational
discrete algebra with an emphasis on computational group theory. The existing
XGAP package for GAP works exclusively on the X Window System. It lacks
abstraction between its mathematical and graphical cores, making it difficult
to extend, maintain, or port. In this paper, we present Francy, a graphical
semantics package for GAP. Francy is responsible for creating a
representational structure that can be rendered using many GUI frameworks
independent from any particular programming language or operating system.
Building on this, we use state of the art web technologies that take advantage
of an improved REPL environment, which is currently under development for GAP.
The integration of this project with Jupyter provides a rich graphical
environment full of features enhancing the usability and accessibility of GAP.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Martins_M/0/1/0/all/0/1&quot;&gt;Manuel Machado Martins&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pfeiffer_M/0/1/0/all/0/1&quot;&gt;Markus Pfeiffer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.08672">
<title>Variational Bi-domain Triplet Autoencoder. (arXiv:1806.08672v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.08672</link>
<description rdf:parseType="Literal">&lt;p&gt;We investigate deep generative models, which allow us to use training data
from one domain to build a model for another domain. We consider domains to
have similar structure (texts, images). We propose the Variational Bi-domain
Triplet Autoencoder (VBTA) that learns a joint distribution of objects from
different domains. There are many cases when obtaining any supervision (e.g.
paired data) is difficult or ambiguous. For such cases we can seek a method
that is able to the information about data relation and structure from the
latent space. We extend the VBTAs objective function by the relative
constraints or triplets that sampled from the shared latent space across
domains. In other words, we combine the deep generative model with a metric
learning ideas in order to improve the final objective with the triplets
information. We demonstrate the performance of the VBTA model on different
tasks: bi-directional image generation, image-to-image translation, even on
unpaired data. We also provide the qualitative analysis. We show that VBTA
model is comparable and outperforms some of the existing generative models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kuznetsova_R/0/1/0/all/0/1&quot;&gt;Rita Kuznetsova&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bakhteev_O/0/1/0/all/0/1&quot;&gt;Oleg Bakhteev&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.08727">
<title>Jack the Reader - A Machine Reading Framework. (arXiv:1806.08727v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1806.08727</link>
<description rdf:parseType="Literal">&lt;p&gt;Many Machine Reading and Natural Language Understanding tasks require reading
supporting text in order to answer questions. For example, in Question
Answering, the supporting text can be newswire or Wikipedia articles; in
Natural Language Inference, premises can be seen as the supporting text and
hypotheses as questions. Providing a set of useful primitives operating in a
single framework of related tasks would allow for expressive modelling, and
easier model comparison and replication. To that end, we present Jack the
Reader (Jack), a framework for Machine Reading that allows for quick model
prototyping by component reuse, evaluation of new models on existing datasets
as well as integrating new datasets and applying them on a growing set of
implemented baseline models. Jack is currently supporting (but not limited to)
three tasks: Question Answering, Natural Language Inference, and Link
Prediction. It is developed with the aim of increasing research efficiency and
code reuse.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Weissenborn_D/0/1/0/all/0/1&quot;&gt;Dirk Weissenborn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Minervini_P/0/1/0/all/0/1&quot;&gt;Pasquale Minervini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dettmers_T/0/1/0/all/0/1&quot;&gt;Tim Dettmers&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Augenstein_I/0/1/0/all/0/1&quot;&gt;Isabelle Augenstein&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Welbl_J/0/1/0/all/0/1&quot;&gt;Johannes Welbl&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rocktaschel_T/0/1/0/all/0/1&quot;&gt;Tim Rockt&amp;#xe4;schel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bosnjak_M/0/1/0/all/0/1&quot;&gt;Matko Bo&amp;#x161;njak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mitchell_J/0/1/0/all/0/1&quot;&gt;Jeff Mitchell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Demeester_T/0/1/0/all/0/1&quot;&gt;Thomas Demeester&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stenetorp_P/0/1/0/all/0/1&quot;&gt;Pontus Stenetorp&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Riedel_S/0/1/0/all/0/1&quot;&gt;Sebastian Riedel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.08748">
<title>Persistent Hidden States and Nonlinear Transformation for Long Short-Term Memory. (arXiv:1806.08748v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1806.08748</link>
<description rdf:parseType="Literal">&lt;p&gt;Recurrent neural networks (RNNs) have been drawing much attention with great
success in many applications like speech recognition and neural machine
translation. Long short-term memory (LSTM) is one of the most popular RNN units
in deep learning applications. LSTM transforms the input and the previous
hidden states to the next states with the affine transformation, multiplication
operations and a nonlinear activation function, which makes a good data
representation for a given task. The affine transformation includes rotation
and reflection, which change the semantic or syntactic information of
dimensions in the hidden states. However, considering that a model interprets
the output sequence of LSTM over the whole input sequence, the dimensions of
the states need to keep the same type of semantic or syntactic information
regardless of the location in the sequence. In this paper, we propose a simple
variant of the LSTM unit, persistent recurrent unit (PRU), where each dimension
of hidden states keeps persistent information across time, so that the space
keeps the same meaning over the whole sequence. In addition, to improve the
nonlinear transformation power, we add a feedforward layer in the PRU
structure. In the experiment, we evaluate our proposed methods with three
different tasks, and the results confirm that our methods have better
performance than the conventional LSTM.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Choi_H/0/1/0/all/0/1&quot;&gt;Heeyoul Choi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.01312">
<title>Learning Sparse Neural Networks through $L_0$ Regularization. (arXiv:1712.01312v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1712.01312</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a practical method for $L_0$ norm regularization for neural
networks: pruning the network during training by encouraging weights to become
exactly zero. Such regularization is interesting since (1) it can greatly speed
up training and inference, and (2) it can improve generalization. AIC and BIC,
well-known model selection criteria, are special cases of $L_0$ regularization.
However, since the $L_0$ norm of weights is non-differentiable, we cannot
incorporate it directly as a regularization term in the objective function. We
propose a solution through the inclusion of a collection of non-negative
stochastic gates, which collectively determine which weights to set to zero. We
show that, somewhat surprisingly, for certain distributions over the gates, the
expected $L_0$ norm of the resulting gated weights is differentiable with
respect to the distribution parameters. We further propose the \emph{hard
concrete} distribution for the gates, which is obtained by &quot;stretching&quot; a
binary concrete distribution and then transforming its samples with a
hard-sigmoid. The parameters of the distribution over the gates can then be
jointly optimized with the original network parameters. As a result our method
allows for straightforward and efficient learning of model structures with
stochastic gradient descent and allows for conditional computation in a
principled way. We perform various experiments to demonstrate the effectiveness
of the resulting approach and regularizer.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Louizos_C/0/1/0/all/0/1&quot;&gt;Christos Louizos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Welling_M/0/1/0/all/0/1&quot;&gt;Max Welling&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kingma_D/0/1/0/all/0/1&quot;&gt;Diederik P. Kingma&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.03334">
<title>Learning Localized Spatio-Temporal Models From Streaming Data. (arXiv:1802.03334v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1802.03334</link>
<description rdf:parseType="Literal">&lt;p&gt;We address the problem of predicting spatio-temporal processes with temporal
patterns that vary across spatial regions, when data is obtained as a stream.
That is, when the training dataset is augmented sequentially. Specifically, we
develop a localized spatio-temporal covariance model of the process that can
capture spatially varying temporal periodicities in the data. We then apply a
covariance-fitting methodology to learn the model parameters which yields a
predictor that can be updated sequentially with each new data point. The
proposed method is evaluated using both synthetic and real climate data which
demonstrate its ability to accurately predict data missing in spatial regions
over time.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Osama_M/0/1/0/all/0/1&quot;&gt;Muhammad Osama&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zachariah_D/0/1/0/all/0/1&quot;&gt;Dave Zachariah&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Schon_T/0/1/0/all/0/1&quot;&gt;Thomas B. Sch&amp;#xf6;n&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.00236">
<title>Recognizing Challenging Handwritten Annotations with Fully Convolutional Networks. (arXiv:1804.00236v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1804.00236</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper introduces a very challenging dataset of historic German documents
and evaluates Fully Convolutional Neural Network (FCNN) based methods to locate
handwritten annotations of any kind in these documents. The handwritten
annotations can appear in form of underlines and text by using various writing
instruments, e.g., the use of pencils makes the data more challenging. We train
and evaluate various end-to-end semantic segmentation approaches and report the
results. The task is to classify the pixels of documents into two classes:
background and handwritten annotation. The best model achieves a mean
Intersection over Union (IoU) score of 95.6% on the test documents of the
presented dataset. We also present a comparison of different strategies used
for data augmentation and training on our presented dataset. For evaluation, we
use the Layout Analysis Evaluator for the ICDAR 2017 Competition on Layout
Analysis for Challenging Medieval Manuscripts.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kolsch_A/0/1/0/all/0/1&quot;&gt;Andreas K&amp;#xf6;lsch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mishra_A/0/1/0/all/0/1&quot;&gt;Ashutosh Mishra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Varshneya_S/0/1/0/all/0/1&quot;&gt;Saurabh Varshneya&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Afzal_M/0/1/0/all/0/1&quot;&gt;Muhammad Zeshan Afzal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liwicki_M/0/1/0/all/0/1&quot;&gt;Marcus Liwicki&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.07528">
<title>Uncertainty in Multitask Transfer Learning. (arXiv:1806.07528v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1806.07528</link>
<description rdf:parseType="Literal">&lt;p&gt;Using variational Bayes neural networks, we develop an algorithm capable of
accumulating knowledge into a prior from multiple different tasks. The result
is a rich and meaningful prior capable of few-shot learning on new tasks. The
posterior can go beyond the mean field approximation and yields good
uncertainty on the performed experiments. Analysis on toy tasks shows that it
can learn from significantly different tasks while finding similarities among
them. Experiments of Mini-Imagenet yields the new state of the art with 74.5%
accuracy on 5 shot learning. Finally, we provide experiments showing that other
existing methods can fail to perform well in different benchmarks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lacoste_A/0/1/0/all/0/1&quot;&gt;Alexandre Lacoste&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Oreshkin_B/0/1/0/all/0/1&quot;&gt;Boris Oreshkin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chung_W/0/1/0/all/0/1&quot;&gt;Wonchang Chung&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Boquet_T/0/1/0/all/0/1&quot;&gt;Thomas Boquet&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rostamzadeh_N/0/1/0/all/0/1&quot;&gt;Negar Rostamzadeh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Krueger_D/0/1/0/all/0/1&quot;&gt;David Krueger&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.07537">
<title>DeepAffinity: Interpretable Deep Learning of Compound-Protein Affinity through Unified Recurrent and Convolutional Neural Networks. (arXiv:1806.07537v1 [q-bio.BM] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1806.07537</link>
<description rdf:parseType="Literal">&lt;p&gt;Motivation: Drug discovery demands rapid quantification of compound-protein
interaction (CPI). However, there is a lack of methods that can predict
compound-protein affinity from sequences alone with high applicability,
accuracy, and interpretability.
&lt;/p&gt;
&lt;p&gt;Results: We present a seamless integration of domain knowledges and
learning-based approaches. Under novel representations of
structurally-annotated protein sequences, a semi-supervised deep learning model
that unifies recurrent and convolutional neural networks has been proposed to
exploit both unlabeled and labeled data, for jointly encoding molecular
representations and predicting affinities. Our representations and models
outperform conventional options in achieving relative error in IC50 within
5-fold for test cases and 10-fold for protein classes not included for
training. Performances for new protein classes with few labeled data are
further improved by transfer learning. Furthermore, an attention mechanism is
embedded to our model to add to its interpretability, as illustrated in case
studies for predicting and explaining selective drug-target interactions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Karimi_M/0/1/0/all/0/1&quot;&gt;Mostafa Karimi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Wu_D/0/1/0/all/0/1&quot;&gt;Di Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zhangyang Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Shen_Y/0/1/0/all/0/1&quot;&gt;Yang Shen&lt;/a&gt;</dc:creator>
</item></rdf:RDF>