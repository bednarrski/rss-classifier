<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Good papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Good Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-01-09T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.02668"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.02832"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.02852"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1703.10316"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1706.07230"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.08296"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.09943"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.02642"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.02850"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.02929"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1707.08600"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.00632"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1801.02668">
<title>Evorus: A Crowd-powered Conversational Assistant Built to Automate Itself Over Time. (arXiv:1801.02668v1 [cs.HC])</title>
<link>http://arxiv.org/abs/1801.02668</link>
<description rdf:parseType="Literal">&lt;p&gt;Crowd-powered conversational assistants have been shown to be more robust
than automated systems, but do so at the cost of higher response latency and
monetary costs. A promising direction is to combine the two approaches for high
quality, low latency, and low cost solutions. In this paper, we introduce
Evorus, a crowd-powered conversational assistant built to automate itself over
time by (i) allowing new chatbots to be easily integrated to automate more
scenarios, (ii) reusing prior crowd answers, and (iii) learning to
automatically approve response candidates. Our 5-month-long deployment with 80
participants and 281 conversations shows that Evorus can automate itself
without compromising conversation quality. Crowd-AI architectures have long
been proposed as a way to reduce cost and latency for crowd-powered systems;
Evorus demonstrates how automation can be introduced successfully in a deployed
system. Its architecture allows future researchers to make further innovation
on the underlying automated components in the context of a deployed open domain
dialog system.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_T/0/1/0/all/0/1&quot;&gt;Ting-Hao &amp;#x27;Kenneth&amp;#x27; Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chang_J/0/1/0/all/0/1&quot;&gt;Joseph Chee Chang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bigham_J/0/1/0/all/0/1&quot;&gt;Jeffrey P. Bigham&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.02832">
<title>Biomedical Question Answering via Weighted Neural Network Passage Retrieval. (arXiv:1801.02832v1 [cs.IR])</title>
<link>http://arxiv.org/abs/1801.02832</link>
<description rdf:parseType="Literal">&lt;p&gt;The amount of publicly available biomedical literature has been growing
rapidly in recent years, yet question answering systems still struggle to
exploit the full potential of this source of data. In a preliminary processing
step, many question answering systems rely on retrieval models for identifying
relevant documents and passages. This paper proposes a weighted cosine distance
retrieval scheme based on neural network word embeddings. Our experiments are
based on publicly available data and tasks from the BioASQ biomedical question
answering challenge and demonstrate significant performance gains over a wide
range of state-of-the-art models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Galko_F/0/1/0/all/0/1&quot;&gt;Ferenc Galk&amp;#xf3;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Eickhoff_C/0/1/0/all/0/1&quot;&gt;Carsten Eickhoff&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.02852">
<title>Distributed Deep Reinforcement Learning: Learn how to play Atari games in 21 minutes. (arXiv:1801.02852v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1801.02852</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a study in Distributed Deep Reinforcement Learning (DDRL) focused
on scalability of a state-of-the-art Deep Reinforcement Learning algorithm
known as Batch Asynchronous Advantage ActorCritic (BA3C). We show that using
the Adam optimization algorithm with a batch size of up to 2048 is a viable
choice for carrying out large scale machine learning computations. This,
combined with careful reexamination of the optimizer&apos;s hyperparameters, using
synchronous training on the node level (while keeping the local, single node
part of the algorithm asynchronous) and minimizing the memory footprint of the
model, allowed us to achieve linear scaling for up to 64 CPU nodes. This
corresponds to a training time of 21 minutes on 768 CPU cores, as opposed to 10
hours when using a single node with 24 cores achieved by a baseline single-node
implementation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Adamski_I/0/1/0/all/0/1&quot;&gt;Igor Adamski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Adamski_R/0/1/0/all/0/1&quot;&gt;Robert Adamski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grel_T/0/1/0/all/0/1&quot;&gt;Tomasz Grel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jedrych_A/0/1/0/all/0/1&quot;&gt;Adam J&amp;#x119;drych&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kaczmarek_K/0/1/0/all/0/1&quot;&gt;Kamil Kaczmarek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Michalewski_H/0/1/0/all/0/1&quot;&gt;Henryk Michalewski&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1703.10316">
<title>Efficient Parallel Translating Embedding For Knowledge Graphs. (arXiv:1703.10316v4 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1703.10316</link>
<description rdf:parseType="Literal">&lt;p&gt;Knowledge graph embedding aims to embed entities and relations of knowledge
graphs into low-dimensional vector spaces. Translating embedding methods regard
relations as the translation from head entities to tail entities, which achieve
the state-of-the-art results among knowledge graph embedding methods. However,
a major limitation of these methods is the time consuming training process,
which may take several days or even weeks for large knowledge graphs, and
result in great difficulty in practical applications. In this paper, we propose
an efficient parallel framework for translating embedding methods, called
ParTrans-X, which enables the methods to be paralleled without locks by
utilizing the distinguished structures of knowledge graphs. Experiments on two
datasets with three typical translating embedding methods, i.e., TransE [3],
TransH [17], and a more efficient variant TransE- AdaGrad [10] validate that
ParTrans-X can speed up the training process by more than an order of
magnitude.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1&quot;&gt;Denghui Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1&quot;&gt;Manling Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jia_Y/0/1/0/all/0/1&quot;&gt;Yantao Jia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yuanzhuo Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1&quot;&gt;Xueqi Cheng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1706.07230">
<title>Gated-Attention Architectures for Task-Oriented Language Grounding. (arXiv:1706.07230v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1706.07230</link>
<description rdf:parseType="Literal">&lt;p&gt;To perform tasks specified by natural language instructions, autonomous
agents need to extract semantically meaningful representations of language and
map it to visual elements and actions in the environment. This problem is
called task-oriented language grounding. We propose an end-to-end trainable
neural architecture for task-oriented language grounding in 3D environments
which assumes no prior linguistic or perceptual knowledge and requires only raw
pixels from the environment and the natural language instruction as input. The
proposed model combines the image and text representations using a
Gated-Attention mechanism and learns a policy to execute the natural language
instruction using standard reinforcement and imitation learning methods. We
show the effectiveness of the proposed model on unseen instructions as well as
unseen maps, both quantitatively and qualitatively. We also introduce a novel
environment based on a 3D game engine to simulate the challenges of
task-oriented language grounding over a rich set of instructions and
environment states.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chaplot_D/0/1/0/all/0/1&quot;&gt;Devendra Singh Chaplot&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sathyendra_K/0/1/0/all/0/1&quot;&gt;Kanthashree Mysore Sathyendra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pasumarthi_R/0/1/0/all/0/1&quot;&gt;Rama Kumar Pasumarthi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rajagopal_D/0/1/0/all/0/1&quot;&gt;Dheeraj Rajagopal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Salakhutdinov_R/0/1/0/all/0/1&quot;&gt;Ruslan Salakhutdinov&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.08296">
<title>Intelligent Device Discovery in the Internet of Things - Enabling the Robot Society. (arXiv:1712.08296v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1712.08296</link>
<description rdf:parseType="Literal">&lt;p&gt;The Internet of Things (IoT) is continuously growing to connect billions of
smart devices anywhere and anytime in an Internet-like structure, which enables
a variety of applications, services and interactions between human and objects.
In the future, the smart devices are supposed to be able to autonomously
discover a target device with desired features and generate a set of entirely
new services and applications that are not supervised or even imagined by human
beings. The pervasiveness of smart devices, as well as the heterogeneity of
their design and functionalities, raise a major concern: How can a smart device
efficiently discover a desired target device? In this paper, we propose a
Social-Aware and Distributed (SAND) scheme that achieves a fast, scalable and
efficient device discovery in the IoT. The proposed SAND scheme adopts a novel
device ranking criteria that measures the device&apos;s degree, social relationship
diversity, clustering coefficient and betweenness. Based on the device ranking
criteria, the discovery request can be guided to travel through critical
devices that stand at the major intersections of the network, and thus quickly
reach the desired target device by contacting only a limited number of
intermediate devices. With the help of such an intelligent device discovery as
SAND, the IoT devices, as well as other computing facilities, software and data
on the Internet, can autonomously establish new social connections with each
other as human being do. They can formulate self-organized computing groups to
perform required computing tasks, facilitate a fusion of a variety of computing
service, network service and data to generate novel applications and services,
evolve from the individual aritificial intelligence to the collaborative
intelligence, and eventually enable the birth of a robot society.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sunthonlap_J/0/1/0/all/0/1&quot;&gt;James Sunthonlap&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_P/0/1/0/all/0/1&quot;&gt;Phuoc Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ye_Z/0/1/0/all/0/1&quot;&gt;Zilong Ye&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.09943">
<title>Toward Continual Learning for Conversational Agents. (arXiv:1712.09943v3 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1712.09943</link>
<description rdf:parseType="Literal">&lt;p&gt;While end-to-end neural conversation models have led to promising advances in
reducing hand-crafted features and errors induced by the traditional complex
system architecture, they typically require an enormous amount of data due to
the lack of modularity. Previous studies adopted a hybrid approach with
knowledge-based components either to abstract out domain-specific information
or to augment data to cover more diverse patterns. On the contrary, we propose
to directly address the problem using recent developments in the space of
continual learning for neural models. Specifically, we adopt a
domain-independent neural conversational model and introduce a novel neural
continual learning algorithm that allows a conversational agent to accumulate
skills across different tasks in a data-efficient way. To the best of our
knowledge, this is the first work that applies continual learning to
conversation systems. We verified the efficacy of our method through a
conversational skill transfer from either synthetic dialogs or human-human
dialogs to human-computer conversations in a customer support domain.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1&quot;&gt;Sungjin Lee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.02642">
<title>Boundary Optimizing Network (BON). (arXiv:1801.02642v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1801.02642</link>
<description rdf:parseType="Literal">&lt;p&gt;Despite all the success that deep neural networks have seen in classifying
certain datasets, the challenge of finding optimal solutions that generalize
well still remains. In this paper, we propose the Boundary Optimizing Network
(BON), a new approach to generalization for deep neural networks when used for
supervised learning. Given a classification network, we propose to use a
collaborative generative network that produces new synthetic data points in the
form of perturbations of original data points. In this way, we create a data
support around each original data point which prevents decision boundaries to
pass too close to the original data points, i.e. prevents overfitting. To
prevent catastrophic forgetting during training, we propose to use a variation
of Memory Aware Synapses to optimize the generative networks. On the Iris
dataset, we show that the BON algorithm creates better decision boundaries when
compared to a network regularized by the popular dropout scheme.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singh_M/0/1/0/all/0/1&quot;&gt;Marco Singh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pai_A/0/1/0/all/0/1&quot;&gt;Akshay Pai&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.02850">
<title>Less is More: Culling the Training Set to Improve Robustness of Deep Neural Networks. (arXiv:1801.02850v1 [cs.CR])</title>
<link>http://arxiv.org/abs/1801.02850</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep neural networks are vulnerable to adversarial examples. Prior defenses
attempted to make deep networks more robust by either improving the network
architecture or adding adversarial examples into the training set, with their
respective limitations. We propose a new direction. Motivated by recent
research that shows that outliers in the training set have a high negative
influence on the trained model, our approach makes the model more robust by
detecting and removing outliers in the training set without modifying the
network architecture or requiring adversarial examples. We propose two methods
for detecting outliers based on canonical examples and on training errors,
respectively. After removing the outliers, we train the classifier with the
remaining examples to obtain a sanitized model. Our evaluation shows that the
sanitized model improves classification accuracy and forces the attacks to
generate adversarial examples with higher distortions. Moreover, the
Kullback-Leibler divergence from the output of the original model to that of
the sanitized model allows us to distinguish between normal and adversarial
examples reliably.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yongshuai Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1&quot;&gt;Jiyu Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1&quot;&gt;Hao Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.02929">
<title>Data Augmentation by Pairing Samples for Images Classification. (arXiv:1801.02929v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1801.02929</link>
<description rdf:parseType="Literal">&lt;p&gt;Data augmentation is a widely used technique in many machine learning tasks,
such as image classification, to virtually enlarge the training dataset size
and avoid overfitting. Traditional data augmentation techniques for image
classification tasks create new samples from the original training data by, for
example, flipping, distorting, adding a small amount of noise to, or cropping a
patch from an original image. In this paper, we introduce a simple but
surprisingly effective data augmentation technique for image classification
tasks. With our technique, named SamplePairing, we synthesize a new sample from
one image by overlaying another image randomly chosen from the training data
(i.e., taking an average of two images for each pixel). By using two images
randomly selected from the training set, we can generate $N^2$ new samples from
$N$ training samples. This simple data augmentation technique significantly
improved classification accuracy for all the tested datasets; for example, the
top-1 error rate was reduced from 33.5% to 29.0% for the ILSVRC 2012 dataset
with GoogLeNet and from 8.22% to 6.93% in the CIFAR-10 dataset. We also show
that our SamplePairing technique largely improved accuracy when the number of
samples in the training set was very small. Therefore, our technique is more
valuable for tasks with a limited amount of training data, such as medical
imaging tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Inoue_H/0/1/0/all/0/1&quot;&gt;Hiroshi Inoue&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1707.08600">
<title>Pileup Mitigation with Machine Learning (PUMML). (arXiv:1707.08600v3 [hep-ph] UPDATED)</title>
<link>http://arxiv.org/abs/1707.08600</link>
<description rdf:parseType="Literal">&lt;p&gt;Pileup involves the contamination of the energy distribution arising from the
primary collision of interest (leading vertex) by radiation from soft
collisions (pileup). We develop a new technique for removing this contamination
using machine learning and convolutional neural networks. The network takes as
input the energy distribution of charged leading vertex particles, charged
pileup particles, and all neutral particles and outputs the energy distribution
of particles coming from leading vertex alone. The PUMML algorithm performs
remarkably well at eliminating pileup distortion on a wide range of simple and
complex jet observables. We test the robustness of the algorithm in a number of
ways and discuss how the network can be trained directly on data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/hep-ph/1/au:+Komiske_P/0/1/0/all/0/1&quot;&gt;Patrick T. Komiske&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/hep-ph/1/au:+Metodiev_E/0/1/0/all/0/1&quot;&gt;Eric M. Metodiev&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/hep-ph/1/au:+Nachman_B/0/1/0/all/0/1&quot;&gt;Benjamin Nachman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/hep-ph/1/au:+Schwartz_M/0/1/0/all/0/1&quot;&gt;Matthew D. Schwartz&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.00632">
<title>Character-level Recurrent Neural Networks in Practice: Comparing Training and Sampling Schemes. (arXiv:1801.00632v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1801.00632</link>
<description rdf:parseType="Literal">&lt;p&gt;Recurrent neural networks are nowadays successfully used in an abundance of
applications, going from text, speech and image processing to recommender
systems. Backpropagation through time is the algorithm that is commonly used to
train these networks on specific tasks. Many deep learning frameworks have
their own implementation of training and sampling procedures for recurrent
neural networks, while there are in fact multiple other possibilities to choose
from and other parameters to tune. In existing literature this is very often
overlooked or ignored. In this paper we therefore give an overview of possible
training and sampling schemes for character-level recurrent neural networks to
solve the task of predicting the next token in a given sequence. We test these
different schemes on a variety of datasets, neural network architectures and
parameter settings, and formulate a number of take-home recommendations. The
choice of training and sampling scheme turns out to be subject to a number of
trade-offs, such as training stability, sampling time, model performance and
implementation effort, but is largely independent of the data. Perhaps the most
surprising result is that transferring hidden states for correctly initializing
the model on subsequences often leads to unstable training behavior depending
on the dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Boom_C/0/1/0/all/0/1&quot;&gt;Cedric De Boom&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Demeester_T/0/1/0/all/0/1&quot;&gt;Thomas Demeester&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dhoedt_B/0/1/0/all/0/1&quot;&gt;Bart Dhoedt&lt;/a&gt;</dc:creator>
</item></rdf:RDF>