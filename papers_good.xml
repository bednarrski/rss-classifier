<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Good papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Good Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-06-04T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00526"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00628"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00851"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.12152"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.06055"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00588"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00608"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00683"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00738"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00770"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00778"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00805"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00807"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00852"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00931"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00949"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.01203"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.01246"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.01258"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.01261"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1402.6208"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1705.06366"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1708.07580"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.01968"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07798"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10528"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00509"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00572"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00580"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00582"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00630"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00650"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00681"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00711"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00804"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00826"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00900"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00914"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00919"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00989"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.01010"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.01182"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.01833"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.02350"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.03616"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09039"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1806.00526">
<title>Multi-Step Prediction of Dynamic Systems with Recurrent Neural Networks. (arXiv:1806.00526v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1806.00526</link>
<description rdf:parseType="Literal">&lt;p&gt;Recurrent Neural Networks (RNNs) can encode rich dynamics which makes them
suitable for modeling dynamic systems. To train an RNN for multi-step
prediction of dynamic systems, it is crucial to efficiently address the state
initialization problem, which seeks proper values for the RNN initial states at
the beginning of each prediction interval. In this work, the state
initialization problem is addressed using Neural Networks (NNs) to effectively
train a variety of RNNs for modeling two aerial vehicles, a helicopter and a
quadrotor, from experimental data. It is shown that the RNN initialized by the
NN-based initialization method outperforms the state of the art. Further, a
comprehensive study of RNNs trained for multi-step prediction of the two aerial
vehicles is presented. The multi-step prediction of the quadrotor is enhanced
using a hybrid model which combines a simplified physics-based motion model of
the vehicle with RNNs. While the maximum translational and rotational
velocities in the quadrotor dataset are about 4 m/s and 3.8 rad/s,
respectively, the hybrid model produces predictions, over 1.9 second, which
remain within 9 cm/s and 0.12 rad/s of the measured translational and
rotational velocities, with 99\% confidence on the test dataset
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mohajerin_N/0/1/0/all/0/1&quot;&gt;Nima Mohajerin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Waslander_S/0/1/0/all/0/1&quot;&gt;Steven L. Waslander&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00628">
<title>A Novel Framework for Recurrent Neural Networks with Enhancing Information Processing and Transmission between Units. (arXiv:1806.00628v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1806.00628</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper proposes a novel framework for recurrent neural networks (RNNs)
inspired by the human memory models in the field of cognitive neuroscience to
enhance information processing and transmission between adjacent RNNs&apos; units.
The proposed framework for RNNs consists of three stages that is working
memory, forget, and long-term store. The first stage includes taking input data
into sensory memory and transferring it to working memory for preliminary
treatment. And the second stage mainly focuses on proactively forgetting the
secondary information rather than the primary in the working memory. And
finally, we get the long-term store normally using some kind of RNN&apos;s unit. Our
framework, which is generalized and simple, is evaluated on 6 datasets which
fall into 3 different tasks, corresponding to text classification, image
classification and language modelling. Experiments reveal that our framework
can obviously improve the performance of traditional recurrent neural networks.
And exploratory task shows the ability of our framework of correctly forgetting
the secondary information.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1&quot;&gt;Xi Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deng_Z/0/1/0/all/0/1&quot;&gt;Zhihong Deng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_G/0/1/0/all/0/1&quot;&gt;Gehui Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_T/0/1/0/all/0/1&quot;&gt;Ting Huang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00851">
<title>An Aggressive Genetic Programming Approach for Searching Neural Network Structure Under Computational Constraints. (arXiv:1806.00851v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1806.00851</link>
<description rdf:parseType="Literal">&lt;p&gt;Recently, there emerged revived interests of designing automatic programs
(e.g., using genetic/evolutionary algorithms) to optimize the structure of
Convolutional Neural Networks (CNNs) for a specific task. The challenge in
designing such programs lies in how to balance between large search space of
the network structures and high computational costs. Existing works either
impose strong restrictions on the search space or use enormous computing
resources. In this paper, we study how to design a genetic programming approach
for optimizing the structure of a CNN for a given task under limited
computational resources yet without imposing strong restrictions on the search
space. To reduce the computational costs, we propose two general strategies
that are observed to be helpful: (i) aggressively selecting strongest
individuals for survival and reproduction, and killing weaker individuals at a
very early age; (ii) increasing mutation frequency to encourage diversity and
faster evolution. The combined strategy with additional optimization techniques
allows us to explore a large search space but with affordable computational
costs. Our results on standard benchmark datasets (MNIST, SVHN, CIFAR-10,
CIFAR-100) are competitive to similar approaches with significantly reduced
computational costs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Zhe Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiong_X/0/1/0/all/0/1&quot;&gt;Xuehan Xiong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ren_Z/0/1/0/all/0/1&quot;&gt;Zhou Ren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_N/0/1/0/all/0/1&quot;&gt;Ning Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;Xiaoyu Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_T/0/1/0/all/0/1&quot;&gt;Tianbao Yang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.12152">
<title>There Is No Free Lunch In Adversarial Robustness (But There Are Unexpected Benefits). (arXiv:1805.12152v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1805.12152</link>
<description rdf:parseType="Literal">&lt;p&gt;We provide a new understanding of the fundamental nature of adversarially
robust classifiers and how they differ from standard models. In particular, we
show that there provably exists a trade-off between the standard accuracy of a
model and its robustness to adversarial perturbations. We demonstrate an
intriguing phenomenon at the root of this tension: a certain dichotomy between
&quot;robust&quot; and &quot;non-robust&quot; features. We show that while robustness comes at a
price, it also has some surprising benefits. Robust models turn out to have
interpretable gradients and feature representations that align unusually well
with salient data characteristics. In fact, they yield striking feature
interpolations that have thus far been possible to obtain only using generative
models such as GANs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tsipras_D/0/1/0/all/0/1&quot;&gt;Dimitris Tsipras&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Santurkar_S/0/1/0/all/0/1&quot;&gt;Shibani Santurkar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Engstrom_L/0/1/0/all/0/1&quot;&gt;Logan Engstrom&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Turner_A/0/1/0/all/0/1&quot;&gt;Alexander Turner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Madry_A/0/1/0/all/0/1&quot;&gt;Aleksander Madry&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.06055">
<title>Evolution in Virtual Worlds. (arXiv:1710.06055v1 [cs.NE] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1710.06055</link>
<description rdf:parseType="Literal">&lt;p&gt;This chapter discusses the possibility of instilling a virtual world with
mechanisms for evolution and natural selection in order to generate rich
ecosystems of complex organisms in a process akin to biological evolution. Some
previous work in the area is described, and successes and failures are
discussed. The components of a more comprehensive framework for designing such
worlds are mapped out, including the design of the individual organisms, the
properties and dynamics of the environmental medium in which they are evolving,
and the representational relationship between organism and environment. Some of
the key issues discussed include how to allow organisms to evolve new
structures and functions with few restrictions, and how to create an
interconnectedness between organisms in order to generate drives for continuing
evolutionary activity.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Taylor_T/0/1/0/all/0/1&quot;&gt;Tim Taylor&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00588">
<title>Fast Locality Sensitive Hashing for Beam Search on GPU. (arXiv:1806.00588v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1806.00588</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a GPU-based Locality Sensitive Hashing (LSH) algorithm to speed up
beam search for sequence models. We utilize the winner-take-all (WTA) hash,
which is based on relative ranking order of hidden dimensions and thus
resilient to perturbations in numerical values. Our algorithm is designed by
fully considering the underling architecture of CUDA-enabled GPUs
(Algorithm/Architecture Co-design): 1) A parallel Cuckoo hash table is applied
for LSH code lookup (guaranteed O(1) lookup time); 2) Candidate lists are
shared across beams to maximize the parallelism; 3) Top frequent words are
merged into candidate lists to improve performance. Experiments on 4
large-scale neural machine translation models demonstrate that our algorithm
can achieve up to 4x speedup on softmax module, and 2x overall speedup without
hurting BLEU on GPU.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_X/0/1/0/all/0/1&quot;&gt;Xing Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1&quot;&gt;Shizhen Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Knight_K/0/1/0/all/0/1&quot;&gt;Kevin Knight&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00608">
<title>GamePad: A Learning Environment for Theorem Proving. (arXiv:1806.00608v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.00608</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we introduce a system called GamePad that can be used to
explore the application of machine learning methods to theorem proving in the
Coq proof assistant. Interactive theorem provers such as Coq enable users to
construct machine-checkable proofs in a step-by-step manner. Hence, they
provide an opportunity to explore theorem proving at a human level of
abstraction. We use GamePad to synthesize proofs for a simple algebraic rewrite
problem and train baseline models for a formalization of the Feit-Thompson
theorem. We address position evaluation (i.e., predict the number of proof
steps left) and tactic prediction (i.e., predict the next proof step) tasks,
which arise naturally in human-level theorem proving.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_D/0/1/0/all/0/1&quot;&gt;Daniel Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dhariwal_P/0/1/0/all/0/1&quot;&gt;Prafulla Dhariwal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_D/0/1/0/all/0/1&quot;&gt;Dawn Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sutskever_I/0/1/0/all/0/1&quot;&gt;Ilya Sutskever&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00683">
<title>Deep Pepper: Expert Iteration based Chess agent in the Reinforcement Learning Setting. (arXiv:1806.00683v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1806.00683</link>
<description rdf:parseType="Literal">&lt;p&gt;An almost-perfect chess playing agent has been a long standing challenge in
the field of Artificial Intelligence. Some of the recent advances demonstrate
we are approaching that goal. In this project, we provide methods for faster
training of self-play style algorithms, mathematical details of the algorithm
used, various potential future directions, and discuss most of the relevant
work in the area of computer chess. Deep Pepper uses embedded knowledge to
accelerate the training of the chess engine over a &quot;tabula rasa&quot; system such as
Alpha Zero. We also release our code to promote further research.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+V%2E_S/0/1/0/all/0/1&quot;&gt;Sai Krishna G.V.&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goyette_K/0/1/0/all/0/1&quot;&gt;Kyle Goyette&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chamseddine_A/0/1/0/all/0/1&quot;&gt;Ahmad Chamseddine&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Considine_B/0/1/0/all/0/1&quot;&gt;Breandan Considine&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00738">
<title>Contextualize, Show and Tell: A Neural Visual Storyteller. (arXiv:1806.00738v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1806.00738</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a neural model for generating short stories from image sequences,
which extends the image description model by Vinyals et al. (Vinyals et al.,
2015). This extension relies on an encoder LSTM to compute a context vector of
each story from the image sequence. This context vector is used as the first
state of multiple independent decoder LSTMs, each of which generates the
portion of the story corresponding to each image in the sequence by taking the
image embedding as the first input. Our model showed competitive results with
the METEOR metric and human ratings in the internal track of the Visual
Storytelling Challenge 2018.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gonzalez_Rico_D/0/1/0/all/0/1&quot;&gt;Diana Gonzalez-Rico&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fuentes_Pineda_G/0/1/0/all/0/1&quot;&gt;Gibran Fuentes-Pineda&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00770">
<title>Dual-Primal Graph Convolutional Networks. (arXiv:1806.00770v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.00770</link>
<description rdf:parseType="Literal">&lt;p&gt;In recent years, there has been a surge of interest in developing deep
learning methods for non-Euclidean structured data such as graphs. In this
paper, we propose Dual-Primal Graph CNN, a graph convolutional architecture
that alternates convolution-like operations on the graph and its dual. Our
approach allows to learn both vertex- and edge features and generalizes the
previous graph attention (GAT) model. We provide extensive experimental
validation showing state-of-the-art results on a variety of tasks tested on
established graph benchmarks, including CORA and Citeseer citation networks as
well as MovieLens, Flixter, Douban and Yahoo Music graph-guided recommender
systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Monti_F/0/1/0/all/0/1&quot;&gt;Federico Monti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shchur_O/0/1/0/all/0/1&quot;&gt;Oleksandr Shchur&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bojchevski_A/0/1/0/all/0/1&quot;&gt;Aleksandar Bojchevski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Litany_O/0/1/0/all/0/1&quot;&gt;Or Litany&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gunnemann_S/0/1/0/all/0/1&quot;&gt;Stephan G&amp;#xfc;nnemann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bronstein_M/0/1/0/all/0/1&quot;&gt;Michael M. Bronstein&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00778">
<title>Multi-Cast Attention Networks for Retrieval-based Question Answering and Response Prediction. (arXiv:1806.00778v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1806.00778</link>
<description rdf:parseType="Literal">&lt;p&gt;Attention is typically used to select informative sub-phrases that are used
for prediction. This paper investigates the novel use of attention as a form of
feature augmentation, i.e, casted attention. We propose Multi-Cast Attention
Networks (MCAN), a new attention mechanism and general model architecture for a
potpourri of ranking tasks in the conversational modeling and question
answering domains. Our approach performs a series of soft attention operations,
each time casting a scalar feature upon the inner word embeddings. The key idea
is to provide a real-valued hint (feature) to a subsequent encoder layer and is
targeted at improving the representation learning process. There are several
advantages to this design, e.g., it allows an arbitrary number of attention
mechanisms to be casted, allowing for multiple attention types (e.g.,
co-attention, intra-attention) and attention variants (e.g., alignment-pooling,
max-pooling, mean-pooling) to be executed simultaneously. This not only
eliminates the costly need to tune the nature of the co-attention layer, but
also provides greater extents of explainability to practitioners. Via extensive
experiments on four well-known benchmark datasets, we show that MCAN achieves
state-of-the-art performance. On the Ubuntu Dialogue Corpus, MCAN outperforms
existing state-of-the-art models by $9\%$. MCAN also achieves the best
performing score to date on the well-studied TrecQA dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tay_Y/0/1/0/all/0/1&quot;&gt;Yi Tay&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tuan_L/0/1/0/all/0/1&quot;&gt;Luu Anh Tuan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hui_S/0/1/0/all/0/1&quot;&gt;Siu Cheung Hui&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00805">
<title>Admissible Abstractions for Near-optimal Task and Motion Planning. (arXiv:1806.00805v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1806.00805</link>
<description rdf:parseType="Literal">&lt;p&gt;We define an admissibility condition for abstractions expressed using angelic
semantics and show that these conditions allow us to accelerate planning while
preserving the ability to find the optimal motion plan. We then derive
admissible abstractions for two motion planning domains with continuous state.
We extract upper and lower bounds on the cost of concrete motion plans using
local metric and topological properties of the problem domain. These bounds
guide the search for a plan while maintaining performance guarantees. We show
that abstraction can dramatically reduce the complexity of search relative to a
direct motion planner. Using our abstractions, we find near-optimal motion
plans in planning problems involving $10^{13}$ states without using a separate
task planner.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vega_Brown_W/0/1/0/all/0/1&quot;&gt;William Vega-Brown&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roy_N/0/1/0/all/0/1&quot;&gt;Nicholas Roy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00807">
<title>Learning Semantic Sentence Embeddings using Pair-wise Discriminator. (arXiv:1806.00807v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1806.00807</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we propose a method for obtaining sentence-level embeddings.
While the problem of securing word-level embeddings is very well studied, we
propose a novel method for obtaining sentence-level embeddings. This is
obtained by a simple method in the context of solving the paraphrase generation
task. If we use a sequential encoder-decoder model for generating paraphrase,
we would like the generated paraphrase to be semantically close to the original
sentence. One way to ensure this is by adding constraints for true paraphrase
embeddings to be close and unrelated paraphrase candidate sentence embeddings
to be far. This is ensured by using a sequential pair-wise discriminator that
shares weights with the encoder that is trained with a suitable loss function.
Our loss function penalizes paraphrase sentence embedding distances from being
too large. This loss is used in combination with a sequential encoder-decoder
network. We also validated our method by evaluating the obtained embeddings for
a sentiment analysis task. The proposed method results in semantic embeddings
and outperforms the state-of-the-art on the paraphrase generation and sentiment
analysis task on standard datasets. These results are also shown to be
statistically significant.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Patro_B/0/1/0/all/0/1&quot;&gt;Badri N. Patro&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kurmi_V/0/1/0/all/0/1&quot;&gt;Vinod K. Kurmi&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1&quot;&gt;Sandeep Kumar&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Namboodiri_V/0/1/0/all/0/1&quot;&gt;Vinay P. Namboodiri&lt;/a&gt; (1) ((1) Indian Institute of Technology, Kanpur)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00852">
<title>On the Importance of Attention in Meta-Learning for Few-Shot Text Classification. (arXiv:1806.00852v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.00852</link>
<description rdf:parseType="Literal">&lt;p&gt;Current deep learning based text classification methods are limited by their
ability to achieve fast learning and generalization when the data is scarce. We
address this problem by integrating a meta-learning procedure that uses the
knowledge learned across many tasks as an inductive bias towards better natural
language understanding. Based on the Model-Agnostic Meta-Learning framework
(MAML), we introduce the Attentive Task-Agnostic Meta-Learning (ATAML)
algorithm for text classification. The essential difference between MAML and
ATAML is in the separation of task-agnostic representation learning and
task-specific attentive adaptation. The proposed ATAML is designed to encourage
task-agnostic representation learning by way of task-agnostic parameterization
and facilitate task-specific adaptation via attention mechanisms. We provide
evidence to show that the attention mechanism in ATAML has a synergistic effect
on learning performance. In comparisons with models trained from random
initialization, pretrained models and meta trained MAML, our proposed ATAML
method generalizes better on single-label and multi-label classification tasks
in miniRCV1 and miniReuters-21578 datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_X/0/1/0/all/0/1&quot;&gt;Xiang Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Havaei_M/0/1/0/all/0/1&quot;&gt;Mohammad Havaei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chartrand_G/0/1/0/all/0/1&quot;&gt;Gabriel Chartrand&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chouaib_H/0/1/0/all/0/1&quot;&gt;Hassan Chouaib&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vincent_T/0/1/0/all/0/1&quot;&gt;Thomas Vincent&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jesson_A/0/1/0/all/0/1&quot;&gt;Andrew Jesson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chapados_N/0/1/0/all/0/1&quot;&gt;Nicolas Chapados&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Matwin_S/0/1/0/all/0/1&quot;&gt;Stan Matwin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00931">
<title>Holographic Neural Architectures. (arXiv:1806.00931v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.00931</link>
<description rdf:parseType="Literal">&lt;p&gt;Representation learning is at the heart of what makes deep learning
effective. In this work, we introduce a new framework for representation
learning that we call &quot;Holographic Neural Architectures&quot; (HNAs). In the same
way that an observer can experience the 3D structure of a holographed object by
looking at its hologram from several angles, HNAs derive Holographic
Representations from the training set. These representations can then be
explored by moving along a continuous bounded single dimension. We show that
HNAs can be used to make generative networks, state-of-the-art regression
models and that they are inherently highly resistant to noise. Finally, we
argue that because of their denoising abilities and their capacity to
generalize well from very few examples, models based upon HNAs are particularly
well suited for biological applications where training examples are rare or
noisy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Daouda_T/0/1/0/all/0/1&quot;&gt;Tariq Daouda&lt;/a&gt; (1 and 2 and 3), &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zumer_J/0/1/0/all/0/1&quot;&gt;Jeremie Zumer&lt;/a&gt; (1 and 4 and 3), &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Perreault_C/0/1/0/all/0/1&quot;&gt;Claude Perreault&lt;/a&gt; (1 and 5 and 3), &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lemieux_S/0/1/0/all/0/1&quot;&gt;S&amp;#xe9;bastien Lemieux&lt;/a&gt; (1 and 4 and 3) ((1) Institute for Research in Immunology and Cancer, (2) Department of biochemistry, (3) Universit&amp;#xe9; de Montr&amp;#xe9;al, (4) Department of Computer Science and Operations Research, (5) Department of Medicine)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00949">
<title>Private PAC learning implies finite Littlestone dimension. (arXiv:1806.00949v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.00949</link>
<description rdf:parseType="Literal">&lt;p&gt;We show that every approximately differentially private learning algorithm
(possibly improper) for a class $H$ with Littlestone dimension~$d$ requires
$\Omega\bigl(\log^*(d)\bigr)$ examples. As a corollary it follows that the
class of thresholds over $\mathbb{N}$ can not be learned in a private manner;
this resolves an open question due to [Bun et al. FOCS &apos;15]. We leave as an
open question whether every class with a finite Littlestone dimension can be
learned by an approximately differentially private algorithm.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alon_N/0/1/0/all/0/1&quot;&gt;Noga Alon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Livni_R/0/1/0/all/0/1&quot;&gt;Roi Livni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Malliaris_M/0/1/0/all/0/1&quot;&gt;Maryanthe Malliaris&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moran_S/0/1/0/all/0/1&quot;&gt;Shay Moran&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.01203">
<title>Relational inductive bias for physical construction in humans and machines. (arXiv:1806.01203v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.01203</link>
<description rdf:parseType="Literal">&lt;p&gt;While current deep learning systems excel at tasks such as object
classification, language processing, and gameplay, few can construct or modify
a complex system such as a tower of blocks. We hypothesize that what these
systems lack is a &quot;relational inductive bias&quot;: a capacity for reasoning about
inter-object relations and making choices over a structured description of a
scene. To test this hypothesis, we focus on a task that involves gluing pairs
of blocks together to stabilize a tower, and quantify how well humans perform.
We then introduce a deep reinforcement learning agent which uses object- and
relation-centric scene and policy representations and apply it to the task. Our
results show that these structured representations allow the agent to
outperform both humans and more naive approaches, suggesting that relational
inductive bias is an important component in solving structured reasoning
problems and for building more intelligent, flexible machines.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hamrick_J/0/1/0/all/0/1&quot;&gt;Jessica B. Hamrick&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Allen_K/0/1/0/all/0/1&quot;&gt;Kelsey R. Allen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bapst_V/0/1/0/all/0/1&quot;&gt;Victor Bapst&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_T/0/1/0/all/0/1&quot;&gt;Tina Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+McKee_K/0/1/0/all/0/1&quot;&gt;Kevin R. McKee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tenenbaum_J/0/1/0/all/0/1&quot;&gt;Joshua B. Tenenbaum&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Battaglia_P/0/1/0/all/0/1&quot;&gt;Peter W. Battaglia&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.01246">
<title>ML-Leaks: Model and Data Independent Membership Inference Attacks and Defenses on Machine Learning Models. (arXiv:1806.01246v1 [cs.CR])</title>
<link>http://arxiv.org/abs/1806.01246</link>
<description rdf:parseType="Literal">&lt;p&gt;Machine learning (ML) has become a core component of many real-world
applications and training data is a key factor that drives current progress.
This huge success has led Internet companies to deploy machine learning as a
service (MLaaS). Recently, the first membership inference attack has shown that
extraction of information on the training set is possible in such MLaaS
settings, which has severe security and privacy implications.
&lt;/p&gt;
&lt;p&gt;However, the early demonstrations of the feasibility of such attacks have
many assumptions on the adversary such as using multiple so-called shadow
models, knowledge of the target model structure and having a dataset from the
same distribution as the target model&apos;s training data. We relax all 3 key
assumptions, thereby showing that such attacks are very broadly applicable at
low cost and thereby pose a more severe risk than previously thought. We
present the most comprehensive study so far on this emerging and developing
threat using eight diverse datasets which show the viability of the proposed
attacks across domains.
&lt;/p&gt;
&lt;p&gt;In addition, we propose the first effective defense mechanisms against such
broader class of membership inference attacks that maintain a high level of
utility of the ML model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Salem_A/0/1/0/all/0/1&quot;&gt;Ahmed Salem&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yang Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Humbert_M/0/1/0/all/0/1&quot;&gt;Mathias Humbert&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fritz_M/0/1/0/all/0/1&quot;&gt;Mario Fritz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Backes_M/0/1/0/all/0/1&quot;&gt;Michael Backes&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.01258">
<title>Agreement-based Learning. (arXiv:1806.01258v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.01258</link>
<description rdf:parseType="Literal">&lt;p&gt;Model selection is a problem that has occupied machine learning researchers
for a long time. Recently, its importance has become evident through
applications in deep learning. We propose an agreement-based learning framework
that prevents many of the pitfalls associated with model selection. It relies
on coupling the training of multiple models by encouraging them to agree on
their predictions while training. In contrast with other model selection and
combination approaches used in machine learning, the proposed framework is
inspired by human learning. We also propose a learning algorithm defined within
this framework which manages to significantly outperform alternatives in
practice, and whose performance improves further with the availability of
unlabeled data. Finally, we describe a number of potential directions for
developing more flexible agreement-based learning algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Platanios_E/0/1/0/all/0/1&quot;&gt;Emmanouil Antonios Platanios&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.01261">
<title>Relational inductive biases, deep learning, and graph networks. (arXiv:1806.01261v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.01261</link>
<description rdf:parseType="Literal">&lt;p&gt;Artificial intelligence (AI) has undergone a renaissance recently, making
major progress in key domains such as vision, language, control, and
decision-making. This has been due, in part, to cheap data and cheap compute
resources, which have fit the natural strengths of deep learning. However, many
defining characteristics of human intelligence, which developed under much
different pressures, remain out of reach for current approaches. In particular,
generalizing beyond one&apos;s experiences--a hallmark of human intelligence from
infancy--remains a formidable challenge for modern AI.
&lt;/p&gt;
&lt;p&gt;The following is part position paper, part review, and part unification. We
argue that combinatorial generalization must be a top priority for AI to
achieve human-like abilities, and that structured representations and
computations are key to realizing this objective. Just as biology uses nature
and nurture cooperatively, we reject the false choice between
&quot;hand-engineering&quot; and &quot;end-to-end&quot; learning, and instead advocate for an
approach which benefits from their complementary strengths. We explore how
using relational inductive biases within deep learning architectures can
facilitate learning about entities, relations, and rules for composing them. We
present a new building block for the AI toolkit with a strong relational
inductive bias--the graph network--which generalizes and extends various
approaches for neural networks that operate on graphs, and provides a
straightforward interface for manipulating structured knowledge and producing
structured behaviors. We discuss how graph networks can support relational
reasoning and combinatorial generalization, laying the foundation for more
sophisticated, interpretable, and flexible patterns of reasoning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Battaglia_P/0/1/0/all/0/1&quot;&gt;Peter W. Battaglia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hamrick_J/0/1/0/all/0/1&quot;&gt;Jessica B. Hamrick&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bapst_V/0/1/0/all/0/1&quot;&gt;Victor Bapst&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sanchez_Gonzalez_A/0/1/0/all/0/1&quot;&gt;Alvaro Sanchez-Gonzalez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zambaldi_V/0/1/0/all/0/1&quot;&gt;Vinicius Zambaldi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Malinowski_M/0/1/0/all/0/1&quot;&gt;Mateusz Malinowski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tacchetti_A/0/1/0/all/0/1&quot;&gt;Andrea Tacchetti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Raposo_D/0/1/0/all/0/1&quot;&gt;David Raposo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Santoro_A/0/1/0/all/0/1&quot;&gt;Adam Santoro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Faulkner_R/0/1/0/all/0/1&quot;&gt;Ryan Faulkner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gulcehre_C/0/1/0/all/0/1&quot;&gt;Caglar Gulcehre&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_F/0/1/0/all/0/1&quot;&gt;Francis Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ballard_A/0/1/0/all/0/1&quot;&gt;Andrew Ballard&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gilmer_J/0/1/0/all/0/1&quot;&gt;Justin Gilmer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dahl_G/0/1/0/all/0/1&quot;&gt;George Dahl&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vaswani_A/0/1/0/all/0/1&quot;&gt;Ashish Vaswani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Allen_K/0/1/0/all/0/1&quot;&gt;Kelsey Allen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nash_C/0/1/0/all/0/1&quot;&gt;Charles Nash&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Langston_V/0/1/0/all/0/1&quot;&gt;Victoria Langston&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dyer_C/0/1/0/all/0/1&quot;&gt;Chris Dyer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Heess_N/0/1/0/all/0/1&quot;&gt;Nicolas Heess&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wierstra_D/0/1/0/all/0/1&quot;&gt;Daan Wierstra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kohli_P/0/1/0/all/0/1&quot;&gt;Pushmeet Kohli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Botvinick_M/0/1/0/all/0/1&quot;&gt;Matt Botvinick&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vinyals_O/0/1/0/all/0/1&quot;&gt;Oriol Vinyals&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yujia Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pascanu_R/0/1/0/all/0/1&quot;&gt;Razvan Pascanu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1402.6208">
<title>The Anatomy of a Modular System for Media Content Analysis. (arXiv:1402.6208v2 [cs.MA] UPDATED)</title>
<link>http://arxiv.org/abs/1402.6208</link>
<description rdf:parseType="Literal">&lt;p&gt;Intelligent systems for the annotation of media content are increasingly
being used for the automation of parts of social science research. In this
domain the problem of integrating various Artificial Intelligence (AI)
algorithms into a single intelligent system arises spontaneously. As part of
our ongoing effort in automating media content analysis for the social
sciences, we have built a modular system by combining multiple AI modules into
a flexible framework in which they can cooperate in complex tasks. Our system
combines data gathering, machine translation, topic classification, extraction
and annotation of entities and social networks, as well as many other tasks
that have been perfected over the past years of AI research. Over the last few
years, it has allowed us to realise a series of scientific studies over a vast
range of applications including comparative studies between news outlets and
media content in different countries, modelling of user preferences, and
monitoring public mood. The framework is flexible and allows the design and
implementation of modular agents, where simple modules cooperate in the
annotation of a large dataset without central coordination.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Flaounas_I/0/1/0/all/0/1&quot;&gt;Ilias Flaounas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lansdall_Welfare_T/0/1/0/all/0/1&quot;&gt;Thomas Lansdall-Welfare&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Antonakaki_P/0/1/0/all/0/1&quot;&gt;Panagiota Antonakaki&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cristianini_N/0/1/0/all/0/1&quot;&gt;Nello Cristianini&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1705.06366">
<title>Automatic Goal Generation for Reinforcement Learning Agents. (arXiv:1705.06366v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1705.06366</link>
<description rdf:parseType="Literal">&lt;p&gt;Reinforcement learning is a powerful technique to train an agent to perform a
task. However, an agent that is trained using reinforcement learning is only
capable of achieving the single task that is specified via its reward function.
Such an approach does not scale well to settings in which an agent needs to
perform a diverse set of tasks, such as navigating to varying positions in a
room or moving objects to varying locations. Instead, we propose a method that
allows an agent to automatically discover the range of tasks that it is capable
of performing. We use a generator network to propose tasks for the agent to try
to achieve, specified as goal states. The generator network is optimized using
adversarial training to produce tasks that are always at the appropriate level
of difficulty for the agent. Our method thus automatically produces a
curriculum of tasks for the agent to learn. We show that, by using this
framework, an agent can efficiently and automatically learn to perform a wide
set of tasks without requiring any prior knowledge of its environment. Our
method can also learn to achieve tasks with sparse rewards, which traditionally
pose significant challenges.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Held_D/0/1/0/all/0/1&quot;&gt;David Held&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Geng_X/0/1/0/all/0/1&quot;&gt;Xinyang Geng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Florensa_C/0/1/0/all/0/1&quot;&gt;Carlos Florensa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1&quot;&gt;Pieter Abbeel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1708.07580">
<title>The Expanding Approvals Rule: Improving Proportional Representation and Monotonicity. (arXiv:1708.07580v2 [cs.GT] UPDATED)</title>
<link>http://arxiv.org/abs/1708.07580</link>
<description rdf:parseType="Literal">&lt;p&gt;Proportional representation (PR) is often discussed in voting settings as a
major desideratum. For the past century or so, it is common both in practice
and in the academic literature to jump to single transferable vote (STV) as the
solution for achieving PR. Some of the most prominent electoral reform
movements around the globe are pushing for the adoption of STV. It has been
termed a major open problem to design a voting rule that satisfies the same PR
properties as STV and better monotonicity properties. In this paper, we first
present a taxonomy of proportional representation axioms for general weak order
preferences, some of which generalise and strengthen previously introduced
concepts. We then present a rule called Expanding Approvals Rule (EAR) that
satisfies properties stronger than the central PR axiom satisfied by STV, can
handle indifferences in a convenient and computationally efficient manner, and
also satisfies better candidate monotonicity properties. In view of this, our
proposed rule seems to be a compelling solution for achieving proportional
representation in voting settings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aziz_H/0/1/0/all/0/1&quot;&gt;Haris Aziz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_B/0/1/0/all/0/1&quot;&gt;Barton Lee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.01968">
<title>Faster Deep Q-learning using Neural Episodic Control. (arXiv:1801.01968v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1801.01968</link>
<description rdf:parseType="Literal">&lt;p&gt;The research on deep reinforcement learning which estimates Q-value by deep
learning has been attracted the interest of researchers recently. In deep
reinforcement learning, it is important to efficiently learn the experiences
that an agent has collected by exploring environment. We propose NEC2DQN that
improves learning speed of a poor sample efficiency algorithm such as DQN by
using good one such as NEC at the beginning of learning. We show it is able to
learn faster than Double DQN or N-step DQN in the experiments of Pong.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nishio_D/0/1/0/all/0/1&quot;&gt;Daichi Nishio&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yamane_S/0/1/0/all/0/1&quot;&gt;Satoshi Yamane&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07798">
<title>Improved Learning of One-hidden-layer Convolutional Neural Networks with Overlaps. (arXiv:1805.07798v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.07798</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a new algorithm to learn a one-hidden-layer convolutional neural
network where both the convolutional weights and the outputs weights are
parameters to be learned. Our algorithm works for a general class of
(potentially overlapping) patches, including commonly used structures for
computer vision tasks. Our algorithm draws ideas from (1) isotonic regression
for learning neural networks and (2) landscape analysis of non-convex matrix
factorization problems. We believe these findings may inspire further
development in designing provable algorithms for learning neural networks and
other complex models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Du_S/0/1/0/all/0/1&quot;&gt;Simon S. Du&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goel_S/0/1/0/all/0/1&quot;&gt;Surbhi Goel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.10528">
<title>Dependent Gated Reading for Cloze-Style Question Answering. (arXiv:1805.10528v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1805.10528</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a novel deep learning architecture to address the cloze-style
question answering task. Existing approaches employ reading mechanisms that do
not fully exploit the interdependency between the document and the query. In
this paper, we propose a novel \emph{dependent gated reading} bidirectional GRU
network (DGR) to efficiently model the relationship between the document and
the query during encoding and decision making. Our evaluation shows that DGR
obtains highly competitive performance on well-known machine comprehension
benchmarks such as the Children&apos;s Book Test (CBT-NE and CBT-CN) and Who DiD
What (WDW, Strict and Relaxed). Finally, we extensively analyze and validate
our model by ablation and attention studies.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghaeini_R/0/1/0/all/0/1&quot;&gt;Reza Ghaeini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fern_X/0/1/0/all/0/1&quot;&gt;Xiaoli Z. Fern&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shahbazi_H/0/1/0/all/0/1&quot;&gt;Hamed Shahbazi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tadepalli_P/0/1/0/all/0/1&quot;&gt;Prasad Tadepalli&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00509">
<title>Semi-Recurrent CNN-based VAE-GAN for Sequential Data Generation. (arXiv:1806.00509v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.00509</link>
<description rdf:parseType="Literal">&lt;p&gt;A semi-recurrent hybrid VAE-GAN model for generating sequential data is
introduced. In order to consider the spatial correlation of the data in each
frame of the generated sequence, CNNs are utilized in the encoder, generator,
and discriminator. The subsequent frames are sampled from the latent
distributions obtained by encoding the previous frames. As a result, the
dependencies between the frames are maintained. Two testing frameworks for
synthesizing a sequence with any number of frames are also proposed. The
promising experimental results on piano music generation indicates the
potential of the proposed framework in modeling other sequential data such as
video.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Akbari_M/0/1/0/all/0/1&quot;&gt;Mohammad Akbari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_J/0/1/0/all/0/1&quot;&gt;Jie Liang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00572">
<title>Autoencoders Learn Generative Linear Models. (arXiv:1806.00572v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.00572</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent progress in learning theory has led to the emergence of provable
algorithms for training certain families of neural networks. Under the
assumption that the training data is sampled from a suitable generative model,
the weights of the trained networks obtained by these algorithms recover
(either exactly or approximately) the generative model parameters. However, the
large majority of these results are only applicable to supervised learning
architectures. In this paper, we complement this line of work by providing a
series of results for unsupervised learning with neural networks. Specifically,
we study the familiar setting of shallow autoencoder architectures with shared
weights. We focus on three generative models for the data: (i) the
mixture-of-gaussians model, (ii) the sparse coding model, and (iii) the
non-negative sparsity model. All three models are widely studied in the machine
learning literature. For each of these models, we rigorously prove that under
suitable choices of hyperparameters, architectures, and initialization, the
autoencoder weights learned by gradient descent % -based training can
successfully recover the parameters of the corresponding model. To our
knowledge, this is the first result that rigorously studies the dynamics of
gradient descent for weight-sharing autoencoders. Our analysis can be viewed as
theoretical evidence that shallow autoencoder modules indeed can be used as
unsupervised feature training mechanisms for a wide range of datasets, and may
shed insight on how to train larger stacked architectures with autoencoders as
basic building blocks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Nguyen_T/0/1/0/all/0/1&quot;&gt;Thanh V. Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wong_R/0/1/0/all/0/1&quot;&gt;Raymond K. W. Wong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hegde_C/0/1/0/all/0/1&quot;&gt;Chinmay Hegde&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00580">
<title>Detecting Adversarial Examples via Key-based Network. (arXiv:1806.00580v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.00580</link>
<description rdf:parseType="Literal">&lt;p&gt;Though deep neural networks have achieved state-of-the-art performance in
visual classification, recent studies have shown that they are all vulnerable
to the attack of adversarial examples. Small and often imperceptible
perturbations to the input images are sufficient to fool the most powerful deep
neural networks. Various defense methods have been proposed to address this
issue. However, they either require knowledge on the process of generating
adversarial examples, or are not robust against new attacks specifically
designed to penetrate the existing defense. In this work, we introduce
key-based network, a new detection-based defense mechanism to distinguish
adversarial examples from normal ones based on error correcting output codes,
using the binary code vectors produced by multiple binary classifiers applied
to randomly chosen label-sets as signatures to match normal images and reject
adversarial examples. In contrast to existing defense methods, the proposed
method does not require knowledge of the process for generating adversarial
examples and can be applied to defend against different types of attacks. For
the practical black-box and gray-box scenarios, where the attacker does not
know the encoding scheme, we show empirically that key-based network can
effectively detect adversarial examples generated by several state-of-the-art
attacks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_P/0/1/0/all/0/1&quot;&gt;Pinlong Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fu_Z/0/1/0/all/0/1&quot;&gt;Zhouyu Fu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+wu_O/0/1/0/all/0/1&quot;&gt;Ou wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_Q/0/1/0/all/0/1&quot;&gt;Qinghua Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jun Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00582">
<title>Federated Learning with Non-IID Data. (arXiv:1806.00582v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.00582</link>
<description rdf:parseType="Literal">&lt;p&gt;Federated learning enables resource-constrained edge compute devices, such as
mobile phones and IoT devices, to learn a shared model for prediction, while
keeping the training data local. This decentralized approach to train models
provides privacy, security, regulatory and economic benefits. In this work, we
focus on the statistical challenge of federated learning when local data is
non-IID. We first show that the accuracy of federated learning reduces
significantly, by up to 55% for neural networks trained for highly skewed
non-IID data, where each client device trains only on a single class of data.
We further show that this accuracy reduction can be explained by the weight
divergence, which can be quantified by the earth mover&apos;s distance (EMD) between
the distribution over classes on each device and the population distribution.
As a solution, we propose a strategy to improve training on non-IID data by
creating a small subset of data which is globally shared between all the edge
devices. Experiments show that accuracy can be increased by 30% for the
CIFAR-10 dataset with only 5% globally shared data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1&quot;&gt;Yue Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1&quot;&gt;Meng Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lai_L/0/1/0/all/0/1&quot;&gt;Liangzhen Lai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Suda_N/0/1/0/all/0/1&quot;&gt;Naveen Suda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Civin_D/0/1/0/all/0/1&quot;&gt;Damon Civin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chandra_V/0/1/0/all/0/1&quot;&gt;Vikas Chandra&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00630">
<title>DAQN: Deep Auto-encoder and Q-Network. (arXiv:1806.00630v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1806.00630</link>
<description rdf:parseType="Literal">&lt;p&gt;The deep reinforcement learning method usually requires a large number of
training images and executing actions to obtain sufficient results. When it is
extended a real-task in the real environment with an actual robot, the method
will be required more training images due to complexities or noises of the
input images, and executing a lot of actions on the real robot also becomes a
serious problem. Therefore, we propose an extended deep reinforcement learning
method that is applied a generative model to initialize the network for
reducing the number of training trials. In this paper, we used a deep q-network
method as the deep reinforcement learning method and a deep auto-encoder as the
generative model. We conducted experiments on three different tasks: a
cart-pole game, an atari game, and a real-game with an actual robot. The
proposed method trained efficiently on all tasks than the previous method,
especially 2.5 times faster on a task with real environment images.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kimura_D/0/1/0/all/0/1&quot;&gt;Daiki Kimura&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00650">
<title>Signal and Noise Statistics Oblivious Orthogonal Matching Pursuit. (arXiv:1806.00650v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.00650</link>
<description rdf:parseType="Literal">&lt;p&gt;Orthogonal matching pursuit (OMP) is a widely used algorithm for recovering
sparse high dimensional vectors in linear regression models. The optimal
performance of OMP requires \textit{a priori} knowledge of either the sparsity
of regression vector or noise statistics. Both these statistics are rarely
known \textit{a priori} and are very difficult to estimate. In this paper, we
present a novel technique called residual ratio thresholding (RRT) to operate
OMP without any \textit{a priori} knowledge of sparsity and noise statistics
and establish finite sample and large sample support recovery guarantees for
the same. Both analytical results and numerical simulations in real and
synthetic data sets indicate that RRT has a performance comparable to OMP with
\textit{a priori} knowledge of sparsity and noise statistics.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kallummil_S/0/1/0/all/0/1&quot;&gt;Sreejith Kallummil&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kalyani_S/0/1/0/all/0/1&quot;&gt;Sheetal Kalyani&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00681">
<title>Nonlocal Neural Networks, Nonlocal Diffusion and Nonlocal Modeling. (arXiv:1806.00681v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.00681</link>
<description rdf:parseType="Literal">&lt;p&gt;Nonlocal neural networks have been proposed and shown to be effective in
several computer vision tasks, where the nonlocal operations can directly
capture long-range dependencies in the feature space. In this paper, we study
the nature of diffusion and damping effect of nonlocal networks by doing the
spectrum analysis on the weight matrices of the well-trained networks, and
propose a new formulation of the nonlocal block. The new block not only learns
the nonlocal interactions but also has stable dynamics and thus allows deeper
nonlocal structures. Moreover, we interpret our formulation from the general
nonlocal modeling perspective, where we make connections between the proposed
nonlocal network and other nonlocal models, such as nonlocal diffusion
processes and nonlocal Markov jump processes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tao_Y/0/1/0/all/0/1&quot;&gt;Yunzhe Tao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_Q/0/1/0/all/0/1&quot;&gt;Qi Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Du_Q/0/1/0/all/0/1&quot;&gt;Qiang Du&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1&quot;&gt;Wei Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00711">
<title>Learning and Generalizing Motion Primitives from Driving Data for Path-Tracking Applications. (arXiv:1806.00711v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.00711</link>
<description rdf:parseType="Literal">&lt;p&gt;Considering the driving habits which are learned from the naturalistic
driving data in the path-tracking system can significantly improve the
acceptance of intelligent vehicles. Therefore, the goal of this paper is to
generate the prediction results of lateral commands with confidence regions
according to the reference based on the learned motion primitives. We present a
two-level structure for learning and generalizing motion primitives through
demonstrations. The lower-level motion primitives are generated under the path
segmentation and clustering layer in the upper-level. The Gaussian Mixture
Model(GMM) is utilized to represent the primitives and Gaussian Mixture
Regression (GMR) is selected to generalize the motion primitives. We show how
the upper-level can help to improve the prediction accuracy and evaluate the
influence of different time scales and the number of Gaussian components. The
model is trained and validated by using the driving data collected from the
Beijing Institute of Technology (BIT) intelligent vehicle platform. Experiment
results show that the proposed method can extract the motion primitives from
the driving data and predict the future lateral control commands with high
accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1&quot;&gt;Boyang Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Zirui Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gong_J/0/1/0/all/0/1&quot;&gt;Jianwei Gong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yidi Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1&quot;&gt;Huiyan Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_C/0/1/0/all/0/1&quot;&gt;Chao Lu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00804">
<title>NAM: Non-Adversarial Unsupervised Domain Mapping. (arXiv:1806.00804v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.00804</link>
<description rdf:parseType="Literal">&lt;p&gt;Several methods were recently proposed for the task of translating images
between domains without prior knowledge in the form of correspondences. The
existing methods apply adversarial learning to ensure that the distribution of
the mapped source domain is indistinguishable from the target domain, which
suffers from known stability issues. In addition, most methods rely heavily on
&quot;cycle&quot; relationships between the domains, which enforce a one-to-one mapping.
In this work, we introduce an alternative method: Non-Adversarial Mapping
(NAM), which separates the task of target domain generative modeling from the
cross-domain mapping task. NAM relies on a pre-trained generative model of the
target domain, and aligns each source image with an image synthesized from the
target domain, while jointly optimizing the domain mapping function. It has
several key advantages: higher quality and resolution image translations,
simpler and more stable training and reusable target models. Extensive
experiments are presented validating the advantages of our method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hoshen_Y/0/1/0/all/0/1&quot;&gt;Yedid Hoshen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wolf_L/0/1/0/all/0/1&quot;&gt;Lior Wolf&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00826">
<title>Analysis of regularized Nystr\&quot;om subsampling for regression functions of low smoothness. (arXiv:1806.00826v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.00826</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper studies a Nystr\&quot;om type subsampling approach to large kernel
learning methods in the misspecified case, where the target function is not
assumed to belong to the reproducing kernel Hilbert space generated by the
underlying kernel. This case is less understood, in spite of its practical
importance. To model such a case, the smoothness of target functions is
described in terms of general source conditions. It is surprising that almost
for the whole range of the source conditions, describing the misspecified case,
the corresponding learning rate bounds can be achieved with just one value of
the regularization parameter. This observation allows a formulation of mild
conditions under which the plain Nystr\&quot;om subsampling can be realized with
subquadratic cost maintaining the guaranteed learning rates.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lu_S/0/1/0/all/0/1&quot;&gt;Shuai Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mathe_P/0/1/0/all/0/1&quot;&gt;Peter Math&amp;#xe9;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pereverzyev_S/0/1/0/all/0/1&quot;&gt;Sergiy Pereverzyev Jr&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00900">
<title>Algorithmic Regularization in Learning Deep Homogeneous Models: Layers are Automatically Balanced. (arXiv:1806.00900v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.00900</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the implicit regularization imposed by gradient descent for learning
multi-layer homogeneous functions including feed-forward fully connected and
convolutional deep neural networks with linear, ReLU or Leaky ReLU activation.
We rigorously prove that gradient flow (i.e. gradient descent with
infinitesimal step size) effectively enforces the differences between squared
norms across different layers to remain invariant without any explicit
regularization. This result implies that if the weights are initially small,
gradient flow automatically balances the magnitudes of all layers. Using a
discretization argument, we analyze gradient descent with positive step size
for the non-convex low-rank asymmetric matrix factorization problem without any
regularization. Inspired by our findings for gradient flow, we prove that
gradient descent with step sizes $\eta_t = O\left(t^{-\left(
\frac12+\delta\right)} \right)$ ($0&amp;lt;\delta\le\frac12$) automatically balances
two low-rank factors and converges to a bounded global optimum. Furthermore,
for rank-$1$ asymmetric matrix factorization we give a finer analysis showing
gradient descent with constant step size converges to the global minimum at a
globally linear rate. We believe that the idea of examining the invariance
imposed by first order algorithms in learning homogeneous models could serve as
a fundamental building block for studying optimization for learning deep
models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Du_S/0/1/0/all/0/1&quot;&gt;Simon S. Du&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_W/0/1/0/all/0/1&quot;&gt;Wei Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1&quot;&gt;Jason D. Lee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00914">
<title>How Much Are You Willing to Share? A &quot;Poker-Styled&quot; Selective Privacy Preserving Framework for Recommender Systems. (arXiv:1806.00914v1 [cs.IR])</title>
<link>http://arxiv.org/abs/1806.00914</link>
<description rdf:parseType="Literal">&lt;p&gt;Most industrial recommender systems rely on the popular collaborative
filtering (CF) technique for providing personalized recommendations to its
users. However, the very nature of CF is adversarial to the idea of user
privacy, because users need to share their preferences with others in order to
be grouped with like-minded people and receive accurate recommendations. While
previous privacy preserving approaches have been successful inasmuch as they
concealed user preference information to some extent from a centralized
recommender system, they have also, nevertheless, incurred significant
trade-offs in terms of privacy, scalability, and accuracy. They are also
vulnerable to privacy breaches by malicious actors. In light of these
observations, we propose a novel selective privacy preserving (SP2) paradigm
that allows users to custom define the scope and extent of their individual
privacies, by marking their personal ratings as either public (which can be
shared) or private (which are never shared and stored only on the user device).
Our SP2 framework works in two steps: (i) First, it builds an initial
recommendation model based on the sum of all public ratings that have been
shared by users and (ii) then, this public model is fine-tuned on each user&apos;s
device based on the user private ratings, thus eventually learning a more
accurate model. Furthermore, in this work, we introduce three different
algorithms for implementing an end-to-end SP2 framework that can scale
effectively from thousands to hundreds of millions of items. Our user survey
shows that an overwhelming fraction of users are likely to rate much more items
to improve the overall recommendations when they can control what ratings will
be publicly shared with others.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dareddy_M/0/1/0/all/0/1&quot;&gt;Manoj Reddy Dareddy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Das_A/0/1/0/all/0/1&quot;&gt;Ariyam Das&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cho_J/0/1/0/all/0/1&quot;&gt;Junghoo Cho&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zaniolo_C/0/1/0/all/0/1&quot;&gt;Carlo Zaniolo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00919">
<title>Adversarial confidence and smoothness regularizations for scalable unsupervised discriminative learning. (arXiv:1806.00919v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.00919</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we consider a generic probabilistic discriminative learner
from the functional viewpoint and argue that, to make it learn well, it is
necessary to constrain its hypothesis space to a set of non-trivial piecewise
constant functions. To achieve this goal, we present a scalable unsupervised
regularization framework. On the theoretical front, we prove that this
framework is conducive to a factually confident and smooth discriminative model
and connect it to an adversarial Taboo game, spectral clustering and virtual
adversarial training. Experimentally, we take deep neural networks as our
learners and demonstrate that, when trained under our framework in the
unsupervised setting, they not only achieve state-of-the-art clustering results
but also generalize well on both synthetic and real data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yi-Qing Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00989">
<title>Efficiency of adaptive importance sampling. (arXiv:1806.00989v1 [math.ST])</title>
<link>http://arxiv.org/abs/1806.00989</link>
<description rdf:parseType="Literal">&lt;p&gt;The \textit{sampling policy} of stage $t$, formally expressed as a
probability density function $q_t$, stands for the distribution of the sample
$(x_{t,1},\ldots, x_{t,n_t})$ generated at $t$. From the past samples, some
information depending on some \textit{objective} is derived leading eventually
to update the sampling policy to $q_{t+1}$. This generic approach characterizes
\textit{adaptive importance sampling} (AIS) schemes. Each stage $t$ is formed
with two steps : (i) to explore the space with $n_t$ points according to $q_t$
and (ii) to exploit the current amount of information to update the sampling
policy. The very fundamental question raised in the paper concerns the behavior
of empirical sums based on AIS. Without making any assumption on the
\textit{allocation policy} $n_t$, the theory developed involves no restriction
on the split of computational resources between the explore (i) and the exploit
(ii) step. It is shown that AIS is efficient : the asymptotic behavior of AIS
is the same as some &quot;oracle&quot; strategy that knows the optimal sampling policy
from the beginning. From a practical perspective, weighted AIS is introduced, a
new method that allows to forget poor samples from early stages.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Delyon_B/0/1/0/all/0/1&quot;&gt;Bernard Delyon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Portier_F/0/1/0/all/0/1&quot;&gt;Fran&amp;#xe7;ois Portier&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.01010">
<title>Meta Learner with Linear Nulling. (arXiv:1806.01010v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.01010</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a meta learning algorithm utilizing a linear transformer that
carries out null-space projection of neural network outputs. The main idea is
to construct a classification space such that the error signals during few-shot
training are zero-forced on that space. The final decision on a test sample is
obtained utilizing a null-space-projected distance measure between the network
output and label-dependent weights that have been trained in the initial meta
learning phase. Our meta learner achieves the best or near-best accuracies
among known methods in few-shot image classification tasks with Omniglot and
miniImageNet. In particular, our method shows stronger relative performance by
significant margins as the classification task becomes more complicated.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yoon_S/0/1/0/all/0/1&quot;&gt;Sung Whan Yoon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Seo_J/0/1/0/all/0/1&quot;&gt;Jun Seo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moon_J/0/1/0/all/0/1&quot;&gt;Jaekyun Moon&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.01182">
<title>Online Reciprocal Recommendation with Theoretical Performance Guarantees. (arXiv:1806.01182v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.01182</link>
<description rdf:parseType="Literal">&lt;p&gt;A reciprocal recommendation problem is one where the goal of learning is not
just to predict a user&apos;s preference towards a passive item (e.g., a book), but
to recommend the targeted user on one side another user from the other side
such that a mutual interest between the two exists. The problem thus is sharply
different from the more traditional items-to-users recommendation, since a good
match requires meeting the preferences of both users. We initiate a rigorous
theoretical investigation of the reciprocal recommendation task in a specific
framework of sequential learning. We point out general limitations, formulate
reasonable assumptions enabling effective learning and, under these
assumptions, we design and analyze a computationally efficient algorithm that
uncovers mutual likes at a pace comparable to those achieved by a clearvoyant
algorithm knowing all user preferences in advance. Finally, we validate our
algorithm against synthetic and real-world datasets, showing improved empirical
performance over simple baselines.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vitale_F/0/1/0/all/0/1&quot;&gt;Fabio Vitale&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Parotsidis_N/0/1/0/all/0/1&quot;&gt;Nikos Parotsidis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gentile_C/0/1/0/all/0/1&quot;&gt;Claudio Gentile&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.01833">
<title>Marginal Singularity, and the Benefits of Labels in Covariate-Shift. (arXiv:1803.01833v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1803.01833</link>
<description rdf:parseType="Literal">&lt;p&gt;We present new minimax results that concisely capture the relative benefits
of source and target labeled data, under covariate-shift. Namely, we show that
the benefits of target labels are controlled by a transfer-exponent $\gamma$
that encodes how singular Q is locally w.r.t. P, and interestingly allows
situations where transfer did not seem possible under previous insights. In
fact, our new minimax analysis - in terms of $\gamma$ - reveals a continuum of
regimes ranging from situations where target labels have little benefit, to
regimes where target labels dramatically improve classification. We then show
that a recently proposed semi-supervised procedure can be extended to adapt to
unknown $\gamma$, and therefore requests labels only when beneficial, while
achieving minimax transfer rates.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kpotufe_S/0/1/0/all/0/1&quot;&gt;Samory Kpotufe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Martinet_G/0/1/0/all/0/1&quot;&gt;Guillaume Martinet&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.02350">
<title>Efficient active learning of sparse halfspaces. (arXiv:1805.02350v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.02350</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the problem of efficient PAC active learning of homogeneous linear
classifiers (halfspaces) in $\mathbb{R}^d$, where the goal is to learn a
halfspace with low error using as few label queries as possible. Under the
extra assumption that there is a $t$-sparse halfspace that performs well on the
data ($t \ll d$), we would like our active learning algorithm to be {\em
attribute efficient}, i.e. to have label requirements sublinear in $d$. In this
paper, we provide a computationally efficient algorithm that achieves this
goal. Under certain distributional assumptions on the data, our algorithm
achieves a label complexity of $O(t \cdot \mathrm{polylog}(d, \frac 1
\epsilon))$. In contrast, existing algorithms in this setting are either
computationally inefficient, or subject to label requirements polynomial in $d$
or $\frac 1 \epsilon$.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1&quot;&gt;Chicheng Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.03616">
<title>A Reinforced Topic-Aware Convolutional Sequence-to-Sequence Model for Abstractive Text Summarization. (arXiv:1805.03616v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1805.03616</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we propose a deep learning approach to tackle the automatic
summarization tasks by incorporating topic information into the convolutional
sequence-to-sequence (ConvS2S) model and using self-critical sequence training
(SCST) for optimization. Through jointly attending to topics and word-level
alignment, our approach can improve coherence, diversity, and informativeness
of generated summaries via a biased probability generation mechanism. On the
other hand, reinforcement training, like SCST, directly optimizes the proposed
model with respect to the non-differentiable metric ROUGE, which also avoids
the exposure bias during inference. We carry out the experimental evaluation
with state-of-the-art methods over the Gigaword, DUC-2004, and LCSTS datasets.
The empirical results demonstrate the superiority of our proposed method in the
abstractive summarization.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1&quot;&gt;Li Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yao_J/0/1/0/all/0/1&quot;&gt;Junlin Yao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tao_Y/0/1/0/all/0/1&quot;&gt;Yunzhe Tao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhong_L/0/1/0/all/0/1&quot;&gt;Li Zhong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1&quot;&gt;Wei Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Du_Q/0/1/0/all/0/1&quot;&gt;Qiang Du&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09039">
<title>Amortized Context Vector Inference for Sequence-to-Sequence Networks. (arXiv:1805.09039v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.09039</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural attention (NA) is an effective mechanism for inferring complex
structural data dependencies that span long temporal horizons. As a
consequence, it has become a key component of sequence-to-sequence models that
yield state-of-the-art performance in as hard tasks as abstractive document
summarization (ADS), machine translation (MT), and video captioning (VC). NA
mechanisms perform inference of context vectors; these constitute weighted sums
of deterministic input sequence encodings, adaptively sourced over long
temporal horizons. However, recent work in the field of amortized variational
inference (AVI) has shown that it is often useful to treat the representations
generated by deep networks as latent random variables. This allows for the
models to better explore the space of possible representations. Based on this
motivation, in this work we introduce a novel regard towards a popular NA
mechanism, namely soft-attention (SA). Our approach treats the context vectors
generated by SA models as latent variables, the posteriors of which are
inferred by employing AVI. Both the means and the covariance matrices of the
inferred posteriors are parameterized via deep network mechanisms similar to
those employed in the context of standard SA. To illustrate our method, we
implement it in the context of popular sequence-to-sequence model variants with
SA. We conduct an extensive experimental evaluation using challenging ADS, VC,
and MT benchmarks, and show how our approach compares to the baselines.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chatzis_S/0/1/0/all/0/1&quot;&gt;Sotirios Chatzis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Charalampous_A/0/1/0/all/0/1&quot;&gt;Aristotelis Charalampous&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tolias_K/0/1/0/all/0/1&quot;&gt;Kyriacos Tolias&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vassou_S/0/1/0/all/0/1&quot;&gt;Sotiris A. Vassou&lt;/a&gt;</dc:creator>
</item></rdf:RDF>