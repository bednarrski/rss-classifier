<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Good papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Good Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-06-18T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06446"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06628"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06765"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1705.04058"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05415"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.04264"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04641"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06205"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06208"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06298"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06301"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06408"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06411"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06478"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06506"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06569"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06734"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1603.08253"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1705.05035"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.03825"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.05372"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04899"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06068"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06116"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06144"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06173"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06176"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06253"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06362"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06365"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06384"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06513"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06616"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06763"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06775"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1608.07710"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1702.00763"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1708.00112"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.00168"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.04333"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09001"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09298"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11046"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02782"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05009"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05662"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1806.06446">
<title>Self-Attentive Neural Collaborative Filtering. (arXiv:1806.06446v1 [cs.IR])</title>
<link>http://arxiv.org/abs/1806.06446</link>
<description rdf:parseType="Literal">&lt;p&gt;The dominant, state-of-the-art collaborative filtering (CF) methods today
mainly comprises neural models. In these models, deep neural networks, e.g..,
multi-layered perceptrons (MLP), are often used to model nonlinear
relationships between user and item representations. As opposed to shallow
models (e.g., factorization-based models), deep models generally provide a
greater extent of expressiveness, albeit at the expense of impaired/restricted
information flow. Consequently, the performance of most neural CF models
plateaus at 3-4 layers, with performance stagnating or even degrading when
increasing the model depth. As such, the question of how to train really deep
networks in the context of CF remains unclear. To this end, this paper proposes
a new technique that enables training neural CF models all the way up to 20
layers and beyond. Our proposed approach utilizes a new hierarchical
self-attention mechanism that learns introspective intra-feature similarity
across all the hidden layers of a standard MLP model. All in all, our proposed
architecture, SA-NCF (Self-Attentive Neural Collaborative Filtering) is a
densely connected self-matching model that can be trained up to 24 layers
without plateau-ing, achieving wide performance margins against its
competitors. On several popular benchmark datasets, our proposed architecture
achieves up to an absolute improvement of 23%-58% and 1.3x to 2.8x fold
improvement in terms of nDCG@10 and Hit Ratio (HR@10) scores over several
strong neural CF baselines.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tay_Y/0/1/0/all/0/1&quot;&gt;Yi Tay&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1&quot;&gt;Shuai Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tuan_L/0/1/0/all/0/1&quot;&gt;Luu Anh Tuan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hui_S/0/1/0/all/0/1&quot;&gt;Siu Cheung Hui&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06628">
<title>Cardinality Leap for Open-Ended Evolution: Theoretical Consideration and Demonstration by &quot;Hash Chemistry&quot;. (arXiv:1806.06628v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1806.06628</link>
<description rdf:parseType="Literal">&lt;p&gt;Open-ended evolution requires unbounded possibilities that evolving entities
can explore. The cardinality of those possibilities thus has a significant
implication for the open-endedness of evolution. We propose that facilitating
formation of higher-order entities is a generalizable, effective way to cause a
&quot;cardinality leap&quot; in the set of possibilities that promotes open-endedness. We
demonstrate this idea with a simple, proof-of-concept toy model called &quot;Hash
Chemistry&quot; that uses a hash function as a fitness evaluator of evolving
entities of any size/order. Simulation results showed that the number of
individual entities involved in a single replication event gradually increased
over time, indicating evolutionary appearance of higher-order entities. It was
also observed that the cumulative number of unique replicating entities that
appeared in evolution increased almost linearly along time without a bound,
presenting a concrete example of open-endedness achieved by the cardinality
leap.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sayama_H/0/1/0/all/0/1&quot;&gt;Hiroki Sayama&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06765">
<title>Modularity Matters: Learning Invariant Relational Reasoning Tasks. (arXiv:1806.06765v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.06765</link>
<description rdf:parseType="Literal">&lt;p&gt;We focus on two supervised visual reasoning tasks whose labels encode a
semantic relational rule between two or more objects in an image: the MNIST
Parity task and the colorized Pentomino task. The objects in the images undergo
random translation, scaling, rotation and coloring transformations. Thus these
tasks involve invariant relational reasoning. We report uneven performance of
various deep CNN models on these two tasks. For the MNIST Parity task, we
report that the VGG19 model soundly outperforms a family of ResNet models.
Moreover, the family of ResNet models exhibits a general sensitivity to random
initialization for the MNIST Parity task. For the colorized Pentomino task, now
both the VGG19 and ResNet models exhibit sluggish optimization and very poor
test generalization, hovering around 30% test error. The CNN we tested all
learn hierarchies of fully distributed features and thus encode the distributed
representation prior. We are motivated by a hypothesis from cognitive
neuroscience which posits that the human visual cortex is modularized, and this
allows the visual cortex to learn higher order invariances. To this end, we
consider a modularized variant of the ResNet model, referred to as a Residual
Mixture Network (ResMixNet) which employs a mixture-of-experts architecture to
interleave distributed representations with more specialized, modular
representations. We show that very shallow ResMixNets are capable of learning
each of the two tasks well, attaining less than 2% and 1% test error on the
MNIST Parity and the colorized Pentomino tasks respectively. Most importantly,
the ResMixNet models are extremely parameter efficient: generalizing better
than various non-modular CNNs that have over 10x the number of parameters.
These experimental results support the hypothesis that modularity is a robust
prior for learning invariant relational reasoning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jo_J/0/1/0/all/0/1&quot;&gt;Jason Jo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Verma_V/0/1/0/all/0/1&quot;&gt;Vikas Verma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bengio_Y/0/1/0/all/0/1&quot;&gt;Yoshua Bengio&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1705.04058">
<title>Neural Style Transfer: A Review. (arXiv:1705.04058v6 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1705.04058</link>
<description rdf:parseType="Literal">&lt;p&gt;The seminal work of Gatys et al. demonstrated the power of Convolutional
Neural Networks (CNN) in creating artistic imagery by separating and
recombining image content and style. This process of using CNN to render a
content image in different styles is referred to as Neural Style Transfer
(NST). Since then, NST has become a trending topic both in academic literature
and industrial applications. It is receiving increasing attention and a variety
of approaches are proposed to either improve or extend the original NST
algorithm. This review aims to provide an overview of the current progress
towards NST, as well as discussing its various applications and open problems
for future research.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jing_Y/0/1/0/all/0/1&quot;&gt;Yongcheng Jing&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1&quot;&gt;Yezhou Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feng_Z/0/1/0/all/0/1&quot;&gt;Zunlei Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1&quot;&gt;Jingwen Ye&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1&quot;&gt;Yizhou Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_M/0/1/0/all/0/1&quot;&gt;Mingli Song&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05415">
<title>Teaching Machines to Code: Neural Markup Generation with Visual Attention. (arXiv:1802.05415v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1802.05415</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a neural transducer model with visual attention that learns to
generate LaTeX markup of a real-world math formula given its image. Applying
sequence modeling and transduction techniques that have been very successful
across modalities such as natural language, image, handwriting, speech and
audio; we construct an image-to-markup model that learns to produce
syntactically and semantically correct LaTeX markup code over 150 words long
and achieves a BLEU score of 89%; improving upon the previous state-of-art for
the Im2Latex problem. We also demonstrate with heat-map visualization how
attention helps in interpreting the model and can pinpoint (detect and
localize) symbols on the image accurately despite having been trained without
any bounding box data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1&quot;&gt;Sumeet S. Singh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.04264">
<title>State Gradients for RNN Memory Analysis. (arXiv:1805.04264v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1805.04264</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a framework for analyzing what the state in RNNs remembers from
its input embeddings. Our approach is inspired by backpropagation, in the sense
that we compute the gradients of the states with respect to the input
embeddings. The gradient matrix is decomposed with Singular Value Decomposition
to analyze which directions in the embedding space are best transferred to the
hidden state space, characterized by the largest singular values. We apply our
approach to LSTM language models and investigate to what extent and for how
long certain classes of words are remembered on average for a certain corpus.
Additionally, the extent to which a specific property or relationship is
remembered by the RNN can be tracked by comparing a vector characterizing that
property with the direction(s) in embedding space that are best preserved in
hidden state space.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Verwimp_L/0/1/0/all/0/1&quot;&gt;Lyan Verwimp&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+hamme_H/0/1/0/all/0/1&quot;&gt;Hugo Van hamme&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Renkens_V/0/1/0/all/0/1&quot;&gt;Vincent Renkens&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wambacq_P/0/1/0/all/0/1&quot;&gt;Patrick Wambacq&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04641">
<title>Predicting Citation Counts with a Neural Network. (arXiv:1806.04641v2 [cs.DL] UPDATED)</title>
<link>http://arxiv.org/abs/1806.04641</link>
<description rdf:parseType="Literal">&lt;p&gt;We here describe and present results of a simple neural network that predicts
individual researchers&apos; future citation counts based on a variety of data from
the researchers&apos; past. For publications available on the open access-server
arXiv.org we find a higher predictability than previous studies.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mistele_T/0/1/0/all/0/1&quot;&gt;Tobias Mistele&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Price_T/0/1/0/all/0/1&quot;&gt;Tom Price&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hossenfelder_S/0/1/0/all/0/1&quot;&gt;Sabine Hossenfelder&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06205">
<title>TrQuery: An Embedding-based Framework for Recommanding SPARQL Queries. (arXiv:1806.06205v1 [cs.DB])</title>
<link>http://arxiv.org/abs/1806.06205</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we present an embedding-based framework (TrQuery) for
recommending solutions of a SPARQL query, including approximate solutions when
exact querying solutions are not available due to incompleteness or
inconsistencies of real-world RDF data. Within this framework, embedding is
applied to score solutions together with edit distance so that we could obtain
more fine-grained recommendations than those recommendations via edit distance.
For instance, graphs of two querying solutions with a similar structure can be
distinguished in our proposed framework while the edit distance depending on
structural difference becomes unable. To this end, we propose a novel score
model built on vector space generated in embedding system to compute the
similarity between an approximate subgraph matching and a whole graph matching.
Finally, we evaluate our approach on large RDF datasets DBpedia and YAGO, and
experimental results show that TrQuery exhibits an excellent behavior in terms
of both effectiveness and efficiency.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1&quot;&gt;Lijing Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xiaowang Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feng_Z/0/1/0/all/0/1&quot;&gt;Zhiyong Feng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06208">
<title>Offline Extraction of Indic Regional Language from Natural Scene Image using Text Segmentation and Deep Convolutional Sequence. (arXiv:1806.06208v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1806.06208</link>
<description rdf:parseType="Literal">&lt;p&gt;Regional language extraction from a natural scene image is always a
challenging proposition due to its dependence on the text information extracted
from Image. Text Extraction on the other hand varies on different lighting
condition, arbitrary orientation, inadequate text information, heavy background
influence over text and change of text appearance. This paper presents a novel
unified method for tackling the above challenges. The proposed work uses an
image correction and segmentation technique on the existing Text Detection
Pipeline an Efficient and Accurate Scene Text Detector (EAST). EAST uses
standard PVAnet architecture to select features and non maximal suppression to
detect text from image. Text recognition is done using combined architecture of
MaxOut convolution neural network (CNN) and Bidirectional long short term
memory (LSTM) network. After recognizing text using the Deep Learning based
approach, the native Languages are translated to English and tokenized using
standard Text Tokenizers. The tokens that very likely represent a location is
used to find the Global Positioning System (GPS) coordinates of the location
and subsequently the regional languages spoken in that location is extracted.
The proposed method is tested on a self generated dataset collected from
Government of India dataset and experimented on Standard Dataset to evaluate
the performance of the proposed technique. Comparative study with a few
state-of-the-art methods on text detection, recognition and extraction of
regional language from images shows that the proposed method outperforms the
existing methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nag_S/0/1/0/all/0/1&quot;&gt;Sauradip Nag&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ganguly_P/0/1/0/all/0/1&quot;&gt;Pallab Kumar Ganguly&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roy_S/0/1/0/all/0/1&quot;&gt;Sumit Roy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jha_S/0/1/0/all/0/1&quot;&gt;Sourab Jha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bose_K/0/1/0/all/0/1&quot;&gt;Krishna Bose&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jha_A/0/1/0/all/0/1&quot;&gt;Abhishek Jha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dasgupta_K/0/1/0/all/0/1&quot;&gt;Koushik Dasgupta&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06298">
<title>Deformable Generator Network: Unsupervised Disentanglement of Appearance and Geometry. (arXiv:1806.06298v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.06298</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a deformable generator model to disentangle the appearance and
geometric information from images into two independent latent vectors. The
appearance generator produces the appearance information, including color,
illumination, identity or category, of an image. The geometric generator
produces displacement of the coordinates of each pixel and performs geometric
warping, such as stretching and rotation, on the appearance generator to obtain
the final synthesized image. The proposed model can learn both representations
from image data in an unsupervised manner. The learned geometric generator can
be conveniently transferred to the other image datasets to facilitate
downstream AI tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xing_X/0/1/0/all/0/1&quot;&gt;Xianglei Xing&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_R/0/1/0/all/0/1&quot;&gt;Ruiqi Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Han_T/0/1/0/all/0/1&quot;&gt;Tian Han&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_S/0/1/0/all/0/1&quot;&gt;Song-Chun Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1&quot;&gt;Ying Nian Wu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06301">
<title>Biased Embeddings from Wild Data: Measuring, Understanding and Removing. (arXiv:1806.06301v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1806.06301</link>
<description rdf:parseType="Literal">&lt;p&gt;Many modern Artificial Intelligence (AI) systems make use of data embeddings,
particularly in the domain of Natural Language Processing (NLP). These
embeddings are learnt from data that has been gathered &quot;from the wild&quot; and have
been found to contain unwanted biases. In this paper we make three
contributions towards measuring, understanding and removing this problem. We
present a rigorous way to measure some of these biases, based on the use of
word lists created for social psychology applications; we observe how gender
bias in occupations reflects actual gender bias in the same occupations in the
real world; and finally we demonstrate how a simple projection can
significantly reduce the effects of embedding bias. All this is part of an
ongoing effort to understand how trust can be built into AI systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sutton_A/0/1/0/all/0/1&quot;&gt;Adam Sutton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lansdall_Welfare_T/0/1/0/all/0/1&quot;&gt;Thomas Lansdall-Welfare&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cristianini_N/0/1/0/all/0/1&quot;&gt;Nello Cristianini&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06408">
<title>Gated Path Planning Networks. (arXiv:1806.06408v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.06408</link>
<description rdf:parseType="Literal">&lt;p&gt;Value Iteration Networks (VINs) are effective differentiable path planning
modules that can be used by agents to perform navigation while still
maintaining end-to-end differentiability of the entire architecture. Despite
their effectiveness, they suffer from several disadvantages including training
instability, random seed sensitivity, and other optimization problems. In this
work, we reframe VINs as recurrent-convolutional networks which demonstrates
that VINs couple recurrent convolutions with an unconventional max-pooling
activation. From this perspective, we argue that standard gated recurrent
update equations could potentially alleviate the optimization issues plaguing
VIN. The resulting architecture, which we call the Gated Path Planning Network,
is shown to empirically outperform VIN on a variety of metrics such as learning
speed, hyperparameter sensitivity, iteration count, and even generalization.
Furthermore, we show that this performance gap is consistent across different
maze transition types, maze sizes and even show success on a challenging 3D
environment, where the planner is only provided with first-person RGB images.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_L/0/1/0/all/0/1&quot;&gt;Lisa Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Parisotto_E/0/1/0/all/0/1&quot;&gt;Emilio Parisotto&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chaplot_D/0/1/0/all/0/1&quot;&gt;Devendra Singh Chaplot&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xing_E/0/1/0/all/0/1&quot;&gt;Eric Xing&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Salakhutdinov_R/0/1/0/all/0/1&quot;&gt;Ruslan Salakhutdinov&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06411">
<title>Measuring Semantic Coherence of a Conversation. (arXiv:1806.06411v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1806.06411</link>
<description rdf:parseType="Literal">&lt;p&gt;Conversational systems have become increasingly popular as a way for humans
to interact with computers. To be able to provide intelligent responses,
conversational systems must correctly model the structure and semantics of a
conversation. We introduce the task of measuring semantic (in)coherence in a
conversation with respect to background knowledge, which relies on the
identification of semantic relations between concepts introduced during a
conversation. We propose and evaluate graph-based and machine learning-based
approaches for measuring semantic coherence using knowledge graphs, their
vector space embeddings and word embedding models, as sources of background
knowledge. We demonstrate how these approaches are able to uncover different
coherence patterns in conversations on the Ubuntu Dialogue Corpus.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vakulenko_S/0/1/0/all/0/1&quot;&gt;Svitlana Vakulenko&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rijke_M/0/1/0/all/0/1&quot;&gt;Maarten de Rijke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cochez_M/0/1/0/all/0/1&quot;&gt;Michael Cochez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Savenkov_V/0/1/0/all/0/1&quot;&gt;Vadim Savenkov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Polleres_A/0/1/0/all/0/1&quot;&gt;Axel Polleres&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06478">
<title>Co-training Embeddings of Knowledge Graphs and Entity Descriptions for Cross-lingual Entity Alignment. (arXiv:1806.06478v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1806.06478</link>
<description rdf:parseType="Literal">&lt;p&gt;Multilingual knowledge graph (KG) embeddings provide latent semantic
representations of entities and structured knowledge with cross-lingual
inferences, which benefit various knowledge-driven cross-lingual NLP tasks.
However, precisely learning such cross-lingual inferences is usually hindered
by the low coverage of entity alignment in many KGs. Since many multilingual
KGs also provide literal descriptions of entities, in this paper, we introduce
an embedding-based approach which leverages a weakly aligned multilingual KG
for semi-supervised cross-lingual learning using entity descriptions. Our
approach performs co-training of two embedding models, i.e. a multilingual KG
embedding model and a multilingual literal description embedding model. The
models are trained on a large Wikipedia-based trilingual dataset where most
entity alignment is unknown to training. Experimental results show that the
performance of the proposed approach on the entity alignment task improves at
each iteration of co-training, and eventually reaches a stage at which it
significantly surpasses previous approaches. We also show that our approach has
promising abilities for zero-shot entity alignment, and cross-lingual KG
completion.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1&quot;&gt;Muhao Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1&quot;&gt;Yingtao Tian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chang_K/0/1/0/all/0/1&quot;&gt;Kai-Wei Chang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Skiena_S/0/1/0/all/0/1&quot;&gt;Steven Skiena&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zaniolo_C/0/1/0/all/0/1&quot;&gt;Carlo Zaniolo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06506">
<title>An Ensemble of Transfer, Semi-supervised and Supervised Learning Methods for Pathological Heart Sound Classification. (arXiv:1806.06506v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1806.06506</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work, we propose an ensemble of classifiers to distinguish between
various degrees of abnormalities of the heart using Phonocardiogram (PCG)
signals acquired using digital stethoscopes in a clinical setting, for the
INTERSPEECH 2018 Computational Paralinguistics (ComParE) Heart Beats
SubChallenge. Our primary classification framework constitutes a convolutional
neural network with 1D-CNN time-convolution (tConv) layers, which uses features
transferred from a model trained on the 2016 Physionet Heart Sound Database. We
also employ a Representation Learning (RL) approach to generate features in an
unsupervised manner using Deep Recurrent Autoencoders and use Support Vector
Machine (SVM) and Linear Discriminant Analysis (LDA) classifiers. Finally, we
utilize an SVM classifier on a high-dimensional segment-level feature extracted
using various functionals on short-term acoustic features, i.e., Low-Level
Descriptors (LLD). An ensemble of the three different approaches provides a
relative improvement of 11.13% compared to our best single sub-system in terms
of the Unweighted Average Recall (UAR) performance metric on the evaluation
dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Humayun_A/0/1/0/all/0/1&quot;&gt;Ahmed Imtiaz Humayun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khan_M/0/1/0/all/0/1&quot;&gt;Md. Tauhiduzzaman Khan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghaffarzadegan_S/0/1/0/all/0/1&quot;&gt;Shabnam Ghaffarzadegan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feng_Z/0/1/0/all/0/1&quot;&gt;Zhe Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hasan_T/0/1/0/all/0/1&quot;&gt;Taufiq Hasan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06569">
<title>Learning from Outside the Viability Kernel: Why we Should Build Robots that can Fall with Grace. (arXiv:1806.06569v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1806.06569</link>
<description rdf:parseType="Literal">&lt;p&gt;Despite impressive results using reinforcement learning to solve complex
problems from scratch, in robotics this has still been largely limited to
model-based learning with very informative reward functions. One of the major
challenges is that the reward landscape often has large patches with no
gradient, making it difficult to sample gradients effectively. We show here
that the robot state-initialization can have a more important effect on the
reward landscape than is generally expected. In particular, we show the
counter-intuitive benefit of including initializations that are unviable, in
other words initializing in states that are doomed to fail.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Heim_S/0/1/0/all/0/1&quot;&gt;Steve Heim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sprowitz_A/0/1/0/all/0/1&quot;&gt;Alexander Spr&amp;#xf6;witz&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06734">
<title>Unsupervised Word Segmentation from Speech with Attention. (arXiv:1806.06734v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1806.06734</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a first attempt to perform attentional word segmentation directly
from the speech signal, with the final goal to automatically identify lexical
units in a low-resource, unwritten language (UL). Our methodology assumes a
pairing between recordings in the UL with translations in a well-resourced
language. It uses Acoustic Unit Discovery (AUD) to convert speech into a
sequence of pseudo-phones that is segmented using neural soft-alignments
produced by a neural machine translation model. Evaluation uses an actual Bantu
UL, Mboshi; comparisons to monolingual and bilingual baselines illustrate the
potential of attentional word segmentation for language documentation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Godard_P/0/1/0/all/0/1&quot;&gt;Pierre Godard&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zanon_Boito_M/0/1/0/all/0/1&quot;&gt;Marcely Zanon-Boito&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ondel_L/0/1/0/all/0/1&quot;&gt;Lucas Ondel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Berard_A/0/1/0/all/0/1&quot;&gt;Alexandre Berard&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yvon_F/0/1/0/all/0/1&quot;&gt;Fran&amp;#xe7;ois Yvon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Villavicencio_A/0/1/0/all/0/1&quot;&gt;Aline Villavicencio&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Besacier_L/0/1/0/all/0/1&quot;&gt;Laurent Besacier&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1603.08253">
<title>Negative Learning Rates and P-Learning. (arXiv:1603.08253v3 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1603.08253</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a method of training a differentiable function approximator for a
regression task using negative examples. We effect this training using negative
learning rates. We also show how this method can be used to perform direct
policy learning in a reinforcement learning setting.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Merrill_D/0/1/0/all/0/1&quot;&gt;Devon Merrill&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1705.05035">
<title>Discrete Sequential Prediction of Continuous Actions for Deep RL. (arXiv:1705.05035v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1705.05035</link>
<description rdf:parseType="Literal">&lt;p&gt;It has long been assumed that high dimensional continuous control problems
cannot be solved effectively by discretizing individual dimensions of the
action space due to the exponentially large number of bins over which policies
would have to be learned. In this paper, we draw inspiration from the recent
success of sequence-to-sequence models for structured prediction problems to
develop policies over discretized spaces. Central to this method is the
realization that complex functions over high dimensional spaces can be modeled
by neural networks that predict one dimension at a time. Specifically, we show
how Q-values and policies over continuous spaces can be modeled using a next
step prediction model over discretized dimensions. With this parameterization,
it is possible to both leverage the compositional structure of action spaces
during learning, as well as compute maxima over action spaces (approximately).
On a simple example task we demonstrate empirically that our method can perform
global search, which effectively gets around the local optimization issues that
plague DDPG. We apply the technique to off-policy (Q-learning) methods and show
that our method can achieve the state-of-the-art for off-policy methods on
several continuous control tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Metz_L/0/1/0/all/0/1&quot;&gt;Luke Metz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ibarz_J/0/1/0/all/0/1&quot;&gt;Julian Ibarz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jaitly_N/0/1/0/all/0/1&quot;&gt;Navdeep Jaitly&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Davidson_J/0/1/0/all/0/1&quot;&gt;James Davidson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.03825">
<title>EARL: Joint Entity and Relation Linking for Question Answering over Knowledge Graphs. (arXiv:1801.03825v3 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1801.03825</link>
<description rdf:parseType="Literal">&lt;p&gt;Many question answering systems over knowledge graphs rely on entity and
relation linking components in order to connect the natural language input to
the underlying knowledge graph. Traditionally, entity linking and relation
linking have been performed either as dependent sequential tasks or as
independent parallel tasks. In this paper, we propose a framework called EARL,
which performs entity linking and relation linking as a joint task. EARL
implements two different solution strategies for which we provide a comparative
analysis in this paper: The first strategy is a formalisation of the joint
entity and relation linking tasks as an instance of the Generalised Travelling
Salesman Problem (GTSP). In order to be computationally feasible, we employ
approximate GTSP solvers. The second strategy uses machine learning in order to
exploit the connection density between nodes in the knowledge graph. It relies
on three base features and re-ranking steps in order to predict entities and
relations. We compare the strategies and evaluate them on a dataset with 5000
questions. Both strategies significantly outperform the current
state-of-the-art approaches for entity and relation linking.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dubey_M/0/1/0/all/0/1&quot;&gt;Mohnish Dubey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Banerjee_D/0/1/0/all/0/1&quot;&gt;Debayan Banerjee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chaudhuri_D/0/1/0/all/0/1&quot;&gt;Debanjan Chaudhuri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lehmann_J/0/1/0/all/0/1&quot;&gt;Jens Lehmann&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.05372">
<title>Neural Feature Learning From Relational Database. (arXiv:1801.05372v3 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1801.05372</link>
<description rdf:parseType="Literal">&lt;p&gt;Feature engineering is one of the most important but most tedious tasks in
data science. This work studies automation of feature learning from relational
database. We first prove theoretically that finding the optimal features from
relational data for predictive tasks is NP-hard. We propose an efficient
rule-based approach based on heuristics and a deep neural network to
automatically learn appropriate features from relational data. We benchmark our
approaches in ensembles in past Kaggle competitions. Our new approach wins late
medals and beats the state-of-the-art solutions with significant margins. To
the best of our knowledge, this is the first time an automated data science
system could win medals in Kaggle competitions with complex relational
database.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lam_H/0/1/0/all/0/1&quot;&gt;Hoang Thanh Lam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Minh_T/0/1/0/all/0/1&quot;&gt;Tran Ngoc Minh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sinn_M/0/1/0/all/0/1&quot;&gt;Mathieu Sinn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Buesser_B/0/1/0/all/0/1&quot;&gt;Beat Buesser&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wistuba_M/0/1/0/all/0/1&quot;&gt;Martin Wistuba&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04899">
<title>Ensemble Pruning based on Objection Maximization with a General Distributed Framework. (arXiv:1806.04899v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1806.04899</link>
<description rdf:parseType="Literal">&lt;p&gt;Ensemble pruning, selecting a subset of individual learners from an original
ensemble, alleviates the deficiencies of ensemble learning on the cost of time
and space. Accuracy and diversity serve as two crucial factors while they
usually conflict with each other. To balance both of them, we formalize the
ensemble pruning problem as an objection maximization problem based on
information entropy. Then we propose an ensemble pruning method including a
centralized version and a distributed version, in which the latter is to speed
up the former&apos;s execution. At last, we extract a general distributed framework
for ensemble pruning, which can be widely suitable for most of existing
ensemble pruning methods and achieve less time consuming without much accuracy
decline. Experimental results validate the efficiency of our framework and
methods, particularly with regard to a remarkable improvement of the execution
speed, accompanied by gratifying accuracy performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bian_Y/0/1/0/all/0/1&quot;&gt;Yijun Bian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yijun Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1&quot;&gt;Yaqiang Yao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1&quot;&gt;Huanhuan Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06068">
<title>Detecting Dead Weights and Units in Neural Networks. (arXiv:1806.06068v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.06068</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep Neural Networks are highly over-parameterized and the size of the neural
networks can be reduced significantly after training without any decrease in
performance. One can clearly see this phenomenon in a wide range of
architectures trained for various problems. Weight/channel pruning,
distillation, quantization, matrix factorization are some of the main methods
one can use to remove the redundancy to come up with smaller and faster models.
&lt;/p&gt;
&lt;p&gt;This work starts with a short informative chapter, where we motivate the
pruning idea and provide the necessary notation. In the second chapter, we
compare various saliency scores in the context of parameter pruning. Using the
insights obtained from this comparison and stating the problems it brings we
motivate why pruning units instead of the individual parameters might be a
better idea. We propose some set of definitions to quantify and analyze units
that don&apos;t learn and create any useful information. We propose an efficient way
for detecting dead units and use it to select which units to prune. We get 5x
model size reduction through unit-wise pruning on MNIST.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Evci_U/0/1/0/all/0/1&quot;&gt;Utku Evci&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06116">
<title>Stochastic WaveNet: A Generative Latent Variable Model for Sequential Data. (arXiv:1806.06116v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.06116</link>
<description rdf:parseType="Literal">&lt;p&gt;How to model distribution of sequential data, including but not limited to
speech and human motions, is an important ongoing research problem. It has been
demonstrated that model capacity can be significantly enhanced by introducing
stochastic latent variables in the hidden states of recurrent neural networks.
Simultaneously, WaveNet, equipped with dilated convolutions, achieves
astonishing empirical performance in natural speech generation task. In this
paper, we combine the ideas from both stochastic latent variables and dilated
convolutions, and propose a new architecture to model sequential data, termed
as Stochastic WaveNet, where stochastic latent variables are injected into the
WaveNet structure. We argue that Stochastic WaveNet enjoys powerful
distribution modeling capacity and the advantage of parallel training from
dilated convolutions. In order to efficiently infer the posterior distribution
of the latent variables, a novel inference network structure is designed based
on the characteristics of WaveNet architecture. State-of-the-art performances
on benchmark datasets are obtained by Stochastic WaveNet on natural speech
modeling and high quality human handwriting samples can be generated as well.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lai_G/0/1/0/all/0/1&quot;&gt;Guokun Lai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1&quot;&gt;Bohan Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_G/0/1/0/all/0/1&quot;&gt;Guoqing Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1&quot;&gt;Yiming Yang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06144">
<title>Learning kernels that adapt to GPU. (arXiv:1806.06144v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.06144</link>
<description rdf:parseType="Literal">&lt;p&gt;In recent years machine learning methods that nearly interpolate the data
have achieved remarkable success. In many settings achieving near-zero training
error leads to excellent test results. In this work we show how the
mathematical and conceptual simplicity of interpolation can be harnessed to
construct a framework for very efficient, scalable and accurate kernel
machines.
&lt;/p&gt;
&lt;p&gt;Our main innovation is in constructing kernel machines that output solutions
mathematically equivalent to those obtained using standard kernels, yet capable
of fully utilizing the available computing power of a parallel computational
resource, such as GPU. Such utilization is key to strong performance since much
of the computational resource capability is wasted by the standard iterative
methods. The computational resource and data adaptivity of our learned kernels
is based on theoretical convergence bounds.
&lt;/p&gt;
&lt;p&gt;The resulting algorithm, which we call EigenPro 2.0, is accurate, principled
and very fast. For example, using a single GPU, training on ImageNet with
$1.3\times 10^6$ data points and $1000$ labels takes under an hour, while
smaller datasets, such as MNIST, take seconds. Moreover, as the parameters are
chosen analytically, based on the theory, little tuning beyond selecting the
kernel and kernel parameter is needed, further facilitating the practical use
of these methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ma_S/0/1/0/all/0/1&quot;&gt;Siyuan Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Belkin_M/0/1/0/all/0/1&quot;&gt;Mikhail Belkin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06173">
<title>On the Complexity of Detecting Convexity over a Box. (arXiv:1806.06173v1 [math.OC])</title>
<link>http://arxiv.org/abs/1806.06173</link>
<description rdf:parseType="Literal">&lt;p&gt;It has recently been shown that the problem of testing global convexity of
polynomials of degree four is {strongly} NP-hard, answering an open question of
N.Z. Shor. This result is minimal in the degree of the polynomial when global
convexity is of concern. In a number of applications however, one is interested
in testing convexity only over a compact region, most commonly a box (i.e.,
hyper-rectangle). In this paper, we show that this problem is also strongly
NP-hard, in fact for polynomials of degree as low as three. This result is
minimal in the degree of the polynomial and in some sense justifies why
convexity detection in nonlinear optimization solvers is limited to quadratic
functions or functions with special structure. As a byproduct, our proof shows
that the problem of testing whether all matrices in an interval family are
positive semidefinite is strongly NP-hard. This problem, which was previously
shown to be (weakly) NP-hard by Nemirovski, is of independent interest in the
theory of robust control.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Ahmadi_A/0/1/0/all/0/1&quot;&gt;Amir Ali Ahmadi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Hall_G/0/1/0/all/0/1&quot;&gt;Georgina Hall&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06176">
<title>Learning Factorized Multimodal Representations. (arXiv:1806.06176v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.06176</link>
<description rdf:parseType="Literal">&lt;p&gt;Learning representations of multimodal data is a fundamentally complex
research problem due to the presence of multiple sources of information. To
address the complexities of multimodal data, we argue that suitable
representation learning models should: 1) factorize representations according
to independent factors of variation in the data, capture important features for
both 2) discriminative and 3) generative tasks, and 4) couple both
modality-specific and multimodal information. To encapsulate all these
properties, we propose the Multimodal Factorization Model (MFM) that factorizes
multimodal representations into two sets of independent factors: multimodal
discriminative factors and modality-specific generative factors. Multimodal
discriminative factors are shared across all modalities and contain joint
multimodal features required for discriminative tasks such as predicting
sentiment. Modality-specific generative factors are unique for each modality
and contain the information required for generating data. Our experimental
results show that our model is able to learn meaningful multimodal
representations and achieve state-of-the-art or competitive performance on five
multimodal datasets. Our model also demonstrates flexible generative
capabilities by conditioning on the independent factors. We further interpret
our factorized representations to understand the interactions that influence
multimodal learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tsai_Y/0/1/0/all/0/1&quot;&gt;Yao-Hung Hubert Tsai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_P/0/1/0/all/0/1&quot;&gt;Paul Pu Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zadeh_A/0/1/0/all/0/1&quot;&gt;Amir Zadeh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Morency_L/0/1/0/all/0/1&quot;&gt;Louis-Philippe Morency&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Salakhutdinov_R/0/1/0/all/0/1&quot;&gt;Ruslan Salakhutdinov&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06253">
<title>DynMat, a network that can learn after learning. (arXiv:1806.06253v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.06253</link>
<description rdf:parseType="Literal">&lt;p&gt;To survive in the dynamically-evolving world, we accumulate knowledge and
improve our skills based on experience. In the process, gaining new knowledge
does not disrupt our vigilance to external stimuli. In other words, our
learning process is &apos;accumulative&apos; and &apos;online&apos; without interruption. However,
despite the recent success, artificial neural networks (ANNs) must be trained
offline, and they suffer catastrophic interference between old and new
learning, indicating that ANNs&apos; conventional learning algorithms may not be
suitable for building intelligent agents comparable to our brain. In this
study, we propose a novel neural network architecture (DynMat) consisting of
dual learning systems, inspired by the complementary learning system (CLS)
theory suggesting that the brain relies on short- and long-term learning
systems to learn continuously. Our experiments show that 1) DynMat can learn a
new class without catastrophic interference and 2) it does not strictly require
offline training.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1&quot;&gt;Jung H. Lee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06362">
<title>Exact information propagation through fully-connected feed forward neural networks. (arXiv:1806.06362v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.06362</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural network ensembles at initialisation give rise to the trainability and
training speed of neural networks and thus support parameter choices at
initialisation. These insights rely so far on mean field approximations that
assume infinite layer width and study average squared signals. Thus,
information about the full output distribution gets lost. Therefore, we derive
the output distribution exactly (without mean field assumptions), for
fully-connected networks with Gaussian weights and biases. The layer-wise
transition of the signal distribution is guided by a linear integral operator,
whose kernel has a closed form solution in case of rectified linear units for
nonlinear activations. This enables us to analyze some of its spectral
properties, for instance, the shape of the stationary distribution for
different parameter choices and the dynamics of signal propagation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Burkholz_R/0/1/0/all/0/1&quot;&gt;Rebekka Burkholz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Dubatovka_A/0/1/0/all/0/1&quot;&gt;Alina Dubatovka&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06365">
<title>How Could Polyhedral Theory Harness Deep Learning?. (arXiv:1806.06365v1 [math.OC])</title>
<link>http://arxiv.org/abs/1806.06365</link>
<description rdf:parseType="Literal">&lt;p&gt;The holy grail of deep learning is to come up with an automatic method to
design optimal architectures for different applications. In other words, how
can we effectively dimension and organize neurons along the network layers
based on the computational resources, input size, and amount of training data?
We outline promising research directions based on polyhedral theory and
mixed-integer representability that may offer an analytical approach to this
question, in contrast to the empirical techniques often employed.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Serra_T/0/1/0/all/0/1&quot;&gt;Thiago Serra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Tjandraatmadja_C/0/1/0/all/0/1&quot;&gt;Christian Tjandraatmadja&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Ramalingam_S/0/1/0/all/0/1&quot;&gt;Srikumar Ramalingam&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06384">
<title>Multi-variable LSTM neural network for autoregressive exogenous model. (arXiv:1806.06384v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.06384</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we propose multi-variable LSTM capable of accurate forecasting
and variable importance interpretation for time series with exogenous
variables. Current attention mechanism in recurrent neural networks mostly
focuses on the temporal aspect of data and falls short of characterizing
variable importance. To this end, the multi-variable LSTM equipped with
tensorized hidden states is developed to learn hidden states for individual
variables, which give rise to our mixture temporal and variable attention.
Based on such attention mechanism, we infer and quantify variable importance.
Extensive experiments using real datasets with Granger-causality test and the
synthetic dataset with ground truth demonstrate the prediction performance and
interpretability of multi-variable LSTM in comparison to a variety of
baselines. It exhibits the prospect of multi-variable LSTM as an end-to-end
framework for both forecasting and knowledge discovery.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_T/0/1/0/all/0/1&quot;&gt;Tian Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_T/0/1/0/all/0/1&quot;&gt;Tao Lin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06513">
<title>Semi-tied Units for Efficient Gating in LSTM and Highway Networks. (arXiv:1806.06513v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1806.06513</link>
<description rdf:parseType="Literal">&lt;p&gt;Gating is a key technique used for integrating information from multiple
sources by long short-term memory (LSTM) models and has recently also been
applied to other models such as the highway network. Although gating is
powerful, it is rather expensive in terms of both computation and storage as
each gating unit uses a separate full weight matrix. This issue can be severe
since several gates can be used together in e.g. an LSTM cell. This paper
proposes a semi-tied unit (STU) approach to solve this efficiency issue, which
uses one shared weight matrix to replace those in all the units in the same
layer. The approach is termed &quot;semi-tied&quot; since extra parameters are used to
separately scale each of the shared output values. These extra scaling factors
are associated with the network activation functions and result in the use of
parameterised sigmoid, hyperbolic tangent, and rectified linear unit functions.
Speech recognition experiments using British English multi-genre broadcast data
showed that using STUs can reduce the calculation and storage cost by a factor
of three for highway networks and four for LSTMs, while giving similar word
error rates to the original models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1&quot;&gt;Chao Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Woodland_P/0/1/0/all/0/1&quot;&gt;Philip Woodland&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06616">
<title>Comparison-Based Random Forests. (arXiv:1806.06616v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.06616</link>
<description rdf:parseType="Literal">&lt;p&gt;Assume we are given a set of items from a general metric space, but we
neither have access to the representation of the data nor to the distances
between data points. Instead, suppose that we can actively choose a triplet of
items (A,B,C) and ask an oracle whether item A is closer to item B or to item
C. In this paper, we propose a novel random forest algorithm for regression and
classification that relies only on such triplet comparisons. In the theory part
of this paper, we establish sufficient conditions for the consistency of such a
forest. In a set of comprehensive experiments, we then demonstrate that the
proposed random forest is efficient both for classification and regression. In
particular, it is even competitive with other methods that have direct access
to the metric representation of the data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Haghiri_S/0/1/0/all/0/1&quot;&gt;Siavash Haghiri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Garreau_D/0/1/0/all/0/1&quot;&gt;Damien Garreau&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Luxburg_U/0/1/0/all/0/1&quot;&gt;Ulrike von Luxburg&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06763">
<title>Closing the Generalization Gap of Adaptive Gradient Methods in Training Deep Neural Networks. (arXiv:1806.06763v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.06763</link>
<description rdf:parseType="Literal">&lt;p&gt;Adaptive gradient methods, which adopt historical gradient information to
automatically adjust the learning rate, have been observed to generalize worse
than stochastic gradient descent (SGD) with momentum in training deep neural
networks. This leaves how to close the generalization gap of adaptive gradient
methods an open problem. In this work, we show that adaptive gradient methods
such as Adam, Amsgrad, are sometimes &quot;over adapted&quot;. We design a new algorithm,
called Partially adaptive momentum estimation method (Padam), which unifies the
Adam/Amsgrad with SGD to achieve the best from both worlds. Experiments on
standard benchmarks show that Padam can maintain fast convergence rate as
Adam/Amsgrad while generalizing as well as SGD in training deep neural
networks. These results would suggest practitioners pick up adaptive gradient
methods once again for faster training of deep neural networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1&quot;&gt;Jinghui Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gu_Q/0/1/0/all/0/1&quot;&gt;Quanquan Gu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06775">
<title>Kernel-based Outlier Detection using the Inverse Christoffel Function. (arXiv:1806.06775v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.06775</link>
<description rdf:parseType="Literal">&lt;p&gt;Outlier detection methods have become increasingly relevant in recent years
due to increased security concerns and because of its vast application to
different fields. Recently, Pauwels and Lasserre (2016) noticed that the
sublevel sets of the inverse Christoffel function accurately depict the shape
of a cloud of data using a sum-of-squares polynomial and can be used to perform
outlier detection. In this work, we propose a kernelized variant of the inverse
Christoffel function that makes it computationally tractable for data sets with
a large number of features. We compare our approach to current methods on 15
different data sets and achieve the best average area under the precision
recall curve (AUPRC) score, the best average rank and the lowest root mean
square deviation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Askari_A/0/1/0/all/0/1&quot;&gt;Armin Askari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yang_F/0/1/0/all/0/1&quot;&gt;Forest Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ghaoui_L/0/1/0/all/0/1&quot;&gt;Laurent El Ghaoui&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1608.07710">
<title>Random Forest for Label Ranking. (arXiv:1608.07710v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1608.07710</link>
<description rdf:parseType="Literal">&lt;p&gt;Label ranking aims to learn a mapping from instances to rankings over a
finite number of predefined labels. Random forest is a powerful and one of the
most successful general-purpose machine learning algorithms of modern times. In
this paper, we present a powerful random forest label ranking method which uses
random decision trees to retrieve nearest neighbors. We have developed a novel
two-step rank aggregation strategy to effectively aggregate neighboring
rankings discovered by the random forest into a final predicted ranking.
Compared with existing methods, the new random forest method has many
advantages including its intrinsically scalable tree data structure, highly
parallel-able computational architecture and much superior performance. We
present extensive experimental results to demonstrate that our new method
achieves the highly competitive performance compared with state-of-the-art
methods for datasets with complete ranking and datasets with only partial
ranking information.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1&quot;&gt;Yangming Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qiu_G/0/1/0/all/0/1&quot;&gt;Guoping Qiu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1702.00763">
<title>Natasha: Faster Non-Convex Stochastic Optimization Via Strongly Non-Convex Parameter. (arXiv:1702.00763v4 [math.OC] UPDATED)</title>
<link>http://arxiv.org/abs/1702.00763</link>
<description rdf:parseType="Literal">&lt;p&gt;Given a nonconvex function that is an average of $n$ smooth functions, we
design stochastic first-order methods to find its approximate stationary
points. The convergence of our new methods depends on the smallest (negative)
eigenvalue $-\sigma$ of the Hessian, a parameter that describes how nonconvex
the function is.
&lt;/p&gt;
&lt;p&gt;Our methods outperform known results for a range of parameter $\sigma$, and
can be used to find approximate local minima. Our result implies an interesting
dichotomy: there exists a threshold $\sigma_0$ so that the currently fastest
methods for $\sigma&amp;gt;\sigma_0$ and for $\sigma&amp;lt;\sigma_0$ have different
behaviors: the former scales with $n^{2/3}$ and the latter scales with
$n^{3/4}$.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Allen_Zhu_Z/0/1/0/all/0/1&quot;&gt;Zeyuan Allen-Zhu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1708.00112">
<title>Retrofitting Distributional Embeddings to Knowledge Graphs with Functional Relations. (arXiv:1708.00112v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1708.00112</link>
<description rdf:parseType="Literal">&lt;p&gt;Knowledge graphs are a versatile framework to encode richly structured data
relationships, but it can be challenging to combine these graphs with
unstructured data. Methods for retrofitting pre-trained entity representations
to the structure of a knowledge graph typically assume that entities are
embedded in a connected space and that relations imply similarity. However,
useful knowledge graphs often contain diverse entities and relations (with
potentially disjoint underlying corpora) which do not accord with these
assumptions. To overcome these limitations, we present Functional Retrofitting,
a framework that generalizes current retrofitting methods by explicitly
modeling pairwise relations. Our framework can directly incorporate a variety
of pairwise penalty functions previously developed for knowledge graph
completion. Further, it allows users to encode, learn, and extract information
about relation semantics. We present both linear and neural instantiations of
the framework. Functional Retrofitting significantly outperforms existing
retrofitting methods on complex knowledge graphs and loses no accuracy on
simpler graphs (in which relations do imply similarity). Finally, we
demonstrate the utility of the framework by predicting new drug--disease
treatment pairs in a large, complex health knowledge graph.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lengerich_B/0/1/0/all/0/1&quot;&gt;Benjamin J. Lengerich&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Maas_A/0/1/0/all/0/1&quot;&gt;Andrew L. Maas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Potts_C/0/1/0/all/0/1&quot;&gt;Christopher Potts&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.00168">
<title>Deep Neural Nets with Interpolating Function as Output Activation. (arXiv:1802.00168v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1802.00168</link>
<description rdf:parseType="Literal">&lt;p&gt;We replace the output layer of deep neural nets, typically the softmax
function, by a novel interpolating function. And we propose end-to-end training
and testing algorithms for this new architecture. Compared to classical neural
nets with softmax function as output activation, the surrogate with
interpolating function as output activation combines advantages of both deep
and manifold learning. The new framework demonstrates the following major
advantages: First, it is better applicable to the case with insufficient
training data. Second, it significantly improves the generalization accuracy on
a wide variety of networks. The algorithm is implemented in PyTorch, and code
will be made publicly available.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1&quot;&gt;Bao Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_X/0/1/0/all/0/1&quot;&gt;Xiyang Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Zhen Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_W/0/1/0/all/0/1&quot;&gt;Wei Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_Z/0/1/0/all/0/1&quot;&gt;Zuoqiang Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Osher_S/0/1/0/all/0/1&quot;&gt;Stanley J. Osher&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.04333">
<title>Causal Generative Domain Adaptation Networks. (arXiv:1804.04333v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1804.04333</link>
<description rdf:parseType="Literal">&lt;p&gt;An essential problem in domain adaptation is to understand and make use of
distribution changes across domains. For this purpose, we first propose a
flexible Generative Domain Adaptation Network (G-DAN) with specific latent
variables to capture changes in the generating process of features across
domains. By explicitly modeling the changes, one can even generate data in new
domains using the generating process with new values for the latent variables
in G-DAN. In practice, the process to generate all features together may
involve high-dimensional latent variables, requiring dealing with distributions
in high dimensions and making it difficult to learn domain changes from few
source domains. Interestingly, by further making use of the causal
representation of joint distributions, we then decompose the joint distribution
into separate modules, each of which involves different low-dimensional latent
variables and can be learned separately, leading to a Causal G-DAN (CG-DAN).
This improves both statistical and computational efficiency of the learning
procedure. Finally, by matching the feature distribution in the target domain,
we can recover the target-domain joint distribution and derive the learning
machine for the target domain. We demonstrate the efficacy of both G-DAN and
CG-DAN in domain generation and cross-domain prediction on both synthetic and
real data experiments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gong_M/0/1/0/all/0/1&quot;&gt;Mingming Gong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhang_K/0/1/0/all/0/1&quot;&gt;Kun Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Huang_B/0/1/0/all/0/1&quot;&gt;Biwei Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Glymour_C/0/1/0/all/0/1&quot;&gt;Clark Glymour&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tao_D/0/1/0/all/0/1&quot;&gt;Dacheng Tao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Batmanghelich_K/0/1/0/all/0/1&quot;&gt;Kayhan Batmanghelich&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09001">
<title>On the Relation of Impulse Propagation to Synaptic Strength. (arXiv:1805.09001v2 [q-bio.NC] UPDATED)</title>
<link>http://arxiv.org/abs/1805.09001</link>
<description rdf:parseType="Literal">&lt;p&gt;In neural network, synaptic strength could be seen as probability to transmit
impulse, and function could exist from transmission probability to synaptic
strength. If the function satisfies constraint such as continuity and
monotonicity, neural network would always go to one unique fixed point. A
biological image classifier is proposed to utilize this fixed point.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Sizhong_L/0/1/0/all/0/1&quot;&gt;Lan Sizhong&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09298">
<title>Learning towards Minimum Hyperspherical Energy. (arXiv:1805.09298v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.09298</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural networks are a powerful class of nonlinear functions that can be
trained end-to-end on various applications. While the over-parametrization
nature in many neural networks renders the ability to fit complex functions and
the strong representation power to handle challenging tasks, it also leads to
highly correlated neurons that can hurt the generalization ability and incur
unnecessary computation cost. As a result, how to regularize the network to
avoid undesired representation redundancy becomes an important issue. To this
end, we draw inspiration from a well-known problem in physics -- Thomson
problem, where one seeks to find a state that distributes N electrons on a unit
sphere as even as possible with minimum potential energy. In light of this
intuition, we reduce the redundancy regularization problem to generic energy
minimization, and propose a minimum hyperspherical energy (MHE) objective as
generic regularization for neural networks. We also propose a few novel
variants of MHE, and provide some insights from a theoretical point of view.
Finally, we apply networks with MHE regularization to several challenging
tasks. Extensive experiments demonstrate the effectiveness of our method, by
showing the superior performance with MHE regularization.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1&quot;&gt;Weiyang Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_R/0/1/0/all/0/1&quot;&gt;Rongmei Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1&quot;&gt;Zhen Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1&quot;&gt;Lixin Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1&quot;&gt;Zhiding Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dai_B/0/1/0/all/0/1&quot;&gt;Bo Dai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_L/0/1/0/all/0/1&quot;&gt;Le Song&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11046">
<title>Scalable Methods for 8-bit Training of Neural Networks. (arXiv:1805.11046v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.11046</link>
<description rdf:parseType="Literal">&lt;p&gt;Quantized Neural Networks (QNNs) are often used to improve network efficiency
during the inference phase, i.e. after the network has been trained. Extensive
research in the field suggests many different quantization schemes. Still, the
number of bits required, as well as the best quantization scheme, are yet
unknown. Our theoretical analysis suggests that most of the training process is
robust to substantial precision reduction, and points to only a few specific
operations that require higher precision. Armed with this knowledge, we
quantize the model parameters, activations and layer gradients to 8-bit,
leaving at a higher precision only the final step in the computation of the
weight gradients. Additionally, as QNNs require batch-normalization to be
trained at high precision, we introduce Range Batch-Normalization (BN) which
has significantly higher tolerance to quantization noise and improved
computational complexity. Our simulations show that Range BN is equivalent to
the traditional batch norm if a precise scale adjustment, which can be
approximated analytically, is applied. To the best of the authors&apos; knowledge,
this work is the first to quantize the weights, activations, as well as a
substantial volume of the gradients stream, in all layers (including batch
normalization) to 8-bit while showing state-of-the-art results over the
ImageNet-1K dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Banner_R/0/1/0/all/0/1&quot;&gt;Ron Banner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hubara_I/0/1/0/all/0/1&quot;&gt;Itay Hubara&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hoffer_E/0/1/0/all/0/1&quot;&gt;Elad Hoffer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Soudry_D/0/1/0/all/0/1&quot;&gt;Daniel Soudry&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02782">
<title>Training Augmentation with Adversarial Examples for Robust Speech Recognition. (arXiv:1806.02782v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1806.02782</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper explores the use of adversarial examples in training speech
recognition systems to increase robustness of deep neural network acoustic
models. During training, the fast gradient sign method is used to generate
adversarial examples augmenting the original training data. Different from
conventional data augmentation based on data transformations, the examples are
dynamically generated based on current acoustic model parameters. We assess the
impact of adversarial data augmentation in experiments on the Aurora-4 and
CHiME-4 single-channel tasks, showing improved robustness against noise and
channel variation. Further improvement is obtained when combining adversarial
examples with teacher/student training, leading to a 23% relative word error
rate reduction on Aurora-4.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_S/0/1/0/all/0/1&quot;&gt;Sining Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yeh_C/0/1/0/all/0/1&quot;&gt;Ching-Feng Yeh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ostendorf_M/0/1/0/all/0/1&quot;&gt;Mari Ostendorf&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hwang_M/0/1/0/all/0/1&quot;&gt;Mei-Yuh Hwang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_L/0/1/0/all/0/1&quot;&gt;Lei Xie&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05009">
<title>Tree Edit Distance Learning via Adaptive Symbol Embeddings. (arXiv:1806.05009v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1806.05009</link>
<description rdf:parseType="Literal">&lt;p&gt;Metric learning has the aim to improve classification accuracy by learning a
distance measure which brings data points from the same class closer together
and pushes data points from different classes further apart. Recent research
has demonstrated that metric learning approaches can also be applied to trees,
such as molecular structures, abstract syntax trees of computer programs, or
syntax trees of natural language, by learning the cost function of an edit
distance, i.e. the costs of replacing, deleting, or inserting nodes in a tree.
However, learning such costs directly may yield an edit distance which violates
metric axioms, is challenging to interpret, and may not generalize well.
&lt;/p&gt;
&lt;p&gt;In this contribution, we propose a novel metric learning approach for trees
which learns an edit distance indirectly by embedding the tree nodes as
vectors, such that the Euclidean distance between those vectors supports class
discrimination. We learn such embeddings by reducing the distance to
prototypical trees from the same class and increasing the distance to
prototypical trees from different classes. In our experiments, we show that our
proposed metric learning approach improves upon the state-of-the-art in metric
learning for trees on six benchmark data sets, ranging from computer science
over biomedical data to a natural-language processing data set containing over
300,000 nodes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Paassen_B/0/1/0/all/0/1&quot;&gt;Benjamin Paa&amp;#xdf;en&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gallicchio_C/0/1/0/all/0/1&quot;&gt;Claudio Gallicchio&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Micheli_A/0/1/0/all/0/1&quot;&gt;Alessio Micheli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hammer_B/0/1/0/all/0/1&quot;&gt;Barbara Hammer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05662">
<title>GLoMo: Unsupervisedly Learned Relational Graphs as Transferable Representations. (arXiv:1806.05662v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1806.05662</link>
<description rdf:parseType="Literal">&lt;p&gt;Modern deep transfer learning approaches have mainly focused on learning
generic feature vectors from one task that are transferable to other tasks,
such as word embeddings in language and pretrained convolutional features in
vision. However, these approaches usually transfer unary features and largely
ignore more structured graphical representations. This work explores the
possibility of learning generic latent relational graphs that capture
dependencies between pairs of data units (e.g., words or pixels) from
large-scale unlabeled data and transferring the graphs to downstream tasks. Our
proposed transfer learning framework improves performance on various tasks
including question answering, natural language inference, sentiment analysis,
and image classification. We also show that the learned graphs are generic
enough to be transferred to different embeddings on which the graphs have not
been trained (including GloVe embeddings, ELMo embeddings, and task-specific
RNN hidden unit), or embedding-free units such as image pixels.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1&quot;&gt;Zhilin Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1&quot;&gt;Jake Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dhingra_B/0/1/0/all/0/1&quot;&gt;Bhuwan Dhingra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_K/0/1/0/all/0/1&quot;&gt;Kaiming He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cohen_W/0/1/0/all/0/1&quot;&gt;William W. Cohen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Salakhutdinov_R/0/1/0/all/0/1&quot;&gt;Ruslan Salakhutdinov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+LeCun_Y/0/1/0/all/0/1&quot;&gt;Yann LeCun&lt;/a&gt;</dc:creator>
</item></rdf:RDF>