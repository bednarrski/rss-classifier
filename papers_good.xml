<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Good papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Good Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-05-16T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.06242"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.06280"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.06366"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1705.04058"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.02599"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.06020"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.06061"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.06064"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.06085"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.06248"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.06297"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.00981"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.06299"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.06370"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.06431"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.06440"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.04432"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.06146"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.09111"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.04775"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.04950"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1805.06242">
<title>Conversational Analysis using Utterance-level Attention-based Bidirectional Recurrent Neural Networks. (arXiv:1805.06242v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1805.06242</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent approaches for dialogue act recognition have shown that context from
preceding utterances is important to classify the subsequent one. It was shown
that the performance improves rapidly when the context is taken into account.
We propose an utterance-level attention-based bidirectional recurrent neural
network (Utt-Att-BiRNN) model to analyze the importance of preceding utterances
to classify the current one. In our setup, the BiRNN is given the input set of
current and preceding utterances. Our model outperforms previous models that
use only preceding utterances as context on the used corpus. Another
contribution of the article is to discover the amount of information in each
utterance to classify the subsequent one and to show that context-based
learning not only improves the performance but also achieves higher confidence
in the classification. We use character- and word-level features to represent
the utterances. The results are presented for character and word feature
representations and as an ensemble model of both representations. We found that
when classifying short utterances, the closest preceding utterances contributes
to a higher degree.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bothe_C/0/1/0/all/0/1&quot;&gt;Chandrakant Bothe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Magg_S/0/1/0/all/0/1&quot;&gt;Sven Magg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Weber_C/0/1/0/all/0/1&quot;&gt;Cornelius Weber&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wermter_S/0/1/0/all/0/1&quot;&gt;Stefan Wermter&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.06280">
<title>A Context-based Approach for Dialogue Act Recognition using Simple Recurrent Neural Networks. (arXiv:1805.06280v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1805.06280</link>
<description rdf:parseType="Literal">&lt;p&gt;Dialogue act recognition is an important part of natural language
understanding. We investigate the way dialogue act corpora are annotated and
the learning approaches used so far. We find that the dialogue act is
context-sensitive within the conversation for most of the classes.
Nevertheless, previous models of dialogue act classification work on the
utterance-level and only very few consider context. We propose a novel
context-based learning method to classify dialogue acts using a character-level
language model utterance representation, and we notice significant improvement.
We evaluate this method on the Switchboard Dialogue Act corpus, and our results
show that the consideration of the preceding utterances as a context of the
current utterance improves dialogue act detection.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bothe_C/0/1/0/all/0/1&quot;&gt;Chandrakant Bothe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Weber_C/0/1/0/all/0/1&quot;&gt;Cornelius Weber&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Magg_S/0/1/0/all/0/1&quot;&gt;Sven Magg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wermter_S/0/1/0/all/0/1&quot;&gt;Stefan Wermter&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.06366">
<title>Towards Complex Artificial Life. (arXiv:1805.06366v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1805.06366</link>
<description rdf:parseType="Literal">&lt;p&gt;An object-oriented combinator chemistry was used to construct an artificial
organism with a system architecture possessing characteristics necessary for
organisms to evolve into more complex forms. This architecture supports
modularity by providing a mechanism for the construction of executable modules
called $methods$ that can be duplicated and specialized to increase complexity.
At the same time, its support for concurrency provides the flexibility in
execution order necessary for redundancy, degeneracy and parallelism to
mitigate increased replication costs. The organism is a moving,
self-replicating, spatially distributed assembly of elemental combinators
called a $roving \: pile.$ The pile hosts an asynchronous message passing
computation implemented by parallel subprocesses encoded by genes distributed
through out the pile like the plasmids of a bacterial cell.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Williams_L/0/1/0/all/0/1&quot;&gt;Lance R. Williams&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1705.04058">
<title>Neural Style Transfer: A Review. (arXiv:1705.04058v5 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1705.04058</link>
<description rdf:parseType="Literal">&lt;p&gt;The seminal work of Gatys et al. demonstrated the power of Convolutional
Neural Networks (CNN) in creating artistic imagery by separating and
recombining image content and style. This process of using CNN to render a
content image in different styles is referred to as Neural Style Transfer
(NST). Since then, NST has become a trending topic both in academic literature
and industrial applications. It is receiving increasing attention and a variety
of approaches are proposed to either improve or extend the original NST
algorithm. This review aims to provide an overview of the current progress
towards NST, as well as discussing its various applications and open problems
for future research.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jing_Y/0/1/0/all/0/1&quot;&gt;Yongcheng Jing&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1&quot;&gt;Yezhou Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feng_Z/0/1/0/all/0/1&quot;&gt;Zunlei Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1&quot;&gt;Jingwen Ye&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1&quot;&gt;Yizhou Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_M/0/1/0/all/0/1&quot;&gt;Mingli Song&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.02599">
<title>Superconducting Optoelectronic Neurons II: Receiver Circuits. (arXiv:1805.02599v3 [q-bio.NC] UPDATED)</title>
<link>http://arxiv.org/abs/1805.02599</link>
<description rdf:parseType="Literal">&lt;p&gt;Circuits using superconducting single-photon detectors and Josephson
junctions to perform signal reception, synaptic weighting, and integration are
investigated. The circuits convert photon-detection events into flux quanta,
the number of which is determined by the synaptic weight. The current from many
synaptic connections is inductively coupled to a superconducting loop that
implements the neuronal threshold operation. Designs are presented for synapses
and neurons that perform integration as well as detect coincidence events for
temporal coding. Both excitatory and inhibitory connections are demonstrated.
It is shown that a neuron with a single integration loop can receive input from
1000 such synaptic connections, and neurons of similar design could employ many
loops for dendritic processing.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Shainline_J/0/1/0/all/0/1&quot;&gt;Jeffrey M. Shainline&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Buckley_S/0/1/0/all/0/1&quot;&gt;Sonia M. Buckley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+McCaughan_A/0/1/0/all/0/1&quot;&gt;Adam N. McCaughan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Castellanos_Beltran_M/0/1/0/all/0/1&quot;&gt;Manuel Castellanos-Beltran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Donnelly_C/0/1/0/all/0/1&quot;&gt;Christine A. Donnelly&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Schneider_M/0/1/0/all/0/1&quot;&gt;Michael L. Schneider&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Mirin_R/0/1/0/all/0/1&quot;&gt;Richard P. Mirin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Nam_S/0/1/0/all/0/1&quot;&gt;Sae Woo Nam&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.06020">
<title>Do deep reinforcement learning agents model intentions?. (arXiv:1805.06020v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1805.06020</link>
<description rdf:parseType="Literal">&lt;p&gt;Inferring other agents&apos; mental states such as their knowledge, beliefs and
intentions is thought to be essential for effective interactions with other
agents. Recently, multiagent systems trained via deep reinforcement learning
have been shown to succeed in solving different tasks, but it remains unclear
how each agent modeled or represented other agents in their environment. In
this work we test whether deep reinforcement learning agents explicitly
represent other agents&apos; intentions (their specific aims or goals) during a task
in which the agents had to coordinate the covering of different spots in a 2D
environment. In particular, we tracked over time the performance of a linear
decoder trained to predict the final goal of all agents from the hidden state
of each agent&apos;s neural network controller. We observed that the hidden layers
of agents represented explicit information about other agents&apos; goals, i.e. the
target landmark they ended up covering. We also performed a series of
experiments, in which some agents were replaced by others with fixed goals, to
test the level of generalization of the trained agents. We noticed that during
the training phase the agents developed a differential preference for each
goal, which hindered generalization. To alleviate the above problem, we propose
simple changes to the MADDPG training algorithm which leads to better
generalization against unseen agents. We believe that training protocols
promoting more active intention reading mechanisms, e.g. by preventing simple
symmetry-breaking solutions, is a promising direction towards achieving a more
robust generalization in different cooperative and competitive tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Matiisen_T/0/1/0/all/0/1&quot;&gt;Tambet Matiisen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Labash_A/0/1/0/all/0/1&quot;&gt;Aqeel Labash&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Majoral_D/0/1/0/all/0/1&quot;&gt;Daniel Majoral&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aru_J/0/1/0/all/0/1&quot;&gt;Jaan Aru&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vicente_R/0/1/0/all/0/1&quot;&gt;Raul Vicente&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.06061">
<title>SoPa: Bridging CNNs, RNNs, and Weighted Finite-State Machines. (arXiv:1805.06061v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1805.06061</link>
<description rdf:parseType="Literal">&lt;p&gt;Recurrent and convolutional neural networks comprise two distinct families of
models that have proven to be useful for encoding natural language utterances.
In this paper we present SoPa, a new model that aims to bridge these two
approaches. SoPa combines neural representation learning with weighted
finite-state automata (WFSAs) to learn a soft version of traditional surface
patterns. We show that SoPa is an extension of a one-layer CNN, and that such
CNNs are equivalent to a restricted version of SoPa, and accordingly, to a
restricted form of WFSA. Empirically, on three text classification tasks, SoPa
is comparable or better than both a BiLSTM (RNN) baseline and a CNN baseline,
and is particularly useful in small data settings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schwartz_R/0/1/0/all/0/1&quot;&gt;Roy Schwartz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Thomson_S/0/1/0/all/0/1&quot;&gt;Sam Thomson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Smith_N/0/1/0/all/0/1&quot;&gt;Noah A. Smith&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.06064">
<title>Paper Abstract Writing through Editing Mechanism. (arXiv:1805.06064v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1805.06064</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a paper abstract writing system based on an attentive neural
sequence-to-sequence model that can take a title as input and automatically
generate an abstract. We design a novel Writing-editing Network that can attend
to both the title and the previously generated abstract drafts and then
iteratively revise and polish the abstract. With two series of Turing tests,
where the human judges are asked to distinguish the system-generated abstracts
from human-written ones, our system passes Turing tests by junior domain
experts at a rate up to 30% and by non-expert at a rate up to 80%.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1&quot;&gt;Qingyun Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1&quot;&gt;Zhihao Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1&quot;&gt;Lifu Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Whitehead_S/0/1/0/all/0/1&quot;&gt;Spencer Whitehead&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1&quot;&gt;Boliang Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ji_H/0/1/0/all/0/1&quot;&gt;Heng Ji&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Knight_K/0/1/0/all/0/1&quot;&gt;Kevin Knight&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.06085">
<title>PACT: Parameterized Clipping Activation for Quantized Neural Networks. (arXiv:1805.06085v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1805.06085</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep learning algorithms achieve high classification accuracy at the expense
of significant computation cost. To address this cost, a number of quantization
schemes have been proposed - but most of these techniques focused on quantizing
weights, which are relatively smaller in size compared to activations. This
paper proposes a novel quantization scheme for activations during training -
that enables neural networks to work well with ultra low precision weights and
activations without any significant accuracy degradation. This technique,
PArameterized Clipping acTivation (PACT), uses an activation clipping parameter
$\alpha$ that is optimized during training to find the right quantization
scale. PACT allows quantizing activations to arbitrary bit precisions, while
achieving much better accuracy relative to published state-of-the-art
quantization schemes. We show, for the first time, that both weights and
activations can be quantized to 4-bits of precision while still achieving
accuracy comparable to full precision networks across a range of popular models
and datasets. We also show that exploiting these reduced-precision
computational units in hardware can enable a super-linear improvement in
inferencing performance due to a significant reduction in the area of
accelerator compute engines coupled with the ability to retain the quantized
model and activation data in on-chip memories.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1&quot;&gt;Jungwook Choi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zhuo Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Venkataramani_S/0/1/0/all/0/1&quot;&gt;Swagath Venkataramani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chuang_P/0/1/0/all/0/1&quot;&gt;Pierce I-Jen Chuang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Srinivasan_V/0/1/0/all/0/1&quot;&gt;Vijayalakshmi Srinivasan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gopalakrishnan_K/0/1/0/all/0/1&quot;&gt;Kailash Gopalakrishnan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.06248">
<title>Modeling Human Inference of Others&apos; Intentions in Complex Situations with Plan Predictability Bias. (arXiv:1805.06248v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1805.06248</link>
<description rdf:parseType="Literal">&lt;p&gt;A recent approach based on Bayesian inverse planning for the &quot;theory of mind&quot;
has shown good performance in modeling human cognition. However, perfect
inverse planning differs from human cognition during one kind of complex tasks
due to human bounded rationality. One example is an environment in which there
are many available plans for achieving a specific goal. We propose a &quot;plan
predictability oriented model&quot; as a model of inferring other peoples&apos; goals in
complex environments. This model adds the bias that people prefer predictable
plans. This bias is calculated with simple plan prediction. We tested this
model with a behavioral experiment in which humans observed the partial path of
goal-directed actions. Our model had a higher correlation with human inference.
We also confirmed the robustness of our model with complex tasks and determined
that it can be improved by taking account of individual differences in &quot;bounded
rationality&quot;.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nakahashi_R/0/1/0/all/0/1&quot;&gt;Ryo Nakahashi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yamada_S/0/1/0/all/0/1&quot;&gt;Seiji Yamada&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.06297">
<title>A robust self-learning method for fully unsupervised cross-lingual mappings of word embeddings. (arXiv:1805.06297v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1805.06297</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent work has managed to learn cross-lingual word embeddings without
parallel data by mapping monolingual embeddings to a shared space through
adversarial training. However, their evaluation has focused on favorable
conditions, using comparable corpora or closely-related languages, and we show
that they often fail in more realistic scenarios. This work proposes an
alternative approach based on a fully unsupervised initialization that
explicitly exploits the structural similarity of the embeddings, and a robust
self-learning algorithm that iteratively improves this solution. Our method
succeeds in all tested scenarios and obtains the best published results in
standard datasets, even surpassing previous supervised systems. Our
implementation is released as an open source project at
https://github.com/artetxem/vecmap.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Artetxe_M/0/1/0/all/0/1&quot;&gt;Mikel Artetxe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Labaka_G/0/1/0/all/0/1&quot;&gt;Gorka Labaka&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Agirre_E/0/1/0/all/0/1&quot;&gt;Eneko Agirre&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.00981">
<title>Adaptive Representation Selection in Contextual Bandit. (arXiv:1802.00981v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1802.00981</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider an extension of the contextual bandit setting, motivated by
several practical applications, where an unlabeled history of contexts can
become available for pre-training before the online decision-making begins. We
propose an approach for improving the performance of contextual bandit in such
setting, via adaptive, dynamic representation learning, which combines offline
pre-training on unlabeled history of contexts with online selection and
modification of embedding functions. Our experiments on a variety of datasets
and in different nonstationary environments demonstrate clear advantages of our
approach over the standard contextual bandit.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_B/0/1/0/all/0/1&quot;&gt;Baihan Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cecchi_G/0/1/0/all/0/1&quot;&gt;Guillermo Cecchi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bouneffouf_D/0/1/0/all/0/1&quot;&gt;Djallel Bouneffouf&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rish_I/0/1/0/all/0/1&quot;&gt;Irina Rish&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.06299">
<title>Learning Graph Embeddings on Constant-Curvature Manifolds for Change Detection in Graph Streams. (arXiv:1805.06299v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.06299</link>
<description rdf:parseType="Literal">&lt;p&gt;The space of graphs is characterized by a non-trivial geometry, which often
complicates performing inference in practical applications. A common approach
is to use embedding techniques to represent graphs as points in a conventional
Euclidean space, but non-Euclidean spaces are often better suited for embedding
graphs. Among these, constant curvature manifolds (CCMs), like hyperspheres and
hyperboloids, offer a computationally tractable way to compute metric, yet
non-Euclidean, geodesic distances. In this paper, we introduce a novel
adversarial graph embedding technique to represent graphs on CCMs, and exploit
such a mapping for detecting changes in stationarity in a graph-generating
process. To this end, we introduce a novel family of change detection tests
operating by means of distances on CCMs. We perform experiments on synthetic
graph streams, and on sequences of functional networks extracted from iEEG data
with the aim of detecting the onset of epileptic seizures. We show that our
methods are able to detect extremely small changes in the graph-generating
process, consistently outperforming solutions based on Euclidean embeddings.
The general nature of our framework highlights its potential to be extended to
other applications characterized by graph data or non-Euclidean geometries.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Grattarola_D/0/1/0/all/0/1&quot;&gt;Daniele Grattarola&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zambon_D/0/1/0/all/0/1&quot;&gt;Daniele Zambon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Alippi_C/0/1/0/all/0/1&quot;&gt;Cesare Alippi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Livi_L/0/1/0/all/0/1&quot;&gt;Lorenzo Livi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.06370">
<title>Progress &amp; Compress: A scalable framework for continual learning. (arXiv:1805.06370v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.06370</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce a conceptually simple and scalable framework for continual
learning domains where tasks are learned sequentially. Our method is constant
in the number of parameters and is designed to preserve performance on
previously encountered tasks while accelerating learning progress on subsequent
problems. This is achieved through training two neural networks: A knowledge
base, capable of solving previously encountered problems, which is connected to
an active column that is employed to efficiently learn the current task. After
learning a new task, the active column is distilled into the knowledge base,
taking care to protect any previously learnt tasks. This cycle of active
learning (progression) followed by consolidation (compression) requires no
architecture growth, no access to or storing of previous data or tasks, and no
task-specific parameters. Thus, it is a learning process that may be sustained
over a lifetime of tasks while supporting forward transfer and minimising
forgetting. We demonstrate the progress &amp;amp; compress approach on sequential
classification of handwritten alphabets as well as two reinforcement learning
domains: Atari games and 3D maze navigation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Schwarz_J/0/1/0/all/0/1&quot;&gt;Jonathan Schwarz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Luketina_J/0/1/0/all/0/1&quot;&gt;Jelena Luketina&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Czarnecki_W/0/1/0/all/0/1&quot;&gt;Wojciech M. Czarnecki&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Grabska_Barwinska_A/0/1/0/all/0/1&quot;&gt;Agnieszka Grabska-Barwinska&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Teh_Y/0/1/0/all/0/1&quot;&gt;Yee Whye Teh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pascanu_R/0/1/0/all/0/1&quot;&gt;Razvan Pascanu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hadsell_R/0/1/0/all/0/1&quot;&gt;Raia Hadsell&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.06431">
<title>ChoiceNet: Robust Learning by Revealing Output Correlations. (arXiv:1805.06431v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.06431</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we focus on the supervised learning problem with corrupted
training data. We assume that the training dataset is generated from a mixture
of a target distribution and other unknown distributions. We estimate the
quality of each data by revealing the correlation between the generated
distribution and the target distribution. To this end, we present a novel
framework referred to here as ChoiceNet that can robustly infer the target
distribution in the presence of inconsistent data. We demonstrate that the
proposed framework is applicable to both classification and regression tasks.
ChoiceNet is extensively evaluated in comprehensive experiments, where we show
that it constantly outperforms existing baseline methods in the handling of
noisy data. Particularly, ChoiceNet is successfully applied to autonomous
driving tasks where it learns a safe driving policy from a dataset with mixed
qualities. In the classification task, we apply the proposed method to the
CIFAR-10 dataset and it shows superior performances in terms of robustness to
noisy labels.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Choi_S/0/1/0/all/0/1&quot;&gt;Sungjoon Choi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hong_S/0/1/0/all/0/1&quot;&gt;Sanghoon Hong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lim_S/0/1/0/all/0/1&quot;&gt;Sungbin Lim&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.06440">
<title>Regularization Learning Networks. (arXiv:1805.06440v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.06440</link>
<description rdf:parseType="Literal">&lt;p&gt;Despite their impressive performance, Deep Neural Networks (DNNs) typically
underperform Gradient Boosting Trees (GBTs) on many tabular-dataset learning
tasks. We propose that applying a different regularization coefficient to each
weight might boost the performance of DNNs by allowing them to make more use of
the more relevant inputs. However, this will lead to an intractable number of
hyperparameters. Here, we introduce Regularization Learning Networks (RLNs),
which overcome this challenge by introducing an efficient hyperparameter tuning
scheme that minimizes a new Counterfactual Loss. Our results show that RLNs
significantly improve DNNs on tabular datasets, and achieve comparable results
to GBTs, with the best performance achieved with an ensemble that combines GBTs
and RLNs. RLNs produce extremely sparse networks, eliminating up to 99.8% of
the network edges and 82% of the input features, thus providing more
interpretable models and reveal the importance that the network assigns to
different inputs. RLNs could efficiently learn a single network in datasets
that comprise both tabular and unstructured data, such as in the setting of
medical imaging accompanied by electronic health records.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Shavitt_I/0/1/0/all/0/1&quot;&gt;Ira Shavitt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Segal_E/0/1/0/all/0/1&quot;&gt;Eran Segal&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.04432">
<title>Integrated Model, Batch and Domain Parallelism in Training Neural Networks. (arXiv:1712.04432v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1712.04432</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a new integrated method of exploiting model, batch and domain
parallelism for the training of deep neural networks (DNNs) on large
distributed-memory computers using minibatch stochastic gradient descent (SGD).
Our goal is to find an efficient parallelization strategy for a fixed batch
size using $P$ processes. Our method is inspired by the communication-avoiding
algorithms in numerical linear algebra. We see $P$ processes as logically
divided into a $P_r \times P_c$ grid where the $P_r$ dimension is implicitly
responsible for model/domain parallelism and the $P_c$ dimension is implicitly
responsible for batch parallelism. In practice, the integrated matrix-based
parallel algorithm encapsulates these types of parallelism automatically. We
analyze the communication complexity and analytically demonstrate that the
lowest communication costs are often achieved neither with pure model nor with
pure data parallelism. We also show how the domain parallel approach can help
in extending the theoretical scaling limit of the typical batch parallel
method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gholami_A/0/1/0/all/0/1&quot;&gt;Amir Gholami&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Azad_A/0/1/0/all/0/1&quot;&gt;Ariful Azad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jin_P/0/1/0/all/0/1&quot;&gt;Peter Jin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Keutzer_K/0/1/0/all/0/1&quot;&gt;Kurt Keutzer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Buluc_A/0/1/0/all/0/1&quot;&gt;Aydin Buluc&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.06146">
<title>Universal Language Model Fine-tuning for Text Classification. (arXiv:1801.06146v3 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1801.06146</link>
<description rdf:parseType="Literal">&lt;p&gt;Inductive transfer learning has greatly impacted computer vision, but
existing approaches in NLP still require task-specific modifications and
training from scratch. We propose Universal Language Model Fine-tuning
(ULMFiT), an effective transfer learning method that can be applied to any task
in NLP, and introduce techniques that are key for fine-tuning a language model.
Our method significantly outperforms the state-of-the-art on six text
classification tasks, reducing the error by 18-24% on the majority of datasets.
Furthermore, with only 100 labeled examples, it matches the performance of
training from scratch on 100x more data. We open-source our pretrained models
and code.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Howard_J/0/1/0/all/0/1&quot;&gt;Jeremy Howard&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ruder_S/0/1/0/all/0/1&quot;&gt;Sebastian Ruder&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.09111">
<title>Learning architectures based on quantum entanglement: a simple matrix product state algorithm for image recognition. (arXiv:1803.09111v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1803.09111</link>
<description rdf:parseType="Literal">&lt;p&gt;It is a fundamental, but still elusive question whether methods based on
quantum mechanics, in particular on quantum entanglement, can be used for
classical information processing and machine learning. Even partial answer to
this question would bring important insights to both fields of machine learning
and quantum mechanics. In this work, we implement simple numerical experiments,
related to pattern/images classification, in which we represent the classifiers
by many-qubit quantum states written in the matrix product states (MPS).
Classical machine learning algorithm is applied to these quantum states to
learn the classical data. We explicitly show how quantum features (i.e.,
single-site and bipartite entanglement) can emerge in such represented images.
Particularly, entanglement characterizes here the importance of data, and such
information are used to guide the architecture of MPS, and improve the
efficiency. The number of needed qubits can be reduced to less than $1/10$ of
the original number. We expect such numerical experiments could open new paths
in classical machine learning algorithms, and at the same time shed lights on
generic quantum simulations/computations for machine learning tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yuhan Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xiao Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lewenstein_M/0/1/0/all/0/1&quot;&gt;Maciej Lewenstein&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ran_S/0/1/0/all/0/1&quot;&gt;Shi-Ju Ran&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.04775">
<title>Distribution Regression Network. (arXiv:1804.04775v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1804.04775</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce our Distribution Regression Network (DRN) which performs
regression from input probability distributions to output probability
distributions. Compared to existing methods, DRN learns with fewer model
parameters and easily extends to multiple input and multiple output
distributions. On synthetic and real-world datasets, DRN performs similarly or
better than the state-of-the-art. Furthermore, DRN generalizes the conventional
multilayer perceptron (MLP). In the framework of MLP, each node encodes a real
number, whereas in DRN, each node encodes a probability distribution.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kou_C/0/1/0/all/0/1&quot;&gt;Connie Kou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1&quot;&gt;Hwee Kuan Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ng_T/0/1/0/all/0/1&quot;&gt;Teck Khim Ng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.04950">
<title>DeepFM: An End-to-End Wide &amp; Deep Learning Framework for CTR Prediction. (arXiv:1804.04950v2 [cs.IR] UPDATED)</title>
<link>http://arxiv.org/abs/1804.04950</link>
<description rdf:parseType="Literal">&lt;p&gt;Learning sophisticated feature interactions behind user behaviors is critical
in maximizing CTR for recommender systems. Despite great progress, existing
methods have a strong bias towards low- or high-order interactions, or rely on
expertise feature engineering. In this paper, we show that it is possible to
derive an end-to-end learning model that emphasizes both low- and high-order
feature interactions. The proposed framework, DeepFM, combines the power of
factorization machines for recommendation and deep learning for feature
learning in a new neural network architecture. Compared to the latest Wide &amp;amp;
Deep model from Google, DeepFM has a shared raw feature input to both its
&quot;wide&quot; and &quot;deep&quot; components, with no need of feature engineering besides raw
features. DeepFM, as a general learning framework, can incorporate various
network architectures in its deep component. In this paper, we study two
instances of DeepFM where its &quot;deep&quot; component is DNN and PNN respectively, for
which we denote as DeepFM-D and DeepFM-P. Comprehensive experiments are
conducted to demonstrate the effectiveness of DeepFM-D and DeepFM-P over the
existing models for CTR prediction, on both benchmark data and commercial data.
We conduct online A/B test in Huawei App Market, which reveals that DeepFM-D
leads to more than 10% improvement of click-through rate in the production
environment, compared to a well-engineered LR model. We also covered related
practice in deploying our framework in Huawei App Market.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_H/0/1/0/all/0/1&quot;&gt;Huifeng Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_R/0/1/0/all/0/1&quot;&gt;Ruiming Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ye_Y/0/1/0/all/0/1&quot;&gt;Yunming Ye&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Zhenguo Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1&quot;&gt;Xiuqiang He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dong_Z/0/1/0/all/0/1&quot;&gt;Zhenhua Dong&lt;/a&gt;</dc:creator>
</item></rdf:RDF>