<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Good papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Good Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-09-06T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.06530"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.01696"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.01721"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.01771"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.01941"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.01997"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.02031"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.02077"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.02079"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.02094"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.02112"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.05812"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.05402"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.01509"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.09293"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.09442"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.01715"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.01749"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.01829"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.01833"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.01845"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.01887"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.01913"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.01999"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.02064"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.02104"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.02121"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1708.07469"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08905"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.01132"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.00758"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.01185"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1712.06530">
<title>Dynamic Weight Alignment for Temporal Convolutional Neural Networks. (arXiv:1712.06530v5 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1712.06530</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we propose a method of improving Convolutional Neural Networks
(CNN) by determining the optimal alignment of weights and inputs using dynamic
programming. Conventional CNNs convolve learnable shared weights, or filters,
across the input data. These filters use an inner product to linearly match the
shared weights to a window of the input. However, it is possible that there
exists a more optimal alignment of weights. Thus, we propose the use of Dynamic
Time Warping (DTW) to dynamically align the weights to optimized input
elements. This dynamic alignment is especially useful for time series
recognition due to the complexities with temporal distortions, such as varying
rates and sequence lengths. We demonstrate the effectiveness of the proposed
architecture on the Unipen online handwritten digit and character datasets, the
UCI Spoken Arabic Digit dataset, and the UCI Activities of Daily Life dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Iwana_B/0/1/0/all/0/1&quot;&gt;Brian Kenji Iwana&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Uchida_S/0/1/0/all/0/1&quot;&gt;Seiichi Uchida&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.01696">
<title>TVQA: Localized, Compositional Video Question Answering. (arXiv:1809.01696v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1809.01696</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent years have witnessed an increasing interest in image-based
question-answering (QA) tasks. However, due to data limitations, there has been
much less work on video-based QA. In this paper, we present TVQA, a large-scale
video QA dataset based on 6 popular TV shows. TVQA consists of 152,545 QA pairs
from 21,793 clips, spanning over 460 hours of video. Questions are designed to
be compositional in nature, requiring systems to jointly localize relevant
moments within a clip, comprehend subtitle-based dialogue, and recognize
relevant visual concepts. We provide analyses of this new dataset as well as
several baselines and a multi-stream end-to-end trainable neural network
framework for the TVQA task. The dataset is publicly available at
&lt;a href=&quot;http://tvqa.cs.unc.edu.&quot;&gt;this http URL&lt;/a&gt;
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lei_J/0/1/0/all/0/1&quot;&gt;Jie Lei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_L/0/1/0/all/0/1&quot;&gt;Licheng Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bansal_M/0/1/0/all/0/1&quot;&gt;Mohit Bansal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Berg_T/0/1/0/all/0/1&quot;&gt;Tamara L. Berg&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.01721">
<title>Three-Stage Speaker Verification Architecture in Emotional Talking Environments. (arXiv:1809.01721v1 [cs.SD])</title>
<link>http://arxiv.org/abs/1809.01721</link>
<description rdf:parseType="Literal">&lt;p&gt;Speaker verification performance in neutral talking environment is usually
high, while it is sharply decreased in emotional talking environments. This
performance degradation in emotional environments is due to the problem of
mismatch between training in neutral environment while testing in emotional
environments. In this work, a three-stage speaker verification architecture has
been proposed to enhance speaker verification performance in emotional
environments. This architecture is comprised of three cascaded stages: gender
identification stage followed by an emotion identification stage followed by a
speaker verification stage. The proposed framework has been evaluated on two
distinct and independent emotional speech datasets: in-house dataset and
Emotional Prosody Speech and Transcripts dataset. Our results show that speaker
verification based on both gender information and emotion information is
superior to each of speaker verification based on gender information only,
emotion information only, and neither gender information nor emotion
information. The attained average speaker verification performance based on the
proposed framework is very alike to that attained in subjective assessment by
human listeners.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shahin_I/0/1/0/all/0/1&quot;&gt;Ismail Shahin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nassif_A/0/1/0/all/0/1&quot;&gt;Ali Bou Nassif&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.01771">
<title>An Analysis of Hierarchical Text Classification Using Word Embeddings. (arXiv:1809.01771v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1809.01771</link>
<description rdf:parseType="Literal">&lt;p&gt;Efficient distributed numerical word representation models (word embeddings)
combined with modern machine learning algorithms have recently yielded
considerable improvement on automatic document classification tasks. However,
the effectiveness of such techniques has not been assessed for the hierarchical
text classification (HTC) yet. This study investigates the application of those
models and algorithms on this specific problem by means of experimentation and
analysis. We trained classification models with prominent machine learning
algorithm implementations---fastText, XGBoost, SVM, and Keras&apos; CNN---and
noticeable word embeddings generation methods---GloVe, word2vec, and
fastText---with publicly available data and evaluated them with measures
specifically appropriate for the hierarchical context. FastText achieved an
${}_{LCA}F_1$ of 0.893 on a single-labeled version of the RCV1 dataset. An
analysis indicates that using word embeddings and its flavors is a very
promising approach for HTC.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stein_R/0/1/0/all/0/1&quot;&gt;Roger A. Stein&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jaques_P/0/1/0/all/0/1&quot;&gt;Patricia A. Jaques&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Valiati_J/0/1/0/all/0/1&quot;&gt;Joao F. Valiati&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.01941">
<title>Why are Sequence-to-Sequence Models So Dull? Understanding the Low-Diversity Problem of Chatbots. (arXiv:1809.01941v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1809.01941</link>
<description rdf:parseType="Literal">&lt;p&gt;Diversity is a long-studied topic in information retrieval that usually
refers to the requirement that retrieved results should be non-repetitive and
cover different aspects. In a conversational setting, an additional dimension
of diversity matters: an engaging response generation system should be able to
output responses that are diverse and interesting. Sequence-to-sequence
(Seq2Seq) models have been shown to be very effective for response generation.
However, dialogue responses generated by Seq2Seq models tend to have low
diversity. In this paper, we review known sources and existing approaches to
this low-diversity problem. We also identify a source of low diversity that has
been little studied so far, namely model over-confidence. We sketch several
directions for tackling model over-confidence and, hence, the low-diversity
problem, including confidence penalties and label smoothing.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_S/0/1/0/all/0/1&quot;&gt;Shaojie Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rijke_M/0/1/0/all/0/1&quot;&gt;Maarten de Rijke&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.01997">
<title>Dual Ask-Answer Network for Machine Reading Comprehension. (arXiv:1809.01997v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1809.01997</link>
<description rdf:parseType="Literal">&lt;p&gt;There are three modalities in the reading comprehension setting: question,
answer and context. The task of question answering or question generation aims
to infer an answer or a question when given the counterpart based on context.
We present a novel two-way neural sequence transduction model that connects
three modalities, allowing it to learn two tasks simultaneously and mutually
benefit one another. During training, the model receives
question-context-answer triplets as input and captures the cross-modal
interaction via a hierarchical attention process. Unlike previous joint
learning paradigms that leverage the duality of question generation and
question answering at data level, we solve such dual tasks at the architecture
level by mirroring the network structure and partially sharing components at
different layers. This enables the knowledge to be transferred from one task to
another, helping the model to find a general representation for each modality.
The evaluation on four public datasets shows that our dual-learning model
outperforms the mono-learning counterpart as well as the state-of-the-art joint
models on both question answering and question generation tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiao_H/0/1/0/all/0/1&quot;&gt;Han Xiao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1&quot;&gt;Feng Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1&quot;&gt;Yanjian Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_J/0/1/0/all/0/1&quot;&gt;Jingyao Zheng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.02031">
<title>Planning with Arithmetic and Geometric Attributes. (arXiv:1809.02031v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1809.02031</link>
<description rdf:parseType="Literal">&lt;p&gt;A desirable property of an intelligent agent is its ability to understand its
environment to quickly generalize to novel tasks and compose simpler tasks into
more complex ones. If the environment has geometric or arithmetic structure,
the agent should exploit these for faster generalization. Building on recent
work that augments the environment with user-specified attributes, we show that
further equipping these attributes with the appropriate geometric and
arithmetic structure brings substantial gains in sample complexity.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Folque_D/0/1/0/all/0/1&quot;&gt;David Folqu&amp;#xe9;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sukhbaatar_S/0/1/0/all/0/1&quot;&gt;Sainbayar Sukhbaatar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Szlam_A/0/1/0/all/0/1&quot;&gt;Arthur Szlam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bruna_J/0/1/0/all/0/1&quot;&gt;Joan Bruna&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.02077">
<title>IDSGAN: Generative Adversarial Networks for Attack Generation against Intrusion Detection. (arXiv:1809.02077v1 [cs.CR])</title>
<link>http://arxiv.org/abs/1809.02077</link>
<description rdf:parseType="Literal">&lt;p&gt;As an important tool in security, the intrusion detection system bears the
responsibility of the defense to network attacks performed by malicious
traffic. Nowadays, with the help of machine learning algorithms, the intrusion
detection system develops rapidly. However, the robustness of this system is
questionable when it faces the adversarial attacks. To improve the detection
system, more potential attack approaches should be researched. In this paper, a
framework of the generative adversarial networks, IDSGAN, is proposed to
generate the adversarial attacks, which can deceive and evade the intrusion
detection system. Considering that the internal structure of the detection
system is unknown to attackers, adversarial attack examples perform the
black-box attacks against the detection system. IDSGAN leverages a generator to
transform original malicious traffic into adversarial malicious traffic. A
discriminator classifies traffic examples and simulates the black-box detection
system. More significantly, we only modify part of the attacks&apos; nonfunctional
features to guarantee the validity of the intrusion. Based on the dataset
NSL-KDD, the feasibility of the model is demonstrated to attack many detection
systems with different attacks and the excellent results are achieved.
Moreover, the robustness of IDSGAN is verified by changing the amount of the
unmodified features.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1&quot;&gt;Zilong Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1&quot;&gt;Yong Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xue_Z/0/1/0/all/0/1&quot;&gt;Zhi Xue&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.02079">
<title>Adversarial Over-Sensitivity and Over-Stability Strategies for Dialogue Models. (arXiv:1809.02079v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1809.02079</link>
<description rdf:parseType="Literal">&lt;p&gt;We present two categories of model-agnostic adversarial strategies that
reveal the weaknesses of several generative, task-oriented dialogue models:
Should-Not-Change strategies that evaluate over-sensitivity to small and
semantics-preserving edits, as well as Should-Change strategies that test if a
model is over-stable against subtle yet semantics-changing modifications. We
next perform adversarial training with each strategy, employing a max-margin
approach for negative generative examples. This not only makes the target
dialogue model more robust to the adversarial inputs, but also helps it perform
significantly better on the original inputs. Moreover, training on all
strategies combined achieves further improvements, achieving a new
state-of-the-art performance on the original task (also verified via human
evaluation). In addition to adversarial training, we also address the
robustness task at the model-level, by feeding it subword units as both inputs
and outputs, and show that the resulting model is equally competitive, requires
only 1/4 of the original vocabulary size, and is robust to one of the
adversarial strategies (to which the original model is vulnerable) even without
adversarial training.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Niu_T/0/1/0/all/0/1&quot;&gt;Tong Niu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bansal_M/0/1/0/all/0/1&quot;&gt;Mohit Bansal&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.02094">
<title>Uncovering divergent linguistic information in word embeddings with lessons for intrinsic and extrinsic evaluation. (arXiv:1809.02094v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1809.02094</link>
<description rdf:parseType="Literal">&lt;p&gt;Following the recent success of word embeddings, it has been argued that
there is no such thing as an ideal representation for words, as different
models tend to capture divergent and often mutually incompatible aspects like
semantics/syntax and similarity/relatedness. In this paper, we show that each
embedding model captures more information than directly apparent. A linear
transformation that adjusts the similarity order of the model without any
external resource can tailor it to achieve better results in those aspects,
providing a new perspective on how embeddings encode divergent linguistic
information. In addition, we explore the relation between intrinsic and
extrinsic evaluation, as the effect of our transformations in downstream tasks
is higher for unsupervised systems than for supervised ones.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Artetxe_M/0/1/0/all/0/1&quot;&gt;Mikel Artetxe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Labaka_G/0/1/0/all/0/1&quot;&gt;Gorka Labaka&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lopez_Gazpio_I/0/1/0/all/0/1&quot;&gt;I&amp;#xf1;igo Lopez-Gazpio&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Agirre_E/0/1/0/all/0/1&quot;&gt;Eneko Agirre&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.02112">
<title>ANS: Adaptive Network Scaling for Deep Rectifier Reinforcement Learning Models. (arXiv:1809.02112v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1809.02112</link>
<description rdf:parseType="Literal">&lt;p&gt;This work provides a thorough study on how reward scaling can affect
performance of deep reinforcement learning agents. In particular, we would like
to answer the question that how does reward scaling affect non-saturating ReLU
networks in RL? This question matters because ReLU is one of the most effective
activation functions for deep learning models. We also propose an Adaptive
Network Scaling framework to find a suitable scale of the rewards during
learning for better performance. We conducted empirical studies to justify the
solution.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1&quot;&gt;Yeah-Hua Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_F/0/1/0/all/0/1&quot;&gt;Fan-Yun Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chang_Y/0/1/0/all/0/1&quot;&gt;Yen-Yu Chang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_S/0/1/0/all/0/1&quot;&gt;Should-De Lin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.05812">
<title>Impossibility of deducing preferences and rationality from human policy. (arXiv:1712.05812v4 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1712.05812</link>
<description rdf:parseType="Literal">&lt;p&gt;Inverse reinforcement learning (IRL) attempts to infer human rewards or
preferences from observed behavior. Since human planning systematically
deviates from rationality, several approaches have been tried to account for
specific human shortcomings. However, there has been little analysis of the
general problem of inferring the reward of a human of unknown rationality. The
observed behavior can, in principle, be decomposed into two components: a
reward function and a planning algorithm, both of which have to be inferred
from behavior. This paper presents a No Free Lunch theorem, showing that,
without making `normative&apos; assumptions beyond the data, nothing about the human
reward function can be deduced from human behavior. Unlike most No Free Lunch
theorems, this cannot be alleviated by regularising with simplicity
assumptions. We show that the simplest hypotheses which explain the data are
generally degenerate.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Armstrong_S/0/1/0/all/0/1&quot;&gt;Stuart Armstrong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mindermann_S/0/1/0/all/0/1&quot;&gt;S&amp;#xf6;ren Mindermann&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.05402">
<title>Imitation Learning with Concurrent Actions in 3D Games. (arXiv:1803.05402v5 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1803.05402</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work we describe a novel deep reinforcement learning architecture
that allows multiple actions to be selected at every time-step in an efficient
manner. Multi-action policies allow complex behaviours to be learnt that would
otherwise be hard to achieve when using single action selection techniques. We
use both imitation learning and temporal difference (TD) reinforcement learning
(RL) to provide a 4x improvement in training time and 2.5x improvement in
performance over single action selection TD RL. We demonstrate the capabilities
of this network using a complex in-house 3D game. Mimicking the behavior of the
expert teacher significantly improves world state exploration and allows the
agents vision system to be trained more rapidly than TD RL alone. This initial
training technique kick-starts TD learning and the agent quickly learns to
surpass the capabilities of the expert.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Harmer_J/0/1/0/all/0/1&quot;&gt;Jack Harmer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gisslen_L/0/1/0/all/0/1&quot;&gt;Linus Gissl&amp;#xe9;n&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Val_J/0/1/0/all/0/1&quot;&gt;Jorge del Val&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Holst_H/0/1/0/all/0/1&quot;&gt;Henrik Holst&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bergdahl_J/0/1/0/all/0/1&quot;&gt;Joakim Bergdahl&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Olsson_T/0/1/0/all/0/1&quot;&gt;Tom Olsson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sjoo_K/0/1/0/all/0/1&quot;&gt;Kristoffer Sj&amp;#xf6;&amp;#xf6;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nordin_M/0/1/0/all/0/1&quot;&gt;Magnus Nordin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.01509">
<title>RECS: Robust Graph Embedding Using Connection Subgraphs. (arXiv:1805.01509v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.01509</link>
<description rdf:parseType="Literal">&lt;p&gt;The success of graph embeddings or node representation learning in a variety
of downstream tasks, such as node classification, link prediction, and
recommendation systems, has led to their popularity in recent years.
Representation learning algorithms aim to preserve local and global network
structure by identifying node neighborhood notions. However, many existing
algorithms generate embeddings that fail to properly preserve the network
structure, or lead to unstable representations due to random processes (e.g.,
random walks to generate context) and, thus, cannot generate to multi-graph
problems. In this paper, we propose RECS, a novel, stable graph embedding
algorithmic framework. RECS learns graph representations using connection
subgraphs by employing the analogy of graphs with electrical circuits. It
preserves both local and global connectivity patterns, and addresses the issue
of high-degree nodes. Further, it exploits the strength of weak ties and
meta-data that have been neglected by baselines. The experiments show that RECS
outperforms state-of-the-art algorithms by up to 36.85% on multi-label
classification problem. Further, in contrast to baselines, RECS, being
deterministic, is completely stable.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Al_Sayouri_S/0/1/0/all/0/1&quot;&gt;Saba A. Al-Sayouri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koutra_D/0/1/0/all/0/1&quot;&gt;Danai Koutra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Papalexakis_E/0/1/0/all/0/1&quot;&gt;Evangelos E. Papalexakis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lam_S/0/1/0/all/0/1&quot;&gt;Sarah S. Lam&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.09293">
<title>A Summary Description of the A2RD Project. (arXiv:1808.09293v3 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1808.09293</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper describes the Autonomous Architecture Over Restricted Domains
project. It begins with the description of the context upon which the project
is focused, and in the sequence describes the project and implementation
models. It finish by presenting the environment conceptual model, showing where
stand the components, inputs and facilities required to interact among the
intelligent agents of the various implementations in their respective and
restricted, routing domains (Autonomous Systems) which together make the
Internet work.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Braga_J/0/1/0/all/0/1&quot;&gt;Juliao Braga&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Silva_J/0/1/0/all/0/1&quot;&gt;Joao Nuno Silva&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Endo_P/0/1/0/all/0/1&quot;&gt;Patricia Takako Endo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Omar_N/0/1/0/all/0/1&quot;&gt;Nizam Omar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.09442">
<title>Discriminative Deep Dyna-Q: Robust Planning for Dialogue Policy Learning. (arXiv:1808.09442v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1808.09442</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents a Discriminative Deep Dyna-Q (D3Q) approach to improving
the effectiveness and robustness of Deep Dyna-Q (DDQ), a recently proposed
framework that extends the Dyna-Q algorithm to integrate planning for
task-completion dialogue policy learning. To obviate DDQ&apos;s high dependency on
the quality of simulated experiences, we incorporate an RNN-based discriminator
in D3Q to differentiate simulated experience from real user experience in order
to control the quality of training data. Experiments show that D3Q
significantly outperforms DDQ by controlling the quality of simulated
experience used for planning. The effectiveness and robustness of D3Q is
further demonstrated in a domain extension setting, where the agent&apos;s
capability of adapting to a changing environment is tested.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Su_S/0/1/0/all/0/1&quot;&gt;Shang-Yu Su&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xiujun Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1&quot;&gt;Jianfeng Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Jingjing Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yun-Nung Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.01715">
<title>Bridging machine learning and cryptography in defence against adversarial attacks. (arXiv:1809.01715v1 [cs.CR])</title>
<link>http://arxiv.org/abs/1809.01715</link>
<description rdf:parseType="Literal">&lt;p&gt;In the last decade, deep learning algorithms have become very popular thanks
to the achieved performance in many machine learning and computer vision tasks.
However, most of the deep learning architectures are vulnerable to so called
adversarial examples. This questions the security of deep neural networks (DNN)
for many security- and trust-sensitive domains. The majority of the proposed
existing adversarial attacks are based on the differentiability of the DNN cost
function.Defence strategies are mostly based on machine learning and signal
processing principles that either try to detect-reject or filter out the
adversarial perturbations and completely neglect the classical cryptographic
component in the defence. In this work, we propose a new defence mechanism
based on the second Kerckhoffs&apos;s cryptographic principle which states that the
defence and classification algorithm are supposed to be known, but not the key.
To be compliant with the assumption that the attacker does not have access to
the secret key, we will primarily focus on a gray-box scenario and do not
address a white-box one. More particularly, we assume that the attacker does
not have direct access to the secret block, but (a) he completely knows the
system architecture, (b) he has access to the data used for training and
testing and (c) he can observe the output of the classifier for each given
input. We show empirically that our system is efficient against most famous
state-of-the-art attacks in black-box and gray-box scenarios.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Taran_O/0/1/0/all/0/1&quot;&gt;Olga Taran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rezaeifar_S/0/1/0/all/0/1&quot;&gt;Shideh Rezaeifar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Voloshynovskiy_S/0/1/0/all/0/1&quot;&gt;Slava Voloshynovskiy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.01749">
<title>A deep learning approach for Magnetic Resonance Fingerprinting. (arXiv:1809.01749v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1809.01749</link>
<description rdf:parseType="Literal">&lt;p&gt;Current popular methods for Magnetic Resonance Fingerprint (MRF) recovery are
bottlenecked by the heavy storage and computation requirements of a
matched-filtering step due to the growing size and complexity of the
fingerprint dictionaries in multi-parametric quantitative MRI applications. In
this abstract we investigate and evaluate advantages of a deep learning
approach for embedding the manifold of solutions of the Bloch equations and to
address these shortcomings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Golbabaee_M/0/1/0/all/0/1&quot;&gt;Mohammad Golbabaee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1&quot;&gt;Dongdong Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gomez_P/0/1/0/all/0/1&quot;&gt;Pedro A. G&amp;#xf3;mez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Menzel_M/0/1/0/all/0/1&quot;&gt;Marion I. Menzel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Davies_M/0/1/0/all/0/1&quot;&gt;Mike E. Davies&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.01829">
<title>Adversarial Reprogramming of Sequence Classification Neural Networks. (arXiv:1809.01829v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1809.01829</link>
<description rdf:parseType="Literal">&lt;p&gt;Adversarial Reprogramming has demonstrated success in utilizing pre-trained
neural network classifiers for alternative classification tasks without
modification to the original network. An adversary in such an attack scenario
trains an additive contribution to the inputs to repurpose the neural network
for the new classification task. While this reprogramming approach works for
neural networks with a continuous input space such as that of images, it is not
directly applicable to neural networks trained for tasks such as text
classification, where the input space is discrete. Repurposing such
classification networks would require the attacker to learn an adversarial
program that maps inputs from one discrete space to the other. In this work, we
introduce a context-based vocabulary remapping model to reprogram neural
networks trained on a specific sequence classification task, for a new sequence
classification task desired by the adversary. We propose training procedures
for this adversarial program in both white-box and black-box settings. We
demonstrate the application of our model by adversarially repurposing various
text-classification models including LSTM, bi-directional LSTM and CNN for
alternate classification tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Neekhara_P/0/1/0/all/0/1&quot;&gt;Paarth Neekhara&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hussain_S/0/1/0/all/0/1&quot;&gt;Shehzeen Hussain&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dubnov_S/0/1/0/all/0/1&quot;&gt;Shlomo Dubnov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koushanfar_F/0/1/0/all/0/1&quot;&gt;Farinaz Koushanfar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.01833">
<title>Wasserstein Soft Label Propagation on Hypergraphs: Algorithm and Generalization Error Bounds. (arXiv:1809.01833v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1809.01833</link>
<description rdf:parseType="Literal">&lt;p&gt;Inspired by recent interests of developing machine learning and data mining
algorithms on hypergraphs, we investigate in this paper the semi-supervised
learning algorithm of propagating &quot;soft labels&quot; (e.g. probability
distributions, class membership scores) over hypergraphs, by means of optimal
transportation. Borrowing insights from Wasserstein propagation on graphs
[Solomon et al. 2014], we re-formulate the label propagation procedure as a
message-passing algorithm, which renders itself naturally to a generalization
applicable to hypergraphs through Wasserstein barycenters. Furthermore, in a
PAC learning framework, we provide generalization error bounds for propagating
one-dimensional distributions on graphs and hypergraphs using 2-Wasserstein
distance, by establishing the \textit{algorithmic stability} of the proposed
semi-supervised learning algorithm. These theoretical results also shed new
lights upon deeper understandings of the Wasserstein propagation on graphs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gao_T/0/1/0/all/0/1&quot;&gt;Tingran Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Asoodeh_S/0/1/0/all/0/1&quot;&gt;Shahab Asoodeh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Huang_Y/0/1/0/all/0/1&quot;&gt;Yi Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Evans_J/0/1/0/all/0/1&quot;&gt;James Evans&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.01845">
<title>Yes, IoU loss is submodular - as a function of the mispredictions. (arXiv:1809.01845v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1809.01845</link>
<description rdf:parseType="Literal">&lt;p&gt;This note is a response to [7] in which it is claimed that [13, Proposition
11] is false. We demonstrate here that this assertion in [7] is false, and is
based on a misreading of the notion of set membership in [13, Proposition 11].
We maintain that [13, Proposition 11] is true.
&lt;/p&gt;
&lt;p&gt;([7] = &lt;a href=&quot;/abs/1809.00593&quot;&gt;arXiv:1809.00593&lt;/a&gt;, [13] = &lt;a href=&quot;/abs/1512.07797&quot;&gt;arXiv:1512.07797&lt;/a&gt;)
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Berman_M/0/1/0/all/0/1&quot;&gt;Maxim Berman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Blaschko_M/0/1/0/all/0/1&quot;&gt;Matthew B. Blaschko&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Triki_A/0/1/0/all/0/1&quot;&gt;Amal Rannen Triki&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1&quot;&gt;Jiaqian Yu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.01887">
<title>Travel Speed Prediction with a Hierarchical Convolutional Neural Network and Long Short-Term Memory Model Framework. (arXiv:1809.01887v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1809.01887</link>
<description rdf:parseType="Literal">&lt;p&gt;Advanced travel information and warning, if provided accurately, can help
road users avoid traffic congestion through dynamic route planning and behavior
change. It also enables traffic control centres mitigate the impact of
congestion by activating Intelligent Transport System (ITS) proactively. Deep
learning has become increasingly popular in recent years, following a surge of
innovative GPU technology, high-resolution, big datasets and thriving machine
learning algorithms. However, there are few examples exploiting this emerging
technology to develop applications for traffic prediction. This is largely due
to the difficulty in capturing random, seasonal, non-linear, and
spatio-temporal correlated nature of traffic data. In this paper, we propose a
data-driven modelling approach with a novel hierarchical D-CLSTM-t deep
learning model for short-term traffic speed prediction, a framework combined
with convolutional neural network (CNN) and long short-term memory (LSTM)
models. A deep CNN model is employed to learn the spatio-temporal traffic
patterns of the input graphs, which are then fed into a deep LSTM model for
sequence learning. To capture traffic seasonal variations, time of the day and
day of the week indicators are fused with trained features. The model is
trained end-to-end to predict travel speed in 15 to 90 minutes in the future.
We compare the model performance against other baseline models including CNN,
LGBM, LSTM, and traditional speed-flow curves. Experiment results show that the
D-CLSTM-t outperforms other models considerably. Model tests show that speed
upstream also responds sensibly to a sudden accident occurring downstream. Our
D-CLSTM-t model framework is also highly scalable for future extension such as
for network-wide traffic prediction, which can also be improved by including
additional features such as weather, long term seasonality and accident
information.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1&quot;&gt;Wei Wang&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xucheng Li&lt;/a&gt; (2) ((1) Akins (SNC-Lavalin), UK, (2) Shenzhen Urban Transport Planning Center Co. Ltd, China)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.01913">
<title>Hands-on Experience with Gaussian Processes (GPs): Implementing GPs in Python - I. (arXiv:1809.01913v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1809.01913</link>
<description rdf:parseType="Literal">&lt;p&gt;This document serves to complement our website which was developed with the
aim of exposing the students to Gaussian Processes (GPs). GPs are
non-parametric Bayesian regression models that are largely used by
statisticians and geospatial data scientists for modeling spatial data. Several
open source libraries spanning from Matlab [1], Python [2], R [3] etc., are
already available for simple plug-and-use. The objective of this handout and in
turn the website was to allow the users to develop stand-alone GPs in Python by
relying on minimal external dependencies. To this end, we only use the default
python modules and assist the users in developing their own GPs from scratch
giving them an in-depth knowledge of what goes on under the hood. The module
covers GP inference using maximum likelihood estimation (MLE) and gives
examples of 1D (dummy) spatial data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tiwari_K/0/1/0/all/0/1&quot;&gt;Kshitij Tiwari&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.01999">
<title>Recurrent World Models Facilitate Policy Evolution. (arXiv:1809.01999v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1809.01999</link>
<description rdf:parseType="Literal">&lt;p&gt;A generative recurrent neural network is quickly trained in an unsupervised
manner to model popular reinforcement learning environments through compressed
spatio-temporal representations. The world model&apos;s extracted features are fed
into compact and simple policies trained by evolution, achieving state of the
art results in various environments. We also train our agent entirely inside of
an environment generated by its own internal world model, and transfer this
policy back into the actual environment. Interactive version of paper at
https://worldmodels.github.io
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ha_D/0/1/0/all/0/1&quot;&gt;David Ha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schmidhuber_J/0/1/0/all/0/1&quot;&gt;J&amp;#xfc;rgen Schmidhuber&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.02064">
<title>Sample-Efficient Imitation Learning via Generative Adversarial Nets. (arXiv:1809.02064v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1809.02064</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent work in imitation learning articulate their formulation around the
GAIL architecture, relying on the adversarial training procedure introduced in
GANs. Albeit successful at generating behaviours similar to those demonstrated
to the agent, GAIL suffers from a high sample complexity in the number of
interactions it has to carry out in the environment in order to achieve
satisfactory performance. In this work, we dramatically shrink the amount of
interactions with the environment by leveraging an off-policy actor-critic
architecture. Additionally, employing deterministic policy gradients allows us
to treat the learned reward as a differentiable node in the computational
graph, while preserving the model-free nature of our approach. Our experiments
span a variety of continuous control tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Blonde_L/0/1/0/all/0/1&quot;&gt;Lionel Blond&amp;#xe9;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kalousis_A/0/1/0/all/0/1&quot;&gt;Alexandros Kalousis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.02104">
<title>Are adversarial examples inevitable?. (arXiv:1809.02104v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1809.02104</link>
<description rdf:parseType="Literal">&lt;p&gt;A wide range of defenses have been proposed to harden neural networks against
adversarial attacks. However, a pattern has emerged in which the majority of
adversarial defenses are quickly broken by new attacks. Given the lack of
success at generating robust defenses, we are led to ask a fundamental
question: Are adversarial attacks inevitable?
&lt;/p&gt;
&lt;p&gt;This paper analyzes adversarial examples from a theoretical perspective, and
identifies fundamental bounds on the susceptibility of a classifier to
adversarial attacks. We show that, for certain classes of problems, adversarial
examples are inescapable. Using experiments, we explore the implications of
theoretical guarantees for real-world problems and discuss how factors such as
dimensionality and image complexity limit a classifier&apos;s robustness against
adversarial examples.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shafahi_A/0/1/0/all/0/1&quot;&gt;Ali Shafahi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_W/0/1/0/all/0/1&quot;&gt;W. Ronny Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Studer_C/0/1/0/all/0/1&quot;&gt;Christoph Studer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feizi_S/0/1/0/all/0/1&quot;&gt;Soheil Feizi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goldstein_T/0/1/0/all/0/1&quot;&gt;Tom Goldstein&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.02121">
<title>Learn What Not to Learn: Action Elimination with Deep Reinforcement Learning. (arXiv:1809.02121v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1809.02121</link>
<description rdf:parseType="Literal">&lt;p&gt;Learning how to act when there are many available actions in each state is a
challenging task for Reinforcement Learning (RL) agents, especially when many
of the actions are redundant or irrelevant. In such cases, it is sometimes
easier to learn which actions not to take. In this work, we propose the
Action-Elimination Deep Q-Network (AE-DQN) architecture that combines a Deep RL
algorithm with an Action Elimination Network (AEN) that eliminates sub-optimal
actions. The AEN is trained to predict invalid actions, supervised by an
external elimination signal provided by the environment. Simulations
demonstrate a considerable speedup and added robustness over vanilla DQN in
text-based games with over a thousand discrete actions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zahavy_T/0/1/0/all/0/1&quot;&gt;Tom Zahavy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Haroush_M/0/1/0/all/0/1&quot;&gt;Matan Haroush&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Merlis_N/0/1/0/all/0/1&quot;&gt;Nadav Merlis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mankowitz_D/0/1/0/all/0/1&quot;&gt;Daniel J. Mankowitz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mannor_S/0/1/0/all/0/1&quot;&gt;Shie Mannor&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1708.07469">
<title>DGM: A deep learning algorithm for solving partial differential equations. (arXiv:1708.07469v5 [q-fin.MF] UPDATED)</title>
<link>http://arxiv.org/abs/1708.07469</link>
<description rdf:parseType="Literal">&lt;p&gt;High-dimensional PDEs have been a longstanding computational challenge. We
propose to solve high-dimensional PDEs by approximating the solution with a
deep neural network which is trained to satisfy the differential operator,
initial condition, and boundary conditions. Our algorithm is meshfree, which is
key since meshes become infeasible in higher dimensions. Instead of forming a
mesh, the neural network is trained on batches of randomly sampled time and
space points. The algorithm is tested on a class of high-dimensional free
boundary PDEs, which we are able to accurately solve in up to $200$ dimensions.
The algorithm is also tested on a high-dimensional Hamilton-Jacobi-Bellman PDE
and Burgers&apos; equation. The deep learning algorithm approximates the general
solution to the Burgers&apos; equation for a continuum of different boundary
conditions and physical conditions (which can be viewed as a high-dimensional
space). We call the algorithm a &quot;Deep Galerkin Method (DGM)&quot; since it is
similar in spirit to Galerkin methods, with the solution approximated by a
neural network instead of a linear combination of basis functions. In addition,
we prove a theorem regarding the approximation power of neural networks for a
class of quasilinear parabolic PDEs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-fin/1/au:+Sirignano_J/0/1/0/all/0/1&quot;&gt;Justin Sirignano&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-fin/1/au:+Spiliopoulos_K/0/1/0/all/0/1&quot;&gt;Konstantinos Spiliopoulos&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08905">
<title>AffinityNet: semi-supervised few-shot learning for disease type prediction. (arXiv:1805.08905v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.08905</link>
<description rdf:parseType="Literal">&lt;p&gt;While deep learning has achieved great success in computer vision and many
other fields, currently it does not work very well on patient genomic data with
the &quot;big p, small N&quot; problem (i.e., a relatively small number of samples with
high-dimensional features). In order to make deep learning work with a small
amount of training data, we have to design new models that facilitate few-shot
learning. Here we present the Affinity Network Model (AffinityNet), a data
efficient deep learning model that can learn from a limited number of training
examples and generalize well. The backbone of the AffinityNet model consists of
stacked k-Nearest-Neighbor (kNN) attention pooling layers. The kNN attention
pooling layer is a generalization of the Graph Attention Model (GAM), and can
be applied to not only graphs but also any set of objects regardless of whether
a graph is given or not. As a new deep learning module, kNN attention pooling
layers can be plugged into any neural network model just like convolutional
layers. As a simple special case of kNN attention pooling layer, feature
attention layer can directly select important features that are useful for
classification tasks. Experiments on both synthetic data and cancer genomic
data from TCGA projects show that our AffinityNet model has better
generalization power than conventional neural network models with little
training data. The code is freely available at
https://github.com/BeautyOfWeb/AffinityNet .
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_T/0/1/0/all/0/1&quot;&gt;Tianle Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_A/0/1/0/all/0/1&quot;&gt;Aidong Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.01132">
<title>Generalized Spectral Mixture Kernels for Multi-Task Gaussian Processes. (arXiv:1808.01132v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1808.01132</link>
<description rdf:parseType="Literal">&lt;p&gt;Multi-Task Gaussian processes (MTGPs) have shown a significant progress both
in expressiveness and interpretation of the relatedness between different
tasks: from linear combinations of independent single-output Gaussian processes
(GPs), through the direct modeling of the cross-covariances such as spectral
mixture kernels with phase shift, to the design of multivariate covariance
functions based on spectral mixture kernels which model delays among tasks in
addition to phase differences, and which provide a parametric interpretation of
the relatedness across tasks. In this paper we further extend expressiveness
and interpretability of MTGPs models and introduce a new family of kernels
capable to model nonlinear correlations between tasks as well as dependencies
between spectral mixtures, including time and phase delay. Specifically, we use
generalized convolution spectral mixture kernels for modeling dependencies at
spectral mixture level, and coupling coregionalization for discovering task
level correlations. The proposed kernels for MTGP are validated on artificial
data and compared with existing MTGPs methods on three real-world experiments.
Results indicate the benefits of our more expressive representation with
respect to performance and interpretability.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1&quot;&gt;Kai Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Groot_P/0/1/0/all/0/1&quot;&gt;Perry Groot&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1&quot;&gt;Jinsong Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Marchiori_E/0/1/0/all/0/1&quot;&gt;Elena Marchiori&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.00758">
<title>End-to-end Multimodal Emotion and Gender Recognition with Dynamic Weights of Joint Loss. (arXiv:1809.00758v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1809.00758</link>
<description rdf:parseType="Literal">&lt;p&gt;Multi-task learning (MTL) is one of the method for improving generalizability
of multiple tasks. In order to perform multiple classification tasks with one
neural network model, the losses of each task should be combined. Previous
studies have mostly focused on prediction of multiple tasks using joint loss
with static weights for training model. Choosing weights between tasks have not
taken any considerations while it is set by uniformly or empirically. In this
study, we propose a method to make joint loss using dynamic weights to improve
total performance not an individual performance of tasks, and apply this method
to end-to-end multimodal emotion and gender recognition model using audio and
video data. This approach provides proper weights for each loss of the tasks
when training ends. In our experiment, a performance of emotion and gender
recognition with proposed method shows lower joint loss which is computed as
negative log-likelihood than the one with static weights of joint loss. Also,
our proposed model shows better generalizability than compared models. In our
best knowledge, this research shows the strength of dynamic weights of joint
loss for maximizing total performance at first in emotion and gender
recognition task.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chae_M/0/1/0/all/0/1&quot;&gt;Myungsu Chae&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_T/0/1/0/all/0/1&quot;&gt;Tae-Ho Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shin_Y/0/1/0/all/0/1&quot;&gt;Young Hoon Shin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1&quot;&gt;June-Woo Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1&quot;&gt;Soo-Young Lee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.01185">
<title>DeepPINK: reproducible feature selection in deep neural networks. (arXiv:1809.01185v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1809.01185</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep learning has become increasingly popular in both supervised and
unsupervised machine learning thanks to its outstanding empirical performance.
However, because of their intrinsic complexity, most deep learning methods are
largely treated as black box tools with little interpretability. Even though
recent attempts have been made to facilitate the interpretability of deep
neural networks (DNNs), existing methods are susceptible to noise and lack of
robustness.
&lt;/p&gt;
&lt;p&gt;Therefore, scientists are justifiably cautious about the reproducibility of
the discoveries, which is often related to the interpretability of the
underlying statistical models. In this paper, we describe a method to increase
the interpretability and reproducibility of DNNs by incorporating the idea of
feature selection with controlled error rate. By designing a new DNN
architecture and integrating it with the recently proposed knockoffs framework,
we perform feature selection with a controlled error rate, while maintaining
high power. This new method, DeepPINK (Deep feature selection using
Paired-Input Nonlinear Knockoffs), is applied to both simulated and real data
sets to demonstrate its empirical utility.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1&quot;&gt;Yang Young Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fan_Y/0/1/0/all/0/1&quot;&gt;Yingying Fan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lv_J/0/1/0/all/0/1&quot;&gt;Jinchi Lv&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Noble_W/0/1/0/all/0/1&quot;&gt;William Stafford Noble&lt;/a&gt;</dc:creator>
</item></rdf:RDF>