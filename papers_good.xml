<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Good papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Good Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-05-30T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11703"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11752"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11797"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.12024"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1706.04560"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11144"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11648"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11711"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11768"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11799"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11867"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.12069"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.09303"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.10188"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.11130"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1708.09401"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.03930"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10503"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11008"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11710"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11718"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11761"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11770"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11861"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11916"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11917"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11921"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.12017"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.12076"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.07535"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08770"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.09060"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.02855"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10896"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1805.11703">
<title>Biologically Motivated Algorithms for Propagating Local Target Representations. (arXiv:1805.11703v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1805.11703</link>
<description rdf:parseType="Literal">&lt;p&gt;Finding biologically plausible alternatives to back-propagation of errors is
a fundamentally important challenge in artificial neural network research. In
this paper, we propose a simple learning algorithm called error-driven Local
Representation Alignment, which has strong connections to predictive coding, a
theory that offers a mechanistic way of describing neurocomputational
machinery. In addition, we propose an improved variant of Difference Target
Propagation, another algorithm that comes from the same family of algorithms as
Local Representation Alignment. We compare our learning procedures to several
other biologically-motivated algorithms, including two feedback alignment
algorithms and Equilibrium Propagation. In two benchmark datasets, we find that
both of our proposed learning algorithms yield stable performance and strong
generalization abilities in comparison to other competing back-propagation
alternatives when training deeper, highly nonlinear networks, with Local
Representation Alignment performing the best overall.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ororbia_A/0/1/0/all/0/1&quot;&gt;Alexander G. Ororbia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mali_A/0/1/0/all/0/1&quot;&gt;Ankur Mali&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11752">
<title>Multi-turn Dialogue Response Generation in an Adversarial Learning Framework. (arXiv:1805.11752v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1805.11752</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose an adversarial learning approach to the generation of multi-turn
dialogue responses. Our proposed framework, hredGAN, is based on conditional
generative adversarial networks (GANs). The GAN&apos;s generator is a modified
hierarchical recurrent encoder-decoder network (HRED) and the discriminator is
a word-level bidirectional RNN that shares context and word embedding with the
generator. During inference, noise samples conditioned on the dialogue history
are used to perturb the generator&apos;s latent space to generate several possible
responses. The final response is the one ranked best by the discriminator. The
hredGAN shows major advantages over existing methods: (1) it generalizes better
than networks trained using only the log-likelihood criterion, and (2) it
generates longer, more informative and more diverse responses with high
utterance and topic relevance even with limited training data. This superiority
is demonstrated on the Movie triples and Ubuntu dialogue datasets in terms of
perplexity, BLEU, ROUGE and Distinct n-gram scores.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Olabiyi_O/0/1/0/all/0/1&quot;&gt;Oluwatobi Olabiyi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Salimov_A/0/1/0/all/0/1&quot;&gt;Alan Salimov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khazane_A/0/1/0/all/0/1&quot;&gt;Anish Khazane&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mueller_E/0/1/0/all/0/1&quot;&gt;Erik Mueller&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11797">
<title>Grow and Prune Compact, Fast, and AccurateLSTMs. (arXiv:1805.11797v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.11797</link>
<description rdf:parseType="Literal">&lt;p&gt;Long short-term memory (LSTM) has been widely used for sequential data
modeling. Researchers have increased LSTM depth by stacking LSTM cells to
improve performance. This incurs model redundancy, increases run-time delay,
and makes the LSTMs more prone to overfitting. To address these problems, we
propose a hidden-layer LSTM (H-LSTM) that adds hidden layers to LSTM&apos;s original
one level non-linear control gates. H-LSTM increases accuracy while employing
fewer external stacked layers, thus reducing the number of parameters and
run-time latency significantly. We employ grow-and-prune (GP) training to
iteratively adjust the hidden layers through gradient-based growth and
magnitude-based pruning of connections. This learns both the weights and the
compact architecture of H-LSTM control gates. We have GP-trained H-LSTMs for
image captioning and speech recognition applications. For the NeuralTalk
architecture on the MSCOCO dataset, our three models reduce the number of
parameters by 38.7x [floating-point operations (FLOPs) by 45.5x], run-time
latency by 4.5x, and improve the CIDEr score by 2.6. For the DeepSpeech2
architecture on the AN4 dataset, our two models reduce the number of parameters
by 19.4x (FLOPs by 23.5x), run-time latency by 15.7%, and the word error rate
from 12.9% to 8.7%. Thus, GP-trained H-LSTMs can be seen to be compact, fast,
and accurate.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dai_X/0/1/0/all/0/1&quot;&gt;Xiaoliang Dai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yin_H/0/1/0/all/0/1&quot;&gt;Hongxu Yin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jha_N/0/1/0/all/0/1&quot;&gt;Niraj K. Jha&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.12024">
<title>Privacy Aware Offloading of Deep Neural Networks. (arXiv:1805.12024v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.12024</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep neural networks require large amounts of resources which makes them hard
to use on resource constrained devices such as Internet-of-things devices.
Offloading the computations to the cloud can circumvent these constraints but
introduces a privacy risk since the operator of the cloud is not necessarily
trustworthy. We propose a technique that obfuscates the data before sending it
to the remote computation node. The obfuscated data is unintelligible for a
human eavesdropper but can still be classified with a high accuracy by a neural
network trained on unobfuscated images.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leroux_S/0/1/0/all/0/1&quot;&gt;Sam Leroux&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Verbelen_T/0/1/0/all/0/1&quot;&gt;Tim Verbelen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Simoens_P/0/1/0/all/0/1&quot;&gt;Pieter Simoens&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dhoedt_B/0/1/0/all/0/1&quot;&gt;Bart Dhoedt&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1706.04560">
<title>Neural Models for Key Phrase Detection and Question Generation. (arXiv:1706.04560v3 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1706.04560</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a two-stage neural model to tackle question generation from
documents. First, our model estimates the probability that word sequences in a
document are ones that a human would pick when selecting candidate answers by
training a neural key-phrase extractor on the answers in a question-answering
corpus. Predicted key phrases then act as target answers and condition a
sequence-to-sequence question-generation model with a copy mechanism.
Empirically, our key-phrase extraction model significantly outperforms an
entity-tagging baseline and existing rule-based approaches. We further
demonstrate that our question generation system formulates fluent, answerable
questions from key phrases. This two-stage system could be used to augment or
generate reading comprehension datasets, which may be leveraged to improve
machine reading systems or in educational settings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Subramanian_S/0/1/0/all/0/1&quot;&gt;Sandeep Subramanian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1&quot;&gt;Tong Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yuan_X/0/1/0/all/0/1&quot;&gt;Xingdi Yuan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1&quot;&gt;Saizheng Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bengio_Y/0/1/0/all/0/1&quot;&gt;Yoshua Bengio&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Trischler_A/0/1/0/all/0/1&quot;&gt;Adam Trischler&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11144">
<title>NengoDL: Combining deep learning and neuromorphic modelling methods. (arXiv:1805.11144v2 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1805.11144</link>
<description rdf:parseType="Literal">&lt;p&gt;NengoDL is a software framework designed to combine the strengths of
neuromorphic modelling and deep learning. NengoDL allows users to construct
biologically detailed neural models, intermix those models with deep learning
elements (such as convolutional networks), and then efficiently simulate those
models in an easy-to-use, unified framework. In addition, NengoDL allows users
to apply deep learning training methods to optimize the parameters of
biological neural models. In this paper we present basic usage examples,
benchmarking, and details on the key implementation elements of NengoDL. More
details can be found at https://www.nengo.ai/nengo-dl .
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rasmussen_D/0/1/0/all/0/1&quot;&gt;Daniel Rasmussen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11648">
<title>Teaching Meaningful Explanations. (arXiv:1805.11648v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1805.11648</link>
<description rdf:parseType="Literal">&lt;p&gt;The adoption of machine learning in high-stakes applications such as
healthcare and law has lagged in part because predictions are not accompanied
by explanations comprehensible to the domain user, who often holds ultimate
responsibility for decisions and outcomes. In this paper, we propose an
approach to generate such explanations in which training data is augmented to
include, in addition to features and labels, explanations elicited from domain
users. A joint model is then learned to produce both labels and explanations
from the input features. This simple idea ensures that explanations are
tailored to the complexity expectations and domain knowledge of the consumer.
Evaluation spans multiple modeling techniques on a simple game dataset, an
image dataset, and a chemical odor dataset, showing that our approach is
generalizable across domains and algorithms. Results demonstrate that
meaningful explanations can be reliably taught to machine learning algorithms,
and in some cases, improve modeling accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Codella_N/0/1/0/all/0/1&quot;&gt;Noel C. F. Codella&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hind_M/0/1/0/all/0/1&quot;&gt;Michael Hind&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ramamurthy_K/0/1/0/all/0/1&quot;&gt;Karthikeyan Natesan Ramamurthy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Campbell_M/0/1/0/all/0/1&quot;&gt;Murray Campbell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dhurandhar_A/0/1/0/all/0/1&quot;&gt;Amit Dhurandhar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Varshney_K/0/1/0/all/0/1&quot;&gt;Kush R. Varshney&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wei_D/0/1/0/all/0/1&quot;&gt;Dennis Wei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mojsilovic_A/0/1/0/all/0/1&quot;&gt;Aleksandra Mojsilovic&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11711">
<title>Depth and nonlinearity induce implicit exploration for RL. (arXiv:1805.11711v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.11711</link>
<description rdf:parseType="Literal">&lt;p&gt;The question of how to explore, i.e., take actions with uncertain outcomes to
learn about possible future rewards, is a key question in reinforcement
learning (RL). Here, we show a surprising result: We show that Q-learning with
nonlinear Q-function and no explicit exploration (i.e., a purely greedy policy)
can learn several standard benchmark tasks, including mountain car, equally
well as, or better than, the most commonly-used $\epsilon$-greedy exploration.
We carefully examine this result and show that both the depth of the Q-network
and the type of nonlinearity are important to induce such deterministic
exploration.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dauparas_J/0/1/0/all/0/1&quot;&gt;Justas Dauparas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tomioka_R/0/1/0/all/0/1&quot;&gt;Ryota Tomioka&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hofmann_K/0/1/0/all/0/1&quot;&gt;Katja Hofmann&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11768">
<title>&quot;Press Space to Fire&quot;: Automatic Video Game Tutorial Generation. (arXiv:1805.11768v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1805.11768</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose the problem of tutorial generation for games, i.e. to generate
tutorials which can teach players to play games, as an AI problem. This problem
can be approached in several ways, including generating natural language
descriptions of game rules, generating instructive game levels, and generating
demonstrations of how to play a game using agents that play in a human-like
manner. We further argue that the General Video Game AI framework provides a
useful testbed for addressing this problem.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Green_M/0/1/0/all/0/1&quot;&gt;Michael Cerny Green&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khalifa_A/0/1/0/all/0/1&quot;&gt;Ahmed Khalifa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barros_G/0/1/0/all/0/1&quot;&gt;Gabriella A. B. Barros&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Togelius_J/0/1/0/all/0/1&quot;&gt;Julian Togelius&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11799">
<title>Automated proof synthesis for propositional logic with deep neural networks. (arXiv:1805.11799v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1805.11799</link>
<description rdf:parseType="Literal">&lt;p&gt;This work explores the application of deep learning, a machine learning
technique that uses deep neural networks (DNN) in its core, to an automated
theorem proving (ATP) problem. To this end, we construct a statistical model
which quantifies the likelihood that a proof is indeed a correct one of a given
proposition. Based on this model, we give a proof-synthesis procedure that
searches for a proof in the order of the likelihood. This procedure uses an
estimator of the likelihood of an inference rule being applied at each step of
a proof. As an implementation of the estimator, we propose a
proposition-to-proof architecture, which is a DNN tailored to the automated
proof synthesis problem. To empirically demonstrate its usefulness, we apply
our model to synthesize proofs of propositional logic. We train the
proposition-to-proof model using a training dataset of proposition-proof pairs.
The evaluation against a benchmark set shows the very high accuracy and an
improvement to the recent work of neural proof synthesis.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sekiyama_T/0/1/0/all/0/1&quot;&gt;Taro Sekiyama&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Suenaga_K/0/1/0/all/0/1&quot;&gt;Kohei Suenaga&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11867">
<title>Using Inter-Sentence Diverse Beam Search to Reduce Redundancy in Visual Storytelling. (arXiv:1805.11867v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1805.11867</link>
<description rdf:parseType="Literal">&lt;p&gt;Visual storytelling includes two important parts: coherence between the story
and images as well as the story structure. For image to text neural network
models, similar images in the sequence would provide close information for
story generator to obtain almost identical sentence. However, repeatedly
narrating same objects or events will undermine a good story structure. In this
paper, we proposed an inter-sentence diverse beam search to generate a more
expressive story. Comparing to some recent models of visual storytelling task,
which generate story without considering the generated sentence of the previous
picture, our proposed method can avoid generating identical sentence even given
a sequence of similar pictures.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hsu_C/0/1/0/all/0/1&quot;&gt;Chao-Chun Hsu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1&quot;&gt;Szu-Min Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hsieh_M/0/1/0/all/0/1&quot;&gt;Ming-Hsun Hsieh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ku_L/0/1/0/all/0/1&quot;&gt;Lun-Wei Ku&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.12069">
<title>Omega: An Architecture for AI Unification. (arXiv:1805.12069v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1805.12069</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce the open-ended, modular, self-improving Omega AI unification
architecture which is a refinement of Solomonoff&apos;s Alpha architecture, as
considered from first principles. The architecture embodies several crucial
principles of general intelligence including diversity of representations,
diversity of data types, integrated memory, modularity, and higher-order
cognition. We retain the basic design of a fundamental algorithmic substrate
called an &quot;AI kernel&quot; for problem solving and basic cognitive functions like
memory, and a larger, modular architecture that re-uses the kernel in many
ways. Omega includes eight representation languages and six classes of neural
networks, which are briefly introduced. The architecture is intended to
initially address data science automation, hence it includes many problem
solving methods for statistical tasks. We review the broad software
architecture, higher-order cognition, self-improvement, modular neural
architectures, intelligent agents, the process and memory hierarchy, hardware
abstraction, peer-to-peer computing, and data abstraction facility.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ozkural_E/0/1/0/all/0/1&quot;&gt;Eray &amp;#xd6;zkural&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.09303">
<title>HONE: Higher-Order Network Embeddings. (arXiv:1801.09303v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1801.09303</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper describes a general framework for learning Higher-Order Network
Embeddings (HONE) from graph data based on network motifs. The HONE framework
is highly expressive and flexible with many interchangeable components. The
experimental results demonstrate the effectiveness of learning higher-order
network representations. In all cases, HONE outperforms recent embedding
methods that are unable to capture higher-order structures with a mean relative
gain in AUC of $19\%$ (and up to $75\%$ gain) across a wide variety of networks
and embedding methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rossi_R/0/1/0/all/0/1&quot;&gt;Ryan A. Rossi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ahmed_N/0/1/0/all/0/1&quot;&gt;Nesreen K. Ahmed&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Koh_E/0/1/0/all/0/1&quot;&gt;Eunyee Koh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kim_S/0/1/0/all/0/1&quot;&gt;Sungchul Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rao_A/0/1/0/all/0/1&quot;&gt;Anup Rao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yadkori_Y/0/1/0/all/0/1&quot;&gt;Yasin Abbasi Yadkori&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.10188">
<title>Dialogue Modeling Via Hash Functions: Applications to Psychotherapy. (arXiv:1804.10188v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1804.10188</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a novel machine-learning framework for dialogue modeling which
uses representations based on hash functions. More specifically, each person&apos;s
response is represented by a binary hashcode where each bit reflects presence
or absence of a certain text pattern in the response. Hashcodes serve as
compressed text representations, allowing for efficient similarity search.
Moreover, hashcode of one person&apos;s response can be used as a feature vector for
predicting the hashcode representing another person&apos;s response. The proposed
hashing model of dialogue is obtained by maximizing a novel lower bound on the
mutual information between the hashcodes of consecutive responses. We apply our
approach in psychotherapy domain, evaluating its effectiveness on a real-life
dataset consisting of therapy sessions with patients suffering from depression.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garg_S/0/1/0/all/0/1&quot;&gt;Sahil Garg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cecchi_G/0/1/0/all/0/1&quot;&gt;Guillermo Cecchi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rish_I/0/1/0/all/0/1&quot;&gt;Irina Rish&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_S/0/1/0/all/0/1&quot;&gt;Shuyang Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Steeg_G/0/1/0/all/0/1&quot;&gt;Greg Ver Steeg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goyal_P/0/1/0/all/0/1&quot;&gt;Palash Goyal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Galstyan_A/0/1/0/all/0/1&quot;&gt;Aram Galstyan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.11130">
<title>Clustering Meets Implicit Generative Models. (arXiv:1804.11130v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1804.11130</link>
<description rdf:parseType="Literal">&lt;p&gt;Clustering is a cornerstone of unsupervised learning which can be thought as
disentangling multiple generative mechanisms underlying the data. In this paper
we introduce an algorithmic framework to train mixtures of implicit generative
models which we particularize for variational autoencoders. Relying on an
additional set of discriminators, we propose a competitive procedure in which
the models only need to approximate the portion of the data distribution from
which they can produce realistic samples. As a byproduct, each model is simpler
to train, and a clustering interpretation arises naturally from the
partitioning of the training points among the models. We empirically show that
our approach splits the training distribution in a reasonable way and increases
the quality of the generated samples.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Locatello_F/0/1/0/all/0/1&quot;&gt;Francesco Locatello&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vincent_D/0/1/0/all/0/1&quot;&gt;Damien Vincent&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tolstikhin_I/0/1/0/all/0/1&quot;&gt;Ilya Tolstikhin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ratsch_G/0/1/0/all/0/1&quot;&gt;Gunnar R&amp;#xe4;tsch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gelly_S/0/1/0/all/0/1&quot;&gt;Sylvain Gelly&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Scholkopf_B/0/1/0/all/0/1&quot;&gt;Bernhard Sch&amp;#xf6;lkopf&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1708.09401">
<title>Machine Learning Topological Invariants with Neural Networks. (arXiv:1708.09401v3 [cond-mat.mes-hall] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1708.09401</link>
<description rdf:parseType="Literal">&lt;p&gt;In this Letter we supervisedly train neural networks to distinguish different
topological phases in the context of topological band insulators. After
training with Hamiltonians of one-dimensional insulators with chiral symmetry,
the neural network can predict their topological winding numbers with nearly
100% accuracy, even for Hamiltonians with larger winding numbers that are not
included in the training data. These results show a remarkable success that the
neural network can capture the global and nonlinear topological features of
quantum phases from local inputs. By opening up the neural network, we confirm
that the network does learn the discrete version of the winding number formula.
We also make a couple of remarks regarding the role of the symmetry and the
opposite effect of regularization techniques when applying machine learning to
physical systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Zhang_P/0/1/0/all/0/1&quot;&gt;Pengfei Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Shen_H/0/1/0/all/0/1&quot;&gt;Huitao Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Zhai_H/0/1/0/all/0/1&quot;&gt;Hui Zhai&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.03930">
<title>Visualizing Neural Network Developing Perturbation Theory. (arXiv:1802.03930v2 [physics.comp-ph] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1802.03930</link>
<description rdf:parseType="Literal">&lt;p&gt;In this letter, motivated by the question that whether the empirical fitting
of data by neural network can yield the same structure of physical laws, we
apply the neural network to a simple quantum mechanical two-body scattering
problem with short-range potentials, which by itself also plays an important
role in many branches of physics. We train a neural network to accurately
predict $ s $-wave scattering length, which governs the low-energy scattering
physics, directly from the scattering potential without solving Schr\&quot;odinger
equation or obtaining the wavefunction. After analyzing the neural network, it
is shown that the neural network develops perturbation theory order by order
when the potential increases. This provides an important benchmark to the
machine-assisted physics research or even automated machine learning physics
laws.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Wu_Y/0/1/0/all/0/1&quot;&gt;Yadong Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Zhang_P/0/1/0/all/0/1&quot;&gt;Pengfei Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Shen_H/0/1/0/all/0/1&quot;&gt;Huitao Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Zhai_H/0/1/0/all/0/1&quot;&gt;Hui Zhai&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.10503">
<title>Deep Learning for Topological Invariants. (arXiv:1805.10503v1 [cond-mat.str-el] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1805.10503</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work we design and train deep neural networks to predict topological
invariants for one-dimensional four-band insulators in AIII class whose
topological invariant is the winding number, and two-dimensional two-band
insulators in A class whose topological invariant is the Chern number. Given
Hamiltonians in the momentum space as the input, neural networks can predict
topological invariants for both classes with accuracy close to or higher than
90%, even for Hamiltonians whose invariants are beyond the training data set.
Despite the complexity of the neural network, we find that the output of
certain intermediate hidden layers resembles either the winding angle for
models in AIII class or the solid angle (Berry curvature) for models in A
class, indicating that neural networks essentially capture the mathematical
formula of topological invariants. Our work demonstrates the ability of neural
networks to predict topological invariants for complicated models with local
Hamiltonians as the only input, and offers an example that even a deep neural
network is understandable.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Sun_N/0/1/0/all/0/1&quot;&gt;Ning Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Yi_J/0/1/0/all/0/1&quot;&gt;Jinmin Yi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Zhang_P/0/1/0/all/0/1&quot;&gt;Pengfei Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Shen_H/0/1/0/all/0/1&quot;&gt;Huitao Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Zhai_H/0/1/0/all/0/1&quot;&gt;Hui Zhai&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11008">
<title>A Sequential Embedding Approach for Item Recommendation with Heterogeneous Attributes. (arXiv:1805.11008v1 [cs.IR] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1805.11008</link>
<description rdf:parseType="Literal">&lt;p&gt;Attributes, such as metadata and profile, carry useful information which in
principle can help improve accuracy in recommender systems. However, existing
approaches have difficulty in fully leveraging attribute information due to
practical challenges such as heterogeneity and sparseness. These approaches
also fail to combine recurrent neural networks which have recently shown
effectiveness in item recommendations in applications such as video and music
browsing. To overcome the challenges and to harvest the advantages of sequence
models, we present a novel approach, Heterogeneous Attribute Recurrent Neural
Networks (HA-RNN), which incorporates heterogeneous attributes and captures
sequential dependencies in \textit{both} items and attributes. HA-RNN extends
recurrent neural networks with 1) a hierarchical attribute combination input
layer and 2) an output attribute embedding layer. We conduct extensive
experiments on two large-scale datasets. The new approach show significant
improvements over the state-of-the-art models. Our ablation experiments
demonstrate the effectiveness of the two components to address heterogeneous
attribute challenges including variable lengths and attribute sparseness. We
further investigate why sequence modeling works well by conducting exploratory
studies and show sequence models are more effective when data scale increases.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_K/0/1/0/all/0/1&quot;&gt;Kuan Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_X/0/1/0/all/0/1&quot;&gt;Xing Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Natarajan_P/0/1/0/all/0/1&quot;&gt;Prem Natarajan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11710">
<title>Active and Adaptive Sequential learning. (arXiv:1805.11710v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.11710</link>
<description rdf:parseType="Literal">&lt;p&gt;A framework is introduced for actively and adaptively solving a sequence of
machine learning problems, which are changing in bounded manner from one time
step to the next. An algorithm is developed that actively queries the labels of
the most informative samples from an unlabeled data pool, and that adapts to
the change by utilizing the information acquired in the previous steps. Our
analysis shows that the proposed active learning algorithm based on stochastic
gradient descent achieves a near-optimal excess risk performance for maximum
likelihood estimation. Furthermore, an estimator of the change in the learning
problems using the active learning samples is constructed, which provides an
adaptive sample size selection rule that guarantees the excess risk is bounded
for sufficiently large number of time steps. Experiments with synthetic and
real data are presented to validate our algorithm and theoretical results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bu_Y/0/1/0/all/0/1&quot;&gt;Yuheng Bu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1&quot;&gt;Jiaxun Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Veeravalli_V/0/1/0/all/0/1&quot;&gt;Venugopal V. Veeravalli&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11718">
<title>Deep Mesh Projectors for Inverse Problems. (arXiv:1805.11718v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1805.11718</link>
<description rdf:parseType="Literal">&lt;p&gt;We develop a new learning-based approach to ill-posed inverse problems.
Instead of directly learning the complex mapping from the measured data to the
reconstruction, we learn an ensemble of simpler mappings from data to
projections of the unknown model into random low-dimensional subspaces. We form
the reconstruction by combining the estimated subspace projections. Structured
subspaces of piecewise-constant images on random Delaunay triangulations allow
us to address inverse problems with extremely sparse data and still get good
reconstructions of the unknown geometry. This choice also makes our method
robust against arbitrary data corruptions not seen during training. Further, it
marginalizes the role of the training dataset which is essential for
applications in geophysics where ground-truth datasets are exceptionally
scarce.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gupta_S/0/1/0/all/0/1&quot;&gt;Sidharth Gupta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kothari_K/0/1/0/all/0/1&quot;&gt;Konik Kothari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hoop_M/0/1/0/all/0/1&quot;&gt;Maarten V. de Hoop&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dokmanic_I/0/1/0/all/0/1&quot;&gt;Ivan Dokmani&amp;#x107;&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11761">
<title>Collaborative Learning for Deep Neural Networks. (arXiv:1805.11761v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.11761</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce collaborative learning in which multiple classifier heads of the
same network are simultaneously trained on the same training data to improve
generalization and robustness to label noise with no extra inference cost. It
acquires the strengths from auxiliary training, multi-task learning and
knowledge distillation. There are two important mechanisms involved in
collaborative learning. First, the consensus of multiple views from different
classifier heads on the same example provides supplementary information as well
as regularization to each classifier, thereby improving generalization. Second,
intermediate-level representation (ILR) sharing with backpropagation rescaling
aggregates the gradient flows from all heads, which not only reduces training
computational complexity, but also facilitates supervision to the shared
layers. The empirical results on CIFAR and ImageNet datasets demonstrate that
deep neural networks learned as a group in a collaborative way significantly
reduce the generalization error and increase the robustness to label noise.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Song_G/0/1/0/all/0/1&quot;&gt;Guocong Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chai_W/0/1/0/all/0/1&quot;&gt;Wei Chai&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11770">
<title>AutoZOOM: Autoencoder-based Zeroth Order Optimization Method for Attacking Black-box Neural Networks. (arXiv:1805.11770v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1805.11770</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent studies have shown that adversarial examples in state-of-the-art image
classifiers trained by deep neural networks (DNN) can be easily generated when
the target model is transparent to an attacker, known as the white-box setting.
However, when attacking a deployed machine learning service, one can only
acquire the input-output correspondences of the target model; this is the
so-called black-box attack setting. The major drawback of existing black-box
attacks is the need for excessive model queries, which may lead to a false
sense of model robustness due to inefficient query designs. To bridge this gap,
we propose a generic framework for query-efficient black-box attacks. Our
framework, AutoZOOM, which is short for Autoencoder-based Zeroth Order
Optimization Method, has two novel building blocks towards efficient black-box
attacks: (i) an adaptive random gradient estimation strategy to balance query
counts and distortion, and (ii) an autoencoder trained offline with unlabeled
data towards attack acceleration. Experimental results suggest that, by
applying AutoZOOM to a state-of-the-art black-box attack (ZOO), a significant
reduction in model queries can be achieved without sacrificing the attack
success rate and the visual quality of the resulting adversarial examples. In
particular, when compared to the standard ZOO method, AutoZOOM can consistently
reduce the mean query counts in finding successful adversarial examples by at
least 93% on MNIST, CIFAR-10 and ImageNet datasets. AutoZOOM&apos;s post-success
fine-tuning can further reduce attack distortion.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tu_C/0/1/0/all/0/1&quot;&gt;Chun-Chen Tu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ting_P/0/1/0/all/0/1&quot;&gt;Paishun Ting&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_P/0/1/0/all/0/1&quot;&gt;Pin-Yu Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1&quot;&gt;Sijia Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1&quot;&gt;Huan Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yi_J/0/1/0/all/0/1&quot;&gt;Jinfeng Yi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hsieh_C/0/1/0/all/0/1&quot;&gt;Cho-Jui Hsieh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_S/0/1/0/all/0/1&quot;&gt;Shin-Ming Cheng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11861">
<title>Foresee: Attentive Future Projections of Chaotic Road Environments with Online Training. (arXiv:1805.11861v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.11861</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we train a recurrent neural network to learn dynamics of a
chaotic road environment and to project the future of the environment on an
image. Future projection can be used to anticipate an unseen environment for
example, in autonomous driving. Road environment is highly dynamic and complex
due to the interaction among traffic participants such as vehicles and
pedestrians. Even in this complex environment, a human driver is efficacious to
safely drive on chaotic roads irrespective of the number of traffic
participants. The proliferation of deep learning research has shown the
efficacy of neural networks in learning this human behavior. In the same
direction, we investigate recurrent neural networks to understand the chaotic
road environment which is shared by pedestrians, vehicles (cars, trucks,
bicycles etc.), and sometimes animals as well. We propose \emph{Foresee}, a
unidirectional gated recurrent units (GRUs) network with attention to project
future of the environment in the form of images. We have collected several
videos on Delhi roads consisting of various traffic participants, background
and infrastructure differences (like 3D pedestrian crossing) at various times
on various days. We train \emph{Foresee} in an unsupervised way and we use
online training to project frames up to $0.5$ seconds in advance. We show that
our proposed model performs better than state of the art methods (prednet and
Enc. Dec. LSTM) and finally, we show that our trained model generalizes to a
public dataset for future projections.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1&quot;&gt;Anil Sharma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kumar_P/0/1/0/all/0/1&quot;&gt;Prabhat Kumar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11916">
<title>On the Spectrum of Random Features Maps of High Dimensional Data. (arXiv:1805.11916v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.11916</link>
<description rdf:parseType="Literal">&lt;p&gt;Random feature maps are ubiquitous in modern statistical machine learning,
where they generalize random projections by means of powerful, yet often
difficult to analyze nonlinear operators. In this paper, we leverage the
&quot;concentration&quot; phenomenon induced by random matrix theory to perform a
spectral analysis on the Gram matrix of these random feature maps, here for
Gaussian mixture models of simultaneously large dimension and size. Our results
are instrumental to a deeper understanding on the interplay of the nonlinearity
and the statistics of the data, thereby allowing for a better tuning of random
feature-based techniques.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Liao_Z/0/1/0/all/0/1&quot;&gt;Zhenyu Liao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Couillet_R/0/1/0/all/0/1&quot;&gt;Romain Couillet&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11917">
<title>The Dynamics of Learning: A Random Matrix Approach. (arXiv:1805.11917v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.11917</link>
<description rdf:parseType="Literal">&lt;p&gt;Understanding the learning dynamics of neural networks is one of the key
issues for the improvement of optimization algorithms as well as for the
theoretical comprehension of why deep neural nets work so well today. In this
paper, we introduce a random matrix-based framework to analyze the learning
dynamics of a single-layer linear network on a binary classification problem,
for data of simultaneously large dimension and size, trained by gradient
descent. Our results provide rich insights into common questions in neural
nets, such as overfitting, early stopping and the initialization of training,
thereby opening the door for future studies of more elaborate structures and
models appearing in today&apos;s neural networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Liao_Z/0/1/0/all/0/1&quot;&gt;Zhenyu Liao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Couillet_R/0/1/0/all/0/1&quot;&gt;Romain Couillet&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11921">
<title>Anonymous Walk Embeddings. (arXiv:1805.11921v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.11921</link>
<description rdf:parseType="Literal">&lt;p&gt;The task of representing entire graphs has seen a surge of prominent results,
mainly due to learning convolutional neural networks (CNNs) on graph-structured
data. While CNNs demonstrate state-of-the-art performance in graph
classification task, such methods are supervised and therefore steer away from
the original problem of network representation in task-agnostic manner. Here,
we coherently propose an approach for embedding entire graphs and show that our
feature representations with SVM classifier increase classification accuracy of
CNN algorithms and traditional graph kernels. For this we describe a recently
discovered graph object, anonymous walk, on which we design task-independent
algorithms for learning graph representations in explicit and distributed way.
Overall, our work represents a new scalable unsupervised learning of
state-of-the-art representations of entire graphs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ivanov_S/0/1/0/all/0/1&quot;&gt;Sergey Ivanov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Burnaev_E/0/1/0/all/0/1&quot;&gt;Evgeny Burnaev&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.12017">
<title>Counterstrike: Defending Deep Learning Architectures Against Adversarial Samples by Langevin Dynamics with Supervised Denoising Autoencoder. (arXiv:1805.12017v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.12017</link>
<description rdf:parseType="Literal">&lt;p&gt;Adversarial attacks on deep learning models have been demonstrated to be
imperceptible to a human, while decreasing the model performance considerably.
Attempts to provide invariance against such attacks have denoised adversarial
samples to only send cleaned samples to the classifier. In a similar spirit
this paper proposes a novel effective strategy that allows to relax adversarial
samples onto the underlying manifold of the (unknown) target class
distribution. Specifically, given an off-manifold adversarial example, our
Metroplis-adjusted Langevin algorithm (Mala) guided through a supervised
denoising autoencoder network (sDAE) allows to drive the adversarial samples
towards high density regions of the data generating distribution. So, in a
nutshell the adversarial example is transformed back from off-manifold onto the
data manifold for which the learning model was originally trained and where it
can perform well and robustly. Experiments on various benchmark datasets show
that our novel Malade method exhibits a high robustness against blackbox and
whitebox attacks and outperforms state-of-the-art defense algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Srinivasan_V/0/1/0/all/0/1&quot;&gt;Vignesh Srinivasan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Marban_A/0/1/0/all/0/1&quot;&gt;Arturo Marban&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Muller_K/0/1/0/all/0/1&quot;&gt;Klaus-Robert M&amp;#xfc;ller&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Samek_W/0/1/0/all/0/1&quot;&gt;Wojciech Samek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nakajima_S/0/1/0/all/0/1&quot;&gt;Shinichi Nakajima&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.12076">
<title>Towards Understanding the Role of Over-Parametrization in Generalization of Neural Networks. (arXiv:1805.12076v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.12076</link>
<description rdf:parseType="Literal">&lt;p&gt;Despite existing work on ensuring generalization of neural networks in terms
of scale sensitive complexity measures, such as norms, margin and sharpness,
these complexity measures do not offer an explanation of why neural networks
generalize better with over-parametrization. In this work we suggest a novel
complexity measure based on unit-wise capacities resulting in a tighter
generalization bound for two layer ReLU networks. Our capacity bound correlates
with the behavior of test error with increasing network sizes, and could
potentially explain the improvement in generalization with
over-parametrization. We further present a matching lower bound for the
Rademacher complexity that improves over previous capacity lower bounds for
neural networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Neyshabur_B/0/1/0/all/0/1&quot;&gt;Behnam Neyshabur&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Zhiyuan Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bhojanapalli_S/0/1/0/all/0/1&quot;&gt;Srinadh Bhojanapalli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+LeCun_Y/0/1/0/all/0/1&quot;&gt;Yann LeCun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Srebro_N/0/1/0/all/0/1&quot;&gt;Nathan Srebro&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.07535">
<title>BRUNO: A Deep Recurrent Model for Exchangeable Data. (arXiv:1802.07535v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1802.07535</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a novel model architecture which leverages deep learning tools to
perform exact Bayesian inference on sets of high dimensional, complex
observations. Our model is provably exchangeable, meaning that the joint
distribution over observations is invariant under permutation: this property
lies at the heart of Bayesian inference. The model does not require variational
approximations to train, and new samples can be generated conditional on
previous samples, with cost linear in the size of the conditioning set. The
advantages of our architecture are demonstrated on learning tasks that require
generalisation from short observed sequences while modelling sequence
variability, such as conditional image generation, few-shot learning, and
anomaly detection.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Korshunova_I/0/1/0/all/0/1&quot;&gt;Iryna Korshunova&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Degrave_J/0/1/0/all/0/1&quot;&gt;Jonas Degrave&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Huszar_F/0/1/0/all/0/1&quot;&gt;Ferenc Husz&amp;#xe1;r&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gal_Y/0/1/0/all/0/1&quot;&gt;Yarin Gal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gretton_A/0/1/0/all/0/1&quot;&gt;Arthur Gretton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Dambre_J/0/1/0/all/0/1&quot;&gt;Joni Dambre&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08770">
<title>A Walk with SGD. (arXiv:1802.08770v4 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1802.08770</link>
<description rdf:parseType="Literal">&lt;p&gt;We present novel empirical observations regarding how stochastic gradient
descent (SGD) navigates the loss landscape of over-parametrized deep neural
networks (DNNs). These observations expose the qualitatively different roles of
learning rate and batch-size in DNN optimization and generalization.
Specifically we study the DNN loss surface along the trajectory of SGD by
interpolating the loss surface between parameters from consecutive
\textit{iterations} and tracking various metrics during training. We find that
the loss interpolation between parameters before and after each training
iteration&apos;s update is roughly convex with a minimum (\textit{valley floor}) in
between for most of the training. Based on this and other metrics, we deduce
that for most of the training update steps, SGD moves in valley like regions of
the loss surface by jumping from one valley wall to another at a height above
the valley floor. This &apos;bouncing between walls at a height&apos; mechanism helps SGD
traverse larger distance for small batch sizes and large learning rates which
we find play qualitatively different roles in the dynamics. While a large
learning rate maintains a large height from the valley floor, a small batch
size injects noise facilitating exploration. We find this mechanism is crucial
for generalization because the valley floor has barriers and this exploration
above the valley floor allows SGD to quickly travel far away from the
initialization point (without being affected by barriers) and find flatter
regions, corresponding to better generalization.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Xing_C/0/1/0/all/0/1&quot;&gt;Chen Xing&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Arpit_D/0/1/0/all/0/1&quot;&gt;Devansh Arpit&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tsirigotis_C/0/1/0/all/0/1&quot;&gt;Christos Tsirigotis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bengio_Y/0/1/0/all/0/1&quot;&gt;Yoshua Bengio&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.09060">
<title>An Information-Theoretic View for Deep Learning. (arXiv:1804.09060v5 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1804.09060</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep learning has transformed computer vision, natural language processing,
and speech recognition. However, two critical questions remain obscure: (1) why
do deep neural networks generalize better than shallow networks; and (2) does
it always hold that a deeper network leads to better performance? Specifically,
letting $L$ be the number of convolutional and pooling layers in a deep neural
network, and $n$ be the size of the training sample, we derive an upper bound
on the expected generalization error for this network, i.e.,
&lt;/p&gt;
&lt;p&gt;\begin{eqnarray*}
&lt;/p&gt;
&lt;p&gt;\mathbb{E}[R(W)-R_S(W)] \leq
\exp{\left(-\frac{L}{2}\log{\frac{1}{\eta}}\right)}\sqrt{\frac{2\sigma^2}{n}I(S,W)
}
&lt;/p&gt;
&lt;p&gt;\end{eqnarray*} where $\sigma &amp;gt;0$ is a constant depending on the loss
function, $0&amp;lt;\eta&amp;lt;1$ is a constant depending on the information loss for each
convolutional or pooling layer, and $I(S, W)$ is the mutual information between
the training sample $S$ and the output hypothesis $W$. This upper bound shows
that as the number of convolutional and pooling layers $L$ increases in the
network, the expected generalization error will decrease exponentially to zero.
Layers with strict information loss, such as the convolutional layers, reduce
the generalization error for the whole network; this answers the first
question. However, algorithms with zero expected generalization error does not
imply a small test error or $\mathbb{E}[R(W)]$. This is because
$\mathbb{E}[R_S(W)]$ is large when the information for fitting the data is lost
as the number of layers increases. This suggests that the claim &quot;the deeper the
better&quot; is conditioned on a small training error or $\mathbb{E}[R_S(W)]$.
Finally, we show that deep learning satisfies a weak notion of stability and
the sample complexity of deep neural networks will decrease as $L$ increases.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Jingwei Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Liu_T/0/1/0/all/0/1&quot;&gt;Tongliang Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tao_D/0/1/0/all/0/1&quot;&gt;Dacheng Tao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.02855">
<title>Tile2Vec: Unsupervised representation learning for spatially distributed data. (arXiv:1805.02855v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1805.02855</link>
<description rdf:parseType="Literal">&lt;p&gt;Geospatial analysis lacks methods like the word vector representations and
pre-trained networks that significantly boost performance across a wide range
of natural language and computer vision tasks. To fill this gap, we introduce
Tile2Vec, an unsupervised representation learning algorithm that extends the
distributional hypothesis from natural language -- words appearing in similar
contexts tend to have similar meanings -- to spatially distributed data. We
demonstrate empirically that Tile2Vec learns semantically meaningful
representations on three datasets. Our learned representations significantly
improve performance in downstream classification tasks and, similar to word
vectors, visual analogies can be obtained via simple arithmetic in the latent
space.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jean_N/0/1/0/all/0/1&quot;&gt;Neal Jean&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1&quot;&gt;Sherrie Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Samar_A/0/1/0/all/0/1&quot;&gt;Anshul Samar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Azzari_G/0/1/0/all/0/1&quot;&gt;George Azzari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lobell_D/0/1/0/all/0/1&quot;&gt;David Lobell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ermon_S/0/1/0/all/0/1&quot;&gt;Stefano Ermon&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.10896">
<title>Adaptive Network Sparsification via Dependent Variational Beta-Bernoulli Dropout. (arXiv:1805.10896v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1805.10896</link>
<description rdf:parseType="Literal">&lt;p&gt;While variational dropout approaches have been shown to be effective for
network sparsification, they are still suboptimal in the sense that they set
the dropout rate for each neuron without consideration of the input data. With
such input-independent dropout, each neuron is evolved to be generic across
inputs, which makes it difficult to sparsify networks without accuracy loss. To
overcome this limitation, we propose adaptive variational dropout whose
probabilities are drawn from sparsity-inducing beta-Bernoulli prior. It allows
each neuron to be evolved either to be generic or specific for certain inputs,
or dropped altogether. Such input-adaptive sparsity- inducing dropout allows
the resulting network to tolerate larger degree of sparsity without losing its
expressive power by removing redundancies among features. We validate our
dependent variational beta-Bernoulli dropout on multiple public datasets, on
which it obtains significantly more compact networks than baseline methods,
with consistent accuracy improvements over the base networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lee_J/0/1/0/all/0/1&quot;&gt;Juho Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kim_S/0/1/0/all/0/1&quot;&gt;Saehoon Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yoon_J/0/1/0/all/0/1&quot;&gt;Jaehong Yoon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lee_H/0/1/0/all/0/1&quot;&gt;Hae Beom Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yang_E/0/1/0/all/0/1&quot;&gt;Eunho Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hwang_S/0/1/0/all/0/1&quot;&gt;Sung Ju Hwang&lt;/a&gt;</dc:creator>
</item></rdf:RDF>