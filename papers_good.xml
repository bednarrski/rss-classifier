<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Good papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Good Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-05-27T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10002"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10190"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.06105"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.05859"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09822"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09843"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09938"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09980"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10129"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10174"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.03980"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.04008"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.00934"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.03390"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.00823"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09871"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09898"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09906"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09921"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09965"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10004"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10032"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10130"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10133"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10170"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10212"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10222"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10265"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.02483"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09461"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1805.10002">
<title>Transductive Propagation Network for Few-shot Learning. (arXiv:1805.10002v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.10002</link>
<description rdf:parseType="Literal">&lt;p&gt;Few-shot learning aims to build a learner that quickly generalizes to novel
classes even when a limited number of labeled examples (so-called low-data
problem) are available. Meta-learning is commonly deployed to mimic the test
environment in a training phase for good generalization, where episodes (i.e.,
learning problems) are manually constructed from the training set. This
framework gains a lot of attention to few-shot learning with impressive
performance, though the low-data problem is not fully addressed. In this paper,
we propose Transductive Propagation Network (TPN), a transductive method that
classifies the entire test set at once to alleviate the low-data problem.
Specifically, our proposed network explicitly learns an underlying manifold
space that is appropriate to propagate labels from few-shot examples, where all
parameters of feature embedding, manifold structure, and label propagation are
estimated in an end-to-end way on episodes. We evaluate the proposed method on
the commonly used miniImageNet and tieredImageNet benchmarks and achieve the
state-of-the-art or promising results on these datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yanbin Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1&quot;&gt;Juho Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Park_M/0/1/0/all/0/1&quot;&gt;Minseop Park&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1&quot;&gt;Saehoon Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1&quot;&gt;Yi Yang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.10190">
<title>Snips Voice Platform: an embedded Spoken Language Understanding system for private-by-design voice interfaces. (arXiv:1805.10190v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1805.10190</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents the machine learning architecture of the Snips Voice
Platform, a software solution to perform Spoken Language Understanding on
microprocessors typical of IoT devices. The embedded inference is fast and
accurate while enforcing privacy by design, as no personal user data is
ever~collected. Focusing on Automatic Speech Recognition and Natural Language
Understanding, we detail our approach to training high-performance Machine
Learning models that are small enough to run in real-time on small devices.
Additionally, we describe a data generation procedure that provides sufficient,
high-quality training data without compromising user privacy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Coucke_A/0/1/0/all/0/1&quot;&gt;Alice Coucke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saade_A/0/1/0/all/0/1&quot;&gt;Alaa Saade&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ball_A/0/1/0/all/0/1&quot;&gt;Adrien Ball&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bluche_T/0/1/0/all/0/1&quot;&gt;Th&amp;#xe9;odore Bluche&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Caulier_A/0/1/0/all/0/1&quot;&gt;Alexandre Caulier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leroy_D/0/1/0/all/0/1&quot;&gt;David Leroy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Doumouro_C/0/1/0/all/0/1&quot;&gt;Cl&amp;#xe9;ment Doumouro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gisselbrecht_T/0/1/0/all/0/1&quot;&gt;Thibault Gisselbrecht&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Caltagirone_F/0/1/0/all/0/1&quot;&gt;Francesco Caltagirone&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lavril_T/0/1/0/all/0/1&quot;&gt;Thibaut Lavril&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Primet_M/0/1/0/all/0/1&quot;&gt;Ma&amp;#xeb;l Primet&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dureau_J/0/1/0/all/0/1&quot;&gt;Joseph Dureau&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.06105">
<title>Overcoming the vanishing gradient problem in plain recurrent networks. (arXiv:1801.06105v2 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1801.06105</link>
<description rdf:parseType="Literal">&lt;p&gt;Plain recurrent networks greatly suffer from the vanishing gradient problem
while Gated Neural Networks (GNNs) such as Long-short Term Memory (LSTM) and
Gated Recurrent Unit (GRU) deliver promising results in many sequence learning
tasks through sophisticated network designs. This paper shows how we can
address this problem in a plain recurrent network by analyzing the gating
mechanisms in GNNs. We propose a novel network called the Recurrent Identity
Network (RIN) which allows a plain recurrent network to overcome the vanishing
gradient problem while training very deep models without the use of gates. We
compare this model with IRNNs and LSTMs on multiple sequence modeling
benchmarks. The RINs demonstrate competitive performance and converge faster in
all tasks. Notably, small RIN models produce 12%--67% higher accuracy on the
Sequential and Permuted MNIST datasets and reach state-of-the-art performance
on the bAbI question answering dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1&quot;&gt;Yuhuang Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huber_A/0/1/0/all/0/1&quot;&gt;Adrian Huber&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Anumula_J/0/1/0/all/0/1&quot;&gt;Jithendar Anumula&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1&quot;&gt;Shih-Chii Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.05859">
<title>Neural Network Quine. (arXiv:1803.05859v4 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1803.05859</link>
<description rdf:parseType="Literal">&lt;p&gt;Self-replication is a key aspect of biological life that has been largely
overlooked in Artificial Intelligence systems. Here we describe how to build
and train self-replicating neural networks. The network replicates itself by
learning to output its own weights. The network is designed using a loss
function that can be optimized with either gradient-based or non-gradient-based
methods. We also describe a method we call regeneration to train the network
without explicit optimization, by injecting the network with predictions of its
own parameters. The best solution for a self-replicating network was found by
alternating between regeneration and optimization steps. Finally, we describe a
design for a self-replicating neural network that can solve an auxiliary task
such as MNIST image classification. We observe that there is a trade-off
between the network&apos;s ability to classify images and its ability to replicate,
but training is biased towards increasing its specialization at image
classification at the expense of replication. This is analogous to the
trade-off between reproduction and other tasks observed in nature. We suggest
that a self-replication mechanism for artificial intelligence is useful because
it introduces the possibility of continual improvement through natural
selection.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chang_O/0/1/0/all/0/1&quot;&gt;Oscar Chang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lipson_H/0/1/0/all/0/1&quot;&gt;Hod Lipson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09822">
<title>Filtering and Mining Parallel Data in a Joint Multilingual Space. (arXiv:1805.09822v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1805.09822</link>
<description rdf:parseType="Literal">&lt;p&gt;We learn a joint multilingual sentence embedding and use the distance between
sentences in different languages to filter noisy parallel data and to mine for
parallel data in large news collections. We are able to improve a competitive
baseline on the WMT&apos;14 English to German task by 0.3 BLEU by filtering out 25%
of the training data. The same approach is used to mine additional bitexts for
the WMT&apos;14 system and to obtain competitive results on the BUCC shared task to
identify parallel sentences in comparable corpora. The approach is generic, it
can be applied to many language pairs and it is independent of the architecture
of the machine translation system.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schwenk_H/0/1/0/all/0/1&quot;&gt;Holger Schwenk&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09843">
<title>Baseline Needs More Love: On Simple Word-Embedding-Based Models and Associated Pooling Mechanisms. (arXiv:1805.09843v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1805.09843</link>
<description rdf:parseType="Literal">&lt;p&gt;Many deep learning architectures have been proposed to model the
compositionality in text sequences, requiring a substantial number of
parameters and expensive computations. However, there has not been a rigorous
evaluation regarding the added value of sophisticated compositional functions.
In this paper, we conduct a point-by-point comparative study between Simple
Word-Embedding-based Models (SWEMs), consisting of parameter-free pooling
operations, relative to word-embedding-based RNN/CNN models. Surprisingly,
SWEMs exhibit comparable or even superior performance in the majority of cases
considered. Based upon this understanding, we propose two additional pooling
strategies over learned word embeddings: (i) a max-pooling operation for
improved interpretability; and (ii) a hierarchical pooling operation, which
preserves spatial (n-gram) information within text sequences. We present
experiments on 17 datasets encompassing three tasks: (i) (long) document
classification; (ii) text sequence matching; and (iii) short text tasks,
including classification and tagging. The source code and datasets can be
obtained from https:// github.com/dinghanshen/SWEM.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_D/0/1/0/all/0/1&quot;&gt;Dinghan Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1&quot;&gt;Guoyin Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1&quot;&gt;Wenlin Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Min_M/0/1/0/all/0/1&quot;&gt;Martin Renqiang Min&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Su_Q/0/1/0/all/0/1&quot;&gt;Qinliang Su&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yizhe Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1&quot;&gt;Chunyuan Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Henao_R/0/1/0/all/0/1&quot;&gt;Ricardo Henao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Carin_L/0/1/0/all/0/1&quot;&gt;Lawrence Carin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09938">
<title>Automated Verification of Neural Networks: Advances, Challenges and Perspectives. (arXiv:1805.09938v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1805.09938</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural networks are one of the most investigated and widely used techniques
in Machine Learning. In spite of their success, they still find limited
application in safety- and security-related contexts, wherein assurance about
networks&apos; performances must be provided. In the recent past, automated
reasoning techniques have been proposed by several researchers to close the gap
between neural networks and applications requiring formal guarantees about
their behavior. In this work, we propose a primer of such techniques and a
comprehensive categorization of existing approaches for the automated
verification of neural networks. A discussion about current limitations and
directions for future investigation is provided to foster research on this
topic at the crossroads of Machine Learning and Automated Reasoning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leofante_F/0/1/0/all/0/1&quot;&gt;Francesco Leofante&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Narodytska_N/0/1/0/all/0/1&quot;&gt;Nina Narodytska&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pulina_L/0/1/0/all/0/1&quot;&gt;Luca Pulina&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tacchella_A/0/1/0/all/0/1&quot;&gt;Armando Tacchella&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09980">
<title>Deep Graph Translation. (arXiv:1805.09980v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.09980</link>
<description rdf:parseType="Literal">&lt;p&gt;Inspired by the tremendous success of deep generative models on generating
continuous data like image and audio, in the most recent year, few deep graph
generative models have been proposed to generate discrete data such as graphs.
They are typically unconditioned generative models which has no control on
modes of the graphs being generated. Differently, in this paper, we are
interested in a new problem named \emph{Deep Graph Translation}: given an input
graph, we want to infer a target graph based on their underlying (both global
and local) translation mapping. Graph translation could be highly desirable in
many applications such as disaster management and rare event forecasting, where
the rare and abnormal graph patterns (e.g., traffic congestions and terrorism
events) will be inferred prior to their occurrence even without historical data
on the abnormal patterns for this graph (e.g., a road network or human contact
network). To achieve this, we propose a novel Graph-Translation-Generative
Adversarial Networks (GT-GAN) which will generate a graph translator from input
to target graphs. GT-GAN consists of a graph translator where we propose new
graph convolution and deconvolution layers to learn the global and local
translation mapping. A new conditional graph discriminator has also been
proposed to classify target graphs by conditioning on input graphs. Extensive
experiments on multiple synthetic and real-world datasets demonstrate the
effectiveness and scalability of the proposed GT-GAN.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_X/0/1/0/all/0/1&quot;&gt;Xiaojie Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1&quot;&gt;Lingfei Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_L/0/1/0/all/0/1&quot;&gt;Liang Zhao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.10129">
<title>Dyna Planning using a Feature Based Generative Model. (arXiv:1805.10129v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.10129</link>
<description rdf:parseType="Literal">&lt;p&gt;Dyna-style reinforcement learning is a powerful approach for problems where
not much real data is available. The main idea is to supplement real
trajectories, or sequences of sampled states over time, with simulated ones
sampled from a learned model of the environment. However, in large state
spaces, the problem of learning a good generative model of the environment has
been open so far. We propose to use deep belief networks to learn an
environment model for use in Dyna. We present our approach and validate it
empirically on problems where the state observations consist of images. Our
results demonstrate that using deep belief networks, which are full generative
models, significantly outperforms the use of linear expectation models,
proposed in Sutton et al. (2008)
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Faulkner_R/0/1/0/all/0/1&quot;&gt;Ryan Faulkner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Precup_D/0/1/0/all/0/1&quot;&gt;Doina Precup&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.10174">
<title>f-CNN$^{\text{x}}$: A Toolflow for Mapping Multiple Convolutional Neural Networks on FPGAs. (arXiv:1805.10174v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1805.10174</link>
<description rdf:parseType="Literal">&lt;p&gt;The predictive power of Convolutional Neural Networks (CNNs) has been an
integral factor for emerging latency-sensitive applications, such as autonomous
drones and vehicles. Such systems employ multiple CNNs, each one trained for a
particular task. The efficient mapping of multiple CNNs on a single FPGA device
is a challenging task as the allocation of compute resources and external
memory bandwidth needs to be optimised at design time. This paper proposes
f-CNN$^{\text{x}}$, an automated toolflow for the optimised mapping of multiple
CNNs on FPGAs, comprising a novel multi-CNN hardware architecture together with
an automated design space exploration method that considers the user-specified
performance requirements for each model to allocate compute resources and
generate a synthesisable accelerator. Moreover, f-CNN$^{\text{x}}$ employs a
novel scheduling algorithm that alleviates the limitations of the memory
bandwidth contention between CNNs and sustains the high utilisation of the
architecture. Experimental evaluation shows that f-CNN$^{\text{x}}$&apos;s designs
outperform contention-unaware FPGA mappings by up to 50% and deliver up to 6.8x
higher performance-per-Watt over highly optimised GPU designs for multi-CNN
systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Venieris_S/0/1/0/all/0/1&quot;&gt;Stylianos I. Venieris&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bouganis_C/0/1/0/all/0/1&quot;&gt;Christos-Savvas Bouganis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.03980">
<title>Refining Source Representations with Relation Networks for Neural Machine Translation. (arXiv:1709.03980v3 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1709.03980</link>
<description rdf:parseType="Literal">&lt;p&gt;Although neural machine translation (NMT) with the encoder-decoder framework
has achieved great success in recent times, it still suffers from some
drawbacks: RNNs tend to forget old information which is often useful and the
encoder only operates through words without considering word relationship. To
solve these problems, we introduce a relation networks (RN) into NMT to refine
the encoding representations of the source. In our method, the RN first
augments the representation of each source word with its neighbors and reasons
all the possible pairwise relations between them. Then the source
representations and all the relations are fed to the attention module and the
decoder together, keeping the main encoder-decoder architecture unchanged.
Experiments on two Chinese-to-English data sets in different scales both show
that our method can outperform the competitive baselines significantly.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1&quot;&gt;Wen Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_J/0/1/0/all/0/1&quot;&gt;Jiawei Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1&quot;&gt;Yang Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1&quot;&gt;Qun Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.04008">
<title>Investigating the Impact of Data Volume and Domain Similarity on Transfer Learning Applications. (arXiv:1712.04008v3 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1712.04008</link>
<description rdf:parseType="Literal">&lt;p&gt;Transfer learning allows practitioners to recognize and apply knowledge
learned in previous tasks (source task) to new tasks or new domains (target
task), which share some commonality. The two important factors impacting the
performance of transfer learning models are: (a) the size of the target
dataset, and (b) the similarity in distribution between source and target
domains. Thus far, there has been little investigation into just how important
these factors are. In this paper, we investigate the impact of target dataset
size and source/target domain similarity on model performance through a series
of experiments. We find that more data is always beneficial, and model
performance improves linearly with the log of data size, until we are out of
data. As source/target domains differ, more data is required and fine tuning
will render better performance than feature extraction. When source/target
domains are similar and data size is small, fine tuning and feature extraction
renders equivalent performance. Our hope is that by beginning this quantitative
investigation on the effect of data volume and domain similarity in transfer
learning we might inspire others to explore the significance of data in
developing more accurate statistical models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bernico_M/0/1/0/all/0/1&quot;&gt;Michael Bernico&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yuntao Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1&quot;&gt;Dingchao Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.00934">
<title>Incorporating Literals into Knowledge Graph Embeddings. (arXiv:1802.00934v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1802.00934</link>
<description rdf:parseType="Literal">&lt;p&gt;Knowledge graphs, on top of entities and their relationships, contain other
important elements: literals. Literals encode interesting properties (e.g. the
height) of entities that are not captured by links between entities alone. Most
of the existing work on embedding (or latent feature) based knowledge graph
analysis focuses mainly on the relations between entities. In this work, we
study the effect of incorporating literal information into existing link
prediction methods. Our approach, which we name LiteralE, is an extension that
can be plugged into existing latent feature methods. LiteralE merges entity
embeddings with their literal information using a learnable, parametrized
function, such as a simple linear or nonlinear transformation, or a multilayer
neural network. We extend several popular embedding models based on LiteralE
and evaluate their performance on the task of link prediction. Despite its
simplicity, LiteralE proves to be an effective way to incorporate literal
information into existing embedding based methods, improving their performance
on different standard datasets, which we augmented with their literals and
provide as testbed for further research.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kristiadi_A/0/1/0/all/0/1&quot;&gt;Agustinus Kristiadi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khan_M/0/1/0/all/0/1&quot;&gt;Mohammad Asif Khan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lukovnikov_D/0/1/0/all/0/1&quot;&gt;Denis Lukovnikov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lehmann_J/0/1/0/all/0/1&quot;&gt;Jens Lehmann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fischer_A/0/1/0/all/0/1&quot;&gt;Asja Fischer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.03390">
<title>Same-different problems strain convolutional neural networks. (arXiv:1802.03390v3 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1802.03390</link>
<description rdf:parseType="Literal">&lt;p&gt;The robust and efficient recognition of visual relations in images is a
hallmark of biological vision. We argue that, despite recent progress in visual
recognition, modern machine vision algorithms are severely limited in their
ability to learn visual relations. Through controlled experiments, we
demonstrate that visual-relation problems strain convolutional neural networks
(CNNs). The networks eventually break altogether when rote memorization becomes
impossible, as when intra-class variability exceeds network capacity. Motivated
by the comparable success of biological vision, we argue that feedback
mechanisms including attention and perceptual grouping may be the key
computational components underlying abstract visual reasoning.\
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ricci_M/0/1/0/all/0/1&quot;&gt;Matthew Ricci&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1&quot;&gt;Junkyung Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Serre_T/0/1/0/all/0/1&quot;&gt;Thomas Serre&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.00823">
<title>Graph2Seq: Graph to Sequence Learning with Attention-based Neural Networks. (arXiv:1804.00823v3 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1804.00823</link>
<description rdf:parseType="Literal">&lt;p&gt;The celebrated \emph{Sequence to Sequence learning (Seq2Seq)} technique and
its numerous variants achieve excellent performance on many tasks. However,
many machine learning tasks have inputs naturally represented as graphs;
existing Seq2Seq models face a significant challenge in achieving accurate
conversion from graph form to the appropriate sequence. To address this
challenge, we introduce a general end-to-end graph-to-sequence neural
encoder-decoder architecture that maps an input graph to a sequence of vectors
and uses an attention-based LSTM method to decode the target sequence from
these vectors. Our method first generates the node and graph embeddings using
an improved graph-based neural network with a novel aggregation strategy to
incorporate edge direction information in the node embeddings. We further
introduce an attention mechanism that aligns node embeddings and the decoding
sequence to better cope with large graphs. Experimental results on bAbI,
Shortest Path, and Natural Language Generation tasks demonstrate that our model
achieves state-of-the-art performance and significantly outperforms baseline
systems; using the proposed aggregation strategy, the model can converge
rapidly to the optimal performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_K/0/1/0/all/0/1&quot;&gt;Kun Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_L/0/1/0/all/0/1&quot;&gt;Lingfei Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zhiguo Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1&quot;&gt;Yansong Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Witbrock_M/0/1/0/all/0/1&quot;&gt;Michael Witbrock&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sheinin_V/0/1/0/all/0/1&quot;&gt;Vadim Sheinin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09871">
<title>Confidence interval of singular vectors for high-dimensional and low-rank matrix regression. (arXiv:1805.09871v1 [math.ST])</title>
<link>http://arxiv.org/abs/1805.09871</link>
<description rdf:parseType="Literal">&lt;p&gt;Let ${\bf M}\in\mathbb{R}^{m_1\times m_2}$ be an unknown matrix with $r={\rm
rank}({\bf M})\ll \min(m_1,m_2)$ whose thin singular value decomposition is
denoted by ${\bf M}={\bf U}{\bf \Lambda}{\bf V}^{\top}$ where ${\bf
\Lambda}={\rm diag}(\lambda_1,\cdots,\lambda_r)$ contains its non-increasing
singular values. Low rank matrix regression refers to instances of estimating
${\bf M}$ from $n$ i.i.d. copies of random pair $\{({\bf X}, y)\}$ where ${\bf
X}\in\mathbb{R}^{m_1\times m_2}$ is a random measurement matrix and
$y\in\mathbb{R}$ is a noisy output satisfying $y={\rm tr}({\bf M}^{\top}{\bf
X})+\xi$ with $\xi$ being stochastic error independent of ${\bf X}$. The goal
of this paper is to construct efficient estimator (denoted by $\hat{\bf U}$ and
$\hat{\bf V}$) and confidence interval of ${\bf U}$ and ${\bf V}$. In
particular, we characterize the distribution of $$ {\rm dist}^2\big[(\hat{\bf
U},\hat{\bf V}), ({\bf U},{\bf V})\big]=\|\hat{\bf U}\hat{\bf U}^{\top}-{\bf
U}{\bf U}^{\top}\|_{\rm F}^2+\|\hat{\bf V}\hat{\bf V}^{\top}-{\bf V}{\bf
V}^{\top}\|_{\rm F}^2. $$ We prove the asymptotical normality of properly
centered and normalized ${\rm dist}^2\big[(\hat{\bf U},\hat{\bf V}), ({\bf
U},{\bf V})\big]$ with data-dependent centering and normalization when
$r^{5/2}(m_1+m_2)^{3/2}=o(n/\log n)$, based on which confidence interval of
${\bf U}$ and ${\bf V}$ is constructed achieving any pre-determined confidence
level asymptotically.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Xia_D/0/1/0/all/0/1&quot;&gt;Dong Xia&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09898">
<title>Generative Model: Membership Attack,Generalization and Diversity. (arXiv:1805.09898v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.09898</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper considers membership attacks to deep generative models, which is
to check whether a given instance x was used in the training data or not.
Membership attack is an important topic closely related to the privacy issue of
training data and most prior work were on supervised learning. In this paper we
propose new methods to launch membership attacks against Variational
Autoencoders (VAEs) and Generative Adversarial Networks (GANs). The main idea
is to train another neural network (called the attacker network) to search for
the seed to reproduce the target data x. The difference of the generated data
and x is used to conclude whether x is in the training data or not. We examine
extensively the similarity/correlation and differences of membership attack
with model generalization, overfitting, and diversity of the model. On
different data sets we show our membership attacks are more effective than
alternative methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_K/0/1/0/all/0/1&quot;&gt;Kin Sum Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1&quot;&gt;Bo Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1&quot;&gt;Jie Gao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09906">
<title>Diffusion Maps for Textual Network Embedding. (arXiv:1805.09906v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1805.09906</link>
<description rdf:parseType="Literal">&lt;p&gt;Textual network embedding leverages rich text information associated with the
network to learn low-dimensional vectorial representations of vertices. Rather
than using typical natural language processing (NLP) approaches, recent
research exploits the relationship of texts on the same edge to graphically
embed text. However, these models neglect to measure the complete level of
connectivity between any two texts in the graph. We present diffusion maps for
textual network embedding (DMTE), integrating global structural information of
the graph to capture the semantic relatedness between texts, with a
diffusion-convolution operation applied on the text inputs. In addition, a new
objective function is designed to efficiently preserve the high-order proximity
using the graph diffusion. Experimental results show that the proposed approach
outperforms state-of-the-art methods on the vertex-classification and
link-prediction tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xinyuan Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yitong Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_D/0/1/0/all/0/1&quot;&gt;Dinghan Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Carin_L/0/1/0/all/0/1&quot;&gt;Lawrence Carin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09921">
<title>Decision-Theoretic Meta-Learning: Versatile and Efficient Amortization of Few-Shot Learning. (arXiv:1805.09921v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.09921</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper develops a general framework for data efficient and versatile deep
learning. The new framework comprises three elements: 1) Discriminative
probabilistic models from multi-task learning that leverage shared statistical
information across tasks. 2) A novel Bayesian decision theoretic approach to
meta-learning probabilistic inference across many tasks. 3) A fast, flexible,
and simple to train amortization network that can automatically generalize and
extrapolate to a wide range of settings. The VERSA algorithm, a particular
instance of the framework, is evaluated on a suite of supervised few-shot
learning tasks. VERSA achieves state-of-the-art performance in one-shot
learning on Omniglot and miniImagenet, and produces compelling results on a
one-shot ShapeNet view reconstruction challenge.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gordon_J/0/1/0/all/0/1&quot;&gt;Jonathan Gordon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bronskill_J/0/1/0/all/0/1&quot;&gt;John Bronskill&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bauer_M/0/1/0/all/0/1&quot;&gt;Matthias Bauer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Nowozin_S/0/1/0/all/0/1&quot;&gt;Sebastian Nowozin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Turner_R/0/1/0/all/0/1&quot;&gt;Richard E. Turner&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09965">
<title>LAG: Lazily Aggregated Gradient for Communication-Efficient Distributed Learning. (arXiv:1805.09965v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.09965</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents a new class of gradient methods for distributed machine
learning that adaptively skip the gradient calculations to learn with reduced
communication and computation. Simple rules are designed to detect
slowly-varying gradients and, therefore, trigger the reuse of outdated
gradients. The resultant gradient-based algorithms are termed \textbf{L}azily
\textbf{A}ggregated \textbf{G}radient --- justifying our acronym \textbf{LAG}
used henceforth. Theoretically, the merits of this contribution are: i) the
convergence rate is the same as batch gradient descent in strongly-convex,
convex, and nonconvex smooth cases; and, ii) if the distributed datasets are
heterogeneous (quantified by certain measurable constants), the communication
rounds needed to achieve a targeted accuracy are reduced thanks to the adaptive
reuse of \emph{lagged} gradients. Numerical experiments on both synthetic and
real data corroborate a significant communication reduction compared to
alternatives.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chen_T/0/1/0/all/0/1&quot;&gt;Tianyi Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Giannakis_G/0/1/0/all/0/1&quot;&gt;Georgios B. Giannakis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sun_T/0/1/0/all/0/1&quot;&gt;Tao Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yin_W/0/1/0/all/0/1&quot;&gt;Wotao Yin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.10004">
<title>Masked Conditional Neural Networks for Environmental Sound Classification. (arXiv:1805.10004v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.10004</link>
<description rdf:parseType="Literal">&lt;p&gt;The ConditionaL Neural Network (CLNN) exploits the nature of the temporal
sequencing of the sound signal represented in a spectrogram, and its variant
the Masked ConditionaL Neural Network (MCLNN) induces the network to learn in
frequency bands by embedding a filterbank-like sparseness over the network&apos;s
links using a binary mask. Additionally, the masking automates the exploration
of different feature combinations concurrently analogous to handcrafting the
optimum combination of features for a recognition task. We have evaluated the
MCLNN performance using the Urbansound8k dataset of environmental sounds.
Additionally, we present a collection of manually recorded sounds for rail and
road traffic, YorNoise, to investigate the confusion rates among machine
generated sounds possessing low-frequency components. MCLNN has achieved
competitive results without augmentation and using 12% of the trainable
parameters utilized by an equivalent model based on state-of-the-art
Convolutional Neural Networks on the Urbansound8k. We extended the Urbansound8k
dataset with YorNoise, where experiments have shown that common tonal
properties affect the classification performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Medhat_F/0/1/0/all/0/1&quot;&gt;Fady Medhat&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chesmore_D/0/1/0/all/0/1&quot;&gt;David Chesmore&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Robinson_J/0/1/0/all/0/1&quot;&gt;John Robinson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.10032">
<title>Zeno: Byzantine-suspicious stochastic gradient descent. (arXiv:1805.10032v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.10032</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose Zeno, a new robust aggregation rule, for distributed synchronous
Stochastic Gradient Descent~(SGD) under a general Byzantine failure model. The
key idea is to suspect the workers that are potentially malicious, and use a
ranking-based preference mechanism. This allows us to generalize beyond past
work--in our case, the number of malicious workers can be arbitrarily large,
and we use only the weakest assumption on honest workers~(at least one honest
worker). We prove the convergence of SGD under these scenarios. Empirical
results show that Zeno outperforms existing approaches under various attacks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_C/0/1/0/all/0/1&quot;&gt;Cong Xie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koyejo_O/0/1/0/all/0/1&quot;&gt;Oluwasanmi Koyejo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gupta_I/0/1/0/all/0/1&quot;&gt;Indranil Gupta&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.10130">
<title>Cross Domain Image Generation through Latent Space Exploration with Adversarial Loss. (arXiv:1805.10130v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.10130</link>
<description rdf:parseType="Literal">&lt;p&gt;Conditional domain generation is a good way to interactively control sample
generation process of deep generative models. However, once a conditional
generative model has been created, it is often expensive to allow it to adapt
to new conditional controls, especially the network structure is relatively
deep. We propose a conditioned latent domain transfer framework across latent
spaces of unconditional variational autoencoders(VAE). With this framework, we
can allow unconditionally trained VAEs to generate images in its domain with
conditionals provided by a latent representation of another domain. This
framework does not assume commonalities between two domains. We demonstrate
effectiveness and robustness of our model under widely used image datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1&quot;&gt;Yingjing Lu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.10133">
<title>Laplacian Power Networks: Bounding Indicator Function Smoothness for Adversarial Defense. (arXiv:1805.10133v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.10133</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep Neural Networks often suffer from lack of robustness to adversarial
noise.
&lt;/p&gt;
&lt;p&gt;To mitigate this drawback, authors have proposed different approaches, such
as adding regularizers or training using adversarial examples.
&lt;/p&gt;
&lt;p&gt;In this paper we propose a new regularizer built upon the Laplacian of
similarity graphs obtained from the representation of training data at each
intermediate representation. This regularizer penalizes large changes (across
consecutive layers in the architecture) in the distance between examples of
different classes.
&lt;/p&gt;
&lt;p&gt;We provide theoretical justification for this regularizer and demonstrate its
effectiveness when facing adversarial noise on classical supervised learning
vision datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lassance_C/0/1/0/all/0/1&quot;&gt;Carlos Eduardo Rosar Kos Lassance&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gripon_V/0/1/0/all/0/1&quot;&gt;Vincent Gripon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ortega_A/0/1/0/all/0/1&quot;&gt;Antonio Ortega&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.10170">
<title>A Lifelong Learning Approach to Brain MR Segmentation Across Scanners and Protocols. (arXiv:1805.10170v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.10170</link>
<description rdf:parseType="Literal">&lt;p&gt;Convolutional neural networks (CNNs) have shown promising results on several
segmentation tasks in magnetic resonance (MR) images. However, the accuracy of
CNNs may degrade severely when segmenting images acquired with different
scanners and/or protocols as compared to the training data, thus limiting their
practical utility. We address this shortcoming in a lifelong multi-domain
learning setting by treating images acquired with different scanners or
protocols as samples from different, but related domains. Our solution is a
single CNN with shared convolutional filters and domain-specific batch
normalization layers, which can be tuned to new domains with only a few
($\approx$ 4) labelled images. Importantly, this is achieved while retaining
performance on the older domains whose training data may no longer be
available. We evaluate the method for brain structure segmentation in MR
images. Results demonstrate that the proposed method largely closes the gap to
the benchmark, which is training a dedicated CNN for each scanner.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Karani_N/0/1/0/all/0/1&quot;&gt;Neerav Karani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chaitanya_K/0/1/0/all/0/1&quot;&gt;Krishna Chaitanya&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Baumgartner_C/0/1/0/all/0/1&quot;&gt;Christian Baumgartner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Konukoglu_E/0/1/0/all/0/1&quot;&gt;Ender Konukoglu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.10212">
<title>Multiview Learning of Weighted Majority Vote by Bregman Divergence Minimization. (arXiv:1805.10212v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.10212</link>
<description rdf:parseType="Literal">&lt;p&gt;We tackle the issue of classifier combinations when observations have
multiple views. Our method jointly learns view-specific weighted majority vote
classifiers (i.e. for each view) over a set of base voters, and a second
weighted majority vote classifier over the set of these view-specific weighted
majority vote classifiers. We show that the empirical risk minimization of the
final majority vote given a multiview training set can be cast as the
minimization of Bregman divergences. This allows us to derive a parallel-update
optimization algorithm for learning our multiview model. We empirically study
our algorithm with a particular focus on the impact of the training set size on
the multiview learning results. The experiments show that our approach is able
to overcome the lack of labeled information.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Goyal_A/0/1/0/all/0/1&quot;&gt;Anil Goyal&lt;/a&gt; (AMA, LHC), &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Morvant_E/0/1/0/all/0/1&quot;&gt;Emilie Morvant&lt;/a&gt; (LHC), &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Amini_M/0/1/0/all/0/1&quot;&gt;Massih-Reza Amini&lt;/a&gt; (AMA)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.10222">
<title>Graph Oracle Models, Lower Bounds, and Gaps for Parallel Stochastic Optimization. (arXiv:1805.10222v1 [math.OC])</title>
<link>http://arxiv.org/abs/1805.10222</link>
<description rdf:parseType="Literal">&lt;p&gt;We suggest a general oracle-based framework that captures different parallel
stochastic optimization settings described by a dependency graph, and derive
generic lower bounds in terms of this graph. We then use the framework and
derive lower bounds for several specific parallel optimization settings,
including delayed updates and parallel processing with intermittent
communication. We highlight gaps between lower and upper bounds on the oracle
complexity, and cases where the &quot;natural&quot; algorithms are not known to be
optimal.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Woodworth_B/0/1/0/all/0/1&quot;&gt;Blake Woodworth&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jialei Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+McMahan_B/0/1/0/all/0/1&quot;&gt;Brendan McMahan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Srebro_N/0/1/0/all/0/1&quot;&gt;Nathan Srebro&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.10265">
<title>Training verified learners with learned verifiers. (arXiv:1805.10265v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.10265</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper proposes a new algorithmic framework,predictor-verifier
training,to train neural networks that areverifiable,i.e., networks
thatprovablysatisfysome desired input-output properties. The key idea is to
simultaneously train twonetworks: apredictornetwork that performs the task at
hand,e.g., predictinglabels given inputs, and averifiernetwork that computes a
bound on how wellthe predictor satisfies the properties being verified. Both
networks can be trainedsimultaneously to optimize a weighted combination of the
standard data-fittingloss and a term that bounds the maximum violation of the
property. Experimentsshow that not only is the predictor-verifier architecture
able to train networks toachieve state of the artverifiedrobustness to
adversarial examples with muchshorter training times (outperforming previous
algorithms on small datasets likeMNIST and SVHN), but it can also be scaled to
produce the first known (to thebest of our knowledge) verifiably robust
networks for CIFAR-10.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dvijotham_K/0/1/0/all/0/1&quot;&gt;Krishnamurthy Dvijotham&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gowal_S/0/1/0/all/0/1&quot;&gt;Sven Gowal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stanforth_R/0/1/0/all/0/1&quot;&gt;Robert Stanforth&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Arandjelovic_R/0/1/0/all/0/1&quot;&gt;Relja Arandjelovic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+ODonoghue_B/0/1/0/all/0/1&quot;&gt;Brendan O&amp;#x27;Donoghue&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Uesato_J/0/1/0/all/0/1&quot;&gt;Jonathan Uesato&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kohli_P/0/1/0/all/0/1&quot;&gt;Pushmeet Kohli&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.02483">
<title>The Logistic Network Lasso. (arXiv:1805.02483v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.02483</link>
<description rdf:parseType="Literal">&lt;p&gt;We apply the network Lasso to solve binary classification and clustering
problems on network-structured data. To this end, we generalize ordinary
logistic regression to non-Euclidean data conforming to a complex network
structure. The resulting &quot;logistic network Lasso&quot; classifier amounts to solving
a non-smooth convex optimization problem. A scalable classification algorithm
is obtained by applying (an inexact variant of) the alternating direction
methods of multipliers to solve this optimization problem.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ambos_H/0/1/0/all/0/1&quot;&gt;Henrik Ambos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tran_N/0/1/0/all/0/1&quot;&gt;Nguyen Tran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jung_A/0/1/0/all/0/1&quot;&gt;Alexander Jung&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09461">
<title>Deep Reinforcement Learning For Sequence to Sequence Models. (arXiv:1805.09461v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.09461</link>
<description rdf:parseType="Literal">&lt;p&gt;In recent years, sequence-to-sequence (seq2seq) models are used in a variety
of tasks from machine translation, headline generation, text summarization,
speech to text, to image caption generation. The underlying framework of all
these models are usually a deep neural network which contains an encoder and
decoder. The encoder processes the input data and a decoder receives the output
of the encoder and generates the final output. Although simply using an
encoder/decoder model would, most of the time, produce better result than
traditional methods on the above-mentioned tasks, researchers proposed
additional improvements over these sequence to sequence models, like using an
attention-based model over the input, pointer-generation models, and
self-attention models. However, all these seq2seq models suffer from two common
problems: 1) exposure bias and 2) inconsistency between train/test measurement.
Recently a completely fresh point of view emerged in solving these two problems
in seq2seq models by using methods in Reinforcement Learning (RL). In these new
researches, we try to look at the seq2seq problems from the RL point of view
and we try to come up with a formulation that could combine the power of RL
methods in decision-making and sequence to sequence models in remembering long
memories. In this paper, we will summarize some of the most recent frameworks
that combines concepts from RL world to the deep neural network area and
explain how these two areas could benefit from each other in solving complex
seq2seq tasks. In the end, we will provide insights on some of the problems of
the current existing models and how we can improve them with better RL models.
We also provide the source code for implementing most of the models that will
be discussed in this paper on the complex task of abstractive text
summarization.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Keneshloo_Y/0/1/0/all/0/1&quot;&gt;Yaser Keneshloo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_T/0/1/0/all/0/1&quot;&gt;Tian Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ramakrishnan_N/0/1/0/all/0/1&quot;&gt;Naren Ramakrishnan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Reddy_C/0/1/0/all/0/1&quot;&gt;Chandan K. Reddy&lt;/a&gt;</dc:creator>
</item></rdf:RDF>