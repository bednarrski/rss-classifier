<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Good papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Good Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-06-12T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04344"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04646"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04491"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.05374"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11752"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04168"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04169"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04189"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04265"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04387"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04471"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04562"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04611"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04624"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04640"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05438"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00807"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04166"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04205"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04321"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04326"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04342"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04418"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04550"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04555"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04655"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.03878"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08526"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.04062"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.07433"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.02294"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07892"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07984"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02924"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.03107"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1806.04344">
<title>Optimizing Variational Quantum Circuits using Evolution Strategies. (arXiv:1806.04344v1 [quant-ph])</title>
<link>http://arxiv.org/abs/1806.04344</link>
<description rdf:parseType="Literal">&lt;p&gt;Variational quantum algorithms are leading candidates for early applications
of near-term quantum computing devices. Borrowing Evolution Strategy methods
developed in the context of Reinforcement Learning and Search Gradient
Optimization, we show how to apply these methods to quantum circuit
optimization in the spirit of hybrid quantum-classical algorithms. These
techniques do not rely on direct gradient estimates, gradient circuits or
additional ancilla qubits, hence reducing the sampling cost and runtime for
large numbers of variational parameters and work even in the limit of
single-shot measurements. Additional benefits of the optimizer are its ease of
implementation, and the ability to avoid small local optima, making it ideally
suitable for optimizing non-convex black-box objective functions. We highlight
the efficiency by investigating the behavior of the optimizer on a simple
\textsc{Maxcut} example using the Quantum Approximate Optimization Algorithm
and compare it to the Goemans-Williamson algorithm.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Otterbach_J/0/1/0/all/0/1&quot;&gt;Johannes S. Otterbach&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04646">
<title>Adversarial Attacks on Variational Autoencoders. (arXiv:1806.04646v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1806.04646</link>
<description rdf:parseType="Literal">&lt;p&gt;Adversarial attacks are malicious inputs that derail machine-learning models.
We propose a scheme to attack autoencoders, as well as a quantitative
evaluation framework that correlates well with the qualitative assessment of
the attacks. We assess --- with statistically validated experiments --- the
resistance to attacks of three variational autoencoders (simple, convolutional,
and DRAW) in three datasets (MNIST, SVHN, CelebA), showing that both DRAW&apos;s
recurrence and attention mechanism lead to better resistance. As autoencoders
are proposed for compressing data --- a scenario in which their safety is
paramount --- we expect more attention will be given to adversarial attacks on
them.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gondim_Ribeiro_G/0/1/0/all/0/1&quot;&gt;George Gondim-Ribeiro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tabacof_P/0/1/0/all/0/1&quot;&gt;Pedro Tabacof&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Valle_E/0/1/0/all/0/1&quot;&gt;Eduardo Valle&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04491">
<title>Slice as an Evolutionary Service: Genetic Optimization for Inter-Slice Resource Management in 5G Networks. (arXiv:1802.04491v3 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1802.04491</link>
<description rdf:parseType="Literal">&lt;p&gt;In the context of Fifth Generation (5G) mobile networks, the concept of
&quot;Slice as a Service&quot; (SlaaS) promotes mobile network operators to flexibly
share infrastructures with mobile service providers and stakeholders. However,
it also challenges with an emerging demand for efficient online algorithms to
optimize the request-and-decision-based inter-slice resource management
strategy. Based on genetic algorithms, this paper presents a novel online
optimizer that efficiently approaches towards the ideal slicing strategy with
maximized long-term network utility. The proposed method encodes slicing
strategies into binary sequences to cope with the request-and-decision
mechanism. It requires no a priori knowledge about the traffic/utility models,
and therefore supports heterogeneous slices, while providing solid
effectiveness, good robustness against non-stationary service scenarios, and
high scalability.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Han_B/0/1/0/all/0/1&quot;&gt;Bin Han&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ji_L/0/1/0/all/0/1&quot;&gt;Lianghai Ji&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schotten_H/0/1/0/all/0/1&quot;&gt;Hans D. Schotten&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.05374">
<title>Twin Regularization for online speech recognition. (arXiv:1804.05374v2 [eess.AS] UPDATED)</title>
<link>http://arxiv.org/abs/1804.05374</link>
<description rdf:parseType="Literal">&lt;p&gt;Online speech recognition is crucial for developing natural human-machine
interfaces. This modality, however, is significantly more challenging than
off-line ASR, since real-time/low-latency constraints inevitably hinder the use
of future information, that is known to be very helpful to perform robust
predictions. A popular solution to mitigate this issue consists of feeding
neural acoustic models with context windows that gather some future frames.
This introduces a latency which depends on the number of employed look-ahead
features. This paper explores a different approach, based on estimating the
future rather than waiting for it. Our technique encourages the hidden
representations of a unidirectional recurrent network to embed some useful
information about the future. Inspired by a recently proposed technique called
Twin Networks, we add a regularization term that forces forward hidden states
to be as close as possible to cotemporal backward ones, computed by a &quot;twin&quot;
neural network running backwards in time. The experiments, conducted on a
number of datasets, recurrent architectures, input features, and acoustic
conditions, have shown the effectiveness of this approach. One important
advantage is that our method does not introduce any additional computation at
test time if compared to standard unidirectional recurrent networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Ravanelli_M/0/1/0/all/0/1&quot;&gt;Mirco Ravanelli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Serdyuk_D/0/1/0/all/0/1&quot;&gt;Dmitriy Serdyuk&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Bengio_Y/0/1/0/all/0/1&quot;&gt;Yoshua Bengio&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11752">
<title>Multi-turn Dialogue Response Generation in an Adversarial Learning Framework. (arXiv:1805.11752v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1805.11752</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose an adversarial learning approach to the generation of multi-turn
dialogue responses. Our proposed framework, hredGAN, is based on conditional
generative adversarial networks (GANs). The GAN&apos;s generator is a modified
hierarchical recurrent encoder-decoder network (HRED) and the discriminator is
a word-level bidirectional RNN that shares context and word embedding with the
generator. During inference, noise samples conditioned on the dialogue history
are used to perturb the generator&apos;s latent space to generate several possible
responses. The final response is the one ranked best by the discriminator. The
hredGAN shows major advantages over existing methods: (1) it generalizes better
than networks trained using only the log-likelihood criterion, and (2) it
generates longer, more informative and more diverse responses with high
utterance and topic relevance even with limited training data. This superiority
is demonstrated on the Movie triples and Ubuntu dialogue datasets in terms of
perplexity, BLEU, ROUGE and Distinct n-gram scores.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Olabiyi_O/0/1/0/all/0/1&quot;&gt;Oluwatobi Olabiyi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Salimov_A/0/1/0/all/0/1&quot;&gt;Alan Salimov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khazane_A/0/1/0/all/0/1&quot;&gt;Anish Khazane&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mueller_E/0/1/0/all/0/1&quot;&gt;Erik T. Mueller&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04168">
<title>Straight to the Tree: Constituency Parsing with Neural Syntactic Distance. (arXiv:1806.04168v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1806.04168</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work, we propose a novel constituency parsing scheme. The model
predicts a vector of real-valued scalars, named syntactic distances, for each
split position in the input sentence. The syntactic distances specify the order
in which the split points will be selected, recursively partitioning the input,
in a top-down fashion. Compared to traditional shift-reduce parsing schemes,
our approach is free from the potential problem of compounding errors, while
being faster and easier to parallelize. Our model achieves competitive
performance amongst single model, discriminative parsers in the PTB dataset and
outperforms previous models in the CTB dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1&quot;&gt;Yikang Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1&quot;&gt;Zhouhan Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jacob_A/0/1/0/all/0/1&quot;&gt;Athul Paul Jacob&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sordoni_A/0/1/0/all/0/1&quot;&gt;Alessandro Sordoni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Courville_A/0/1/0/all/0/1&quot;&gt;Aaron Courville&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bengio_Y/0/1/0/all/0/1&quot;&gt;Yoshua Bengio&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04169">
<title>Defense Against the Dark Arts: An overview of adversarial example security research and future research directions. (arXiv:1806.04169v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.04169</link>
<description rdf:parseType="Literal">&lt;p&gt;This article presents a summary of a keynote lecture at the Deep Learning
Security workshop at IEEE Security and Privacy 2018. This lecture summarizes
the state of the art in defenses against adversarial examples and provides
recommendations for future research directions on this topic.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goodfellow_I/0/1/0/all/0/1&quot;&gt;Ian Goodfellow&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04189">
<title>Navigating with Graph Representations for Fast and Scalable Decoding of Neural Language Models. (arXiv:1806.04189v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1806.04189</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural language models (NLMs) have recently gained a renewed interest by
achieving state-of-the-art performance across many natural language processing
(NLP) tasks. However, NLMs are very computationally demanding largely due to
the computational cost of the softmax layer over a large vocabulary. We observe
that, in decoding of many NLP tasks, only the probabilities of the top-K
hypotheses need to be calculated preciously and K is often much smaller than
the vocabulary size. This paper proposes a novel softmax layer approximation
algorithm, called Fast Graph Decoder (FGD), which quickly identifies, for a
given context, a set of K words that are most likely to occur according to a
NLM. We demonstrate that FGD reduces the decoding time by an order of magnitude
while attaining close to the full softmax baseline accuracy on neural machine
translation and language modeling tasks. We also prove the theoretical
guarantee on the softmax approximation quality.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1&quot;&gt;Minjia Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1&quot;&gt;Xiaodong Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1&quot;&gt;Wenhan Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1&quot;&gt;Jianfeng Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1&quot;&gt;Yuxiong He&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04265">
<title>Accurate and Robust Neural Networks for Security Related Applications Exampled by Face Morphing Attacks. (arXiv:1806.04265v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1806.04265</link>
<description rdf:parseType="Literal">&lt;p&gt;Artificial neural networks tend to learn only what they need for a task. A
manipulation of the training data can counter this phenomenon. In this paper,
we study the effect of different alterations of the training data, which limit
the amount and position of information that is available for the decision
making. We analyze the accuracy and robustness against semantic and black box
attacks on the networks that were trained on different training data
modifications for the particular example of morphing attacks. A morphing attack
is an attack on a biometric facial recognition system where the system is
fooled to match two different individuals with the same synthetic face image.
Such a synthetic image can be created by aligning and blending images of the
two individuals that should be matched with this image.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Seibold_C/0/1/0/all/0/1&quot;&gt;Clemens Seibold&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Samek_W/0/1/0/all/0/1&quot;&gt;Wojciech Samek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hilsmann_A/0/1/0/all/0/1&quot;&gt;Anna Hilsmann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Eisert_P/0/1/0/all/0/1&quot;&gt;Peter Eisert&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04387">
<title>Knowledge Amalgam: Generating Jokes and Quotes Together. (arXiv:1806.04387v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1806.04387</link>
<description rdf:parseType="Literal">&lt;p&gt;Generating humor and quotes are very challenging problems in the field of
computational linguistics and are often tackled separately. In this paper, we
present a controlled Long Short-Term Memory (LSTM) architecture which is
trained with categorical data like jokes and quotes together by passing
category as an input along with the sequence of words. The idea is that a
single neural net will learn the structure of both jokes and quotes to generate
them on demand according to input category. Importantly, we believe the neural
net has more knowledge as it&apos;s trained on different datasets and hence will
enable it to generate more creative jokes or quotes from the mixture of
information. May the network generate a funny inspirational joke!
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chippada_B/0/1/0/all/0/1&quot;&gt;Bhargav Chippada&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saha_S/0/1/0/all/0/1&quot;&gt;Shubajit Saha&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04471">
<title>Colwell&apos;s Castle Defence: A Custom Game Using Dynamic Difficulty Adjustment to Increase Player Enjoyment. (arXiv:1806.04471v1 [cs.HC])</title>
<link>http://arxiv.org/abs/1806.04471</link>
<description rdf:parseType="Literal">&lt;p&gt;Dynamic Difficulty Adjustment (DDA) is a mechanism used in video games that
automatically tailors the individual gaming experience to match an appropriate
difficulty setting. This is generally achieved by removing pre-defined
difficulty tiers such as Easy, Medium and Hard; and instead concentrates on
balancing the gameplay to match the challenge to the individual&apos;s abilities.
The work presented in this paper examines the implementation of DDA in a custom
survival game developed by the author, namely Colwell&apos;s Castle Defence. The
premise of this arcade-style game is to defend a castle from hordes of oncoming
enemies. The AI system that we developed adjusts the enemy spawn rate based on
the current performance of the player. Specifically, we read the Player Health
and Gate Health at the end of each level and then assign the player with an
appropriate difficulty tier for the proceeding level. We tested the impact of
our technique on thirty human players and concluded, based on questionnaire
feedback, that enabling the technique led to more enjoyable gameplay.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Colwell_A/0/1/0/all/0/1&quot;&gt;Anthony M. Colwell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Glavin_F/0/1/0/all/0/1&quot;&gt;Frank G. Glavin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04562">
<title>Multi-Agent Deep Reinforcement Learning with Human Strategies. (arXiv:1806.04562v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.04562</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep learning has enabled traditional reinforcement learning methods to deal
with high-dimensional problems. However, one of the disadvantages of deep
reinforcement learning methods is the limited exploration capacity of learning
agents. In this paper, we introduce an approach that integrates human
strategies to increase the exploration capacity of multiple deep reinforcement
learning agents. We also report the development of our own multi-agent
environment called Multiple Tank Defence to simulate the proposed approach. The
results show the significant performance improvement of multiple agents that
have learned cooperatively with human strategies. This implies that there is a
critical need for human intellect teamed with machines to solve complex
problems. In addition, the success of this simulation indicates that our
developed multi-agent environment can be used as a testbed platform to develop
and validate other multi-agent control algorithms. Details of the environment
implementation can be referred to
&lt;a href=&quot;http://www.deakin.edu.au/~thanhthi/madrl_human.htm&quot;&gt;this http URL&lt;/a&gt;
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1&quot;&gt;Thanh Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_N/0/1/0/all/0/1&quot;&gt;Ngoc Duy Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nahavandi_S/0/1/0/all/0/1&quot;&gt;Saeid Nahavandi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04611">
<title>A Hierarchical Fuzzy System for an Advanced Driving Assistance System. (arXiv:1806.04611v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1806.04611</link>
<description rdf:parseType="Literal">&lt;p&gt;In this study, we present a hierarchical fuzzy system by evaluating the risk
state for a Driver Assistance System in order to contribute in reducing the
road accident&apos;s number. A key component of this system is its ability to
continually detect and test the inside and outside risks in real time: The
outside car risks by detecting various road moving objects; this proposed
system stands on computer vision approaches. The inside risks by presenting an
automatic system for drowsy driving identification or detection by evaluating
EEG signals of the driver; this developed system is based on computer vision
techniques and biometrics factors (electroencephalogram EEG). This proposed
system is then composed of three main modules. The first module is responsible
for identifying the driver drowsiness state through his eye movements (physical
drowsiness). The second one is responsible for detecting and analysing his
physiological signals to also identify his drowsiness state (moral drowsiness).
The third module is responsible to evaluate the road driving risks by detecting
of the road different moving objects in a real time. The final decision will be
obtained by merging of the three detection systems through the use of fuzzy
decision rules. Finally, the proposed approach has been improved on ten samples
from a proposed dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dkhil_M/0/1/0/all/0/1&quot;&gt;Mejdi Ben Dkhil&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wali_A/0/1/0/all/0/1&quot;&gt;Ali Wali&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alimi_A/0/1/0/all/0/1&quot;&gt;Adel M. Alimi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04624">
<title>Organizing Experience: A Deeper Look at Replay Mechanisms for Sample-based Planning in Continuous State Domains. (arXiv:1806.04624v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1806.04624</link>
<description rdf:parseType="Literal">&lt;p&gt;Model-based strategies for control are critical to obtain sample efficient
learning. Dyna is a planning paradigm that naturally interleaves learning and
planning, by simulating one-step experience to update the action-value
function. This elegant planning strategy has been mostly explored in the
tabular setting. The aim of this paper is to revisit sample-based planning, in
stochastic and continuous domains with learned models. We first highlight the
flexibility afforded by a model over Experience Replay (ER). Replay-based
methods can be seen as stochastic planning methods that repeatedly sample from
a buffer of recent agent-environment interactions and perform updates to
improve data efficiency. We show that a model, as opposed to a replay buffer,
is particularly useful for specifying which states to sample from during
planning, such as predecessor states that propagate information in reverse from
a state more quickly. We introduce a semi-parametric model learning approach,
called Reweighted Experience Models (REMs), that makes it simple to sample next
states or predecessors. We demonstrate that REM-Dyna exhibits similar
advantages over replay-based methods in learning in continuous state problems,
and that the performance gap grows when moving to stochastic domains, of
increasing size.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pan_Y/0/1/0/all/0/1&quot;&gt;Yangchen Pan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zaheer_M/0/1/0/all/0/1&quot;&gt;Muhammad Zaheer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+White_A/0/1/0/all/0/1&quot;&gt;Adam White&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Patterson_A/0/1/0/all/0/1&quot;&gt;Andrew Patterson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+White_M/0/1/0/all/0/1&quot;&gt;Martha White&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04640">
<title>Unsupervised Meta-Learning for Reinforcement Learning. (arXiv:1806.04640v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.04640</link>
<description rdf:parseType="Literal">&lt;p&gt;Meta-learning is a powerful tool that builds on multi-task learning to learn
how to quickly adapt a model to new tasks. In the context of reinforcement
learning, meta-learning algorithms can acquire reinforcement learning
procedures to solve new problems more efficiently by meta-learning prior tasks.
The performance of meta-learning algorithms critically depends on the tasks
available for meta-training: in the same way that supervised learning
algorithms generalize best to test points drawn from the same distribution as
the training points, meta-learning methods generalize best to tasks from the
same distribution as the meta-training tasks. In effect, meta-reinforcement
learning offloads the design burden from algorithm design to task design. If we
can automate the process of task design as well, we can devise a meta-learning
algorithm that is truly automated. In this work, we take a step in this
direction, proposing a family of unsupervised meta-learning algorithms for
reinforcement learning. We describe a general recipe for unsupervised
meta-reinforcement learning, and describe an effective instantiation of this
approach based on a recently proposed unsupervised exploration technique and
model-agnostic meta-learning. We also discuss practical and conceptual
considerations for developing unsupervised meta-learning methods. Our
experimental results demonstrate that unsupervised meta-reinforcement learning
effectively acquires accelerated reinforcement learning procedures without the
need for manual task design, significantly exceeds the performance of learning
from scratch, and even matches performance of meta-learning methods that use
hand-specified task distributions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1&quot;&gt;Abhishek Gupta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Eysenbach_B/0/1/0/all/0/1&quot;&gt;Benjamin Eysenbach&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Finn_C/0/1/0/all/0/1&quot;&gt;Chelsea Finn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1&quot;&gt;Sergey Levine&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05438">
<title>Mean Field Multi-Agent Reinforcement Learning. (arXiv:1802.05438v3 [cs.MA] UPDATED)</title>
<link>http://arxiv.org/abs/1802.05438</link>
<description rdf:parseType="Literal">&lt;p&gt;Existing multi-agent reinforcement learning methods are limited typically to
a small number of agents. When the agent number increases largely, the learning
becomes intractable due to the curse of the dimensionality and the exponential
growth of agent interactions. In this paper, we present Mean Field
Reinforcement Learning where the interactions within the population of agents
are approximated by those between a single agent and the average effect from
the overall population or neighboring agents; the interplay between the two
entities is mutually reinforced: the learning of the individual agent&apos;s optimal
policy depends on the dynamics of the population, while the dynamics of the
population change according to the collective patterns of the individual
policies. We develop practical mean field Q-learning and mean field
Actor-Critic algorithms and analyze the convergence of the solution to Nash
equilibrium. Experiments on Gaussian squeeze, Ising model, and battle games
justify the learning effectiveness of our mean field approaches. In addition,
we report the first result to solve the Ising model via model-free
reinforcement learning methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1&quot;&gt;Yaodong Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_R/0/1/0/all/0/1&quot;&gt;Rui Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1&quot;&gt;Minne Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1&quot;&gt;Ming Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1&quot;&gt;Weinan Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jun Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00807">
<title>Learning Semantic Sentence Embeddings using Pair-wise Discriminator. (arXiv:1806.00807v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1806.00807</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we propose a method for obtaining sentence-level embeddings.
While the problem of securing word-level embeddings is very well studied, we
propose a novel method for obtaining sentence-level embeddings. This is
obtained by a simple method in the context of solving the paraphrase generation
task. If we use a sequential encoder-decoder model for generating paraphrase,
we would like the generated paraphrase to be semantically close to the original
sentence. One way to ensure this is by adding constraints for true paraphrase
embeddings to be close and unrelated paraphrase candidate sentence embeddings
to be far. This is ensured by using a sequential pair-wise discriminator that
shares weights with the encoder that is trained with a suitable loss function.
Our loss function penalizes paraphrase sentence embedding distances from being
too large. This loss is used in combination with a sequential encoder-decoder
network. We also validated our method by evaluating the obtained embeddings for
a sentiment analysis task. The proposed method results in semantic embeddings
and outperforms the state-of-the-art on the paraphrase generation and sentiment
analysis task on standard datasets. These results are also shown to be
statistically significant.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Patro_B/0/1/0/all/0/1&quot;&gt;Badri N. Patro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kurmi_V/0/1/0/all/0/1&quot;&gt;Vinod K. Kurmi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kumar_S/0/1/0/all/0/1&quot;&gt;Sandeep Kumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Namboodiri_V/0/1/0/all/0/1&quot;&gt;Vinay P. Namboodiri&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04166">
<title>Learning to Decompose and Disentangle Representations for Video Prediction. (arXiv:1806.04166v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.04166</link>
<description rdf:parseType="Literal">&lt;p&gt;Our goal is to predict future video frames given a sequence of input frames.
Despite large amounts of video data, this remains a challenging task because of
the high-dimensionality of video frames. We address this challenge by proposing
the Decompositional Disentangled Predictive Auto-Encoder (DDPAE), a framework
that combines structured probabilistic models and deep networks to
automatically (i) decompose the high-dimensional video that we aim to predict
into components, and (ii) disentangle each component to have low-dimensional
temporal dynamics that are easier to predict. Crucially, with an appropriately
specified generative model of video frames, our DDPAE is able to learn both the
latent decomposition and disentanglement without explicit supervision. For the
Moving MNIST dataset, we show that DDPAE is able to recover the underlying
components (individual digits) and disentanglement (appearance and location) as
we would intuitively do. We further demonstrate that DDPAE can be applied to
the Bouncing Balls dataset involving complex interactions between multiple
objects to predict the video frame directly from the pixels and recover
physical states without explicit supervision.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hsieh_J/0/1/0/all/0/1&quot;&gt;Jun-Ting Hsieh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1&quot;&gt;Bingbin Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_D/0/1/0/all/0/1&quot;&gt;De-An Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fei_Fei_L/0/1/0/all/0/1&quot;&gt;Li Fei-Fei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Niebles_J/0/1/0/all/0/1&quot;&gt;Juan Carlos Niebles&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04205">
<title>A Note about: Local Explanation Methods for Deep Neural Networks lack Sensitivity to Parameter Values. (arXiv:1806.04205v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.04205</link>
<description rdf:parseType="Literal">&lt;p&gt;Local explanation methods, also known as attribution methods, attribute a
deep network&apos;s prediction to its input (cf. Baehrens et al. (2010)). We respond
to the claim from Adebayo et al. (2018) that local explanation methods lack
sensitivity, i.e., DNNs with randomly-initialized weights produce explanations
that are both visually and quantitatively similar to those produced by DNNs
with learned weights.
&lt;/p&gt;
&lt;p&gt;Further investigation reveals that their findings are due to two choices in
their analysis: (a) ignoring the signs of the attributions; and (b) for
integrated gradients (IG), including pixels in their analysis that have zero
attributions by choice of the baseline (an auxiliary input relative to which
the attributions are computed). When both factors are accounted for, IG
attributions for a random network and the actual network are uncorrelated. Our
investigation also sheds light on how these issues affect visualizations,
although we note that more work is needed to understand how viewers interpret
the difference between the random and the actual attributions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sundararajan_M/0/1/0/all/0/1&quot;&gt;Mukund Sundararajan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Taly_A/0/1/0/all/0/1&quot;&gt;Ankur Taly&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04321">
<title>End-to-End Learning of Energy-Constrained Deep Neural Networks. (arXiv:1806.04321v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.04321</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep Neural Networks (DNN) are increasingly deployed in highly
energy-constrained environments such as autonomous drones and wearable devices
while at the same time must operate in real-time. Therefore, reducing the
energy consumption has become a major design consideration in DNN training.
This paper proposes the first end-to-end DNN training framework that provides
quantitative energy guarantees. The key idea is to formulate the DNN training
as an optimization problem in which the energy budget imposes a previously
unconsidered optimization constraint. We integrate the quantitative DNN energy
estimation into the DNN training process to assist the constraint optimization.
We prove that an approximate algorithm can be used to efficiently solve the
optimization problem. Compared to the best prior energy-saving techniques, our
framework trains DNNs that provide higher accuracies under same or lower energy
budgets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1&quot;&gt;Haichuan Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1&quot;&gt;Yuhao Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Ji Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04326">
<title>Differentiable Compositional Kernel Learning for Gaussian Processes. (arXiv:1806.04326v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.04326</link>
<description rdf:parseType="Literal">&lt;p&gt;The generalization properties of Gaussian processes depend heavily on the
choice of kernel, and this choice remains a dark art. We present the Neural
Kernel Network (NKN), a flexible family of kernels represented by a neural
network. The NKN architecture is based on the composition rules for kernels, so
that each unit of the network corresponds to a valid kernel. It can compactly
approximate compositional kernel structures such as those used by the Automatic
Statistician (Lloyd et al., 2014), but because the architecture is
differentiable, it is end-to-end trainable with gradient-based optimization. We
show that the NKN is universal for the class of stationary kernels. Empirically
we demonstrate pattern discovery and extrapolation abilities of NKN on several
tasks that depend crucially on identifying the underlying structure, including
time series and texture extrapolation, as well as Bayesian optimization.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_S/0/1/0/all/0/1&quot;&gt;Shengyang Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1&quot;&gt;Guodong Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1&quot;&gt;Chaoqi Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zeng_W/0/1/0/all/0/1&quot;&gt;Wenyuan Zeng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jiaman Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grosse_R/0/1/0/all/0/1&quot;&gt;Roger Grosse&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04342">
<title>Focused Hierarchical RNNs for Conditional Sequence Processing. (arXiv:1806.04342v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.04342</link>
<description rdf:parseType="Literal">&lt;p&gt;Recurrent Neural Networks (RNNs) with attention mechanisms have obtained
state-of-the-art results for many sequence processing tasks. Most of these
models use a simple form of encoder with attention that looks over the entire
sequence and assigns a weight to each token independently. We present a
mechanism for focusing RNN encoders for sequence modelling tasks which allows
them to attend to key parts of the input as needed. We formulate this using a
multi-layer conditional sequence encoder that reads in one token at a time and
makes a discrete decision on whether the token is relevant to the context or
question being asked. The discrete gating mechanism takes in the context
embedding and the current hidden state as inputs and controls information flow
into the layer above. We train it using policy gradient methods. We evaluate
this method on several types of tasks with different attributes. First, we
evaluate the method on synthetic tasks which allow us to evaluate the model for
its generalization ability and probe the behavior of the gates in more
controlled settings. We then evaluate this approach on large scale Question
Answering tasks including the challenging MS MARCO and SearchQA tasks. Our
models shows consistent improvements for both tasks over prior work and our
baselines. It has also shown to generalize significantly better on synthetic
tasks as compared to the baselines.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ke_N/0/1/0/all/0/1&quot;&gt;Nan Rosemary Ke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zolna_K/0/1/0/all/0/1&quot;&gt;Konrad Zolna&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sordoni_A/0/1/0/all/0/1&quot;&gt;Alessandro Sordoni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lin_Z/0/1/0/all/0/1&quot;&gt;Zhouhan Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Trischler_A/0/1/0/all/0/1&quot;&gt;Adam Trischler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bengio_Y/0/1/0/all/0/1&quot;&gt;Yoshua Bengio&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pineau_J/0/1/0/all/0/1&quot;&gt;Joelle Pineau&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Charlin_L/0/1/0/all/0/1&quot;&gt;Laurent Charlin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pal_C/0/1/0/all/0/1&quot;&gt;Chris Pal&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04418">
<title>Quaternion Recurrent Neural Networks. (arXiv:1806.04418v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.04418</link>
<description rdf:parseType="Literal">&lt;p&gt;Recurrent neural networks (RNNs) are powerful architectures to model
sequential data, due to their capability to learn short and long-term
dependencies between the basic elements of a sequence. Nonetheless, popular
tasks such as speech or images recognition, involve multi-dimensional input
features that are characterized by strong internal dependencies between the
dimensions of the input vector. We propose a novel quaternion recurrent neural
network (QRNN) that takes into account both the external relations and these
internal structural dependencies with the quaternion algebra. Similarly to
capsules, quaternions allow the QRNN to code internal dependencies by composing
and processing multidimensional features as single entities, while the
recurrent operation reveals correlations between the elements composing the
sequence. We show that the QRNN achieves better performances in both a
synthetic memory copy task and in a realistic application of phoneme
recognition. Finally, we show that the QRNN reduces by a factor of 3x the
number of free parameters needed, compared to RNNs to reach equal or even
better results, leading to a more compact representation of the relevant
information.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Parcollet_T/0/1/0/all/0/1&quot;&gt;Titouan Parcollet&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ravanelli_M/0/1/0/all/0/1&quot;&gt;Mirco Ravanelli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Morchid_M/0/1/0/all/0/1&quot;&gt;Mohamed Morchid&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Linares_G/0/1/0/all/0/1&quot;&gt;Georges Linar&amp;#xe8;s&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Trabelsi_C/0/1/0/all/0/1&quot;&gt;Chiheb Trabelsi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mori_R/0/1/0/all/0/1&quot;&gt;Renato De Mori&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bengio_Y/0/1/0/all/0/1&quot;&gt;Yoshua Bengio&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04550">
<title>Deep State Space Models for Unconditional Word Generation. (arXiv:1806.04550v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.04550</link>
<description rdf:parseType="Literal">&lt;p&gt;Autoregressive feedback is considered a necessity for successful
unconditional text generation using stochastic sequence models. However, such
feedback is known to introduce systematic biases into the training and it
obscures a principle of generation: committing to global information and
forgetting local nuances. We show that a non-autoregressive deep state space
model with a clear separation of global and local uncertainty can be build from
only two ingredients: An independent noise source and a deterministic
transition function. Recent advances on flow-based variational inference allow
training an evidence lower-bound without resorting to annealing, auxiliary
losses or similar measures. The result is a highly interpretable generative
model on par with a comparable auto-regressive model on the task of word
generation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schmidt_F/0/1/0/all/0/1&quot;&gt;Florian Schmidt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hofmann_T/0/1/0/all/0/1&quot;&gt;Thomas Hofmann&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04555">
<title>Logistic Ensemble Models. (arXiv:1806.04555v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.04555</link>
<description rdf:parseType="Literal">&lt;p&gt;Predictive models that are developed in a regulated industry or a regulated
application, like determination of credit worthiness, must be interpretable and
rational (e.g., meaningful improvements in basic credit behavior must result in
improved credit worthiness scores). Machine Learning technologies provide very
good performance with minimal analyst intervention, making them well suited to
a high volume analytic environment, but the majority are black box tools that
provide very limited insight or interpretability into key drivers of model
performance or predicted model output values. This paper presents a methodology
that blends one of the most popular predictive statistical modeling methods for
binary classification with a core model enhancement strategy found in machine
learning. The resulting prediction methodology provides solid performance, from
minimal analyst effort, while providing the interpretability and rationality
required in regulated industries, as well as in other environments where
interpretation of model parameters is required (e.g. businesses that require
interpretation of models, to take action on them).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Vanderheyden_B/0/1/0/all/0/1&quot;&gt;Bob Vanderheyden&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Priestley_J/0/1/0/all/0/1&quot;&gt;Jennifer Priestley&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04655">
<title>A Question-Answering framework for plots using Deep learning. (arXiv:1806.04655v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.04655</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep Learning has managed to push boundaries in a wide variety of tasks. One
area of interest is to tackle problems in reasoning and understanding, in an
aim to emulate human intelligence. In this work, we describe a deep learning
model that addresses the reasoning task of question-answering on bar graphs and
pie charts. We introduce a novel architecture that learns to identify various
plot elements, quantify the represented values and determine a relative
ordering of these statistical values. We test our model on the recently
released FigureQA dataset, which provides images and accompanying questions,
for bar graphs and pie charts, augmented with rich annotations. Our approach
outperforms the state-of-the-art Relation Networks baseline and traditional
CNN-LSTM models when evaluated on this dataset. Our model also has a
considerably faster training time of approximately 2 days on 1 GPU compared to
the Relation Networks baseline
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Reddy_R/0/1/0/all/0/1&quot;&gt;Revanth Reddy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ramesh_R/0/1/0/all/0/1&quot;&gt;Rahul Ramesh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deshpande_A/0/1/0/all/0/1&quot;&gt;Ameet Deshpande&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khapra_M/0/1/0/all/0/1&quot;&gt;Mitesh M. Khapra&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.03878">
<title>Generalized Zero-Shot Learning via Synthesized Examples. (arXiv:1712.03878v5 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1712.03878</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a generative framework for generalized zero-shot learning where
the training and test classes are not necessarily disjoint. Built upon a
variational autoencoder based architecture, consisting of a probabilistic
encoder and a probabilistic conditional decoder, our model can generate novel
exemplars from seen/unseen classes, given their respective class attributes.
These exemplars can subsequently be used to train any off-the-shelf
classification model. One of the key aspects of our encoder-decoder
architecture is a feedback-driven mechanism in which a discriminator (a
multivariate regressor) learns to map the generated exemplars to the
corresponding class attribute vectors, leading to an improved generator. Our
model&apos;s ability to generate and leverage examples from unseen classes to train
the classification model naturally helps to mitigate the bias towards
predicting seen classes in generalized zero-shot learning settings. Through a
comprehensive set of experiments, we show that our model outperforms several
state-of-the-art methods, on several benchmark datasets, for both standard as
well as generalized zero-shot learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Verma_V/0/1/0/all/0/1&quot;&gt;Vinay Kumar Verma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Arora_G/0/1/0/all/0/1&quot;&gt;Gundeep Arora&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mishra_A/0/1/0/all/0/1&quot;&gt;Ashish Mishra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rai_P/0/1/0/all/0/1&quot;&gt;Piyush Rai&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08526">
<title>The Weighted Kendall and High-order Kernels for Permutations. (arXiv:1802.08526v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1802.08526</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose new positive definite kernels for permutations. First we introduce
a weighted version of the Kendall kernel, which allows to weight unequally the
contributions of different item pairs in the permutations depending on their
ranks. Like the Kendall kernel, we show that the weighted version is invariant
to relabeling of items and can be computed efficiently in $O(n \ln(n))$
operations, where $n$ is the number of items in the permutation. Second, we
propose a supervised approach to learn the weights by jointly optimizing them
with the function estimated by a kernel machine. Third, while the Kendall
kernel considers pairwise comparison between items, we extend it by considering
higher-order comparisons among tuples of items and show that the supervised
approach of learning the weights can be systematically generalized to
higher-order permutation kernels.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Jiao_Y/0/1/0/all/0/1&quot;&gt;Yunlong Jiao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Vert_J/0/1/0/all/0/1&quot;&gt;Jean-Philippe Vert&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.04062">
<title>Pseudo-task Augmentation: From Deep Multitask Learning to Intratask Sharing---and Back. (arXiv:1803.04062v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1803.04062</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep multitask learning boosts performance by sharing learned structure
across related tasks. This paper adapts ideas from deep multitask learning to
the setting where only a single task is available. The method is formalized as
pseudo-task augmentation, in which models are trained with multiple decoders
for each task. Pseudo-tasks simulate the effect of training towards
closely-related tasks drawn from the same universe. In a suite of experiments,
pseudo-task augmentation is shown to improve performance on single-task
learning problems. When combined with multitask learning, further improvements
are achieved, including state-of-the-art performance on the CelebA dataset,
showing that pseudo-task augmentation and multitask learning have complementary
value. All in all, pseudo-task augmentation is a broadly applicable and
efficient way to boost performance in deep learning systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meyerson_E/0/1/0/all/0/1&quot;&gt;Elliot Meyerson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Miikkulainen_R/0/1/0/all/0/1&quot;&gt;Risto Miikkulainen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.07433">
<title>Two Use Cases of Machine Learning for SDN-Enabled IP/Optical Networks: Traffic Matrix Prediction and Optical Path Performance Prediction. (arXiv:1804.07433v2 [cs.NI] UPDATED)</title>
<link>http://arxiv.org/abs/1804.07433</link>
<description rdf:parseType="Literal">&lt;p&gt;We describe two applications of machine learning in the context of IP/Optical
networks. The first one allows agile management of resources at a core
IP/Optical network by using machine learning for short-term and long-term
prediction of traffic flows and joint global optimization of IP and optical
layers using colorless/directionless (CD) flexible ROADMs. Multilayer
coordination allows for significant cost savings, flexible new services to meet
dynamic capacity needs, and improved robustness by being able to proactively
adapt to new traffic patterns and network conditions. The second application is
important as we migrate our metro networks to Open ROADM networks, to allow
physical routing without the need for detailed knowledge of optical parameters.
We discuss a proof-of-concept study, where detailed performance data for
wavelengths on a current flexible ROADM network is used for machine learning to
predict the optical performance of each wavelength. Both applications can be
efficiently implemented by using a SDN (Software Defined Network) controller.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Choudhury_G/0/1/0/all/0/1&quot;&gt;Gagan Choudhury&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lynch_D/0/1/0/all/0/1&quot;&gt;David Lynch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Thakur_G/0/1/0/all/0/1&quot;&gt;Gaurav Thakur&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tse_S/0/1/0/all/0/1&quot;&gt;Simon Tse&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.02294">
<title>Examining the Use of Neural Networks for Feature Extraction: A Comparative Analysis using Deep Learning, Support Vector Machines, and K-Nearest Neighbor Classifiers. (arXiv:1805.02294v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.02294</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural networks in many varieties are touted as very powerful machine
learning tools because of their ability to distill large amounts of information
from different forms of data, extracting complex features and enabling powerful
classification abilities. In this study, we use neural networks to extract
features from both images and numeric data and use these extracted features as
inputs for other machine learning models, namely support vector machines (SVMs)
and k-nearest neighbor classifiers (KNNs), in order to see if
neural-network-extracted features enhance the capabilities of these models. We
tested 7 different neural network architectures in this manner, 4 for images
and 3 for numeric data, training each for varying lengths of time and then
comparing the results of the neural network independently to those of an SVM
and KNN on the data, and finally comparing these results to models of SVM and
KNN trained using features extracted via the neural network architecture. This
process was repeated on 3 different image datasets and 2 different numeric
datasets. The results show that, in many cases, the features extracted using
the neural network significantly improve the capabilities of SVMs and KNNs
compared to running these algorithms on the raw features, and in some cases
also surpass the performance of the neural network alone. This in turn suggests
that it may be a reasonable practice to use neural networks as a means to
extract features for classification by other machine learning models for some
datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Notley_S/0/1/0/all/0/1&quot;&gt;Stephen Notley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Magdon_Ismail_M/0/1/0/all/0/1&quot;&gt;Malik Magdon-Ismail&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07892">
<title>Localized Multiple Kernel Learning for Anomaly Detection: One-class Classification. (arXiv:1805.07892v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.07892</link>
<description rdf:parseType="Literal">&lt;p&gt;Multi-kernel learning has been well explored in the recent past and has
exhibited promising outcomes for multi-class classification and regression
tasks. In this paper, we present a multiple kernel learning approach for the
One-class Classification (OCC) task and employ it for anomaly detection.
Recently, the basic multi-kernel approach has been proposed to solve the OCC
problem, which is simply a convex combination of different kernels with equal
weights. This paper proposes a Localized Multiple Kernel learning approach for
Anomaly Detection (LMKAD) using OCC, where the weight for each kernel is
assigned locally. Proposed LMKAD approach adapts the weight for each kernel
using a gating function. The parameters of the gating function and one-class
classifier are optimized simultaneously through a two-step optimization
process. We present the empirical results of the performance of LMKAD on 25
benchmark datasets from various disciplines. This performance is evaluated
against existing Multi Kernel Anomaly Detection (MKAD) algorithm, and four
other existing kernel-based one-class classifiers to showcase the credibility
of our approach. Our algorithm achieves significantly better Gmean scores while
using a lesser number of support vectors compared to MKAD. Friedman test is
also performed to verify the statistical significance of the results claimed in
this paper.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gautam_C/0/1/0/all/0/1&quot;&gt;Chandan Gautam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Balaji_R/0/1/0/all/0/1&quot;&gt;Ramesh Balaji&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sudharsan_K/0/1/0/all/0/1&quot;&gt;K Sudharsan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tiwari_A/0/1/0/all/0/1&quot;&gt;Aruna Tiwari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ahuja_K/0/1/0/all/0/1&quot;&gt;Kapil Ahuja&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07984">
<title>Adversarial Attacks on Neural Networks for Graph Data. (arXiv:1805.07984v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1805.07984</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep learning models for graphs have achieved strong performance for the task
of node classification. Despite their proliferation, currently there is no
study of their robustness to adversarial attacks. Yet, in domains where they
are likely to be used, e.g. the web, adversaries are common. Can deep learning
models for graphs be easily fooled? In this work, we introduce the first study
of adversarial attacks on attributed graphs, specifically focusing on models
exploiting ideas of graph convolutions. In addition to attacks at test time, we
tackle the more challenging class of poisoning/causative attacks, which focus
on the training phase of a machine learning model. We generate adversarial
perturbations targeting the node&apos;s features and the graph structure, thus,
taking the dependencies between instances in account. Moreover, we ensure that
the perturbations remain unnoticeable by preserving important data
characteristics. To cope with the underlying discrete domain we propose an
efficient algorithm Nettack exploiting incremental computations. Our
experimental study shows that accuracy of node classification significantly
drops even when performing only few perturbations. Even more, our attacks are
transferable: the learned attacks generalize to other state-of-the-art node
classification models and unsupervised approaches, and likewise are successful
even when only limited knowledge about the graph is given.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zugner_D/0/1/0/all/0/1&quot;&gt;Daniel Z&amp;#xfc;gner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Akbarnejad_A/0/1/0/all/0/1&quot;&gt;Amir Akbarnejad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gunnemann_S/0/1/0/all/0/1&quot;&gt;Stephan G&amp;#xfc;nnemann&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02924">
<title>On Adversarial Risk and Training. (arXiv:1806.02924v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1806.02924</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work we formally define the notions of adversarial perturbations,
adversarial risk and adversarial training and analyze their properties. Our
analysis provides several interesting insights into adversarial risk,
adversarial training, and their relation to the classification risk,
&quot;traditional&quot; training. We also show that adversarial training can result in
models with better classification accuracy and can result in better explainable
models than traditional training. Although adversarial training is
computationally expensive, our results and insights suggest that one should
prefer adversarial training over traditional risk minimization for learning
complex models from data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Suggala_A/0/1/0/all/0/1&quot;&gt;Arun Sai Suggala&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Prasad_A/0/1/0/all/0/1&quot;&gt;Adarsh Prasad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Nagarajan_V/0/1/0/all/0/1&quot;&gt;Vaishnavh Nagarajan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ravikumar_P/0/1/0/all/0/1&quot;&gt;Pradeep Ravikumar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.03107">
<title>Temporal Difference Variational Auto-Encoder. (arXiv:1806.03107v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1806.03107</link>
<description rdf:parseType="Literal">&lt;p&gt;One motivation for learning generative models of environments is to use them
as simulators for model-based reinforcement learning. Yet, it is intuitively
clear that when time horizons are long, rolling out single step transitions is
inefficient and often prohibitive. In this paper, we propose a generative model
that learns state representations containing explicit beliefs about states
several time steps in the future and that can be rolled out directly in these
states without executing single step transitions. The model is trained on pairs
of temporally separated time points, using an analogue of temporal difference
learning used in reinforcement learning, taking the belief about possible
futures at one time point as a bootstrap for training the belief at an earlier
time. While we focus purely on the study of the model rather than its use in
reinforcement learning, the model architecture we design respects agents&apos;
constraints as it builds the representation online.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gregor_K/0/1/0/all/0/1&quot;&gt;Karol Gregor&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Besse_F/0/1/0/all/0/1&quot;&gt;Frederic Besse&lt;/a&gt;</dc:creator>
</item></rdf:RDF>