<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Good papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Good Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-07-01T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.11420"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1706.04223"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.11304"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.11401"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.11463"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.02618"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.09381"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.04770"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.10131"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.11187"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.11302"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.11332"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.11377"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.11382"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.11416"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.11500"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.11532"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02169"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1806.11420">
<title>Discourse-Wizard: Discovering Deep Discourse Structure in your Conversation with RNNs. (arXiv:1806.11420v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1806.11420</link>
<description rdf:parseType="Literal">&lt;p&gt;Spoken language understanding is one of the key factors in a dialogue system,
and a context in a conversation plays an important role to understand the
current utterance. In this work, we demonstrate the importance of context
within the dialogue for neural network models through an online web interface
live demo. We developed two different neural models: a model that does not use
context and a context-based model. The no-context model classifies dialogue
acts at an utterance-level whereas the context-based model takes some preceding
utterances into account. We make these trained neural models available as a
live demo called Discourse-Wizard using a modular server architecture. The live
demo provides an easy to use interface for conversational analysis and for
discovering deep discourse structures in a conversation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bothe_C/0/1/0/all/0/1&quot;&gt;Chandrakant Bothe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Magg_S/0/1/0/all/0/1&quot;&gt;Sven Magg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Weber_C/0/1/0/all/0/1&quot;&gt;Cornelius Weber&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wermter_S/0/1/0/all/0/1&quot;&gt;Stefan Wermter&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1706.04223">
<title>Adversarially Regularized Autoencoders. (arXiv:1706.04223v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1706.04223</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep latent variable models, trained using variational autoencoders or
generative adversarial networks, are now a key technique for representation
learning of continuous structures. However, applying similar methods to
discrete structures, such as text sequences or discretized images, has proven
to be more challenging. In this work, we propose a flexible method for training
deep latent variable models of discrete structures. Our approach is based on
the recently-proposed Wasserstein autoencoder (WAE) which formalizes the
adversarial autoencoder (AAE) as an optimal transport problem. We first extend
this framework to model discrete sequences, and then further explore different
learned priors targeting a controllable representation. This adversarially
regularized autoencoder (ARAE) allows us to generate natural textual outputs as
well as perform manipulations in the latent space to induce change in the
output space. Finally we show that the latent representation can be trained to
perform unaligned textual style transfer, giving improvements both in
automatic/human evaluation compared to existing methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1&quot;&gt;Jake Zhao&lt;/a&gt; (Junbo), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1&quot;&gt;Yoon Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1&quot;&gt;Kelly Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rush_A/0/1/0/all/0/1&quot;&gt;Alexander M. Rush&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+LeCun_Y/0/1/0/all/0/1&quot;&gt;Yann LeCun&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.11304">
<title>Dependence in Propositional Logic: Formula-Formula Dependence and Formula Forgetting -- Application to Belief Update and Conservative Extension. (arXiv:1806.11304v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1806.11304</link>
<description rdf:parseType="Literal">&lt;p&gt;Dependence is an important concept for many tasks in artificial intelligence.
A task can be executed more efficiently by discarding something independent
from the task. In this paper, we propose two novel notions of dependence in
propositional logic: formula-formula dependence and formula forgetting. The
first is a relation between formulas capturing whether a formula depends on
another one, while the second is an operation that returns the strongest
consequence independent of a formula. We also apply these two notions in two
well-known issues: belief update and conservative extension. Firstly, we define
a new update operator based on formula-formula dependence. Furthermore, we
reduce conservative extension to formula forgetting.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fang_L/0/1/0/all/0/1&quot;&gt;Liangda Fang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wan_H/0/1/0/all/0/1&quot;&gt;Hai Wan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1&quot;&gt;Xianqiao Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fang_B/0/1/0/all/0/1&quot;&gt;Biqing Fang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lai_Z/0/1/0/all/0/1&quot;&gt;Zhaorong Lai&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.11401">
<title>WEBCA: Weakly-Electric-Fish Bioinspired Cognitive Architecture. (arXiv:1806.11401v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1806.11401</link>
<description rdf:parseType="Literal">&lt;p&gt;Neuroethology has been an active field of study for more than a century now.
Out of some of the most interesting species that has been studied so far,
weakly electric fish is a fascinating one. It performs communication,
echo-location and inter-species detection efficiently with an interesting
configuration of sensors, neu-rons and a simple brain. In this paper we propose
a cognitive architecture inspired by the way these fishes handle and process
information. We believe that it is eas-ier to understand and mimic the neural
architectures of a simpler species than that of human. Hence, the proposed
architecture is expected to both help research in cognitive robotics and also
help understand more complicated brains like that of human beings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mishra_A/0/1/0/all/0/1&quot;&gt;Amit Kumar Mishra&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.11463">
<title>Bayesian Deep Learning on a Quantum Computer. (arXiv:1806.11463v1 [quant-ph])</title>
<link>http://arxiv.org/abs/1806.11463</link>
<description rdf:parseType="Literal">&lt;p&gt;Bayesian methods in machine learning, such as Gaussian processes, have great
advantages compared to other techniques. In particular, they provide estimates
of the uncertainty associated with a prediction. Extending the Bayesian
approach to deep architectures has remained a major challenge. Recent results
connected deep feedforward neural networks with Gaussian processes, allowing
training without backpropagation. This connection enables us to leverage a
quantum algorithm designed for Gaussian processes and develop new algorithms
for Bayesian deep learning on quantum computers. The properties of the kernel
matrix in the Gaussian process ensure the efficient execution of the core
component of the protocol, quantum matrix inversion, providing a polynomial
speedup with respect to classical algorithm. Furthermore, we demonstrate the
execution of the algorithm on contemporary quantum computers and analyze its
robustness to realistic noise models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Zhao_Z/0/1/0/all/0/1&quot;&gt;Zhikuan Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Pozas_Kerstjens_A/0/1/0/all/0/1&quot;&gt;Alejandro Pozas-Kerstjens&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Rebentrost_P/0/1/0/all/0/1&quot;&gt;Patrick Rebentrost&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Wittek_P/0/1/0/all/0/1&quot;&gt;Peter Wittek&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.02618">
<title>The Shape of a Benedictine Monastery: The SaintGall Ontology (Extended Version). (arXiv:1709.02618v5 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1709.02618</link>
<description rdf:parseType="Literal">&lt;p&gt;We present an OWL 2 ontology representing the Saint Gall plan, one of the
most ancient documents arrived intact to us, which describes the ideal model of
a Benedictine monastic complex that inspired the design of many European
monasteries.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cantale_C/0/1/0/all/0/1&quot;&gt;Claudia Cantale&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cantone_D/0/1/0/all/0/1&quot;&gt;Domenico Cantone&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rinato_M/0/1/0/all/0/1&quot;&gt;Manuela Lupica Rinato&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nicolosi_Asmundo_M/0/1/0/all/0/1&quot;&gt;Marianna Nicolosi-Asmundo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Santamaria_D/0/1/0/all/0/1&quot;&gt;Daniele Francesco Santamaria&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.09381">
<title>RLlib: Abstractions for Distributed Reinforcement Learning. (arXiv:1712.09381v4 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1712.09381</link>
<description rdf:parseType="Literal">&lt;p&gt;Reinforcement learning (RL) algorithms involve the deep nesting of highly
irregular computation patterns, each of which typically exhibits opportunities
for distributed computation. We argue for distributing RL components in a
composable way by adapting algorithms for top-down hierarchical control,
thereby encapsulating parallelism and resource requirements within
short-running compute tasks. We demonstrate the benefits of this principle
through RLlib: a library that provides scalable software primitives for RL.
These primitives enable a broad range of algorithms to be implemented with high
performance, scalability, and substantial code reuse. RLlib is available at
https://rllib.io/.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_E/0/1/0/all/0/1&quot;&gt;Eric Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liaw_R/0/1/0/all/0/1&quot;&gt;Richard Liaw&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moritz_P/0/1/0/all/0/1&quot;&gt;Philipp Moritz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nishihara_R/0/1/0/all/0/1&quot;&gt;Robert Nishihara&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fox_R/0/1/0/all/0/1&quot;&gt;Roy Fox&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goldberg_K/0/1/0/all/0/1&quot;&gt;Ken Goldberg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gonzalez_J/0/1/0/all/0/1&quot;&gt;Joseph E. Gonzalez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jordan_M/0/1/0/all/0/1&quot;&gt;Michael I. Jordan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stoica_I/0/1/0/all/0/1&quot;&gt;Ion Stoica&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.04770">
<title>Born Again Neural Networks. (arXiv:1805.04770v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1805.04770</link>
<description rdf:parseType="Literal">&lt;p&gt;Knowledge distillation (KD) consists of transferring knowledge from one
machine learning model (the teacher}) to another (the student). Commonly, the
teacher is a high-capacity model with formidable performance, while the student
is more compact. By transferring knowledge, one hopes to benefit from the
student&apos;s compactness. %we desire a compact model with performance close to the
teacher&apos;s. We study KD from a new perspective: rather than compressing models,
we train students parameterized identically to their teachers. Surprisingly,
these {Born-Again Networks (BANs), outperform their teachers significantly,
both on computer vision and language modeling tasks. Our experiments with BANs
based on DenseNets demonstrate state-of-the-art performance on the CIFAR-10
(3.5%) and CIFAR-100 (15.5%) datasets, by validation error. Additional
experiments explore two distillation objectives: (i) Confidence-Weighted by
Teacher Max (CWTM) and (ii) Dark Knowledge with Permuted Predictions (DKPP).
Both methods elucidate the essential components of KD, demonstrating a role of
the teacher outputs on both predicted and non-predicted classes. We present
experiments with students of various capacities, focusing on the under-explored
case where students overpower teachers. Our experiments show significant
advantages from transferring knowledge between DenseNets and ResNets in either
direction.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Furlanello_T/0/1/0/all/0/1&quot;&gt;Tommaso Furlanello&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lipton_Z/0/1/0/all/0/1&quot;&gt;Zachary C. Lipton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tschannen_M/0/1/0/all/0/1&quot;&gt;Michael Tschannen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Itti_L/0/1/0/all/0/1&quot;&gt;Laurent Itti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Anandkumar_A/0/1/0/all/0/1&quot;&gt;Anima Anandkumar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.10131">
<title>Request-and-Reverify: Hierarchical Hypothesis Testing for Concept Drift Detection with Expensive Labels. (arXiv:1806.10131v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1806.10131</link>
<description rdf:parseType="Literal">&lt;p&gt;One important assumption underlying common classification models is the
stationarity of the data. However, in real-world streaming applications, the
data concept indicated by the joint distribution of feature and label is not
stationary but drifting over time. Concept drift detection aims to detect such
drifts and adapt the model so as to mitigate any deterioration in the model&apos;s
predictive performance. Unfortunately, most existing concept drift detection
methods rely on a strong and over-optimistic condition that the true labels are
available immediately for all already classified instances. In this paper, a
novel Hierarchical Hypothesis Testing framework with Request-and-Reverify
strategy is developed to detect concept drifts by requesting labels only when
necessary. Two methods, namely Hierarchical Hypothesis Testing with
Classification Uncertainty (HHT-CU) and Hierarchical Hypothesis Testing with
Attribute-wise &quot;Goodness-of-fit&quot; (HHT-AG), are proposed respectively under the
novel framework. In experiments with benchmark datasets, our methods
demonstrate overwhelming advantages over state-of-the-art unsupervised drift
detectors. More importantly, our methods even outperform DDM (the widely used
supervised drift detector) when we use significantly fewer labels.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_S/0/1/0/all/0/1&quot;&gt;Shujian Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;Xiaoyang Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Principe_J/0/1/0/all/0/1&quot;&gt;Jose C. Principe&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.11187">
<title>Neural-net-induced Gaussian process regression for function approximation and PDE solution. (arXiv:1806.11187v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.11187</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural-net-induced Gaussian process (NNGP) regression inherits both the high
expressivity of deep neural networks (deep NNs) as well as the uncertainty
quantification property of Gaussian processes (GPs). We generalize the current
NNGP to first include a larger number of hyperparameters and subsequently train
the model by maximum likelihood estimation. Unlike previous works on NNGP that
targeted classification, here we apply the generalized NNGP to function
approximation and to solving partial differential equations (PDEs).
Specifically, we develop an analytical iteration formula to compute the
covariance function of GP induced by deep NN with an error-function
nonlinearity. We compare the performance of the generalized NNGP for function
approximations and PDE solutions with those of GPs and fully-connected NNs. We
observe that for smooth functions the generalized NNGP can yield the same order
of accuracy with GP, while both NNGP and GP outperform deep NN. For non-smooth
functions, the generalized NNGP is superior to GP and comparable or superior to
deep NN.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pang_G/0/1/0/all/0/1&quot;&gt;Guofei Pang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1&quot;&gt;Liu Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Karniadakis_G/0/1/0/all/0/1&quot;&gt;George Em Karniadakis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.11302">
<title>Generate the corresponding Image from Text Description using Modified GAN-CLS Algorithm. (arXiv:1806.11302v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.11302</link>
<description rdf:parseType="Literal">&lt;p&gt;Synthesizing images or texts automatically is a useful research area in the
artificial intelligence nowadays. Generative adversarial networks (GANs), which
are proposed by Goodfellow in 2014, make this task to be done more efficiently
by using deep neural networks. We consider generating corresponding images from
an input text description using a GAN. In this paper, we analyze the GAN-CLS
algorithm, which is a kind of advanced method of GAN proposed by Scott Reed in
2016. First, we find the problem with this algorithm through inference. Then we
correct the GAN-CLS algorithm according to the inference by modifying the
objective function of the model. Finally, we do the experiments on the
Oxford-102 dataset and the CUB dataset. As a result, our modified algorithm can
generate images which are more plausible than the GAN-CLS algorithm in some
cases. Also, some of the generated images match the input texts better.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gong_F/0/1/0/all/0/1&quot;&gt;Fuzhou Gong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xia_Z/0/1/0/all/0/1&quot;&gt;Zigeng Xia&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.11332">
<title>Knowledge-Based Distant Regularization in Learning Probabilistic Models. (arXiv:1806.11332v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.11332</link>
<description rdf:parseType="Literal">&lt;p&gt;Exploiting the appropriate inductive bias based on the knowledge of data is
essential for achieving good performance in statistical machine learning. In
practice, however, the domain knowledge of interest often provides information
on the relationship of data attributes only distantly, which hinders direct
utilization of such domain knowledge in popular regularization methods. In this
paper, we propose the knowledge-based distant regularization framework, in
which we utilize the distant information encoded in a knowledge graph for
regularization of probabilistic model estimation. In particular, we propose to
impose prior distributions on model parameters specified by knowledge graph
embeddings. As an instance of the proposed framework, we present the factor
analysis model with the knowledge-based distant regularization. We show the
results of preliminary experiments on the improvement of the generalization
capability of such model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Takeishi_N/0/1/0/all/0/1&quot;&gt;Naoya Takeishi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Akimoto_K/0/1/0/all/0/1&quot;&gt;Kosuke Akimoto&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.11377">
<title>Learning from graphs with structural variation. (arXiv:1806.11377v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.11377</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the effect of structural variation in graph data on the predictive
performance of graph kernels. To this end, we introduce a novel, noise-robust
adaptation of the GraphHopper kernel and validate it on benchmark data,
obtaining modestly improved predictive performance on a range of datasets.
Next, we investigate the performance of the state-of-the-art Weisfeiler-Lehman
graph kernel under increasing synthetic structural errors and find that the
effect of introducing errors depends strongly on the dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nielsen_R/0/1/0/all/0/1&quot;&gt;Rune Kok Nielsen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Holm_A/0/1/0/all/0/1&quot;&gt;Andreas Nugaard Holm&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feragen_A/0/1/0/all/0/1&quot;&gt;Aasa Feragen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.11382">
<title>Convergence Problems with Generative Adversarial Networks (GANs). (arXiv:1806.11382v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.11382</link>
<description rdf:parseType="Literal">&lt;p&gt;Generative adversarial networks (GANs) are a novel approach to generative
modelling, a task whose goal it is to learn a distribution of real data points.
They have often proved difficult to train: GANs are unlike many techniques in
machine learning, in that they are best described as a two-player game between
a discriminator and generator. This has yielded both unreliability in the
training process, and a general lack of understanding as to how GANs converge,
and if so, to what. The purpose of this dissertation is to provide an account
of the theory of GANs suitable for the mathematician, highlighting both
positive and negative results. This involves identifying the problems when
training GANs, and how topological and game-theoretic perspectives of GANs have
contributed to our understanding and improved our techniques in recent years.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barnett_S/0/1/0/all/0/1&quot;&gt;Samuel A. Barnett&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.11416">
<title>Bounds on the Approximation Power of Feedforward Neural Networks. (arXiv:1806.11416v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.11416</link>
<description rdf:parseType="Literal">&lt;p&gt;The approximation power of general feedforward neural networks with piecewise
linear activation functions is investigated. First, lower bounds on the size of
a network are established in terms of the approximation error and network depth
and width. These bounds improve upon state-of-the-art bounds for certain
classes of functions, such as strongly convex functions. Second, an upper bound
is established on the difference of two neural networks with identical weights
but different activation functions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mehrabi_M/0/1/0/all/0/1&quot;&gt;Mohammad Mehrabi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tchamkerten_A/0/1/0/all/0/1&quot;&gt;Aslan Tchamkerten&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yousefi_M/0/1/0/all/0/1&quot;&gt;Mansoor I. Yousefi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.11500">
<title>Bayesian Counterfactual Risk Minimization. (arXiv:1806.11500v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.11500</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a Bayesian view of counterfactual risk minimization (CRM), also
known as offline policy optimization from logged bandit feedback. Using
PAC-Bayesian analysis, we derive a new generalization bound for the truncated
IPS estimator. We apply the bound to a class of Bayesian policies, which
motivates a novel, potentially data-dependent, regularization technique for
CRM.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+London_B/0/1/0/all/0/1&quot;&gt;Ben London&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sandler_T/0/1/0/all/0/1&quot;&gt;Ted Sandler&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.11532">
<title>TextWorld: A Learning Environment for Text-based Games. (arXiv:1806.11532v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.11532</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce TextWorld, a sandbox learning environment for the training and
evaluation of RL agents on text-based games. TextWorld is a Python library that
handles interactive play-through of text games, as well as backend functions
like state tracking and reward assignment. It comes with a curated list of
games whose features and challenges we have analyzed. More significantly, it
enables users to handcraft or automatically generate new games. Its generative
mechanisms give precise control over the difficulty, scope, and language of
constructed games, and can be used to relax challenges inherent to commercial
text games like partial observability and sparse rewards. By generating sets of
varied but similar games, TextWorld can also be used to study generalization
and transfer learning. We cast text-based games in the Reinforcement Learning
formalism, use our framework to develop a set of benchmark games, and evaluate
several baseline agents on this set and the curated list.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cote_M/0/1/0/all/0/1&quot;&gt;Marc-Alexandre C&amp;#xf4;t&amp;#xe9;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kadar_A/0/1/0/all/0/1&quot;&gt;&amp;#xc1;kos K&amp;#xe1;d&amp;#xe1;r&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yuan_X/0/1/0/all/0/1&quot;&gt;Xingdi Yuan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kybartas_B/0/1/0/all/0/1&quot;&gt;Ben Kybartas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barnes_T/0/1/0/all/0/1&quot;&gt;Tavian Barnes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fine_E/0/1/0/all/0/1&quot;&gt;Emery Fine&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moore_J/0/1/0/all/0/1&quot;&gt;James Moore&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hausknecht_M/0/1/0/all/0/1&quot;&gt;Matthew Hausknecht&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Asri_L/0/1/0/all/0/1&quot;&gt;Layla El Asri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Adada_M/0/1/0/all/0/1&quot;&gt;Mahmoud Adada&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tay_W/0/1/0/all/0/1&quot;&gt;Wendy Tay&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Trischler_A/0/1/0/all/0/1&quot;&gt;Adam Trischler&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02169">
<title>StarGAN-VC: Non-parallel many-to-many voice conversion with star generative adversarial networks. (arXiv:1806.02169v2 [cs.SD] UPDATED)</title>
<link>http://arxiv.org/abs/1806.02169</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper proposes a method that allows non-parallel many-to-many voice
conversion (VC) by using a variant of a generative adversarial network (GAN)
called StarGAN. Our method, which we call StarGAN-VC, is noteworthy in that it
(1) requires no parallel utterances, transcriptions, or time alignment
procedures for speech generator training, (2) simultaneously learns
many-to-many mappings across different attribute domains using a single
generator network, (3) is able to generate converted speech signals quickly
enough to allow real-time implementations and (4) requires only several minutes
of training examples to generate reasonably realistic-sounding speech.
Subjective evaluation experiments on a non-parallel many-to-many speaker
identity conversion task revealed that the proposed method obtained higher
sound quality and speaker similarity than a state-of-the-art method based on
variational autoencoding GANs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kameoka_H/0/1/0/all/0/1&quot;&gt;Hirokazu Kameoka&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kaneko_T/0/1/0/all/0/1&quot;&gt;Takuhiro Kaneko&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tanaka_K/0/1/0/all/0/1&quot;&gt;Kou Tanaka&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hojo_N/0/1/0/all/0/1&quot;&gt;Nobukatsu Hojo&lt;/a&gt;</dc:creator>
</item></rdf:RDF>