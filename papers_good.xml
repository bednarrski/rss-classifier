<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Good papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Good Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2017-12-14T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.05042"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.05043"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.05067"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.05249"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.05284"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1706.07888"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1707.03502"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1707.05970"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.07128"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.02501"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.05087"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.05181"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.05191"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.05247"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.05291"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.05302"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1606.07282"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1705.08926"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1706.09838"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1708.06040"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1708.08722"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.04997"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.05016"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.05134"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.05279"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.05382"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1610.02581"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1610.09127"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1702.05148"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1703.00893"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1706.05439"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1706.08269"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1707.09118"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.00578"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.08005"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.08621"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.10467"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.11527"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.02519"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.10396"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1712.05042">
<title>A Particle Swarm Optimization-based Flexible Convolutional Auto-Encoder for Image Classification. (arXiv:1712.05042v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1712.05042</link>
<description rdf:parseType="Literal">&lt;p&gt;Convolutional auto-encoders have shown their remarkable performance in
stacking to deep convolutional neural networks for classifying image data
during past several years. However, they are unable to construct the
state-of-the-art convolutional neural networks due to their intrinsic
architectures. In this regard, we propose a flexible convolutional auto-encoder
by eliminating the constraints on the numbers of convolutional layers and
pooling layers from the traditional convolutional auto-encoder. We also design
an architecture discovery method by using particle swarm optimization, which is
capable of automatically searching for the optimal architectures of the
proposed flexible convolutional auto-encoder with much less computational
resource and without any manual intervention. We use the designed architecture
optimization algorithm to test the proposed flexible convolutional auto-encoder
through utilizing one graphic processing unit card on four extensively used
image classification datasets. Experimental results show that our work in this
paper significantly outperform the peer competitors including the
state-of-the-art algorithm.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1&quot;&gt;Yanan Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xue_B/0/1/0/all/0/1&quot;&gt;Bing Xue&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1&quot;&gt;Mengjie Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.05043">
<title>Evolving Unsupervised Deep Neural Networks for Learning Meaningful Representations. (arXiv:1712.05043v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1712.05043</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep Learning (DL) aims at learning the \emph{meaningful representations}. A
meaningful representation refers to the one that gives rise to significant
performance improvement of associated Machine Learning (ML) tasks by replacing
the raw data as the input. However, optimal architecture design and model
parameter estimation in DL algorithms are widely considered to be intractable.
Evolutionary algorithms are much preferable for complex and non-convex problems
due to its inherent characteristics of gradient-free and insensitivity to local
optimum. In this paper, we propose a computationally economical algorithm for
evolving \emph{unsupervised deep neural networks} to efficiently learn
\emph{meaningful representations}, which is very suitable in the current Big
Data era where sufficient labeled data for training is often expensive to
acquire. In the proposed algorithm, finding an appropriate architecture and the
initialized parameter values for a ML task at hand is modeled by one
computational efficient gene encoding approach, which is employed to
effectively model the task with a large number of parameters. In addition, a
local search strategy is incorporated to facilitate the exploitation search for
further improving the performance. Furthermore, a small proportion labeled data
is utilized during evolution search to guarantee the learnt representations to
be meaningful. The performance of the proposed algorithm has been thoroughly
investigated over classification tasks. Specifically, error classification rate
on MNIST with $1.15\%$ is reached by the proposed algorithm consistently, which
is a very promising result against state-of-the-art unsupervised DL algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1&quot;&gt;Yanan Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yen_G/0/1/0/all/0/1&quot;&gt;Gary G. Yen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yi_Z/0/1/0/all/0/1&quot;&gt;Zhang Yi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.05067">
<title>Neural networks catching up with finite differences in solving partial differential equations in higher dimensions. (arXiv:1712.05067v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1712.05067</link>
<description rdf:parseType="Literal">&lt;p&gt;Fully connected multilayer perceptrons are used for obtaining numerical
solutions of partial differential equations in various dimensions. Independent
variables are fed into the input layer, and the output is considered as
solution&apos;s value. To train such a network one can use square of equation&apos;s
residual as a cost function and minimize it with respect to weights by gradient
descent. Following previously developed method, derivatives of the equation&apos;s
residual along random directions in space of independent variables are also
added to cost function. Similar procedure is known to produce nearly machine
precision results using less than 8 grid points per dimension for 2D case. The
same effect is observed here for higher dimensions: solutions are obtained on
low density grids, but maintain their precision in the entire region. Boundary
value problems for linear and nonlinear Poisson equations are solved inside 2,
3, 4, and 5 dimensional balls. Grids for linear cases have 40, 159, 512 and
1536 points and for nonlinear 64, 350, 1536 and 6528 points respectively. In
all cases maximum error is less than $8.8\cdot10^{-6}$, and median error is
less than $2.4\cdot10^{-6}$. Very weak grid requirements enable neural networks
to obtain solution of 5D linear problem within 22 minutes, whereas projected
solving time for finite differences on the same hardware is 50 minutes. Method
is applied to second order equation, but requires little to none modifications
to solve systems or higher order PDEs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Avrutskiy_V/0/1/0/all/0/1&quot;&gt;V.I. Avrutskiy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.05249">
<title>Proximodistal Exploration in Motor Learning as an Emergent Property of Optimization. (arXiv:1712.05249v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1712.05249</link>
<description rdf:parseType="Literal">&lt;p&gt;To harness the complexity of their high-dimensional bodies during
sensorimotor development, infants are guided by patterns of freezing and
freeing of degrees of freedom. For instance, when learning to reach, infants
free the degrees of freedom in their arm proximodistally, i.e. from joints that
are closer to the body to those that are more distant. Here, we formulate and
study computationally the hypothesis that such patterns can emerge
spontaneously as the result of a family of stochastic optimization processes
(evolution strategies with covariance-matrix adaptation), without an innate
encoding of a maturational schedule. In particular, we present simulated
experiments with an arm where a computational learner progressively acquires
reaching skills through adaptive exploration, and we show that a proximodistal
organization appears spontaneously, which we denote PDFF (ProximoDistal
Freezing and Freeing of degrees of freedom). We also compare this emergent
organization between different arm morphologies -- from human-like to quite
unnatural ones -- to study the effect of different kinematic structures on the
emergence of PDFF. Keywords: human motor learning; proximo-distal exploration;
stochastic optimization; modelling; evolution strategies; cross-entropy
methods; policy search; morphology.}
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stulp_F/0/1/0/all/0/1&quot;&gt;Freek Stulp&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oudeyer_P/0/1/0/all/0/1&quot;&gt;Pierre-Yves Oudeyer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.05284">
<title>Adaptation to criticality through organizational invariance in embodied agents. (arXiv:1712.05284v1 [nlin.AO])</title>
<link>http://arxiv.org/abs/1712.05284</link>
<description rdf:parseType="Literal">&lt;p&gt;Many biological and cognitive systems do not operate deep within one or other
regime of activity. Instead, they are poised at critical points located at
transitions of their parameter space. The pervasiveness of criticality suggests
that there may be general principles inducing this behaviour, yet there is no
well-founded theory for understanding how criticality is found at a wide range
of levels and contexts. In this paper we present a general adaptive mechanism
that maintains an internal organizational structure in order to drive a system
towards critical points while it interacts with different environments. We
implement the mechanism in artificial embodied agents controlled by a neural
network maintaining a correlation structure randomly sampled from an Ising
model at critical temperature. Agents are evaluated in two classical
reinforcement learning scenarios: the Mountain Car and the Acrobot double
pendulum. In both cases the neural controller reaches a point of criticality,
which coincides with a transition point between two regimes of the agent&apos;s
behaviour. These results suggest that adaptation to criticality could be used
as a general adaptive mechanism in some circumstances, providing an alternative
explanation for the pervasive presence of criticality in biological and
cognitive systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/nlin/1/au:+Aguilera_M/0/1/0/all/0/1&quot;&gt;Miguel Aguilera&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/nlin/1/au:+Bedia_M/0/1/0/all/0/1&quot;&gt;Manuel G. Bedia&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1706.07888">
<title>Evolving Spatially Aggregated Features from Satellite Imagery for Regional Modeling. (arXiv:1706.07888v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1706.07888</link>
<description rdf:parseType="Literal">&lt;p&gt;Satellite imagery and remote sensing provide explanatory variables at
relatively high resolutions for modeling geospatial phenomena, yet regional
summaries are often desirable for analysis and actionable insight. In this
paper, we propose a novel method of inducing spatial aggregations as a
component of the machine learning process, yielding regional model features
whose construction is driven by model prediction performance rather than prior
assumptions. Our results demonstrate that Genetic Programming is particularly
well suited to this type of feature construction because it can automatically
synthesize appropriate aggregations, as well as better incorporate them into
predictive models compared to other regression methods we tested. In our
experiments we consider a specific problem instance and real-world dataset
relevant to predicting snow properties in high-mountain Asia.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kriegman_S/0/1/0/all/0/1&quot;&gt;Sam Kriegman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Szubert_M/0/1/0/all/0/1&quot;&gt;Marcin Szubert&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bongard_J/0/1/0/all/0/1&quot;&gt;Josh C. Bongard&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Skalka_C/0/1/0/all/0/1&quot;&gt;Christian Skalka&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1707.03502">
<title>Deep Learning for Sensor-based Activity Recognition: A Survey. (arXiv:1707.03502v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1707.03502</link>
<description rdf:parseType="Literal">&lt;p&gt;Sensor-based activity recognition seeks the profound high-level knowledge
about human activities from multitudes of low-level sensor readings.
Conventional pattern recognition approaches have made tremendous progress in
the past years. However, those methods often heavily rely on heuristic
hand-crafted feature extraction, which could hinder their generalization
performance. Additionally, existing methods are undermined for unsupervised and
incremental learning tasks. Recently, the recent advancement of deep learning
makes it possible to perform automatic high-level feature extraction thus
achieves promising performance in many areas. Since then, deep learning based
methods have been widely adopted for the sensor-based activity recognition
tasks. This paper surveys the recent advance of deep learning based
sensor-based activity recognition. We summarize existing literature from three
aspects: sensor modality, deep model, and application. We also present detailed
insights on existing work and propose grand challenges for future research.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jindong Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yiqiang Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hao_S/0/1/0/all/0/1&quot;&gt;Shuji Hao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peng_X/0/1/0/all/0/1&quot;&gt;Xiaohui Peng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_L/0/1/0/all/0/1&quot;&gt;Lisha Hu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1707.05970">
<title>Generic Black-Box End-to-End Attack Against State of the Art API Call Based Malware Classifiers. (arXiv:1707.05970v3 [cs.CR] UPDATED)</title>
<link>http://arxiv.org/abs/1707.05970</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we present a black-box attack against API call based machine
learning malware classifiers, focusing on generating adversarial API call
sequences that would be misclassified by the classifier without affecting the
malware functionality. We show that this attack is effective against many
classifiers due to the transferability principle between RNN variants, feed
forward DNNs, and traditional machine learning classifiers such as SVM. We
further extend our attack against hybrid classifiers based on a combination of
static and dynamic features, focusing on printable strings and API calls.
Finally, we implement GADGET, a software framework to convert any malware
binary to a binary undetected by malware classifiers, using the proposed
attack, without access to the malware source code. We conclude by discussing
possible defense mechanisms against the attack.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rosenberg_I/0/1/0/all/0/1&quot;&gt;Ishai Rosenberg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shabtai_A/0/1/0/all/0/1&quot;&gt;Asaf Shabtai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rokach_L/0/1/0/all/0/1&quot;&gt;Lior Rokach&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Elovici_Y/0/1/0/all/0/1&quot;&gt;Yuval Elovici&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.07128">
<title>Hello Edge: Keyword Spotting on Microcontrollers. (arXiv:1711.07128v2 [cs.SD] UPDATED)</title>
<link>http://arxiv.org/abs/1711.07128</link>
<description rdf:parseType="Literal">&lt;p&gt;Keyword spotting (KWS) is a critical component for enabling speech based user
interactions on smart devices. It requires real-time response and high accuracy
for good user experience. Recently, neural networks have become an attractive
choice for KWS architecture because of their superior accuracy compared to
traditional speech processing algorithms. Due to its always-on nature, KWS
application has highly constrained power budget and typically runs on tiny
microcontrollers with limited memory and compute capability. The design of
neural network architecture for KWS must consider these constraints. In this
work, we perform neural network architecture evaluation and exploration for
running KWS on resource-constrained microcontrollers. We train various neural
network architectures for keyword spotting published in literature to compare
their accuracy and memory/compute requirements. We show that it is possible to
optimize these neural network architectures to fit within the memory and
compute constraints of microcontrollers without sacrificing accuracy. We
further explore the depthwise separable convolutional neural network (DS-CNN)
and compare it against other neural network architectures. DS-CNN achieves an
accuracy of 95.4%, which is ~10% higher than the DNN model with similar number
of parameters.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yundong Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Suda_N/0/1/0/all/0/1&quot;&gt;Naveen Suda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lai_L/0/1/0/all/0/1&quot;&gt;Liangzhen Lai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chandra_V/0/1/0/all/0/1&quot;&gt;Vikas Chandra&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.02501">
<title>CNNs are Globally Optimal Given Multi-Layer Support. (arXiv:1712.02501v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1712.02501</link>
<description rdf:parseType="Literal">&lt;p&gt;Stochastic Gradient Descent (SGD) is the central workhorse for training
modern CNNs. Although giving impressive empirical performance it can be slow to
converge. In this paper we explore a novel strategy for training a CNN using an
alternation strategy that offers substantial speedups during training. We make
the following contributions: (i) replace the ReLU non-linearity within a CNN
with positive hard-thresholding, (ii) reinterpret this non-linearity as a
binary state vector making the entire CNN linear if the multi-layer support is
known, and (iii) demonstrate that under certain conditions a global optima to
the CNN can be found through local descent. We then employ a novel alternation
strategy (between weights and support) for CNN training that leads to
substantially faster convergence rates, nice theoretical properties, and
achieving state of the art results across large scale datasets (e.g. ImageNet)
as well as other standard benchmarks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_C/0/1/0/all/0/1&quot;&gt;Chen Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kong_C/0/1/0/all/0/1&quot;&gt;Chen Kong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lucey_S/0/1/0/all/0/1&quot;&gt;Simon Lucey&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.05087">
<title>Learning Binary Residual Representations for Domain-specific Video Streaming. (arXiv:1712.05087v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1712.05087</link>
<description rdf:parseType="Literal">&lt;p&gt;We study domain-specific video streaming. Specifically, we target a streaming
setting where the videos to be streamed from a server to a client are all in
the same domain and they have to be compressed to a small size for low-latency
transmission. Several popular video streaming services, such as the video game
streaming services of GeForce Now and Twitch, fall in this category. While
conventional video compression standards such as H.264 are commonly used for
this task, we hypothesize that one can leverage the property that the videos
are all in the same domain to achieve better video quality. Based on this
hypothesis, we propose a novel video compression pipeline. Specifically, we
first apply H.264 to compress domain-specific videos. We then train a novel
binary autoencoder to encode the leftover domain-specific residual information
frame-by-frame into binary representations. These binary representations are
then compressed and sent to the client together with the H.264 stream. In our
experiments, we show that our pipeline yields consistent gains over standard
H.264 compression across several benchmark datasets while using the same
channel bandwidth.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tsai_Y/0/1/0/all/0/1&quot;&gt;Yi-Hsuan Tsai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1&quot;&gt;Ming-Yu Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_D/0/1/0/all/0/1&quot;&gt;Deqing Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_M/0/1/0/all/0/1&quot;&gt;Ming-Hsuan Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kautz_J/0/1/0/all/0/1&quot;&gt;Jan Kautz&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.05181">
<title>Rasa: Open Source Language Understanding and Dialogue Management. (arXiv:1712.05181v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1712.05181</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce a pair of tools, Rasa NLU and Rasa Core, which are open source
python libraries for building conversational software. Their purpose is to make
machine-learning based dialogue management and language understanding
accessible to non-specialist software developers. In terms of design
philosophy, we aim for ease of use, and bootstrapping from minimal (or no)
initial training data. Both packages are extensively documented and ship with a
comprehensive suite of tests. The code is available at
https://github.com/RasaHQ/
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bocklisch_T/0/1/0/all/0/1&quot;&gt;Tom Bocklisch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Faulker_J/0/1/0/all/0/1&quot;&gt;Joey Faulker&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pawlowski_N/0/1/0/all/0/1&quot;&gt;Nick Pawlowski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nichol_A/0/1/0/all/0/1&quot;&gt;Alan Nichol&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.05191">
<title>Relation Extraction : A Survey. (arXiv:1712.05191v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1712.05191</link>
<description rdf:parseType="Literal">&lt;p&gt;With the advent of the Internet, large amount of digital text is generated
everyday in the form of news articles, research publications, blogs, question
answering forums and social media. It is important to develop techniques for
extracting information automatically from these documents, as lot of important
information is hidden within them. This extracted information can be used to
improve access and management of knowledge hidden in large text corpora.
Several applications such as Question Answering, Information Retrieval would
benefit from this information. Entities like persons and organizations, form
the most basic unit of the information. Occurrences of entities in a sentence
are often linked through well-defined relations; e.g., occurrences of person
and organization in a sentence may be linked through relations such as employed
at. The task of Relation Extraction (RE) is to identify such relations
automatically. In this paper, we survey several important supervised,
semi-supervised and unsupervised RE techniques. We also cover the paradigms of
Open Information Extraction (OIE) and Distant Supervision. Finally, we describe
some of the recent trends in the RE techniques and possible future research
directions. This survey would be useful for three kinds of readers - i)
Newcomers in the field who want to quickly learn about RE; ii) Researchers who
want to know how the various RE techniques evolved over time and what are
possible future research directions and iii) Practitioners who just need to
know which RE technique works best in various settings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pawar_S/0/1/0/all/0/1&quot;&gt;Sachin Pawar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Palshikar_G/0/1/0/all/0/1&quot;&gt;Girish K. Palshikar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bhattacharyya_P/0/1/0/all/0/1&quot;&gt;Pushpak Bhattacharyya&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.05247">
<title>Intrinsic Point of Interest Discovery from Trajectory Data. (arXiv:1712.05247v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1712.05247</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents a framework for intrinsic point of interest discovery
from trajectory databases. Intrinsic points of interest are regions of a
geospatial area innately defined by the spatial and temporal aspects of
trajectory data, and can be of varying size, shape, and resolution. Any
trajectory database exhibits such points of interest, and hence are intrinsic,
as compared to most other point of interest definitions which are said to be
extrinsic, as they require trajectory metadata, external knowledge about the
region the trajectories are observed, or other application-specific
information. Spatial and temporal aspects are qualities of any trajectory
database, making the framework applicable to data from any domain and of any
resolution. The framework is developed under recent developments on the
consistency of nonparametric hierarchical density estimators and enables the
possibility of formal statistical inference and evaluation over such intrinsic
points of interest. Comparisons of the POIs uncovered by the framework in
synthetic truth data to thousands of parameter settings for common POI
discovery methods show a marked improvement in fidelity without the need to
tune any parameters by hand.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Piekenbrock_M/0/1/0/all/0/1&quot;&gt;Matthew Piekenbrock&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Doran_D/0/1/0/all/0/1&quot;&gt;Derek Doran&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.05291">
<title>A Bayesian Clearing Mechanism for Combinatorial Auctions. (arXiv:1712.05291v1 [cs.GT])</title>
<link>http://arxiv.org/abs/1712.05291</link>
<description rdf:parseType="Literal">&lt;p&gt;We cast the problem of combinatorial auction design in a Bayesian framework
in order to incorporate prior information into the auction process and minimize
the number of rounds to convergence. We first develop a generative model of
agent valuations and market prices such that clearing prices become maximum a
posteriori estimates given observed agent valuations. This generative model
then forms the basis of an auction process which alternates between refining
estimates of agent valuations and computing candidate clearing prices. We
provide an implementation of the auction using assumed density filtering to
estimate valuations and expectation maximization to compute prices. An
empirical evaluation over a range of valuation domains demonstrates that our
Bayesian auction mechanism is highly competitive against the combinatorial
clock auction in terms of rounds to convergence, even under the most favorable
choices of price increment for this baseline.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brero_G/0/1/0/all/0/1&quot;&gt;Gianluca Brero&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lahaie_S/0/1/0/all/0/1&quot;&gt;S&amp;#xe9;bastien Lahaie&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.05302">
<title>Constraint and Mathematical Programming Models for Integrated Port Container Terminal Operations. (arXiv:1712.05302v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1712.05302</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper considers the integrated problem of quay crane assignment, quay
crane scheduling, yard location assignment, and vehicle dispatching operations
at a container terminal. The main objective is to minimize vessel turnover
times and maximize the terminal throughput, which are key economic drivers in
terminal operations. Due to their computational complexities, these problems
are not optimized jointly in existing work. This paper revisits this limitation
and proposes Mixed Integer Programming (MIP) and Constraint Programming (CP)
models for the integrated problem, under some realistic assumptions.
Experimental results show that the MIP formulation can only solve small
instances, while the CP model finds optimal solutions in reasonable times for
realistic instances derived from actual container terminal operations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kizilay_D/0/1/0/all/0/1&quot;&gt;Damla Kizilay&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Eliiyi_D/0/1/0/all/0/1&quot;&gt;Deniz T. Eliiyi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hentenryck_P/0/1/0/all/0/1&quot;&gt;Pascal Van Hentenryck&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1606.07282">
<title>On Gaussian Markov models for conditional independence. (arXiv:1606.07282v3 [stat.ME] UPDATED)</title>
<link>http://arxiv.org/abs/1606.07282</link>
<description rdf:parseType="Literal">&lt;p&gt;Markov models lie at the interface between statistical independence in a
probability distribution and graph separation properties. We review model
selection and estimation in directed and undirected Markov models with Gaussian
parametrization, emphasizing the main similarities and differences. These two
models are similar but not equivalent, although they share a common
intersection. We present the existing results from a historical perspective,
taking into account the amount of literature existing from both the artificial
intelligence and statistics research communities, where these models were
originated. We also discuss how the Gaussian assumption can be relaxed. We
finally point out the main areas of application where these Markov models are
nowadays used.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sanchez_I/0/1/0/all/0/1&quot;&gt;Irene C&amp;#xf3;rdoba S&amp;#xe1;nchez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bielza_C/0/1/0/all/0/1&quot;&gt;Concha Bielza&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Larranaga_P/0/1/0/all/0/1&quot;&gt;Pedro Larra&amp;#xf1;aga&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1705.08926">
<title>Counterfactual Multi-Agent Policy Gradients. (arXiv:1705.08926v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1705.08926</link>
<description rdf:parseType="Literal">&lt;p&gt;Cooperative multi-agent systems can be naturally used to model many real
world problems, such as network packet routing and the coordination of
autonomous vehicles. There is a great need for new reinforcement learning
methods that can efficiently learn decentralised policies for such systems. To
this end, we propose a new multi-agent actor-critic method called
counterfactual multi-agent (COMA) policy gradients. COMA uses a centralised
critic to estimate the Q-function and decentralised actors to optimise the
agents&apos; policies. In addition, to address the challenges of multi-agent credit
assignment, it uses a counterfactual baseline that marginalises out a single
agent&apos;s action, while keeping the other agents&apos; actions fixed. COMA also uses a
critic representation that allows the counterfactual baseline to be computed
efficiently in a single forward pass. We evaluate COMA in the testbed of
StarCraft unit micromanagement, using a decentralised variant with significant
partial observability. COMA significantly improves average performance over
other multi-agent actor-critic methods in this setting, and the best performing
agents are competitive with state-of-the-art centralised controllers that get
access to the full state.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Foerster_J/0/1/0/all/0/1&quot;&gt;Jakob Foerster&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Farquhar_G/0/1/0/all/0/1&quot;&gt;Gregory Farquhar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Afouras_T/0/1/0/all/0/1&quot;&gt;Triantafyllos Afouras&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nardelli_N/0/1/0/all/0/1&quot;&gt;Nantas Nardelli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Whiteson_S/0/1/0/all/0/1&quot;&gt;Shimon Whiteson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1706.09838">
<title>New Fairness Metrics for Recommendation that Embrace Differences. (arXiv:1706.09838v2 [cs.CY] UPDATED)</title>
<link>http://arxiv.org/abs/1706.09838</link>
<description rdf:parseType="Literal">&lt;p&gt;We study fairness in collaborative-filtering recommender systems, which are
sensitive to discrimination that exists in historical data. Biased data can
lead collaborative filtering methods to make unfair predictions against
minority groups of users. We identify the insufficiency of existing fairness
metrics and propose four new metrics that address different forms of
unfairness. These fairness metrics can be optimized by adding fairness terms to
the learning objective. Experiments on synthetic and real data show that our
new metrics can better measure fairness than the baseline, and that the
fairness objectives effectively help reduce unfairness.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yao_S/0/1/0/all/0/1&quot;&gt;Sirui Yao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_B/0/1/0/all/0/1&quot;&gt;Bert Huang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1708.06040">
<title>Neural Block Sampling. (arXiv:1708.06040v3 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1708.06040</link>
<description rdf:parseType="Literal">&lt;p&gt;Efficient Monte Carlo inference often requires manual construction of
model-specific proposals. We propose an approach to automated proposal
construction by training neural networks to provide fast approximations to
block Gibbs conditionals. The learned proposals generalize to occurrences of
common structural motifs both within a given model and across models, allowing
for the construction of a library of learned inference primitives that can
accelerate inference on unseen models with no model-specific training required.
We explore several applications including open-universe Gaussian mixture
models, in which our learned proposals outperform a hand-tuned sampler, and a
real-world named entity recognition task, in which our sampler&apos;s ability to
escape local modes yields higher final F1 scores than single-site Gibbs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1&quot;&gt;Tongzhou Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1&quot;&gt;Yi Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moore_D/0/1/0/all/0/1&quot;&gt;David A. Moore&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Russell_S/0/1/0/all/0/1&quot;&gt;Stuart J. Russell&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1708.08722">
<title>Unifying DAGs and UGs. (arXiv:1708.08722v4 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1708.08722</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce a new class of graphical models that generalizes
Lauritzen-Wermuth-Frydenberg chain graphs by relaxing the semi-directed
acyclity constraint so that only directed cycles are forbidden. Moreover, up to
two edges are allowed between any pair of nodes. Specifically, we present
local, pairwise and global Markov properties for the new graphical models and
prove their equivalence. We also present an equivalent factorization property.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pena_J/0/1/0/all/0/1&quot;&gt;Jose M. Pe&amp;#xf1;a&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.04997">
<title>Predicting Station-level Hourly Demands in a Large-scale Bike-sharing Network: A Graph Convolutional Neural Network Approach. (arXiv:1712.04997v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1712.04997</link>
<description rdf:parseType="Literal">&lt;p&gt;Bike sharing is a vital piece in a modern multi-modal transportation system.
However, it suffers from the bike unbalancing problem due to fluctuating
spatial and temporal demands. Accurate bike sharing demand predictions can help
operators to make optimal routes and schedules for bike redistributions, and
therefore enhance the system efficiency. In this study, we propose a novel
Graph Convolutional Neural Network with Data-driven Graph Filter (GCNN-DDGF)
model to predict station-level hourly demands in a large-scale bike-sharing
network. With each station as a vertex in the network, the new proposed
GCNN-DDGF model is able to automatically learn the hidden correlations between
stations, and thus overcomes a common issue reported in the previous studies,
i.e., the quality and performance of GCNN models rely on the predefinition of
the adjacency matrix. To show the performance of the proposed model, this study
compares the GCNN-DDGF model with four GCNNs models, whose adjacency matrices
are from different bike sharing system matrices including the Spatial Distance
matrix (SD), the Demand matrix (DE), the Average Trip Duration matrix (ATD) and
the Demand Correlation matrix (DC), respectively. The five types of GCNN models
and the classic Support Vector Regression model are built on a Citi Bike
dataset from New York City which includes 272 stations and over 28 million
transactions from 2013 to 2016. Results show that the GCNN-DDGF model has the
lowest Root Mean Square Error, followed by the GCNN-DC model, and the GCNN-ATD
model has the worst performance. Through a further examination, we find the
learned DDGF captures some similar information embedded in the SD, DE and DC
matrices, and it also uncovers more hidden heterogeneous pairwise correlations
between stations that are not revealed by any of those matrices.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lin_L/0/1/0/all/0/1&quot;&gt;Lei Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+He_Z/0/1/0/all/0/1&quot;&gt;Zhengbing He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Peeta_S/0/1/0/all/0/1&quot;&gt;Srinivas Peeta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wen_X/0/1/0/all/0/1&quot;&gt;Xuejin Wen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.05016">
<title>Deep Prior. (arXiv:1712.05016v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1712.05016</link>
<description rdf:parseType="Literal">&lt;p&gt;The recent literature on deep learning offers new tools to learn a rich
probability distribution over high dimensional data such as images or sounds.
In this work we investigate the possibility of learning the prior distribution
over neural network parameters using such tools. Our resulting variational
Bayes algorithm generalizes well to new tasks, even when very few training
examples are provided. Furthermore, this learned prior allows the model to
extrapolate correctly far from a given task&apos;s training data on a meta-dataset
of periodic signals.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lacoste_A/0/1/0/all/0/1&quot;&gt;Alexandre Lacoste&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Boquet_T/0/1/0/all/0/1&quot;&gt;Thomas Boquet&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rostamzadeh_N/0/1/0/all/0/1&quot;&gt;Negar Rostamzadeh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Oreshki_B/0/1/0/all/0/1&quot;&gt;Boris Oreshki&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chung_W/0/1/0/all/0/1&quot;&gt;Wonchang Chung&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Krueger_D/0/1/0/all/0/1&quot;&gt;David Krueger&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.05134">
<title>Learning Compact Recurrent Neural Networks with Block-Term Tensor Decomposition. (arXiv:1712.05134v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1712.05134</link>
<description rdf:parseType="Literal">&lt;p&gt;Recurrent Neural Networks (RNNs) are powerful sequence modeling tools.
However, when dealing with high dimensional inputs, the training of RNNs
becomes computational expensive due to the large number of model parameters.
This hinders RNNs from solving many important computer vision tasks, such as
Action Recognition in Videos and Image Captioning. To overcome this problem, we
propose a compact and flexible structure, namely Block-Term tensor
decomposition, which greatly reduces the parameters of RNNs and improves their
training efficiency. Compared with alternative low-rank approximations, such as
tensor-train RNN (TT-RNN), our method, Block-Term RNN (BT-RNN), is not only
more concise (when using the same rank), but also able to attain a better
approximation to the original RNNs with much fewer parameters. On three
challenging tasks, including Action Recognition in Videos, Image Captioning and
Image Generation, BT-RNN outperforms TT-RNN and the standard RNN in terms of
both prediction accuracy and convergence rate. Specifically, BT-LSTM utilizes
17,388 times fewer parameters than the standard LSTM to achieve an accuracy
improvement over 15.6\% in the Action Recognition task on the UCF11 dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1&quot;&gt;Jinmian Ye&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1&quot;&gt;Linnan Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1&quot;&gt;Guangxi Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1&quot;&gt;Di Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhe_S/0/1/0/all/0/1&quot;&gt;Shandian Zhe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chu_X/0/1/0/all/0/1&quot;&gt;Xinqi Chu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1&quot;&gt;Zenglin Xu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.05279">
<title>Strictly proper kernel scores and characteristic kernels on compact spaces. (arXiv:1712.05279v1 [math.FA])</title>
<link>http://arxiv.org/abs/1712.05279</link>
<description rdf:parseType="Literal">&lt;p&gt;Strictly proper kernel scores are well-known tool in probabilistic
forecasting, while characteristic kernels have been extensively investigated in
the machine learning literature. We first show that both notions coincide, so
that insights from one part of the literature can be used in the other. We then
show that the metric induced by a characteristic kernel cannot reliably
distinguish between distributions that are far apart in the total variation
norm as soon as the underlying space of measures is infinite dimensional. In
addition, we provide a characterization of characteristic kernels in terms of
eigenvalues and -functions and apply this characterization to the case of
continuous kernels on (locally) compact spaces. In the compact case we further
show that characteristic kernels exist if and only if the space is metrizable.
As special cases of our general theory we investigate translation-invariant
kernels on compact Abelian groups and isotropic kernels on spheres. The latter
are of particular interest for forecast evaluation of probabilistic predictions
on spherical domains as frequently encountered in meteorology and climatology.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Steinwart_I/0/1/0/all/0/1&quot;&gt;Ingo Steinwart&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Ziegel_J/0/1/0/all/0/1&quot;&gt;Johanna F. Ziegel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.05382">
<title>Monotonic Chunkwise Attention. (arXiv:1712.05382v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1712.05382</link>
<description rdf:parseType="Literal">&lt;p&gt;Sequence-to-sequence models with soft attention have been successfully
applied to a wide variety of problems, but their decoding process incurs a
quadratic time and space cost and is inapplicable to real-time sequence
transduction. To address these issues, we propose Monotonic Chunkwise Attention
(MoChA), which adaptively splits the input sequence into small chunks over
which soft attention is computed. We show that models utilizing MoChA can be
trained efficiently with standard backpropagation while allowing online and
linear-time decoding at test time. When applied to online speech recognition,
we obtain state-of-the-art results and match the performance of a model using
an offline soft attention mechanism. In document summarization experiments
where we do not expect monotonic alignments, we show significantly improved
performance compared to a baseline monotonic attention-based model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chiu_C/0/1/0/all/0/1&quot;&gt;Chung-Cheng Chiu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Raffel_C/0/1/0/all/0/1&quot;&gt;Colin Raffel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1610.02581">
<title>Variance-based regularization with convex objectives. (arXiv:1610.02581v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1610.02581</link>
<description rdf:parseType="Literal">&lt;p&gt;We develop an approach to risk minimization and stochastic optimization that
provides a convex surrogate for variance, allowing near-optimal and
computationally efficient trading between approximation and estimation error.
Our approach builds off of techniques for distributionally robust optimization
and Owen&apos;s empirical likelihood, and we provide a number of finite-sample and
asymptotic results characterizing the theoretical performance of the estimator.
In particular, we show that our procedure comes with certificates of
optimality, achieving (in some scenarios) faster rates of convergence than
empirical risk minimization by virtue of automatically balancing bias and
variance. We give corroborating empirical evidence showing that in practice,
the estimator indeed trades between variance and absolute performance on a
training sample, improving out-of-sample (test) performance over standard
empirical risk minimization for a number of classification problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Duchi_J/0/1/0/all/0/1&quot;&gt;John Duchi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Namkoong_H/0/1/0/all/0/1&quot;&gt;Hongseok Namkoong&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1610.09127">
<title>Adaptive regularization for Lasso models in the context of non-stationary data streams. (arXiv:1610.09127v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1610.09127</link>
<description rdf:parseType="Literal">&lt;p&gt;Large scale, streaming datasets are ubiquitous in modern machine learning.
Streaming algorithms must be scalable, amenable to incremental training and
robust to the presence of non-stationarity. In this work consider the problem
of learning $\ell_1$ regularized linear models in the context of streaming
data. In particular, the focus of this work revolves around how to select the
regularization parameter when data arrives sequentially and the underlying
distribution is non-stationary (implying the choice of optimal regularization
parameter is itself time-varying). We propose a framework through which to
infer an adaptive regularization parameter. Our approach employs an $\ell_1$
penalty constraint where the corresponding sparsity parameter is iteratively
updated via stochastic gradient descent. This serves to reformulate the choice
of regularization parameter in a principled framework for online learning. The
proposed method is derived for linear regression and subsequently extended to
generalized linear models. We validate our approach using simulated and real
datasets and present an application to a neuroimaging dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Monti_R/0/1/0/all/0/1&quot;&gt;Ricardo Pio Monti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Anagnostopoulos_C/0/1/0/all/0/1&quot;&gt;Christoforos Anagnostopoulos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Montana_G/0/1/0/all/0/1&quot;&gt;Giovanni Montana&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1702.05148">
<title>Latent Laplacian Maximum Entropy Discrimination for Detection of High-Utility Anomalies. (arXiv:1702.05148v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1702.05148</link>
<description rdf:parseType="Literal">&lt;p&gt;Data-driven anomaly detection methods suffer from the drawback of detecting
all instances that are statistically rare, irrespective of whether the detected
instances have real-world significance or not. In this paper, we are interested
in the problem of specifically detecting anomalous instances that are known to
have high real-world utility, while ignoring the low-utility statistically
anomalous instances. To this end, we propose a novel method called Latent
Laplacian Maximum Entropy Discrimination (LatLapMED) as a potential solution.
This method uses the EM algorithm to simultaneously incorporate the Geometric
Entropy Minimization principle for identifying statistical anomalies, and the
Maximum Entropy Discrimination principle to incorporate utility labels, in
order to detect high-utility anomalies. We apply our method in both simulated
and real datasets to demonstrate that it has superior performance over existing
alternatives that independently pre-process with unsupervised anomaly detection
algorithms before classifying.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hou_E/0/1/0/all/0/1&quot;&gt;Elizabeth Hou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sricharan_K/0/1/0/all/0/1&quot;&gt;Kumar Sricharan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hero_A/0/1/0/all/0/1&quot;&gt;Alfred O. Hero&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1703.00893">
<title>Being Robust (in High Dimensions) Can Be Practical. (arXiv:1703.00893v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1703.00893</link>
<description rdf:parseType="Literal">&lt;p&gt;Robust estimation is much more challenging in high dimensions than it is in
one dimension: Most techniques either lead to intractable optimization problems
or estimators that can tolerate only a tiny fraction of errors. Recent work in
theoretical computer science has shown that, in appropriate distributional
models, it is possible to robustly estimate the mean and covariance with
polynomial time algorithms that can tolerate a constant fraction of
corruptions, independent of the dimension. However, the sample and time
complexity of these algorithms is prohibitively large for high-dimensional
applications. In this work, we address both of these issues by establishing
sample complexity bounds that are optimal, up to logarithmic factors, as well
as giving various refinements that allow the algorithms to tolerate a much
larger fraction of corruptions. Finally, we show on both synthetic and real
data that our algorithms have state-of-the-art performance and suddenly make
high-dimensional robust estimation a realistic possibility.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Diakonikolas_I/0/1/0/all/0/1&quot;&gt;Ilias Diakonikolas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kamath_G/0/1/0/all/0/1&quot;&gt;Gautam Kamath&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kane_D/0/1/0/all/0/1&quot;&gt;Daniel M. Kane&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jerry Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moitra_A/0/1/0/all/0/1&quot;&gt;Ankur Moitra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stewart_A/0/1/0/all/0/1&quot;&gt;Alistair Stewart&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1706.05439">
<title>Control Variates for Stochastic Gradient MCMC. (arXiv:1706.05439v2 [stat.CO] UPDATED)</title>
<link>http://arxiv.org/abs/1706.05439</link>
<description rdf:parseType="Literal">&lt;p&gt;It is well known that Markov chain Monte Carlo (MCMC) methods scale poorly
with dataset size. A popular class of methods for solving this issue is
stochastic gradient MCMC. These methods use a noisy estimate of the gradient of
the log posterior, which reduces the per iteration computational cost of the
algorithm. Despite this, there are a number of results suggesting that
stochastic gradient Langevin dynamics (SGLD), probably the most popular of
these methods, still has computational cost proportional to the dataset size.
We suggest an alternative log posterior gradient estimate for stochastic
gradient MCMC, which uses control variates to reduce the variance. We analyse
SGLD using this gradient estimate, and show that, under log-concavity
assumptions on the target distribution, the computational cost required for a
given level of accuracy is independent of the dataset size. Next we show that a
different control variate technique, known as zero variance control variates
can be applied to SGMCMC algorithms for free. This post-processing step
improves the inference of the algorithm by reducing the variance of the MCMC
output. Zero variance control variates rely on the gradient of the log
posterior; we explore how the variance reduction is affected by replacing this
with the noisy gradient estimate calculated by SGMCMC.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Baker_J/0/1/0/all/0/1&quot;&gt;Jack Baker&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Fearnhead_P/0/1/0/all/0/1&quot;&gt;Paul Fearnhead&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Fox_E/0/1/0/all/0/1&quot;&gt;Emily B. Fox&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Nemeth_C/0/1/0/all/0/1&quot;&gt;Christopher Nemeth&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1706.08269">
<title>Top-down Transformation Choice. (arXiv:1706.08269v2 [stat.ME] UPDATED)</title>
<link>http://arxiv.org/abs/1706.08269</link>
<description rdf:parseType="Literal">&lt;p&gt;Simple models are preferred over complex models, but over-simplistic models
could lead to erroneous interpretations. The classical approach is to start
with a simple model, whose shortcomings are assessed in residual-based model
diagnostics. Eventually, one increases the complexity of this initial overly
simple model and obtains a better-fitting model. I illustrate how
transformation analysis can be used as an alternative approach to model choice.
Instead of adding complexity to simple models, step-wise complexity reduction
is used to help identify simpler and better-interpretable models. As an
example, body mass index distributions in Switzerland are modelled by means of
transformation models to understand the impact of sex, age, smoking and other
lifestyle factors on a person&apos;s body mass index. In this process, I searched
for a compromise between model fit and model interpretability. Special emphasis
is given to the understanding of the connections between transformation models
of increasing complexity. The models used in this analysis ranged from
evergreens, such as the normal linear regression model with constant variance,
to novel models with extremely flexible conditional distribution functions,
such as transformation trees and transformation forests.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hothorn_T/0/1/0/all/0/1&quot;&gt;Torsten Hothorn&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1707.09118">
<title>Counterfactual Learning from Bandit Feedback under Deterministic Logging: A Case Study in Statistical Machine Translation. (arXiv:1707.09118v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1707.09118</link>
<description rdf:parseType="Literal">&lt;p&gt;The goal of counterfactual learning for statistical machine translation (SMT)
is to optimize a target SMT system from logged data that consist of user
feedback to translations that were predicted by another, historic SMT system. A
challenge arises by the fact that risk-averse commercial SMT systems
deterministically log the most probable translation. The lack of sufficient
exploration of the SMT output space seemingly contradicts the theoretical
requirements for counterfactual learning. We show that counterfactual learning
from deterministic bandit logs is possible nevertheless by smoothing out
deterministic components in learning. This can be achieved by additive and
multiplicative control variates that avoid degenerate behavior in empirical
risk minimization. Our simulation experiments show improvements of up to 2 BLEU
points by counterfactual learning from deterministic bandit feedback.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lawrence_C/0/1/0/all/0/1&quot;&gt;Carolin Lawrence&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sokolov_A/0/1/0/all/0/1&quot;&gt;Artem Sokolov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Riezler_S/0/1/0/all/0/1&quot;&gt;Stefan Riezler&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.00578">
<title>sgmcmc: An R Package for Stochastic Gradient Markov Chain Monte Carlo. (arXiv:1710.00578v2 [stat.CO] UPDATED)</title>
<link>http://arxiv.org/abs/1710.00578</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper introduces the R package sgmcmc; which can be used for Bayesian
inference on problems with large datasets using stochastic gradient Markov
chain Monte Carlo (SGMCMC). Traditional Markov chain Monte Carlo (MCMC)
methods, such as Metropolis-Hastings, are known to run prohibitively slowly as
the dataset size increases. SGMCMC solves this issue by only using a subset of
data at each iteration. SGMCMC requires calculating gradients of the log
likelihood and log priors, which can be time consuming and error prone to
perform by hand. The sgmcmc package calculates these gradients itself using
automatic differentiation, making the implementation of these methods much
easier. To do this, the package uses the software library TensorFlow, which has
a variety of statistical distributions and mathematical operations as standard,
meaning a wide class of models can be built using this framework. SGMCMC has
become widely adopted in the machine learning literature, but less so in the
statistics community. We believe this may be partly due to lack of software;
this package aims to bridge this gap.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Baker_J/0/1/0/all/0/1&quot;&gt;Jack Baker&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Fearnhead_P/0/1/0/all/0/1&quot;&gt;Paul Fearnhead&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Fox_E/0/1/0/all/0/1&quot;&gt;Emily B. Fox&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Nemeth_C/0/1/0/all/0/1&quot;&gt;Christopher Nemeth&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.08005">
<title>Smart &quot;Predict, then Optimize&quot;. (arXiv:1710.08005v2 [math.OC] UPDATED)</title>
<link>http://arxiv.org/abs/1710.08005</link>
<description rdf:parseType="Literal">&lt;p&gt;Many real-world analytics problems involve two significant challenges:
prediction and optimization. Due to the typically complex nature of each
challenge, the standard paradigm is to predict, then optimize. By and large,
machine learning tools are intended to minimize prediction error and do not
account for how the predictions will be used in a downstream optimization
problem. In contrast, we propose a new and very general framework, called Smart
&quot;Predict, then Optimize&quot; (SPO), which directly leverages the optimization
problem structure, i.e., its objective and constraints, for designing
successful analytics tools. A key component of our framework is the SPO loss
function, which measures the quality of a prediction by comparing the objective
values of the solutions generated using the predicted and observed parameters,
respectively. Training a model with respect to the SPO loss is computationally
challenging, and therefore we also develop a surrogate loss function, called
the SPO+ loss, which upper bounds the SPO loss, has desirable convexity
properties, and is statistically consistent under mild conditions. We also
propose a stochastic gradient descent algorithm which allows for situations in
which the number of training samples is large, model regularization is desired,
and/or the optimization problem of interest is nonlinear or integer. Finally,
we perform computational experiments to empirically verify the success of our
SPO framework in comparison to the standard predict-then-optimize approach.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Elmachtoub_A/0/1/0/all/0/1&quot;&gt;Adam N. Elmachtoub&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Grigas_P/0/1/0/all/0/1&quot;&gt;Paul Grigas&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.08621">
<title>Counterfactual Learning for Machine Translation: Degeneracies and Solutions. (arXiv:1711.08621v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1711.08621</link>
<description rdf:parseType="Literal">&lt;p&gt;Counterfactual learning is a natural scenario to improve web-based machine
translation services by offline learning from feedback logged during user
interactions. In order to avoid the risk of showing inferior translations to
users, in such scenarios mostly exploration-free deterministic logging policies
are in place. We analyze possible degeneracies of inverse and reweighted
propensity scoring estimators, in stochastic and deterministic settings, and
relate them to recently proposed techniques for counterfactual learning under
deterministic logging.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lawrence_C/0/1/0/all/0/1&quot;&gt;Carolin Lawrence&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gajane_P/0/1/0/all/0/1&quot;&gt;Pratik Gajane&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Riezler_S/0/1/0/all/0/1&quot;&gt;Stefan Riezler&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.10467">
<title>Implicit Regularization in Nonconvex Statistical Estimation: Gradient Descent Converges Linearly for Phase Retrieval, Matrix Completion and Blind Deconvolution. (arXiv:1711.10467v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1711.10467</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent years have seen a flurry of activities in designing provably efficient
nonconvex procedures for solving statistical estimation problems. Due to the
highly nonconvex nature of the empirical loss, state-of-the-art procedures
often require proper regularization (e.g. trimming, regularized cost,
projection) in order to guarantee fast convergence. For vanilla procedures such
as gradient descent, however, prior theory either recommends highly
conservative learning rates to avoid overshooting, or completely lacks
performance guarantees.
&lt;/p&gt;
&lt;p&gt;This paper uncovers a striking phenomenon in nonconvex optimization: even in
the absence of explicit regularization, gradient descent enforces proper
regularization implicitly under various statistical models. In fact, gradient
descent follows a trajectory staying within a basin that enjoys nice geometry,
consisting of points incoherent with the sampling mechanism. This &quot;implicit
regularization&quot; feature allows gradient descent to proceed in a far more
aggressive fashion without overshooting, which in turn results in substantial
computational savings. Focusing on three fundamental statistical estimation
problems, i.e. phase retrieval, low-rank matrix completion, and blind
deconvolution, we establish that gradient descent achieves near-optimal
statistical and computational guarantees without explicit regularization. In
particular, by marrying statistical modeling with generic optimization theory,
we develop a general recipe for analyzing the trajectories of iterative
algorithms via a leave-one-out perturbation argument. As a byproduct, for noisy
matrix completion, we demonstrate that gradient descent achieves near-optimal
error control --- measured entrywise and by the spectral norm --- which might
be of independent interest.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_C/0/1/0/all/0/1&quot;&gt;Cong Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1&quot;&gt;Kaizheng Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chi_Y/0/1/0/all/0/1&quot;&gt;Yuejie Chi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yuxin Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.11527">
<title>Improved Linear Embeddings via Lagrange Duality. (arXiv:1711.11527v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1711.11527</link>
<description rdf:parseType="Literal">&lt;p&gt;Near isometric orthogonal embeddings to lower dimensions are a fundamental
tool in data science and machine learning. In this paper, we present the
construction of such embeddings that minimizes the maximum distortion for a
given set of points. We formulate the problem as a non convex constrained
optimization problem. We first construct a primal relaxation and then use the
theory of Lagrange duality to create dual relaxation. We also suggest a
polynomial time algorithm based on the theory of convex optimization to solve
the dual relaxation provably. We provide a theoretical upper bound on the
approximation guarantees for our algorithm, which depends only on the spectral
properties of the dataset. We experimentally demonstrate the superiority of our
algorithm compared to baselines in terms of the scalability and the ability to
achieve lower distortion.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sheth_K/0/1/0/all/0/1&quot;&gt;Kshiteej Sheth&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Garg_D/0/1/0/all/0/1&quot;&gt;Dinesh Garg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Dasgupta_A/0/1/0/all/0/1&quot;&gt;Anirban Dasgupta&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.02519">
<title>Convergence Rates of Variational Posterior Distributions. (arXiv:1712.02519v2 [math.ST] UPDATED)</title>
<link>http://arxiv.org/abs/1712.02519</link>
<description rdf:parseType="Literal">&lt;p&gt;We study convergence rates of variational posterior distributions for
nonparametric and high-dimensional inference. We formulate general conditions
on prior, likelihood, and variational class that characterize the convergence
rates. Under similar &quot;prior mass and testing&quot; conditions considered in the
literature, the rate is found to be the sum of two terms. The first term stands
for the convergence rate of the true posterior distribution, and the second
term is contributed by the variational approximation error. For a class of
priors that admit the structure of a mixture of product measures, we propose a
novel prior mass condition, under which the variational approximation error of
the generalized mean-field class is dominated by convergence rate of the true
posterior. We demonstrate the applicability of our general results for various
models, prior distributions and variational classes by deriving convergence
rates of the corresponding variational posteriors.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Zhang_F/0/1/0/all/0/1&quot;&gt;Fengshuo Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Gao_C/0/1/0/all/0/1&quot;&gt;Chao Gao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.10396">
<title>Assessment Formats and Student Learning Performance: What is the Relation?. (arXiv:1711.10396v1 [physics.ed-ph] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1711.10396</link>
<description rdf:parseType="Literal">&lt;p&gt;Although compelling assessments have been examined in recent years, more
studies are required to yield a better understanding of the several methods
where assessment techniques significantly affect student learning process. Most
of the educational research in this area does not consider demographics data,
differing methodologies, and notable sample size. To address these drawbacks,
the objective of our study is to analyse student learning outcomes of multiple
assessment formats for a web-facilitated in-class section with an asynchronous
online class of a core data communications course in the Undergraduate IT
program of the Information Sciences and Technology (IST) Department at George
Mason University (GMU). In this study, students were evaluated based on course
assessments such as home and lab assignments, skill-based assessments, and
traditional midterm and final exams across all four sections of the course. All
sections have equivalent content, assessments, and teaching methodologies.
Student demographics such as exam type and location preferences are considered
in our study to determine whether they have any impact on their learning
approach. Large amount of data from the learning management system (LMS),
Blackboard (BB) Learn, had to be examined to compare the results of several
assessment outcomes for all students within their respective section and
amongst students of other sections. To investigate the effect of dissimilar
assessment formats on student performance, we had to correlate individual
question formats with the overall course grade. The results show that
collective assessment formats allow students to be effective in demonstrating
their knowledge.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Islam_K/0/1/0/all/0/1&quot;&gt;Khondkar Islam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Ahmadi_P/0/1/0/all/0/1&quot;&gt;Pouyan Ahmadi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Yousaf_S/0/1/0/all/0/1&quot;&gt;Salman Yousaf&lt;/a&gt;</dc:creator>
</item></rdf:RDF>