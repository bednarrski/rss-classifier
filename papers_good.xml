<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Good papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Good Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-02-12T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.03505"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.03620"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04051"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.05027"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.03039"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.03268"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.03499"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.03544"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.03685"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.03691"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.03701"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.03753"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.03774"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.03788"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.03875"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.03881"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.03976"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04009"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04030"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04032"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04086"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04093"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04127"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04181"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1703.01008"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1706.01284"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.01308"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.05453"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.05706"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.00350"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.01957"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.03175"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.09547"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.03487"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.03567"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.03675"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.03689"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.03690"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.03761"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.03830"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.03839"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.03866"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.03882"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.03903"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04223"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.07172"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.06952"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.10370"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.11595"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.02294"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.00662"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.01448"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.02664"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.03911"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1802.03505">
<title>Plummer Autoencoders. (arXiv:1802.03505v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.03505</link>
<description rdf:parseType="Literal">&lt;p&gt;Estimating the true density in high-dimensional feature spaces is a
well-known problem in machine learning. This work shows that it is possible to
formulate the optimization problem as a minimization and use the
representational power of neural networks to learn very complex densities. A
theoretical bound on the estimation error is given when dealing with finite
number of samples. The proposed theory is corroborated by extensive experiments
on different datasets and compared against several existing approaches from the
families of generative adversarial networks and autoencoder-based models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sansone_E/0/1/0/all/0/1&quot;&gt;Emanuele Sansone&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Phan_Q/0/1/0/all/0/1&quot;&gt;Quoc-Tin Phan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Natale_F/0/1/0/all/0/1&quot;&gt;Francesco G.B. De Natale&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.03620">
<title>Optimal approximation of continuous functions by very deep ReLU networks. (arXiv:1802.03620v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1802.03620</link>
<description rdf:parseType="Literal">&lt;p&gt;We prove that deep ReLU neural networks with conventional fully-connected
architectures with $W$ weights can approximate continuous $\nu$-variate
functions $f$ with uniform error not exceeding $a_\nu\omega_f(c_\nu
W^{-2/\nu}),$ where $\omega_f$ is the modulus of continuity of $f$ and $a_\nu,
c_\nu$ are some $\nu$-dependent constants. This bound is tight. Our
construction is inherently deep and nonlinear: the obtained approximation rate
cannot be achieved by networks with fewer than $\Omega(W/\ln W)$ layers or by
networks with weights continuously depending on $f$.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yarotsky_D/0/1/0/all/0/1&quot;&gt;Dmitry Yarotsky&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04051">
<title>One Deep Music Representation to Rule Them All? : A comparative analysis of different representation learning strategies. (arXiv:1802.04051v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1802.04051</link>
<description rdf:parseType="Literal">&lt;p&gt;Inspired by the success of deploying deep learning in the fields of Computer
Vision and Natural Language Processing, this learning paradigm has also found
its way into the field of Music Information Retrieval. In order to benefit from
deep learning in an effective, but also efficient manner, deep transfer
learning has become a common approach. In this approach, it is possible to
reuse the output of a pre-trained neural network as the basis for a new, yet
unseen learning task. The underlying hypothesis is that if the initial and new
learning tasks show commonalities and are applied to the same type of data
(e.g. music audio), the generated deep representation of the data is also
informative for the new task. Since, however, most of the networks used to
generate deep representations are trained using a single initial learning task,
the validity of the above hypothesis is questionable for an arbitrary new
learning task. In this paper we present the results of our investigation of
what the best ways are to generate deep representations for the data and
learning tasks in the music domain. We conducted this investigation via an
extensive empirical study that involves multiple learning tasks, as well as
multiple deep learning architectures with varying levels of information sharing
between tasks, in order to learn music representations. We then validate these
representations considering multiple unseen learning tasks for evaluation. The
results of our experiments yield several insights on how to approach the design
of methods for learning widely deployable deep data representations in the
music domain.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1&quot;&gt;Jaehun Kim&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Urbano_J/0/1/0/all/0/1&quot;&gt;Juli&amp;#xe1;n Urbano&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liem_C/0/1/0/all/0/1&quot;&gt;Cynthia C. S. Liem&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hanjalic_A/0/1/0/all/0/1&quot;&gt;Alan Hanjalic&lt;/a&gt; (1) ((1) Delft University of Technology)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.05027">
<title>Learning Intrinsic Sparse Structures within Long Short-Term Memory. (arXiv:1709.05027v7 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1709.05027</link>
<description rdf:parseType="Literal">&lt;p&gt;Model compression is significant for the wide adoption of Recurrent Neural
Networks (RNNs) in both user devices possessing limited resources and business
clusters requiring quick responses to large-scale service requests. This work
aims to learn structurally-sparse Long Short-Term Memory (LSTM) by reducing the
sizes of basic structures within LSTM units, including input updates, gates,
hidden states, cell states and outputs. Independently reducing the sizes of
basic structures can result in inconsistent dimensions among them, and
consequently, end up with invalid LSTM units. To overcome the problem, we
propose Intrinsic Sparse Structures (ISS) in LSTMs. Removing a component of ISS
will simultaneously decrease the sizes of all basic structures by one and
thereby always maintain the dimension consistency. By learning ISS within LSTM
units, the obtained LSTMs remain regular while having much smaller basic
structures. Based on group Lasso regularization, our method achieves 10.59x
speedup without losing any perplexity of a language modeling of Penn TreeBank
dataset. It is also successfully evaluated through a compact model with only
2.69M weights for machine Question Answering of SQuAD dataset. Our approach is
successfully extended to non- LSTM RNNs, like Recurrent Highway Networks
(RHNs). Our source code is publicly available at
https://github.com/wenwei202/iss-rnns
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wen_W/0/1/0/all/0/1&quot;&gt;Wei Wen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1&quot;&gt;Yuxiong He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rajbhandari_S/0/1/0/all/0/1&quot;&gt;Samyam Rajbhandari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1&quot;&gt;Minjia Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1&quot;&gt;Wenhan Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1&quot;&gt;Fang Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_B/0/1/0/all/0/1&quot;&gt;Bin Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yiran Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1&quot;&gt;Hai Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.03039">
<title>Imitation networks: Few-shot learning of neural networks from scratch. (arXiv:1802.03039v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1802.03039</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we propose imitation networks, a simple but effective method
for training neural networks with a limited amount of training data. Our
approach inherits the idea of knowledge distillation that transfers knowledge
from a deep or wide reference model to a shallow or narrow target model. The
proposed method employs this idea to mimic predictions of reference estimators
that are much more robust against overfitting than the network we want to
train. Different from almost all the previous work for knowledge distillation
that requires a large amount of labeled training data, the proposed method
requires only a small amount of training data. Instead, we introduce pseudo
training examples that are optimized as a part of model parameters.
Experimental results for several benchmark datasets demonstrate that the
proposed method outperformed all the other baselines, such as naive training of
the target model and standard knowledge distillation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kimura_A/0/1/0/all/0/1&quot;&gt;Akisato Kimura&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ghahramani_Z/0/1/0/all/0/1&quot;&gt;Zoubin Ghahramani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Takeuchi_K/0/1/0/all/0/1&quot;&gt;Koh Takeuchi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Iwata_T/0/1/0/all/0/1&quot;&gt;Tomoharu Iwata&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ueda_N/0/1/0/all/0/1&quot;&gt;Naonori Ueda&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.03268">
<title>Efficient Neural Architecture Search via Parameter Sharing. (arXiv:1802.03268v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1802.03268</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose Efficient Neural Architecture Search (ENAS), a fast and
inexpensive approach for automatic model design. In ENAS, a controller learns
to discover neural network architectures by searching for an optimal subgraph
within a large computational graph. The controller is trained with policy
gradient to select a subgraph that maximizes the expected reward on the
validation set. Meanwhile the model corresponding to the selected subgraph is
trained to minimize a canonical cross entropy loss. Thanks to parameter sharing
between child models, ENAS is fast: it delivers strong empirical performances
using much fewer GPU-hours than all existing automatic model design approaches,
and notably, 1000x less expensive than standard Neural Architecture Search. On
the Penn Treebank dataset, ENAS discovers a novel architecture that achieves a
test perplexity of 55.8, establishing a new state-of-the-art among all methods
without post-training processing. On the CIFAR-10 dataset, ENAS designs novel
architectures that achieve a test error of 2.89%, which is on par with NASNet
(Zoph et al., 2018), whose test error is 2.65%.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pham_H/0/1/0/all/0/1&quot;&gt;Hieu Pham&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guan_M/0/1/0/all/0/1&quot;&gt;Melody Y. Guan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zoph_B/0/1/0/all/0/1&quot;&gt;Barret Zoph&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Le_Q/0/1/0/all/0/1&quot;&gt;Quoc V. Le&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dean_J/0/1/0/all/0/1&quot;&gt;Jeff Dean&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.03499">
<title>Local Contrast Learning. (arXiv:1802.03499v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.03499</link>
<description rdf:parseType="Literal">&lt;p&gt;Learning a deep model from small data is yet an opening and challenging
problem. We focus on one-shot classification by deep learning approach based on
a small quantity of training samples. We proposed a novel deep learning
approach named Local Contrast Learning (LCL) based on the key insight about a
human cognitive behavior that human recognizes the objects in a specific
context by contrasting the objects in the context or in her/his memory. LCL is
used to train a deep model that can contrast the recognizing sample with a
couple of contrastive samples randomly drawn and shuffled. On one-shot
classification task on Omniglot, the deep model based LCL with 122 layers and
1.94 millions of parameters, which was trained on a tiny dataset with only 60
classes and 20 samples per class, achieved the accuracy 97.99% that outperforms
human and state-of-the-art established by Bayesian Program Learning (BPL)
trained on 964 classes. LCL is a fundamental idea which can be applied to
alleviate parametric model&apos;s overfitting resulted by lack of training samples.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1&quot;&gt;Chuanyun Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yang Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feng_X/0/1/0/all/0/1&quot;&gt;Xin Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ge_Y/0/1/0/all/0/1&quot;&gt;YongXing Ge&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yihao Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Long_J/0/1/0/all/0/1&quot;&gt;Jianwu Long&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.03544">
<title>To the problem of &quot;The Instrumental complex for ontological engineering purpose&quot; software system design. (arXiv:1802.03544v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.03544</link>
<description rdf:parseType="Literal">&lt;p&gt;The given work describes methodological principles of design instrumental
complex of ontological purpose. Instrumental complex intends for the
implementation of the integrated information technologies automated build of
domain ontologies. Results focus on enhancing the effectiveness of the
automatic analysis and understanding of natural-language texts, building of
knowledge description of subject areas (primarily in the area of science and
technology) and for interdisciplinary research in conjunction with the solution
of complex problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Palagin_A/0/1/0/all/0/1&quot;&gt;A.V. Palagin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Petrenko_N/0/1/0/all/0/1&quot;&gt;N.G. Petrenko&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Velychko_V/0/1/0/all/0/1&quot;&gt;V.Yu. Velychko&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Malakhov_K/0/1/0/all/0/1&quot;&gt;K.S. Malakhov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tikhonov_Y/0/1/0/all/0/1&quot;&gt;Yu.L. Tikhonov&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.03685">
<title>Learning a SAT Solver from Single-Bit Supervision. (arXiv:1802.03685v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.03685</link>
<description rdf:parseType="Literal">&lt;p&gt;We present NeuroSAT, a message passing neural network that learns to solve
SAT problems after only being trained as a classifier to predict
satisfiability. Although it is not competitive with state-of-the-art SAT
solvers, NeuroSAT can solve problems that are substantially larger and more
difficult than it ever saw during training by simply running for more
iterations. Moreover, NeuroSAT generalizes to novel distributions; after
training only on random SAT problems, at test time it can solve SAT problems
encoding graph coloring, clique detection, dominating set, and vertex cover
problems, all on a range of distributions over small random graphs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Selsam_D/0/1/0/all/0/1&quot;&gt;Daniel Selsam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lamm_M/0/1/0/all/0/1&quot;&gt;Matthew Lamm&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bunz_B/0/1/0/all/0/1&quot;&gt;Benedikt Bunz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_P/0/1/0/all/0/1&quot;&gt;Percy Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moura_L/0/1/0/all/0/1&quot;&gt;Leonardo de Moura&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dill_D/0/1/0/all/0/1&quot;&gt;David L. Dill&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.03691">
<title>Tree-to-tree Neural Networks for Program Translation. (arXiv:1802.03691v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.03691</link>
<description rdf:parseType="Literal">&lt;p&gt;Program translation is an important tool to migrate legacy code in one
language into an ecosystem built in a different language. In this work, we are
the first to consider employing deep neural networks toward tackling this
problem. We observe that program translation is a modular procedure, in which a
sub-tree of the source tree is translated into the corresponding target
sub-tree at each step. To capture this intuition, we design a tree-to-tree
neural network as an encoder-decoder architecture to translate a source tree
into a target one. Meanwhile, we develop an attention mechanism for the
tree-to-tree model, so that when the decoder expands one non-terminal in the
target tree, the attention mechanism locates the corresponding sub-tree in the
source tree to guide the expansion of the decoder. We evaluate the program
translation capability of our tree-to-tree model against several
state-of-the-art approaches. Compared against other neural translation models,
we observe that our approach is consistently better than the baselines with a
margin of up to 15 points. Further, our approach can improve the previous
state-of-the-art program translation approaches by a margin of 20 points on the
translation of real-world projects.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1&quot;&gt;Xinyun Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1&quot;&gt;Chang Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_D/0/1/0/all/0/1&quot;&gt;Dawn Song&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.03701">
<title>Formal Ontology Learning from English IS-A Sentences. (arXiv:1802.03701v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.03701</link>
<description rdf:parseType="Literal">&lt;p&gt;Ontology learning (OL) is the process of automatically generating an
ontological knowledge base from a plain text document. In this paper, we
propose a new ontology learning approach and tool, called DLOL, which generates
a knowledge base in the description logic (DL) SHOQ(D) from a collection of
factual non-negative IS-A sentences in English. We provide extensive
experimental results on the accuracy of DLOL, giving experimental comparisons
to three state-of-the-art existing OL tools, namely Text2Onto, FRED, and LExO.
Here, we use the standard OL accuracy measure, called lexical accuracy, and a
novel OL accuracy measure, called instance-based inference model. In our
experimental results, DLOL turns out to be about 21% and 46%, respectively,
better than the best of the other three approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dasgupta_S/0/1/0/all/0/1&quot;&gt;Sourish Dasgupta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Padia_A/0/1/0/all/0/1&quot;&gt;Ankur Padia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Maheshwari_G/0/1/0/all/0/1&quot;&gt;Gaurav Maheshwari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Trivedi_P/0/1/0/all/0/1&quot;&gt;Priyansh Trivedi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lehmann_J/0/1/0/all/0/1&quot;&gt;Jens Lehmann&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.03753">
<title>Sample Efficient Deep Reinforcement Learning for Dialogue Systems with Large Action Spaces. (arXiv:1802.03753v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1802.03753</link>
<description rdf:parseType="Literal">&lt;p&gt;In spoken dialogue systems, we aim to deploy artificial intelligence to build
automated dialogue agents that can converse with humans. A part of this effort
is the policy optimisation task, which attempts to find a policy describing how
to respond to humans, in the form of a function taking the current state of the
dialogue and returning the response of the system. In this paper, we
investigate deep reinforcement learning approaches to solve this problem.
Particular attention is given to actor-critic methods, off-policy reinforcement
learning with experience replay, and various methods aimed at reducing the bias
and variance of estimators. When combined, these methods result in the
previously proposed ACER algorithm that gave competitive results in gaming
environments. These environments however are fully observable and have a
relatively small action set so in this paper we examine the application of ACER
to dialogue policy optimisation. We show that this method beats the current
state-of-the-art in deep learning approaches for spoken dialogue systems. This
not only leads to a more sample efficient algorithm that can train faster, but
also allows us to apply the algorithm in more difficult environments than
before. We thus experiment with learning in a very large action space, which
has two orders of magnitude more actions than previously considered. We find
that ACER trains significantly faster than the current state-of-the-art.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Weisz_G/0/1/0/all/0/1&quot;&gt;Gell&amp;#xe9;rt Weisz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Budzianowski_P/0/1/0/all/0/1&quot;&gt;Pawe&amp;#x142; Budzianowski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Su_P/0/1/0/all/0/1&quot;&gt;Pei-Hao Su&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gasic_M/0/1/0/all/0/1&quot;&gt;Milica Ga&amp;#x161;i&amp;#x107;&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.03774">
<title>Learning Multiple Levels of Representations with Kernel Machines. (arXiv:1802.03774v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.03774</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a connectionist-inspired kernel machine model with three key
advantages over traditional kernel machines. First, it is capable of learning
distributed and hierarchical representations. Second, its performance is highly
robust to the choice of kernel function. Third, the solution space is not
limited to the span of images of training data in reproducing kernel Hilbert
space (RKHS). Together with the architecture, we propose a greedy learning
algorithm that allows the proposed multilayer network to be trained layer-wise
without backpropagation by optimizing the geometric properties of images in
RKHS. With a single fixed generic kernel for each layer and two layers in
total, our model compares favorably with state-of-the-art multiple kernel
learning algorithms using significantly more kernels and popular deep
architectures on widely used classification benchmarks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Duan_S/0/1/0/all/0/1&quot;&gt;Shiyu Duan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yunmei Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Principe_J/0/1/0/all/0/1&quot;&gt;Jose Principe&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.03788">
<title>Influence-Directed Explanations for Deep Convolutional Networks. (arXiv:1802.03788v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.03788</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the problem of explaining a rich class of behavioral properties of
deep neural networks. Distinctively, our influence-directed explanations
approach this problem by peering inside the net- work to identify neurons with
high influence on the property and distribution of interest using an
axiomatically justified influence measure, and then providing an interpretation
for the concepts these neurons represent. We evaluate our approach by training
convolutional neural net- works on MNIST, ImageNet, Pubfig, and Diabetic
Retinopathy datasets. Our evaluation demonstrates that influence-directed
explanations (1) identify influential concepts that generalize across
instances, (2) help extract the essence of what the network learned about a
class, (3) isolate individual features the network uses to make decisions and
distinguish related instances, and (4) assist in understanding
misclassifications.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leino_K/0/1/0/all/0/1&quot;&gt;Klas Leino&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1&quot;&gt;Linyi Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sen_S/0/1/0/all/0/1&quot;&gt;Shayak Sen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Datta_A/0/1/0/all/0/1&quot;&gt;Anupam Datta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fredrikson_M/0/1/0/all/0/1&quot;&gt;Matt Fredrikson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.03875">
<title>Pseudo-Recursal: Solving the Catastrophic Forgetting Problem in Deep Neural Networks. (arXiv:1802.03875v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.03875</link>
<description rdf:parseType="Literal">&lt;p&gt;In general, neural networks are not currently capable of learning tasks in a
sequential fashion. When a novel, unrelated task is learnt by a neural network,
it substantially forgets how to solve previously learnt tasks. One of the
original solutions to this problem is pseudo-rehearsal, which involves learning
the new task while rehearsing generated items representative of the previous
task/s. This is very effective for simple tasks. However, pseudo-rehearsal has
not yet been successfully applied to very complex tasks because in these tasks
it is difficult to generate representative items. We accomplish
pseudo-rehearsal by using a Generative Adversarial Network to generate items so
that our deep network can learn to sequentially classify the CIFAR-10, SVHN and
MNIST datasets. After training on all tasks, our network loses only 1.67%
absolute accuracy on CIFAR-10 and gains 0.24% absolute accuracy on SVHN. Our
model&apos;s performance is a substantial improvement compared to the current state
of the art solution.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Atkinson_C/0/1/0/all/0/1&quot;&gt;Craig Atkinson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+McCane_B/0/1/0/all/0/1&quot;&gt;Brendan McCane&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Szymanski_L/0/1/0/all/0/1&quot;&gt;Lech Szymanski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Robins_A/0/1/0/all/0/1&quot;&gt;Anthony Robins&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.03881">
<title>Answerer in Questioner&apos;s Mind for Goal-Oriented Visual Dialogue. (arXiv:1802.03881v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1802.03881</link>
<description rdf:parseType="Literal">&lt;p&gt;Goal-oriented dialogue has been paid attention for its numerous applications
in artificial intelligence. To solve this task, deep learning and reinforcement
learning have recently been applied. However, these approaches struggle to find
a competent recurrent neural questioner, owing to the complexity of learning a
series of sentences. Motivated by theory of mind, we propose &quot;Answerer in
Questioner&apos;s Mind&quot; (AQM), a novel algorithm for goal-oriented dialogue. With
AQM, a questioner asks and infers based on an approximated probabilistic model
of the answerer. The questioner figures out the answerer&apos;s intent via selecting
a plausible question by explicitly calculating the information gain of the
candidate intentions and possible answers to each question. We test our
framework on two goal-oriented visual dialogue tasks: &quot;MNIST Counting Dialog&quot;
and &quot;GuessWhat?!.&quot; In our experiments, AQM outperforms comparative algorithms
and makes human-like dialogue. We further use AQM as a tool for analyzing the
mechanism of deep reinforcement learning approach and discuss the future
direction of practical goal-oriented neural dialogue systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1&quot;&gt;Sang-Woo Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Heo_Y/0/1/0/all/0/1&quot;&gt;Yu-Jung Heo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1&quot;&gt;Byoung-Tak Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.03976">
<title>A note on reinforcement learning with Wasserstein distance regularisation, with applications to multipolicy learning. (arXiv:1802.03976v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.03976</link>
<description rdf:parseType="Literal">&lt;p&gt;In this note we describe an application of Wasserstein distance to
Reinforcement Learning. The Wasserstein distance in question is between the
distribution of mappings of trajectories of a policy into some metric space,
and some other fixed distribution (which may, for example, come from another
policy). Different policies induce different distributions, so given an
underlying metric, the Wasserstein distance quantifies how different policies
are. This can be used to learn multiple polices which are different in terms of
such Wasserstein distances by using a Wasserstein regulariser. Changing the
sign of the regularisation parameter, one can learn a policy for which its
trajectory mapping distribution is attracted to a given fixed distribution.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abdullah_M/0/1/0/all/0/1&quot;&gt;Mohammed Amin Abdullah&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pacchiano_A/0/1/0/all/0/1&quot;&gt;Aldo Pacchiano&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Draief_M/0/1/0/all/0/1&quot;&gt;Moez Draief&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04009">
<title>Distinguishing Question Subjectivity from Difficulty for Improved Crowdsourcing. (arXiv:1802.04009v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.04009</link>
<description rdf:parseType="Literal">&lt;p&gt;The questions in a crowdsourcing task typically exhibit varying degrees of
difficulty and subjectivity. Their joint effects give rise to the variation in
responses to the same question by different crowd-workers. This variation is
low when the question is easy to answer and objective, and high when it is
difficult and subjective. Unfortunately, current quality control methods for
crowdsourcing consider only the question difficulty to account for the
variation. As a result,these methods cannot distinguish workers personal
preferences for different correct answers of a partially subjective question
from their ability/expertise to avoid objectively wrong answers for that
question. To address this issue, we present a probabilistic model which (i)
explicitly encodes question difficulty as a model parameter and (ii) implicitly
encodes question subjectivity via latent preference factors for crowd-workers.
We show that question subjectivity induces grouping of crowd-workers, revealed
through clustering of their latent preferences. Moreover, we develop a
quantitative measure of the subjectivity of a question. Experiments show that
our model(1) improves the performance of both quality control for crowd-sourced
answers and next answer prediction for crowd-workers,and (2) can potentially
provide coherent rankings of questions in terms of their difficulty and
subjectivity, so that task providers can refine their designs of the
crowdsourcing tasks, e.g. by removing highly subjective questions or
inappropriately difficult questions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jin_Y/0/1/0/all/0/1&quot;&gt;Yuan Jin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Carman_M/0/1/0/all/0/1&quot;&gt;Mark Carman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1&quot;&gt;Ye Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Buntine_W/0/1/0/all/0/1&quot;&gt;Wray Buntine&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04030">
<title>Introducer Concepts in n-Dimensional Contexts. (arXiv:1802.04030v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.04030</link>
<description rdf:parseType="Literal">&lt;p&gt;Concept lattices are well-known conceptual structures that organise
interesting patterns-the concepts-extracted from data. In some applications,
such as software engineering or data mining, the size of the lattice can be a
problem, as it is often too large to be efficiently computed, and too complex
to be browsed. For this reason, the Galois Sub-Hierarchy, a restriction of the
concept lattice to introducer concepts, has been introduced as a smaller
alternative. In this paper, we generalise the Galois Sub-Hierarchy to
n-lattices, conceptual structures obtained from multidimensional data in the
same way that concept lattices are obtained from binary relations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kahn_G/0/1/0/all/0/1&quot;&gt;Giacomo Kahn&lt;/a&gt; (LIMOS), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bazin_A/0/1/0/all/0/1&quot;&gt;Alexandre Bazin&lt;/a&gt; (LIMOS)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04032">
<title>Average Size of Implicational Bases. (arXiv:1802.04032v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.04032</link>
<description rdf:parseType="Literal">&lt;p&gt;Implicational bases are objects of interest in formal concept analysis and
its applications. Unfortunately, even the smallest base, the Duquenne-Guigues
base, has an exponential size in the worst case. In this paper, we use results
on the average number of minimal transversals in random hypergraphs to show
that the base of proper premises is, on average, of quasi-polynomial size.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kahn_G/0/1/0/all/0/1&quot;&gt;Giacomo Kahn&lt;/a&gt; (LIMOS), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bazin_A/0/1/0/all/0/1&quot;&gt;Alexandre Bazin&lt;/a&gt; (Le2i)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04086">
<title>The Complex Event Recognition Group. (arXiv:1802.04086v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.04086</link>
<description rdf:parseType="Literal">&lt;p&gt;The Complex Event Recognition (CER) group is a research team, affiliated with
the National Centre of Scientific Research &quot;Demokritos&quot; in Greece. The CER
group works towards advanced and efficient methods for the recognition of
complex events in a multitude of large, heterogeneous and interdependent data
streams. Its research covers multiple aspects of complex event recognition,
from efficient detection of patterns on event streams to handling uncertainty
and noise in streams, and machine learning techniques for inferring interesting
patterns. Lately, it has expanded to methods for forecasting the occurrence of
events. It was founded in 2009 and currently hosts 3 senior researchers, 5 PhD
students and works regularly with under-graduate students.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alevizos_E/0/1/0/all/0/1&quot;&gt;Elias Alevizos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Artikis_A/0/1/0/all/0/1&quot;&gt;Alexander Artikis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Katzouris_N/0/1/0/all/0/1&quot;&gt;Nikos Katzouris&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Michelioudakis_E/0/1/0/all/0/1&quot;&gt;Evangelos Michelioudakis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Paliouras_G/0/1/0/all/0/1&quot;&gt;Georgios Paliouras&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04093">
<title>Reasoning in a Hierarchical System with Missing Group Size Information. (arXiv:1802.04093v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.04093</link>
<description rdf:parseType="Literal">&lt;p&gt;The paper analyzes the problem of judgments or preferences subsequent to
initial analysis by autonomous agents in a hierarchical system where the higher
level agents does not have access to group size information. We propose methods
that reduce instances of preference reversal of the kind encountered in
Simpson&apos;s paradox.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kak_S/0/1/0/all/0/1&quot;&gt;Subhash Kak&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04127">
<title>A New Algorithmic Decision for Catergorical Syllogisms via Caroll&apos;s Diagrams. (arXiv:1802.04127v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.04127</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work, we give an algorithm by using Carroll diagrammatic method for
deciding the syllogism is valid or not.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gursoy_A/0/1/0/all/0/1&quot;&gt;Arif Gursoy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Senturk_I/0/1/0/all/0/1&quot;&gt;Ibrahim Senturk&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oner_T/0/1/0/all/0/1&quot;&gt;Tahsin Oner&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04181">
<title>State Representation Learning for Control: An Overview. (arXiv:1802.04181v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.04181</link>
<description rdf:parseType="Literal">&lt;p&gt;Representation learning algorithms are designed to learn abstract features
that characterize data. State representation learning (SRL) focuses on a
particular kind of representation learning where learned features are in low
dimension, evolve through time, and are influenced by actions of an agent. As
the representation learned captures the variation in the environment generated
by agents, this kind of representation is particularly suitable for robotics
and control scenarios. In particular, the low dimension helps to overcome the
curse of dimensionality, provides easier interpretation and utilization by
humans and can help improve performance and speed in policy learning algorithms
such as reinforcement learning.
&lt;/p&gt;
&lt;p&gt;This survey aims at covering the state-of-the-art on state representation
learning in the most recent years. It reviews different SRL methods that
involve interaction with the environment, their implementations and their
applications in robotics control tasks (simulated or real). In particular, it
highlights how generic learning objectives are differently exploited in the
reviewed algorithms. Finally, it discusses evaluation methods to assess the
representation learned and summarizes current and future lines of research.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lesort_T/0/1/0/all/0/1&quot;&gt;Timoth&amp;#xe9;e Lesort&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Diaz_Rodriguez_N/0/1/0/all/0/1&quot;&gt;Natalia D&amp;#xed;az-Rodr&amp;#xed;guez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goudou_J/0/1/0/all/0/1&quot;&gt;Jean-Fran&amp;#xe7;ois Goudou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Filliat_D/0/1/0/all/0/1&quot;&gt;David Filliat&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1703.01008">
<title>End-to-End Task-Completion Neural Dialogue Systems. (arXiv:1703.01008v4 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1703.01008</link>
<description rdf:parseType="Literal">&lt;p&gt;One of the major drawbacks of modularized task-completion dialogue systems is
that each module is trained individually, which presents several challenges.
For example, downstream modules are affected by earlier modules, and the
performance of the entire system is not robust to the accumulated errors. This
paper presents a novel end-to-end learning framework for task-completion
dialogue systems to tackle such issues. Our neural dialogue system can directly
interact with a structured database to assist users in accessing information
and accomplishing certain tasks. The reinforcement learning based dialogue
manager offers robust capabilities to handle noises caused by other components
of the dialogue system. Our experiments in a movie-ticket booking domain show
that our end-to-end system not only outperforms modularized dialogue system
baselines for both objective and subjective evaluation, but also is robust to
noises as demonstrated by several systematic experiments with different error
granularity and rates specific to the language understanding module.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xiujun Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yun-Nung Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1&quot;&gt;Lihong Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1&quot;&gt;Jianfeng Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Celikyilmaz_A/0/1/0/all/0/1&quot;&gt;Asli Celikyilmaz&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1706.01284">
<title>Towards Synthesizing Complex Programs from Input-Output Examples. (arXiv:1706.01284v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1706.01284</link>
<description rdf:parseType="Literal">&lt;p&gt;In recent years, deep learning techniques have been developed to improve the
performance of program synthesis from input-output examples. Albeit its
significant progress, the programs that can be synthesized by state-of-the-art
approaches are still simple in terms of their complexity. In this work, we move
a significant step forward along this direction by proposing a new class of
challenging tasks in the domain of program synthesis from input-output
examples: learning a context-free parser from pairs of input programs and their
parse trees. We show that this class of tasks are much more challenging than
previously studied tasks, and the test accuracy of existing approaches is
almost 0%.
&lt;/p&gt;
&lt;p&gt;We tackle the challenges by developing three novel techniques inspired by
three novel observations, which reveal the key ingredients of using deep
learning to synthesize a complex program. First, the use of a
non-differentiable machine is the key to effectively restrict the search space.
Thus our proposed approach learns a neural program operating a domain-specific
non-differentiable machine. Second, recursion is the key to achieve
generalizability. Thus, we bake-in the notion of recursion in the design of our
non-differentiable machine. Third, reinforcement learning is the key to learn
how to operate the non-differentiable machine, but it is also hard to train the
model effectively with existing reinforcement learning algorithms from a cold
boot. We develop a novel two-phase reinforcement learning-based search
algorithm to overcome this issue. In our evaluation, we show that using our
novel approach, neural parsing programs can be learned to achieve 100% test
accuracy on test inputs that are 500x longer than the training samples.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1&quot;&gt;Xinyun Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1&quot;&gt;Chang Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_D/0/1/0/all/0/1&quot;&gt;Dawn Song&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.01308">
<title>BOOK: Storing Algorithm-Invariant Episodes for Deep Reinforcement Learning. (arXiv:1709.01308v3 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1709.01308</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce a novel method to train agents of reinforcement learning (RL) by
sharing knowledge in a way similar to the concept of using a book. The recorded
information in the form of a book is the main means by which humans learn
knowledge. Nevertheless, the conventional deep RL methods have mainly focused
either on experiential learning where the agent learns through interactions
with the environment from the start or on imitation learning that tries to
mimic the teacher. Contrary to these, our proposed book learning shares key
information among different agents in a book-like manner by delving into the
following two characteristic features: (1) By defining the linguistic function,
input states can be clustered semantically into a relatively small number of
core clusters, which are forwarded to other RL agents in a prescribed manner.
(2) By defining state priorities and the contents for recording, core
experiences can be selected and stored in a small container. We call this
container as `BOOK&apos;. Our method learns hundreds to thousand times faster than
the conventional methods by learning only a handful of core cluster
information, which shows that deep RL agents can effectively learn through the
shared knowledge from other agents.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chang_S/0/1/0/all/0/1&quot;&gt;Simyung Chang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yoo_Y/0/1/0/all/0/1&quot;&gt;YoungJoon Yoo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Choi_J/0/1/0/all/0/1&quot;&gt;Jaeseok Choi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kwak_N/0/1/0/all/0/1&quot;&gt;Nojun Kwak&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.05453">
<title>Augmenting End-to-End Dialog Systems with Commonsense Knowledge. (arXiv:1709.05453v3 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1709.05453</link>
<description rdf:parseType="Literal">&lt;p&gt;Building dialog agents that can converse naturally with humans is a
challenging yet intriguing problem of artificial intelligence. In open-domain
human-computer conversation, where the conversational agent is expected to
respond to human responses in an interesting and engaging way, commonsense
knowledge has to be integrated into the model effectively. In this paper, we
investigate the impact of providing commonsense knowledge about the concepts
covered in the dialog. Our model represents the first attempt to integrating a
large commonsense knowledge base into end-to-end conversational models. In the
retrieval-based scenario, we propose the Tri-LSTM model to jointly take into
account message and commonsense for selecting an appropriate response. Our
experiments suggest that the knowledge-augmented models are superior to their
knowledge-free counterparts in automatic evaluation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Young_T/0/1/0/all/0/1&quot;&gt;Tom Young&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cambria_E/0/1/0/all/0/1&quot;&gt;Erik Cambria&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chaturvedi_I/0/1/0/all/0/1&quot;&gt;Iti Chaturvedi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_M/0/1/0/all/0/1&quot;&gt;Minlie Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1&quot;&gt;Hao Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Biswas_S/0/1/0/all/0/1&quot;&gt;Subham Biswas&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.05706">
<title>Memory Augmented Control Networks. (arXiv:1709.05706v5 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1709.05706</link>
<description rdf:parseType="Literal">&lt;p&gt;Planning problems in partially observable environments cannot be solved
directly with convolutional networks and require some form of memory. But, even
memory networks with sophisticated addressing schemes are unable to learn
intelligent reasoning satisfactorily due to the complexity of simultaneously
learning to access memory and plan. To mitigate these challenges we introduce
the Memory Augmented Control Network (MACN). The proposed network architecture
consists of three main parts. The first part uses convolutions to extract
features and the second part uses a neural network-based planning module to
pre-plan in the environment. The third part uses a network controller that
learns to store those specific instances of past information that are necessary
for planning. The performance of the network is evaluated in discrete grid
world environments for path planning in the presence of simple and complex
obstacles. We show that our network learns to plan and can generalize to new
environments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khan_A/0/1/0/all/0/1&quot;&gt;Arbaaz Khan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1&quot;&gt;Clark Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Atanasov_N/0/1/0/all/0/1&quot;&gt;Nikolay Atanasov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Karydis_K/0/1/0/all/0/1&quot;&gt;Konstantinos Karydis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kumar_V/0/1/0/all/0/1&quot;&gt;Vijay Kumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_D/0/1/0/all/0/1&quot;&gt;Daniel D. Lee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.00350">
<title>Generalization without systematicity: On the compositional skills of sequence-to-sequence recurrent networks. (arXiv:1711.00350v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1711.00350</link>
<description rdf:parseType="Literal">&lt;p&gt;Humans can understand and produce new utterances effortlessly, thanks to
their compositional skills. Once a person learns the meaning of a new verb
&quot;dax,&quot; he or she can immediately understand the meaning of &quot;dax twice&quot; or &quot;sing
and dax.&quot; In this paper, we introduce the SCAN domain, consisting of a set of
simple compositional navigation commands paired with the corresponding action
sequences. We then test the zero-shot generalization capabilities of a variety
of recurrent neural networks (RNNs) trained on SCAN with sequence-to-sequence
methods. We find that RNNs can make successful zero-shot generalizations when
the differences between training and test commands are small, so that they can
apply &quot;mix-and-match&quot; strategies to solve the task. However, when
generalization requires systematic compositional skills (as in the &quot;dax&quot;
example above), RNNs fail spectacularly. We conclude with a proof-of-concept
experiment in neural machine translation, suggesting that lack of systematicity
might be partially responsible for neural networks&apos; notorious training data
thirst.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lake_B/0/1/0/all/0/1&quot;&gt;Brenden M. Lake&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Baroni_M/0/1/0/all/0/1&quot;&gt;Marco Baroni&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.01957">
<title>From Eliza to XiaoIce: Challenges and Opportunities with Social Chatbots. (arXiv:1801.01957v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1801.01957</link>
<description rdf:parseType="Literal">&lt;p&gt;Conversational systems have come a long way since their inception in the
1960s. After decades of research and development, we&apos;ve seen progress from
Eliza and Parry in the 60&apos;s and 70&apos;s, to task-completion systems as in the
DARPA Communicator program in the 2000s, to intelligent personal assistants
such as Siri in the 2010s, to today&apos;s social chatbots like XiaoIce. Social
chatbots&apos; appeal lies not only in their ability to respond to users&apos; diverse
requests, but also in being able to establish an emotional connection with
users. The latter is done by satisfying users&apos; need for communication,
affection, as well as social belonging. To further the advancement and adoption
of social chatbots, their design must focus on user engagement and take both
intellectual quotient (IQ) and emotional quotient (EQ) into account. Users
should want to engage with a social chatbot; as such, we define the success
metric for social chatbots as conversation-turns per session (CPS). Using
XiaoIce as an illustrative example, we discuss key technologies in building
social chatbots from core chat to visual awareness to skills. We also show how
XiaoIce can dynamically recognize emotion and engage the user throughout long
conversations with appropriate interpersonal responses. As we become the first
generation of humans ever living with AI, we have a responsibility to design
social chatbots to be both useful and empathetic, so they will become
ubiquitous and help society as a whole.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shum_H/0/1/0/all/0/1&quot;&gt;Heung-Yeung Shum&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1&quot;&gt;Xiaodong He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1&quot;&gt;Di Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.03175">
<title>Precision and Recall for Range-Based Anomaly Detection. (arXiv:1801.03175v3 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1801.03175</link>
<description rdf:parseType="Literal">&lt;p&gt;Classical anomaly detection is principally concerned with point-based
anomalies, anomalies that occur at a single data point. In this paper, we
present a new mathematical model to express range-based anomalies, anomalies
that occur over a range (or period) of time.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_T/0/1/0/all/0/1&quot;&gt;Tae Jun Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gottschlich_J/0/1/0/all/0/1&quot;&gt;Justin Gottschlich&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tatbul_N/0/1/0/all/0/1&quot;&gt;Nesime Tatbul&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Metcalf_E/0/1/0/all/0/1&quot;&gt;Eric Metcalf&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zdonik_S/0/1/0/all/0/1&quot;&gt;Stan Zdonik&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.09547">
<title>An Improved Tabu Search Heuristics for Static Dial-A-Ride Problem. (arXiv:1801.09547v3 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1801.09547</link>
<description rdf:parseType="Literal">&lt;p&gt;Multi-vehicle routing has become increasingly important with the rapid
development of autonomous vehicle technology. Dial-a-ride problem, a variant of
vehicle routing problem (VRP), deals with the allocation of customer requests
to vehicles, scheduling the pick-up and drop-off times and the sequence of
serving those requests by ensuring high customer satisfaction with minimized
travel cost. In this paper, we propose an improved tabu search (ITS) heuristic
for static dial-a-ride problem (DARP) with the objective of obtaining
high-quality solutions in short time. Two new techniques, initialization
heuristic, and time window adjustment are proposed to achieve faster
convergence to the global optimum. Various numerical experiments are conducted
for the proposed solution methodology using DARP test instances from the
literature and the convergence speed up is validated.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ho_S/0/1/0/all/0/1&quot;&gt;Songguang Ho&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nagavarapu_S/0/1/0/all/0/1&quot;&gt;Sarat Chandra Nagavarapu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pandi_R/0/1/0/all/0/1&quot;&gt;Ramesh Ramasamy Pandi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dauwels_J/0/1/0/all/0/1&quot;&gt;Justin Dauwels&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.03487">
<title>A Critical View of Global Optimality in Deep Learning. (arXiv:1802.03487v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.03487</link>
<description rdf:parseType="Literal">&lt;p&gt;We investigate the loss surface of deep linear and nonlinear neural networks.
We show that for deep linear networks with differentiable losses, critical
points after the multilinear parameterization inherit the structure of critical
points of the underlying loss with linear parameterization. As corollaries we
obtain &quot;local minima are global&quot; results that subsume most previous results,
while showing how to distinguish global minima from saddle points. For
nonlinear neural networks, we prove two theorems showing that even for networks
with one hidden layer, there can be spurious local minima. Indeed, for
piecewise linear nonnegative homogeneous activations (e.g., ReLU), we prove
that for almost all practical datasets there exist infinitely many local minima
that are not global. We conclude by constructing a counterexample involving
other activation functions (e.g., sigmoid, tanh, arctan, etc.), for which there
exists a local minimum strictly inferior to the global minimum.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yun_C/0/1/0/all/0/1&quot;&gt;Chulhee Yun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sra_S/0/1/0/all/0/1&quot;&gt;Suvrit Sra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jadbabaie_A/0/1/0/all/0/1&quot;&gt;Ali Jadbabaie&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.03567">
<title>Crit\`eres de qualit\&apos;e d&apos;un classifieur g\&apos;en\&apos;eraliste. (arXiv:1802.03567v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.03567</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper considers the problem of choosing a good classifier. For each
problem there exist an optimal classifier, but none are optimal, regarding the
error rate, in all cases. Because there exists a large number of classifiers, a
user would rather prefer an all-purpose classifier that is easy to adjust, in
the hope that it will do almost as good as the optimal. In this paper we
establish a list of criteria that a good generalist classifier should satisfy .
We first discuss data analytic, these criteria are presented. Six among the
most popular classifiers are selected and scored according to these criteria.
Tables allow to easily appreciate the relative values of each. In the end,
random forests turn out to be the best classifiers.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ducharme_G/0/1/0/all/0/1&quot;&gt;Gilles R. Ducharme&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.03675">
<title>Understanding Convolutional Networks with APPLE : Automatic Patch Pattern Labeling for Explanation. (arXiv:1802.03675v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.03675</link>
<description rdf:parseType="Literal">&lt;p&gt;With the success of deep learning, recent efforts have been focused on
analyzing how learned networks make their classifications. We are interested in
analyzing the network output based on the network structure and information
flow through the network layers. We contribute an algorithm for 1) analyzing a
deep network to find neurons that are &apos;important&apos; in terms of the network
classification outcome, and 2)automatically labeling the patches of the input
image that activate these important neurons. We propose several measures of
importance for neurons and demonstrate that our technique can be used to gain
insight into, and explain how a network decomposes an image to make its final
classification.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Konam_S/0/1/0/all/0/1&quot;&gt;Sandeep Konam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Quah_I/0/1/0/all/0/1&quot;&gt;Ian Quah&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rosenthal_S/0/1/0/all/0/1&quot;&gt;Stephanie Rosenthal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Veloso_M/0/1/0/all/0/1&quot;&gt;Manuela Veloso&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.03689">
<title>Dual Control Memory Augmented Neural Networks for Treatment Recommendations. (arXiv:1802.03689v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.03689</link>
<description rdf:parseType="Literal">&lt;p&gt;Machine-assisted treatment recommendations hold a promise to reduce physician
time and decision errors. We formulate the task as a sequence-to-sequence
prediction model that takes the entire time-ordered medical history as input,
and predicts a sequence of future clinical procedures and medications. It is
built on the premise that an effective treatment plan may have long-term
dependencies from previous medical history. We approach the problem by using a
memory-augmented neural network, in particular, by leveraging the recent
differentiable neural computer that consists of a neural controller and an
external memory module. But differing from the original model, we use dual
controllers, one for encoding the history followed by another for decoding the
treatment sequences. In the encoding phase, the memory is updated as new input
is read; at the end of this phase, the memory holds not only the medical
history but also the information about the current illness. During the decoding
phase, the memory is write-protected. The decoding controller generates a
treatment sequence, one treatment option at a time. The resulting dual
controller write-protected memory-augmented neural network is demonstrated on
the MIMIC-III dataset on two tasks: procedure prediction and medication
prescription. The results show improved performance over both traditional
bag-of-words and sequence-to-sequence methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Le_H/0/1/0/all/0/1&quot;&gt;Hung Le&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tran_T/0/1/0/all/0/1&quot;&gt;Truyen Tran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Venkatesh_S/0/1/0/all/0/1&quot;&gt;Svetha Venkatesh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.03690">
<title>On the Generalization of Equivariance and Convolution in Neural Networks to the Action of Compact Groups. (arXiv:1802.03690v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.03690</link>
<description rdf:parseType="Literal">&lt;p&gt;Convolutional neural networks have been extremely successful in the image
recognition domain because they ensure equivariance to translations. There have
been many recent attempts to generalize this framework to other domains,
including graphs and data lying on manifolds. In this paper we give a rigorous,
theoretical treatment of convolution and equivariance in neural networks with
respect to not just translations, but the action of any compact group. Our main
result is to prove that (given some natural constraints) convolutional
structure is not just a sufficient, but also a necessary condition for
equivariance to the action of a compact group. Our exposition makes use of
concepts from representation theory and noncommutative harmonic analysis and
derives new generalized convolution formulae.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kondor_R/0/1/0/all/0/1&quot;&gt;Risi Kondor&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Trivedi_S/0/1/0/all/0/1&quot;&gt;Shubhendu Trivedi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.03761">
<title>On the Latent Space of Wasserstein Auto-Encoders. (arXiv:1802.03761v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.03761</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the role of latent space dimensionality in Wasserstein auto-encoders
(WAEs). Through experimentation on synthetic and real datasets, we argue that
random encoders should be preferred over deterministic encoders. We highlight
the potential of WAEs for representation learning with promising results on a
benchmark disentanglement task.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rubenstein_P/0/1/0/all/0/1&quot;&gt;Paul K. Rubenstein&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Schoelkopf_B/0/1/0/all/0/1&quot;&gt;Bernhard Schoelkopf&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tolstikhin_I/0/1/0/all/0/1&quot;&gt;Ilya Tolstikhin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.03830">
<title>Distributed Stochastic Multi-Task Learning with Graph Regularization. (arXiv:1802.03830v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.03830</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose methods for distributed graph-based multi-task learning that are
based on weighted averaging of messages from other machines. Uniform averaging
or diminishing stepsize in these methods would yield consensus (single task)
learning. We show how simply skewing the averaging weights or controlling the
stepsize allows learning different, but related, tasks on the different
machines.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wang_W/0/1/0/all/0/1&quot;&gt;Weiran Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jialei Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kolar_M/0/1/0/all/0/1&quot;&gt;Mladen Kolar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Srebro_N/0/1/0/all/0/1&quot;&gt;Nathan Srebro&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.03839">
<title>Band Target Entropy Minimization and Target Partial Least Squares for Single Target Multivariate Curve Resolution and Calibration. (arXiv:1802.03839v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.03839</link>
<description rdf:parseType="Literal">&lt;p&gt;Band target entropy minimization (BTEM) and target partial least squares
calibration (T-PLS) were employed to resolve estimates for single pure
component spectra and to calibrate those components concentrations in a true
one-at-a-time fashion in unknown mixtures. It was found that BTEM could be used
to provide spectral estimates that, when applied as the target spectra in T-PLS
afforded similar errors of prediction as those from a standard multivariate
curve resolution method, multivariate curve resolution alternating least
squares (MCR-ALS). The calibration of BTEM resolved spectral estimates by T-PLS
rather than the typical classical least squares calibration allows for the
semiquantitation of individual well-represented components when other
components of an unknown mixture do not have sufficient independent variation
for spectral resolution. Two experimental scenarios were investigated to
demonstrate situations where the combination of BTEM and T-PLS could be applied
to model the pure component spectra and concentration profiles and MCR-ALS
could not. The combination of both techniques are shown to resolve and
calibrate a chemical impurity, melamine, by reflectance measurements of
serially diluted samples of reference milk powder and of dimethyl
methylphosphonate from a mid-infrared hyperspectral image of a gas stack.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kneale_C/0/1/0/all/0/1&quot;&gt;Casey Kneale&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Brown_S/0/1/0/all/0/1&quot;&gt;Steven D. Brown&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.03866">
<title>Katyusha X: Practical Momentum Method for Stochastic Sum-of-Nonconvex Optimization. (arXiv:1802.03866v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.03866</link>
<description rdf:parseType="Literal">&lt;p&gt;The problem of minimizing sum-of-nonconvex functions (i.e., convex functions
that are average of non-convex ones) is becoming increasingly important in
machine learning, and is the core machinery for PCA, SVD, regularized Newton&apos;s
method, accelerated non-convex optimization, and more.
&lt;/p&gt;
&lt;p&gt;We show how to provably obtain an accelerated stochastic algorithm for
minimizing sum-of-nonconvex functions, by $\textit{adding one additional line}$
to the well-known SVRG method. This line corresponds to momentum, and shows how
to directly apply momentum to the finite-sum stochastic minimization of
sum-of-nonconvex functions. As a side result, our method enjoys linear parallel
speed-up using mini-batch.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Allen_Zhu_Z/0/1/0/all/0/1&quot;&gt;Zeyuan Allen-Zhu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.03882">
<title>Random Hinge Forest for Differentiable Learning. (arXiv:1802.03882v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.03882</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose random hinge forests, a simple, efficient, and novel variant of
decision forests. Importantly, random hinge forests can be readily incorporated
as a general component within arbitrary computation graphs that are optimized
end-to-end with stochastic gradient descent or variants thereof. We derive
random hinge forest and ferns, focusing on their sparse and efficient nature,
their min-max margin property, strategies to initialize them for arbitrary
network architectures, and the class of optimizers most suitable for optimizing
random hinge forest. The performance and versatility of random hinge forests
are demonstrated by experiments incorporating a variety of of small and large
UCI machine learning data sets and also ones involving the MNIST, Letter, and
USPS image datasets. We compare random hinge forests with random forests and
the more recent backpropagating deep neural decision forests.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lay_N/0/1/0/all/0/1&quot;&gt;Nathan Lay&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Harrison_A/0/1/0/all/0/1&quot;&gt;Adam P. Harrison&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Schreiber_S/0/1/0/all/0/1&quot;&gt;Sharon Schreiber&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Dawer_G/0/1/0/all/0/1&quot;&gt;Gitesh Dawer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Barbu_A/0/1/0/all/0/1&quot;&gt;Adrian Barbu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.03903">
<title>Unsupervised Anomaly Detection via Variational Auto-Encoder for Seasonal KPIs in Web Applications. (arXiv:1802.03903v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.03903</link>
<description rdf:parseType="Literal">&lt;p&gt;To ensure undisrupted business, large Internet companies need to closely
monitor various KPIs (e.g., Page Views, number of online users, and number of
orders) of its Web applications, to accurately detect anomalies and trigger
timely troubleshooting/mitigation. However, anomaly detection for these
seasonal KPIs with various patterns and data quality has been a great
challenge, especially without labels. In this paper, we proposed Donut, an
unsupervised anomaly detection algorithm based on VAE. Thanks to a few of our
key techniques, Donut greatly outperforms a state-of-arts supervised ensemble
approach and a baseline VAE approach, and its best F-scores range from 0.75 to
0.9 for the studied KPIs from a top global Internet company. We come up with a
novel KDE interpretation of reconstruction for Donut, making it the first
VAE-based anomaly detection algorithm with solid theoretical explanation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1&quot;&gt;Haowen Xu&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1&quot;&gt;Wenxiao Chen&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_N/0/1/0/all/0/1&quot;&gt;Nengwen Zhao&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Zeyan Li&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bu_J/0/1/0/all/0/1&quot;&gt;Jiahao Bu&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Zhihan Li&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Ying Liu&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1&quot;&gt;Youjian Zhao&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pei_D/0/1/0/all/0/1&quot;&gt;Dan Pei&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feng_Y/0/1/0/all/0/1&quot;&gt;Yang Feng&lt;/a&gt; (2), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1&quot;&gt;Jie Chen&lt;/a&gt; (2), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zhaogang Wang&lt;/a&gt; (2), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qiao_H/0/1/0/all/0/1&quot;&gt;Honglin Qiao&lt;/a&gt; (2) ((1) Tsinghua University, (2) Alibaba Group)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04223">
<title>SparseMAP: Differentiable Sparse Structured Inference. (arXiv:1802.04223v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.04223</link>
<description rdf:parseType="Literal">&lt;p&gt;Structured prediction requires searching over a combinatorial number of
structures. To tackle it, we introduce SparseMAP, a new method for sparse
structured inference, together with corresponding loss functions. SparseMAP
inference is able to automatically select only a few global structures: it is
situated between MAP inference, which picks a single structure, and marginal
inference, which assigns probability mass to all structures, including
implausible ones. Importantly, SparseMAP can be computed using only calls to a
MAP oracle, hence it is applicable even to problems where marginal inference is
intractable, such as linear assignment. Moreover, thanks to the solution
sparsity, gradient backpropagation is efficient regardless of the structure.
SparseMAP thus enables us to augment deep neural networks with generic and
sparse structured hidden layers. Experiments in dependency parsing and natural
language inference reveal competitive accuracy, improved interpretability, and
the ability to capture natural language ambiguities, which is attractive for
pipeline systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Niculae_V/0/1/0/all/0/1&quot;&gt;Vlad Niculae&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Martins_A/0/1/0/all/0/1&quot;&gt;Andr&amp;#xe9; F. T. Martins&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Blondel_M/0/1/0/all/0/1&quot;&gt;Mathieu Blondel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Cardie_C/0/1/0/all/0/1&quot;&gt;Claire Cardie&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.07172">
<title>SpectralLeader: Online Spectral Learning for Single Topic Models. (arXiv:1709.07172v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1709.07172</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the problem of learning a latent variable model from a stream of
data. Latent variable models are popular in practice because they can explain
observed data in terms of unobserved concepts. These models have been
traditionally studied in the offline setting. The online EM is arguably the
most popular algorithm for learning latent variable models online. Although it
is computationally efficient, it typically converges to a local optimum. In
this work, we develop a new online learning algorithm for latent variable
models, which we call SpectralLeader. SpectralLeader always converges to the
global optimum, and we derive a $O(\sqrt{n})$ upper bound up to log factors on
its $n$-step regret in the bag-of-words model. We show that SpectralLeader
performs similarly to or better than the online EM with tuned hyper-parameters,
in both synthetic and real-world experiments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_T/0/1/0/all/0/1&quot;&gt;Tong Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kveton_B/0/1/0/all/0/1&quot;&gt;Branislav Kveton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wen_Z/0/1/0/all/0/1&quot;&gt;Zheng Wen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mengshoel_O/0/1/0/all/0/1&quot;&gt;Ole J. Mengshoel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bui_H/0/1/0/all/0/1&quot;&gt;Hung Bui&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.06952">
<title>Asynchronous Decentralized Parallel Stochastic Gradient Descent. (arXiv:1710.06952v2 [math.OC] UPDATED)</title>
<link>http://arxiv.org/abs/1710.06952</link>
<description rdf:parseType="Literal">&lt;p&gt;Most commonly used distributed machine learning systems are either
synchronous or centralized asynchronous. Synchronous algorithms like
AllReduce-SGD perform poorly in a heterogeneous environment, while asynchronous
algorithms using a parameter server suffer from 1) communication bottleneck at
parameter servers when workers are many, and 2) significantly worse convergence
when the traffic to parameter server is congested. Can we design an algorithm
that is robust in a heterogeneous environment, while being communication
efficient and maintaining the best-possible convergence rate? In this paper, we
propose an asynchronous decentralized stochastic gradient decent algorithm
(AD-PSGD) satisfying all above expectations. Our theoretical analysis shows
AD-PSGD converges at the optimal $O(1/\sqrt{K})$ rate as SGD and has linear
speedup w.r.t. number of workers. Empirically, AD-PSGD outperforms the best of
decentralized parallel SGD (D-PSGD), asynchronous parallel SGD (A-PSGD), and
standard data parallel SGD (AllReduce-SGD), often by orders of magnitude in a
heterogeneous environment. When training ResNet-50 on ImageNet with up to 128
GPUs, AD-PSGD converges (w.r.t epochs) similarly to the AllReduce-SGD, but each
epoch can be up to 4-8X faster than its synchronous counterparts in a
network-sharing HPC environment. To the best of our knowledge, AD-PSGD is the
first asynchronous algorithm that achieves a similar epoch-wise convergence
rate as AllReduce-SGD, at an over 100-GPU scale.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Lian_X/0/1/0/all/0/1&quot;&gt;Xiangru Lian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Zhang_W/0/1/0/all/0/1&quot;&gt;Wei Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Zhang_C/0/1/0/all/0/1&quot;&gt;Ce Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Ji Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.10370">
<title>Topology Adaptive Graph Convolutional Networks. (arXiv:1710.10370v5 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1710.10370</link>
<description rdf:parseType="Literal">&lt;p&gt;Spectral graph convolutional neural networks (CNNs) require approximation to
the convolution to alleviate the computational complexity, resulting in
performance loss. This paper proposes the topology adaptive graph convolutional
network (TAGCN), a novel graph convolutional network defined in the vertex
domain. We provide a systematic way to design a set of fixed-size learnable
filters to perform convolutions on graphs. The topologies of these filters are
adaptive to the topology of the graph when they scan the graph to perform
convolution. The TAGCN not only inherits the properties of convolutions in CNN
for grid-structured data, but it is also consistent with convolution as defined
in graph signal processing. Since no approximation to the convolution is
needed, TAGCN exhibits better performance than existing spectral CNNs on a
number of data sets and is also computationally simpler than other recent
methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Du_J/0/1/0/all/0/1&quot;&gt;Jian Du&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1&quot;&gt;Shanghang Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_G/0/1/0/all/0/1&quot;&gt;Guanhang Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moura_J/0/1/0/all/0/1&quot;&gt;Jose M. F. Moura&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kar_S/0/1/0/all/0/1&quot;&gt;Soummya Kar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.11595">
<title>Partial Least Squares Random Forest Ensemble Regression as a Soft Sensor. (arXiv:1710.11595v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1710.11595</link>
<description rdf:parseType="Literal">&lt;p&gt;Five simple small sample size, soft sensor methodologies with two update
conditions were compared on two experimentally-obtained datasets and one
simulated dataset. The soft sensors investigated were based on: moving window
partial least squares regression (and a recursive variant), moving window
random forest regression, the mean moving window of $y$, and a novel random
forest partial least squares regression ensemble (RF-PLS). It was found that,
on two of the datasets studied, very small window sizes (4 samples) led to the
lowest prediction errors for all of the moving window methods studied. On the
majority of datasets studied the RF-PLS method offered the lowest
one-step-ahead prediction errors compared to those of the other methods, and
demonstrated greater stability at larger time delays than moving window PLS
alone. We found that the RF-PLS method most adequately modeled the datasets
that did not feature purely monotonic increases in property values, and
performed more poorly than moving window PLS on monotonically increasing $y$
data. Other data dependent findings are presented and discussed.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kneale_C/0/1/0/all/0/1&quot;&gt;Casey Kneale&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Brown_S/0/1/0/all/0/1&quot;&gt;Steven Brown&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.02294">
<title>Learning Tree-based Deep Model for Recommender Systems. (arXiv:1801.02294v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1801.02294</link>
<description rdf:parseType="Literal">&lt;p&gt;Model-based methods for recommender systems have been studied to provide more
precise results. In systems with large corpus, the amount of calculation for
learnt model to predict all user-item pairs&apos; preferences is tremendous, which
makes the model difficult to be directly employed in recommendation candidate
generation stage. To overcome the calculation barrier, models like matrix
factorization can resort to inner product form (i.e., use the inner product of
user and item&apos;s latent factors as the preference) and index like hashing to
perform efficient approximate k-nearest neighbor search. However, other more
expressive interaction forms between user and item features, e.g., interactions
through advanced deep neural networks, are still prevented from large corpus
recommendation because of the amount of calculation.
&lt;/p&gt;
&lt;p&gt;In this paper, we focus on the problem how arbitrary advanced models can be
introduced to generate recommendations from large corpus. We propose a novel
tree-based method which can provide logarithmic complexity prediction w.r.t.
corpus size with more expressive deep neural networks. The main idea of
tree-based model is to predict user interests coarse-to-fine, by traversing
tree nodes top-down and making decisions whether to pick up each node to user.
Furthermore, we show that the tree structure can also be jointly learnt towards
better compatible with user interests&apos; distribution, to facilitate both
training and prediction. Experiments in two large-scale real-world datasets
indicate that the proposed model significantly outperforms traditional methods.
And online A/B test results in Taobao display advertising platform prove the
effectiveness of the tree-based deep model in production.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhu_H/0/1/0/all/0/1&quot;&gt;Han Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhang_P/0/1/0/all/0/1&quot;&gt;Pengye Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Li_G/0/1/0/all/0/1&quot;&gt;Guozheng Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+He_J/0/1/0/all/0/1&quot;&gt;Jie He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Li_H/0/1/0/all/0/1&quot;&gt;Han Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gai_K/0/1/0/all/0/1&quot;&gt;Kun Gai&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.00662">
<title>Dual Memory Neural Computer for Asynchronous Two-view Sequential Learning. (arXiv:1802.00662v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1802.00662</link>
<description rdf:parseType="Literal">&lt;p&gt;One of the core tasks in multi-view learning is to capture relations among
views. For sequential data, the relations not only span across views, but also
extend throughout the view length to form long-term intra-view and inter-view
interactions. In this paper, we present a new memory augmented neural network
model that aims to model these complex interactions between two asynchronous
sequential views. Our model uses two encoders for reading from and writing to
two external memories for encoding input views. The intra-view interactions and
the long-term dependencies are captured by the use of memories during this
encoding process. There are two modes of memory accessing in our system:
late-fusion and early-fusion, corresponding to late and early inter-view
interactions. In the late-fusion mode, the two memories are separated,
containing only view-specific contents. In the early-fusion mode, the two
memories share the same addressing space, allowing cross-memory accessing. In
both cases, the knowledge from the memories will be combined by a decoder to
make predictions over the output space. The resulting dual memory neural
computer is demonstrated on a comprehensive set of experiments, including a
synthetic task of summing two sequences and the tasks of drug prescription and
disease progression in healthcare. The results demonstrate competitive
performance over both traditional algorithms and deep learning methods designed
for multi-view problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Le_H/0/1/0/all/0/1&quot;&gt;Hung Le&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tran_T/0/1/0/all/0/1&quot;&gt;Truyen Tran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Venkatesh_S/0/1/0/all/0/1&quot;&gt;Svetha Venkatesh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.01448">
<title>Hardening Deep Neural Networks via Adversarial Model Cascades. (arXiv:1802.01448v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1802.01448</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep neural networks (DNNs) have been shown to be vulnerable to adversarial
examples - malicious inputs which are crafted by the adversary to induce the
trained model to produce erroneous outputs. This vulnerability has inspired a
lot of research on how to secure neural networks against these kinds of
attacks. Although existing techniques increase the robustness of the models
against white-box attacks, they are ineffective against black-box attacks. To
address the challenge of black-box adversarial attacks, we propose Adversarial
Model Cascades (AMC); a framework that performs better than existing
state-of-the-art defenses, in both black-box and white-box settings and is easy
to integrate into existing set-ups. Our approach trains a cascade of models by
injecting images crafted from an already defended proxy model, to improve the
robustness of the target models against adversarial attacks. AMC provides an
increase in robustness of 8.175% &amp;amp; 7.115% for white-box attacks and 30.218% &amp;amp;
4.717% for black-box, in comparison to defensive distillation and adversarial
hardening. To the best of our knowledge, ours is the first work that aims to
provide a defense mechanism that can improve robustness against multiple
adversarial attacks simultaneously.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vijaykeerthy_D/0/1/0/all/0/1&quot;&gt;Deepak Vijaykeerthy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Suri_A/0/1/0/all/0/1&quot;&gt;Anshuman Suri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mehta_S/0/1/0/all/0/1&quot;&gt;Sameep Mehta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kumaraguru_P/0/1/0/all/0/1&quot;&gt;Ponnurangam Kumaraguru&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.02664">
<title>Geometry Score: A Method For Comparing Generative Adversarial Networks. (arXiv:1802.02664v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1802.02664</link>
<description rdf:parseType="Literal">&lt;p&gt;One of the biggest challenges in the research of generative adversarial
networks (GANs) is assessing the quality of generated samples and detecting
various levels of mode collapse. In this work, we construct a novel measure of
performance of a GAN by comparing geometrical properties of the underlying data
manifold and the generated one, which provides both qualitative and
quantitative means for evaluation. Our algorithm can be applied to datasets of
an arbitrary nature and is not limited to visual data. We test the obtained
metric on various real-life models and datasets and demonstrate that our method
provides new insights into properties of GANs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khrulkov_V/0/1/0/all/0/1&quot;&gt;Valentin Khrulkov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oseledets_I/0/1/0/all/0/1&quot;&gt;Ivan Oseledets&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.03911">
<title>Stochastic Learning of Nonstationary Kernels for Natural Language Modeling. (arXiv:1801.03911v2 [cs.CL] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1801.03911</link>
<description rdf:parseType="Literal">&lt;p&gt;Natural language processing often involves computations with semantic or
syntactic graphs to facilitate sophisticated reasoning based on structural
relationships. While convolution kernels provide a powerful tool for comparing
graph structure based on node (word) level relationships, they are difficult to
customize and can be computationally expensive. We propose a generalization of
convolution kernels, with a nonstationary model, for better expressibility of
natural languages in supervised settings. For a scalable learning of the
parameters introduced with our model, we propose a novel algorithm that
leverages stochastic sampling on k-nearest neighbor graphs, along with
approximations based on locality-sensitive hashing. We demonstrate the
advantages of our approach on a challenging real-world (structured inference)
problem of automatically extracting biological models from the text of
scientific papers.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garg_S/0/1/0/all/0/1&quot;&gt;Sahil Garg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Steeg_G/0/1/0/all/0/1&quot;&gt;Greg Ver Steeg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Galstyan_A/0/1/0/all/0/1&quot;&gt;Aram Galstyan&lt;/a&gt;</dc:creator>
</item></rdf:RDF>