<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Good papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Good Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-08-02T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.00508"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.00597"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.00733"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.00737"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.06964"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.00590"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.00677"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.11130"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.00911"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.00525"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.00529"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.00783"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.00878"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.00931"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1705.06400"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1708.08157"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1808.00508">
<title>Neural Arithmetic Logic Units. (arXiv:1808.00508v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1808.00508</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural networks can learn to represent and manipulate numerical information,
but they seldom generalize well outside of the range of numerical values
encountered during training. To encourage more systematic numerical
extrapolation, we propose an architecture that represents numerical quantities
as linear activations which are manipulated using primitive arithmetic
operators, controlled by learned gates. We call this module a neural arithmetic
logic unit (NALU), by analogy to the arithmetic logic unit in traditional
processors. Experiments show that NALU-enhanced neural networks can learn to
track time, perform arithmetic over images of numbers, translate numerical
language into real-valued scalars, execute computer code, and count objects in
images. In contrast to conventional architectures, we obtain substantially
better generalization both inside and outside of the range of numerical values
encountered during training, often extrapolating orders of magnitude beyond
trained numerical ranges.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Trask_A/0/1/0/all/0/1&quot;&gt;Andrew Trask&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hill_F/0/1/0/all/0/1&quot;&gt;Felix Hill&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Reed_S/0/1/0/all/0/1&quot;&gt;Scott Reed&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rae_J/0/1/0/all/0/1&quot;&gt;Jack Rae&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dyer_C/0/1/0/all/0/1&quot;&gt;Chris Dyer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Blunsom_P/0/1/0/all/0/1&quot;&gt;Phil Blunsom&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.00597">
<title>Saccadic Predictive Vision Model with a Fovea. (arXiv:1808.00597v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1808.00597</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a model that emulates saccades, the rapid movements of the eye,
called the Error Saccade Model, based on the prediction error of the Predictive
Vision Model (PVM). The Error Saccade Model carries out movements of the
model&apos;s field of view to regions with the highest prediction error. Comparisons
of the Error Saccade Model on Predictive Vision Models with and without a fovea
show that a fovea-like structure in the input level of the PVM improves the
Error Saccade Model&apos;s ability to pursue detailed objects in its view. We
hypothesize that the improvement is due to poorer resolution in the periphery
causing higher prediction error when an object passes, triggering a saccade to
the next location.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hazoglou_M/0/1/0/all/0/1&quot;&gt;Michael Hazoglou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hylton_T/0/1/0/all/0/1&quot;&gt;Todd Hylton&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.00733">
<title>Approximate Probabilistic Neural Networks with Gated Threshold Logic. (arXiv:1808.00733v1 [cs.ET])</title>
<link>http://arxiv.org/abs/1808.00733</link>
<description rdf:parseType="Literal">&lt;p&gt;Probabilistic Neural Network (PNN) is a feed-forward artificial neural
network developed for solving classification problems. This paper proposes a
hardware implementation of an approximated PNN (APNN) algorithm in which the
conventional exponential function of the PNN is replaced with gated threshold
logic. The weights of the PNN are approximated using a memristive crossbar
architecture. In particular, the proposed algorithm performs normalization of
the training weights, and quantization into 16 levels which significantly
reduces the complexity of the circuit.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Krestinskaya_O/0/1/0/all/0/1&quot;&gt;Olga Krestinskaya&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+James_A/0/1/0/all/0/1&quot;&gt;Alex Pappachen James&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.00737">
<title>Binary Weighted Memristive Analog Deep Neural Network for Near-Sensor Edge Processing. (arXiv:1808.00737v1 [cs.ET])</title>
<link>http://arxiv.org/abs/1808.00737</link>
<description rdf:parseType="Literal">&lt;p&gt;The memristive crossbar aims to implement analog weighted neural network,
however, the realistic implementation of such crossbar arrays is not possible
due to limited switching states of memristive devices. In this work, we propose
the design of an analog deep neural network with binary weight update through
backpropagation algorithm using binary state memristive devices. We show that
such networks can be successfully used for image processing task and has the
advantage of lower power consumption and small on-chip area in comparison with
digital counterparts. The proposed network was benchmarked for MNIST
handwritten digits recognition achieving an accuracy of approximately 90%.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Krestinskaya_O/0/1/0/all/0/1&quot;&gt;Olga Krestinskaya&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+James_A/0/1/0/all/0/1&quot;&gt;Alex Pappachen James&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.06964">
<title>GNAS: A Greedy Neural Architecture Search Method for Multi-Attribute Learning. (arXiv:1804.06964v2 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1804.06964</link>
<description rdf:parseType="Literal">&lt;p&gt;A key problem in deep multi-attribute learning is to effectively discover the
inter-attribute correlation structures. Typically, the conventional deep
multi-attribute learning approaches follow the pipeline of manually designing
the network architectures based on task-specific expertise prior knowledge and
careful network tunings, leading to the inflexibility for various complicated
scenarios in practice. Motivated by addressing this problem, we propose an
efficient greedy neural architecture search approach (GNAS) to automatically
discover the optimal tree-like deep architecture for multi-attribute learning.
In a greedy manner, GNAS divides the optimization of global architecture into
the optimizations of individual connections step by step. By iteratively
updating the local architectures, the global tree-like architecture gets
converged where the bottom layers are shared across relevant attributes and the
branches in top layers more encode attribute-specific features. Experiments on
three benchmark multi-attribute datasets show the effectiveness and compactness
of neural architectures derived by GNAS, and also demonstrate the efficiency of
GNAS in searching neural architectures.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1&quot;&gt;Siyu Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xi Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_Z/0/1/0/all/0/1&quot;&gt;Zhi-Qi Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1&quot;&gt;Zhongfei Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hauptmann_A/0/1/0/all/0/1&quot;&gt;Alexander Hauptmann&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.00590">
<title>MLCapsule: Guarded Offline Deployment of Machine Learning as a Service. (arXiv:1808.00590v1 [cs.CR])</title>
<link>http://arxiv.org/abs/1808.00590</link>
<description rdf:parseType="Literal">&lt;p&gt;With the widespread use of machine learning (ML) techniques, ML as a service
has become increasingly popular. In this setting, an ML model resides on a
server and users can query the model with their data via an API. However, if
the user&apos;s input is sensitive, sending it to the server is not an option.
Equally, the service provider does not want to share the model by sending it to
the client for protecting its intellectual property and pay-per-query business
model. In this paper, we propose MLCapsule, a guarded offline deployment of
machine learning as a service. MLCapsule executes the machine learning model
locally on the user&apos;s client and therefore the data never leaves the client.
Meanwhile, MLCapsule offers the service provider the same level of control and
security of its model as the commonly used server-side execution. In addition,
MLCapsule is applicable to offline applications that require local execution.
Beyond protecting against direct model access, we demonstrate that MLCapsule
allows for implementing defenses against advanced attacks on machine learning
models such as model stealing/reverse engineering and membership inference.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hanzlik_L/0/1/0/all/0/1&quot;&gt;Lucjan Hanzlik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yang Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grosse_K/0/1/0/all/0/1&quot;&gt;Kathrin Grosse&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Salem_A/0/1/0/all/0/1&quot;&gt;Ahmed Salem&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Augustin_M/0/1/0/all/0/1&quot;&gt;Max Augustin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Backes_M/0/1/0/all/0/1&quot;&gt;Michael Backes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fritz_M/0/1/0/all/0/1&quot;&gt;Mario Fritz&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.00677">
<title>Double Supervised Network with Attention Mechanism for Scene Text Recognition. (arXiv:1808.00677v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1808.00677</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we propose Double Supervised Network with Attention Mechanism
(DSAN), a novel end-to-end trainable framework for scene text recognition. It
incorporates one text attention module during feature extraction which enforces
the model to focus on text regions and the whole framework is supervised by two
branches. One supervision branch comes from context-level modelling and another
comes from one extra supervision enhancement branch which aims at tackling
inexplicit semantic information at character level. These two supervisions can
benefit each other and yield better performance. The proposed approach can
recognize text in arbitrary length and does not need any predefined lexicon.
Our method outperforms the current state-of-the-art methods on three text
recognition benchmarks: IIIT5K, ICDAR2013 and SVT reaching accuracy 88.6%,
92.3% and 84.1% respectively which suggests the effectiveness of the proposed
method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1&quot;&gt;Yuting Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1&quot;&gt;Zheng Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dai_Y/0/1/0/all/0/1&quot;&gt;Yuchen Dai&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.11130">
<title>Clustering Meets Implicit Generative Models. (arXiv:1804.11130v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1804.11130</link>
<description rdf:parseType="Literal">&lt;p&gt;Clustering is a cornerstone of unsupervised learning which can be thought as
disentangling the multiple generative mechanisms underlying the data. In this
paper we introduce an algorithmic framework to train mixtures of implicit
generative models which we instantiate for variational autoencoders. Relying on
an additional set of discriminators, we propose a competitive procedure in
which the models only need to approximate the portion of the data distribution
from which they can produce realistic samples. As a byproduct, each model is
simpler to train, and a clustering interpretation arises naturally from the
partitioning of the training points among the models. We empirically show that
our approach splits the training distribution in a reasonable way and increases
the quality of the generated samples.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Locatello_F/0/1/0/all/0/1&quot;&gt;Francesco Locatello&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vincent_D/0/1/0/all/0/1&quot;&gt;Damien Vincent&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tolstikhin_I/0/1/0/all/0/1&quot;&gt;Ilya Tolstikhin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ratsch_G/0/1/0/all/0/1&quot;&gt;Gunnar R&amp;#xe4;tsch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gelly_S/0/1/0/all/0/1&quot;&gt;Sylvain Gelly&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Scholkopf_B/0/1/0/all/0/1&quot;&gt;Bernhard Sch&amp;#xf6;lkopf&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.00911">
<title>Semantic Segmentation with Scarce Data. (arXiv:1807.00911v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1807.00911</link>
<description rdf:parseType="Literal">&lt;p&gt;Semantic segmentation is a challenging vision problem that usually
necessitates the collection of large amounts of finely annotated data, which is
often quite expensive to obtain. Coarsely annotated data provides an
interesting alternative as it is usually substantially more cheap. In this
work, we present a method to leverage coarsely annotated data along with fine
supervision to produce better segmentation results than would be obtained when
training using only the fine data. We validate our approach by simulating a
scarce data setting with less than 200 low resolution images from the
Cityscapes dataset and show that our method substantially outperforms solely
training on the fine annotation data by an average of 15.52% mIoU and
outperforms the coarse mask by an average of 5.28% mIoU.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Katsman_I/0/1/0/all/0/1&quot;&gt;Isay Katsman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tripathi_R/0/1/0/all/0/1&quot;&gt;Rohun Tripathi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Veit_A/0/1/0/all/0/1&quot;&gt;Andreas Veit&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Belongie_S/0/1/0/all/0/1&quot;&gt;Serge Belongie&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.00525">
<title>The impact of imbalanced training data on machine learning for author name disambiguation. (arXiv:1808.00525v1 [cs.IR])</title>
<link>http://arxiv.org/abs/1808.00525</link>
<description rdf:parseType="Literal">&lt;p&gt;In supervised machine learning for author name disambiguation, negative
training data are often dominantly larger than positive training data. This
paper examines how the ratios of negative to positive training data can affect
the performance of machine learning algorithms to disambiguate author names in
bibliographic records. On multiple labeled datasets, three classifiers -
Logistic Regression, Na\&quot;ive Bayes, and Random Forest - are trained through
representative features such as coauthor names, and title words extracted from
the same training data but with various positive-negative training data ratios.
Results show that increasing negative training data can improve disambiguation
performance but with a few percent of performance gains and sometimes degrade
it. Logistic and Na\&quot;ive Bayes learn optimal disambiguation models even with a
base ratio (1:1) of positive and negative training data. Also, the performance
improvement by Random Forest tends to quickly saturate roughly after 1:10 ~
1:15. These findings imply that contrary to the common practice using all
training data, name disambiguation algorithms can be trained using part of
negative training data without degrading much disambiguation performance while
increasing computational efficiency. This study calls for more attention from
author name disambiguation scholars to methods for machine learning from
imbalanced data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1&quot;&gt;Jinseok Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1&quot;&gt;Jenna Kim&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.00529">
<title>Open Category Detection with PAC Guarantees. (arXiv:1808.00529v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1808.00529</link>
<description rdf:parseType="Literal">&lt;p&gt;Open category detection is the problem of detecting &quot;alien&quot; test instances
that belong to categories or classes that were not present in the training
data. In many applications, reliably detecting such aliens is central to
ensuring the safety and accuracy of test set predictions. Unfortunately, there
are no algorithms that provide theoretical guarantees on their ability to
detect aliens under general assumptions. Further, while there are algorithms
for open category detection, there are few empirical results that directly
report alien detection rates. Thus, there are significant theoretical and
empirical gaps in our understanding of open category detection. In this paper,
we take a step toward addressing this gap by studying a simple, but
practically-relevant variant of open category detection. In our setting, we are
provided with a &quot;clean&quot; training set that contains only the target categories
of interest and an unlabeled &quot;contaminated&quot; training set that contains a
fraction $\alpha$ of alien examples. Under the assumption that we know an upper
bound on $\alpha$, we develop an algorithm with PAC-style guarantees on the
alien detection rate, while aiming to minimize false alarms. Empirical results
on synthetic and standard benchmark datasets demonstrate the regimes in which
the algorithm can be effective and provide a baseline for further advancements.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1&quot;&gt;Si Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garrepalli_R/0/1/0/all/0/1&quot;&gt;Risheek Garrepalli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dietterich_T/0/1/0/all/0/1&quot;&gt;Thomas G. Dietterich&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fern_A/0/1/0/all/0/1&quot;&gt;Alan Fern&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hendrycks_D/0/1/0/all/0/1&quot;&gt;Dan Hendrycks&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.00783">
<title>The Quest for the Golden Activation Function. (arXiv:1808.00783v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1808.00783</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep Neural Networks have been shown to be beneficial for a variety of tasks,
in particular allowing for end-to-end learning and reducing the requirement for
manual design decisions. However, still many parameters have to be chosen in
advance, also raising the need to optimize them. One important, but often
ignored system parameter is the selection of a proper activation function.
Thus, in this paper we target to demonstrate the importance of activation
functions in general and show that for different tasks different activation
functions might be meaningful. To avoid the manual design or selection of
activation functions, we build on the idea of genetic algorithms to learn the
best activation function for a given task. In addition, we introduce two new
activation functions, ELiSH and HardELiSH, which can easily be incorporated in
our framework. In this way, we demonstrate for three different image
classification benchmarks that different activation functions are learned, also
showing improved results compared to typically used baselines.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Basirat_M/0/1/0/all/0/1&quot;&gt;Mina Basirat&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roth_P/0/1/0/all/0/1&quot;&gt;Peter M. Roth&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.00878">
<title>Supervised classification for object identification in urban areas using satellite imagery. (arXiv:1808.00878v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1808.00878</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents a useful method to achieve classification in satellite
imagery. The approach is based on pixel level study employing various features
such as correlation, homogeneity, energy and contrast. In this study gray-scale
images are used for training the classification model. For supervised
classification, two classification techniques are employed namely the Support
Vector Machine (SVM) and the Naive Bayes. With textural features used for
gray-scale images, Naive Bayes performs better with an overall accuracy of 76%
compared to 68% achieved by SVM. The computational time is evaluated while
performing the experiment with two different window sizes i.e., 50x50 and
70x70. The required computational time on a single image is found to be 27
seconds for a window size of 70x70 and 45 seconds for a window size of 50x50.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ali_H/0/1/0/all/0/1&quot;&gt;Hazrat Ali&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Awan_A/0/1/0/all/0/1&quot;&gt;Adnan Ali Awan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khan_S/0/1/0/all/0/1&quot;&gt;Sanaullah Khan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shafique_O/0/1/0/all/0/1&quot;&gt;Omer Shafique&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rahman_A/0/1/0/all/0/1&quot;&gt;Atiq ur Rahman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khan_S/0/1/0/all/0/1&quot;&gt;Shahid Khan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.00931">
<title>Machine Learning of Space-Fractional Differential Equations. (arXiv:1808.00931v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1808.00931</link>
<description rdf:parseType="Literal">&lt;p&gt;Data-driven discovery of &quot;hidden physics&quot; -- i.e., machine learning of
differential equation models underlying observed data -- has recently been
approached by embedding the discovery problem into a Gaussian Process
regression of spatial data, treating and discovering unknown equation
parameters as hyperparameters of a modified &quot;physics informed&quot; Gaussian Process
kernel. This kernel includes the parametrized differential operators applied to
a prior covariance kernel. We extend this framework to linear space-fractional
differential equations. The methodology is compatible with a wide variety of
fractional operators in $\mathbb{R}^d$ and stationary covariance kernels,
including the Matern class, and can optimize the Matern parameter during
training. We provide a user-friendly and feasible way to perform fractional
derivatives of kernels, via a unified set of d-dimensional Fourier integral
formulas amenable to generalized Gauss-Laguerre quadrature.
&lt;/p&gt;
&lt;p&gt;The implementation of fractional derivatives has several benefits. First, it
allows for discovering fractional-order PDEs for systems characterized by heavy
tails or anomalous diffusion, bypassing the analytical difficulty of fractional
calculus. Data sets exhibiting such features are of increasing prevalence in
physical and financial domains. Second, a single fractional-order archetype
allows for a derivative of arbitrary order to be learned, with the order itself
being a parameter in the regression. This is advantageous even when used for
discovering integer-order equations; the user is not required to assume a
&quot;dictionary&quot; of derivatives of various orders, and directly controls the
parsimony of the models being discovered. We illustrate on several examples,
including fractional-order interpolation of advection-diffusion and modeling
relative stock performance in the S&amp;amp;P 500 with alpha-stable motion via a
fractional diffusion equation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gulian_M/0/1/0/all/0/1&quot;&gt;Mamikon Gulian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Raissi_M/0/1/0/all/0/1&quot;&gt;Maziar Raissi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Perdikaris_P/0/1/0/all/0/1&quot;&gt;Paris Perdikaris&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Karniadakis_G/0/1/0/all/0/1&quot;&gt;George Karniadakis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1705.06400">
<title>Learning a bidirectional mapping between human whole-body motion and natural language using deep recurrent neural networks. (arXiv:1705.06400v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1705.06400</link>
<description rdf:parseType="Literal">&lt;p&gt;Linking human whole-body motion and natural language is of great interest for
the generation of semantic representations of observed human behaviors as well
as for the generation of robot behaviors based on natural language input. While
there has been a large body of research in this area, most approaches that
exist today require a symbolic representation of motions (e.g. in the form of
motion primitives), which have to be defined a-priori or require complex
segmentation algorithms. In contrast, recent advances in the field of neural
networks and especially deep learning have demonstrated that sub-symbolic
representations that can be learned end-to-end usually outperform more
traditional approaches, for applications such as machine translation. In this
paper we propose a generative model that learns a bidirectional mapping between
human whole-body motion and natural language using deep recurrent neural
networks (RNNs) and sequence-to-sequence learning. Our approach does not
require any segmentation or manual feature engineering and learns a distributed
representation, which is shared for all motions and descriptions. We evaluate
our approach on 2,846 human whole-body motions and 6,187 natural language
descriptions thereof from the KIT Motion-Language Dataset. Our results clearly
demonstrate the effectiveness of the proposed model: We show that our model
generates a wide variety of realistic motions only from descriptions thereof in
form of a single sentence. Conversely, our model is also capable of generating
correct and detailed natural language descriptions from human motions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Plappert_M/0/1/0/all/0/1&quot;&gt;Matthias Plappert&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mandery_C/0/1/0/all/0/1&quot;&gt;Christian Mandery&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Asfour_T/0/1/0/all/0/1&quot;&gt;Tamim Asfour&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1708.08157">
<title>Characteristic and Universal Tensor Product Kernels. (arXiv:1708.08157v4 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1708.08157</link>
<description rdf:parseType="Literal">&lt;p&gt;Maximum mean discrepancy (MMD), also called energy distance or N-distance in
statistics and Hilbert-Schmidt independence criterion (HSIC), specifically
distance covariance in statistics, are among the most popular and successful
approaches to quantify the difference and independence of random variables,
respectively. Thanks to their kernel-based foundations, MMD and HSIC are
applicable on a wide variety of domains. Despite their tremendous success,
quite little is known about when HSIC characterizes independence and when MMD
with tensor product kernel can discriminate probability distributions. In this
paper, we answer these questions by studying various notions of characteristic
property of the tensor product kernel.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Szabo_Z/0/1/0/all/0/1&quot;&gt;Zoltan Szabo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sriperumbudur_B/0/1/0/all/0/1&quot;&gt;Bharath K. Sriperumbudur&lt;/a&gt;</dc:creator>
</item></rdf:RDF>