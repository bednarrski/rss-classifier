<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Good papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Good Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-09-12T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.04166"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.04423"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.04497"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.04520"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.04113"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.04136"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.04234"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.04258"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.04280"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.04288"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.04313"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.04318"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.04359"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.04362"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.04399"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.04506"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.04525"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.04560"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.06538"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.04110"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.04157"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.04176"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.04270"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.04281"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.04432"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.04445"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.04474"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.04564"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.02548"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.04015"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.01531"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.01478"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.02270"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.03474"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1809.04166">
<title>Leabra7: a Python package for modeling recurrent, biologically-realistic neural networks. (arXiv:1809.04166v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1809.04166</link>
<description rdf:parseType="Literal">&lt;p&gt;Emergent is a software package that uses the AdEx neural dynamics model and
LEABRA learning algorithm to simulate and train arbitrary recurrent neural
network architectures in a biologically-realistic manner. We present Leabra7, a
complementary Python library that implements these same algorithms. Leabra7 is
developed and distributed using modern software development principles, and
integrates tightly with Python&apos;s scientific stack. We demonstrate recurrent
Leabra7 networks using traditional pattern-association tasks and a standard
machine learning task, classifying the IRIS dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Greenidge_C/0/1/0/all/0/1&quot;&gt;C. Daniel Greenidge&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Miller_N/0/1/0/all/0/1&quot;&gt;Noam Miller&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Norman_K/0/1/0/all/0/1&quot;&gt;Kenneth A. Norman&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.04423">
<title>Re-purposing Compact Neuronal Circuit Policies to Govern Reinforcement Learning Tasks. (arXiv:1809.04423v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1809.04423</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose an effective method for creating interpretable control agents, by
\textit{re-purposing} the function of a biological neural circuit model, to
govern simulated and real world reinforcement learning (RL) test-beds. Inspired
by the structure of the nervous system of the soil-worm, \emph{C. elegans}, we
introduce \emph{Neuronal Circuit Policies} (NCPs) as a novel recurrent neural
network instance with liquid time-constants, universal approximation
capabilities and interpretable dynamics. We theoretically show that they can
approximate any finite simulation time of a given continuous n-dimensional
dynamical system, with $n$ output units and some hidden units. We model
instances of the policies and learn their synaptic and neuronal parameters to
control standard RL tasks and demonstrate its application for autonomous
parking of a real rover robot on a pre-defined trajectory. For reconfiguration
of the \emph{purpose} of the neural circuit, we adopt a search-based RL
algorithm. We show that our neuronal circuit policies perform as good as deep
neural network policies with the advantage of realizing interpretable dynamics
at the cell-level. We theoretically find bounds for the time-varying dynamics
of the circuits, and introduce a novel way to reason about networks&apos; dynamics.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hasani_R/0/1/0/all/0/1&quot;&gt;Ramin M. Hasani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lechner_M/0/1/0/all/0/1&quot;&gt;Mathias Lechner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Amini_A/0/1/0/all/0/1&quot;&gt;Alexander Amini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rus_D/0/1/0/all/0/1&quot;&gt;Daniela Rus&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grosu_R/0/1/0/all/0/1&quot;&gt;Radu Grosu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.04497">
<title>Hyperprior Induced Unsupervised Disentanglement of Latent Representations. (arXiv:1809.04497v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1809.04497</link>
<description rdf:parseType="Literal">&lt;p&gt;We address the problem of unsupervised disentanglement of latent
representations learnt via deep generative models. In contrast to current
approaches that operate on the evidence lower bound (ELBO), we argue that
statistical independence in the latent space of VAEs can be enforced in a
principled hierarchical Bayesian manner. To this effect, we augment the
standard VAE with an inverse-Wishart (IW) prior on the covariance matrix of the
latent code. By tuning the IW parameters, we are able to encourage (or
discourage) independence in the learnt latent dimensions. Extensive
experimental results on a range of datasets (2DShapes, 3DChairs, 3DFaces and
CelebA) show our approach to outperform the $\beta$-VAE and is competitive with
the state-of-the-art FactorVAE. Our approach achieves significantly better
disentanglement and reconstruction on a new dataset (CorrelatedEllipses) which
introduces correlations between the factors of variation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ansari_A/0/1/0/all/0/1&quot;&gt;Abdul Fatir Ansari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Soh_H/0/1/0/all/0/1&quot;&gt;Harold Soh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.04520">
<title>Genetic algorithms with DNN-based trainable crossover as an example of partial specialization of general search. (arXiv:1809.04520v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1809.04520</link>
<description rdf:parseType="Literal">&lt;p&gt;Universal induction relies on some general search procedure that is doomed to
be inefficient. One possibility to achieve both generality and efficiency is to
specialize this procedure w.r.t. any given narrow task. However, complete
specialization that implies direct mapping from the task parameters to
solutions (discriminative models) without search is not always possible. In
this paper, partial specialization of general search is considered in the form
of genetic algorithms (GAs) with a specialized crossover operator. We perform a
feasibility study of this idea implementing such an operator in the form of a
deep feedforward neural network. GAs with trainable crossover operators are
compared with the result of complete specialization, which is also represented
as a deep neural network. Experimental results show that specialized GAs can be
more efficient than both general GAs and discriminative models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Potapov_A/0/1/0/all/0/1&quot;&gt;Alexey Potapov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rodionov_S/0/1/0/all/0/1&quot;&gt;Sergey Rodionov&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.04113">
<title>Detecting egregious responses in neural sequence-to-sequence models. (arXiv:1809.04113v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1809.04113</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work, we attempt to answer a critical question: whether there exists
some input sequence that will cause a well-trained discrete-space neural
network sequence-to-sequence (seq2seq) model to generate egregious outputs
(aggressive, malicious, attacking, etc.). And if such inputs exist, how to find
them efficiently. We adopt an empirical methodology, in which we first create
lists of egregious outputs, and then design a discrete optimization algorithm
to find input sequences that will generate them. Moreover, the optimization
algorithm is enhanced for large vocabulary search and constrained to search for
input sequences that are likely to appear in real-world settings. In our
experiments, we apply this approach to a dialogue response generation model for
two real-world dialogue datasets: Ubuntu and Switchboard, testing whether the
model can generate malicious responses. We demonstrate that given the trigger
inputs our algorithm finds, a significant number of malicious sentences are
assigned a large probability by the model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_T/0/1/0/all/0/1&quot;&gt;Tianxing He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Glass_J/0/1/0/all/0/1&quot;&gt;James Glass&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.04136">
<title>Randomized Wagering Mechanisms. (arXiv:1809.04136v1 [cs.GT])</title>
<link>http://arxiv.org/abs/1809.04136</link>
<description rdf:parseType="Literal">&lt;p&gt;Wagering mechanisms are one-shot betting mechanisms that elicit agents&apos;
predictions of an event. For deterministic wagering mechanisms, an existing
impossibility result has shown incompatibility of some desirable theoretical
properties. In particular, Pareto optimality (no profitable side bet before
allocation) can not be achieved together with weak incentive compatibility,
weak budget balance and individual rationality. In this paper, we expand the
design space of wagering mechanisms to allow randomization and ask whether
there are randomized wagering mechanisms that can achieve all previously
considered desirable properties, including Pareto optimality. We answer this
question positively with two classes of randomized wagering mechanisms: i) one
simple randomized lottery-type implementation of existing deterministic
wagering mechanisms, and ii) another family of simple and randomized wagering
mechanisms which we call surrogate wagering mechanisms, which are robust to
noisy ground truth. This family of mechanisms builds on the idea of learning
with noisy labels (Natarajan et al. 2013) as well as a recent extension of this
idea to the information elicitation without verification setting (Liu and Chen
2018). We show that a broad family of randomized wagering mechanisms satisfy
all desirable theoretical properties.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yiling Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+liu_Y/0/1/0/all/0/1&quot;&gt;Yang liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Juntao Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.04234">
<title>TGE-PS: Text-driven Graph Embedding with Pairs Sampling. (arXiv:1809.04234v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1809.04234</link>
<description rdf:parseType="Literal">&lt;p&gt;In graphs with rich text information, constructing expressive graph
representations requires incorporating textual information with structural
information. Graph embedding models are becoming more and more popular in
representing graphs, yet they are faced with two issues: sampling efficiency
and text utilization. Through analyzing existing models, we find their training
objectives are composed of pairwise proximities, and there are large amounts of
redundant node pairs in Random Walk-based methods. Besides, inferring graph
structures directly from texts (also known as zero-shot scenario) is a problem
that requires higher text utilization. To solve these problems, we propose a
novel Text-driven Graph Embedding with Pairs Sampling (TGE-PS) framework.
TGE-PS uses Pairs Sampling (PS) to generate training samples which reduces ~99%
training samples and is competitive compared to Random Walk. TGE-PS uses
Text-driven Graph Embedding (TGE) which adopts word- and character-level
embeddings to generate node embeddings. We evaluate TGE-PS on several
real-world datasets, and experimental results demonstrate that TGE-PS produces
state-of-the-art results in traditional and zero-shot link prediction tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1&quot;&gt;Liheng Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qu_Y/0/1/0/all/0/1&quot;&gt;Yanru Qu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zhenghui Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qiu_L/0/1/0/all/0/1&quot;&gt;Lin Qiu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1&quot;&gt;Weinan Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1&quot;&gt;Ken Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1&quot;&gt;Shaodian Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1&quot;&gt;Yong Yu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.04258">
<title>An Ontology-Based Artificial Intelligence Model for Medicine Side-Effect Prediction: Taking Traditional Chinese Medicine as An Example. (arXiv:1809.04258v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1809.04258</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work, an ontology-based model for AI-assisted medicine side-effect
(SE) prediction is developed, where three main components, including the drug
model, the treatment model, and the AI-assisted prediction model, of proposed
model are presented. To validate the proposed model, an ANN structure is
established and trained by two hundred and forty-two TCM prescriptions that are
gathered and classified from the most famous ancient TCM book and more than one
thousand SE reports, in which two ontology-based attributions, hot and cold,
are simply introduced to evaluate whether the prediction will cause a SE or
not. The results preliminarily reveal that it is a relationship between the
ontology-based attributions and the corresponding indicator that can be learnt
by AI for predicting the SE, which suggests the proposed model has a potential
in AI-assisted SE prediction. However, it should be noted that, the proposed
model highly depends on the sufficient clinic data, and hereby, much deeper
exploration is important for enhancing the accuracy of the prediction.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zeheng Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_K/0/1/0/all/0/1&quot;&gt;Kun Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cao_J/0/1/0/all/0/1&quot;&gt;Jun Cao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1&quot;&gt;Yuanzhe Yao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1&quot;&gt;Liang Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_R/0/1/0/all/0/1&quot;&gt;Runyu Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1&quot;&gt;Zhiyuan Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1&quot;&gt;Jing Yan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.04280">
<title>Safe Navigation with Human Instructions in Complex Scenes. (arXiv:1809.04280v1 [cs.RO])</title>
<link>http://arxiv.org/abs/1809.04280</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we present a robotic navigation algorithm with natural
language interfaces, which enables a robot to safely walk through a changing
environment with moving persons by following human instructions such as &quot;go to
the restaurant and keep away from people&quot;. We first classify human instructions
into three types: the goal, the constraints, and uninformative phrases. Next,
we provide grounding for the extracted goal and constraint items in a dynamic
manner along with the navigation process, to deal with the target objects that
are too far away for sensor observation and the appearance of moving obstacles
like humans. In particular, for a goal phrase (e.g., &quot;go to the restaurant&quot;),
we ground it to a location in a predefined semantic map and treat it as a goal
for a global motion planner, which plans a collision-free path in the workspace
for the robot to follow. For a constraint phrase (e.g., &quot;keep away from
people&quot;), we dynamically add the corresponding constraint into a local planner
by adjusting the values of a local costmap according to the results returned by
the object detection module. The updated costmap is then used to compute a
local collision avoidance control for the safe navigation of the robot. By
combining natural language processing, motion planning, and computer vision,
our developed system is demonstrated to be able to successfully follow natural
language navigation instructions to achieve navigation tasks in both simulated
and real-world scenarios. Videos are available at
https://sites.google.com/view/snhi
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_Z/0/1/0/all/0/1&quot;&gt;Zhe Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pan_J/0/1/0/all/0/1&quot;&gt;Jia Pan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fan_T/0/1/0/all/0/1&quot;&gt;Tingxiang Fan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_R/0/1/0/all/0/1&quot;&gt;Ruigang Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Manocha_D/0/1/0/all/0/1&quot;&gt;Dinesh Manocha&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.04288">
<title>Deep Learning Based Multi-modal Addressee Recognition in Visual Scenes with Utterances. (arXiv:1809.04288v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1809.04288</link>
<description rdf:parseType="Literal">&lt;p&gt;With the widespread use of intelligent systems, such as smart speakers,
addressee recognition has become a concern in human-computer interaction, as
more and more people expect such systems to understand complicated social
scenes, including those outdoors, in cafeterias, and hospitals. Because
previous studies typically focused only on pre-specified tasks with limited
conversational situations such as controlling smart homes, we created a mock
dataset called Addressee Recognition in Visual Scenes with Utterances (ARVSU)
that contains a vast body of image variations in visual scenes with an
annotated utterance and a corresponding addressee for each scenario. We also
propose a multi-modal deep-learning-based model that takes different human
cues, specifically eye gazes and transcripts of an utterance corpus, into
account to predict the conversational addressee from a specific speaker&apos;s view
in various real-life conversational scenarios. To the best of our knowledge, we
are the first to introduce an end-to-end deep learning model that combines
vision and transcripts of utterance for addressee recognition. As a result, our
study suggests that future addressee recognition can reach the ability to
understand human intention in many social situations previously unexplored, and
our modality dataset is a first step in promoting research in this field.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Le_T/0/1/0/all/0/1&quot;&gt;Thao Minh Le&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shimizu_N/0/1/0/all/0/1&quot;&gt;Nobuyuki Shimizu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Miyazaki_T/0/1/0/all/0/1&quot;&gt;Takashi Miyazaki&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shinoda_K/0/1/0/all/0/1&quot;&gt;Koichi Shinoda&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.04313">
<title>Chinese Poetry Generation with a Salient-Clue Mechanism. (arXiv:1809.04313v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1809.04313</link>
<description rdf:parseType="Literal">&lt;p&gt;As a precious part of the human cultural heritage, Chinese poetry has
influenced people for generations. Automatic poetry composition is a challenge
for AI. In recent years, significant progress has been made in this area
benefiting from the development of neural networks. However, the coherence in
meaning, theme or even artistic conception for a generated poem as a whole
still remains a big problem. In this paper, we propose a novel Salient-Clue
mechanism for Chinese poetry generation. Different from previous work which
tried to exploit all the context information, our model selects the most
salient characters automatically from each so-far generated line to gradually
form a salient clue, which is utilized to guide successive poem generation
process so as to eliminate interruptions and improve coherence. Besides, our
model can be flexibly extended to control the generated poem in different
aspects, for example, poetry style, which further enhances the coherence.
Experimental results show that our model is very effective, outperforming three
strong baselines.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yi_X/0/1/0/all/0/1&quot;&gt;Xiaoyuan Yi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1&quot;&gt;Ruoyu Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1&quot;&gt;Maosong Sun&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.04318">
<title>Neural Melody Composition from Lyrics. (arXiv:1809.04318v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1809.04318</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we study a novel task that learns to compose music from
natural language. Given the lyrics as input, we propose a melody composition
model that generates lyrics-conditional melody as well as the exact alignment
between the generated melody and the given lyrics simultaneously. More
specifically, we develop the melody composition model based on the
sequence-to-sequence framework. It consists of two neural encoders to encode
the current lyrics and the context melody respectively, and a hierarchical
decoder to jointly produce musical notes and the corresponding alignment.
Experimental results on lyrics-melody pairs of 18,451 pop songs demonstrate the
effectiveness of our proposed methods. In addition, we apply a singing voice
synthesizer software to synthesize the &quot;singing&quot; of the lyrics and melodies for
human evaluation. Results indicate that our generated melodies are more
melodious and tuneful compared with the baseline method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bao_H/0/1/0/all/0/1&quot;&gt;Hangbo Bao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1&quot;&gt;Shaohan Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wei_F/0/1/0/all/0/1&quot;&gt;Furu Wei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cui_L/0/1/0/all/0/1&quot;&gt;Lei Cui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1&quot;&gt;Yu Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tan_C/0/1/0/all/0/1&quot;&gt;Chuanqi Tan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Piao_S/0/1/0/all/0/1&quot;&gt;Songhao Piao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1&quot;&gt;Ming Zhou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.04359">
<title>Training Deep Neural Networks with Different Datasets In-the-wild: The Emotion Recognition Paradigm. (arXiv:1809.04359v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1809.04359</link>
<description rdf:parseType="Literal">&lt;p&gt;A novel procedure is presented in this paper, for training a deep
convolutional and recurrent neural network, taking into account both the
available training data set and some information extracted from similar
networks trained with other relevant data sets. This information is included in
an extended loss function used for the network training, so that the network
can have an improved performance when applied to the other data sets, without
forgetting the learned knowledge from the original data set. Facial expression
and emotion recognition in-the-wild is the test bed application that is used to
demonstrate the improved performance achieved using the proposed approach. In
this framework, we provide an experimental study on categorical emotion
recognition using datasets from a very recent related emotion recognition
challenge.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kollias_D/0/1/0/all/0/1&quot;&gt;Dimitrios Kollias&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zafeiriou_S/0/1/0/all/0/1&quot;&gt;Stefanos Zafeiriou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.04362">
<title>The Convergence of Iterative Delegations in Liquid Democracy. (arXiv:1809.04362v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1809.04362</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we study liquid democracy, a collective decision making
paradigm which lies between direct and representative democracy. One main
feature of liquid democracy is that voters can delegate their votes in a
transitive manner such that: A delegates to B and B delegates to C leads to A
delegates to C. We study the stability (w.r.t. voters preferences) of the
delegation process in liquid democracy and model it as a game in which the
players are the voters and the strategies are possible delegations. This
game-theoretic model enables us to answer several questions on the equilibria
of this process under general preferences and several types of restricted
preferences (e.g., single-peaked preferences).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Escoffier_B/0/1/0/all/0/1&quot;&gt;Bruno Escoffier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gilbert_H/0/1/0/all/0/1&quot;&gt;Hugo Gilbert&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pass_Lanneau_A/0/1/0/all/0/1&quot;&gt;Ad&amp;#xe8;le Pass-Lanneau&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.04399">
<title>Artificial Intelligence for the Public Sector: Opportunities and challenges of cross-sector collaboration. (arXiv:1809.04399v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1809.04399</link>
<description rdf:parseType="Literal">&lt;p&gt;Public sector organisations are increasingly interested in using data science
and artificial intelligence capabilities to deliver policy and generate
efficiencies in high uncertainty environments. The long-term success of data
science and AI in the public sector relies on effectively embedding it into
delivery solutions for policy implementation. However, governments cannot do
this integration of AI into public service delivery on their own. The UK
Government Industrial Strategy is clear that delivering on the AI grand
challenge requires collaboration between universities and public and private
sectors. This cross-sectoral collaborative approach is the norm in applied AI
centres of excellence around the world. Despite their popularity, cross-sector
collaborations entail serious management challenges that hinder their success.
In this article we discuss the opportunities and challenges from AI for public
sector. Finally, we propose a series of strategies to successfully manage these
cross-sectoral collaborations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mikhaylov_S/0/1/0/all/0/1&quot;&gt;Slava Jankin Mikhaylov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Esteve_M/0/1/0/all/0/1&quot;&gt;Marc Esteve&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Campion_A/0/1/0/all/0/1&quot;&gt;Averill Campion&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.04506">
<title>Combined Reinforcement Learning via Abstract Representations. (arXiv:1809.04506v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1809.04506</link>
<description rdf:parseType="Literal">&lt;p&gt;In the quest for efficient and robust reinforcement learning methods, both
model-free and model-based approaches offer advantages. In this paper we
propose a new way of explicitly bridging both approaches via a shared
low-dimensional learned encoding of the environment, meant to capture
summarizing abstractions. We show that the modularity brought by this approach
leads to good generalization while being computationally efficient, with
planning happening in a smaller latent state space. In addition, this approach
recovers a sufficient low-dimensional representation of the environment, which
opens up new strategies for interpretable AI, exploration and transfer
learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Francois_Lavet_V/0/1/0/all/0/1&quot;&gt;Vincent Fran&amp;#xe7;ois-Lavet&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bengio_Y/0/1/0/all/0/1&quot;&gt;Yoshua Bengio&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Precup_D/0/1/0/all/0/1&quot;&gt;Doina Precup&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pineau_J/0/1/0/all/0/1&quot;&gt;Joelle Pineau&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.04525">
<title>Label-less Learning for Traffic Control in an Edge Network. (arXiv:1809.04525v1 [cs.NI])</title>
<link>http://arxiv.org/abs/1809.04525</link>
<description rdf:parseType="Literal">&lt;p&gt;With the development of intelligent applications (e.g., self-driving,
real-time emotion recognition, etc), there are higher requirements for the
cloud intelligence. However, cloud intelligence depends on the multi-modal data
collected by user equipments (UEs). Due to the limited capacity of network
bandwidth, offloading all data generated from the UEs to the remote cloud is
impractical. Thus, in this article, we consider the challenging issue of
achieving a certain level of cloud intelligence while reducing network traffic.
In order to solve this problem, we design a traffic control algorithm based on
label-less learning on the edge cloud, which is dubbed as LLTC. By the use of
the limited computing and storage resources at edge cloud, LLTC evaluates the
value of data, which will be offloaded. Specifically, we first give a statement
of the problem and the system architecture. Then, we design the LLTC algorithm
in detail. Finally, we set up the system testbed. Experimental results show
that the proposed LLTC can guarantee the required cloud intelligence while
minimizing the amount of data transmission.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1&quot;&gt;Min Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hao_Y/0/1/0/all/0/1&quot;&gt;Yixue Hao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_K/0/1/0/all/0/1&quot;&gt;Kai Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yuan_Z/0/1/0/all/0/1&quot;&gt;Zhiyong Yuan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_L/0/1/0/all/0/1&quot;&gt;Long Hu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.04560">
<title>Game-Based Video-Context Dialogue. (arXiv:1809.04560v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1809.04560</link>
<description rdf:parseType="Literal">&lt;p&gt;Current dialogue systems focus more on textual and speech context knowledge
and are usually based on two speakers. Some recent work has investigated static
image-based dialogue. However, several real-world human interactions also
involve dynamic visual context (similar to videos) as well as dialogue
exchanges among multiple speakers. To move closer towards such multimodal
conversational skills and visually-situated applications, we introduce a new
video-context, many-speaker dialogue dataset based on live-broadcast soccer
game videos and chats from Twitch.tv. This challenging testbed allows us to
develop visually-grounded dialogue models that should generate relevant
temporal and spatial event language from the live video, while also being
relevant to the chat history. For strong baselines, we also present several
discriminative and generative models, e.g., based on tridirectional attention
flow (TriDAF). We evaluate these models via retrieval ranking-recall, automatic
phrase-matching metrics, as well as human evaluation studies. We also present
dataset analyses, model ablations, and visualizations to understand the
contribution of different modalities and model components.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pasunuru_R/0/1/0/all/0/1&quot;&gt;Ramakanth Pasunuru&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bansal_M/0/1/0/all/0/1&quot;&gt;Mohit Bansal&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.06538">
<title>Pseudo-Feature Generation for Imbalanced Data Analysis in Deep Learning. (arXiv:1807.06538v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1807.06538</link>
<description rdf:parseType="Literal">&lt;p&gt;We generate pseudo-features by multivariate probability distributions
obtained from feature maps in a low layer of trained deep neural networks.
Then, we virtually augment the data of minor classes by the pseudo-features in
order to overcome imbalanced data problems. Because all the wild data are
imbalanced, the proposed method has the possibility to improve the ability of
DNN in a broad range of problems
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Konno_T/0/1/0/all/0/1&quot;&gt;Tomohiko Konno&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Iwazume_M/0/1/0/all/0/1&quot;&gt;Michiaki Iwazume&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.04110">
<title>Joint Embedding of Meta-Path and Meta-Graph for Heterogeneous Information Networks. (arXiv:1809.04110v1 [cs.SI])</title>
<link>http://arxiv.org/abs/1809.04110</link>
<description rdf:parseType="Literal">&lt;p&gt;Meta-graph is currently the most powerful tool for similarity search on
heterogeneous information networks,where a meta-graph is a composition of
meta-paths that captures the complex structural information. However, current
relevance computing based on meta-graph only considers the complex structural
information, but ignores its embedded meta-paths information. To address this
problem, we proposeMEta-GrAph-based network embedding models, called MEGA and
MEGA++, respectively. The MEGA model uses normalized relevance or similarity
measures that are derived from a meta-graph and its embedded meta-paths between
nodes simultaneously, and then leverages tensor decomposition method to perform
node embedding. The MEGA++ further facilitates the use of coupled tensor-matrix
decomposition method to obtain a joint embedding for nodes, which
simultaneously considers the hidden relations of all meta information of a
meta-graph.Extensive experiments on two real datasets demonstrate thatMEGA and
MEGA++ are more effective than state-of-the-art approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_L/0/1/0/all/0/1&quot;&gt;Lichao Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_L/0/1/0/all/0/1&quot;&gt;Lifang He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1&quot;&gt;Zhipeng Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cao_B/0/1/0/all/0/1&quot;&gt;Bokai Cao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xia_C/0/1/0/all/0/1&quot;&gt;Congying Xia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wei_X/0/1/0/all/0/1&quot;&gt;Xiaokai Wei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1&quot;&gt;Philip S. Yu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.04157">
<title>Heated-Up Softmax Embedding. (arXiv:1809.04157v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1809.04157</link>
<description rdf:parseType="Literal">&lt;p&gt;Metric learning aims at learning a distance which is consistent with the
semantic meaning of the samples. The problem is generally solved by learning an
embedding for each sample such that the embeddings of samples of the same
category are compact while the embeddings of samples of different categories
are spread-out in the feature space. We study the features extracted from the
second last layer of a deep neural network based classifier trained with the
cross entropy loss on top of the softmax layer. We show that training
classifiers with different temperature values of softmax function leads to
features with different levels of compactness. Leveraging these insights, we
propose a &quot;heating-up&quot; strategy to train a classifier with increasing
temperatures, leading the corresponding embeddings to achieve state-of-the-art
performance on a variety of metric learning benchmarks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xu Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_F/0/1/0/all/0/1&quot;&gt;Felix Xinnan Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Karaman_S/0/1/0/all/0/1&quot;&gt;Svebor Karaman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1&quot;&gt;Wei Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chang_S/0/1/0/all/0/1&quot;&gt;Shih-Fu Chang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.04176">
<title>Phaseless Subspace Tracking. (arXiv:1809.04176v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1809.04176</link>
<description rdf:parseType="Literal">&lt;p&gt;This work takes the first steps towards solving the &quot;phaseless subspace
tracking&quot; (PST) problem. PST involves recovering a time sequence of signals (or
images) from phaseless linear projections of each signal under the following
structural assumption: the signal sequence is generated from a much lower
dimensional subspace (than the signal dimension) and this subspace can change
over time, albeit gradually. It can be simply understood as a dynamic
(time-varying subspace) extension of the low-rank phase retrieval problem
studied in recent work.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nayer_S/0/1/0/all/0/1&quot;&gt;Seyedehsara Nayer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vaswani_N/0/1/0/all/0/1&quot;&gt;Namrata Vaswani&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.04270">
<title>Rapid Training of Very Large Ensembles of Diverse Neural Networks. (arXiv:1809.04270v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1809.04270</link>
<description rdf:parseType="Literal">&lt;p&gt;Ensembles of deep neural networks with diverse architectures significantly
improve generalization accuracy. However, training such ensembles requires a
large amount of computational resources and time as every network in the
ensemble has to be separately trained. In practice, this restricts the number
of different deep neural network architectures that can be included within an
ensemble. We propose a new approach to address this problem. Our approach
captures the structural similarity between members of a neural network ensemble
and train it only once. Subsequently, this knowledge is transferred to all
members of the ensemble using function-preserving transformations. Then, these
ensemble networks converge significantly faster as compared to training from
scratch. We show through experiments on CIFAR-10, CIFAR-100, and SVHN data sets
that our approach can train large and diverse ensembles of deep neural networks
achieving comparable accuracy to existing approaches in a fraction of their
training time. In particular, our approach trains an ensemble of $100$ variants
of deep neural networks with diverse architectures up to $6 \times$ faster as
compared to existing approaches. This improvement in training cost grows
linearly with the size of the ensemble.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wasay_A/0/1/0/all/0/1&quot;&gt;Abdul Wasay&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liao_Y/0/1/0/all/0/1&quot;&gt;Yuze Liao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Idreos_S/0/1/0/all/0/1&quot;&gt;Stratos Idreos&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.04281">
<title>An Improved Relative Self-Attention Mechanism for Transformer with Application to Music Generation. (arXiv:1809.04281v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1809.04281</link>
<description rdf:parseType="Literal">&lt;p&gt;Music relies heavily on self-reference to build structure and meaning. We
explore the Transformer architecture (Vaswani et al., 2017) as a generative
model for music, as self-attention has shown compelling results on tasks that
require long-term structure such as Wikipedia summary generation (Liu et al,
2018). However, timing information is critical for polyphonic music, and
Transformer does not explicitly model absolute or relative timing in its
structure. To address this challenge, Shaw et al. (2018) introduced relative
position representations to self-attention to improve machine translation.
However, the formulation was not scalable to longer sequences. We propose an
improved formulation which reduces the memory requirements of the relative
position computation from $O(l^2d)$ to $O(ld)$, making it possible to train
much longer sequences and achieve faster convergence. In experiments on
symbolic music we find that relative self-attention substantially improves
sample quality for unconditioned generation and is able to generate sequences
of lengths longer than those from the training set. When primed with an initial
sequence, the model generates continuations that develop the prime coherently
and exhibit long-term structure. Relative self-attention can be instrumental in
capturing richer relationships within a musical piece.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_C/0/1/0/all/0/1&quot;&gt;Cheng-Zhi Anna Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vaswani_A/0/1/0/all/0/1&quot;&gt;Ashish Vaswani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Uszkoreit_J/0/1/0/all/0/1&quot;&gt;Jakob Uszkoreit&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shazeer_N/0/1/0/all/0/1&quot;&gt;Noam Shazeer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hawthorne_C/0/1/0/all/0/1&quot;&gt;Curtis Hawthorne&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dai_A/0/1/0/all/0/1&quot;&gt;Andrew M. Dai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hoffman_M/0/1/0/all/0/1&quot;&gt;Matthew D. Hoffman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Eck_D/0/1/0/all/0/1&quot;&gt;Douglas Eck&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.04432">
<title>Addressing the Fundamental Tension of PCGML with Discriminative Learning. (arXiv:1809.04432v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1809.04432</link>
<description rdf:parseType="Literal">&lt;p&gt;Procedural content generation via machine learning (PCGML) is typically
framed as the task of fitting a generative model to full-scale examples of a
desired content distribution. This approach presents a fundamental tension: the
more design effort expended to produce detailed training examples for shaping a
generator, the lower the return on investment from applying PCGML in the first
place. In response, we propose the use of discriminative models (which capture
the validity of a design rather the distribution of the content) trained on
positive and negative examples. Through a modest modification of
WaveFunctionCollapse, a commercially-adopted PCG approach that we characterize
as using elementary machine learning, we demonstrate a new mode of control for
learning-based generators. We demonstrate how an artist might craft a focused
set of additional positive and negative examples by critique of the generator&apos;s
previous outputs. This interaction mode bridges PCGML with mixed-initiative
design assistance tools by working with a machine to define a space of valid
designs rather than just one new design.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Karth_I/0/1/0/all/0/1&quot;&gt;Isaac Karth&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Smith_A/0/1/0/all/0/1&quot;&gt;Adam M. Smith&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.04445">
<title>Structured and Unstructured Outlier Identification for Robust PCA: A Non iterative, Parameter free Algorithm. (arXiv:1809.04445v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1809.04445</link>
<description rdf:parseType="Literal">&lt;p&gt;Robust PCA, the problem of PCA in the presence of outliers has been
extensively investigated in the last few years. Here we focus on Robust PCA in
the outlier model where each column of the data matrix is either an inlier or
an outlier. Most of the existing methods for this model assumes either the
knowledge of the dimension of the lower dimensional subspace or the fraction of
outliers in the system. However in many applications knowledge of these
parameters is not available. Motivated by this we propose a parameter free
outlier identification method for robust PCA which a) does not require the
knowledge of outlier fraction, b) does not require the knowledge of the
dimension of the underlying subspace, c) is computationally simple and fast d)
can handle structured and unstructured outliers. Further, analytical guarantees
are derived for outlier identification and the performance of the algorithm is
compared with the existing state of the art methods in both real and synthetic
data for various outlier structures.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Menon_V/0/1/0/all/0/1&quot;&gt;Vishnu Menon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kalyani_S/0/1/0/all/0/1&quot;&gt;Sheetal Kalyani&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.04474">
<title>Multi-task Deep Reinforcement Learning with PopArt. (arXiv:1809.04474v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1809.04474</link>
<description rdf:parseType="Literal">&lt;p&gt;The reinforcement learning community has made great strides in designing
algorithms capable of exceeding human performance on specific tasks. These
algorithms are mostly trained one task at the time, each new task requiring to
train a brand new agent instance. This means the learning algorithm is general,
but each solution is not; each agent can only solve the one task it was trained
on. In this work, we study the problem of learning to master not one but
multiple sequential-decision tasks at once. A general issue in multi-task
learning is that a balance must be found between the needs of multiple tasks
competing for the limited resources of a single learning system. Many learning
algorithms can get distracted by certain tasks in the set of tasks to solve.
Such tasks appear more salient to the learning process, for instance because of
the density or magnitude of the in-task rewards. This causes the algorithm to
focus on those salient tasks at the expense of generality. We propose to
automatically adapt the contribution of each task to the agent&apos;s updates, so
that all tasks have a similar impact on the learning dynamics. This resulted in
state of the art performance on learning to play all games in a set of 57
diverse Atari games. Excitingly, our method learned a single trained policy -
with a single set of weights - that exceeds median human performance. To our
knowledge, this was the first time a single agent surpassed human-level
performance on this multi-task domain. The same approach also demonstrated
state of the art performance on a set of 30 tasks in the 3D reinforcement
learning platform DeepMind Lab.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hessel_M/0/1/0/all/0/1&quot;&gt;Matteo Hessel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Soyer_H/0/1/0/all/0/1&quot;&gt;Hubert Soyer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Espeholt_L/0/1/0/all/0/1&quot;&gt;Lasse Espeholt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Czarnecki_W/0/1/0/all/0/1&quot;&gt;Wojciech Czarnecki&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schmitt_S/0/1/0/all/0/1&quot;&gt;Simon Schmitt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hasselt_H/0/1/0/all/0/1&quot;&gt;Hado van Hasselt&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.04564">
<title>On the Stability and Convergence of Stochastic Gradient Descent with Momentum. (arXiv:1809.04564v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1809.04564</link>
<description rdf:parseType="Literal">&lt;p&gt;While momentum-based methods, in conjunction with the stochastic gradient
descent, are widely used when training machine learning models, there is little
theoretical understanding on the generalization error of such methods. In
practice, the momentum parameter is often chosen in a heuristic fashion with
little theoretical guidance. In the first part of this paper, for the case of
general loss functions, we analyze a modified momentum-based update rule, i.e.,
the method of early momentum, and develop an upper-bound on the generalization
error using the framework of algorithmic stability. Our results show that
machine learning models can be trained for multiple epochs of this method while
their generalization errors are bounded. We also study the convergence of the
method of early momentum by establishing an upper-bound on the expected norm of
the gradient. In the second part of the paper, we focus on the case of strongly
convex loss functions and the classical heavy-ball momentum update rule. We use
the framework of algorithmic stability to provide an upper-bound on the
generalization error of the stochastic gradient method with momentum. We also
develop an upper-bound on the expected true risk, in terms of the number of
training steps, the size of the training set, and the momentum parameter.
Experimental evaluations verify the consistency between the numerical results
and our theoretical bounds and the effectiveness of the method of early
momentum for the case of non-convex loss functions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ramezani_Kebrya_A/0/1/0/all/0/1&quot;&gt;Ali Ramezani-Kebrya&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khisti_A/0/1/0/all/0/1&quot;&gt;Ashish Khisti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_B/0/1/0/all/0/1&quot;&gt;Ben Liang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.02548">
<title>Predicting Hurricane Trajectories using a Recurrent Neural Network. (arXiv:1802.02548v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1802.02548</link>
<description rdf:parseType="Literal">&lt;p&gt;Hurricanes are cyclones circulating about a defined center whose closed wind
speeds exceed 75 mph originating over tropical and subtropical waters. At
landfall, hurricanes can result in severe disasters. The accuracy of predicting
their trajectory paths is critical to reduce economic loss and save human
lives. Given the complexity and nonlinearity of weather data, a recurrent
neural network (RNN) could be beneficial in modeling hurricane behavior. We
propose the application of a fully connected RNN to predict the trajectory of
hurricanes. We employed the RNN over a fine grid to reduce typical truncation
errors. We utilized their latitude, longitude, wind speed, and pressure
publicly provided by the National Hurricane Center (NHC) to predict the
trajectory of a hurricane at 6-hour intervals. Results show that this proposed
technique is competitive to methods currently employed by the NHC and can
predict up to approximately 120 hours of hurricane path.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alemany_S/0/1/0/all/0/1&quot;&gt;Sheila Alemany&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Beltran_J/0/1/0/all/0/1&quot;&gt;Jonathan Beltran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Perez_A/0/1/0/all/0/1&quot;&gt;Adrian Perez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ganzfried_S/0/1/0/all/0/1&quot;&gt;Sam Ganzfried&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.04015">
<title>On catastrophic forgetting and mode collapse in Generative Adversarial Networks. (arXiv:1807.04015v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1807.04015</link>
<description rdf:parseType="Literal">&lt;p&gt;Generative Adversarial Networks (GAN) are one of the most prominent tools for
learning complicated distributions. However, problems such as mode collapse and
catastrophic forgetting, prevent GAN from learning the target distribution.
These problems are usually studied independently from each other. In this
paper, we show that both problems are present in GAN and their combined effect
makes the training of GAN unstable. We also show that methods such as gradient
penalties and momentum based optimizers can improve the stability of GAN by
effectively preventing these problems from happening. Finally, we study a
mechanism for mode collapse to occur and propagate in feedforward neural
networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Thanh_Tung_H/0/1/0/all/0/1&quot;&gt;Hoang Thanh-Tung&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tran_T/0/1/0/all/0/1&quot;&gt;Truyen Tran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Venkatesh_S/0/1/0/all/0/1&quot;&gt;Svetha Venkatesh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.01531">
<title>Global Convergence to the Equilibrium of GANs using Variational Inequalities. (arXiv:1808.01531v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1808.01531</link>
<description rdf:parseType="Literal">&lt;p&gt;In optimization, the negative gradient of a function denotes the direction of
steepest descent. Furthermore, traveling in any direction orthogonal to the
gradient maintains the value of the function. In this work, we show that these
orthogonal directions that are ignored by gradient descent can be critical in
equilibrium problems. Equilibrium problems have drawn heightened attention in
machine learning due to the emergence of the Generative Adversarial Network
(GAN). We use the framework of Variational Inequalities to analyze popular
training algorithms for a fundamental GAN variant: the Wasserstein
Linear-Quadratic GAN. We show that the steepest descent direction causes
divergence from the equilibrium, and guaranteed convergence to the equilibrium
is achieved through following a particular orthogonal direction. We call this
successful technique Crossing-the-Curl, named for its mathematical derivation
as well as its intuition: identify the game&apos;s axis of rotation and move
&quot;across&quot; space in the direction towards smaller &quot;curling&quot;.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gemp_I/0/1/0/all/0/1&quot;&gt;Ian Gemp&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mahadevan_S/0/1/0/all/0/1&quot;&gt;Sridhar Mahadevan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.01478">
<title>Weakly-Supervised Neural Text Classification. (arXiv:1809.01478v2 [cs.IR] UPDATED)</title>
<link>http://arxiv.org/abs/1809.01478</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep neural networks are gaining increasing popularity for the classic text
classification task, due to their strong expressive power and less requirement
for feature engineering. Despite such attractiveness, neural text
classification models suffer from the lack of training data in many real-world
applications. Although many semi-supervised and weakly-supervised text
classification models exist, they cannot be easily applied to deep neural
models and meanwhile support limited supervision types. In this paper, we
propose a weakly-supervised method that addresses the lack of training data in
neural text classification. Our method consists of two modules: (1) a
pseudo-document generator that leverages seed information to generate
pseudo-labeled documents for model pre-training, and (2) a self-training module
that bootstraps on real unlabeled data for model refinement. Our method has the
flexibility to handle different types of weak supervision and can be easily
integrated into existing deep neural models for text classification. We have
performed extensive experiments on three real-world datasets from different
domains. The results demonstrate that our proposed method achieves inspiring
performance without requiring excessive training data and outperforms baseline
methods significantly.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meng_Y/0/1/0/all/0/1&quot;&gt;Yu Meng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_J/0/1/0/all/0/1&quot;&gt;Jiaming Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1&quot;&gt;Chao Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1&quot;&gt;Jiawei Han&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.02270">
<title>Learning Embeddings of Directed Networks with Text-Associated Nodes---with Applications in Software Package Dependency Networks. (arXiv:1809.02270v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1809.02270</link>
<description rdf:parseType="Literal">&lt;p&gt;A network embedding consists of a vector representation for each node in the
network. Network embeddings have shown their usefulness in node classification
and visualization in many real-world application domains, such as social
networks and web networks. While directed networks with text associated with
each node, such as citation networks and software package dependency networks,
are commonplace, to the best of our knowledge, their embeddings have not been
specifically studied. In this paper, we create PCTADW-1 and PCTADW-2, two
algorithms based on NNs that learn embeddings of directed networks with text
associated with each node. We create two new labeled directed networks with
text-associated node: The package dependency networks in two popular GNU/Linux
distributions, Debian and Fedora. We experimentally demonstrate that the
embeddings produced by our NNs resulted in node classification with better
quality than those of various baselines on these two networks. We observe that
there exist systematic presence of analogies (similar to those in word
embeddings) in the network embeddings of software package dependency networks.
To the best of our knowledge, this is the first time that such a systematic
presence of analogies is observed in network and document embeddings. This may
potentially open up a new venue for better understanding networks and documents
algorithmically using their embeddings as well as for better human
understanding of network and document embeddings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhong_S/0/1/0/all/0/1&quot;&gt;Shudan Zhong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1&quot;&gt;Hong Xu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.03474">
<title>Multi-party Poisoning through Generalized $p$-Tampering. (arXiv:1809.03474v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1809.03474</link>
<description rdf:parseType="Literal">&lt;p&gt;In a poisoning attack against a learning algorithm, an adversary tampers with
a fraction of the training data $T$ with the goal of increasing the
classification error of the constructed hypothesis/model over the final test
distribution. In the distributed setting, $T$ might be gathered gradually from
$m$ data providers $P_1,\dots,P_m$ who generate and submit their shares of $T$
in an online way.
&lt;/p&gt;
&lt;p&gt;In this work, we initiate a formal study of $(k,p)$-poisoning attacks in
which an adversary controls $k\in[n]$ of the parties, and even for each
corrupted party $P_i$, the adversary submits some poisoned data $T&apos;_i$ on
behalf of $P_i$ that is still &quot;$(1-p)$-close&quot; to the correct data $T_i$ (e.g.,
$1-p$ fraction of $T&apos;_i$ is still honestly generated). For $k=m$, this model
becomes the traditional notion of poisoning, and for $p=1$ it coincides with
the standard notion of corruption in multi-party computation.
&lt;/p&gt;
&lt;p&gt;We prove that if there is an initial constant error for the generated
hypothesis $h$, there is always a $(k,p)$-poisoning attacker who can decrease
the confidence of $h$ (to have a small error), or alternatively increase the
error of $h$, by $\Omega(p \cdot k/m)$. Our attacks can be implemented in
polynomial time given samples from the correct data, and they use no wrong
labels if the original distributions are not noisy.
&lt;/p&gt;
&lt;p&gt;At a technical level, we prove a general lemma about biasing bounded
functions $f(x_1,\dots,x_n)\in[0,1]$ through an attack model in which each
block $x_i$ might be controlled by an adversary with marginal probability $p$
in an online way. When the probabilities are independent, this coincides with
the model of $p$-tampering attacks, thus we call our model generalized
$p$-tampering. We prove the power of such attacks by incorporating ideas from
the context of coin-flipping attacks into the $p$-tampering model and
generalize the results in both of these areas.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mahloujifar_S/0/1/0/all/0/1&quot;&gt;Saeed Mahloujifar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mahmoody_M/0/1/0/all/0/1&quot;&gt;Mohammad Mahmoody&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mohammed_A/0/1/0/all/0/1&quot;&gt;Ameer Mohammed&lt;/a&gt;</dc:creator>
</item></rdf:RDF>