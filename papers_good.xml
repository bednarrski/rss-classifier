<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Good papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Good Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-02-26T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08842"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09405"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1703.02065"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1703.10722"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1705.09792"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1705.10694"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1707.03141"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.10355"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.06761"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08831"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08864"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08946"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08969"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09030"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09059"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09089"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09442"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09465"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1611.06589"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.11041"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.11342"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.07163"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05883"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06024"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08717"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08768"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08770"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08780"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08888"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08908"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09031"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09069"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09128"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09197"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09381"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09386"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09484"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1703.04782"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1705.04977"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1708.02582"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1708.06742"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.00489"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.07436"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.10130"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.07384"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08530"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1802.08842">
<title>Back to Basics: Benchmarking Canonical Evolution Strategies for Playing Atari. (arXiv:1802.08842v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1802.08842</link>
<description rdf:parseType="Literal">&lt;p&gt;Evolution Strategies (ES) have recently been demonstrated to be a viable
alternative to reinforcement learning (RL) algorithms on a set of challenging
deep RL problems, including Atari games and MuJoCo humanoid locomotion
benchmarks. While the ES algorithms in that work belonged to the specialized
class of natural evolution strategies (which resemble approximate gradient RL
algorithms, such as REINFORCE), we demonstrate that even a very basic canonical
ES algorithm can achieve the same or even better performance. This success of a
basic ES algorithm suggests that the state-of-the-art can be advanced further
by integrating the many advances made in the field of ES in the last decades.
&lt;/p&gt;
&lt;p&gt;We also demonstrate qualitatively that ES algorithms have very different
performance characteristics than traditional RL algorithms: on some games, they
learn to exploit the environment and perform much better while on others they
can get stuck in suboptimal local minima. Combining their strengths with those
of traditional RL algorithms is therefore likely to lead to new advances in the
state of the art.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chrabaszcz_P/0/1/0/all/0/1&quot;&gt;Patryk Chrabaszcz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Loshchilov_I/0/1/0/all/0/1&quot;&gt;Ilya Loshchilov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hutter_F/0/1/0/all/0/1&quot;&gt;Frank Hutter&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09405">
<title>Improving Graph Convolutional Networks with Non-Parametric Activation Functions. (arXiv:1802.09405v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1802.09405</link>
<description rdf:parseType="Literal">&lt;p&gt;Graph neural networks (GNNs) are a class of neural networks that allow to
efficiently perform inference on data that is associated to a graph structure,
such as, e.g., citation networks or knowledge graphs. While several variants of
GNNs have been proposed, they only consider simple nonlinear activation
functions in their layers, such as rectifiers or squashing functions. In this
paper, we investigate the use of graph convolutional networks (GCNs) when
combined with more complex activation functions, able to adapt from the
training data. More specifically, we extend the recently proposed kernel
activation function, a non-parametric model which can be implemented easily,
can be regularized with standard $\ell_p$-norms techniques, and is smooth over
its entire domain. Our experimental evaluation shows that the proposed
architecture can significantly improve over its baseline, while similar
improvements cannot be obtained by simply increasing the depth or size of the
original GCN.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Scardapane_S/0/1/0/all/0/1&quot;&gt;Simone Scardapane&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vaerenbergh_S/0/1/0/all/0/1&quot;&gt;Steven Van Vaerenbergh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Comminiello_D/0/1/0/all/0/1&quot;&gt;Danilo Comminiello&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Uncini_A/0/1/0/all/0/1&quot;&gt;Aurelio Uncini&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1703.02065">
<title>On the Expressive Power of Overlapping Architectures of Deep Learning. (arXiv:1703.02065v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1703.02065</link>
<description rdf:parseType="Literal">&lt;p&gt;Expressive efficiency refers to the relation between two architectures A and
B, whereby any function realized by B could be replicated by A, but there
exists functions realized by A, which cannot be replicated by B unless its size
grows significantly larger. For example, it is known that deep networks are
exponentially efficient with respect to shallow networks, in the sense that a
shallow network must grow exponentially large in order to approximate the
functions represented by a deep network of polynomial size. In this work, we
extend the study of expressive efficiency to the attribute of network
connectivity and in particular to the effect of &quot;overlaps&quot; in the convolutional
process, i.e., when the stride of the convolution is smaller than its filter
size (receptive field). To theoretically analyze this aspect of network&apos;s
design, we focus on a well-established surrogate for ConvNets called
Convolutional Arithmetic Circuits (ConvACs), and then demonstrate empirically
that our results hold for standard ConvNets as well. Specifically, our analysis
shows that having overlapping local receptive fields, and more broadly denser
connectivity, results in an exponential increase in the expressive capacity of
neural networks. Moreover, while denser connectivity can increase the
expressive capacity, we show that the most common types of modern architectures
already exhibit exponential increase in expressivity, without relying on
fully-connected layers.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sharir_O/0/1/0/all/0/1&quot;&gt;Or Sharir&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shashua_A/0/1/0/all/0/1&quot;&gt;Amnon Shashua&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1703.10722">
<title>Factorization tricks for LSTM networks. (arXiv:1703.10722v3 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1703.10722</link>
<description rdf:parseType="Literal">&lt;p&gt;We present two simple ways of reducing the number of parameters and
accelerating the training of large Long Short-Term Memory (LSTM) networks: the
first one is &quot;matrix factorization by design&quot; of LSTM matrix into the product
of two smaller matrices, and the second one is partitioning of LSTM matrix, its
inputs and states into the independent groups. Both approaches allow us to
train large LSTM networks significantly faster to the near state-of the art
perplexity while using significantly less RNN parameters.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kuchaiev_O/0/1/0/all/0/1&quot;&gt;Oleksii Kuchaiev&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ginsburg_B/0/1/0/all/0/1&quot;&gt;Boris Ginsburg&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1705.09792">
<title>Deep Complex Networks. (arXiv:1705.09792v4 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1705.09792</link>
<description rdf:parseType="Literal">&lt;p&gt;At present, the vast majority of building blocks, techniques, and
architectures for deep learning are based on real-valued operations and
representations. However, recent work on recurrent neural networks and older
fundamental theoretical analysis suggests that complex numbers could have a
richer representational capacity and could also facilitate noise-robust memory
retrieval mechanisms. Despite their attractive properties and potential for
opening up entirely new neural architectures, complex-valued deep neural
networks have been marginalized due to the absence of the building blocks
required to design such models. In this work, we provide the key atomic
components for complex-valued deep neural networks and apply them to
convolutional feed-forward networks and convolutional LSTMs. More precisely, we
rely on complex convolutions and present algorithms for complex
batch-normalization, complex weight initialization strategies for
complex-valued neural nets and we use them in experiments with end-to-end
training schemes. We demonstrate that such complex-valued models are
competitive with their real-valued counterparts. We test deep complex models on
several computer vision tasks, on music transcription using the MusicNet
dataset and on Speech Spectrum Prediction using the TIMIT dataset. We achieve
state-of-the-art performance on these audio-related tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Trabelsi_C/0/1/0/all/0/1&quot;&gt;Chiheb Trabelsi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bilaniuk_O/0/1/0/all/0/1&quot;&gt;Olexa Bilaniuk&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Ying Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Serdyuk_D/0/1/0/all/0/1&quot;&gt;Dmitriy Serdyuk&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Subramanian_S/0/1/0/all/0/1&quot;&gt;Sandeep Subramanian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Santos_J/0/1/0/all/0/1&quot;&gt;Jo&amp;#xe3;o Felipe Santos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mehri_S/0/1/0/all/0/1&quot;&gt;Soroush Mehri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rostamzadeh_N/0/1/0/all/0/1&quot;&gt;Negar Rostamzadeh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bengio_Y/0/1/0/all/0/1&quot;&gt;Yoshua Bengio&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pal_C/0/1/0/all/0/1&quot;&gt;Christopher J Pal&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1705.10694">
<title>Deep Learning is Robust to Massive Label Noise. (arXiv:1705.10694v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1705.10694</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep neural networks trained on large supervised datasets have led to
impressive results in image classification and other tasks. However,
well-annotated datasets can be time-consuming and expensive to collect, lending
increased interest to larger but noisy datasets that are more easily obtained.
In this paper, we show that deep neural networks are capable of generalizing
from training data for which true labels are massively outnumbered by incorrect
labels. We demonstrate remarkably high test performance after training on
corrupted data from MNIST, CIFAR, and ImageNet. For example, on MNIST we obtain
test accuracy above 90 percent even after each clean training example has been
diluted with 100 randomly-labeled examples. Such behavior holds across multiple
patterns of label noise, even when erroneous labels are biased towards
confusing classes. We show that training in this regime requires a significant
but manageable increase in dataset size that is related to the factor by which
correct labels have been diluted. Finally, we provide an analysis of our
results that shows how increasing noise decreases the effective batch size.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rolnick_D/0/1/0/all/0/1&quot;&gt;David Rolnick&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Veit_A/0/1/0/all/0/1&quot;&gt;Andreas Veit&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Belongie_S/0/1/0/all/0/1&quot;&gt;Serge Belongie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shavit_N/0/1/0/all/0/1&quot;&gt;Nir Shavit&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1707.03141">
<title>A Simple Neural Attentive Meta-Learner. (arXiv:1707.03141v3 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1707.03141</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep neural networks excel in regimes with large amounts of data, but tend to
struggle when data is scarce or when they need to adapt quickly to changes in
the task. In response, recent work in meta-learning proposes training a
meta-learner on a distribution of similar tasks, in the hopes of generalization
to novel but related tasks by learning a high-level strategy that captures the
essence of the problem it is asked to solve. However, many recent meta-learning
approaches are extensively hand-designed, either using architectures
specialized to a particular application, or hard-coding algorithmic components
that constrain how the meta-learner solves the task. We propose a class of
simple and generic meta-learner architectures that use a novel combination of
temporal convolutions and soft attention; the former to aggregate information
from past experience and the latter to pinpoint specific pieces of information.
In the most extensive set of meta-learning experiments to date, we evaluate the
resulting Simple Neural AttentIve Learner (or SNAIL) on several
heavily-benchmarked tasks. On all tasks, in both supervised and reinforcement
learning, SNAIL attains state-of-the-art performance by significant margins.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mishra_N/0/1/0/all/0/1&quot;&gt;Nikhil Mishra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rohaninejad_M/0/1/0/all/0/1&quot;&gt;Mostafa Rohaninejad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1&quot;&gt;Xi Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1&quot;&gt;Pieter Abbeel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.10355">
<title>Convolutional Neural Networks Via Node-Varying Graph Filters. (arXiv:1710.10355v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1710.10355</link>
<description rdf:parseType="Literal">&lt;p&gt;Convolutional neural networks (CNNs) are being applied to an increasing
number of problems and fields due to their superior performance in
classification and regression tasks. Since two of the key operations that CNNs
implement are convolution and pooling, this type of networks is implicitly
designed to act on data described by regular structures such as images.
Motivated by the recent interest in processing signals defined in irregular
domains, we advocate a CNN architecture that operates on signals supported on
graphs. The proposed design replaces the classical convolution not with a
node-invariant graph filter (GF), which is the natural generalization of
convolution to graph domains, but with a node-varying GF. This filter extracts
different local features without increasing the output dimension of each layer
and, as a result, bypasses the need for a pooling stage while involving only
local operations. A second contribution is to replace the node-varying GF with
a hybrid node-varying GF, which is a new type of GF introduced in this paper.
While the alternative architecture can still be run locally without requiring a
pooling stage, the number of trainable parameters is smaller and can be
rendered independent of the data dimension. Tests are run on a synthetic source
localization problem and on the 20NEWS dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gama_F/0/1/0/all/0/1&quot;&gt;Fernando Gama&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leus_G/0/1/0/all/0/1&quot;&gt;Geert Leus&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Marques_A/0/1/0/all/0/1&quot;&gt;Antonio G. Marques&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ribeiro_A/0/1/0/all/0/1&quot;&gt;Alejandro Ribeiro&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.06761">
<title>Scalable Recollections for Continual Lifelong Learning. (arXiv:1711.06761v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1711.06761</link>
<description rdf:parseType="Literal">&lt;p&gt;Given the recent success of Deep Learning applied to a variety of single
tasks, it is natural to consider more human-realistic settings. Perhaps the
most difficult of these settings is that of continual lifelong learning, where
the model must learn online over a continuous stream of non-stationary data. A
continual lifelong learning system must have three primary capabilities to
succeed: it must learn and adapt over time, it must not forget what it has
learned, and it must be efficient in both training time and memory. Recent
techniques have focused their efforts largely on the first two capabilities
while the third capability remains largely unexplored. In this paper, we
consider the problem of efficient and effective storage of experiences over
very large time-frames. In particular we consider the case where typical
experiences are n bits and memories are limited to k bits for k &amp;lt;&amp;lt; n. We
present a novel scalable architecture and training algorithm in this
challenging domain and provide an extensive evaluation of its performance. Our
results show that we can achieve considerable gains on top of state-of-the-art
methods such as GEM.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Riemer_M/0/1/0/all/0/1&quot;&gt;Matthew Riemer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Klinger_T/0/1/0/all/0/1&quot;&gt;Tim Klinger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Franceschini_M/0/1/0/all/0/1&quot;&gt;Michele Franceschini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bouneffouf_D/0/1/0/all/0/1&quot;&gt;Djallel Bouneffouf&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08831">
<title>Convolutional Neural Networks combined with Runge-Kutta Methods. (arXiv:1802.08831v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1802.08831</link>
<description rdf:parseType="Literal">&lt;p&gt;A convolutional neural network for image classification can be constructed
following some mathematical ways since it models the ventral stream in visual
cortex which is regarded as a multi-period dynamical system. In this paper, a
new point of view is proposed for constructing network models as well as
providing a direction to get inspiration or explanation for neural network. If
each period in ventral stream was deemed to be a dynamical system with time as
the independent variable, there should be a set of ordinary differential
equations (ODEs) for this system. Runge-Kutta methods are common means to solve
ODE. Thus, network model ought to be built using these methods. Moreover,
convolutional networks could be employed to emulate the increments within every
time-step. The model constructed in the above way is named Runge-Kutta
Convolutional Neural Network (RKNet). According to this idea, Dense
Convolutional Networks (DenseNets) and Residual Networks (ResNets) were varied
to RKNets. To prove the feasibility of RKNets, these variants were verified on
benchmark datasets, CIFAR and ImageNet. The experimental results show that the
RKNets transformed from DenseNets gained similar or even higher parameter
efficiency. The success of the experiments denotes that Runge-Kutta methods can
be utilized to construct convolutional neural networks for image classification
efficiently. Furthermore, the network models might be structured more
rationally in the future basing on RKNet and priori knowledge.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_M/0/1/0/all/0/1&quot;&gt;Mai Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fu_C/0/1/0/all/0/1&quot;&gt;Chong Fu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08864">
<title>One Big Net For Everything. (arXiv:1802.08864v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.08864</link>
<description rdf:parseType="Literal">&lt;p&gt;I apply recent work on &quot;learning to think&quot; (2015) and on PowerPlay (2011) to
the incremental training of an increasingly general problem solver, continually
learning to solve new tasks without forgetting previous skills. The problem
solver is a single recurrent neural network (or similar general purpose
computer) called ONE. ONE is unusual in the sense that it is trained in various
ways, e.g., by black box optimization / reinforcement learning / artificial
evolution as well as supervised / unsupervised learning. For example, ONE may
learn through neuroevolution to control a robot through environment-changing
actions, and learn through unsupervised gradient descent to predict future
inputs and vector-valued reward signals as suggested in 1990. User-given tasks
can be defined through extra goal-defining input patterns, also proposed in
1990. Suppose ONE has already learned many skills. Now a copy of ONE can be
re-trained to learn a new skill, e.g., through neuroevolution without a
teacher. Here it may profit from re-using previously learned subroutines, but
it may also forget previous skills. Then ONE is retrained in PowerPlay style
(2011) on stored input/output traces of (a) ONE&apos;s copy executing the new skill
and (b) previous instances of ONE whose skills are still considered worth
memorizing. Simultaneously, ONE is retrained on old traces (even those of
unsuccessful trials) to become a better predictor, without additional expensive
interaction with the enviroment. More and more control and prediction skills
are thus collapsed into ONE, like in the chunker-automatizer system of the
neural history compressor (1991). This forces ONE to relate partially analogous
skills (with shared algorithmic information) to each other, creating common
subroutines in form of shared subnetworks of ONE, to greatly speed up
subsequent learning of additional, novel but algorithmically related skills.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schmidhuber_J/0/1/0/all/0/1&quot;&gt;Juergen Schmidhuber&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08946">
<title>Teacher Improves Learning by Selecting a Training Subset. (arXiv:1802.08946v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.08946</link>
<description rdf:parseType="Literal">&lt;p&gt;We call a learner super-teachable if a teacher can trim down an iid training
set while making the learner learn even better. We provide sharp super-teaching
guarantees on two learners: the maximum likelihood estimator for the mean of a
Gaussian, and the large margin classifier in 1D. For general learners, we
provide a mixed-integer nonlinear programming-based algorithm to find a super
teaching set. Empirical experiments show that our algorithm is able to find
good super-teaching sets for both regression and classification problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ma_Y/0/1/0/all/0/1&quot;&gt;Yuzhe Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Nowak_R/0/1/0/all/0/1&quot;&gt;Robert Nowak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rigollet_P/0/1/0/all/0/1&quot;&gt;Philippe Rigollet&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xuezhou Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhu_X/0/1/0/all/0/1&quot;&gt;Xiaojin Zhu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08969">
<title>Meta Multi-Task Learning for Sequence Modeling. (arXiv:1802.08969v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.08969</link>
<description rdf:parseType="Literal">&lt;p&gt;Semantic composition functions have been playing a pivotal role in neural
representation learning of text sequences. In spite of their success, most
existing models suffer from the underfitting problem: they use the same shared
compositional function on all the positions in the sequence, thereby lacking
expressive power due to incapacity to capture the richness of compositionality.
Besides, the composition functions of different tasks are independent and
learned from scratch. In this paper, we propose a new sharing scheme of
composition function across multiple tasks. Specifically, we use a shared
meta-network to capture the meta-knowledge of semantic composition and generate
the parameters of the task-specific semantic composition models. We conduct
extensive experiments on two types of tasks, text classification and sequence
tagging, which demonstrate the benefits of our approach. Besides, we show that
the shared meta-knowledge learned by our proposed model can be regarded as
off-the-shelf knowledge and easily transferred to new tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1&quot;&gt;Junkun Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qiu_X/0/1/0/all/0/1&quot;&gt;Xipeng Qiu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_P/0/1/0/all/0/1&quot;&gt;Pengfei Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1&quot;&gt;Xuanjing Huang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09030">
<title>Cakewalk Sampling. (arXiv:1802.09030v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.09030</link>
<description rdf:parseType="Literal">&lt;p&gt;Combinatorial optimization is a common theme in computer science which
underlies a considerable variety of problems. In contrast to the continuous
setting, combinatorial problems require special solution strategies, and it&apos;s
hard to come by generic schemes like gradient methods for continuous domains.
We follow a standard construction of a parametric sampling distribution that
transforms the problem to the continuous domain, allowing us to optimize the
expectation of a given objective using estimates of the gradient. In spite of
the apparent generality, such constructions are known to suffer from highly
variable gradient estimates, and thus require careful tuning that is done in a
problem specific manner. We show that a simple trick of converting the
objective values to their cumulative probabilities fixes the distribution of
the objective, allowing us to derive an online optimization algorithm that can
be applied in a generic fashion. As an experimental benchmark we use the task
of finding cliques in undirected graphs, and we show that our method, even when
blindly applied, consistently outperforms related methods. Notably, on the
DIMACS clique benchmark, our method approaches the performance of the best
clique finding algorithms without access to the graph structure, and only
through objective function evaluations, thus providing significant evidence to
the generality and effectivity of our method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Patish_U/0/1/0/all/0/1&quot;&gt;Uri Patish&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ullman_S/0/1/0/all/0/1&quot;&gt;Shimon Ullman&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09059">
<title>One Single Deep Bidirectional LSTM Network for Word Sense Disambiguation of Text Data. (arXiv:1802.09059v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.09059</link>
<description rdf:parseType="Literal">&lt;p&gt;Due to recent technical and scientific advances, we have a wealth of
information hidden in unstructured text data such as offline/online narratives,
research articles, and clinical reports. To mine these data properly,
attributable to their innate ambiguity, a Word Sense Disambiguation (WSD)
algorithm can avoid numbers of difficulties in Natural Language Processing
(NLP) pipeline. However, considering a large number of ambiguous words in one
language or technical domain, we may encounter limiting constraints for proper
deployment of existing WSD models. This paper attempts to address the problem
of one-classifier-per-one-word WSD algorithms by proposing a single
Bidirectional Long Short-Term Memory (BLSTM) network which by considering
senses and context sequences works on all ambiguous words collectively.
Evaluated on SensEval-3 benchmark, we show the result of our model is
comparable with top-performing WSD algorithms. We also discuss how applying
additional modifications alleviates the model fault and the need for more
training data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pesaranghader_A/0/1/0/all/0/1&quot;&gt;Ahmad Pesaranghader&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pesaranghader_A/0/1/0/all/0/1&quot;&gt;Ali Pesaranghader&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Matwin_S/0/1/0/all/0/1&quot;&gt;Stan Matwin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sokolova_M/0/1/0/all/0/1&quot;&gt;Marina Sokolova&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09089">
<title>Kitsune: An Ensemble of Autoencoders for Online Network Intrusion Detection. (arXiv:1802.09089v1 [cs.CR])</title>
<link>http://arxiv.org/abs/1802.09089</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural networks have become an increasingly popular solution for network
intrusion detection systems (NIDS). Their capability of learning complex
patterns and behaviors make them a suitable solution for differentiating
between normal traffic and network attacks. However, a drawback of neural
networks is the amount of resources needed to train them. Many network gateways
and routers devices, which could potentially host an NIDS, simply do not have
the memory or processing power to train and sometimes even execute such models.
More importantly, the existing neural network solutions are trained in a
supervised manner. Meaning that an expert must label the network traffic and
update the model manually from time to time.
&lt;/p&gt;
&lt;p&gt;In this paper, we present Kitsune: a plug and play NIDS which can learn to
detect attacks on the local network, without supervision, and in an efficient
online manner. Kitsune&apos;s core algorithm (KitNET) uses an ensemble of neural
networks called autoencoders to collectively differentiate between normal and
abnormal traffic patterns. KitNET is supported by a feature extraction
framework which efficiently tracks the patterns of every network channel. Our
evaluations show that Kitsune can detect various attacks with a performance
comparable to offline anomaly detectors, even on a Raspberry PI. This
demonstrates that Kitsune can be a practical and economic NIDS.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mirsky_Y/0/1/0/all/0/1&quot;&gt;Yisroel Mirsky&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Doitshman_T/0/1/0/all/0/1&quot;&gt;Tomer Doitshman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Elovici_Y/0/1/0/all/0/1&quot;&gt;Yuval Elovici&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shabtai_A/0/1/0/all/0/1&quot;&gt;Asaf Shabtai&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09442">
<title>Self-organizing maps and generalization: an algorithmic description of Numerosity and Variability Effects. (arXiv:1802.09442v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.09442</link>
<description rdf:parseType="Literal">&lt;p&gt;Category, or property generalization is a central function in the human
cognition. It plays a crucial role in a variety of domains, such as learning,
everyday reasoning, specialized reasoning, and decision making. Judging the
content of a dish as edible, a hormone level as healthy, a building as
belonging to the same architectural style as previously seen buildings, are
examples of category generalization. In this paper, we propose self-organizing
maps as candidates to explain the psychological mechanisms underlying category
generalization. Self-organizing maps are psychologically and biologically
plausible neural network models that learn after limited exposure to positive
category examples, without any need of contrastive information. Just like
humans. They reproduce human behavior in category generalization, in particular
for what concerns the well-known Numerosity and Variability effects, which are
usually explained with Bayesian tools. Where category generalization is
concerned, self-organizing maps are good candidates to bridge the gap between
the computational level of analysis in Marr&apos;s hierarchy (where Bayesian models
are situated) and the algorithmic level of aanalysis in Marr&apos;s hierarchy (where
Bayesian models are situated) and the algorithmic level of analysis in which
plausible mechanisms are described.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gliozzi_V/0/1/0/all/0/1&quot;&gt;Valentina Gliozzi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Plunkett_K/0/1/0/all/0/1&quot;&gt;Kim Plunkett&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09465">
<title>On Strong NP-Completeness of Rational Problems. (arXiv:1802.09465v1 [cs.DM])</title>
<link>http://arxiv.org/abs/1802.09465</link>
<description rdf:parseType="Literal">&lt;p&gt;The computational complexity of the partition, 0-1 subset sum, unbounded
subset sum, 0-1 knapsack and unbounded knapsack problems and their multiple
variants were studied in numerous papers in the past where all the weights and
profits were assumed to be integers. We re-examine here the computational
complexity of all these problems in the setting where the weights and profits
are allowed to be any rational numbers. We show that all of these problems in
this setting become strongly NP-complete and, as a result, no pseudo-polynomial
algorithm can exist for solving them unless P=NP. Despite this result we show
that they all still admit a fully polynomial-time approximation scheme.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wojtczak_D/0/1/0/all/0/1&quot;&gt;Dominik Wojtczak&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1611.06589">
<title>Fair Division via Social Comparison. (arXiv:1611.06589v2 [cs.DS] UPDATED)</title>
<link>http://arxiv.org/abs/1611.06589</link>
<description rdf:parseType="Literal">&lt;p&gt;In the classical cake cutting problem, a resource must be divided among
agents with different utilities so that each agent believes they have received
a fair share of the resource relative to the other agents. We introduce a
variant of the problem in which we model an underlying social network on the
agents with a graph, and agents only evaluate their shares relative to their
neighbors&apos; in the network. This formulation captures many situations in which
it is unrealistic to assume a global view, and also exposes interesting
phenomena in the original problem.
&lt;/p&gt;
&lt;p&gt;Specifically, we say an allocation is locally envy-free if no agent envies a
neighbor&apos;s allocation and locally proportional if each agent values her own
allocation as much as the average value of her neighbor&apos;s allocations, with the
former implying the latter. While global envy-freeness implies local
envy-freeness, global proportionality does not imply local proportionality, or
vice versa. A general result is that for any two distinct graphs on the same
set of nodes and an allocation, there exists a set of valuation functions such
that the allocation is locally proportional on one but not the other.
&lt;/p&gt;
&lt;p&gt;We fully characterize the set of graphs for which an oblivious single-cutter
protocol-- a protocol that uses a single agent to cut the cake into pieces
--admits a bounded protocol with $O(n^2)$ query complexity for locally
envy-free allocations in the Robertson-Webb model. We also consider the price
of envy-freeness, which compares the total utility of an optimal allocation to
the best utility of an allocation that is envy-free. We show that a lower bound
of $\Omega(\sqrt{n})$ on the price of envy-freeness for global allocations in
fact holds for local envy-freeness in any connected undirected graph. Thus,
sparse graphs surprisingly do not provide more flexibility with respect to the
quality of envy-free allocations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abebe_R/0/1/0/all/0/1&quot;&gt;Rediet Abebe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kleinberg_J/0/1/0/all/0/1&quot;&gt;Jon Kleinberg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Parkes_D/0/1/0/all/0/1&quot;&gt;David Parkes&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.11041">
<title>Unsupervised Neural Machine Translation. (arXiv:1710.11041v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1710.11041</link>
<description rdf:parseType="Literal">&lt;p&gt;In spite of the recent success of neural machine translation (NMT) in
standard benchmarks, the lack of large parallel corpora poses a major practical
problem for many language pairs. There have been several proposals to alleviate
this issue with, for instance, triangulation and semi-supervised learning
techniques, but they still require a strong cross-lingual signal. In this work,
we completely remove the need of parallel data and propose a novel method to
train an NMT system in a completely unsupervised manner, relying on nothing but
monolingual corpora. Our model builds upon the recent work on unsupervised
embedding mappings, and consists of a slightly modified attentional
encoder-decoder model that can be trained on monolingual corpora alone using a
combination of denoising and backtranslation. Despite the simplicity of the
approach, our system obtains 15.56 and 10.21 BLEU points in WMT 2014
French-to-English and German-to-English translation. The model can also profit
from small parallel corpora, and attains 21.81 and 15.24 points when combined
with 100,000 parallel sentences, respectively. Our implementation is released
as an open source project.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Artetxe_M/0/1/0/all/0/1&quot;&gt;Mikel Artetxe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Labaka_G/0/1/0/all/0/1&quot;&gt;Gorka Labaka&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Agirre_E/0/1/0/all/0/1&quot;&gt;Eneko Agirre&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cho_K/0/1/0/all/0/1&quot;&gt;Kyunghyun Cho&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.11342">
<title>Generating Natural Adversarial Examples. (arXiv:1710.11342v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1710.11342</link>
<description rdf:parseType="Literal">&lt;p&gt;Due to their complex nature, it is hard to characterize the ways in which
machine learning models can misbehave or be exploited when deployed. Recent
work on adversarial examples, i.e. inputs with minor perturbations that result
in substantially different model predictions, is helpful in evaluating the
robustness of these models by exposing the adversarial scenarios where they
fail. However, these malicious perturbations are often unnatural, not
semantically meaningful, and not applicable to complicated domains such as
language. In this paper, we propose a framework to generate natural and legible
adversarial examples that lie on the data manifold, by searching in semantic
space of dense and continuous data representation, utilizing the recent
advances in generative adversarial networks. We present generated adversaries
to demonstrate the potential of the proposed approach for black-box classifiers
for a wide range of applications such as image classification, textual
entailment, and machine translation. We include experiments to show that the
generated adversaries are natural, legible to humans, and useful in evaluating
and analyzing black-box classifiers.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1&quot;&gt;Zhengli Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dua_D/0/1/0/all/0/1&quot;&gt;Dheeru Dua&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1&quot;&gt;Sameer Singh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.07163">
<title>Dynamic Neural Program Embedding for Program Repair. (arXiv:1711.07163v3 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1711.07163</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural program embeddings have shown much promise recently for a variety of
program analysis tasks, including program synthesis, program repair, fault
localization, etc. However, most existing program embeddings are based on
syntactic features of programs, such as raw token sequences or abstract syntax
trees. Unlike images and text, a program has an unambiguous semantic meaning
that can be difficult to capture by only considering its syntax (i.e.
syntactically similar pro- grams can exhibit vastly different run-time
behavior), which makes syntax-based program embeddings fundamentally limited.
This paper proposes a novel semantic program embedding that is learned from
program execution traces. Our key insight is that program states expressed as
sequential tuples of live variable values not only captures program semantics
more precisely, but also offer a more natural fit for Recurrent Neural Networks
to model. We evaluate different syntactic and semantic program embeddings on
predicting the types of errors that students make in their submissions to an
introductory programming class and two exercises on the CodeHunt education
platform. Evaluation results show that our new semantic program embedding
significantly outperforms the syntactic program embeddings based on token
sequences and abstract syntax trees. In addition, we augment a search-based
program repair system with the predictions obtained from our se- mantic
embedding, and show that search efficiency is also significantly improved.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1&quot;&gt;Ke Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singh_R/0/1/0/all/0/1&quot;&gt;Rishabh Singh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Su_Z/0/1/0/all/0/1&quot;&gt;Zhendong Su&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05883">
<title>Deep Generative Model for Joint Alignment and Word Representation. (arXiv:1802.05883v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1802.05883</link>
<description rdf:parseType="Literal">&lt;p&gt;This work exploits translation data as a source of semantically relevant
learning signal for models of word representation. In particular, we exploit
equivalence through translation as a form of distributed context and jointly
learn how to embed and align with a deep generative model. Our EmbedAlign model
embeds words in their complete observed context and learns by marginalisation
of latent lexical alignments. Besides, it embeds words as posterior probability
densities, rather than point estimates, which allows us to compare words in
context using a measure of overlap between distributions (e.g. KL divergence).
We investigate our model&apos;s performance on a range of lexical semantics tasks
achieving competitive results on several standard benchmarks including natural
language inference, paraphrasing, and text similarity.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rios_M/0/1/0/all/0/1&quot;&gt;Miguel Rios&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aziz_W/0/1/0/all/0/1&quot;&gt;Wilker Aziz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Simaan_K/0/1/0/all/0/1&quot;&gt;Khalil Sima&amp;#x27;an&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06024">
<title>Towards a Continuous Knowledge Learning Engine for Chatbots. (arXiv:1802.06024v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1802.06024</link>
<description rdf:parseType="Literal">&lt;p&gt;Although chatbots have been very popular in recent years, they still have
some serious weaknesses which limit the scope of their applications. One major
weakness is that they cannot learn new knowledge during the conversation
process, i.e., their knowledge is fixed beforehand and cannot be expanded or
updated during conversation. In this paper, we propose to build a general
knowledge learning engine for chatbots to enable them to continuously and
interactively learn new knowledge during conversations. As time goes by, they
become more and more knowledgeable and better and better at learning and
conversation. We model the task as an open-world knowledge base completion
problem and propose a novel technique called lifelong interactive learning and
inference (LiLi) to solve it. LiLi works by imitating how humans acquire
knowledge and perform inference during an interactive conversation. Our
experimental results show LiLi is highly promising.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mazumder_S/0/1/0/all/0/1&quot;&gt;Sahisnu Mazumder&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_N/0/1/0/all/0/1&quot;&gt;Nianzu Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1&quot;&gt;Bing Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08717">
<title>Deep learning in radiology: an overview of the concepts and a survey of the state of the art. (arXiv:1802.08717v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1802.08717</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep learning is a branch of artificial intelligence where networks of simple
interconnected units are used to extract patterns from data in order to solve
complex problems. Deep learning algorithms have shown groundbreaking
performance in a variety of sophisticated tasks, especially those related to
images. They have often matched or exceeded human performance. Since the
medical field of radiology mostly relies on extracting useful information from
images, it is a very natural application area for deep learning, and research
in this area has rapidly grown in recent years. In this article, we review the
clinical reality of radiology and discuss the opportunities for application of
deep learning algorithms. We also introduce basic concepts of deep learning
including convolutional neural networks. Then, we present a survey of the
research in deep learning applied to radiology. We organize the studies by the
types of specific tasks that they attempt to solve and review the broad range
of utilized deep learning algorithms. Finally, we briefly discuss opportunities
and challenges for incorporating deep learning in the radiology practice of the
future.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mazurowski_M/0/1/0/all/0/1&quot;&gt;Maciej A. Mazurowski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Buda_M/0/1/0/all/0/1&quot;&gt;Mateusz Buda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saha_A/0/1/0/all/0/1&quot;&gt;Ashirbani Saha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bashir_M/0/1/0/all/0/1&quot;&gt;Mustafa R. Bashir&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08768">
<title>Is Generator Conditioning Causally Related to GAN Performance?. (arXiv:1802.08768v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.08768</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent work (Pennington et al, 2017) suggests that controlling the entire
distribution of Jacobian singular values is an important design consideration
in deep learning. Motivated by this, we study the distribution of singular
values of the Jacobian of the generator in Generative Adversarial Networks
(GANs). We find that this Jacobian generally becomes ill-conditioned at the
beginning of training. Moreover, we find that the average (with z from p(z))
conditioning of the generator is highly predictive of two other ad-hoc metrics
for measuring the &apos;quality&apos; of trained GANs: the Inception Score and the
Frechet Inception Distance (FID). We test the hypothesis that this relationship
is causal by proposing a &apos;regularization&apos; technique (called Jacobian Clamping)
that softly penalizes the condition number of the generator Jacobian. Jacobian
Clamping improves the mean Inception Score and the mean FID for GANs trained on
several datasets. It also greatly reduces inter-run variance of the
aforementioned scores, addressing (at least partially) one of the main
criticisms of GANs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Odena_A/0/1/0/all/0/1&quot;&gt;Augustus Odena&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Buckman_J/0/1/0/all/0/1&quot;&gt;Jacob Buckman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Olsson_C/0/1/0/all/0/1&quot;&gt;Catherine Olsson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Brown_T/0/1/0/all/0/1&quot;&gt;Tom B. Brown&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Olah_C/0/1/0/all/0/1&quot;&gt;Christopher Olah&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Raffel_C/0/1/0/all/0/1&quot;&gt;Colin Raffel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Goodfellow_I/0/1/0/all/0/1&quot;&gt;Ian Goodfellow&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08770">
<title>A Walk with SGD. (arXiv:1802.08770v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.08770</link>
<description rdf:parseType="Literal">&lt;p&gt;Exploring why stochastic gradient descent (SGD) based optimization methods
train deep neural networks (DNNs) that generalize well has become an active
area of research recently. Towards this end, we empirically study the dynamics
of SGD when training over-parametrized deep networks. Specifically we study the
DNN loss surface along the trajectory of SGD by interpolating the loss surface
between parameters from consecutive \textit{iterations} and tracking various
metrics during the training process. We find that the covariance structure of
the noise induced due to mini-batches is quite special that allows SGD to
descend and explore the loss surface while avoiding barriers along its path.
Specifically, our experiments show evidence that for the most part of training,
SGD explores regions along a valley by bouncing off valley walls at a height
above the valley floor. This &apos;bouncing off walls at a height&apos; mechanism helps
SGD traverse larger distance for small batch sizes and large learning rates
which we find play qualitatively different roles in the dynamics. While a large
learning rate maintains a large height from the valley floor, a small batch
size injects noise facilitating exploration. We find this mechanism is crucial
for generalization because the floor of the valley has barriers and this
exploration above the valley floor allows SGD to quickly travel far away from
the initialization point (without being affected by barriers) and find flatter
regions, corresponding to better generalization.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Xing_C/0/1/0/all/0/1&quot;&gt;Chen Xing&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Arpit_D/0/1/0/all/0/1&quot;&gt;Devansh Arpit&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tsirigotis_C/0/1/0/all/0/1&quot;&gt;Christos Tsirigotis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bengio_Y/0/1/0/all/0/1&quot;&gt;Yoshua Bengio&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08780">
<title>Extremely Fast Decision Tree. (arXiv:1802.08780v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.08780</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce a novel incremental decision tree learning algorithm, Hoeffding
Anytime Tree, that is statistically more efficient than the current
state-of-the-art, Hoeffding Tree. We demonstrate that an implementation of
Hoeffding Anytime Tree---&quot;Extremely Fast Decision Tree&quot;, a minor modification
to the MOA implementation of Hoeffding Tree---obtains significantly superior
prequential accuracy on most of the largest classification datasets from the
UCI repository. Hoeffding Anytime Tree produces the asymptotic batch tree in
the limit, is naturally resilient to concept drift, and can be used as a higher
accuracy replacement for Hoeffding Tree in most scenarios, at a small
additional computational cost.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Manapragada_C/0/1/0/all/0/1&quot;&gt;Chaitanya Manapragada&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Webb_G/0/1/0/all/0/1&quot;&gt;Geoff Webb&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Salehi_M/0/1/0/all/0/1&quot;&gt;Mahsa Salehi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08888">
<title>N-GCN: Multi-scale Graph Convolution for Semi-supervised Node Classification. (arXiv:1802.08888v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.08888</link>
<description rdf:parseType="Literal">&lt;p&gt;Graph Convolutional Networks (GCNs) have shown significant improvements in
semi-supervised learning on graph-structured data. Concurrently, unsupervised
learning of graph embeddings has benefited from the information contained in
random walks. In this paper, we propose a model: Network of GCNs (N-GCN), which
marries these two lines of work. At its core, N-GCN trains multiple instances
of GCNs over node pairs discovered at different distances in random walks, and
learns a combination of the instance outputs which optimizes the classification
objective. Our experiments show that our proposed N-GCN model improves
state-of-the-art baselines on all of the challenging node classification tasks
we consider: Cora, Citeseer, Pubmed, and PPI. In addition, our proposed method
has other desirable properties, including generalization to recently proposed
semi-supervised learning methods such as GraphSAGE, allowing us to propose
N-SAGE, and resilience to adversarial input perturbations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abu_El_Haija_S/0/1/0/all/0/1&quot;&gt;Sami Abu-El-Haija&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kapoor_A/0/1/0/all/0/1&quot;&gt;Amol Kapoor&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Perozzi_B/0/1/0/all/0/1&quot;&gt;Bryan Perozzi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1&quot;&gt;Joonseok Lee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08908">
<title>Scalable Private Learning with PATE. (arXiv:1802.08908v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.08908</link>
<description rdf:parseType="Literal">&lt;p&gt;The rapid adoption of machine learning has increased concerns about the
privacy implications of machine learning models trained on sensitive data, such
as medical records or other personal information. To address those concerns,
one promising approach is Private Aggregation of Teacher Ensembles, or PATE,
which transfers to a &quot;student&quot; model the knowledge of an ensemble of &quot;teacher&quot;
models, with intuitive privacy provided by training teachers on disjoint data
and strong privacy guaranteed by noisy aggregation of teachers&apos; answers.
However, PATE has so far been evaluated only on simple classification tasks
like MNIST, leaving unclear its utility when applied to larger-scale learning
tasks and real-world datasets.
&lt;/p&gt;
&lt;p&gt;In this work, we show how PATE can scale to learning tasks with large numbers
of output classes and uncurated, imbalanced training data with errors. For
this, we introduce new noisy aggregation mechanisms for teacher ensembles that
are more selective and add less noise, and prove their tighter
differential-privacy guarantees. Our new mechanisms build on two insights: the
chance of teacher consensus is increased by using more concentrated noise and,
lacking consensus, no answer need be given to a student. The consensus answers
used are more likely to be correct, offer better intuitive privacy, and incur
lower-differential privacy cost. Our evaluation shows our mechanisms improve on
the original PATE on all measures, and scale to larger tasks with both high
utility and very strong privacy ($\varepsilon$ &amp;lt; 1.0).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Papernot_N/0/1/0/all/0/1&quot;&gt;Nicolas Papernot&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Song_S/0/1/0/all/0/1&quot;&gt;Shuang Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mironov_I/0/1/0/all/0/1&quot;&gt;Ilya Mironov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Raghunathan_A/0/1/0/all/0/1&quot;&gt;Ananth Raghunathan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Talwar_K/0/1/0/all/0/1&quot;&gt;Kunal Talwar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Erlingsson_U/0/1/0/all/0/1&quot;&gt;&amp;#xda;lfar Erlingsson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09031">
<title>Functional Gradient Boosting based on Residual Network Perception. (arXiv:1802.09031v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.09031</link>
<description rdf:parseType="Literal">&lt;p&gt;Residual Networks (ResNets) have become state-of-the-art models in deep
learning and several theoretical studies have been devoted to understanding why
ResNet works so well. One attractive viewpoint on ResNet is that it is
optimizing the risk in a functional space by combining an ensemble of effective
features. In this paper, we adopt this viewpoint to construct a new gradient
boosting method, which is known to be very powerful in data analysis. To do so,
we formalize the gradient boosting perspective of ResNet mathematically using
the notion of functional gradients and propose a new method called ResFGB for
classification tasks by leveraging ResNet perception. Two types of
generalization guarantees are provided from the optimization perspective: one
is the margin bound and the other is the expected risk bound by the
sample-splitting technique. Experimental results show superior performance of
the proposed method over state-of-the-art methods such as LightGBM.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Nitanda_A/0/1/0/all/0/1&quot;&gt;Atsushi Nitanda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Suzuki_T/0/1/0/all/0/1&quot;&gt;Taiji Suzuki&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09069">
<title>Active Learning with Logged Data. (arXiv:1802.09069v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.09069</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider active learning with logged data, where labeled examples are
drawn conditioned on a predetermined logging policy, and the goal is to learn a
classifier on the entire population, not just conditioned on the logging
policy.
&lt;/p&gt;
&lt;p&gt;Prior work addresses this problem either when only logged data is available,
or purely in a controlled random experimentation setting where the logged data
is ignored. In this work, we combine both approaches to provide an algorithm
that uses logged data to bootstrap and inform experimentation, thus achieving
the best of both worlds. Our work is inspired by a connection between
controlled random experimentation and active learning, and modifies existing
disagreement-based active learning algorithms to exploit logged data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yan_S/0/1/0/all/0/1&quot;&gt;Songbai Yan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chaudhuri_K/0/1/0/all/0/1&quot;&gt;Kamalika Chaudhuri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Javidi_T/0/1/0/all/0/1&quot;&gt;Tara Javidi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09128">
<title>Averaging Stochastic Gradient Descent on Riemannian Manifolds. (arXiv:1802.09128v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.09128</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the minimization of a function defined on a Riemannian manifold
$\mathcal{M}$ accessible only through unbiased estimates of its gradients. We
develop a geometric framework to transform a sequence of slowly converging
iterates generated from stochastic gradient descent (SGD) on $\mathcal{M}$ to
an averaged iterate sequence with a robust and fast $O(1/n)$ convergence rate.
We then present an application of our framework to geodesically-strongly-convex
(and possibly Euclidean non-convex) problems. Finally, we demonstrate how these
ideas apply to the case of streaming $k$-PCA, where we show how to accelerate
the slow rate of the randomized power method (without requiring knowledge of
the eigengap) into a robust algorithm achieving the optimal rate of
convergence.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tripuraneni_N/0/1/0/all/0/1&quot;&gt;Nilesh Tripuraneni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Flammarion_N/0/1/0/all/0/1&quot;&gt;Nicolas Flammarion&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bach_F/0/1/0/all/0/1&quot;&gt;Francis Bach&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jordan_M/0/1/0/all/0/1&quot;&gt;Michael I. Jordan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09197">
<title>AI4AI: Quantitative Methods for Classifying Host Species from Avian Influenza DNA Sequence. (arXiv:1802.09197v1 [q-bio.QM])</title>
<link>http://arxiv.org/abs/1802.09197</link>
<description rdf:parseType="Literal">&lt;p&gt;Avian Influenza breakouts cause millions of dollars in damage each year
globally, especially in Asian countries such as China and South Korea. The
impact magnitude of a breakout directly correlates to time required to fully
understand the influenza virus, particularly the interspecies pathogenicity.
The procedure requires laboratory tests that require resources typically
lacking in a breakout emergency. In this study, we propose new quantitative
methods utilizing machine learning and deep learning to correctly classify host
species given raw DNA sequence data of the influenza virus, and provide
probabilities for each classification. The best deep learning models achieve
top-1 classification accuracy of 47%, and top-3 classification accuracy of 82%,
on a dataset of 11 host species classes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Choi_W/0/1/0/all/0/1&quot;&gt;Woo Yong Choi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Song_K/0/1/0/all/0/1&quot;&gt;Kyu Ye Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Lee_C/0/1/0/all/0/1&quot;&gt;Chan Woo Lee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09381">
<title>DropLasso: A robust variant of Lasso for single cell RNA-seq data. (arXiv:1802.09381v1 [q-bio.QM])</title>
<link>http://arxiv.org/abs/1802.09381</link>
<description rdf:parseType="Literal">&lt;p&gt;Single-cell RNA sequencing (scRNA-seq) is a fast growing approach to measure
the genome-wide transcriptome of many individual cells in parallel, but results
in noisy data with many dropout events. Existing methods to learn molecular
signatures from bulk transcriptomic data may therefore not be adapted to
scRNA-seq data, in order to automatically classify individual cells into
predefined classes. We propose a new method called DropLasso to learn a
molecular signature from scRNA-seq data. DropLasso extends the dropout
regularisation technique, popular in neural network training, to esti- mate
sparse linear models. It is well adapted to data corrupted by dropout noise,
such as scRNA-seq data, and we clarify how it relates to elastic net
regularisation. We provide promising results on simulated and real scRNA-seq
data, suggesting that DropLasso may be better adapted than standard regularisa-
tions to infer molecular signatures from scRNA-seq data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Khalfaoui_B/0/1/0/all/0/1&quot;&gt;Beyrem Khalfaoui&lt;/a&gt; (CBIO), &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Vert_J/0/1/0/all/0/1&quot;&gt;Jean-Philippe Vert&lt;/a&gt; (CBIO, DMA)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09386">
<title>Learning Anonymized Representations with Adversarial Neural Networks. (arXiv:1802.09386v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.09386</link>
<description rdf:parseType="Literal">&lt;p&gt;Statistical methods protecting sensitive information or the identity of the
data owner have become critical to ensure privacy of individuals as well as of
organizations. This paper investigates anonymization methods based on
representation learning and deep neural networks, and motivated by novel
information theoretical bounds. We introduce a novel training objective for
simultaneously training a predictor over target variables of interest (the
regular labels) while preventing an intermediate representation to be
predictive of the private labels. The architecture is based on three
sub-networks: one going from input to representation, one from representation
to predicted regular labels, and one from representation to predicted private
labels. The training procedure aims at learning representations that preserve
the relevant part of the information (about regular labels) while dismissing
information about the private labels which correspond to the identity of a
person. We demonstrate the success of this approach for two distinct
classification versus anonymization tasks (handwritten digits and sentiment
analysis).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Feutry_C/0/1/0/all/0/1&quot;&gt;Cl&amp;#xe9;ment Feutry&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Piantanida_P/0/1/0/all/0/1&quot;&gt;Pablo Piantanida&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bengio_Y/0/1/0/all/0/1&quot;&gt;Yoshua Bengio&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Duhamel_P/0/1/0/all/0/1&quot;&gt;Pierre Duhamel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09484">
<title>Disentangling the independently controllable factors of variation by interacting with the world. (arXiv:1802.09484v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.09484</link>
<description rdf:parseType="Literal">&lt;p&gt;It has been postulated that a good representation is one that disentangles
the underlying explanatory factors of variation. However, it remains an open
question what kind of training framework could potentially achieve that.
Whereas most previous work focuses on the static setting (e.g., with images),
we postulate that some of the causal factors could be discovered if the learner
is allowed to interact with its environment. The agent can experiment with
different actions and observe their effects. More specifically, we hypothesize
that some of these factors correspond to aspects of the environment which are
independently controllable, i.e., that there exists a policy and a learnable
feature for each such aspect of the environment, such that this policy can
yield changes in that feature with minimal changes to other features that
explain the statistical variations in the observed data. We propose a specific
objective function to find such factors, and verify experimentally that it can
indeed disentangle independently controllable aspects of the environment
without any extrinsic reward signal.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Thomas_V/0/1/0/all/0/1&quot;&gt;Valentin Thomas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bengio_E/0/1/0/all/0/1&quot;&gt;Emmanuel Bengio&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Fedus_W/0/1/0/all/0/1&quot;&gt;William Fedus&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pondard_J/0/1/0/all/0/1&quot;&gt;Jules Pondard&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Beaudoin_P/0/1/0/all/0/1&quot;&gt;Philippe Beaudoin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Larochelle_H/0/1/0/all/0/1&quot;&gt;Hugo Larochelle&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pineau_J/0/1/0/all/0/1&quot;&gt;Joelle Pineau&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Precup_D/0/1/0/all/0/1&quot;&gt;Doina Precup&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bengio_Y/0/1/0/all/0/1&quot;&gt;Yoshua Bengio&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1703.04782">
<title>Online Learning Rate Adaptation with Hypergradient Descent. (arXiv:1703.04782v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1703.04782</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce a general method for improving the convergence rate of
gradient-based optimizers that is easy to implement and works well in practice.
We demonstrate the effectiveness of the method in a range of optimization
problems by applying it to stochastic gradient descent, stochastic gradient
descent with Nesterov momentum, and Adam, showing that it significantly reduces
the need for the manual tuning of the initial learning rate for these commonly
used algorithms. Our method works by dynamically updating the learning rate
during optimization using the gradient with respect to the learning rate of the
update rule itself. Computing this &quot;hypergradient&quot; needs little additional
computation, requires only one extra copy of the original gradient to be stored
in memory, and relies upon nothing more than what is provided by reverse-mode
automatic differentiation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Baydin_A/0/1/0/all/0/1&quot;&gt;Atilim Gunes Baydin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cornish_R/0/1/0/all/0/1&quot;&gt;Robert Cornish&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rubio_D/0/1/0/all/0/1&quot;&gt;David Martinez Rubio&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schmidt_M/0/1/0/all/0/1&quot;&gt;Mark Schmidt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wood_F/0/1/0/all/0/1&quot;&gt;Frank Wood&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1705.04977">
<title>Detecting Statistical Interactions from Neural Network Weights. (arXiv:1705.04977v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1705.04977</link>
<description rdf:parseType="Literal">&lt;p&gt;We develop a method of detecting statistical interactions in data by directly
interpreting the trained weights of a feedforward multilayer neural network.
With regularization applied to the weights, our method can achieve similar
interaction detection performance compared to the state-of-the-art without
searching an exponential solution space of possible interactions. We obtain our
computational savings by first observing that interactions between input
features are created by the non-additive effect of nonlinear activation
functions, and that interacting paths are encoded in weight matrices. We use
these observations to develop a way of identifying interactions without
assuming their order or functional form via a simple traversal over the input
weight matrix. The generality of these interactions provides simultaneous
insight into the complex functions within feedforward networks and data. In
experiments, we demonstrate the performance of our method and the importance of
discovered interactions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tsang_M/0/1/0/all/0/1&quot;&gt;Michael Tsang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Cheng_D/0/1/0/all/0/1&quot;&gt;Dehua Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yan Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1708.02582">
<title>Cascade Adversarial Machine Learning Regularized with a Unified Embedding. (arXiv:1708.02582v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1708.02582</link>
<description rdf:parseType="Literal">&lt;p&gt;Injecting adversarial examples during training, known as adversarial
training, can improve robustness against one-step attacks, but not for unknown
iterative attacks. To address this challenge, we first show iteratively
generated adversarial images easily transfer between networks trained with the
same strategy. Inspired by this observation, we propose cascade adversarial
training, which transfers the knowledge of the end results of adversarial
training. We train a network from scratch by injecting iteratively generated
adversarial images crafted from already defended networks in addition to
one-step adversarial images from the network being trained. We also propose to
utilize embedding space for both classification and low-level (pixel-level)
similarity learning to ignore unknown pixel level perturbation. During
training, we inject adversarial images without replacing their corresponding
clean images and penalize the distance between the two embeddings (clean and
adversarial). Experimental results show that cascade adversarial training
together with our proposed low-level similarity learning efficiently enhances
the robustness against iterative attacks, but at the expense of decreased
robustness against one-step attacks. We show that combining those two
techniques can also improve robustness under the worst case black box attack
scenario.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Na_T/0/1/0/all/0/1&quot;&gt;Taesik Na&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ko_J/0/1/0/all/0/1&quot;&gt;Jong Hwan Ko&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mukhopadhyay_S/0/1/0/all/0/1&quot;&gt;Saibal Mukhopadhyay&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1708.06742">
<title>Twin Networks: Matching the Future for Sequence Generation. (arXiv:1708.06742v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1708.06742</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a simple technique for encouraging generative RNNs to plan ahead.
We train a &quot;backward&quot; recurrent network to generate a given sequence in reverse
order, and we encourage states of the forward model to predict cotemporal
states of the backward model. The backward network is used only during
training, and plays no role during sampling or inference. We hypothesize that
our approach eases modeling of long-term dependencies by implicitly forcing the
forward states to hold information about the longer-term future (as contained
in the backward states). We show empirically that our approach achieves 9%
relative improvement for a speech recognition task, and achieves significant
improvement on a COCO caption generation task.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Serdyuk_D/0/1/0/all/0/1&quot;&gt;Dmitriy Serdyuk&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ke_N/0/1/0/all/0/1&quot;&gt;Nan Rosemary Ke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sordoni_A/0/1/0/all/0/1&quot;&gt;Alessandro Sordoni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Trischler_A/0/1/0/all/0/1&quot;&gt;Adam Trischler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pal_C/0/1/0/all/0/1&quot;&gt;Chris Pal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bengio_Y/0/1/0/all/0/1&quot;&gt;Yoshua Bengio&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.00489">
<title>Don&apos;t Decay the Learning Rate, Increase the Batch Size. (arXiv:1711.00489v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1711.00489</link>
<description rdf:parseType="Literal">&lt;p&gt;It is common practice to decay the learning rate. Here we show one can
usually obtain the same learning curve on both training and test sets by
instead increasing the batch size during training. This procedure is successful
for stochastic gradient descent (SGD), SGD with momentum, Nesterov momentum,
and Adam. It reaches equivalent test accuracies after the same number of
training epochs, but with fewer parameter updates, leading to greater
parallelism and shorter training times. We can further reduce the number of
parameter updates by increasing the learning rate $\epsilon$ and scaling the
batch size $B \propto \epsilon$. Finally, one can increase the momentum
coefficient $m$ and scale $B \propto 1/(1-m)$, although this tends to slightly
reduce the test accuracy. Crucially, our techniques allow us to repurpose
existing training schedules for large batch training with no hyper-parameter
tuning. We train ResNet-50 on ImageNet to $76.1\%$ validation accuracy in under
30 minutes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Smith_S/0/1/0/all/0/1&quot;&gt;Samuel L. Smith&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kindermans_P/0/1/0/all/0/1&quot;&gt;Pieter-Jan Kindermans&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ying_C/0/1/0/all/0/1&quot;&gt;Chris Ying&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Le_Q/0/1/0/all/0/1&quot;&gt;Quoc V. Le&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.07436">
<title>Incremental Adversarial Domain Adaptation for Continually Changing Environments. (arXiv:1712.07436v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1712.07436</link>
<description rdf:parseType="Literal">&lt;p&gt;Continuous appearance shifts such as changes in weather and lighting
conditions can impact the performance of deployed machine learning models.
While unsupervised domain adaptation aims to address this challenge, current
approaches do not utilise the continuity of the occurring shifts. In
particular, many robotics applications exhibit these conditions and thus
facilitate the potential to incrementally adapt a learnt model over minor
shifts which integrate to massive differences over time. Our work presents an
adversarial approach for lifelong, incremental domain adaptation which benefits
from unsupervised alignment to a series of intermediate domains which
successively diverge from the labelled source domain. We empirically
demonstrate that our incremental approach improves handling of large appearance
changes, e.g. day to night, on a traversable-path segmentation task compared
with a direct, single alignment step approach. Furthermore, by approximating
the feature distribution for the source domain with a generative adversarial
network, the deployment module can be rendered fully independent of retaining
potentially large amounts of the related source training data for only a minor
reduction in performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wulfmeier_M/0/1/0/all/0/1&quot;&gt;Markus Wulfmeier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bewley_A/0/1/0/all/0/1&quot;&gt;Alex Bewley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Posner_I/0/1/0/all/0/1&quot;&gt;Ingmar Posner&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.10130">
<title>Spherical CNNs. (arXiv:1801.10130v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1801.10130</link>
<description rdf:parseType="Literal">&lt;p&gt;Convolutional Neural Networks (CNNs) have become the method of choice for
learning problems involving 2D planar images. However, a number of problems of
recent interest have created a demand for models that can analyze spherical
images. Examples include omnidirectional vision for drones, robots, and
autonomous cars, molecular regression problems, and global weather and climate
modelling. A naive application of convolutional networks to a planar projection
of the spherical signal is destined to fail, because the space-varying
distortions introduced by such a projection will make translational weight
sharing ineffective.
&lt;/p&gt;
&lt;p&gt;In this paper we introduce the building blocks for constructing spherical
CNNs. We propose a definition for the spherical cross-correlation that is both
expressive and rotation-equivariant. The spherical correlation satisfies a
generalized Fourier theorem, which allows us to compute it efficiently using a
generalized (non-commutative) Fast Fourier Transform (FFT) algorithm. We
demonstrate the computational efficiency, numerical accuracy, and effectiveness
of spherical CNNs applied to 3D model recognition and atomization energy
regression.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cohen_T/0/1/0/all/0/1&quot;&gt;Taco S. Cohen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Geiger_M/0/1/0/all/0/1&quot;&gt;Mario Geiger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koehler_J/0/1/0/all/0/1&quot;&gt;Jonas Koehler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Welling_M/0/1/0/all/0/1&quot;&gt;Max Welling&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.07384">
<title>Interpreting Neural Network Judgments via Minimal, Stable, and Symbolic Corrections. (arXiv:1802.07384v1 [cs.LG] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1802.07384</link>
<description rdf:parseType="Literal">&lt;p&gt;The paper describes a new algorithm to generate minimal, stable, and symbolic
corrections to an input that will cause a neural network with ReLU neurons to
change its output. We argue that such a correction is a useful way to provide
feedback to a user when the neural network produces an output that is different
from a desired output. Our algorithm generates such a correction by solving a
series of linear constraint satisfaction problems. The technique is evaluated
on a neural network that has been trained to predict whether an applicant will
pay a mortgage.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xin Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Solar_Lezama_A/0/1/0/all/0/1&quot;&gt;Armando Solar-Lezama&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singh_R/0/1/0/all/0/1&quot;&gt;Rishabh Singh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08530">
<title>Training wide residual networks for deployment using a single bit for each weight. (arXiv:1802.08530v1 [cs.LG] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1802.08530</link>
<description rdf:parseType="Literal">&lt;p&gt;For fast and energy-efficient deployment of trained deep neural networks on
resource-constrained embedded hardware, each learned weight parameter should
ideally be represented and stored using a single bit. Error-rates usually
increase when this requirement is imposed. Here, we report large improvements
in error rates on multiple datasets, for deep convolutional neural networks
deployed with 1-bit-per-weight. Using wide residual networks as our main
baseline, our approach simplifies existing methods that binarize weights by
applying the sign function in training; we apply scaling factors for each layer
with constant unlearned values equal to the layer-specific standard deviations
used for initialization. For CIFAR-10, CIFAR-100 and ImageNet, and models with
1-bit-per-weight requiring less than 10 MB of parameter memory, we achieve
error rates of 3.9%, 18.5% and 26.0% / 8.5% (Top-1 / Top-5) respectively. We
also considered MNIST, SVHN and ImageNet32, achieving 1-bit-per-weight test
results of 0.27%, 1.9%, and 41.3% / 19.1% respectively. For CIFAR, our error
rates halve previously reported values, and are within about 1% of our
error-rates for the same network with full-precision weights. For networks that
overfit, we also show significant improvements in error rate by not learning
batch normalization scale and offset parameters. This applies to both full
precision and 1-bit-per-weight networks. Using a warm-restart learning-rate
schedule, we found that training for 1-bit-per-weight is just as fast as
full-precision networks, with better accuracy than standard schedules, and
achieved about 98%-99% of peak performance in just 62 training epochs for
CIFAR-10/100. For full training code and trained models in MATLAB, Keras and
PyTorch see https://github.com/McDonnell-Lab/1-bit-per-weight/ .
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+McDonnell_M/0/1/0/all/0/1&quot;&gt;Mark D. McDonnell&lt;/a&gt;</dc:creator>
</item></rdf:RDF>