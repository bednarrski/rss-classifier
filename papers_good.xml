<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Good papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Good Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-08-21T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.06604"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.06661"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1706.02596"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.06675"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.06880"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.06885"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.06907"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.06934"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.07004"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.07036"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.07042"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.09702"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.03782"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.01183"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.01251"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.04926"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.06645"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.06671"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.06725"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.06791"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.06809"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.06940"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.07018"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.04129"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.08774"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.06148"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1808.06604">
<title>Artificial Neural Networks in Fluid Dynamics: A Novel Approach to the Navier-Stokes Equations. (arXiv:1808.06604v1 [cs.NA])</title>
<link>http://arxiv.org/abs/1808.06604</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural networks have been used to solve different types of large data related
problems in many different fields.This project takes a novel approach to
solving the Navier-Stokes Equations for turbulence by training a neural network
using Bayesian Cluster and SOM neighbor weighting to map ionospheric velocity
fields based on 3-dimensional inputs. Parameters used in this problem included
the velocity, Reynolds number, Prandtl number, and temperature. In this project
data was obtained from Johns-Hopkins University to train the neural network
using MATLAB. The neural network was able to map the velocity fields within a
sixty-seven percent accuracy of the validation data used. Further studies will
focus on higher accuracy and solving further non-linear differential equations
using convolutional neural networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+McCracken_M/0/1/0/all/0/1&quot;&gt;Megan McCracken&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.06661">
<title>A Hybrid DE Approach to Designing CNN for Image Classification. (arXiv:1808.06661v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1808.06661</link>
<description rdf:parseType="Literal">&lt;p&gt;Convolutional Neural Networks (CNNs) have demonstrated their superiority in
image classification, and evolutionary computation (EC) methods have recently
been surging to automatically design the architectures of CNNs to save the
tedious work of manually designing CNNs. In this paper, a new hybrid
differential evolution (DE) algorithm with a newly added crossover operator is
proposed to evolve the architectures of CNNs of any lengths, which is named
DECNN. There are three new ideas in the proposed DECNN method. Firstly, an
existing effective encoding scheme is refined to cater for variable-length CNN
architectures; Secondly, the new mutation and crossover operators are developed
for variable-length DE to optimise the hyperparameters of CNNs; Finally, the
new second crossover is introduced to evolve the depth of the CNN
architectures. The proposed algorithm is tested on six widely-used benchmark
datasets and the results are compared to 12 state-of-the-art methods, which
shows the proposed method is vigorously competitive to the state-of-the-art
algorithms. Furthermore, the proposed method is also compared with a method
using particle swarm optimisation with a similar encoding strategy named IPPSO,
and the proposed DECNN outperforms IPPSO in terms of the accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1&quot;&gt;Bin Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1&quot;&gt;Yanan Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xue_B/0/1/0/all/0/1&quot;&gt;Bing Xue&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1&quot;&gt;Mengjie Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1706.02596">
<title>Dynamic Integration of Background Knowledge in Neural NLU Systems. (arXiv:1706.02596v3 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1706.02596</link>
<description rdf:parseType="Literal">&lt;p&gt;Common-sense and background knowledge is required to understand natural
language, but in most neural natural language understanding (NLU) systems, this
knowledge must be acquired from training corpora during learning, and then it
is static at test time. We introduce a new architecture for the dynamic
integration of explicit background knowledge in NLU models. A general-purpose
reading module reads background knowledge in the form of free-text statements
(together with task-specific text inputs) and yields refined word
representations to a task-specific NLU architecture that reprocesses the task
inputs with these representations. Experiments on document question answering
(DQA) and recognizing textual entailment (RTE) demonstrate the effectiveness
and flexibility of the approach. Analysis shows that our model learns to
exploit knowledge in a semantically appropriate way.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Weissenborn_D/0/1/0/all/0/1&quot;&gt;Dirk Weissenborn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kocisky_T/0/1/0/all/0/1&quot;&gt;Tom&amp;#xe1;&amp;#x161; Ko&amp;#x10d;isk&amp;#xfd;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dyer_C/0/1/0/all/0/1&quot;&gt;Chris Dyer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.06675">
<title>Class2Str: End to End Latent Hierarchy Learning. (arXiv:1808.06675v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1808.06675</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep neural networks for image classification typically consists of a
convolutional feature extractor followed by a fully connected classifier
network. The predicted and the ground truth labels are represented as one hot
vectors. Such a representation assumes that all classes are equally dissimilar.
However, classes have visual similarities and often form a hierarchy. Learning
this latent hierarchy explicitly in the architecture could provide invaluable
insights. We propose an alternate architecture to the classifier network called
the Latent Hierarchy (LH) Classifier and an end to end learned Class2Str
mapping which discovers a latent hierarchy of the classes. We show that for
some of the best performing architectures on CIFAR and Imagenet datasets, the
proposed replacement and training by LH classifier recovers the accuracy, with
a fraction of the number of parameters in the classifier part. Compared to the
previous work of HDCNN, which also learns a 2 level hierarchy, we are able to
learn a hierarchy at an arbitrary number of levels as well as obtain an
accuracy improvement on the Imagenet classification task over them. We also
verify that many visually similar classes are grouped together, under the
learnt hierarchy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saha_S/0/1/0/all/0/1&quot;&gt;Soham Saha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Varma_G/0/1/0/all/0/1&quot;&gt;Girish Varma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jawahar_C/0/1/0/all/0/1&quot;&gt;C.V.Jawahar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.06880">
<title>Automatic Generation of Text Descriptive Comments for Code Blocks. (arXiv:1808.06880v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1808.06880</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a framework to automatically generate descriptive comments for
source code blocks. While this problem has been studied by many researchers
previously, their methods are mostly based on fixed template and achieves poor
results. Our framework does not rely on any template, but makes use of a new
recursive neural network called Code-RNN to extract features from the source
code and embed them into one vector. When this vector representation is input
to a new recurrent neural network (Code-GRU), the overall framework generates
text descriptions of the code with accuracy (Rouge-2 value) significantly
higher than other learning-based approaches such as sequence-to-sequence model.
The Code-RNN model can also be used in other scenario where the representation
of code is required.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1&quot;&gt;Yuding Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_K/0/1/0/all/0/1&quot;&gt;Kenny Q. Zhu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.06885">
<title>Multi-Source Pointer Network for Product Title Summarization. (arXiv:1808.06885v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1808.06885</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we study the product title summarization problem in E-commerce
applications for display on mobile devices. Comparing with conventional
sentence summarization, product title summarization has some extra and
essential constraints. For example, factual errors or loss of the key
information are intolerable for E-commerce applications. Therefore, we abstract
two more constraints for product title summarization: (i) do not introduce
irrelevant information; (ii) retain the key information (e.g., brand name and
commodity name). To address these issues, we propose a novel multi-source
pointer network by adding a new knowledge encoder for pointer network. The
first constraint is handled by pointer mechanism. For the second constraint, we
restore the key information by copying words from the knowledge encoder with
the help of the soft gating mechanism. For evaluation, we build a large
collection of real-world product titles along with human-written short titles.
Experimental results demonstrate that our model significantly outperforms the
other baselines. Finally, online deployment of our proposed model has yielded a
significant business impact, as measured by the click-through rate.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_F/0/1/0/all/0/1&quot;&gt;Fei Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_P/0/1/0/all/0/1&quot;&gt;Peng Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1&quot;&gt;Hanxiao Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pei_C/0/1/0/all/0/1&quot;&gt;Changhua Pei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ou_W/0/1/0/all/0/1&quot;&gt;Wenwu Ou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;Xiaobo Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.06907">
<title>The Variable Quality of Metadata About Biological Samples Used in Biomedical Experiments. (arXiv:1808.06907v1 [cs.DB])</title>
<link>http://arxiv.org/abs/1808.06907</link>
<description rdf:parseType="Literal">&lt;p&gt;We present an analytical study of the quality of metadata about samples used
in biomedical experiments. The metadata under analysis are stored in two well-
known databases: BioSample---a repository managed by the National Center for
Biotechnology Information (NCBI), and BioSamples---a repository managed by the
European Bioinformatics Institute (EBI). We tested whether 11.4M sample
metadata records in the two repositories are populated with values that fulfill
the stated requirements for such values. Our study revealed multiple anomalies
in the metadata. Most metadata field names and their values are not
standardized or controlled. Even simple binary or numeric fields are often
populated with inadequate values of different data types. By clustering
metadata field names, we discovered there are often many distinct ways to
represent the same aspect of a sample. Overall, the metadata we analyzed reveal
that there is a lack of principled mechanisms to enforce and validate metadata
requirements. The significant aberrancies that we found in the metadata are
likely to impede search and secondary use of the associated datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goncalves_R/0/1/0/all/0/1&quot;&gt;Rafael S. Gon&amp;#xe7;alves&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Musen_M/0/1/0/all/0/1&quot;&gt;Mark A. Musen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.06934">
<title>Backpropagation and Biological Plausibility. (arXiv:1808.06934v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1808.06934</link>
<description rdf:parseType="Literal">&lt;p&gt;By and large, Backpropagation (BP) is regarded as one of the most important
neural computation algorithms at the basis of the progress in machine learning,
including the recent advances in deep learning. However, its computational
structure has been the source of many debates on its arguable biological
plausibility. In this paper, it is shown that when framing supervised learning
in the Lagrangian framework, while one can see a natural emergence of
Backpropagation, biologically plausible local algorithms can also be devised
that are based on the search for saddle points in the learning adjoint space
composed of weights, neural outputs, and Lagrangian multipliers. This might
open the doors to a truly novel class of learning algorithms where, because of
the introduction of the notion of support neurons, the optimization scheme also
plays a fundamental role in the construction of the architecture.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Betti_A/0/1/0/all/0/1&quot;&gt;Alessandro Betti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gori_M/0/1/0/all/0/1&quot;&gt;Marco Gori&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Marra_G/0/1/0/all/0/1&quot;&gt;Giuseppe Marra&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.07004">
<title>Mathematics as information compression via the matching and unification of patterns. (arXiv:1808.07004v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1808.07004</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper describes a novel perspective on the foundations of mathematics:
how mathematics may be seen to be largely about &apos;information compression via
the matching and unification of patterns&apos; (ICMUP). ICMUP is itself a novel
approach to information compression, couched in terms of non-mathematical
primitives, as is necessary in any investigation of the foundations of
mathematics. This new perspective on the foundations of mathematics has grown
out of an extensive programme of research developing the &quot;SP Theory of
Intelligence&quot; and its realisation in the &quot;SP Computer Model&quot;, a system in which
a generalised version of ICMUP -- the powerful concept of SP-multiple-alignment
-- plays a central role. These ideas may be seen to be part of a &quot;Big Picture&quot;
comprising six areas of interest, with information compression as a unifying
theme. The paper describes the close relation between mathematics and
information compression, and describes examples showing how variants of ICMUP
may be seen in widely-used structures and operations in mathematics. Examples
are also given to show how the mathematics-related disciplines of logic and
computing may be understood as ICMUP. There are many potential benefits and
applications of these ideas.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wolff_J/0/1/0/all/0/1&quot;&gt;J Gerard Wolff&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.07036">
<title>QuAC : Question Answering in Context. (arXiv:1808.07036v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1808.07036</link>
<description rdf:parseType="Literal">&lt;p&gt;We present QuAC, a dataset for Question Answering in Context that contains
14K information-seeking QA dialogs (100K questions in total). The interactions
involve two crowd workers: (1) a student who poses a sequence of freeform
questions to learn as much as possible about a hidden Wikipedia text, and (2) a
teacher who answers the questions by providing short excerpts from the text.
QuAC introduces challenges not found in existing machine comprehension
datasets: its questions are often more open-ended, unanswerable, or only
meaningful within the dialog context, as we show in a detailed qualitative
evaluation. We also report results for a number of reference models, including
a recently state-of-the-art reading comprehension architecture extended to
model dialog context. Our best model underperforms humans by 20 F1, suggesting
that there is significant room for future work on this data. Dataset, baseline,
and leaderboard are available at quac.ai.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Choi_E/0/1/0/all/0/1&quot;&gt;Eunsol Choi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_H/0/1/0/all/0/1&quot;&gt;He He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Iyyer_M/0/1/0/all/0/1&quot;&gt;Mohit Iyyer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yatskar_M/0/1/0/all/0/1&quot;&gt;Mark Yatskar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yih_W/0/1/0/all/0/1&quot;&gt;Wen-tau Yih&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Choi_Y/0/1/0/all/0/1&quot;&gt;Yejin Choi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_P/0/1/0/all/0/1&quot;&gt;Percy Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zettlemoyer_L/0/1/0/all/0/1&quot;&gt;Luke Zettlemoyer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.07042">
<title>CoQA: A Conversational Question Answering Challenge. (arXiv:1808.07042v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1808.07042</link>
<description rdf:parseType="Literal">&lt;p&gt;Humans gather information by engaging in conversations involving a series of
interconnected questions and answers. For machines to assist in information
gathering, it is therefore essential to enable them to answer conversational
questions. We introduce CoQA, a novel dataset for building Conversational
Question Answering systems. Our dataset contains 127k questions with answers,
obtained from 8k conversations about text passages from seven diverse domains.
The questions are conversational, and the answers are free-form text with their
corresponding evidence highlighted in the passage. We analyze CoQA in depth and
show that conversational questions have challenging phenomena not present in
existing reading comprehension datasets, e.g., coreference and pragmatic
reasoning. We evaluate strong conversational and reading comprehension models
on CoQA. The best system obtains an F1 score of 65.1%, which is 23.7 points
behind human performance (88.8%), indicating there is ample room for
improvement. We launch CoQA as a challenge to the community at
&lt;a href=&quot;http://stanfordnlp.github.io/coqa/&quot;&gt;this http URL&lt;/a&gt;
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Reddy_S/0/1/0/all/0/1&quot;&gt;Siva Reddy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1&quot;&gt;Danqi Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Manning_C/0/1/0/all/0/1&quot;&gt;Christopher D. Manning&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.09702">
<title>HAMLET: Interpretable Human And Machine co-LEarning Technique. (arXiv:1803.09702v3 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1803.09702</link>
<description rdf:parseType="Literal">&lt;p&gt;Efficient label acquisition processes are key to obtaining robust
classifiers. However, data labeling is often challenging and subject to high
levels of label noise. This can arise even when classification targets are well
defined, if instances to be labeled are more difficult than the prototypes used
to define the class, leading to disagreements among the expert community. Here,
we enable efficient training of deep neural networks. From low-confidence
labels, we iteratively improve their quality by simultaneous learning of
machines and experts. We call it Human And Machine co-LEarning Technique
(HAMLET). Throughout the process, experts become more consistent, while the
algorithm provides them with explainable feedback for confirmation. HAMLET uses
a neural embedding function and a memory module filled with diverse reference
embeddings from different classes. Its output includes classification labels
and highly relevant reference embeddings as explanation. We took the study of
brain monitoring at intensive care unit (ICU) as an application of HAMLET on
continuous electroencephalography (cEEG) data. Although cEEG monitoring yields
large volumes of data, labeling costs and difficulty make it hard to build a
classifier. Additionally, while experts agree on the labels of clear-cut
examples of cEEG patterns, labeling many real-world cEEG data can be extremely
challenging. Thus, a large minority of sequences might be mislabeled. HAMLET
has shown significant performance gain against deep learning and other
baselines, increasing accuracy from 7.03% to 68.75% on challenging inputs.
Besides improved performance, clinical experts confirmed the interpretability
of those reference embeddings in helping explaining the classification results
by HAMLET.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deiss_O/0/1/0/all/0/1&quot;&gt;Olivier Deiss&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Biswal_S/0/1/0/all/0/1&quot;&gt;Siddharth Biswal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jin_J/0/1/0/all/0/1&quot;&gt;Jing Jin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1&quot;&gt;Haoqi Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Westover_M/0/1/0/all/0/1&quot;&gt;M. Brandon Westover&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1&quot;&gt;Jimeng Sun&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.03782">
<title>CoT: Cooperative Training for Generative Modeling of Discrete Data. (arXiv:1804.03782v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1804.03782</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose Cooperative Training (CoT) for training generative models that
measure a tractable density for discrete data. CoT coordinately trains a
generator $G$ and an auxiliary predictive mediator $M$. The training target of
$M$ is to estimate a mixture density of the learned distribution $G$ and the
target distribution $P$, and that of $G$ is to minimize the Jensen-Shannon
divergence estimated through $M$. CoT achieves independent success without the
necessity of pre-training via Maximum Likelihood Estimation or involving
high-variance algorithms like REINFORCE. This low-variance algorithm is
theoretically proved to be unbiased for both generative and predictive tasks.
We also theoretically and empirically show the superiority of CoT over most
previous algorithms in terms of generative quality and diversity, predictive
generalization ability and computational cost.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_S/0/1/0/all/0/1&quot;&gt;Sidi Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_L/0/1/0/all/0/1&quot;&gt;Lantao Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1&quot;&gt;Weinan Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1&quot;&gt;Yong Yu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.01183">
<title>Quantified Markov Logic Networks. (arXiv:1807.01183v3 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1807.01183</link>
<description rdf:parseType="Literal">&lt;p&gt;Markov Logic Networks (MLNs) are well-suited for expressing statistics such
as &quot;with high probability a smoker knows another smoker&quot; but not for expressing
statements such as &quot;there is a smoker who knows most other smokers&quot;, which is
necessary for modeling, e.g. influencers in social networks. To overcome this
shortcoming, we study quantified MLNs which generalize MLNs by introducing
statistical universal quantifiers, allowing to express also the latter type of
statistics in a principled way. Our main technical contribution is to show that
the standard reasoning tasks in quantified MLNs, maximum a posteriori and
marginal inference, can be reduced to their respective MLN counterparts in
polynomial time.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gutierrez_Basulto_V/0/1/0/all/0/1&quot;&gt;V&amp;#xed;ctor Guti&amp;#xe9;rrez-Basulto&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jung_J/0/1/0/all/0/1&quot;&gt;Jean Christoph Jung&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kuzelka_O/0/1/0/all/0/1&quot;&gt;Ondrej Kuzelka&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.01251">
<title>Training behavior of deep neural network in frequency domain. (arXiv:1807.01251v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1807.01251</link>
<description rdf:parseType="Literal">&lt;p&gt;Why deep neural networks (DNNs) capable of overfitting often generalize well
in practice is a mystery in deep learning. Existing works indicate that this
observation holds for both complicated real datasets and simple datasets of
one-dimensional (1-d) functions. In this work, for natural images and
low-frequency dominant 1-d functions, we empirically found that a DNN with
common settings first quickly captures the dominant low-frequency components,
and then relatively slowly captures high-frequency ones. We call this
phenomenon Frequency Principle (F-Principle). F-Principle can be observed over
various DNN setups of different activation functions, layer structures and
training algorithms in our experiments. F-Principle can be used to understand
(i) the behavior of DNN training in the information plane and (ii) why DNNs
often generalize well albeit its ability of overfitting. This F-Principle
potentially can provide insights into understanding the general principle
underlying DNN optimization and generalization for real datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1&quot;&gt;Zhi-Qin J. Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yaoyu Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiao_Y/0/1/0/all/0/1&quot;&gt;Yanyang Xiao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.04926">
<title>How Much Reading Does Reading Comprehension Require? A Critical Investigation of Popular Benchmarks. (arXiv:1808.04926v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1808.04926</link>
<description rdf:parseType="Literal">&lt;p&gt;Many recent papers address reading comprehension, where examples consist of
(question, passage, answer) tuples. Presumably, a model must combine
information from both questions and passages to predict corresponding answers.
However, despite intense interest in the topic, with hundreds of published
papers vying for leaderboard dominance, basic questions about the difficulty of
many popular benchmarks remain unanswered. In this paper, we establish sensible
baselines for the bAbI, SQuAD, CBT, CNN, and Who-did-What datasets, finding
that question- and passage-only models often perform surprisingly well. On $14$
out of $20$ bAbI tasks, passage-only models achieve greater than $50\%$
accuracy, sometimes matching the full model. Interestingly, while CBT provides
$20$-sentence stories only the last is needed for comparably accurate
prediction. By comparison, SQuAD and CNN appear better-constructed.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kaushik_D/0/1/0/all/0/1&quot;&gt;Divyansh Kaushik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lipton_Z/0/1/0/all/0/1&quot;&gt;Zachary C. Lipton&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.06645">
<title>Stochastic Combinatorial Ensembles for Defending Against Adversarial Examples. (arXiv:1808.06645v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1808.06645</link>
<description rdf:parseType="Literal">&lt;p&gt;Many deep learning algorithms can be easily fooled with simple adversarial
examples. To address the limitations of existing defenses, we devised a
probabilistic framework that can generate an exponentially large ensemble of
models from a single model with just a linear cost. This framework takes
advantage of neural network depth and stochastically decides whether or not to
insert noise removal operators such as VAEs between layers. We show empirically
the important role that model gradients have when it comes to determining
transferability of adversarial examples, and take advantage of this result to
demonstrate that it is possible to train models with limited adversarial attack
transferability. Additionally, we propose a detection method based on metric
learning in order to detect adversarial examples that have no hope of being
cleaned of maliciously engineered noise.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Adam_G/0/1/0/all/0/1&quot;&gt;George A. Adam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Smirnov_P/0/1/0/all/0/1&quot;&gt;Petr Smirnov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goldenberg_A/0/1/0/all/0/1&quot;&gt;Anna Goldenberg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Duvenaud_D/0/1/0/all/0/1&quot;&gt;David Duvenaud&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Haibe_Kains_B/0/1/0/all/0/1&quot;&gt;Benjamin Haibe-Kains&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.06671">
<title>Adversarial Sampling for Active Learning. (arXiv:1808.06671v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1808.06671</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper describes ASAL a new active learning strategy that uses
uncertainty sampling, adversarial sample generation and sample matching.
Compared to traditional pool-based uncertainty sampling strategies, ASAL
synthesizes uncertain samples instead of performing an exhaustive search in
each active learning cycle. Then, the sample matching efficiently selects
similar samples from the pool. We present a comprehensive set of experiments on
MNIST and CIFAR-10 and show that ASAL outperforms similar methods and clearly
exceeds passive learning. To the best of our knowledge this is the first
pool-based adversarial active learning technique and the first that is applied
for multi-label classification using deep convolutional classifiers.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mayer_C/0/1/0/all/0/1&quot;&gt;Christoph Mayer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Timofte_R/0/1/0/all/0/1&quot;&gt;Radu Timofte&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.06725">
<title>Learning to Exploit Invariances in Clinical Time-Series Data using Sequence Transformer Networks. (arXiv:1808.06725v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1808.06725</link>
<description rdf:parseType="Literal">&lt;p&gt;Recently, researchers have started applying convolutional neural networks
(CNNs) with one-dimensional convolutions to clinical tasks involving
time-series data. This is due, in part, to their computational efficiency,
relative to recurrent neural networks and their ability to efficiently exploit
certain temporal invariances, (e.g., phase invariance). However, it is
well-established that clinical data may exhibit many other types of invariances
(e.g., scaling). While preprocessing techniques, (e.g., dynamic time warping)
may successfully transform and align inputs, their use often requires one to
identify the types of invariances in advance. In contrast, we propose the use
of Sequence Transformer Networks, an end-to-end trainable architecture that
learns to identify and account for invariances in clinical time-series data.
Applied to the task of predicting in-hospital mortality, our proposed approach
achieves an improvement in the area under the receiver operating characteristic
curve (AUROC) relative to a baseline CNN (AUROC=0.851 vs. AUROC=0.838). Our
results suggest that a variety of valuable invariances can be learned directly
from the data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oh_J/0/1/0/all/0/1&quot;&gt;Jeeheh Oh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jiaxuan Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wiens_J/0/1/0/all/0/1&quot;&gt;Jenna Wiens&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.06791">
<title>LRMM: Learning to Recommend with Missing Modalities. (arXiv:1808.06791v1 [cs.IR])</title>
<link>http://arxiv.org/abs/1808.06791</link>
<description rdf:parseType="Literal">&lt;p&gt;Multimodal learning has shown promising performance in content-based
recommendation due to the auxiliary user and item information of multiple
modalities such as text and images. However, the problem of incomplete and
missing modality is rarely explored and most existing methods fail in learning
a recommendation model with missing or corrupted modalities. In this paper, we
propose LRMM, a novel framework that mitigates not only the problem of missing
modalities but also more generally the cold-start problem of recommender
systems. We propose modality dropout (m-drop) and a multimodal sequential
autoencoder (m-auto) to learn multimodal representations for complementing and
imputing missing modalities. Extensive experiments on real-world Amazon data
show that LRMM achieves state-of-the-art performance on rating prediction
tasks. More importantly, LRMM is more robust to previous methods in alleviating
data-sparsity and the cold-start problem.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1&quot;&gt;Cheng Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Niepert_M/0/1/0/all/0/1&quot;&gt;Mathias Niepert&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1&quot;&gt;Hui Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.06809">
<title>Are You Tampering With My Data?. (arXiv:1808.06809v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1808.06809</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a novel approach towards adversarial attacks on neural networks
(NN), focusing on tampering the data used for training instead of generating
attacks on trained models. Our network-agnostic method creates a backdoor
during training which can be exploited at test time to force a neural network
to exhibit abnormal behaviour. We demonstrate on two widely used datasets
(CIFAR-10 and SVHN) that a universal modification of just one pixel per image
for all the images of a class in the training set is enough to corrupt the
training procedure of several state-of-the-art deep neural networks causing the
networks to misclassify any images to which the modification is applied. Our
aim is to bring to the attention of the machine learning community, the
possibility that even learning-based methods that are personally trained on
public datasets can be subject to attacks by a skillful adversary.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alberti_M/0/1/0/all/0/1&quot;&gt;Michele Alberti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pondenkandath_V/0/1/0/all/0/1&quot;&gt;Vinaychandran Pondenkandath&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wursch_M/0/1/0/all/0/1&quot;&gt;Marcel W&amp;#xfc;rsch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bouillon_M/0/1/0/all/0/1&quot;&gt;Manuel Bouillon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Seuret_M/0/1/0/all/0/1&quot;&gt;Mathias Seuret&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ingold_R/0/1/0/all/0/1&quot;&gt;Rolf Ingold&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liwicki_M/0/1/0/all/0/1&quot;&gt;Marcus Liwicki&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.06940">
<title>End to End Vehicle Lateral Control Using a Single Fisheye Camera. (arXiv:1808.06940v1 [cs.RO])</title>
<link>http://arxiv.org/abs/1808.06940</link>
<description rdf:parseType="Literal">&lt;p&gt;Convolutional neural networks are commonly used to control the steering angle
for autonomous cars. Most of the time, multiple long range cameras are used to
generate lateral failure cases. In this paper we present a novel model to
generate this data and label augmentation using only one short range fisheye
camera. We present our simulator and how it can be used as a consistent metric
for lateral end-to-end control evaluation. Experiments are conducted on a
custom dataset corresponding to more than 10000 km and 200 hours of open road
driving. Finally we evaluate this model on real world driving scenarios, open
road and a custom test track with challenging obstacle avoidance and sharp
turns. In our simulator based on real-world videos, the final model was capable
of more than 99% autonomy on urban road
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Toromanoff_M/0/1/0/all/0/1&quot;&gt;Marin Toromanoff&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wirbel_E/0/1/0/all/0/1&quot;&gt;Emilie Wirbel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wilhelm_F/0/1/0/all/0/1&quot;&gt;Fr&amp;#xe9;d&amp;#xe9;ric Wilhelm&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vejarano_C/0/1/0/all/0/1&quot;&gt;Camilo Vejarano&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Perrotton_X/0/1/0/all/0/1&quot;&gt;Xavier Perrotton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moutarde_F/0/1/0/all/0/1&quot;&gt;Fabien Moutarde&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.07018">
<title>Hypernetwork Knowledge Graph Embeddings. (arXiv:1808.07018v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1808.07018</link>
<description rdf:parseType="Literal">&lt;p&gt;Knowledge graphs are large graph-structured databases of facts, which
typically suffer from incompleteness. Link prediction is the task of inferring
missing relations (links) between entities (nodes) in a knowledge graph. We
propose to solve this task by using a hypernetwork architecture to generate
convolutional layer filters specific to each relation and apply those filters
to the subject entity embeddings. This architecture enables a trade-off between
non-linear expressiveness and the number of parameters to learn. Our model
simplifies the entity and relation embedding interactions introduced by the
predecessor convolutional model, while outperforming all previous approaches to
link prediction across all standard link prediction datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Balazevic_I/0/1/0/all/0/1&quot;&gt;Ivana Balazevic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Allen_C/0/1/0/all/0/1&quot;&gt;Carl Allen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hospedales_T/0/1/0/all/0/1&quot;&gt;Timothy M. Hospedales&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.04129">
<title>Outlier Detection by Consistent Data Selection Method. (arXiv:1712.04129v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1712.04129</link>
<description rdf:parseType="Literal">&lt;p&gt;Often the challenge associated with tasks like fraud and spam detection[1] is
the lack of all likely patterns needed to train suitable supervised learning
models. In order to overcome this limitation, such tasks are attempted as
outlier or anomaly detection tasks. We also hypothesize that out- liers have
behavioral patterns that change over time. Limited data and continuously
changing patterns makes learning significantly difficult. In this work we are
proposing an approach that detects outliers in large data sets by relying on
data points that are consistent. The primary contribution of this work is that
it will quickly help retrieve samples for both consistent and non-outlier data
sets and is also mindful of new outlier patterns. No prior knowledge of each
set is required to extract the samples. The method consists of two phases, in
the first phase, consistent data points (non- outliers) are retrieved by an
ensemble method of unsupervised clustering techniques and in the second phase a
one class classifier trained on the consistent data point set is ap- plied on
the remaining sample set to identify the outliers. The approach is tested on
three publicly available data sets and the performance scores are competitive.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Porwal_U/0/1/0/all/0/1&quot;&gt;Utkarsh Porwal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mukund_S/0/1/0/all/0/1&quot;&gt;Smruthi Mukund&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.08774">
<title>Neural-Brane: Neural Bayesian Personalized Ranking for Attributed Network Embedding. (arXiv:1804.08774v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1804.08774</link>
<description rdf:parseType="Literal">&lt;p&gt;Network embedding methodologies, which learn a distributed vector
representation for each vertex in a network, have attracted considerable
interest in recent years. Existing works have demonstrated that vertex
representation learned through an embedding method provides superior
performance in many real-world applications, such as node classification, link
prediction, and community detection. However, most of the existing methods for
network embedding only utilize topological information of a vertex, ignoring a
rich set of nodal attributes (such as, user profiles of an online social
network, or textual contents of a citation network), which is abundant in all
real-life networks. A joint network embedding that takes into account both
attributional and relational information entails a complete network information
and could further enrich the learned vector representations. In this work, we
present Neural-Brane, a novel Neural Bayesian Personalized Ranking based
Attributed Network Embedding. For a given network, Neural-Brane extracts latent
feature representation of its vertices using a designed neural network model
that unifies network topological information and nodal attributes; Besides, it
utilizes Bayesian personalized ranking objective, which exploits the proximity
ordering between a similar node-pair and a dissimilar node-pair. We evaluate
the quality of vertex embedding produced by Neural-Brane by solving the node
classification and clustering tasks on four real-world datasets. Experimental
results demonstrate the superiority of our proposed method over the
state-of-the-art existing methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dave_V/0/1/0/all/0/1&quot;&gt;Vachik S. Dave&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1&quot;&gt;Baichuan Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_P/0/1/0/all/0/1&quot;&gt;Pin-Yu Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hasan_M/0/1/0/all/0/1&quot;&gt;Mohammad Al Hasan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.06148">
<title>Generalized Bregman and Jensen divergences which include some f-divergences. (arXiv:1808.06148v1 [math.ST] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1808.06148</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we introduce new classes of divergences by extending the
definitions of the Bregman divergence and the skew Jensen divergence. These new
divergence classes (g-Bregman divergence and skew g-Jensen divergence) satisfy
some properties similar to the Bregman or skew Jensen divergence. We show these
g-divergences include divergences which belong to a class of f-divergence (the
Hellinger distance, the chi-square divergence and the alpha-divergence in
addition to the Kullback-Leibler divergence). Moreover, we derive an inequality
between the skew g-Jensen divergence and the g-Bregman divergence and show this
inequality is a generalization of Lin&apos;s inequality.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Nishiyama_T/0/1/0/all/0/1&quot;&gt;Tomohiro Nishiyama&lt;/a&gt;</dc:creator>
</item></rdf:RDF>