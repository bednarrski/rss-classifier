<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Good papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Good Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-08-15T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.10837"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.02234"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.04926"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.05006"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1706.07269"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.11070"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07340"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.04839"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.04873"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.04883"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.04888"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.04947"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.05054"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.05110"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.05128"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.05163"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.04272"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05394"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.11156"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.00245"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.04572"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1803.10837">
<title>Learning Deep Representations with Probabilistic Knowledge Transfer. (arXiv:1803.10837v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1803.10837</link>
<description rdf:parseType="Literal">&lt;p&gt;Knowledge Transfer (KT) techniques tackle the problem of transferring the
knowledge from a large and complex neural network into a smaller and faster
one. However, existing KT methods are tailored towards classification tasks and
they cannot be used efficiently for other representation learning tasks. In
this paper a novel knowledge transfer technique, that is capable of training a
student model that maintains the same amount of mutual information between the
learned representation and a set of (possible unknown) labels as the teacher
model, is proposed. Apart from outperforming existing KT techniques, the
proposed method allows for overcoming several limitations of existing methods
providing new insight into KT as well as novel KT applications, ranging from
knowledge transfer from handcrafted feature extractors to {cross-modal} KT from
the textual modality into the representation extracted from the visual modality
of the data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Passalis_N/0/1/0/all/0/1&quot;&gt;Nikolaos Passalis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tefas_A/0/1/0/all/0/1&quot;&gt;Anastasios Tefas&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.02234">
<title>Deep Stacked Stochastic Configuration Networks for Non-Stationary Data Streams. (arXiv:1808.02234v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1808.02234</link>
<description rdf:parseType="Literal">&lt;p&gt;The concept of stochastic configuration networks (SCNs) others a solid
framework for fast implementation of feedforward neural networks through
randomized learning. Unlike conventional randomized approaches, SCNs provide an
avenue to select appropriate scope of random parameters to ensure the universal
approximation property. In this paper, a deep version of stochastic
configuration networks, namely deep stacked stochastic configuration network
(DSSCN), is proposed for modeling non-stationary data streams. As an extension
of evolving stochastic connfiguration networks (eSCNs), this work contributes a
way to grow and shrink the structure of deep stochastic configuration networks
autonomously from data streams. The performance of DSSCN is evaluated by six
benchmark datasets. Simulation results, compared with prominent data stream
algorithms, show that the proposed method is capable of achieving comparable
accuracy and evolving compact and parsimonious deep stacked network
architecture.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pratama_M/0/1/0/all/0/1&quot;&gt;Mahardhika Pratama&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1&quot;&gt;Dianhui Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.04926">
<title>How Much Reading Does Reading Comprehension Require? A Critical Investigation of Popular Benchmarks. (arXiv:1808.04926v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1808.04926</link>
<description rdf:parseType="Literal">&lt;p&gt;Many recent papers address reading comprehension, where examples consist of
(question, passage, answer) tuples. Presumably, a model must combine
information from both questions and passages to predict corresponding answers.
However, despite intense interest in the topic, with hundreds of published
papers vying for leaderboard dominance, basic questions about the difficulty of
many popular benchmarks remain unanswered. In this paper, we establish sensible
baselines for the bAbI, SQuAD, CBT, CNN, and Who-did-What datasets, finding
that question- and passage-only models often perform surprisingly well. On $14$
out of $20$ bAbI tasks, passage-only models achieve greater than $50\%$
accuracy, sometimes matching the full model. Interestingly, while CBT provides
$20$-sentence stories only the last is needed for comparably accurate
prediction. By comparison, SQuAD and CNN appear better-constructed.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kaushik_D/0/1/0/all/0/1&quot;&gt;Divyansh Kaushik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lipton_Z/0/1/0/all/0/1&quot;&gt;Zachary C. Lipton&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.05006">
<title>Statistical Piano Reduction Controlling Performance Difficulty. (arXiv:1808.05006v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1808.05006</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a statistical-modelling method for piano reduction, i.e.
converting an ensemble score into piano scores, that can control performance
difficulty. While previous studies have focused on describing the condition for
playable piano scores, it depends on player&apos;s skill and can change continuously
with the tempo. We thus computationally quantify performance difficulty as well
as musical fidelity to the original score, and formulate the problem as
optimization of musical fidelity under constraints on difficulty values. First,
performance difficulty measures are developed by means of probabilistic
generative models for piano scores and the relation to the rate of performance
errors is studied. Second, to describe musical fidelity, we construct a
probabilistic model integrating a prior piano-score model and a model
representing how ensemble scores are likely to be edited. An iterative
optimization algorithm for piano reduction is developed based on statistical
inference of the model. We confirm the effect of the iterative procedure; we
find that subjective difficulty and musical fidelity monotonically increase
with controlled difficulty values; and we show that incorporating sequential
dependence of pitches and fingering motion in the piano-score model improves
the quality of reduction scores in high-difficulty cases.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nakamura_E/0/1/0/all/0/1&quot;&gt;Eita Nakamura&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yoshii_K/0/1/0/all/0/1&quot;&gt;Kazuyoshi Yoshii&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1706.07269">
<title>Explanation in Artificial Intelligence: Insights from the Social Sciences. (arXiv:1706.07269v3 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1706.07269</link>
<description rdf:parseType="Literal">&lt;p&gt;There has been a recent resurgence in the area of explainable artificial
intelligence as researchers and practitioners seek to make their algorithms
more understandable. Much of this research is focused on explicitly explaining
decisions or actions to a human observer, and it should not be controversial to
say that looking at how humans explain to each other can serve as a useful
starting point for explanation in artificial intelligence. However, it is fair
to say that most work in explainable artificial intelligence uses only the
researchers&apos; intuition of what constitutes a `good&apos; explanation. There exists
vast and valuable bodies of research in philosophy, psychology, and cognitive
science of how people define, generate, select, evaluate, and present
explanations, which argues that people employ certain cognitive biases and
social expectations towards the explanation process. This paper argues that the
field of explainable artificial intelligence should build on this existing
research, and reviews relevant papers from philosophy, cognitive
psychology/science, and social psychology, which study these topics. It draws
out some important findings, and discusses ways that these can be infused with
work on explainable artificial intelligence.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Miller_T/0/1/0/all/0/1&quot;&gt;Tim Miller&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.11070">
<title>Actor-Critic based Training Framework for Abstractive Summarization. (arXiv:1803.11070v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1803.11070</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a training framework for neural abstractive summarization based on
actor-critic approaches from reinforcement learning. In the traditional neural
network based methods, the objective is only to maximize the likelihood of the
predicted summaries, no other assessment constraints are considered, which may
generate low-quality summaries or even incorrect sentences. To alleviate this
problem, we employ an actor-critic framework to enhance the training procedure.
For the actor, we employ the typical attention based sequence-to-sequence
(seq2seq) framework as the policy network for summary generation. For the
critic, we combine the maximum likelihood estimator with a well designed global
summary quality estimator which is a neural network based binary classifier
aiming to make the generated summaries indistinguishable from the human-written
ones. Policy gradient method is used to conduct the parameter learning. An
alternating training strategy is proposed to conduct the joint training of the
actor and critic models. Extensive experiments on some benchmark datasets in
different languages show that our framework achieves improvements over the
state-of-the-art methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1&quot;&gt;Piji Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bing_L/0/1/0/all/0/1&quot;&gt;Lidong Bing&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lam_W/0/1/0/all/0/1&quot;&gt;Wai Lam&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07340">
<title>Suffix Bidirectional Long Short-Term Memory. (arXiv:1805.07340v1 [cs.LG] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1805.07340</link>
<description rdf:parseType="Literal">&lt;p&gt;Recurrent neural networks have become ubiquitous in computing representations
of sequential data, especially textual data in natural language processing. In
particular, Bidirectional LSTMs are at the heart of several neural models
achieving state-of-the-art performance in a wide variety of tasks in NLP. We
propose a general and effective improvement to the BiLSTM model which encodes
each suffix and prefix of a sequence of tokens in both forward and reverse
directions. We call our model Suffix BiLSTM or SuBiLSTM. Using an extensive set
of experiments, we demonstrate that using SuBiLSTM instead of a BiLSTM in
existing base models leads to improvements in performance in learning general
sentence representations, text classification, textual entailment and named
entity recognition. We achieve new state-of-the-art results for fine-grained
sentiment classification and question classification using SuBiLSTM.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brahma_S/0/1/0/all/0/1&quot;&gt;Siddhartha Brahma&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.04839">
<title>Discrete gradient descent differs qualitatively from gradient flow. (arXiv:1808.04839v1 [math.OC])</title>
<link>http://arxiv.org/abs/1808.04839</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider gradient descent on functions of the form $L_1 = |f|$ and $L_2 =
f^2$, where $f: \mathbb{R}^n \rightarrow \mathbb{R}$ is any smooth function
with 0 as a regular value. We show that gradient descent implemented with a
discrete step size $\tau$ behaves qualitatively differently from continuous
gradient descent. We show that over long time scales, continuous and discrete
gradient descent on $L_1$ find different minima of $L_1$, and we can
characterize the difference - the minima that tend to be found by discrete
gradient descent lie in a secondary critical submanifold $M&apos; \subset M$, the
locus within $M$ where the function $K=|\nabla f|^2 \big|_M$ is minimized. In
this paper, we explain this behavior. We also study the more subtle behavior of
discrete gradient descent on $L_2$.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Cooper_Y/0/1/0/all/0/1&quot;&gt;Y. Cooper&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.04873">
<title>Generalization of Equilibrium Propagation to Vector Field Dynamics. (arXiv:1808.04873v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1808.04873</link>
<description rdf:parseType="Literal">&lt;p&gt;The biological plausibility of the backpropagation algorithm has long been
doubted by neuroscientists. Two major reasons are that neurons would need to
send two different types of signal in the forward and backward phases, and that
pairs of neurons would need to communicate through symmetric bidirectional
connections. We present a simple two-phase learning procedure for fixed point
recurrent networks that addresses both these issues. In our model, neurons
perform leaky integration and synaptic weights are updated through a local
mechanism. Our learning method generalizes Equilibrium Propagation to vector
field dynamics, relaxing the requirement of an energy function. As a
consequence of this generalization, the algorithm does not compute the true
gradient of the objective function, but rather approximates it at a precision
which is proven to be directly related to the degree of symmetry of the
feedforward and feedback weights. We show experimentally that our algorithm
optimizes the objective function.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Scellier_B/0/1/0/all/0/1&quot;&gt;Benjamin Scellier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goyal_A/0/1/0/all/0/1&quot;&gt;Anirudh Goyal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Binas_J/0/1/0/all/0/1&quot;&gt;Jonathan Binas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mesnard_T/0/1/0/all/0/1&quot;&gt;Thomas Mesnard&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bengio_Y/0/1/0/all/0/1&quot;&gt;Yoshua Bengio&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.04883">
<title>COLA: Communication-Efficient Decentralized Linear Learning. (arXiv:1808.04883v1 [cs.DC])</title>
<link>http://arxiv.org/abs/1808.04883</link>
<description rdf:parseType="Literal">&lt;p&gt;Decentralized machine learning is a promising emerging paradigm in view of
global challenges of data ownership and privacy. We consider learning of linear
classification and regression models, in the setting where the training data is
decentralized over many user devices, and the learning algorithm must run
on-device, on an arbitrary communication network, without a central
coordinator. We propose COLA, a new decentralized training algorithm with
strong theoretical guarantees and superior practical performance. Our framework
overcomes many limitations of existing methods, and achieves communication
efficiency, scalability, elasticity as well as resilience to changes in data
and participating devices.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_L/0/1/0/all/0/1&quot;&gt;Lie He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bian_A/0/1/0/all/0/1&quot;&gt;An Bian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jaggi_M/0/1/0/all/0/1&quot;&gt;Martin Jaggi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.04888">
<title>Skill Rating for Generative Models. (arXiv:1808.04888v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1808.04888</link>
<description rdf:parseType="Literal">&lt;p&gt;We explore a new way to evaluate generative models using insights from
evaluation of competitive games between human players. We show experimentally
that tournaments between generators and discriminators provide an effective way
to evaluate generative models. We introduce two methods for summarizing
tournament outcomes: tournament win rate and skill rating. Evaluations are
useful in different contexts, including monitoring the progress of a single
model as it learns during the training process, and comparing the capabilities
of two different fully trained models. We show that a tournament consisting of
a single model playing against past and future versions of itself produces a
useful measure of training progress. A tournament containing multiple separate
models (using different seeds, hyperparameters, and architectures) provides a
useful relative comparison between different trained GANs. Tournament-based
rating methods are conceptually distinct from numerous previous categories of
approaches to evaluation of generative models, and have complementary
advantages and disadvantages.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Olsson_C/0/1/0/all/0/1&quot;&gt;Catherine Olsson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bhupatiraju_S/0/1/0/all/0/1&quot;&gt;Surya Bhupatiraju&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Brown_T/0/1/0/all/0/1&quot;&gt;Tom Brown&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Odena_A/0/1/0/all/0/1&quot;&gt;Augustus Odena&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Goodfellow_I/0/1/0/all/0/1&quot;&gt;Ian Goodfellow&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.04947">
<title>Collapse of Deep and Narrow Neural Nets. (arXiv:1808.04947v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1808.04947</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent theoretical work has demonstrated that deep neural networks have
superior performance over shallow networks, but their training is more
difficult, e.g., they suffer from the vanishing gradient problem. This problem
can be typically resolved by the rectified linear unit (ReLU) activation.
However, here we show that even for such activation, deep and narrow neural
networks will converge to erroneous mean or median states of the target
function depending on the loss with high probability. We demonstrate this
collapse of deep and narrow neural networks both numerically and theoretically,
and provide estimates of the probability of collapse. We also construct a
diagram of a safe region of designing neural networks that avoid the collapse
to erroneous states. Finally, we examine different ways of initialization and
normalization that may avoid the collapse problem.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lu_L/0/1/0/all/0/1&quot;&gt;Lu Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Su_Y/0/1/0/all/0/1&quot;&gt;Yanhui Su&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Karniadakis_G/0/1/0/all/0/1&quot;&gt;George Em Karniadakis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.05054">
<title>Shedding Light on Black Box Machine Learning Algorithms: Development of an Axiomatic Framework to Assess the Quality of Methods that Explain Individual Predictions. (arXiv:1808.05054v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1808.05054</link>
<description rdf:parseType="Literal">&lt;p&gt;From self-driving vehicles and back-flipping robots to virtual assistants who
book our next appointment at the hair salon or at that restaurant for dinner -
machine learning systems are becoming increasingly ubiquitous. The main reason
for this is that these methods boast remarkable predictive capabilities.
However, most of these models remain black boxes, meaning that it is very
challenging for humans to follow and understand their intricate inner workings.
Consequently, interpretability has suffered under this ever-increasing
complexity of machine learning models. Especially with regards to new
regulations, such as the General Data Protection Regulation (GDPR), the
necessity for plausibility and verifiability of predictions made by these black
boxes is indispensable. Driven by the needs of industry and practice, the
research community has recognised this interpretability problem and focussed on
developing a growing number of so-called explanation methods over the past few
years. These methods explain individual predictions made by black box machine
learning models and help to recover some of the lost interpretability. With the
proliferation of these explanation methods, it is, however, often unclear,
which explanation method offers a higher explanation quality, or is generally
better-suited for the situation at hand. In this thesis, we thus propose an
axiomatic framework, which allows comparing the quality of different
explanation methods amongst each other. Through experimental validation, we
find that the developed framework is useful to assess the explanation quality
of different explanation methods and reach conclusions that are consistent with
independent research.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Honegger_M/0/1/0/all/0/1&quot;&gt;Milo Honegger&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.05110">
<title>Joint &amp; Progressive Learning from High-Dimensional Data for Multi-Label Classification. (arXiv:1808.05110v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1808.05110</link>
<description rdf:parseType="Literal">&lt;p&gt;Despite the fact that nonlinear subspace learning techniques (e.g. manifold
learning) have successfully applied to data representation, there is still room
for improvement in explainability (explicit mapping), generalization
(out-of-samples), and cost-effectiveness (linearization). To this end, a novel
linearized subspace learning technique is developed in a joint and progressive
way, called \textbf{j}oint and \textbf{p}rogressive \textbf{l}earning
str\textbf{a}teg\textbf{y} (J-Play), with its application to multi-label
classification. The J-Play learns high-level and semantically meaningful
feature representation from high-dimensional data by 1) jointly performing
multiple subspace learning and classification to find a latent subspace where
samples are expected to be better classified; 2) progressively learning
multi-coupled projections to linearly approach the optimal mapping bridging the
original space with the most discriminative subspace; 3) locally embedding
manifold structure in each learnable latent subspace. Extensive experiments are
performed to demonstrate the superiority and effectiveness of the proposed
method in comparison with previous state-of-the-art methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hong_D/0/1/0/all/0/1&quot;&gt;Danfeng Hong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yokoya_N/0/1/0/all/0/1&quot;&gt;Naoto Yokoya&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1&quot;&gt;Jian Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1&quot;&gt;Xiaoxiang Zhu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.05128">
<title>Using Regular Languages to Explore the Representational Capacity of Recurrent Neural Architectures. (arXiv:1808.05128v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1808.05128</link>
<description rdf:parseType="Literal">&lt;p&gt;The presence of Long Distance Dependencies (LDDs) in sequential data poses
significant challenges for computational models. Various recurrent neural
architectures have been designed to mitigate this issue. In order to test these
state-of-the-art architectures, there is growing need for rich benchmarking
datasets. However, one of the drawbacks of existing datasets is the lack of
experimental control with regards to the presence and/or degree of LDDs. This
lack of control limits the analysis of model performance in relation to the
specific challenge posed by LDDs. One way to address this is to use synthetic
data having the properties of subregular languages. The degree of LDDs within
the generated data can be controlled through the k parameter, length of the
generated strings, and by choosing appropriate forbidden strings. In this
paper, we explore the capacity of different RNN extensions to model LDDs, by
evaluating these models on a sequence of SPk synthesized datasets, where each
subsequent dataset exhibits a longer degree of LDD. Even though SPk are simple
languages, the presence of LDDs does have significant impact on the performance
of recurrent neural architectures, thus making them prime candidate in
benchmarking tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mahalunkar_A/0/1/0/all/0/1&quot;&gt;Abhijit Mahalunkar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kelleher_J/0/1/0/all/0/1&quot;&gt;John D. Kelleher&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.05163">
<title>A Simple but Hard-to-Beat Baseline for Session-based Recommendations. (arXiv:1808.05163v1 [cs.IR])</title>
<link>http://arxiv.org/abs/1808.05163</link>
<description rdf:parseType="Literal">&lt;p&gt;Convolutional Neural Networks (CNNs) models have been recently introduced in
the domain of top-$N$ session-based recommendations. An ordered collection of
past items the user has interacted with in a session (or sequence) are embedded
into a 2-dimensional latent matrix, and treated as an image. The convolution
and pooling operations are then applied to the mapped item embeddings. In this
paper, we first examine the typical session-based CNN recommender and show that
both the generative model and network architecture are suboptimal when modeling
long-range dependencies in the item sequence. To address the issues, we propose
a simple, but very effective generative model that is capable of learning
high-level representation from both short- and long-range dependencies. The
network architecture of the proposed model is formed of a stack of holed
convolutional layers, which can efficiently increase the receptive fields
without relying on the pooling operation. Another contribution is the effective
use of residual block structure in recommender systems, which not only reduces
the number of parameters but also eases the optimization for much deeper
networks. The proposed generative model attains state-of-the-art accuracy with
less training time in the session-based recommendation task. It accordingly can
be used as a powerful session-based recommendation baseline to beat in future,
especially when there are long sequences of user feedback.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yuan_F/0/1/0/all/0/1&quot;&gt;Fajie Yuan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Karatzoglou_A/0/1/0/all/0/1&quot;&gt;Alexandros Karatzoglou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Arapakis_I/0/1/0/all/0/1&quot;&gt;Ioannis Arapakis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jose_J/0/1/0/all/0/1&quot;&gt;Joemon M Jose&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1&quot;&gt;Xiangnan He&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.04272">
<title>An $O(N)$ Sorting Algorithm: Machine Learning Sort. (arXiv:1805.04272v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.04272</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose an $O(N\cdot M)$ sorting algorithm by Machine Learning method,
which shows a huge potential sorting big data. This sorting algorithm can be
applied to parallel sorting and is suitable for GPU or TPU acceleration.
Furthermore, we discuss the application of this algorithm to sparse hash table.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1&quot;&gt;Hanqing Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1&quot;&gt;Yuehan Luo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05394">
<title>Dynamical Isometry and a Mean Field Theory of RNNs: Gating Enables Signal Propagation in Recurrent Neural Networks. (arXiv:1806.05394v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1806.05394</link>
<description rdf:parseType="Literal">&lt;p&gt;Recurrent neural networks have gained widespread use in modeling sequence
data across various domains. While many successful recurrent architectures
employ a notion of gating, the exact mechanism that enables such remarkable
performance is not well understood. We develop a theory for signal propagation
in recurrent networks after random initialization using a combination of mean
field theory and random matrix theory. To simplify our discussion, we introduce
a new RNN cell with a simple gating mechanism that we call the minimalRNN and
compare it with vanilla RNNs. Our theory allows us to define a maximum
timescale over which RNNs can remember an input. We show that this theory
predicts trainability for both recurrent architectures. We show that gated
recurrent networks feature a much broader, more robust, trainable region than
vanilla RNNs, which corroborates recent experimental findings. Finally, we
develop a closed-form critical initialization scheme that achieves dynamical
isometry in both vanilla RNNs and minimalRNNs. We show that this results in
significantly improvement in training dynamics. Finally, we demonstrate that
the minimalRNN achieves comparable performance to its more complex
counterparts, such as LSTMs or GRUs, on a language modeling task.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chen_M/0/1/0/all/0/1&quot;&gt;Minmin Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pennington_J/0/1/0/all/0/1&quot;&gt;Jeffrey Pennington&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Schoenholz_S/0/1/0/all/0/1&quot;&gt;Samuel S. Schoenholz&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.11156">
<title>Transformationally Identical and Invariant Convolutional Neural Networks by Combining Symmetric Operations or Input Vectors. (arXiv:1807.11156v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1807.11156</link>
<description rdf:parseType="Literal">&lt;p&gt;Transformationally invariant processors constructed by transformed input
vectors or operators have been suggested and applied to many applications. In
this study, transformationally identical processing based on combining results
of all sub-processes with corresponding transformations either at the final
processing step or at the beginning step were found to be equivalent through a
special algebraical operation property. This technique can be applied to most
convolutional neural network (CNN) systems. Specifically, a transformationally
identical CNN system can be constructed by running internally symmetric
operations in parallel with the same transformation family followed by a
flatten layer with weights sharing among their corresponding transformation
elements. Such a CNN can output the same result with any transformed input
vector of the family. Interestingly, we found that this type of
transformationally identical CNN system by combining symmetric operations at
the flatten layer is mathematically equivalent to an ordinary CNN but combining
all transformation versions of the input vector at the input layer as the
forward propagation. However, their corresponding backpropagation processes
would take different routes due to greatly different CNN structures between
them.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lo_S/0/1/0/all/0/1&quot;&gt;ShihChung B. Lo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Freedman_M/0/1/0/all/0/1&quot;&gt;Matthew T. Freedman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mun_S/0/1/0/all/0/1&quot;&gt;Seong K. Mun&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.00245">
<title>Robbins-Mobro conditions for persistent exploration learning strategies. (arXiv:1808.00245v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1808.00245</link>
<description rdf:parseType="Literal">&lt;p&gt;We formulate simple assumptions, implying the Robbins-Monro conditions for
the $Q$-learning algorithm with the local learning rate, depending on the
number of visits of a particular state-action pair (local clock) and the number
of iteration (global clock). It is assumed that the Markov decision process is
communicating and the learning policy ensures the persistent exploration. The
restrictions are imposed on the functional dependence of the learning rate on
the local and global clocks. The result partially confirms the conjecture of
Bradkte (1994).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rokhlin_D/0/1/0/all/0/1&quot;&gt;Dmitry B. Rokhlin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.04572">
<title>Small Sample Learning in Big Data Era. (arXiv:1808.04572v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1808.04572</link>
<description rdf:parseType="Literal">&lt;p&gt;As a promising area in artificial intelligence, a new learning paradigm,
called Small Sample Learning (SSL), has been attracting prominent research
attention in the recent years. In this paper, we aim to present a survey to
comprehensively introduce the current techniques proposed on this topic.
Specifically, current SSL techniques can be mainly divided into two categories.
The first category of SSL approaches can be called &quot;concept learning&quot;, which
emphasizes learning new concepts from only few related observations. The
purpose is mainly to simulate human learning behaviors like recognition,
generation, imagination, synthesis and analysis. The second category is called
&quot;experience learning&quot;, which usually co-exists with the large sample learning
manner of conventional machine learning. This category mainly focuses on
learning with insufficient samples, and can also be called small data learning
in some literatures. More extensive surveys on both categories of SSL
techniques are introduced and some neuroscience evidences are provided to
clarify the rationality of the entire SSL regime, and the relationship with
human learning process. Some discussions on the main challenges and possible
future research directions along this line are also presented.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shu_J/0/1/0/all/0/1&quot;&gt;Jun Shu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1&quot;&gt;Zongben Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meng_D/0/1/0/all/0/1&quot;&gt;Deyu Meng&lt;/a&gt;</dc:creator>
</item></rdf:RDF>