<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Good papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Good Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2017-12-03T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.00268"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.10067"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.10644"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.00004"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.00006"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.00180"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.00193"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.00222"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.00377"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.00428"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1608.07685"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1702.04047"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1705.08804"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1707.06325"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.10489"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.04994"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.09401"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.11543"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.00003"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.00010"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.00028"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.00032"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.00117"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.00123"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.00126"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.00155"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.00164"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.00171"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.00174"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.00181"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.00205"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.00232"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.00254"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.00269"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.00287"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.00288"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.00310"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.00311"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.00328"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.00368"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.00409"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.00424"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.00443"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1509.04752"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1512.01631"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1701.02776"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1703.10893"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1704.01701"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1706.05374"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1707.07012"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.04495"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.04461"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.09325"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.10057"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.11386"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1709.00268">
<title>Algorithmically probable mutations reproduce aspects of evolution such as convergence rate, genetic memory, modularity, diversity explosions, and mass extinction. (arXiv:1709.00268v5 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1709.00268</link>
<description rdf:parseType="Literal">&lt;p&gt;Natural selection explains how life has evolved over millions of years from
more primitive forms. The speed at which this happens, however, has sometimes
defied explanations based on random (uniformly distributed) mutations. Here we
investigate the application of algorithmic mutations (no recombination) to
binary matrices drawn from numerical approximations to algorithmic probability
in order to compare evolutionary convergence rates against the null hypothesis
(uniformly distributed mutations). Results both on synthetic and a small
biological examples lead to an accelerated rate of convergence when using the
algorithmic probability. We also show that algorithmically evolved modularity
provides an advantage that produces a genetic memory. We demonstrate that
regular structures are preserved and carried on when they first occur and can
lead to an accelerated production of diversity and extinction, possibly
explaining naturally occurring phenomena such as diversity explosions (e.g. the
Cambrian) and massive extinctions (e.g. the End Triassic) whose causes have
eluded researchers and are a cause for debate. The approach introduced here
appears to be a better approximation to biological evolution than models based
exclusively upon random uniform mutations, and it also approaches better a
formal version of open-ended evolution based on previous results. The results
validate the motivations and results of Chaitin&apos;s Metabiology programme and
previous suggestions that computation may be an equally important driver of
evolution together, and even before, the action and result of natural
selection. We also show that inducing the method on problems of optimization,
such as genetic algorithms, has the potential to significantly accelerate
convergence of artificial evolutionary algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hernandez_Orozco_S/0/1/0/all/0/1&quot;&gt;Santiago Hern&amp;#xe1;ndez-Orozco&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kiani_N/0/1/0/all/0/1&quot;&gt;Narsis A. Kiani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zenil_H/0/1/0/all/0/1&quot;&gt;Hector Zenil&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.10067">
<title>WSNet: Compact and Efficient Networks with Weight Sampling. (arXiv:1711.10067v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1711.10067</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a new approach and a novel architecture, termed WSNet, for
learning compact and efficient deep neural networks. Existing approaches
conventionally learn full model parameters independently at first and then
compress them via ad hoc processing like model pruning or filter factorization.
Different from them, WSNet proposes learning model parameters by sampling from
a compact set of learnable parameters, which naturally enforces parameter
sharing throughout the learning process. We show that such novel weight
sampling approach (and induced WSNet) promotes both weights and computation
sharing favorably. It can more efficiently learn much smaller networks with
competitive performance, compared to baseline networks with equal number of
convolution filters. Specifically, we consider learning compact and efficient
1D convolutional neural networks for audio classification. Extensive
experiments on multiple audio classification datasets verify the effectiveness
of WSNet. Combined with weight quantization, the resulted models are up to 180x
smaller and theoretically up to 16x faster than the well-established baselines,
without noticeable performance drop.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jin_X/0/1/0/all/0/1&quot;&gt;Xiaojie Jin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1&quot;&gt;Yingzhen Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_N/0/1/0/all/0/1&quot;&gt;Ning Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1&quot;&gt;Jianchao Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1&quot;&gt;Jiashi Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yan_S/0/1/0/all/0/1&quot;&gt;Shuicheng Yan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.10644">
<title>PSIque: Next Sequence Prediction of Satellite Images using a Convolutional Sequence-to-Sequence Network. (arXiv:1711.10644v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1711.10644</link>
<description rdf:parseType="Literal">&lt;p&gt;Predicting unseen weather phenomena is an important issue for disaster
management. In this paper, we suggest a model for a convolutional
sequence-to-sequence autoencoder for predicting undiscovered weather situations
from previous satellite images. We also propose a symmetric skip connection
between encoder and decoder modules to produce more comprehensive image
predictions. To examine our model performance, we conducted experiments for
each suggested model to predict future satellite images from historical
satellite images. A specific combination of skip connection and
sequence-to-sequence autoencoder was able to generate closest prediction from
the ground truth image.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hong_S/0/1/0/all/0/1&quot;&gt;Seungkyun Hong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1&quot;&gt;Seongchan Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Joh_M/0/1/0/all/0/1&quot;&gt;Minsu Joh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_S/0/1/0/all/0/1&quot;&gt;Sa-kwang Song&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.00004">
<title>Learnings Options End-to-End for Continuous Action Tasks. (arXiv:1712.00004v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1712.00004</link>
<description rdf:parseType="Literal">&lt;p&gt;We present new results on learning temporally extended actions for
continuoustasks, using the options framework (Suttonet al.[1999b], Precup
[2000]). In orderto achieve this goal we work with the option-critic
architecture (Baconet al.[2017])using a deliberation cost and train it with
proximal policy optimization (Schulmanet al.[2017]) instead of vanilla policy
gradient. Results on Mujoco domains arepromising, but lead to interesting
questions aboutwhena given option should beused, an issue directly connected to
the use of initiation sets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Klissarov_M/0/1/0/all/0/1&quot;&gt;Martin Klissarov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bacon_P/0/1/0/all/0/1&quot;&gt;Pierre-Luc Bacon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Harb_J/0/1/0/all/0/1&quot;&gt;Jean Harb&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Precup_D/0/1/0/all/0/1&quot;&gt;Doina Precup&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.00006">
<title>Comparing Deep Reinforcement Learning and Evolutionary Methods in Continuous Control. (arXiv:1712.00006v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1712.00006</link>
<description rdf:parseType="Literal">&lt;p&gt;Reinforcement learning and evolutionary strategy are two major approaches in
addressing complicated control problems. Both have strong biological basis and
there have been recently many advanced techniques in both domains. In this
paper, we present a thorough comparison between the state of the art techniques
in both domains in complex continuous control tasks. We also formulate the
parallelized version of the Proximal Policy Optimization method and the Deep
Deterministic Policy Gradient method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1&quot;&gt;Shangtong Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zaiane_O/0/1/0/all/0/1&quot;&gt;Osmar R. Zaiane&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.00180">
<title>New Techniques for Inferring L-Systems Using Genetic Algorithm. (arXiv:1712.00180v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1712.00180</link>
<description rdf:parseType="Literal">&lt;p&gt;Lindenmayer systems (L-systems) are a formal grammar system that iteratively
rewrites all symbols of a string, in parallel. When visualized with a graphical
interpretation, the images have self-similar shapes that appear frequently in
nature, and they have been particularly successful as a concise, reusable
technique for simulating plants. The L-system inference problem is to find an
L-system to simulate a given plant. This is currently done mainly by experts,
but this process is limited by the availability of experts, the complexity that
may be solved by humans, and time. This paper introduces the Plant Model
Inference Tool (PMIT) that infers deterministic context-free L-systems from an
initial sequence of strings generated by the system using a genetic algorithm.
PMIT is able to infer more complex systems than existing approaches. Indeed,
while existing approaches are limited to L-systems with a total sum of 20
combined symbols in the productions, PMIT can infer almost all L-systems tested
where the total sum is 140 symbols. This was validated using a test bed of 28
previously developed L-system models, in addition to models created
artificially by bootstrapping larger models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bernard_J/0/1/0/all/0/1&quot;&gt;Jason Bernard&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+McQuillan_I/0/1/0/all/0/1&quot;&gt;Ian McQuillan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.00193">
<title>Improving Smiling Detection with Race and Gender Diversity. (arXiv:1712.00193v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1712.00193</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent progress in deep learning has been accompanied by a growing concern
for whether models are fair for users, with equally good performance across
different demographics. In computer vision research, such questions are
relevant to face detection and the related task of face attribute detection,
among others. We measure race and gender inclusion in the context of smiling
detection, and introduce a method for improving smiling detection across
demographic groups. Our method introduces several modifications over existing
detection methods, leveraging twofold transfer learning to better model facial
diversity. Results show that this technique improves accuracy against strong
baselines for most demographic groups as well as overall. Our best-performing
model defines a new state-of-the-art for smiling detection, reaching 91% on the
Faces of the World dataset. The accompanying multi-head diversity classifier
also defines a new state-of-the-art for gender classification, reaching 93.87%
on the Faces of the World dataset. This research demonstrates the utility of
modeling race and gender to improve a face attribute detection task, using a
twofold transfer learning framework that allows for privacy towards individuals
in a target dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ryu_H/0/1/0/all/0/1&quot;&gt;Hee Jung Ryu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mitchell_M/0/1/0/all/0/1&quot;&gt;Margaret Mitchell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Adam_H/0/1/0/all/0/1&quot;&gt;Hartwig Adam&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.00222">
<title>A double competitive strategy based learning automata algorithm. (arXiv:1712.00222v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1712.00222</link>
<description rdf:parseType="Literal">&lt;p&gt;Learning Automata (LA) are considered as one of the most powerful tools in
the field of reinforcement learning. The family of estimator algorithms is
proposed to improve the convergence rate of LA and has made great achievements.
However, the estimators perform poorly on estimating the reward probabilities
of actions in the initial stage of the learning process of LA. In this
situation, a lot of rewards would be added to the probabilities of non-optimal
actions. Thus, a large number of extra iterations are needed to compensate for
these wrong rewards. In order to improve the speed of convergence, we propose a
new P-model absorbing learning automaton by utilizing a double competitive
strategy which is designed for updating the action probability vector. In this
way, the wrong rewards can be corrected instantly. Hence, the proposed Double
Competitive Algorithm overcomes the drawbacks of existing estimator algorithms.
A refined analysis is presented to show the $\epsilon-optimality$ of the
proposed scheme. The extensive experimental results in benchmark environments
demonstrate that our proposed learning automata perform more efficiently than
the most classic LA $SE_{RI}$ and the current fastest LA $DGCPA^{*}$.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Di_C/0/1/0/all/0/1&quot;&gt;Chong Di&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.00377">
<title>Don&apos;t Just Assume; Look and Answer: Overcoming Priors for Visual Question Answering. (arXiv:1712.00377v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1712.00377</link>
<description rdf:parseType="Literal">&lt;p&gt;A number of studies have found that today&apos;s Visual Question Answering (VQA)
models are heavily driven by superficial correlations in the training data and
lack sufficient image grounding. To encourage development of models geared
towards the latter, we propose a new setting for VQA where for every question
type, train and test sets have different prior distributions of answers.
Specifically, we present new splits of the VQA v1 and VQA v2 datasets, which we
call Visual Question Answering under Changing Priors (VQA-CP v1 and VQA-CP v2
respectively). First, we evaluate several existing VQA models under this new
setting and show that their performance degrades significantly compared to the
original VQA setting. Second, we propose a novel Grounded Visual Question
Answering model (GVQA) that contains inductive biases and restrictions in the
architecture specifically designed to prevent the model from &apos;cheating&apos; by
primarily relying on priors in the training data. Specifically, GVQA explicitly
disentangles the recognition of visual concepts present in the image from the
identification of plausible answer space for a given question, enabling the
model to more robustly generalize across different distributions of answers.
GVQA is built off an existing VQA model -- Stacked Attention Networks (SAN).
Our experiments demonstrate that GVQA significantly outperforms SAN on both
VQA-CP v1 and VQA-CP v2 datasets. Interestingly, it also outperforms more
powerful VQA models such as Multimodal Compact Bilinear Pooling (MCB) in
several cases. GVQA offers strengths complementary to SAN when trained and
evaluated on the original VQA v1 and VQA v2 datasets. Finally, GVQA is more
transparent and interpretable than existing VQA models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Agrawal_A/0/1/0/all/0/1&quot;&gt;Aishwarya Agrawal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Batra_D/0/1/0/all/0/1&quot;&gt;Dhruv Batra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Parikh_D/0/1/0/all/0/1&quot;&gt;Devi Parikh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kembhavi_A/0/1/0/all/0/1&quot;&gt;Aniruddha Kembhavi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.00428">
<title>Novel Exploration Techniques (NETs) for Malaria Policy Interventions. (arXiv:1712.00428v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1712.00428</link>
<description rdf:parseType="Literal">&lt;p&gt;The task of decision-making under uncertainty is daunting, especially for
problems which have significant complexity. Healthcare policy makers across the
globe are facing problems under challenging constraints, with limited tools to
help them make data driven decisions. In this work we frame the process of
finding an optimal malaria policy as a stochastic multi-armed bandit problem,
and implement three agent based strategies to explore the policy space. We
apply a Gaussian Process regression to the findings of each agent, both for
comparison and to account for stochastic results from simulating the spread of
malaria in a fixed population. The generated policy spaces are compared with
published results to give a direct reference with human expert decisions for
the same simulated population. Our novel approach provides a powerful resource
for policy makers, and a platform which can be readily extended to capture
future more nuanced policy spaces.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bent_O/0/1/0/all/0/1&quot;&gt;Oliver Bent&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Remy_S/0/1/0/all/0/1&quot;&gt;Sekou L. Remy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roberts_S/0/1/0/all/0/1&quot;&gt;Stephen Roberts&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Walcott_Bryant_A/0/1/0/all/0/1&quot;&gt;Aisha Walcott-Bryant&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1608.07685">
<title>KSR: A Semantic Representation of Knowledge Graph within a Novel Unsupervised Paradigm. (arXiv:1608.07685v5 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1608.07685</link>
<description rdf:parseType="Literal">&lt;p&gt;Knowledge representation is a long-history topic in AI, which is very
important. A variety of models have been proposed for knowledge graph
embedding, which projects symbolic entities and relations into continuous
vector space. However, most related methods merely focus on the data-fitting of
knowledge graph, and ignore the interpretable semantic expression. Thus,
traditional embedding methods are not friendly for applications that require
semantic analysis, such as question answering and entity retrieval. To this
end, this paper proposes a semantic representation method for knowledge graph
\textbf{(KSR)}, which imposes a two-level hierarchical generative process that
globally extracts many aspects and then locally assigns a specific category in
each aspect for every triple. Since both aspects and categories are
semantics-relevant, the collection of categories in each aspect is treated as
the semantic representation of this triple. Extensive experiments show that our
model outperforms other state-of-the-art baselines substantially.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiao_H/0/1/0/all/0/1&quot;&gt;Han Xiao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meng_L/0/1/0/all/0/1&quot;&gt;Lian Meng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1702.04047">
<title>Constraint Answer Set Solver EZCSP and Why Integration Schemas Matter. (arXiv:1702.04047v3 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1702.04047</link>
<description rdf:parseType="Literal">&lt;p&gt;Researchers in answer set programming and constraint programming have spent
significant efforts in the development of hybrid languages and solving
algorithms combining the strengths of these traditionally separate fields.
These efforts resulted in a new research area: constraint answer set
programming. Constraint answer set programming languages and systems proved to
be successful at providing declarative, yet efficient solutions to problems
involving hybrid reasoning tasks. One of the main contributions of this paper
is the first comprehensive account of the constraint answer set language and
solver EZCSP, a mainstream representative of this research area that has been
used in various successful applications. We also develop an extension of the
transition systems proposed by Nieuwenhuis et al. in 2006 to capture Boolean
satisfiability solvers. We use this extension to describe the EZCSP algorithm
and prove formal claims about it. The design and algorithmic details behind
EZCSP clearly demonstrate that the development of the hybrid systems of this
kind is challenging. Many questions arise when one faces various design choices
in an attempt to maximize system&apos;s benefits. One of the key decisions that a
developer of a hybrid solver makes is settling on a particular integration
schema within its implementation. Thus, another important contribution of this
paper is a thorough case study based on EZCSP, focused on the various
integration schemas that it provides.
&lt;/p&gt;
&lt;p&gt;Under consideration in Theory and Practice of Logic Programming (TPLP).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Balduccini_M/0/1/0/all/0/1&quot;&gt;Marcello Balduccini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lierler_Y/0/1/0/all/0/1&quot;&gt;Yuliya Lierler&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1705.08804">
<title>Beyond Parity: Fairness Objectives for Collaborative Filtering. (arXiv:1705.08804v2 [cs.IR] UPDATED)</title>
<link>http://arxiv.org/abs/1705.08804</link>
<description rdf:parseType="Literal">&lt;p&gt;We study fairness in collaborative-filtering recommender systems, which are
sensitive to discrimination that exists in historical data. Biased data can
lead collaborative-filtering methods to make unfair predictions for users from
minority groups. We identify the insufficiency of existing fairness metrics and
propose four new metrics that address different forms of unfairness. These
fairness metrics can be optimized by adding fairness terms to the learning
objective. Experiments on synthetic and real data show that our new metrics can
better measure fairness than the baseline, and that the fairness objectives
effectively help reduce unfairness.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yao_S/0/1/0/all/0/1&quot;&gt;Sirui Yao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_B/0/1/0/all/0/1&quot;&gt;Bert Huang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1707.06325">
<title>Computing LPMLN Using ASP and MLN Solvers. (arXiv:1707.06325v3 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1707.06325</link>
<description rdf:parseType="Literal">&lt;p&gt;LPMLN is a recent addition to probabilistic logic programming languages. Its
main idea is to overcome the rigid nature of the stable model semantics by
assigning a weight to each rule in a way similar to Markov Logic is defined. We
present two implementations of LPMLN, $\text{LPMLN2ASP}$ and
$\text{LPMLN2MLN}$. System $\text{LPMLN2ASP}$ translates LPMLN programs into
the input language of answer set solver $\text{CLINGO}$, and using weak
constraints and stable model enumeration, it can compute most probable stable
models as well as exact conditional and marginal probabilities. System
$\text{LPMLN2MLN}$ translates LPMLN programs into the input language of Markov
Logic solvers, such as $\text{ALCHEMY}$, $\text{TUFFY}$, and $\text{ROCKIT}$,
and allows for performing approximate probabilistic inference on LPMLN
programs. We also demonstrate the usefulness of the LPMLN systems for computing
other languages, such as ProbLog and Pearl&apos;s Causal Models, that are shown to
be translatable into LPMLN. (Under consideration for acceptance in TPLP)
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1&quot;&gt;Joohyung Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Talsania_S/0/1/0/all/0/1&quot;&gt;Samidh Talsania&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yi Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.10489">
<title>Self-supervised Deep Reinforcement Learning with Generalized Computation Graphs for Robot Navigation. (arXiv:1709.10489v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1709.10489</link>
<description rdf:parseType="Literal">&lt;p&gt;Enabling robots to autonomously navigate complex environments is essential
for real-world deployment. Prior methods approach this problem by having the
robot maintain an internal map of the world, and then use a localization and
planning method to navigate through the internal map. However, these approaches
often include a variety of assumptions, are computationally intensive, and do
not learn from failures. In contrast, learning-based methods improve as the
robot acts in the environment, but are difficult to deploy in the real-world
due to their high sample complexity. To address the need to learn complex
policies with few samples, we propose a generalized computation graph that
subsumes value-based model-free methods and model-based methods, with specific
instantiations interpolating between model-free and model-based. We then
instantiate this graph to form a navigation model that learns from raw images
and is sample efficient. Our simulated car experiments explore the design
decisions of our navigation model, and show our approach outperforms
single-step and $N$-step double Q-learning. We also evaluate our approach on a
real-world RC car and show it can learn to navigate through a complex indoor
environment with a few hours of fully autonomous, self-supervised training.
Videos of the experiments and code can be found at github.com/gkahn13/gcg
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kahn_G/0/1/0/all/0/1&quot;&gt;Gregory Kahn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Villaflor_A/0/1/0/all/0/1&quot;&gt;Adam Villaflor&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ding_B/0/1/0/all/0/1&quot;&gt;Bosen Ding&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1&quot;&gt;Pieter Abbeel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1&quot;&gt;Sergey Levine&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.04994">
<title>Prediction Under Uncertainty with Error-Encoding Networks. (arXiv:1711.04994v3 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1711.04994</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work we introduce a new framework for performing temporal predictions
in the presence of uncertainty. It is based on a simple idea of disentangling
components of the future state which are predictable from those which are
inherently unpredictable, and encoding the unpredictable components into a
low-dimensional latent variable which is fed into a forward model. Our method
uses a supervised training objective which is fast and easy to train. We
evaluate it in the context of video prediction on multiple datasets and show
that it is able to consistently generate diverse predictions without the need
for alternating minimization over a latent space or adversarial training.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Henaff_M/0/1/0/all/0/1&quot;&gt;Mikael Henaff&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_J/0/1/0/all/0/1&quot;&gt;Junbo Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+LeCun_Y/0/1/0/all/0/1&quot;&gt;Yann LeCun&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.09401">
<title>Pedagogical learning. (arXiv:1711.09401v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1711.09401</link>
<description rdf:parseType="Literal">&lt;p&gt;A common assumption in machine learning is that training data are i.i.d.
samples from some distribution. Processes that generate i.i.d. samples are, in
a sense, uninformative---they produce data without regard to how good this data
is for learning. By contrast, cognitive science research has shown that when
people generate training data for others (i.e., teaching), they deliberately
select examples that are helpful for learning. Because the data is more
informative, learning can require less data. Interestingly, such examples are
most effective when learners know that the data were pedagogically generated
(as opposed to randomly generated). We call this pedagogical learning---when a
learner assumes that evidence comes from a helpful teacher. In this work, we
ask how pedagogical learning might work for machine learning algorithms.
Studying this question requires understanding how people actually teach complex
concepts with examples, so we conducted a behavioral study examining how people
teach regular expressions using example strings. We found that teachers&apos;
examples contain powerful clustering structure that can greatly facilitate
learning. We then develop a model of teaching and show a proof of concept that
using this model inside of a learner can improve performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ouyang_L/0/1/0/all/0/1&quot;&gt;Long Ouyang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Frank_M/0/1/0/all/0/1&quot;&gt;Michael C. Frank&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.11543">
<title>Embodied Question Answering. (arXiv:1711.11543v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1711.11543</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a new AI task -- Embodied Question Answering (EmbodiedQA) -- where
an agent is spawned at a random location in a 3D environment and asked a
question (&quot;What color is the car?&quot;). In order to answer, the agent must first
intelligently navigate to explore the environment, gather information through
first-person (egocentric) vision, and then answer the question (&quot;orange&quot;).
&lt;/p&gt;
&lt;p&gt;This challenging task requires a range of AI skills -- active perception,
language understanding, goal-driven navigation, commonsense reasoning, and
grounding of language into actions. In this work, we develop the environments,
end-to-end-trained reinforcement learning agents, and evaluation protocols for
EmbodiedQA.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Das_A/0/1/0/all/0/1&quot;&gt;Abhishek Das&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Datta_S/0/1/0/all/0/1&quot;&gt;Samyak Datta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gkioxari_G/0/1/0/all/0/1&quot;&gt;Georgia Gkioxari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1&quot;&gt;Stefan Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Parikh_D/0/1/0/all/0/1&quot;&gt;Devi Parikh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Batra_D/0/1/0/all/0/1&quot;&gt;Dhruv Batra&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.00003">
<title>Modeling Information Flow Through Deep Neural Networks. (arXiv:1712.00003v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1712.00003</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper proposes a principled information theoretic analysis of
classification for deep neural network structures, e.g. convolutional neural
networks (CNN). The output of convolutional filters is modeled as a random
variable Y conditioned on the object class C and network filter bank F. The
conditional entropy (CENT) H(Y |C,F) is shown in theory and experiments to be a
highly compact and class-informative code, that can be computed from the filter
outputs throughout an existing CNN and used to obtain higher classification
results than the original CNN itself. Experiments demonstrate the effectiveness
of CENT feature analysis in two separate CNN classification contexts. 1) In the
classification of neurodegeneration due to Alzheimer&apos;s disease (AD) and natural
aging from 3D magnetic resonance image (MRI) volumes, 3 CENT features result in
an AUC=94.6% for whole-brain AD classification, the highest reported accuracy
on the public OASIS dataset used and 12% higher than the softmax output of the
original CNN trained for the task. 2) In the context of visual object
classification from 2D photographs, transfer learning based on a small set of
CENT features identified throughout an existing CNN leads to AUC values
comparable to the 1000-feature softmax output of the original network when
classifying previously unseen object categories. The general information
theoretical analysis explains various recent CNN design successes, e.g. densely
connected CNN architectures, and provides insights for future research
directions in deep learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chaddad_A/0/1/0/all/0/1&quot;&gt;Ahmad Chaddad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Naisiri_B/0/1/0/all/0/1&quot;&gt;Behnaz Naisiri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pedersoli_M/0/1/0/all/0/1&quot;&gt;Marco Pedersoli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Granger_E/0/1/0/all/0/1&quot;&gt;Eric Granger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Desrosiers_C/0/1/0/all/0/1&quot;&gt;Christian Desrosiers&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Toews_M/0/1/0/all/0/1&quot;&gt;Matthew Toews&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.00010">
<title>Highrisk Prediction from Electronic Medical Records via Deep Attention Networks. (arXiv:1712.00010v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1712.00010</link>
<description rdf:parseType="Literal">&lt;p&gt;Predicting highrisk vascular diseases is a significant issue in the medical
domain. Most predicting methods predict the prognosis of patients from
pathological and radiological measurements, which are expensive and require
much time to be analyzed. Here we propose deep attention models that predict
the onset of the high risky vascular disease from symbolic medical histories
sequence of hypertension patients such as ICD-10 and pharmacy codes only,
Medical History-based Prediction using Attention Network (MeHPAN). We
demonstrate two types of attention models based on 1) bidirectional gated
recurrent unit (R-MeHPAN) and 2) 1D convolutional multilayer model (C-MeHPAN).
Two MeHPAN models are evaluated on approximately 50,000 hypertension patients
with respect to precision, recall, f1-measure and area under the curve (AUC).
Experimental results show that our MeHPAN methods outperform standard
classification models. Comparing two MeHPANs, R-MeHPAN provides more better
discriminative capability with respect to all metrics while C-MeHPAN presents
much shorter training time with competitive accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1&quot;&gt;You Jin Kim&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_Y/0/1/0/all/0/1&quot;&gt;Yun-Geun Lee&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1&quot;&gt;Jeong Whun Kim&lt;/a&gt; (2), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Park_J/0/1/0/all/0/1&quot;&gt;Jin Joo Park&lt;/a&gt; (2), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ryu_B/0/1/0/all/0/1&quot;&gt;Borim Ryu&lt;/a&gt; (2), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ha_J/0/1/0/all/0/1&quot;&gt;Jung-Woo Ha&lt;/a&gt; (1) ((1) Clova AI Research, NAVER Corp., (2) Seoul National University Bundang Hospital)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.00028">
<title>Feature discovery and visualization of robot mission data using convolutional autoencoders and Bayesian nonparametric topic models. (arXiv:1712.00028v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1712.00028</link>
<description rdf:parseType="Literal">&lt;p&gt;The gap between our ability to collect interesting data and our ability to
analyze these data is growing at an unprecedented rate. Recent algorithmic
attempts to fill this gap have employed unsupervised tools to discover
structure in data. Some of the most successful approaches have used
probabilistic models to uncover latent thematic structure in discrete data.
Despite the success of these models on textual data, they have not generalized
as well to image data, in part because of the spatial and temporal structure
that may exist in an image stream.
&lt;/p&gt;
&lt;p&gt;We introduce a novel unsupervised machine learning framework that
incorporates the ability of convolutional autoencoders to discover features
from images that directly encode spatial information, within a Bayesian
nonparametric topic model that discovers meaningful latent patterns within
discrete data. By using this hybrid framework, we overcome the fundamental
dependency of traditional topic models on rigidly hand-coded data
representations, while simultaneously encoding spatial dependency in our topics
without adding model complexity. We apply this model to the motivating
application of high-level scene understanding and mission summarization for
exploratory marine robots. Our experiments on a seafloor dataset collected by a
marine robot show that the proposed hybrid framework outperforms current
state-of-the-art approaches on the task of unsupervised seafloor terrain
characterization.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Flaspohler_G/0/1/0/all/0/1&quot;&gt;Genevieve Flaspohler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roy_N/0/1/0/all/0/1&quot;&gt;Nicholas Roy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Girdhar_Y/0/1/0/all/0/1&quot;&gt;Yogesh Girdhar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.00032">
<title>Paris-Lille-3D: a large and high-quality ground truth urban point cloud dataset for automatic segmentation and classification. (arXiv:1712.00032v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1712.00032</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper introduces a new Urban Point Cloud Dataset for Automatic
Segmentation and Classification acquired by Mobile Laser Scanning (MLS). We
describe how the dataset is obtained from acquisition to post-processing and
labeling. This dataset can be used to learn classification algorithm, however,
given that a great attention has been paid to the split between the different
objects, this dataset can also be used to learn the segmentation. The dataset
consists of around 2km of MLS point cloud acquired in two cities. The number of
points and range of classes make us consider that it can be used to train
Deep-Learning methods. Besides we show some results of automatic segmentation
and classification. The dataset is available at:
&lt;a href=&quot;http://caor-mines-paristech.fr/fr/paris-lille-3d-dataset/&quot;&gt;this http URL&lt;/a&gt;
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roynard_X/0/1/0/all/0/1&quot;&gt;Xavier Roynard&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deschaud_J/0/1/0/all/0/1&quot;&gt;Jean-Emmanuel Deschaud&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goulette_F/0/1/0/all/0/1&quot;&gt;Fran&amp;#xe7;ois Goulette&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.00117">
<title>Towards Personalized Modeling of the Female Hormonal Cycle: Experiments with Mechanistic Models and Gaussian Processes. (arXiv:1712.00117v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1712.00117</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we introduce a novel task for machine learning in healthcare,
namely personalized modeling of the female hormonal cycle. The motivation for
this work is to model the hormonal cycle and predict its phases in time, both
for healthy individuals and for those with disorders of the reproductive
system. Because there are individual differences in the menstrual cycle, we are
particularly interested in personalized models that can account for individual
idiosyncracies, towards identifying phenotypes of menstrual cycles. As a first
step, we consider the hormonal cycle as a set of observations through time. We
use a previously validated mechanistic model to generate realistic hormonal
patterns, and experiment with Gaussian process regression to estimate their
values over time. Specifically, we are interested in the feasibility of
predicting menstrual cycle phases under varying learning conditions: number of
cycles used for training, hormonal measurement noise and sampling rates, and
informed vs. agnostic sampling of hormonal measurements. Our results indicate
that Gaussian processes can help model the female menstrual cycle. We discuss
the implications of our experiments in the context of modeling the female
menstrual cycle.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Urteaga_I/0/1/0/all/0/1&quot;&gt;I&amp;#xf1;igo Urteaga&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Albers_D/0/1/0/all/0/1&quot;&gt;David J. Albers&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wheeler_M/0/1/0/all/0/1&quot;&gt;Marija Vlajic Wheeler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Druet_A/0/1/0/all/0/1&quot;&gt;Anna Druet&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Raffauf_H/0/1/0/all/0/1&quot;&gt;Hans Raffauf&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Elhadad_N/0/1/0/all/0/1&quot;&gt;No&amp;#xe9;mie Elhadad&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.00123">
<title>Label Efficient Learning of Transferable Representations across Domains and Tasks. (arXiv:1712.00123v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1712.00123</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a framework that learns a representation transferable across
different domains and tasks in a label efficient manner. Our approach battles
domain shift with a domain adversarial loss, and generalizes the embedding to
novel task using a metric learning-based approach. Our model is simultaneously
optimized on labeled source data and unlabeled or sparsely labeled data in the
target domain. Our method shows compelling results on novel classes within a
new domain even when only a few labeled examples per class are available,
outperforming the prevalent fine-tuning approach. In addition, we demonstrate
the effectiveness of our framework on the transfer learning task from image
object recognition to video action recognition.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Luo_Z/0/1/0/all/0/1&quot;&gt;Zelun Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zou_Y/0/1/0/all/0/1&quot;&gt;Yuliang Zou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hoffman_J/0/1/0/all/0/1&quot;&gt;Judy Hoffman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Fei_Fei_L/0/1/0/all/0/1&quot;&gt;Li Fei-Fei&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.00126">
<title>An interpretable latent variable model for attribute applicability in the Amazon catalogue. (arXiv:1712.00126v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1712.00126</link>
<description rdf:parseType="Literal">&lt;p&gt;Learning attribute applicability of products in the Amazon catalog (e.g.,
predicting that a shoe should have a value for size, but not for battery-type
at scale is a challenge. The need for an interpretable model is contingent on
(1) the lack of ground truth training data, (2) the need to utilise prior
information about the underlying latent space and (3) the ability to understand
the quality of predictions on new, unseen data. To this end, we develop the
MaxMachine, a probabilistic latent variable model that learns distributed
binary representations, associated to sets of features that are likely to
co-occur in the data. Layers of MaxMachines can be stacked such that higher
layers encode more abstract information. Any set of variables can be clamped to
encode prior information. We develop fast sampling based posterior inference.
Preliminary results show that the model improves over the baseline in 17 out of
19 product groups qualitatively reasonable predictions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rukat_T/0/1/0/all/0/1&quot;&gt;Tammo Rukat&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lange_D/0/1/0/all/0/1&quot;&gt;Dustin Lange&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Archambeau_C/0/1/0/all/0/1&quot;&gt;C&amp;#xe9;dric Archambeau&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.00155">
<title>Susceptibility Propagation by Using Diagonal Consistency. (arXiv:1712.00155v1 [cond-mat.stat-mech])</title>
<link>http://arxiv.org/abs/1712.00155</link>
<description rdf:parseType="Literal">&lt;p&gt;A susceptibility propagation that is constructed by combining a belief
propagation and a linear response method is used for approximate computation
for Markov random fields. Herein, we formulate a new, improved susceptibility
propagation by using the concept of a diagonal matching method that is based on
mean-field approaches to inverse Ising problems. The proposed susceptibility
propagation is robust for various network structures, and it is reduced to the
ordinary susceptibility propagation and to the adaptive
Thouless-Anderson-Palmer equation in special cases.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Yasuda_M/0/1/0/all/0/1&quot;&gt;Muneki Yasuda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Tanaka_K/0/1/0/all/0/1&quot;&gt;Kazuyuki Tanaka&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.00164">
<title>Generative Adversarial Networks for Electronic Health Records: A Framework for Exploring and Evaluating Methods for Predicting Drug-Induced Laboratory Test Trajectories. (arXiv:1712.00164v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1712.00164</link>
<description rdf:parseType="Literal">&lt;p&gt;Generative Adversarial Networks (GANs) represent a promising class of
generative networks that combine neural networks with game theory. From
generating realistic images and videos to assisting musical creation, GANs are
transforming many fields of arts and sciences. However, their application to
healthcare has not been fully realized, more specifically in generating
electronic health records (EHR) data. In this paper, we propose a framework for
exploring the value of GANs in the context of continuous laboratory time series
data. We devise an unsupervised evaluation method that measures the predictive
power of synthetic laboratory test time series. Further, we show that when it
comes to predicting the impact of drug exposure on laboratory test data,
incorporating representation learning of the training cohorts prior to training
GAN models is beneficial.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yahi_A/0/1/0/all/0/1&quot;&gt;Alexandre Yahi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vanguri_R/0/1/0/all/0/1&quot;&gt;Rami Vanguri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Elhadad_N/0/1/0/all/0/1&quot;&gt;No&amp;#xe9;mie Elhadad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tatonetti_N/0/1/0/all/0/1&quot;&gt;Nicholas P. Tatonetti&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.00171">
<title>Speaker identification from the sound of the human breath. (arXiv:1712.00171v1 [cs.SD])</title>
<link>http://arxiv.org/abs/1712.00171</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper examines the speaker identification potential of breath sounds in
continuous speech. Speech is largely produced during exhalation. In order to
replenish air in the lungs, speakers must periodically inhale. When inhalation
occurs in the midst of continuous speech, it is generally through the mouth.
Intra-speech breathing behavior has been the subject of much study, including
the patterns, cadence, and variations in energy levels. However, an often
ignored characteristic is the {\em sound} produced during the inhalation phase
of this cycle. Intra-speech inhalation is rapid and energetic, performed with
open mouth and glottis, effectively exposing the entire vocal tract to enable
maximum intake of air. This results in vocal tract resonances evoked by
turbulence that are characteristic of the speaker&apos;s speech-producing apparatus.
Consequently, the sounds of inhalation are expected to carry information about
the speaker&apos;s identity. Moreover, unlike other spoken sounds which are subject
to active control, inhalation sounds are generally more natural and less
affected by voluntary influences. The goal of this paper is to demonstrate that
breath sounds are indeed bio-signatures that can be used to identify speakers.
We show that these sounds by themselves can yield remarkably accurate speaker
recognition with appropriate feature representations and classification
frameworks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_W/0/1/0/all/0/1&quot;&gt;Wenbo Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1&quot;&gt;Yang Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singh_R/0/1/0/all/0/1&quot;&gt;Rita Singh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1&quot;&gt;Ming Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.00174">
<title>Rapid point-of-care Hemoglobin measurement through low-cost optics and Convolutional Neural Network based validation. (arXiv:1712.00174v1 [physics.med-ph])</title>
<link>http://arxiv.org/abs/1712.00174</link>
<description rdf:parseType="Literal">&lt;p&gt;A low-cost, robust, and simple mechanism to measure hemoglobin would play a
critical role in the modern health infrastructure. Consistent sample
acquisition has been a long-standing technical hurdle for photometer-based
portable hemoglobin detectors which rely on micro cuvettes and dry chemistry.
Any particulates (e.g. intact red blood cells (RBCs), microbubbles, etc.) in a
cuvette&apos;s sensing area drastically impact optical absorption profile, and
commercial hemoglobinometers lack the ability to automatically detect faulty
samples. We present the ground-up development of a portable, low-cost and open
platform with equivalent accuracy to medical-grade devices, with the addition
of CNN-based image processing for rapid sample viability prechecks. The
developed platform has demonstrated precision to the nearest $0.18[g/dL]$ of
hemoglobin, an R^2 = 0.945 correlation to hemoglobin absorption curves reported
in literature, and a 97% detection accuracy of poorly-prepared samples. We see
the developed hemoglobin device/ML platform having massive implications in
rural medicine, and consider it an excellent springboard for robust deep
learning optical spectroscopy: a currently untapped source of data for
detection of countless analytes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Wu_C/0/1/0/all/0/1&quot;&gt;Chris Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Tandon_T/0/1/0/all/0/1&quot;&gt;Tanay Tandon&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.00181">
<title>Personalized Gaussian Processes for Future Prediction of Alzheimer&apos;s Disease Progression. (arXiv:1712.00181v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1712.00181</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we introduce the use of a personalized Gaussian Process model
(pGP) to predict the key metrics of Alzheimer&apos;s Disease progression (MMSE,
ADAS-Cog13, CDRSB and CS) based on each patient&apos;s previous visits. We start by
learning a population-level model using multi-modal data from previously seen
patients using the base Gaussian Process (GP) regression. Then, this model is
adapted sequentially over time to a new patient using domain adaptive GPs to
form the patient&apos;s pGP. We show that this new approach, together with an
auto-regressive formulation, leads to significant improvements in forecasting
future clinical status and cognitive scores for target patients when compared
to modeling the population with traditional GPs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peterson_K/0/1/0/all/0/1&quot;&gt;Kelly Peterson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ognjen/0/1/0/all/0/1&quot;&gt;Ognjen&lt;/a&gt; (Oggi) &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rudovic/0/1/0/all/0/1&quot;&gt;Rudovic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guerrero_R/0/1/0/all/0/1&quot;&gt;Ricardo Guerrero&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Picard_R/0/1/0/all/0/1&quot;&gt;Rosalind W. Picard&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.00205">
<title>Tensors, Learning, and &apos;Kolmogorov Extension&apos; for Finite-alphabet Random Vectors. (arXiv:1712.00205v1 [eess.SP])</title>
<link>http://arxiv.org/abs/1712.00205</link>
<description rdf:parseType="Literal">&lt;p&gt;Estimating the joint probability mass function (PMF) of a set of random
variables lies at the heart of statistical learning and signal processing.
Without structural assumptions, such as modeling the variables as a Markov
chain, tree, or other graphical model, joint PMF estimation is often considered
mission impossible - the number of unknowns grows exponentially with the number
of variables. But who gives us the structural model? Is there a generic,
&apos;non-parametric&apos; way to control joint PMF complexity without relying on a
priori structural assumptions regarding the underlying probability model? Is it
possible to discover the operational structure without biasing the analysis up
front? What if we only observe random subsets of the variables, can we still
reliably estimate the joint PMF of all? This paper shows, perhaps surprisingly,
that if the joint PMF of any three variables can be estimated, then the joint
PMF of all the variables can be provably recovered under relatively mild
conditions. The result is reminiscent of Kolmogorov&apos;s extension theorem -
consistent specification of lower-order distributions induces a unique
probability measure for the entire process. The difference is that for
processes of limited complexity (rank of the high-order PMF) it is possible to
obtain complete characterization from only third-order distributions. In fact
not all third order PMFs are needed; and under more stringent conditions even
second-order will do. Exploiting multilinear (tensor) algebra, this paper
proves that such higher-order PMF completion can be guaranteed - several
pertinent identifiability results are derived. It also provides a practical and
efficient algorithm to carry out the recovery task. Judiciously designed
simulations and real-data experiments on movie recommendation and data
classification are presented to showcase the effectiveness of the approach.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Kargas_N/0/1/0/all/0/1&quot;&gt;Nikos Kargas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Sidiropoulos_N/0/1/0/all/0/1&quot;&gt;Nicholas D. Sidiropoulos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Fu_X/0/1/0/all/0/1&quot;&gt;Xiao Fu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.00232">
<title>Optimal Algorithms for Distributed Optimization. (arXiv:1712.00232v1 [math.OC])</title>
<link>http://arxiv.org/abs/1712.00232</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we study the optimal convergence rate for distributed convex
optimization problems in networks. We model the communication restrictions
imposed by the network as a set of affine constraints and provide optimal
complexity bounds for four different setups, namely: the function $F(\xb)
\triangleq \sum_{i=1}^{m}f_i(\xb)$ is strongly convex and smooth, either
strongly convex or smooth or just convex. Our results show that Nesterov&apos;s
accelerated gradient descent on the dual problem can be executed in a
distributed manner and obtains the same optimal rates as in the centralized
version of the problem (up to constant or logarithmic factors) with an
additional cost related to the spectral gap of the interaction matrix. Finally,
we discuss some extensions to the proposed setup such as proximal friendly
functions, time-varying graphs, improvement of the condition numbers.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Uribe_C/0/1/0/all/0/1&quot;&gt;C&amp;#xe9;sar A. Uribe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Lee_S/0/1/0/all/0/1&quot;&gt;Soomin Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Gasnikov_A/0/1/0/all/0/1&quot;&gt;Alexander Gasnikov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Nedic_A/0/1/0/all/0/1&quot;&gt;Angelia Nedi&amp;#x107;&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.00254">
<title>Utilizing Domain Knowledge in End-to-End Audio Processing. (arXiv:1712.00254v1 [cs.SD])</title>
<link>http://arxiv.org/abs/1712.00254</link>
<description rdf:parseType="Literal">&lt;p&gt;End-to-end neural network based approaches to audio modelling are generally
outperformed by models trained on high-level data representations. In this
paper we present preliminary work that shows the feasibility of training the
first layers of a deep convolutional neural network (CNN) model to learn the
commonly-used log-scaled mel-spectrogram transformation. Secondly, we
demonstrate that upon initializing the first layers of an end-to-end CNN
classifier with the learned transformation, convergence and performance on the
ESC-50 environmental sound classification dataset are similar to a CNN-based
model trained on the highly pre-processed log-scaled mel-spectrogram features.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tax_T/0/1/0/all/0/1&quot;&gt;Tycho Max Sylvester Tax&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Antich_J/0/1/0/all/0/1&quot;&gt;Jose Luis Diez Antich&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Purwins_H/0/1/0/all/0/1&quot;&gt;Hendrik Purwins&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Maaloe_L/0/1/0/all/0/1&quot;&gt;Lars Maal&amp;#xf8;e&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.00269">
<title>GANosaic: Mosaic Creation with Generative Texture Manifolds. (arXiv:1712.00269v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1712.00269</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents a novel framework for generating texture mosaics with
convolutional neural networks. Our method is called GANosaic and performs
optimization in the latent noise space of a generative texture model, which
allows the transformation of a content image into a mosaic exhibiting the
visual properties of the underlying texture manifold. To represent that
manifold, we use a state-of-the-art generative adversarial method for texture
synthesis, which can learn expressive texture representations from data and
produce mosaic images with very high resolution. This fully convolutional model
generates smooth (without any visible borders) mosaic images which morph and
blend different textures locally. In addition, we develop a new type of
differentiable statistical regularization appropriate for optimization over the
prior noise space of the PSGAN model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jetchev_N/0/1/0/all/0/1&quot;&gt;Nikolay Jetchev&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bergmann_U/0/1/0/all/0/1&quot;&gt;Urs Bergmann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Seward_C/0/1/0/all/0/1&quot;&gt;Calvin Seward&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.00287">
<title>Faithful Model Inversion Substantially Improves Auto-encoding Variational Inference. (arXiv:1712.00287v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1712.00287</link>
<description rdf:parseType="Literal">&lt;p&gt;In learning deep generative models, the encoder for variational inference is
typically formed in an ad hoc manner with a structure and parametrization
analogous to the forward model. Our chief insight is that this results in
coarse approximations to the posterior, and that the d-separation properties of
the BN structure of the forward model should be used, in a principled way, to
produce ones that are faithful to the posterior, for which we introduce the
novel Compact Minimal I-map (CoMI) algorithm. Applying our method to common
models reveals that standard encoder design choices lack many important edges,
and through experiments we demonstrate that modelling these edges is important
for optimal learning. We show how using a faithful encoder is crucial when
modelling with continuous relaxations of categorical distributions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Webb_S/0/1/0/all/0/1&quot;&gt;Stefan Webb&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Golinski_A/0/1/0/all/0/1&quot;&gt;Adam Golinski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zinkov_R/0/1/0/all/0/1&quot;&gt;Robert Zinkov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Siddharth_N/0/1/0/all/0/1&quot;&gt;N. Siddharth&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Teh_Y/0/1/0/all/0/1&quot;&gt;Yee Whye Teh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wood_F/0/1/0/all/0/1&quot;&gt;Frank Wood&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.00288">
<title>Prior and Likelihood Choices for Bayesian Matrix Factorisation on Small Datasets. (arXiv:1712.00288v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1712.00288</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we study the effects of different prior and likelihood choices
for Bayesian matrix factorisation, focusing on small datasets. These choices
can greatly influence the predictive performance of the methods. We identify
four groups of approaches: Gaussian-likelihood with real-valued priors,
nonnegative priors, semi-nonnegative models, and finally Poisson-likelihood
approaches. For each group we review several models from the literature,
considering sixteen in total, and discuss the relations between different
priors and matrix norms. We extensively compare these methods on eight
real-world datasets across three application areas, giving both inter- and
intra-group comparisons. We measure convergence runtime speed, cross-validation
performance, sparse and noisy prediction performance, and model selection
robustness. We offer several insights into the trade-offs between prior and
likelihood choices for Bayesian matrix factorisation on small datasets - such
as that Poisson models give poor predictions, and that nonnegative models are
more constrained than real-valued ones.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Brouwer_T/0/1/0/all/0/1&quot;&gt;Thomas Brouwer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lio_P/0/1/0/all/0/1&quot;&gt;Pietro Lio&amp;#x27;&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.00310">
<title>Deep Learning with Permutation-invariant Operator for Multi-instance Histopathology Classification. (arXiv:1712.00310v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1712.00310</link>
<description rdf:parseType="Literal">&lt;p&gt;The computer-aided analysis of medical scans is a longstanding goal in the
medical imaging field. Currently, deep learning has became a dominant
methodology for supporting pathologists and radiologist. Deep learning
algorithm have been successfully applied to digital pathology and radiology,
nevertheless, there are still practical issues that prevent these tool to be
widely used in practice. The main obstacles are low number of available cases
and large size of images (a.k.a. the small n, large p problem in machine
learning), and a very limited access to annotation at a pixel level that can
lead to severe overfitting and large computational requirements. We propose to
handle these issues by introducing a framework that processes a medical image
as a collection of small patches using a single, shared neural network. The
final diagnosis is provided by combining scores of individual patches using a
permutation-invariant operator (combination). In machine learning community
such approach is called a multi-instance learning (MIL).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tomczak_J/0/1/0/all/0/1&quot;&gt;Jakub M. Tomczak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ilse_M/0/1/0/all/0/1&quot;&gt;Maximilian Ilse&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Welling_M/0/1/0/all/0/1&quot;&gt;Max Welling&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.00311">
<title>Folded Recurrent Neural Networks for Future Video Prediction. (arXiv:1712.00311v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1712.00311</link>
<description rdf:parseType="Literal">&lt;p&gt;Future video prediction is an ill-posed Computer Vision problem that recently
received much attention. Its main challenges are the high variability in video
content, the propagation of errors through time, and the non-specificity of the
future frames: given a sequence of past frames there is a continuous
distribution of possible futures. This work introduces bijective Gated
Recurrent Units, a double mapping between the input and output of a GRU layer.
This allows for recurrent auto-encoders with state sharing between encoder and
decoder, stratifying the sequence representation and helping to prevent
capacity problems. We show how with this topology only the encoder or decoder
needs to be applied for input encoding and prediction, respectively. This
reduces the computational cost and avoids re-encoding the predictions when
generating a sequence of frames, mitigating the propagation of errors.
Furthermore, it is possible to remove layers from an already trained model,
giving an insight to the role performed by each layer and making the model more
explainable. We evaluate our approach on three video datasets, outperforming
state of the art prediction results on MMNIST and UCF101, and obtaining
competitive results on KTH with 2 and 3 times less memory usage and
computational cost than the best scored approach.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oliu_M/0/1/0/all/0/1&quot;&gt;Marc Oliu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Selva_J/0/1/0/all/0/1&quot;&gt;Javier Selva&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Escalera_S/0/1/0/all/0/1&quot;&gt;Sergio Escalera&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.00328">
<title>Group Sparse Bayesian Learning for Active Surveillance on Epidemic Dynamics. (arXiv:1712.00328v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1712.00328</link>
<description rdf:parseType="Literal">&lt;p&gt;Predicting epidemic dynamics is of great value in understanding and
controlling diffusion processes, such as infectious disease spread and
information propagation. This task is intractable, especially when surveillance
resources are very limited. To address the challenge, we study the problem of
active surveillance, i.e., how to identify a small portion of system components
as sentinels to effect monitoring, such that the epidemic dynamics of an entire
system can be readily predicted from the partial data collected by such
sentinels. We propose a novel measure, the gamma value, to identify the
sentinels by modeling a sentinel network with row sparsity structure. We design
a flexible group sparse Bayesian learning algorithm to mine the sentinel
network suitable for handling both linear and non-linear dynamical systems by
using the expectation maximization method and variational approximation. The
efficacy of the proposed algorithm is theoretically analyzed and empirically
validated using both synthetic and real-world data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pei_H/0/1/0/all/0/1&quot;&gt;Hongbin Pei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yang_B/0/1/0/all/0/1&quot;&gt;Bo Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Jiming Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Dong_L/0/1/0/all/0/1&quot;&gt;Lei Dong&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.00368">
<title>Hierarchical Bayesian image analysis: from low-level modeling to robust supervised learning. (arXiv:1712.00368v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1712.00368</link>
<description rdf:parseType="Literal">&lt;p&gt;Within a supervised classification framework, labeled data are used to learn
classifier parameters. Prior to that, it is generally required to perform
dimensionality reduction via feature extraction. These preprocessing steps have
motivated numerous research works aiming at recovering latent variables in an
unsupervised context. This paper proposes a unified framework to perform
classification and low-level modeling jointly. The main objective is to use the
estimated latent variables as features for classification and to incorporate
simultaneously supervised information to help latent variable extraction. The
proposed hierarchical Bayesian model is divided into three stages: a first
low-level modeling stage to estimate latent variables, a second stage
clustering these features into statistically homogeneous groups and a last
classification stage exploiting the (possibly badly) labeled data. Performance
of the model is assessed in the specific context of hyperspectral image
interpretation, unifying two standard analysis techniques, namely unmixing and
classification.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lagrange_A/0/1/0/all/0/1&quot;&gt;Adrien Lagrange&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fauvel_M/0/1/0/all/0/1&quot;&gt;Mathieu Fauvel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+May_S/0/1/0/all/0/1&quot;&gt;St&amp;#xe9;phane May&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dobigeon_N/0/1/0/all/0/1&quot;&gt;Nicolas Dobigeon&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.00409">
<title>Deep Learning Scaling is Predictable, Empirically. (arXiv:1712.00409v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1712.00409</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep learning (DL) creates impactful advances following a virtuous recipe:
model architecture search, creating large training data sets, and scaling
computation. It is widely believed that growing training sets and models should
improve accuracy and result in better products. As DL application domains grow,
we would like a deeper understanding of the relationships between training set
size, computational scale, and model accuracy improvements to advance the
state-of-the-art.
&lt;/p&gt;
&lt;p&gt;This paper presents a large scale empirical characterization of
generalization error and model size growth as training sets grow. We introduce
a methodology for this measurement and test four machine learning domains:
machine translation, language modeling, image processing, and speech
recognition. Our empirical results show power-law generalization error scaling
across a breadth of factors, resulting in power-law exponents---the &quot;steepness&quot;
of the learning curve---yet to be explained by theoretical work. Further, model
improvements only shift the error but do not appear to affect the power-law
exponent. We also show that model size scales sublinearly with data size. These
scaling relationships have significant implications on deep learning research,
practice, and systems. They can assist model debugging, setting accuracy
targets, and decisions about data set growth. They can also guide computing
system design and underscore the importance of continued computational scaling.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hestness_J/0/1/0/all/0/1&quot;&gt;Joel Hestness&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Narang_S/0/1/0/all/0/1&quot;&gt;Sharan Narang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ardalani_N/0/1/0/all/0/1&quot;&gt;Newsha Ardalani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Diamos_G/0/1/0/all/0/1&quot;&gt;Gregory Diamos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jun_H/0/1/0/all/0/1&quot;&gt;Heewoo Jun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kianinejad_H/0/1/0/all/0/1&quot;&gt;Hassan Kianinejad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Patwary_M/0/1/0/all/0/1&quot;&gt;Md. Mostofa Ali Patwary&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1&quot;&gt;Yang Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1&quot;&gt;Yanqi Zhou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.00424">
<title>The reparameterization trick for acquisition functions. (arXiv:1712.00424v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1712.00424</link>
<description rdf:parseType="Literal">&lt;p&gt;Bayesian optimization is a sample-efficient approach to solving global
optimization problems. Along with a surrogate model, this approach relies on
theoretically motivated value heuristics (acquisition functions) to guide the
search process. Maximizing acquisition functions yields the best performance;
unfortunately, this ideal is difficult to achieve since optimizing acquisition
functions per se is frequently non-trivial. This statement is especially true
in the parallel setting, where acquisition functions are routinely non-convex,
high-dimensional, and intractable. Here, we demonstrate how many popular
acquisition functions can be formulated as Gaussian integrals amenable to the
reparameterization trick and, ensuingly, gradient-based optimization. Further,
we use this reparameterized representation to derive an efficient Monte Carlo
estimator for the upper confidence bound acquisition function in the context of
parallel selection.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wilson_J/0/1/0/all/0/1&quot;&gt;James T. Wilson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Moriconi_R/0/1/0/all/0/1&quot;&gt;Riccardo Moriconi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hutter_F/0/1/0/all/0/1&quot;&gt;Frank Hutter&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Deisenroth_M/0/1/0/all/0/1&quot;&gt;Marc Peter Deisenroth&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.00443">
<title>Deep Neural Network Architectures for Modulation Classification. (arXiv:1712.00443v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1712.00443</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work, we investigate the value of employing deep learning for the
task of wireless signal modulation recognition. Recently in [1], a framework
has been introduced by generating a dataset using GNU radio that mimics the
imperfections in a real wireless channel, and uses 11 different modulation
types. Further, a convolutional neural network (CNN) architecture was developed
and shown to deliver performance that exceeds that of expert-based approaches.
Here, we follow the framework of [1] and find deep neural network architectures
that deliver higher accuracy than the state of the art. We tested the
architecture of [1] and found it to achieve an accuracy of approximately 75% of
correctly recognizing the modulation type. We first tune the CNN architecture
of [1] and find a design with four convolutional layers and two dense layers
that gives an accuracy of approximately 83.8% at high SNR. We then develop
architectures based on the recently introduced ideas of Residual Networks
(ResNet [2]) and Densely Connected Networks (DenseNet [3]) to achieve high SNR
accuracies of approximately 83.5% and 86.6%, respectively. Finally, we
introduce a Convolutional Long Short-term Deep Neural Network (CLDNN [4]) to
achieve an accuracy of approximately 88.5% at high SNR.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1&quot;&gt;Xiaoyu Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_D/0/1/0/all/0/1&quot;&gt;Diyu Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gamal_A/0/1/0/all/0/1&quot;&gt;Aly El Gamal&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1509.04752">
<title>Bayesian inference for spatio-temporal spike-and-slab priors. (arXiv:1509.04752v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1509.04752</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work, we address the problem of solving a series of underdetermined
linear inverse problems subject to a sparsity constraint. We generalize the
spike-and-slab prior distribution to encode a priori correlation of the support
of the solution in both space and time by imposing a transformed Gaussian
process on the spike-and-slab probabilities. An expectation propagation (EP)
algorithm for posterior inference under the proposed model is derived. For
large scale problems, the standard EP algorithm can be prohibitively slow. We
therefore introduce three different approximation schemes to reduce the
computational complexity. Finally, we demonstrate the proposed model using
numerical experiments based on both synthetic and real data sets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Andersen_M/0/1/0/all/0/1&quot;&gt;Michael Riis Andersen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Vehtari_A/0/1/0/all/0/1&quot;&gt;Aki Vehtari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Winther_O/0/1/0/all/0/1&quot;&gt;Ole Winther&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hansen_L/0/1/0/all/0/1&quot;&gt;Lars Kai Hansen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1512.01631">
<title>Hierarchical Sparse Modeling: A Choice of Two Group Lasso Formulations. (arXiv:1512.01631v4 [stat.ME] UPDATED)</title>
<link>http://arxiv.org/abs/1512.01631</link>
<description rdf:parseType="Literal">&lt;p&gt;Demanding sparsity in estimated models has become a routine practice in
statistics. In many situations, we wish to require that the sparsity patterns
attained honor certain problem-specific constraints. Hierarchical sparse
modeling (HSM) refers to situations in which these constraints specify that one
set of parameters be set to zero whenever another is set to zero. In recent
years, numerous papers have developed convex regularizers for this form of
sparsity structure, which arises in many areas of statistics including
interaction modeling, time series analysis, and covariance estimation. In this
paper, we observe that these methods fall into two frameworks, the group lasso
(GL) and latent overlapping group lasso (LOG), which have not been
systematically compared in the context of HSM. The purpose of this paper is to
provide a side-by-side comparison of these two frameworks for HSM in terms of
their statistical properties and computational efficiency. We call special
attention to GL&apos;s more aggressive shrinkage of parameters deep in the
hierarchy, a property not shared by LOG. In terms of computation, we introduce
a finite-step algorithm that exactly solves the proximal operator of LOG for a
certain simple HSM structure; we later exploit this to develop a novel
path-based block coordinate descent scheme for general HSM structures. Both
algorithms greatly improve the computational performance of LOG. Finally, we
compare the two methods in the context of covariance estimation, where we
introduce a new sparsely-banded estimator using LOG, which we show achieves the
statistical advantages of an existing GL-based method but is simpler to express
and more efficient to compute.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yan_X/0/1/0/all/0/1&quot;&gt;Xiaohan Yan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bien_J/0/1/0/all/0/1&quot;&gt;Jacob Bien&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1701.02776">
<title>Universal Joint Image Clustering and Registration using Partition Information. (arXiv:1701.02776v2 [cs.IT] UPDATED)</title>
<link>http://arxiv.org/abs/1701.02776</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the problem of universal joint clustering and registration of
images and define algorithms using multivariate information functionals. We
first study registering two images using maximum mutual information and prove
its asymptotic optimality. We then show the shortcomings of pairwise
registration in multi-image registration, and design an asymptotically optimal
algorithm based on multiinformation. Further, we define a novel multivariate
information functional to perform joint clustering and registration of images,
and prove consistency of the algorithm. Finally, we consider registration and
clustering of numerous limited-resolution images, defining algorithms that are
order-optimal in scaling of number of pixels in each image with the number of
images.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Raman_R/0/1/0/all/0/1&quot;&gt;Ravi Kiran Raman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Varshney_L/0/1/0/all/0/1&quot;&gt;Lav R. Varshney&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1703.10893">
<title>Audio-Visual Speech Enhancement based on Multimodal Deep Convolutional Neural Networks. (arXiv:1703.10893v4 [cs.SD] UPDATED)</title>
<link>http://arxiv.org/abs/1703.10893</link>
<description rdf:parseType="Literal">&lt;p&gt;Speech enhancement (SE) aims to reduce noise in speech signals. Most SE
techniques focus only on addressing audio information. In this work, inspired
by multimodal learning, which utilizes data from different modalities, and the
recent success of convolutional neural networks (CNNs) in SE, we propose an
audio-visual deep CNNs (AVDCNN) SE model, which incorporates audio and visual
streams into a unified network model. We also propose a multi-task learning
framework for reconstructing audio and visual signals at the output layer.
Precisely speaking, the proposed AVDCNN model is structured as an audio-visual
encoder-decoder network, in which audio and visual data are first processed
using individual CNNs, and then fused into a joint network to generate enhanced
speech (the primary task) and reconstructed images (the secondary task) at the
output layer. The model is trained in an end-to-end manner, and parameters are
jointly learned through back-propagation. We evaluate enhanced speech using
five instrumental criteria. Results show that the AVDCNN model yields a notably
superior performance compared with an audio-only CNN-based SE model and two
conventional SE approaches, confirming the effectiveness of integrating visual
information into the SE process. In addition, the AVDCNN model also outperforms
an existing audio-visual SE model, confirming its capability of effectively
combining audio and visual information in SE.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hou_J/0/1/0/all/0/1&quot;&gt;Jen-Cheng Hou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1&quot;&gt;Syu-Siang Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lai_Y/0/1/0/all/0/1&quot;&gt;Ying-Hui Lai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tsao_Y/0/1/0/all/0/1&quot;&gt;Yu Tsao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chang_H/0/1/0/all/0/1&quot;&gt;Hsiu-Wen Chang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1&quot;&gt;Hsin-Min Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1704.01701">
<title>Learning Certifiably Optimal Rule Lists for Categorical Data. (arXiv:1704.01701v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1704.01701</link>
<description rdf:parseType="Literal">&lt;p&gt;We present the design and implementation of a custom discrete optimization
technique for building rule lists over a categorical feature space. Our
algorithm produces rule lists with optimal training performance, according to
the regularized empirical risk, with a certificate of optimality. By leveraging
algorithmic bounds, efficient data structures, and computational reuse, we
achieve several orders of magnitude speedup in time and a massive reduction of
memory consumption. We demonstrate that our approach produces optimal rule
lists on practical problems in seconds. Our results indicate that it is
possible to construct optimal sparse rule lists that are approximately as
accurate as the COMPAS proprietary risk prediction tool on data from Broward
County, Florida, but that are completely interpretable. This framework is a
novel alternative to CART and other decision tree methods for interpretable
modeling.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Angelino_E/0/1/0/all/0/1&quot;&gt;Elaine Angelino&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Larus_Stone_N/0/1/0/all/0/1&quot;&gt;Nicholas Larus-Stone&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Alabi_D/0/1/0/all/0/1&quot;&gt;Daniel Alabi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Seltzer_M/0/1/0/all/0/1&quot;&gt;Margo Seltzer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rudin_C/0/1/0/all/0/1&quot;&gt;Cynthia Rudin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1706.05374">
<title>Expected Policy Gradients. (arXiv:1706.05374v4 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1706.05374</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose expected policy gradients (EPG), which unify stochastic policy
gradients (SPG) and deterministic policy gradients (DPG) for reinforcement
learning. Inspired by expected sarsa, EPG integrates across the action when
estimating the gradient, instead of relying only on the action in the sampled
trajectory. We establish a new general policy gradient theorem, of which the
stochastic and deterministic policy gradient theorems are special cases. We
also prove that EPG reduces the variance of the gradient estimates without
requiring deterministic policies and, for the Gaussian case, with no
computational overhead. Finally, we show that it is optimal in a certain sense
to explore with a Gaussian policy such that the covariance is proportional to
the exponential of the scaled Hessian of the critic with respect to the
actions. We present empirical results confirming that this new form of
exploration substantially outperforms DPG with the Ornstein-Uhlenbeck heuristic
in four challenging MuJoCo domains.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ciosek_K/0/1/0/all/0/1&quot;&gt;Kamil Ciosek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Whiteson_S/0/1/0/all/0/1&quot;&gt;Shimon Whiteson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1707.07012">
<title>Learning Transferable Architectures for Scalable Image Recognition. (arXiv:1707.07012v3 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1707.07012</link>
<description rdf:parseType="Literal">&lt;p&gt;Developing neural network image classification models often requires
significant architecture engineering. In this paper, we attempt to automate
this engineering process by learning the model architectures directly on the
dataset of interest. As this approach is expensive when the dataset is large,
we propose to search for an architectural building block on a small dataset and
then transfer the block to a larger dataset. Our key contribution is the design
of a new search space which enables transferability. In our experiments, we
search for the best convolutional layer (or &quot;cell&quot;) on the CIFAR-10 dataset and
then apply this cell to the ImageNet dataset by stacking together more copies
of this cell, each with their own parameters. Although the cell is not searched
for directly on ImageNet, an architecture constructed from the best cell
achieves, among the published works, state-of-the-art accuracy of 82.7% top-1
and 96.2% top-5 on ImageNet. Our model is 1.2% better in top-1 accuracy than
the best human-invented architectures while having 9 billion fewer FLOPS -- a
reduction of 28% in computational demand from the previous state-of-the-art
model. When evaluated at different levels of computational cost, accuracies of
our models exceed those of the state-of-the-art human-designed models. For
instance, a smaller network constructed from the best cell also achieves 74%
top-1 accuracy, which is 3.1% better than equivalently-sized, state-of-the-art
models for mobile platforms. On CIFAR-10, an architecture constructed from the
best cell achieves 2.4% error rate, which is also state-of-the-art. Finally,
the image features learned from image classification can also be transferred to
other computer vision problems. On the task of object detection, the learned
features used with the Faster-RCNN framework surpass state-of-the-art by 4.0%
achieving 43.1% mAP on the COCO dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zoph_B/0/1/0/all/0/1&quot;&gt;Barret Zoph&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vasudevan_V/0/1/0/all/0/1&quot;&gt;Vijay Vasudevan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shlens_J/0/1/0/all/0/1&quot;&gt;Jonathon Shlens&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Le_Q/0/1/0/all/0/1&quot;&gt;Quoc V. Le&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.04495">
<title>Inverse Ising problem in continuous time: A latent variable approach. (arXiv:1709.04495v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1709.04495</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the inverse Ising problem, i.e. the inference of network
couplings from observed spin trajectories for a model with continuous time
Glauber dynamics. By introducing two sets of auxiliary latent random variables
we render the likelihood into a form, which allows for simple iterative
inference algorithms with analytical updates. The variables are: (1) Poisson
variables to linearise an exponential term which is typical for point process
likelihoods and (2) P\&apos;olya-Gamma variables, which make the likelihood
quadratic in the coupling parameters. Using the augmented likelihood, we derive
an expectation-maximization (EM) algorithm to obtain the maximum likelihood
estimate of network parameters. Using a third set of latent variables we extend
the EM algorithm to sparse couplings via L1 regularization. Finally, we develop
an efficient approximate Bayesian inference algorithm using a variational
approach. We demonstrate the performance of our algorithms on data simulated
from an Ising model. For data which are simulated from a more biologically
plausible network with spiking neurons, we show that the Ising model captures
well the low order statistics of the data and how the Ising couplings are
related to the underlying synaptic structure of the simulated network.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Donner_C/0/1/0/all/0/1&quot;&gt;Christian Donner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Opper_M/0/1/0/all/0/1&quot;&gt;Manfred Opper&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.04461">
<title>An Improved Naive Bayes Classifier-based Noise Detection Technique for Classifying User Phone Call Behavior. (arXiv:1710.04461v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1710.04461</link>
<description rdf:parseType="Literal">&lt;p&gt;The presence of noisy instances in mobile phone data is a fundamental issue
for classifying user phone call behavior (i.e., accept, reject, missed and
outgoing), with many potential negative consequences. The classification
accuracy may decrease and the complexity of the classifiers may increase due to
the number of redundant training samples. To detect such noisy instances from a
training dataset, researchers use naive Bayes classifier (NBC) as it identifies
misclassified instances by taking into account independence assumption and
conditional probabilities of the attributes. However, some of these
misclassified instances might indicate usages behavioral patterns of individual
mobile phone users. Existing naive Bayes classifier based noise detection
techniques have not considered this issue and, thus, are lacking in
classification accuracy. In this paper, we propose an improved noise detection
technique based on naive Bayes classifier for effectively classifying users&apos;
phone call behaviors. In order to improve the classification accuracy, we
effectively identify noisy instances from the training dataset by analyzing the
behavioral patterns of individuals. We dynamically determine a noise threshold
according to individual&apos;s unique behavioral patterns by using both the naive
Bayes classifier and Laplace estimator. We use this noise threshold to identify
noisy instances. To measure the effectiveness of our technique in classifying
user phone call behavior, we employ the most popular classification algorithm
(e.g., decision tree). Experimental results on the real phone call log dataset
show that our proposed technique more accurately identifies the noisy instances
from the training datasets that leads to better classification accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sarker_I/0/1/0/all/0/1&quot;&gt;Iqbal H. Sarker&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kabir_M/0/1/0/all/0/1&quot;&gt;Muhammad Ashad Kabir&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Colman_A/0/1/0/all/0/1&quot;&gt;Alan Colman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1&quot;&gt;Jun Han&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.09325">
<title>Training Confidence-calibrated Classifiers for Detecting Out-of-Distribution Samples. (arXiv:1711.09325v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1711.09325</link>
<description rdf:parseType="Literal">&lt;p&gt;The problem of detecting whether a test sample is from in-distribution (i.e.,
training distribution by a classifier) or out-of-distribution sufficiently
different from it arises in many real-world machine learning applications.
However, the state-of-art deep neural networks are known to be highly
overconfident in their predictions, i.e., do not distinguish in- and
out-of-distributions. Recently, to handle this issue, several threshold-based
detectors have been proposed given pre-trained neural classifiers. However, the
performance of prior works highly depends on how to train the classifiers since
they only focus on improving inference procedures. In this paper, we develop a
novel training method for classifiers so that such inference algorithms can
work better. In particular, we suggest two additional terms added to the
original loss (e.g., cross entropy). The first one forces samples from
out-of-distribution less confident by the classifier and the second one is for
(implicitly) generating most effective training samples for the first one. In
essence, our method jointly trains both classification and generative neural
networks for out-of-distribution. We demonstrate its effectiveness using deep
convolutional neural networks on various popular image datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lee_K/0/1/0/all/0/1&quot;&gt;Kimin Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lee_H/0/1/0/all/0/1&quot;&gt;Honglak Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lee_K/0/1/0/all/0/1&quot;&gt;Kibok Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Shin_J/0/1/0/all/0/1&quot;&gt;Jinwoo Shin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.10057">
<title>Predicting Adolescent Suicide Attempts with Neural Networks. (arXiv:1711.10057v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1711.10057</link>
<description rdf:parseType="Literal">&lt;p&gt;Though suicide is a major public health problem in the US, machine learning
methods are not commonly used to predict an individual&apos;s risk of
attempting/committing suicide. In the present work, starting with an anonymized
collection of electronic health records for 522,056 unique, California-resident
adolescents, we develop neural network models to predict suicide attempts. We
frame the problem as a binary classification problem in which we use a
patient&apos;s data from 2006-2009 to predict either the presence (1) or absence (0)
of a suicide attempt in 2010. After addressing issues such as severely
imbalanced classes and the variable length of a patient&apos;s history, we build
neural networks with depths varying from two to eight hidden layers. For test
set observations where we have at least five ED/hospital visits&apos; worth of data
on a patient, our depth-4 model achieves a sensitivity of 0.703, specificity of
0.980, and AUC of 0.958.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bhat_H/0/1/0/all/0/1&quot;&gt;Harish S. Bhat&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Goldman_Mellor_S/0/1/0/all/0/1&quot;&gt;Sidra J. Goldman-Mellor&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.11386">
<title>MR image reconstruction using the learned data distribution as prior. (arXiv:1711.11386v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1711.11386</link>
<description rdf:parseType="Literal">&lt;p&gt;MR image reconstruction from undersampled data exploits priors to compensate
for missing k-space data. This has previously been achieved by using
regularization methods, such as TV and wavelets, or data adaptive methods, such
as dictionary learning. We propose to explicitly learn the probability
distribution of MR image patches and to constrain patches to have a high
probability according to this distribution in reconstruction, effectively
employing it as the prior.
&lt;/p&gt;
&lt;p&gt;We use variational autoencoders (VAE) to learn the distribution of MR image
patches. This high dimensional distribution is modelled by a latent parameter
model of lower dimensions in a non-linear fashion. We develop a reconstruction
algorithm that uses the learned prior in a Maximum-A-Posteriori estimation
formulation. We evaluate the proposed method with T1 weighted images and
compare it to existing alternatives. We also apply our method on images with
white matter lesions.
&lt;/p&gt;
&lt;p&gt;Visual evaluation of the samples drawn from the learned model showed that the
VAE algorithm was able to approximate the distribution of MR image patches.
Furthermore, the reconstruction algorithm using the approximate distribution
produced qualitatively better results. The proposed technique achieved RMSE,
CNR and CN values of 2.77%, 0.43, 0.11 and 4.29%, 0.43, 0.11 for undersampling
ratios of 2 and 3, respectively. It outperformed other evaluated methods in
terms of used metrics. In the experiments on images with white matter lesions,
the method faithfully reconstructed the lesions.
&lt;/p&gt;
&lt;p&gt;We introduced a novel method for MR reconstruction, which takes a new
perspective on regularization by learning priors. Results suggest the method
compares favorably against TV and dictionary based methods as well as the
neural-network based ADMM-Net in terms of the RMSE, CNR and CN and perceptual
image quality and can reconstruct lesions as well.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tezcan_K/0/1/0/all/0/1&quot;&gt;Kerem C. Tezcan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Baumgartner_C/0/1/0/all/0/1&quot;&gt;Christian F. Baumgartner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Konukoglu_E/0/1/0/all/0/1&quot;&gt;Ender Konukoglu&lt;/a&gt;</dc:creator>
</item></rdf:RDF>