<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Good papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Good Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-02-19T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06288"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06360"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06467"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06488"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.06761"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04364"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06091"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06215"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06225"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06412"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06521"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1706.06060"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.02013"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.07686"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.04406"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04289"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06167"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06222"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06287"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06368"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06383"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06384"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06403"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06432"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06441"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06463"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06552"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06640"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06677"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.07172"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.00961"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.01952"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.05558"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1802.06288">
<title>Implementation of Neural Network and feature extraction to classify ECG signals. (arXiv:1802.06288v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1802.06288</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents a suitable and efficient implementation of a feature
extraction algorithm (Pan Tompkins algorithm) on electrocardiography (ECG)
signals, for detection and classification of four cardiac diseases: Sleep
Apnea, Arrhythmia, Supraventricular Arrhythmia and Long Term Atrial
Fibrillation (AF) and differentiating them from the normal heart beat by using
pan Tompkins RR detection followed by feature extraction for classification
purpose .The paper also presents a new approach towards signal classification
using the existing neural networks classifiers.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Karthik_R/0/1/0/all/0/1&quot;&gt;R Karthik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tyagi_D/0/1/0/all/0/1&quot;&gt;Dhruv Tyagi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Raut_A/0/1/0/all/0/1&quot;&gt;Amogh Raut&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saxena_S/0/1/0/all/0/1&quot;&gt;Soumya Saxena&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+M_R/0/1/0/all/0/1&quot;&gt;Rajesh Kumar M&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06360">
<title>Anomaly Detection using One-Class Neural Networks. (arXiv:1802.06360v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.06360</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a one-class neural network (OC-NN) model to detect anomalies in
complex data sets. OC-NN combines the ability of deep networks to extract
progressively rich representation of data with the one-class objective of
creating a tight envelope around normal data. The OC-NN approach breaks new
ground for the following crucial reason: data representation in the hidden
layer is driven by the OC-NN objective and is thus customized for anomaly
detection. This is a departure from other approaches which use a hybrid
approach of learning deep features using an autoencoder and then feeding the
features into a separate anomaly detection method like one-class SVM (OC-SVM).
The hybrid OC-SVM approach is suboptimal because it is unable to influence
representational learning in the hidden layers. A comprehensive set of
experiments demonstrate that on complex data sets (like CIFAR and PFAM), OC-NN
significantly outperforms existing state-of-the-art anomaly detection methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chalapathy_R/0/1/0/all/0/1&quot;&gt;Raghavendra Chalapathy&lt;/a&gt; (University of Sydney and Capital Markets Cooperative Research Centre (CMCRC)), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Menon_A/0/1/0/all/0/1&quot;&gt;Aditya Krishna Menon&lt;/a&gt; (Data61/CSIRO and the Australian National University), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chawla_S/0/1/0/all/0/1&quot;&gt;Sanjay Chawla&lt;/a&gt; (Qatar Computing Research Institute (QCRI), HBKU)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06467">
<title>Memorize or generalize? Searching for a compositional RNN in a haystack. (arXiv:1802.06467v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.06467</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural networks are very powerful learning systems, but they do not readily
generalize from one task to the other. This is partly due to the fact that they
do not learn in a compositional way, that is, by discovering skills that are
shared by different tasks, and recombining them to solve new problems. In this
paper, we explore the compositional generalization capabilities of recurrent
neural networks (RNNs). We first propose the lookup table composition domain as
a simple setup to test compositional behaviour and show that it is
theoretically possible for a standard RNN to learn to behave compositionally in
this domain when trained with standard gradient descent and provided with
additional supervision. We then remove this additional supervision and perform
a search over a large number of model initializations to investigate the
proportion of RNNs that can still converge to a compositional solution. We
discover that a small but non-negligible proportion of RNNs do reach partial
compositional solutions even without special architectural constraints. This
suggests that a combination of gradient descent and evolutionary strategies
directly favouring the minority models that developed more compositional
approaches might suffice to lead standard RNNs towards compositional solutions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liska_A/0/1/0/all/0/1&quot;&gt;Adam Li&amp;#x161;ka&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kruszewski_G/0/1/0/all/0/1&quot;&gt;Germ&amp;#xe1;n Kruszewski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Baroni_M/0/1/0/all/0/1&quot;&gt;Marco Baroni&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06488">
<title>Tiny SSD: A Tiny Single-shot Detection Deep Convolutional Neural Network for Real-time Embedded Object Detection. (arXiv:1802.06488v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1802.06488</link>
<description rdf:parseType="Literal">&lt;p&gt;Object detection is a major challenge in computer vision, involving both
object classification and object localization within a scene. While deep neural
networks have been shown in recent years to yield very powerful techniques for
tackling the challenge of object detection, one of the biggest challenges with
enabling such object detection networks for widespread deployment on embedded
devices is high computational and memory requirements. Recently, there has been
an increasing focus in exploring small deep neural network architectures for
object detection that are more suitable for embedded devices, such as Tiny YOLO
and SqueezeDet. Inspired by the efficiency of the Fire microarchitecture
introduced in SqueezeNet and the object detection performance of the
single-shot detection macroarchitecture introduced in SSD, this paper
introduces Tiny SSD, a single-shot detection deep convolutional neural network
for real-time embedded object detection that is composed of a highly optimized,
non-uniform Fire sub-network stack and a non-uniform sub-network stack of
highly optimized SSD-based auxiliary convolutional feature layers designed
specifically to minimize model size while maintaining object detection
performance. The resulting Tiny SSD possess a model size of 2.3MB (~26X smaller
than Tiny YOLO) while still achieving an mAP of 61.3% on VOC 2007 (~4.2% higher
than Tiny YOLO). These experimental results show that very small deep neural
network architectures can be designed for real-time object detection that are
well-suited for embedded scenarios.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wong_A/0/1/0/all/0/1&quot;&gt;Alexander Wong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shafiee_M/0/1/0/all/0/1&quot;&gt;Mohammad Javad Shafiee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_F/0/1/0/all/0/1&quot;&gt;Francis Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chwyl_B/0/1/0/all/0/1&quot;&gt;Brendan Chwyl&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.06761">
<title>Scalable Recollections for Continual Lifelong Learning. (arXiv:1711.06761v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1711.06761</link>
<description rdf:parseType="Literal">&lt;p&gt;Given the recent success of Deep Learning applied to a variety of single
tasks, it is natural to consider more human-realistic settings. Perhaps the
most difficult of these settings is that of continual lifelong learning, where
the model must learn online over a continuous stream of non-stationary data. A
continual lifelong learning system must have three primary capabilities to
succeed: it must learn and adapt over time, it must not forget what it has
learned, and it must be efficient in both training time and memory. Recent
techniques have focused their efforts largely on the first two capabilities
while the third capability remains largely unexplored. In this paper, we
consider the problem of efficient and effective storage of experiences over
very large time-frames. In particular we consider the case where typical
experiences are n bits and memories are limited to k bits for k &amp;lt;&amp;lt; n. We
present a novel scalable architecture and training algorithm in this
challenging domain and provide an extensive evaluation of its performance. Our
results show that we can achieve considerable gains on top of state-of-the-art
methods such as GEM.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Riemer_M/0/1/0/all/0/1&quot;&gt;Matthew Riemer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Klinger_T/0/1/0/all/0/1&quot;&gt;Tim Klinger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Franceschini_M/0/1/0/all/0/1&quot;&gt;Michele Franceschini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bouneffouf_D/0/1/0/all/0/1&quot;&gt;Djallel Bouneffouf&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04364">
<title>Junction Tree Variational Autoencoder for Molecular Graph Generation. (arXiv:1802.04364v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1802.04364</link>
<description rdf:parseType="Literal">&lt;p&gt;We seek to automate the design of molecules based on specific chemical
properties. In computational terms, this task involves continuous embedding and
generation of molecular graphs. Our primary contribution is the direct
realization of molecular graphs, a task previously approached by generating
linear SMILES strings instead of graphs. Our junction tree variational
autoencoder generates molecular graphs in two phases, by first generating a
tree-structured scaffold over chemical substructures, and then combining them
into a molecule with a graph message passing network. This approach allows us
to incrementally expand molecules while maintaining chemical validity at every
step. We evaluate our model on multiple tasks ranging from molecular generation
to optimization. Across these tasks, our model outperforms previous
state-of-the-art baselines by a significant margin.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jin_W/0/1/0/all/0/1&quot;&gt;Wengong Jin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barzilay_R/0/1/0/all/0/1&quot;&gt;Regina Barzilay&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jaakkola_T/0/1/0/all/0/1&quot;&gt;Tommi Jaakkola&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06091">
<title>Bridging Cognitive Programs and Machine Learning. (arXiv:1802.06091v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.06091</link>
<description rdf:parseType="Literal">&lt;p&gt;While great advances are made in pattern recognition and machine learning,
the successes of such fields remain restricted to narrow applications and seem
to break down when training data is scarce, a shift in domain occurs, or when
intelligent reasoning is required for rapid adaptation to new environments. In
this work, we list several of the shortcomings of modern machine-learning
solutions, specifically in the contexts of computer vision and in reinforcement
learning and suggest directions to explore in order to try to ameliorate these
weaknesses.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rosenfeld_A/0/1/0/all/0/1&quot;&gt;Amir Rosenfeld&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tsotsos_J/0/1/0/all/0/1&quot;&gt;John K. Tsotsos&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06215">
<title>HyP-DESPOT: A Hybrid Parallel Algorithm for Online Planning under Uncertainty. (arXiv:1802.06215v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.06215</link>
<description rdf:parseType="Literal">&lt;p&gt;Planning under uncertainty is critical for robust robot performance in
uncertain, dynamic environments, but it incurs high computational cost.
State-of-the-art online search algorithms, such as DESPOT, have vastly improved
the computational efficiency of planning under uncertainty and made it a
valuable tool for robotics in practice. This work takes one step further by
leveraging both CPU and GPU parallelization in order to achieve near real-time
online planning performance for complex tasks with large state, action, and
observation spaces. Specifically, we propose Hybrid Parallel DESPOT
(HyP-DESPOT), a massively parallel online planning algorithm that integrates
CPU and GPU parallelism in a multi-level scheme. It performs parallel DESPOT
tree search by simultaneously traversing multiple independent paths using
multi-core CPUs and performs parallel Monte-Carlo simulations at the leaf nodes
of the search tree using GPUs. Experimental results show that HyP-DESPOT speeds
up online planning by up to several hundred times, compared with the original
DESPOT algorithm, in several challenging robotic tasks in simulation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cai_P/0/1/0/all/0/1&quot;&gt;Panpan Cai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1&quot;&gt;Yuanfu Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hsu_D/0/1/0/all/0/1&quot;&gt;David Hsu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_W/0/1/0/all/0/1&quot;&gt;Wee Sun Lee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06225">
<title>A Deep Q-Learning Agent for the L-Game with Variable Batch Training. (arXiv:1802.06225v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.06225</link>
<description rdf:parseType="Literal">&lt;p&gt;We employ the Deep Q-Learning algorithm with Experience Replay to train an
agent capable of achieving a high-level of play in the L-Game while
self-learning from low-dimensional states. We also employ variable batch size
for training in order to mitigate the loss of the rare reward signal and
significantly accelerate training. Despite the large action space due to the
number of possible moves, the low-dimensional state space and the rarity of
rewards, which only come at the end of a game, DQL is successful in training an
agent capable of strong play without the use of any search methods or domain
knowledge.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Giannakopoulos_P/0/1/0/all/0/1&quot;&gt;Petros Giannakopoulos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cotronis_Y/0/1/0/all/0/1&quot;&gt;Yannis Cotronis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06412">
<title>Improved TDNNs using Deep Kernels and Frequency Dependent Grid-RNNs. (arXiv:1802.06412v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1802.06412</link>
<description rdf:parseType="Literal">&lt;p&gt;Time delay neural networks (TDNNs) are an effective acoustic model for large
vocabulary speech recognition. The strength of the model can be attributed to
its ability to effectively model long temporal contexts. However, current TDNN
models are relatively shallow, which limits the modelling capability. This
paper proposes a method of increasing the network depth by deepening the kernel
used in the TDNN temporal convolutions. The best performing kernel consists of
three fully connected layers with a residual (ResNet) connection from the
output of the first to the output of the third. The addition of
spectro-temporal processing as the input to the TDNN in the form of a
convolutional neural network (CNN) and a newly designed Grid-RNN was
investigated. The Grid-RNN strongly outperforms a CNN if different sets of
parameters for different frequency bands are used and can be further enhanced
by using a bi-directional Grid-RNN. Experiments using the multi-genre broadcast
(MGB3) English data (275h) show that deep kernel TDNNs reduces the word error
rate (WER) by 6% relative and when combined with the frequency dependent
Grid-RNN gives a relative WER reduction of 9%.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kreyssig_F/0/1/0/all/0/1&quot;&gt;Florian Kreyssig&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1&quot;&gt;Chao Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Woodland_P/0/1/0/all/0/1&quot;&gt;Philip Woodland&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06521">
<title>Human and Smart Machine Co-Learning with Brain Computer Interface. (arXiv:1802.06521v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.06521</link>
<description rdf:parseType="Literal">&lt;p&gt;Machine learning has become a very popular approach for cybernetics systems,
and it has always been considered important research in the Computational
Intelligence area. Nevertheless, when it comes to smart machines, it is not
just about the methodologies. We need to consider systems and cybernetics as
well as include human in the loop. The purpose of this article is as follows:
(1) To integrate the open source Facebook AI Research (FAIR) DarkForest program
of Facebook with Item Response Theory (IRT), to the new open learning system,
namely, DDF learning system; (2) To integrate DDF Go with Robot namely Robotic
DDF Go system; (3) To invite the professional Go players to attend the activity
to play Go games on site with a smart machine. The research team will apply
this technology to education, such as, playing games to enhance the children
concentration on learning mathematics, languages, and other topics. With the
detected brainwaves, the robot will be able to speak some words that are very
much to the point for the students and to assist the teachers in classroom in
the future.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_C/0/1/0/all/0/1&quot;&gt;Chang-Shing Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1&quot;&gt;Mei-Hui Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ko_L/0/1/0/all/0/1&quot;&gt;Li-Wei Ko&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kubota_N/0/1/0/all/0/1&quot;&gt;Naoyuki Kubota&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_L/0/1/0/all/0/1&quot;&gt;Lu-An Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kitaoka_S/0/1/0/all/0/1&quot;&gt;Shinya Kitaoka&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yu-Te Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Su_S/0/1/0/all/0/1&quot;&gt;Shun-Feng Su&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1706.06060">
<title>Consistent feature attribution for tree ensembles. (arXiv:1706.06060v6 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1706.06060</link>
<description rdf:parseType="Literal">&lt;p&gt;Note that a newer expanded version of this paper is now available at:
&lt;a href=&quot;/abs/1802.03888&quot;&gt;arXiv:1802.03888&lt;/a&gt;
&lt;/p&gt;
&lt;p&gt;It is critical in many applications to understand what features are important
for a model, and why individual predictions were made. For tree ensemble
methods these questions are usually answered by attributing importance values
to input features, either globally or for a single prediction. Here we show
that current feature attribution methods are inconsistent, which means changing
the model to rely more on a given feature can actually decrease the importance
assigned to that feature. To address this problem we develop fast exact
solutions for SHAP (SHapley Additive exPlanation) values, which were recently
shown to be the unique additive feature attribution method based on conditional
expectations that is both consistent and locally accurate. We integrate these
improvements into the latest version of XGBoost, demonstrate the
inconsistencies of current methods, and show how using SHAP values results in
significantly improved supervised clustering performance. Feature importance
values are a key part of understanding widely used models such as gradient
boosting trees and random forests, so improvements to them have broad practical
implications.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lundberg_S/0/1/0/all/0/1&quot;&gt;Scott M. Lundberg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1&quot;&gt;Su-In Lee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.02013">
<title>Neural Language Modeling by Jointly Learning Syntax and Lexicon. (arXiv:1711.02013v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1711.02013</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a neural language model capable of unsupervised syntactic
structure induction. The model leverages the structure information to form
better semantic representations and better language modeling. Standard
recurrent neural networks are limited by their structure and fail to
efficiently use syntactic information. On the other hand, tree-structured
recursive networks usually require additional structural supervision at the
cost of human expert annotation. In this paper, We propose a novel neural
language model, called the Parsing-Reading-Predict Networks (PRPN), that can
simultaneously induce the syntactic structure from unannotated sentences and
leverage the inferred structure to learn a better language model. In our model,
the gradient can be directly back-propagated from the language model loss into
the neural parsing network. Experiments show that the proposed model can
discover the underlying syntactic structure and achieve state-of-the-art
performance on word/character-level language model tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1&quot;&gt;Yikang Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1&quot;&gt;Zhouhan Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_C/0/1/0/all/0/1&quot;&gt;Chin-Wei Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Courville_A/0/1/0/all/0/1&quot;&gt;Aaron Courville&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.07686">
<title>Pseudorehearsal in actor-critic agents with neural network function approximation. (arXiv:1712.07686v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1712.07686</link>
<description rdf:parseType="Literal">&lt;p&gt;Catastrophic forgetting has a significant negative impact in reinforcement
learning. The purpose of this study is to investigate how pseudorehearsal can
change performance of an actor-critic agent with neural-network function
approximation. We tested agent in a pole balancing task and compared different
pseudorehearsal approaches. We have found that pseudorehearsal can assist
learning and decrease forgetting.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Marochko_V/0/1/0/all/0/1&quot;&gt;Vladimir Marochko&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Johard_L/0/1/0/all/0/1&quot;&gt;Leonard Johard&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mazzara_M/0/1/0/all/0/1&quot;&gt;Manuel Mazzara&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Longo_L/0/1/0/all/0/1&quot;&gt;Luca Longo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.04406">
<title>Which Training Methods for GANs do actually Converge?. (arXiv:1801.04406v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1801.04406</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent work has shown local convergence of GAN training for absolutely
continuous data and generator distributions. In this paper, we show that the
requirement of absolute continuity is necessary: we describe a simple yet
prototypical counterexample showing that in the more realistic case of
distributions that are not absolutely continuous, unregularized GAN training is
not always convergent. Furthermore, we discuss regularization strategies that
were recently proposed to stabilize GAN training. Our analysis shows that GAN
training with instance noise or zero-centered gradient penalties converges. On
the other hand, we show that Wasserstein-GANs and WGAN-GP with a finite number
of discriminator updates per generator update do not always converge to the
equilibrium point. We discuss these results, leading us to a new explanation
for the stability problems of GAN training. Based on our analysis, we extend
our convergence results to more general GANs and prove local convergence for
simplified gradient penalties even if the generator and data distribution lie
on lower dimensional manifolds. We find these penalties to work well in
practice and use them to learn a generative image model of all 1000 Imagenet
classes in a single GAN with little hyperparameter tuning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mescheder_L/0/1/0/all/0/1&quot;&gt;Lars Mescheder&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Geiger_A/0/1/0/all/0/1&quot;&gt;Andreas Geiger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nowozin_S/0/1/0/all/0/1&quot;&gt;Sebastian Nowozin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04289">
<title>Deep Neural Networks for Bot Detection. (arXiv:1802.04289v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1802.04289</link>
<description rdf:parseType="Literal">&lt;p&gt;The problem of detecting bots, automated social media accounts governed by
software but disguising as human users, has strong implications. For example,
bots have been used to sway political elections by distorting online discourse,
to manipulate the stock market, or to push anti-vaccine conspiracy theories
that caused health epidemics. Most techniques proposed to date detect bots at
the account level, by processing large amount of social media posts, and
leveraging information from network structure, temporal dynamics, sentiment
analysis, etc.
&lt;/p&gt;
&lt;p&gt;In this paper, we propose a deep neural network based on contextual long
short-term memory (LSTM) architecture that exploits both content and metadata
to detect bots at the tweet level: contextual features are extracted from user
metadata and fed as auxiliary input to LSTM deep nets processing the tweet
text.
&lt;/p&gt;
&lt;p&gt;Another contribution that we make is proposing a technique based on synthetic
minority oversampling to generate a large labeled dataset, suitable for deep
nets training, from a minimal amount of labeled data (roughly 3,000 examples of
sophisticated Twitter bots). We demonstrate that, from just one single tweet,
our architecture can achieve high classification accuracy (AUC &amp;gt; 96%) in
separating bots from humans.
&lt;/p&gt;
&lt;p&gt;We apply the same architecture to account-level bot detection, achieving
nearly perfect classification accuracy (AUC &amp;gt; 99%). Our system outperforms
previous state of the art while leveraging a small and interpretable set of
features yet requiring minimal training data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kudugunta_S/0/1/0/all/0/1&quot;&gt;Sneha Kudugunta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ferrara_E/0/1/0/all/0/1&quot;&gt;Emilio Ferrara&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06167">
<title>CapsuleGAN: Generative Adversarial Capsule Network. (arXiv:1802.06167v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.06167</link>
<description rdf:parseType="Literal">&lt;p&gt;We present Generative Adversarial Capsule Network (CapsuleGAN), a framework
that uses capsule networks (CapsNets) instead of the standard convolutional
neural networks (CNNs) as discriminators within the generative adversarial
network (GAN) setting, while modeling image data. We provide guidelines for
designing CapsNet discriminators and the updated GAN objective function, which
incorporates the CapsNet margin loss, for training CapsuleGAN models. We show
that CapsuleGAN outperforms convolutional-GAN at modeling image data
distribution on the MNIST dataset of handwritten digits, evaluated on the
generative adversarial metric and at semi-supervised image classification.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Jaiswal_A/0/1/0/all/0/1&quot;&gt;Ayush Jaiswal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+AbdAlmageed_W/0/1/0/all/0/1&quot;&gt;Wael AbdAlmageed&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Natarajan_P/0/1/0/all/0/1&quot;&gt;Premkumar Natarajan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06222">
<title>Efficient GAN-Based Anomaly Detection. (arXiv:1802.06222v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.06222</link>
<description rdf:parseType="Literal">&lt;p&gt;Generative adversarial networks (GANs) are able to model the complex
highdimensional distributions of real-world data, which suggests they could be
effective for anomaly detection. However, few works have explored the use of
GANs for the anomaly detection task. We leverage recently developed GAN models
for anomaly detection, and achieve state-of-the-art performance on image and
network intrusion datasets, while being several hundred-fold faster at test
time than the only published GAN-based method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zenati_H/0/1/0/all/0/1&quot;&gt;Houssam Zenati&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Foo_C/0/1/0/all/0/1&quot;&gt;Chuan Sheng Foo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lecouat_B/0/1/0/all/0/1&quot;&gt;Bruno Lecouat&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Manek_G/0/1/0/all/0/1&quot;&gt;Gaurav Manek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chandrasekhar_V/0/1/0/all/0/1&quot;&gt;Vijay Ramaseshan Chandrasekhar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06287">
<title>Unsupervised vehicle recognition using incremental reseeding of acoustic signatures. (arXiv:1802.06287v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.06287</link>
<description rdf:parseType="Literal">&lt;p&gt;Vehicle recognition and classification have broad applications, ranging from
traffic flow management to military target identification. We demonstrate an
unsupervised method for automated identification of moving vehicles from
roadside audio sensors. Using a short-time Fourier transform to decompose audio
signals, we treat the frequency signature in each time window as an individual
data point. We then use a spectral embedding for dimensionality reduction.
Based on the leading eigenvectors, we relate the performance of an incremental
reseeding algorithm to that of spectral clustering. We find that incremental
reseeding accurately identifies individual vehicles using their acoustic
signatures.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sunu_J/0/1/0/all/0/1&quot;&gt;Justin Sunu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hunter_B/0/1/0/all/0/1&quot;&gt;Blake Hunter&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Percus_A/0/1/0/all/0/1&quot;&gt;Allon G. Percus&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06368">
<title>Node Centralities and Classification Performance for Characterizing Node Embedding Algorithms. (arXiv:1802.06368v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.06368</link>
<description rdf:parseType="Literal">&lt;p&gt;Embedding graph nodes into a vector space can allow the use of machine
learning to e.g. predict node classes, but the study of node embedding
algorithms is immature compared to the natural language processing field
because of a diverse nature of graphs. We examine the performance of node
embedding algorithms with respect to graph centrality measures that
characterize diverse graphs, through systematic experiments with four node
embedding algorithms, four or five graph centralities, and six datasets.
Experimental results give insights into the properties of node embedding
algorithms, which can be a basis for further research on this topic.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nozawa_K/0/1/0/all/0/1&quot;&gt;Kento Nozawa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kimura_M/0/1/0/all/0/1&quot;&gt;Masanari Kimura&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kanemura_A/0/1/0/all/0/1&quot;&gt;Atsunori Kanemura&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06383">
<title>Efficient Gaussian Process Classification Using Polya-Gamma Data Augmentation. (arXiv:1802.06383v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.06383</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose an efficient stochastic variational approach to GP classification
building on Polya- Gamma data augmentation and inducing points, which is based
on closed-form updates of natural gradients. We evaluate the algorithm on
real-world datasets containing up to 11 million data points and demonstrate
that it is up to three orders of magnitude faster than the state-of-the-art
while being competitive in terms of prediction performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wenzel_F/0/1/0/all/0/1&quot;&gt;Florian Wenzel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Galy_Fajou_T/0/1/0/all/0/1&quot;&gt;Theo Galy-Fajou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Donner_C/0/1/0/all/0/1&quot;&gt;Christan Donner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kloft_M/0/1/0/all/0/1&quot;&gt;Marius Kloft&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Opper_M/0/1/0/all/0/1&quot;&gt;Manfred Opper&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06384">
<title>Neural Networks with Finite Intrinsic Dimension have no Spurious Valleys. (arXiv:1802.06384v1 [math.OC])</title>
<link>http://arxiv.org/abs/1802.06384</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural networks provide a rich class of high-dimensional, non-convex
optimization problems. Despite their non-convexity, gradient-descent methods
often successfully optimize these models. This has motivated a recent spur in
research attempting to characterize properties of their loss surface that may
be responsible for such success. In particular, several authors have noted that
\emph{over-parametrization} appears to act as a remedy against non-convexity.
&lt;/p&gt;
&lt;p&gt;In this paper, we address this phenomenon by studying key topological
properties of the loss, such as the presence or absence of &quot;spurious valleys&quot;,
defined as connected components of sub-level sets that do not include a global
minimum. Focusing on a class of two-layer neural networks defined by smooth
(but generally non-linear) activation functions, our main contribution is to
prove that as soon as the hidden layer size matches the \emph{intrinsic}
dimension of the reproducing space, defined as the linear functional space
generated by the activations, no spurious valleys exist, thus allowing the
existence of descent directions. Our setup includes smooth activations such as
polynomials, both in the empirical and population risk, and generic activations
in the empirical risk case.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Venturi_L/0/1/0/all/0/1&quot;&gt;Luca Venturi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Bandeira_A/0/1/0/all/0/1&quot;&gt;Afonso Bandeira&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Bruna_J/0/1/0/all/0/1&quot;&gt;Joan Bruna&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06403">
<title>RadialGAN: Leveraging multiple datasets to improve target-specific predictive models using Generative Adversarial Networks. (arXiv:1802.06403v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.06403</link>
<description rdf:parseType="Literal">&lt;p&gt;Training complex machine learning models for prediction often requires a
large amount of data that is not always readily available. Leveraging these
external datasets from related but different sources is therefore an important
task if good predictive models are to be built for deployment in settings where
data can be rare. In this paper we propose a novel approach to the problem in
which we use multiple GAN architectures to learn to translate from one dataset
to another, thereby allowing us to effectively enlarge the target dataset, and
therefore learn better predictive models than if we simply used the target
dataset. We show the utility of such an approach, demonstrating that our method
improves the prediction performance on the target domain over using just the
target dataset and also show that our framework outperforms several other
benchmarks on a collection of real-world medical datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yoon_J/0/1/0/all/0/1&quot;&gt;Jinsung Yoon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jordon_J/0/1/0/all/0/1&quot;&gt;James Jordon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schaar_M/0/1/0/all/0/1&quot;&gt;Mihaela van der Schaar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06432">
<title>Music Genre Classification using Masked Conditional Neural Networks. (arXiv:1802.06432v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.06432</link>
<description rdf:parseType="Literal">&lt;p&gt;The ConditionaL Neural Networks (CLNN) and the Masked ConditionaL Neural
Networks (MCLNN) exploit the nature of multi-dimensional temporal signals. The
CLNN captures the conditional temporal influence between the frames in a window
and the mask in the MCLNN enforces a systematic sparseness that follows a
filterbank-like pattern over the network links. The mask induces the network to
learn about time-frequency representations in bands, allowing the network to
sustain frequency shifts. Additionally, the mask in the MCLNN automates the
exploration of a range of feature combinations, usually done through an
exhaustive manual search. We have evaluated the MCLNN performance using the
Ballroom and Homburg datasets of music genres. MCLNN has achieved accuracies
that are competitive to state-of-the-art handcrafted attempts in addition to
models based on Convolutional Neural Networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Medhat_F/0/1/0/all/0/1&quot;&gt;Fady Medhat&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chesmore_D/0/1/0/all/0/1&quot;&gt;David Chesmore&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Robinson_J/0/1/0/all/0/1&quot;&gt;John Robinson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06441">
<title>Deep neural decoders for near term fault-tolerant experiments. (arXiv:1802.06441v1 [quant-ph])</title>
<link>http://arxiv.org/abs/1802.06441</link>
<description rdf:parseType="Literal">&lt;p&gt;Finding efficient decoders for quantum error correcting codes adapted to
realistic experimental noise in fault-tolerant devices represents a significant
challenge. In this paper we introduce several decoding algorithms complemented
by deep neural decoders and apply them to analyze several fault-tolerant error
correction protocols such as the surface code as well as Steane and Knill error
correction. Our methods require no knowledge of the underlying noise model
afflicting the quantum device making them appealing for real-world experiments.
Our analysis is based on a full circuit-level noise model. It considers both
distance-three and five codes, and is performed near the codes pseudo-threshold
regime. Training deep neural decoders in low noise rate regimes appears to be a
challenging machine learning endeavour. We provide a detailed description of
our neural network architectures and training methodology. We then discuss both
the advantages and limitations of deep neural decoders. Lastly, we provide a
rigorous analysis of the decoding runtime of trained deep neural decoders and
compare our methods with anticipated gate times in future quantum devices.
Given the broad applications of our decoding schemes, we believe that the
methods presented in this paper could have practical applications for near term
fault-tolerant experiments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Chamberland_C/0/1/0/all/0/1&quot;&gt;Christopher Chamberland&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Ronagh_P/0/1/0/all/0/1&quot;&gt;Pooya Ronagh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06463">
<title>Local Geometry of One-Hidden-Layer Neural Networks for Logistic Regression. (arXiv:1802.06463v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.06463</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the local geometry of a one-hidden-layer fully-connected neural
network where the training samples are generated from a multi-neuron logistic
regression model. We prove that under Gaussian input, the empirical risk
function employing quadratic loss exhibits strong convexity and smoothness
uniformly in a local neighborhood of the ground truth, for a class of smooth
activation functions satisfying certain properties, including sigmoid and tanh,
as soon as the sample complexity is sufficiently large. This implies that if
initialized in this neighborhood, gradient descent converges linearly to a
critical point that is provably close to the ground truth without requiring a
fresh set of samples at each iteration. This significantly improves upon prior
results on learning shallow neural networks with multiple neurons. To the best
of our knowledge, this is the first global convergence guarantee for
one-hidden-layer neural networks using gradient descent over the empirical risk
function without resampling at the near-optimal sampling and computational
complexity.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Fu_H/0/1/0/all/0/1&quot;&gt;Haoyu Fu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chi_Y/0/1/0/all/0/1&quot;&gt;Yuejie Chi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Liang_Y/0/1/0/all/0/1&quot;&gt;Yingbin Liang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06552">
<title>Are Generative Classifiers More Robust to Adversarial Attacks?. (arXiv:1802.06552v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.06552</link>
<description rdf:parseType="Literal">&lt;p&gt;There is a rising interest in studying the robustness of deep neural network
classifiers against adversaries, with both advanced attack and defence
techniques being actively developed. However, most recent work focuses on
discriminative classifiers which only models the conditional distribution of
the labels given the inputs. In this abstract we propose deep Bayes classifier
that improves the classical naive Bayes with conditional deep generative
models, and verifies its robustness against a number of existing attacks. We
further developed a detection method for adversarial examples based on
conditional deep generative models. Our initial results on MNIST suggest that
deep Bayes classifiers might be more robust when compared with deep
discriminative classifiers, and the proposed detection method achieves high
detection rates against two commonly used attacks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yingzhen Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06640">
<title>Finding Influential Training Samples for Gradient Boosted Decision Trees. (arXiv:1802.06640v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.06640</link>
<description rdf:parseType="Literal">&lt;p&gt;We address the problem of finding influential training samples for a
particular case of tree ensemble-based models, e.g., Random Forest (RF) or
Gradient Boosted Decision Trees (GBDT). A natural way of formalizing this
problem is studying how the model&apos;s predictions change upon leave-one-out
retraining, leaving out each individual training sample. Recent work has shown
that, for parametric models, this analysis can be conducted in a
computationally efficient way. We propose several ways of extending this
framework to non-parametric GBDT ensembles under the assumption that tree
structures remain fixed. Furthermore, we introduce a general scheme of
obtaining further approximations to our method that balance the trade-off
between performance and computational complexity. We evaluate our approaches on
various experimental setups and use-case scenarios and demonstrate both the
quality of our approach to finding influential training samples in comparison
to the baselines and its computational efficiency.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sharchilev_B/0/1/0/all/0/1&quot;&gt;Boris Sharchilev&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ustinovsky_Y/0/1/0/all/0/1&quot;&gt;Yury Ustinovsky&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Serdyukov_P/0/1/0/all/0/1&quot;&gt;Pavel Serdyukov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rijke_M/0/1/0/all/0/1&quot;&gt;Maarten de Rijke&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06677">
<title>Degeneration in VAE: in the Light of Fisher Information Loss. (arXiv:1802.06677v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.06677</link>
<description rdf:parseType="Literal">&lt;p&gt;Variational Autoencoder (VAE) is one of the most popular generative models,
and enormous advances have been explored in recent years. Due to the increasing
complexity of the raw data and the model architecture, deep networks are needed
in VAE models while few works discuss their impacts. According to our
observation, VAE does not always benefit from deeper architecture: 1) Deeper
encoder makes VAE learn more comprehensible latent representations, while
results in blurry reconstruction samples; 2) Deeper decoder ensures more
high-quality generations, while the latent representations become abstruse; 3)
When encoder and decoder both go deeper, abstruse latent representation occurs
with blurry reconstruction samples at same time. In this paper, we deduce a
Fisher information measure for the corresponding analysis. With such measure,
we demonstrate that information loss is ineluctable in feed-forward networks
and causes the previous three types of degeneration, especially when the
network goes deeper. We also demonstrate that skip connections benefit the
preservation of information amount, thus propose a VAE enhanced by skip
connections, named SCVAE. In the experiments, SCVAE is shown to mitigate the
information loss and to achieve a promising performance in both encoding and
decoding tasks. Moreover, SCVAE can be adaptive to other state-of-the-art
variants of VAE for further amelioration.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zheng_H/0/1/0/all/0/1&quot;&gt;Huangjie Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yao_J/0/1/0/all/0/1&quot;&gt;Jiangchao Yao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Ya Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tsang_I/0/1/0/all/0/1&quot;&gt;Ivor W. Tsang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.07172">
<title>SpectralLeader: Online Spectral Learning for Single Topic Models. (arXiv:1709.07172v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1709.07172</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the problem of learning a latent variable model from a stream of
data. Latent variable models are popular in practice because they can explain
observed data in terms of unobserved concepts. These models have been
traditionally studied in the offline setting. The online EM is arguably the
most popular algorithm for learning latent variable models online. Although it
is computationally efficient, it typically converges to a local optimum. In
this work, we develop a new online learning algorithm for latent variable
models, which we call SpectralLeader. SpectralLeader always converges to the
global optimum, and we derive a $O(\sqrt{n})$ upper bound up to log factors on
its $n$-step regret in the bag-of-words model. We show that SpectralLeader
performs similarly to or better than the online EM with tuned hyper-parameters,
in both synthetic and real-world experiments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_T/0/1/0/all/0/1&quot;&gt;Tong Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kveton_B/0/1/0/all/0/1&quot;&gt;Branislav Kveton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wen_Z/0/1/0/all/0/1&quot;&gt;Zheng Wen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mengshoel_O/0/1/0/all/0/1&quot;&gt;Ole J. Mengshoel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bui_H/0/1/0/all/0/1&quot;&gt;Hung Bui&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.00961">
<title>Learning Independent Causal Mechanisms. (arXiv:1712.00961v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1712.00961</link>
<description rdf:parseType="Literal">&lt;p&gt;Statistical learning relies upon data sampled from a distribution, and we
usually do not care what actually generated it in the first place. From the
point of view of causal modeling, the structure of each distribution is induced
by physical mechanisms that give rise to dependencies between observables.
Mechanisms, however, can be meaningful autonomous modules of generative models
that make sense beyond a particular entailed data distribution, lending
themselves to transfer between problems. We develop an algorithm to recover a
set of independent (inverse) mechanisms from a set of transformed data points.
The approach is unsupervised and based on a set of experts that compete for
data generated by the mechanisms, driving specialization. We analyze the
proposed method in a series of experiments on image data. Each expert learns to
map a subset of the transformed data back to a reference distribution. The
learned mechanisms generalize to novel domains. We discuss implications for
transfer learning and links to recent trends in generative modeling.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Parascandolo_G/0/1/0/all/0/1&quot;&gt;Giambattista Parascandolo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kilbertus_N/0/1/0/all/0/1&quot;&gt;Niki Kilbertus&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rojas_Carulla_M/0/1/0/all/0/1&quot;&gt;Mateo Rojas-Carulla&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Scholkopf_B/0/1/0/all/0/1&quot;&gt;Bernhard Sch&amp;#xf6;lkopf&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.01952">
<title>Generating Neural Networks with Neural Networks. (arXiv:1801.01952v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1801.01952</link>
<description rdf:parseType="Literal">&lt;p&gt;Hypernetworks are neural networks that transform a random input vector into
weights for a specified target neural network. We formulate the hypernetwork
training objective as a compromise between accuracy and diversity, where the
diversity takes into account trivial symmetry transformations of the target
network. We show that this formulation naturally arises as a relaxation of an
optimistic probability distribution objective for the generated networks, and
we explain how it is related to variational inference. We use multi-layered
perceptrons to form the mapping from the low dimensional input random vector to
the high dimensional weight space, and demonstrate how to reduce the number of
parameters in this mapping by weight sharing. We perform experiments on a four
layer convolutional target network which classifies MNIST images, and show that
the generated weights are diverse and have interesting distributions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Deutsch_L/0/1/0/all/0/1&quot;&gt;Lior Deutsch&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.05558">
<title>Gradient-Based Meta-Learning with Learned Layerwise Metric and Subspace. (arXiv:1801.05558v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1801.05558</link>
<description rdf:parseType="Literal">&lt;p&gt;Gradient-based meta-learning has been shown to be expressive enough to
approximate any learning algorithm. While previous such methods have been
successful in meta-learning tasks, they resort to simple gradient descent
during meta-testing. Our primary contribution is the {\em MT-net}, which
enables the meta-learner to learn on each layer&apos;s activation space a subspace
that the task-specific learner performs gradient descent on. Additionally, a
task-specific learner of an {\em MT-net} performs gradient descent with respect
to a meta-learned distance metric, which warps the activation space to be more
sensitive to task identity. We demonstrate that the dimension of this learned
subspace reflects the complexity of the task-specific learner&apos;s adaptation
task, and also that our model is less sensitive to the choice of initial
learning rates than previous gradient-based meta-learning methods. Our method
achieves state-of-the-art or comparable performance on few-shot classification
and regression tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lee_Y/0/1/0/all/0/1&quot;&gt;Yoonho Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Choi_S/0/1/0/all/0/1&quot;&gt;Seungjin Choi&lt;/a&gt;</dc:creator>
</item></rdf:RDF>