<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Good papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Good Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-02-11T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.03039"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.03155"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.03268"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.03308"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.03318"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.08992"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.03052"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.03171"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.03216"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.03390"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.04486"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.01561"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.03041"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.03145"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.03184"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.03334"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.03358"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.03360"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1802.03039">
<title>Imitation networks: Few-shot learning of neural networks from scratch. (arXiv:1802.03039v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.03039</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we propose imitation networks, a simple but effective method
for training neural networks with a limited amount of training data. Our
approach inherits the idea of knowledge distillation that transfers knowledge
from a deep or wide reference model to a shallow or narrow target model. The
proposed method employs this idea to mimic predictions of reference estimators
that are much more robust against overfitting than the network we want to
train. Different from almost all the previous work for knowledge distillation
that requires a large amount of labeled training data, the proposed method
requires only a small amount of training data. Instead, we introduce pseudo
training examples that are optimized as a part of model parameters.
Experimental results for several benchmark datasets demonstrate that the
proposed method outperformed all the other baselines, such as naive training of
the target model and standard knowledge distillation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kimura_A/0/1/0/all/0/1&quot;&gt;Akisato Kimura&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ghahramani_Z/0/1/0/all/0/1&quot;&gt;Zoubin Ghahramani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Takeuchi_K/0/1/0/all/0/1&quot;&gt;Koh Takeuchi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Iwata_T/0/1/0/all/0/1&quot;&gt;Tomoharu Iwata&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ueda_N/0/1/0/all/0/1&quot;&gt;Naonori Ueda&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.03155">
<title>Web-Based Implementation of Travelling Salesperson Problem Using Genetic Algorithm. (arXiv:1802.03155v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1802.03155</link>
<description rdf:parseType="Literal">&lt;p&gt;The world is connected through the Internet. As the abundance of Internet
users connected into the Web and the popularity of cloud computing research,
the need of Artificial Intelligence (AI) is demanding. In this research,
Genetic Algorithm (GA) as AI optimization method through natural selection and
genetic evolution is utilized. There are many applications of GA such as web
mining, load balancing, routing, and scheduling or web service selection.
Hence, it is a challenging task to discover whether the code mainly server side
and web based language technology affects the performance of GA. Travelling
Salesperson Problem (TSP) as Non Polynomial-hard (NP-hard) problem is provided
to be a problem domain to be solved by GA. While many scientists prefer Python
in GA implementation, another popular high-level interpreter programming
language such as PHP (PHP Hypertext Preprocessor) and Ruby were benchmarked.
Line of codes, file sizes, and performances based on GA implementation and
runtime were found varies among these programming languages. Based on the
result, the use of Ruby in GA implementation is recommended.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pinandito_A/0/1/0/all/0/1&quot;&gt;Aryo Pinandito&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yudistira_N/0/1/0/all/0/1&quot;&gt;Novanto Yudistira&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pradana_F/0/1/0/all/0/1&quot;&gt;Fajar Pradana&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.03268">
<title>Efficient Neural Architecture Search via Parameters Sharing. (arXiv:1802.03268v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.03268</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose Efficient Neural Architecture Search (ENAS), a fast and
inexpensive approach for automatic model design. In ENAS, a controller learns
to discover neural network architectures by searching for an optimal subgraph
within a large computational graph. The controller is trained with policy
gradient to select a subgraph that maximizes the expected reward on the
validation set. Meanwhile the model corresponding to the selected subgraph is
trained to minimize a canonical cross entropy loss. Thanks to parameter sharing
between child models, ENAS is fast: it delivers strong empirical performances
using much fewer GPU-hours than all existing automatic model design approaches,
and notably, 1000x less expensive than standard Neural Architecture Search. On
the Penn Treebank dataset, ENAS discovers a novel architecture that achieves a
test perplexity of 55.8, establishing a new state-of-the-art among all methods
without post-training processing. On the CIFAR-10 dataset, ENAS designs novel
architectures that achieve a test error of 2.89%, which is on par with NASNet
(Zoph et al., 2018), whose test error is 2.65%.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pham_H/0/1/0/all/0/1&quot;&gt;Hieu Pham&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guan_M/0/1/0/all/0/1&quot;&gt;Melody Y. Guan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zoph_B/0/1/0/all/0/1&quot;&gt;Barret Zoph&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Le_Q/0/1/0/all/0/1&quot;&gt;Quoc V. Le&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dean_J/0/1/0/all/0/1&quot;&gt;Jeff Dean&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.03308">
<title>Predictive Neural Networks. (arXiv:1802.03308v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.03308</link>
<description rdf:parseType="Literal">&lt;p&gt;Recurrent neural networks are a powerful means to cope with time series. We
show that already linearly activated recurrent neural networks can approximate
any time-dependent function f(t) given by a number of function values. The
approximation can effectively be learned by simply solving a linear equation
system; no backpropagation or similar methods are needed. Furthermore the
network size can be reduced by taking only the most relevant components of the
network. Thus, in contrast to others, our approach not only learns network
weights but also the network architecture. The networks have interesting
properties: In the stationary case they end up in ellipse trajectories in the
long run, and they allow the prediction of further values and compact
representations of functions. We demonstrate this by several experiments, among
them multiple superimposed oscillators (MSO) and robotic soccer. Predictive
neural networks outperform the previous state-of-the-art for the MSO task with
a minimal number of units.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stolzenburg_F/0/1/0/all/0/1&quot;&gt;Frieder Stolzenburg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Michael_O/0/1/0/all/0/1&quot;&gt;Olivia Michael&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Obst_O/0/1/0/all/0/1&quot;&gt;Oliver Obst&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.03318">
<title>Nature vs. Nurture: The Role of Environmental Resources in Evolutionary Deep Intelligence. (arXiv:1802.03318v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1802.03318</link>
<description rdf:parseType="Literal">&lt;p&gt;Evolutionary deep intelligence synthesizes highly efficient deep neural
networks architectures over successive generations. Inspired by the nature
versus nurture debate, we propose a study to examine the role of external
factors on the network synthesis process by varying the availability of
simulated environmental resources. Experimental results were obtained for
networks synthesized via asexual evolutionary synthesis (1-parent) and sexual
evolutionary synthesis (2-parent, 3-parent, and 5-parent) using a 10% subset of
the MNIST dataset. Results show that a lower environmental factor model
resulted in a more gradual loss in performance accuracy and decrease in storage
size. This potentially allows significantly reduced storage size with minimal
to no drop in performance accuracy, and the best networks were synthesized
using the lowest environmental factor models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chung_A/0/1/0/all/0/1&quot;&gt;Audrey G. Chung&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fieguth_P/0/1/0/all/0/1&quot;&gt;Paul Fieguth&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wong_A/0/1/0/all/0/1&quot;&gt;Alexander Wong&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.08992">
<title>Embodied Evolution in Collective Robotics: A Review. (arXiv:1709.08992v2 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1709.08992</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper provides an overview of evolutionary robotics techniques applied
to on-line distributed evolution for robot collectives -- namely, embodied
evolution. It provides a definition of embodied evolution as well as a thorough
description of the underlying concepts and mechanisms. The paper also presents
a comprehensive summary of research published in the field since its inception
(1999-2017), providing various perspectives to identify the major trends. In
particular, we identify a shift from considering embodied evolution as a
parallel search method within small robot collectives (fewer than 10 robots) to
embodied evolution as an on-line distributed learning method for designing
collective behaviours in swarm-like collectives. The paper concludes with a
discussion of applications and open questions, providing a milestone for past
and an inspiration for future research.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bredeche_N/0/1/0/all/0/1&quot;&gt;Nicolas Bredeche&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Haasdijk_E/0/1/0/all/0/1&quot;&gt;Evert Haasdijk&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Prieto_A/0/1/0/all/0/1&quot;&gt;Abraham Prieto&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.03052">
<title>WorldTree: A Corpus of Explanation Graphs for Elementary Science Questions supporting Multi-Hop Inference. (arXiv:1802.03052v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1802.03052</link>
<description rdf:parseType="Literal">&lt;p&gt;Developing methods of automated inference that are able to provide users with
compelling human-readable justifications for why the answer to a question is
correct is critical for domains such as science and medicine, where user trust
and detecting costly errors are limiting factors to adoption. One of the
central barriers to training question answering models on explainable inference
tasks is the lack of gold explanations to serve as training data. In this paper
we present a corpus of explanations for standardized science exams, a recent
challenge task for question answering. We manually construct a corpus of
detailed explanations for nearly all publicly available standardized elementary
science question (approximately 1,680 3rd through 5th grade questions) and
represent these as &quot;explanation graphs&quot; -- sets of lexically overlapping
sentences that describe how to arrive at the correct answer to a question
through a combination of domain and world knowledge. We also provide an
explanation-centered tablestore, a collection of semi-structured tables that
contain the knowledge to construct these elementary science explanations.
Together, these two knowledge resources map out a substantial portion of the
knowledge required for answering and explaining elementary science exams, and
provide both structured and free-text training data for the explainable
inference task.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jansen_P/0/1/0/all/0/1&quot;&gt;Peter A. Jansen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wainwright_E/0/1/0/all/0/1&quot;&gt;Elizabeth Wainwright&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Marmorstein_S/0/1/0/all/0/1&quot;&gt;Steven Marmorstein&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Morrison_C/0/1/0/all/0/1&quot;&gt;Clayton T. Morrison&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.03171">
<title>A Unified Approach for Multi-step Temporal-Difference Learning with Eligibility Traces in Reinforcement Learning. (arXiv:1802.03171v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.03171</link>
<description rdf:parseType="Literal">&lt;p&gt;Recently, a new multi-step temporal learning algorithm, called $Q(\sigma)$,
unifies $n$-step Tree-Backup (when $\sigma=0$) and $n$-step Sarsa (when
$\sigma=1$) by introducing a sampling parameter $\sigma$. However, similar to
other multi-step temporal-difference learning algorithms, $Q(\sigma)$ needs
much memory consumption and computation time. Eligibility trace is an important
mechanism to transform the off-line updates into efficient on-line ones which
consume less memory and computation time. In this paper, we further develop the
original $Q(\sigma)$, combine it with eligibility traces and propose a new
algorithm, called $Q(\sigma ,\lambda)$, in which $\lambda$ is trace-decay
parameter. This idea unifies Sarsa$(\lambda)$ (when $\sigma =1$) and
$Q^{\pi}(\lambda)$ (when $\sigma =0$). Furthermore, we give an upper error
bound of $Q(\sigma ,\lambda)$ policy evaluation algorithm. We prove that
$Q(\sigma,\lambda)$ control algorithm can converge to the optimal value
function exponentially. We also empirically compare it with conventional
temporal-difference learning methods. Results show that, with an intermediate
value of $\sigma$, $Q(\sigma ,\lambda)$ creates a mixture of the existing
algorithms that can learn the optimal value significantly faster than the
extreme end ($\sigma=0$, or $1$).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1&quot;&gt;Long Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_M/0/1/0/all/0/1&quot;&gt;Minhao Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_Q/0/1/0/all/0/1&quot;&gt;Qian Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meng_W/0/1/0/all/0/1&quot;&gt;Wenjia Meng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pan_G/0/1/0/all/0/1&quot;&gt;Gang Pan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.03216">
<title>Balancing Two-Player Stochastic Games with Soft Q-Learning. (arXiv:1802.03216v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.03216</link>
<description rdf:parseType="Literal">&lt;p&gt;Within the context of video games the notion of perfectly rational agents can
be undesirable as it leads to uninteresting situations, where humans face tough
adversarial decision makers. Current frameworks for stochastic games and
reinforcement learning prohibit tuneable strategies as they seek optimal
performance. In this paper, we enable such tuneable behaviour by generalising
soft Q-learning to stochastic games, where more than one agent interact
strategically. We contribute both theoretically and empirically. On the theory
side, we show that games with soft Q-learning exhibit a unique value and
generalise team games and zero-sum games far beyond these two extremes to cover
a continuous spectrum of gaming behaviour. Experimentally, we show how tuning
agents&apos; constraints affect performance and demonstrate, through a neural
network architecture, how to reliably balance games with high-dimensional
representations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grau_Moya_J/0/1/0/all/0/1&quot;&gt;Jordi Grau-Moya&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leibfried_F/0/1/0/all/0/1&quot;&gt;Felix Leibfried&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bou_Ammar_H/0/1/0/all/0/1&quot;&gt;Haitham Bou-Ammar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.03390">
<title>Not-So-CLEVR: Visual Relations Strain Feedforward Neural Networks. (arXiv:1802.03390v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1802.03390</link>
<description rdf:parseType="Literal">&lt;p&gt;The robust and efficient recognition of visual relations in images is a
hallmark of biological vision. Here, we argue that, despite recent progress in
visual recognition, modern machine vision algorithms are severely limited in
their ability to learn visual relations. Through controlled experiments, we
demonstrate that visual-relation problems strain convolutional neural networks
(CNNs). The networks eventually break altogether when rote memorization becomes
impossible such as when the intra-class variability exceeds their capacity. We
further show that another type of feedforward network, called a relational
network (RN), which was shown to successfully solve seemingly difficult visual
question answering (VQA) problems on the CLEVR datasets, suffers similar
limitations. Motivated by the comparable success of biological vision, we argue
that feedback mechanisms including working memory and attention are the key
computational components underlying abstract visual reasoning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ricci_M/0/1/0/all/0/1&quot;&gt;Matthew Ricci&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1&quot;&gt;Junkyung Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Serre_T/0/1/0/all/0/1&quot;&gt;Thomas Serre&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.04486">
<title>Can Computers Create Art?. (arXiv:1801.04486v4 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1801.04486</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper discusses whether computers, using Artificial Intelligence (AI),
could create art. The first part concerns AI-based tools for assisting with art
making. The history of technologies that automated aspects of art is covered,
including photography and animation. In each case, we see initial fears and
denial of the technology, followed by a blossoming of new creative and
professional opportunities for artists. The hype and reality of Artificial
Intelligence (AI) tools for art making is discussed, together with predictions
about how AI tools will be used. The second part speculates about whether it
could ever happen that AI systems could conceive of artwork, and be credited
with authorship of an artwork.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hertzmann_A/0/1/0/all/0/1&quot;&gt;Aaron Hertzmann&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.01561">
<title>IMPALA: Scalable Distributed Deep-RL with Importance Weighted Actor-Learner Architectures. (arXiv:1802.01561v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1802.01561</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work we aim to solve a large collection of tasks using a single
reinforcement learning agent with a single set of parameters. A key challenge
is to handle the increased amount of data and extended training time. We have
developed a new distributed agent IMPALA (Importance Weighted Actor-Learner
Architecture) that not only uses resources more efficiently in single-machine
training but also scales to thousands of machines without sacrificing data
efficiency or resource utilisation. We achieve stable learning at high
throughput by combining decoupled acting and learning with a novel off-policy
correction method called V-trace. We demonstrate the effectiveness of IMPALA
for multi-task reinforcement learning on DMLab-30 (a set of 30 tasks from the
DeepMind Lab environment (Beattie et al., 2016)) and Atari-57 (all available
Atari games in Arcade Learning Environment (Bellemare et al., 2013a)). Our
results show that IMPALA is able to achieve better performance than previous
agents with less data, and crucially exhibits positive transfer between tasks
as a result of its multi-task approach.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Espeholt_L/0/1/0/all/0/1&quot;&gt;Lasse Espeholt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Soyer_H/0/1/0/all/0/1&quot;&gt;Hubert Soyer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Munos_R/0/1/0/all/0/1&quot;&gt;Remi Munos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Simonyan_K/0/1/0/all/0/1&quot;&gt;Karen Simonyan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mnih_V/0/1/0/all/0/1&quot;&gt;Volodymir Mnih&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ward_T/0/1/0/all/0/1&quot;&gt;Tom Ward&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Doron_Y/0/1/0/all/0/1&quot;&gt;Yotam Doron&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Firoiu_V/0/1/0/all/0/1&quot;&gt;Vlad Firoiu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Harley_T/0/1/0/all/0/1&quot;&gt;Tim Harley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dunning_I/0/1/0/all/0/1&quot;&gt;Iain Dunning&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Legg_S/0/1/0/all/0/1&quot;&gt;Shane Legg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kavukcuoglu_K/0/1/0/all/0/1&quot;&gt;Koray Kavukcuoglu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.03041">
<title>Detection of Adversarial Training Examples in Poisoning Attacks through Anomaly Detection. (arXiv:1802.03041v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.03041</link>
<description rdf:parseType="Literal">&lt;p&gt;Machine learning has become an important component for many systems and
applications including computer vision, spam filtering, malware and network
intrusion detection, among others. Despite the capabilities of machine learning
algorithms to extract valuable information from data and produce accurate
predictions, it has been shown that these algorithms are vulnerable to attacks.
Data poisoning is one of the most relevant security threats against machine
learning systems, where attackers can subvert the learning process by injecting
malicious samples in the training data. Recent work in adversarial machine
learning has shown that the so-called optimal attack strategies can
successfully poison linear classifiers, degrading the performance of the system
dramatically after compromising a small fraction of the training dataset. In
this paper we propose a defence mechanism to mitigate the effect of these
optimal poisoning attacks based on outlier detection. We show empirically that
the adversarial examples generated by these attack strategies are quite
different from genuine points, as no detectability constrains are considered to
craft the attack. Hence, they can be detected with an appropriate pre-filtering
of the training dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Paudice_A/0/1/0/all/0/1&quot;&gt;Andrea Paudice&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Munoz_Gonzalez_L/0/1/0/all/0/1&quot;&gt;Luis Mu&amp;#xf1;oz-Gonz&amp;#xe1;lez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gyorgy_A/0/1/0/all/0/1&quot;&gt;Andras Gyorgy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lupu_E/0/1/0/all/0/1&quot;&gt;Emil C. Lupu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.03145">
<title>Relational Autoencoder for Feature Extraction. (arXiv:1802.03145v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.03145</link>
<description rdf:parseType="Literal">&lt;p&gt;Feature extraction becomes increasingly important as data grows high
dimensional. Autoencoder as a neural network based feature extraction method
achieves great success in generating abstract features of high dimensional
data. However, it fails to consider the relationships of data samples which may
affect experimental results of using original and new features. In this paper,
we propose a Relation Autoencoder model considering both data features and
their relationships. We also extend it to work with other major autoencoder
models including Sparse Autoencoder, Denoising Autoencoder and Variational
Autoencoder. The proposed relational autoencoder models are evaluated on a set
of benchmark datasets and the experimental results show that considering data
relationships can generate more robust features which achieve lower
construction loss and then lower error rate in further classification compared
to the other variants of autoencoders.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meng_Q/0/1/0/all/0/1&quot;&gt;Qinxue Meng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Catchpoole_D/0/1/0/all/0/1&quot;&gt;Daniel Catchpoole&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Skillicorn_D/0/1/0/all/0/1&quot;&gt;David Skillicorn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kennedy_P/0/1/0/all/0/1&quot;&gt;Paul J. Kennedy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.03184">
<title>Self-Bounded Prediction Suffix Tree via Approximate String Matching. (arXiv:1802.03184v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.03184</link>
<description rdf:parseType="Literal">&lt;p&gt;Prediction suffix trees (PST) provide an effective tool for sequence
modelling and prediction. Current prediction techniques for PSTs rely on exact
matching between the suffix of the current sequence and the previously observed
sequence. We present a provably correct algorithm for learning a PST with
approximate suffix matching by relaxing the exact matching condition. We then
present a self-bounded enhancement of our algorithm where the depth of suffix
tree grows automatically in response to the model performance on a training
sequence. Through experiments on synthetic datasets as well as three real-world
datasets, we show that the approximate matching PST results in better
predictive performance than the other variants of PST.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1&quot;&gt;Dongwoo Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Walder_C/0/1/0/all/0/1&quot;&gt;Christian Walder&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.03334">
<title>Learning Localized Spatio-Temporal Models From Streaming Data. (arXiv:1802.03334v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.03334</link>
<description rdf:parseType="Literal">&lt;p&gt;We address the problem of predicting spatio-temporal processes with temporal
patterns that vary across spatial regions, when data is obtained as a stream.
That is, when the training dataset is augmented sequentially. Specifically, we
develop a localized spatio-temporal covariance model of the process that can
capture spatially varying temporal periodicities in the data. We then apply a
covariance-fitting methodology to learn the model parameters which yields a
predictor that can be updated sequentially with each new data point. The
proposed method is evaluated using both synthetic and real climate data which
demonstrate its ability to accurately predict data missing in spatial regions
over time.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Osama_M/0/1/0/all/0/1&quot;&gt;Muhammad Osama&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zachariah_D/0/1/0/all/0/1&quot;&gt;Dave Zachariah&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Schon_T/0/1/0/all/0/1&quot;&gt;Thomas B. Sch&amp;#xf6;n&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.03358">
<title>Deep Learning for Malicious Flow Detection. (arXiv:1802.03358v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.03358</link>
<description rdf:parseType="Literal">&lt;p&gt;Cyber security has grown up to be a hot issue in recent years. How to
identify potential malware becomes a challenging task. To tackle this
challenge, we adopt deep learning approaches and perform flow detection on real
data. However, real data often encounters an issue of imbalanced data
distribution which will lead to a gradient dilution issue. When training a
neural network, this problem will not only result in a bias toward the majority
class but show the inability to learn from the minority classes. In this paper,
we propose an end-to-end trainable Tree-Shaped Deep Neural Network (TSDNN)
which classifies the data in a layer-wise manner. To better learn from the
minority classes, we propose a Quantity Dependent Backpropagation (QDBP)
algorithm which incorporates the knowledge of the disparity between classes. We
evaluate our method on an imbalanced data set. Experimental result demonstrates
that our approach outperforms the state-of-the-art methods and justifies that
the proposed method is able to overcome the difficulty of imbalanced learning.
We also conduct a partial flow experiment which shows the feasibility of
real-time detection and a zero-shot learning experiment which justifies the
generalization capability of deep learning in cyber security.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yun-Chun Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yu-Jhe Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tseng_A/0/1/0/all/0/1&quot;&gt;Aragorn Tseng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_T/0/1/0/all/0/1&quot;&gt;Tsungnan Lin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.03360">
<title>Information Planning for Text Data. (arXiv:1802.03360v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.03360</link>
<description rdf:parseType="Literal">&lt;p&gt;Information planning enables faster learning with fewer training examples. It
is particularly applicable when training examples are costly to obtain. This
work examines the advantages of information planning for text data by focusing
on three supervised models: Naive Bayes, supervised LDA and deep neural
networks. We show that planning based on entropy and mutual information
outperforms random selection baseline and therefore accelerates learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Smolyakov_V/0/1/0/all/0/1&quot;&gt;Vadim Smolyakov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pacheco_J/0/1/0/all/0/1&quot;&gt;Jason Pacheco&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Fisher_J/0/1/0/all/0/1&quot;&gt;John W. Fisher III&lt;/a&gt;</dc:creator>
</item></rdf:RDF>