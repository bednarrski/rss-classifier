<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Good papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Good Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-01-07T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.01423"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.01539"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.01563"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1704.07816"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1705.08868"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.05027"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.05443"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.06567"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.01143"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.01228"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.01258"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.01681"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.01807"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1704.01006"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.06513"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.01401"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.01467"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.01587"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1703.01220"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1707.06487"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1708.05207"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.11176"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.04432"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.07107"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.00209"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1801.01423">
<title>Overcoming catastrophic forgetting with hard attention to the task. (arXiv:1801.01423v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1801.01423</link>
<description rdf:parseType="Literal">&lt;p&gt;Catastrophic forgetting occurs when a neural network loses the information
learned with the first task, after training on a second task. This problem
remains a hurdle for general artificial intelligence systems with sequential
learning capabilities. In this paper, we propose a task-based hard attention
mechanism that preserves previous tasks&apos; information without substantially
affecting the current task&apos;s learning. An attention mask is learned
concurrently to every task through stochastic gradient descent, and previous
masks are exploited to constrain such learning. We show that the proposed
mechanism is effective for reducing catastrophic forgetting, cutting current
rates by 33 to 84%. We also show that it is robust to different hyperparameter
choices and that it offers a number of monitoring capabilities. The approach
features the possibility to control both the stability and compactness of the
learned knowledge, which we believe makes it also attractive for online
learning and network compression applications.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Serra_J/0/1/0/all/0/1&quot;&gt;Joan Serr&amp;#xe0;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Suris_D/0/1/0/all/0/1&quot;&gt;D&amp;#xed;dac Sur&amp;#xed;s&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Miron_M/0/1/0/all/0/1&quot;&gt;Marius Miron&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Karatzoglou_A/0/1/0/all/0/1&quot;&gt;Alexandros Karatzoglou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.01539">
<title>DeepIso: A Deep Learning Model for Peptide Feature Detection. (arXiv:1801.01539v1 [q-bio.QM])</title>
<link>http://arxiv.org/abs/1801.01539</link>
<description rdf:parseType="Literal">&lt;p&gt;Liquid chromatography with tandem mass spectrometry (LC-MS/MS) based
proteomics is a well-established research field with major applications such as
identification of disease biomarkers, drug discovery, drug design and
development. In proteomics, protein identification and quantification is a
fundamental task, which is done by first enzymatically digesting it into
peptides, and then analyzing peptides by LC-MS/MS instruments. The peptide
feature detection and quantification from an LC-MS map is the first step in
typical analysis workflows. In this paper we propose a novel deep learning
based model, DeepIso, that uses Convolutional Neural Networks (CNNs) to scan an
LC-MS map to detect peptide features and estimate their abundance. Existing
tools are often designed with limited engineered features based on domain
knowledge, and depend on pretrained parameters which are hardly updated despite
huge amount of new coming proteomic data. Our proposed model, on the other
hand, is capable of learning multiple levels of representation of high
dimensional data through its many layers of neurons and continuously evolving
with newly acquired data. To evaluate our proposed model, we use an antibody
dataset including a heavy and a light chain, each digested by Asp-N,
Chymotrypsin, Trypsin, thus giving six LC-MS maps for the experiment. Our model
achieves 93.21% sensitivity with specificity of 99.44% on this dataset. Our
results demonstrate that novel deep learning tools are desirable to advance the
state-of-the-art in protein identification and quantification.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Zohora_F/0/1/0/all/0/1&quot;&gt;Fatema Tuz Zohora&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Tran_N/0/1/0/all/0/1&quot;&gt;Ngoc Hieu Tran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xianglilan Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Xin_L/0/1/0/all/0/1&quot;&gt;Lei Xin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Shan_B/0/1/0/all/0/1&quot;&gt;Baozhen Shan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Li_M/0/1/0/all/0/1&quot;&gt;Ming Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.01563">
<title>DENSER: Deep Evolutionary Network Structured Representation. (arXiv:1801.01563v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1801.01563</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep Evolutionary Network Structured Representation (DENSER) is a novel
approach to automatically design Artificial Neural Networks (ANNs) using
Evolutionary Computation (EC). The algorithm not only searches for the best
network topology (e.g., number of layers, type of layers), but also tunes
hyper-parameters, such as, learning parameters or data augmentation parameters.
The automatic design is achieved using a representation with two distinct
levels, where the outer level encodes the general structure of the network,
i.e., the sequence of layers, and the inner level encodes the parameters
associated with each layer. The allowed layers and hyper-parameter value ranges
are defined by means of a human-readable Context-Free Grammar. DENSER was used
to evolve ANNs for two widely used image classification benchmarks obtaining an
average accuracy result of up to 94.27% on the CIFAR-10 dataset, and of 78.75%
on the CIFAR-100. To the best of our knowledge, our CIFAR-100 results are the
highest performing models generated by methods that aim at the automatic design
of Convolutional Neural Networks (CNNs), and is amongst the best for manually
designed and fine-tuned CNNs .
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Assuncao_F/0/1/0/all/0/1&quot;&gt;Filipe Assun&amp;#xe7;&amp;#xe3;o&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lourenco_N/0/1/0/all/0/1&quot;&gt;Nuno Louren&amp;#xe7;o&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Machado_P/0/1/0/all/0/1&quot;&gt;Penousal Machado&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ribeiro_B/0/1/0/all/0/1&quot;&gt;Bernardete Ribeiro&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1704.07816">
<title>Introspective Classification with Convolutional Nets. (arXiv:1704.07816v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1704.07816</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose introspective convolutional networks (ICN) that emphasize the
importance of having convolutional neural networks empowered with generative
capabilities. We employ a reclassification-by-synthesis algorithm to perform
training using a formulation stemmed from the Bayes theory. Our ICN tries to
iteratively: (1) synthesize pseudo-negative samples; and (2) enhance itself by
improving the classification. The single CNN classifier learned is at the same
time generative --- being able to directly synthesize new samples within its
own discriminative model. We conduct experiments on benchmark datasets
including MNIST, CIFAR-10, and SVHN using state-of-the-art CNN architectures,
and observe improved classification results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jin_L/0/1/0/all/0/1&quot;&gt;Long Jin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lazarow_J/0/1/0/all/0/1&quot;&gt;Justin Lazarow&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tu_Z/0/1/0/all/0/1&quot;&gt;Zhuowen Tu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1705.08868">
<title>Flow-GAN: Combining Maximum Likelihood and Adversarial Learning in Generative Models. (arXiv:1705.08868v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1705.08868</link>
<description rdf:parseType="Literal">&lt;p&gt;Adversarial learning of probabilistic models has recently emerged as a
promising alternative to maximum likelihood. Implicit models such as generative
adversarial networks (GAN) often generate better samples compared to explicit
models trained by maximum likelihood. Yet, GANs sidestep the characterization
of an explicit density which makes quantitative evaluations challenging. To
bridge this gap, we propose Flow-GANs, a generative adversarial network for
which we can perform exact likelihood evaluation, thus supporting both
adversarial and maximum likelihood training. When trained adversarially,
Flow-GANs generate high-quality samples but attain extremely poor
log-likelihood scores, inferior even to a mixture model memorizing the training
data; the opposite is true when trained by maximum likelihood. Results on MNIST
and CIFAR-10 demonstrate that hybrid training can attain high held-out
likelihoods while retaining visual fidelity in the generated samples.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grover_A/0/1/0/all/0/1&quot;&gt;Aditya Grover&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dhar_M/0/1/0/all/0/1&quot;&gt;Manik Dhar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ermon_S/0/1/0/all/0/1&quot;&gt;Stefano Ermon&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.05027">
<title>Learning Intrinsic Sparse Structures within Long Short-Term Memory. (arXiv:1709.05027v5 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1709.05027</link>
<description rdf:parseType="Literal">&lt;p&gt;Model compression is significant for the wide adoption of Recurrent Neural
Networks (RNNs) in both user devices possessing limited resources and business
clusters requiring quick responses to large-scale service requests. This work
aims to learn structurally-sparse Long Short-Term Memory (LSTM) by reducing the
sizes of basic structures within LSTM units, including input updates, gates,
hidden states, cell states and outputs. Independently reducing the sizes of
basic structures can result in inconsistent dimensions among them, and
consequently, end up with invalid LSTM units. To overcome the problem, we
propose Intrinsic Sparse Structures (ISS) in LSTMs. Removing a component of ISS
will simultaneously decrease the sizes of all basic structures by one and
thereby always maintain the dimension consistency. By learning ISS within LSTM
units, the obtained LSTMs remain regular while having much smaller basic
structures. Based on group Lasso regularization, our method achieves 10.59x
speedup without losing any perplexity of a language modeling of Penn TreeBank
dataset. It is also successfully evaluated through a compact model with only
2.69M weights for machine Question Answering of SQuAD dataset. Our approach is
successfully extended to non- LSTM RNNs, like Recurrent Highway Networks
(RHNs). Our source code is publicly available at
https://github.com/wenwei202/iss-rnns
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wen_W/0/1/0/all/0/1&quot;&gt;Wei Wen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1&quot;&gt;Yuxiong He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rajbhandari_S/0/1/0/all/0/1&quot;&gt;Samyam Rajbhandari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1&quot;&gt;Minjia Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1&quot;&gt;Wenhan Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1&quot;&gt;Fang Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_B/0/1/0/all/0/1&quot;&gt;Bin Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yiran Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1&quot;&gt;Hai Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.05443">
<title>Human and Machine Speaker Recognition Based on Short Trivial Events. (arXiv:1711.05443v2 [cs.SD] UPDATED)</title>
<link>http://arxiv.org/abs/1711.05443</link>
<description rdf:parseType="Literal">&lt;p&gt;Trivial events are ubiquitous in human to human conversations, e.g., cough,
laugh and sniff. Compared to regular speech, these trivial events are usually
short and unclear, thus generally regarded as not speaker discriminative and so
are largely ignored by present speaker recognition research. However, these
trivial events are highly valuable in some particular circumstances such as
forensic examination, as they are less subjected to intentional change, so can
be used to discover the genuine speaker from disguised speech. In this paper,
we collect a trivial event speech database that involves 75 speakers and 6
types of events, and report preliminary speaker recognition results on this
database, by both human listeners and machines. Particularly, the deep feature
learning technique recently proposed by our group is utilized to analyze and
recognize the trivial events, which leads to acceptable equal error rates
(EERs) despite the extremely short durations (0.2-0.5 seconds) of these events.
Comparing different types of events, &apos;hmm&apos; seems more speaker discriminative.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1&quot;&gt;Miao Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kang_X/0/1/0/all/0/1&quot;&gt;Xiaofei Kang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yanqing Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1&quot;&gt;Lantian Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_Z/0/1/0/all/0/1&quot;&gt;Zhiyuan Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dai_H/0/1/0/all/0/1&quot;&gt;Haisheng Dai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1&quot;&gt;Dong Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.06567">
<title>Deep Neuroevolution: Genetic Algorithms Are a Competitive Alternative for Training Deep Neural Networks for Reinforcement Learning. (arXiv:1712.06567v2 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1712.06567</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep artificial neural networks (DNNs) are typically trained via
gradient-based learning algorithms, namely backpropagation. Evolution
strategies (ES) can rival backprop-based algorithms such as Q-learning and
policy gradients on challenging deep reinforcement learning (RL) problems.
However, ES can be considered a gradient-based algorithm because it performs
stochastic gradient descent via an operation similar to a finite-difference
approximation of the gradient. That raises the question of whether
non-gradient-based evolutionary algorithms can work at DNN scales. Here we
demonstrate they can: we evolve the weights of a DNN with a simple,
gradient-free, population-based genetic algorithm (GA) and it performs well on
hard deep RL problems, including Atari and humanoid locomotion. The Deep GA
successfully evolves networks with over four million free parameters, the
largest neural networks ever evolved with a traditional evolutionary algorithm.
These results (1) expand our sense of the scale at which GAs can operate, (2)
suggest intriguingly that in some cases following the gradient is not the best
choice for optimizing performance, and (3) make immediately available the
multitude of techniques that have been developed in the neuroevolution
community to improve performance on RL problems. To demonstrate the latter, we
show that combining DNNs with novelty search, which was designed to encourage
exploration on tasks with deceptive or sparse reward functions, can solve a
high-dimensional problem on which reward-maximizing algorithms (e.g. DQN, A3C,
ES, and the GA) fail. Additionally, the Deep GA parallelizes better than ES,
A3C, and DQN, and enables a state-of-the-art compact encoding technique that
can represent million-parameter DNNs in thousands of bytes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Such_F/0/1/0/all/0/1&quot;&gt;Felipe Petroski Such&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Madhavan_V/0/1/0/all/0/1&quot;&gt;Vashisht Madhavan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Conti_E/0/1/0/all/0/1&quot;&gt;Edoardo Conti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lehman_J/0/1/0/all/0/1&quot;&gt;Joel Lehman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stanley_K/0/1/0/all/0/1&quot;&gt;Kenneth O. Stanley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Clune_J/0/1/0/all/0/1&quot;&gt;Jeff Clune&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.01143">
<title>Coins and Logic. (arXiv:1801.01143v1 [math.HO])</title>
<link>http://arxiv.org/abs/1801.01143</link>
<description rdf:parseType="Literal">&lt;p&gt;We establish fun parallels between coin-weighing puzzles and
knights-and-knaves puzzles.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Khovanova_T/0/1/0/all/0/1&quot;&gt;Tanya Khovanova&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.01228">
<title>A Decision-theoretic Approach to Detection-based Target Search with a UAV. (arXiv:1801.01228v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1801.01228</link>
<description rdf:parseType="Literal">&lt;p&gt;Search and rescue missions and surveillance require finding targets in a
large area. These tasks often use unmanned aerial vehicles (UAVs) with cameras
to detect and move towards a target. However, common UAV approaches make two
simplifying assumptions. First, they assume that observations made from
different heights are deterministically correct. In practice, observations are
noisy, with the noise increasing as the height used for observations increases.
Second, they assume that a motion command executes correctly, which may not
happen due to wind and other environmental factors. To address these, we
propose a sequential algorithm that determines actions in real time based on
observations, using partially observable Markov decision processes (POMDPs).
Our formulation handles both observations and motion uncertainty and errors. We
run offline simulations and learn a policy. This policy is run on a UAV to find
the target efficiently. We employ a novel compact formulation to represent the
coordinates of the drone relative to the target coordinates. Our POMDP policy
finds the target up to 3.4 times faster when compared to a heuristic policy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1&quot;&gt;Aayush Gupta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bessonov_D/0/1/0/all/0/1&quot;&gt;Daniel Bessonov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1&quot;&gt;Patrick Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.01258">
<title>Deep Learning Reconstruction for 9-View Dual Energy CT Baggage Scanner. (arXiv:1801.01258v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1801.01258</link>
<description rdf:parseType="Literal">&lt;p&gt;For homeland and transportation security applications, 2D X-ray explosive
detection system (EDS) have been widely used, but they have limitations in
recognizing 3D shape of the hidden objects. Among various types of 3D computed
tomography (CT) systems to address this issue, this paper is interested in a
stationary CT using fixed X-ray sources and detectors. However, due to the
limited number of projection views, analytic reconstruction algorithms produce
severe streaking artifacts. Inspired by recent success of deep learning
approach for sparse view CT reconstruction, here we propose a novel image and
sinogram domain deep learning architecture for 3D reconstruction from very
sparse view measurement. The algorithm has been tested with the real data from
a prototype 9-view dual energy stationary CT EDS carry-on baggage scanner
developed by GEMSS Medical Systems, Korea, which confirms the superior
reconstruction performance over the existing approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Han_Y/0/1/0/all/0/1&quot;&gt;Yoseob Han&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kang_J/0/1/0/all/0/1&quot;&gt;Jingu Kang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1&quot;&gt;Jong Chul Ye&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.01681">
<title>VulDeePecker: A Deep Learning-Based System for Vulnerability Detection. (arXiv:1801.01681v1 [cs.CR])</title>
<link>http://arxiv.org/abs/1801.01681</link>
<description rdf:parseType="Literal">&lt;p&gt;The automatic detection of software vulnerabilities is an important research
problem. However, existing solutions to this problem rely on human experts to
define features and often miss many vulnerabilities (i.e., incurring high false
negative rate). In this paper, we initiate the study of using deep
learning-based vulnerability detection to relieve human experts from the
tedious and subjective task of manually defining features. Since deep learning
is motivated to deal with problems that are very different from the problem of
vulnerability detection, we need some guiding principles for applying deep
learning to vulnerability detection. In particular, we need to find
representations of software programs that are suitable for deep learning. For
this purpose, we propose using code gadgets to represent programs and then
transform them into vectors, where a code gadget is a number of (not
necessarily consecutive) lines of code that are semantically related to each
other. This leads to the design and implementation of a deep learning-based
vulnerability detection system, called Vulnerability Deep Pecker
(VulDeePecker). In order to evaluate VulDeePecker, we present the first
vulnerability dataset for deep learning approaches. Experimental results show
that VulDeePecker can achieve much fewer false negatives (with reasonable false
positives) than other approaches. We further apply VulDeePecker to 3 software
products (namely Xen, Seamonkey, and Libav) and detect 4 vulnerabilities, which
are not reported in the National Vulnerability Database but were &quot;silently&quot;
patched by the vendors when releasing later versions of these products; in
contrast, these vulnerabilities are almost entirely missed by the other
vulnerability detection systems we experimented with.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Zhen Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zou_D/0/1/0/all/0/1&quot;&gt;Deqing Zou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_S/0/1/0/all/0/1&quot;&gt;Shouhuai Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ou_X/0/1/0/all/0/1&quot;&gt;Xinyu Ou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jin_H/0/1/0/all/0/1&quot;&gt;Hai Jin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1&quot;&gt;Sujuan Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deng_Z/0/1/0/all/0/1&quot;&gt;Zhijun Deng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhong_Y/0/1/0/all/0/1&quot;&gt;Yuyi Zhong&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.01807">
<title>A Greedy Search Tree Heuristic for Symbolic Regression. (arXiv:1801.01807v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1801.01807</link>
<description rdf:parseType="Literal">&lt;p&gt;Symbolic Regression tries to find a mathematical expression that describes
the relationship of a set of explanatory variables to a measured variable. The
main objective is to find a model that minimizes the error and, optionally,
that also minimizes the expression size. A smaller expression can be seen as an
interpretable model considered a reliable decision model. This is often
performed with Genetic Programming which represents their solution as
expression trees. The shortcoming of this algorithm lies on this representation
that defines a rugged search space and contains expressions of any size and
difficulty. These pose as a challenge to find the optimal solution under
computational constraints. This paper introduces a new data structure, called
Interaction-Transformation (IT), that constrains the search space in order to
exclude a region of larger and more complicated expressions. In order to test
this data structure, it was also introduced an heuristic called SymTree. The
obtained results show evidence that SymTree are capable of obtaining the
optimal solution whenever the target function is within the search space of the
IT data structure and competitive results when it is not. Overall, the
algorithm found a good compromise between accuracy and simplicity for all the
generated models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Franca_F/0/1/0/all/0/1&quot;&gt;Fabricio Olivetti de Franca&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1704.01006">
<title>Ontology based Scene Creation for the Development of Automated Vehicles. (arXiv:1704.01006v3 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1704.01006</link>
<description rdf:parseType="Literal">&lt;p&gt;The introduction of automated vehicles without permanent human supervision
demands a functional system description, including functional system boundaries
and a comprehensive safety analysis. These inputs to the technical development
can be identified and analyzed by a scenario-based approach. Furthermore, to
establish an economical test and release process, a large number of scenarios
must be identified to obtain meaningful test results. Experts are doing well to
identify scenarios that are difficult to handle or unlikely to happen. However,
experts are unlikely to identify all scenarios possible based on the knowledge
they have on hand. Expert knowledge modeled for computer aided processing may
help for the purpose of providing a wide range of scenarios. This contribution
reviews ontologies as knowledge-based systems in the field of automated
vehicles, and proposes a generation of traffic scenes in natural language as a
basis for a scenario creation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bagschik_G/0/1/0/all/0/1&quot;&gt;Gerrit Bagschik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Menzel_T/0/1/0/all/0/1&quot;&gt;Till Menzel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Maurer_M/0/1/0/all/0/1&quot;&gt;Markus Maurer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.06513">
<title>Learning Pose Grammar to Encode Human Body Configuration for 3D Pose Estimation. (arXiv:1710.06513v6 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1710.06513</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we propose a pose grammar to tackle the problem of 3D human
pose estimation. Our model directly takes 2D pose as input and learns a
generalized 2D-3D mapping function. The proposed model consists of a base
network which efficiently captures pose-aligned features and a hierarchy of
Bi-directional RNNs (BRNN) on the top to explicitly incorporate a set of
knowledge regarding human body configuration (i.e., kinematics, symmetry, motor
coordination). The proposed model thus enforces high-level constraints over
human poses. In learning, we develop a pose sample simulator to augment
training samples in virtual camera views, which further improves our model
generalizability. We validate our method on public 3D human pose benchmarks and
propose a new evaluation protocol working on cross-view setting to verify the
generalization capability of different methods. We empirically observe that
most state-of-the-art methods encounter difficulty under such setting while our
method can well handle such challenges.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fang_H/0/1/0/all/0/1&quot;&gt;Haoshu Fang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1&quot;&gt;Yuanlu Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1&quot;&gt;Wenguan Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1&quot;&gt;Xiaobai Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_S/0/1/0/all/0/1&quot;&gt;Song-Chun Zhu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.01401">
<title>Demystifying MMD GANs. (arXiv:1801.01401v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1801.01401</link>
<description rdf:parseType="Literal">&lt;p&gt;We investigate the training and performance of generative adversarial
networks using the Maximum Mean Discrepancy (MMD) as critic, termed MMD GANs.
As our main theoretical contribution, we clarify the situation with bias in GAN
loss functions raised by recent work: we show that gradient estimators used in
the optimization process for both MMD GANs and Wasserstein GANs are unbiased,
while gradients of the generator&apos;s theoretical loss are biased in both cases.
We discuss the issue of kernel choice for the MMD critic, and characterize the
kernel corresponding to the energy distance used for the Cram\&apos;er GAN critic.
Being an integral probability metric, the MMD benefits from training strategies
recently developed for Wasserstein GANs. In experiments, the MMD GAN is able to
employ a smaller critic network than the Wasserstein GAN, resulting in a
simpler and faster-training algorithm with matching performance. We also
propose an improved measure of GAN convergence, the Kernel Inception Distance,
and show how to use it to dynamically adapt learning rates during GAN training.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Binkowski_M/0/1/0/all/0/1&quot;&gt;Miko&amp;#x142;aj Bi&amp;#x144;kowski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sutherland_D/0/1/0/all/0/1&quot;&gt;Dougal J. Sutherland&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Arbel_M/0/1/0/all/0/1&quot;&gt;Michael Arbel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gretton_A/0/1/0/all/0/1&quot;&gt;Arthur Gretton&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.01467">
<title>Deep Reinforcement Learning based Optimal Control of Hot Water Systems. (arXiv:1801.01467v1 [cs.SY])</title>
<link>http://arxiv.org/abs/1801.01467</link>
<description rdf:parseType="Literal">&lt;p&gt;Energy consumption for hot water production is a major draw in high
efficiency buildings. Optimizing this has typically been approached from a
thermodynamics perspective, decoupled from occupant influence. Furthermore,
optimization usually presupposes existence of a detailed dynamics model for the
hot water system. These assumptions lead to suboptimal energy efficiency in the
real world. In this paper, we present a novel reinforcement learning based
methodology which optimizes hot water production. The proposed methodology is
completely generalizable, and does not require an offline step or human domain
knowledge to build a model for the hot water vessel or the heating element.
Occupant preferences too are learnt on the fly. The proposed system is applied
to a set of 32 houses in the Netherlands where it reduces energy consumption
for hot water production by roughly 20% with no loss of occupant comfort.
Extrapolating, this translates to absolute savings of roughly 200 kWh for a
single household on an annual basis. This performance can be replicated to any
domestic hot water system and optimization objective, given that the fairly
minimal requirements on sensor data are met. With millions of hot water systems
operational worldwide, the proposed framework has the potential to reduce
energy consumption in existing and new systems on a multi Gigawatt-hour scale
in the years to come.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kazmi_H/0/1/0/all/0/1&quot;&gt;Hussain Kazmi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mehmood_F/0/1/0/all/0/1&quot;&gt;Fahad Mehmood&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lodeweyckx_S/0/1/0/all/0/1&quot;&gt;Stefan Lodeweyckx&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Driesen_J/0/1/0/all/0/1&quot;&gt;Johan Driesen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.01587">
<title>SpectralNet: Spectral Clustering using Deep Neural Networks. (arXiv:1801.01587v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1801.01587</link>
<description rdf:parseType="Literal">&lt;p&gt;Spectral clustering is a leading and popular technique in unsupervised data
analysis. Two of its major limitations are scalability and generalization of
the spectral embedding (i.e., out-of-sample-extension). In this paper we
introduce a deep learning approach to spectral clustering that overcomes the
above shortcomings. Our network, which we call SpectralNet, learns a map that
embeds input data points into the eigenspace of their associated graph
Laplacian matrix and subsequently clusters them. We train SpectralNet using a
procedure that involves constrained stochastic optimization. Stochastic
optimization allows it to scale to large datasets, while the constraints, which
are implemented using a special-purpose output layer, allow us to keep the
network output orthogonal. Moreover, the map learned by SpectralNet naturally
generalizes the spectral embedding to unseen data points. To further improve
the quality of the clustering, we replace the standard pairwise Gaussian
affinities with affinities leaned from unlabeled data using a Siamese network.
Additional improvement can be achieved by applying the network to code
representations produced, e.g., by standard autoencoders. Our end-to-end
learning procedure is fully unsupervised. In addition, we apply VC dimension
theory to derive a lower bound on the size of SpectralNet. State-of-the-art
clustering results are reported on the Reuters dataset. Our implementation is
publicly available at https://github.com/kstant0725/SpectralNet .
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Shaham_U/0/1/0/all/0/1&quot;&gt;Uri Shaham&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Stanton_K/0/1/0/all/0/1&quot;&gt;Kelly Stanton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Li_H/0/1/0/all/0/1&quot;&gt;Henry Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Nadler_B/0/1/0/all/0/1&quot;&gt;Boaz Nadler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Basri_R/0/1/0/all/0/1&quot;&gt;Ronen Basri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kluger_Y/0/1/0/all/0/1&quot;&gt;Yuval Kluger&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1703.01220">
<title>Denoising Adversarial Autoencoders. (arXiv:1703.01220v4 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1703.01220</link>
<description rdf:parseType="Literal">&lt;p&gt;Unsupervised learning is of growing interest because it unlocks the potential
held in vast amounts of unlabelled data to learn useful representations for
inference. Autoencoders, a form of generative model, may be trained by learning
to reconstruct unlabelled input data from a latent representation space. More
robust representations may be produced by an autoencoder if it learns to
recover clean input samples from corrupted ones. Representations may be further
improved by introducing regularisation during training to shape the
distribution of the encoded data in latent space. We suggest denoising
adversarial autoencoders, which combine denoising and regularisation, shaping
the distribution of latent space using adversarial training. We introduce a
novel analysis that shows how denoising may be incorporated into the training
and sampling of adversarial autoencoders. Experiments are performed to assess
the contributions that denoising makes to the learning of representations for
classification and sample synthesis. Our results suggest that autoencoders
trained using a denoising criterion achieve higher classification performance,
and can synthesise samples that are more consistent with the input data than
those trained without a corruption process.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Creswell_A/0/1/0/all/0/1&quot;&gt;Antonia Creswell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bharath_A/0/1/0/all/0/1&quot;&gt;Anil Anthony Bharath&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1707.06487">
<title>A Nonlinear Kernel Support Matrix Machine for Matrix Learning. (arXiv:1707.06487v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1707.06487</link>
<description rdf:parseType="Literal">&lt;p&gt;In many problems of supervised tensor learning (STL), real world data such as
face images or MRI scans are naturally represented as matrices, which are also
called as second order tensors. Most existing classifiers based on tensor
representation, such as support tensor machine (STM) need to solve iteratively
which occupy much time and may suffer from local minima. In this paper, we
present a kernel support matrix machine (KSMM) to perform supervised learning
when data are represented as matrices. KSMM is a general framework for the
construction of matrix-based hyperplane to exploit structural information. We
analyze a unifying optimization problem for which we propose an asymptotically
convergent algorithm. Theoretical analysis for the generalization bounds is
derived based on Rademacher complexity with respect to a probability
distribution. We demonstrate the merits of the proposed method by exhaustive
experiments on both simulation study and a number of real-word datasets from a
variety of application domains.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ye_Y/0/1/0/all/0/1&quot;&gt;Yunfei Ye&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1708.05207">
<title>Learning Universal Adversarial Perturbations with Generative Models. (arXiv:1708.05207v3 [cs.CR] UPDATED)</title>
<link>http://arxiv.org/abs/1708.05207</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural networks are known to be vulnerable to adversarial examples, inputs
that have been intentionally perturbed to remain visually similar to the source
input, but cause a misclassification. It was recently shown that given a
dataset and classifier, there exists so called universal adversarial
perturbations, a single perturbation that causes a misclassification when
applied to any input. In this work, we introduce universal adversarial
networks, a generative network that is capable of fooling a target classifier
when it&apos;s generated output is added to a clean sample from a dataset. We show
that this technique improves on known universal adversarial attacks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hayes_J/0/1/0/all/0/1&quot;&gt;Jamie Hayes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Danezis_G/0/1/0/all/0/1&quot;&gt;George Danezis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.11176">
<title>CrescendoNet: A Simple Deep Convolutional Neural Network with Ensemble Behavior. (arXiv:1710.11176v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1710.11176</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce a new deep convolutional neural network, CrescendoNet, by
stacking simple building blocks without residual connections. Each Crescendo
block contains independent convolution paths with increased depths. The numbers
of convolution layers and parameters are only increased linearly in Crescendo
blocks. In experiments, CrescendoNet with only 15 layers outperforms almost all
networks without residual connections on benchmark datasets, CIFAR10, CIFAR100,
and SVHN. Given sufficient amount of data as in SVHN dataset, CrescendoNet with
15 layers and 4.1M parameters can match the performance of DenseNet-BC with 250
layers and 15.3M parameters. CrescendoNet provides a new way to construct high
performance deep convolutional neural networks without residual connections.
Moreover, through investigating the behavior and performance of subnetworks in
CrescendoNet, we note that the high performance of CrescendoNet may come from
its implicit ensemble behavior, which differs from the FractalNet that is also
a deep convolutional neural network without residual connections. Furthermore,
the independence between paths in CrescendoNet allows us to introduce a new
path-wise training procedure, which can reduce the memory needed for training.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xiang Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vishwamitra_N/0/1/0/all/0/1&quot;&gt;Nishant Vishwamitra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1&quot;&gt;Hongxin Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_F/0/1/0/all/0/1&quot;&gt;Feng Luo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.04432">
<title>Integrated Model, Batch and Domain Parallelism in Training Neural Networks. (arXiv:1712.04432v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1712.04432</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a new integrated method of exploiting model, batch and domain
parallelism for the training of deep neural networks (DNNs) on large
distributed-memory computers using minibatch stochastic gradient descent (SGD).
Our goal is to find an efficient parallelization strategy for a fixed batch
size using $P$ processes. Our method is inspired by the communication-avoiding
algorithms in numerical linear algebra. We see $P$ processes as logically
divided into a $P_r \times P_c$ grid where the $P_r$ dimension is implicitly
responsible for model/domain parallelism and the $P_c$ dimension is implicitly
responsible for batch parallelism. In practice, the integrated matrix-based
parallel algorithm encapsulates these types of parallelism automatically. We
analyze the communication complexity and analytically demonstrate that the
lowest communication costs are often achieved neither with pure model nor with
pure data parallelism. We also show the positive effect of our approach in the
computational performance of SGD based DNN training where the reduced number of
processes responsible for data parallelism result in &quot;fatter&quot; matrices that
enable higher-throughput matrix multiplication.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gholami_A/0/1/0/all/0/1&quot;&gt;Amir Gholami&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Azad_A/0/1/0/all/0/1&quot;&gt;Ariful Azad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jin_P/0/1/0/all/0/1&quot;&gt;Peter Jin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Keutzer_K/0/1/0/all/0/1&quot;&gt;Kurt Keutzer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Buluc_A/0/1/0/all/0/1&quot;&gt;Aydin Buluc&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.07107">
<title>Adversarial Examples: Attacks and Defenses for Deep Learning. (arXiv:1712.07107v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1712.07107</link>
<description rdf:parseType="Literal">&lt;p&gt;With rapid progress and great successes in a wide spectrum of applications,
deep learning is being applied in many safety-critical environments. However,
deep neural networks have been recently found vulnerable to well-designed input
samples, called \textit{adversarial examples}. Adversarial examples are
imperceptible to human but can easily fool deep neural networks in the
testing/deploying stage. The vulnerability to adversarial examples becomes one
of the major risks for applying deep neural networks in safety-critical
scenarios. Therefore, the attacks and defenses on adversarial examples draw
great attention.
&lt;/p&gt;
&lt;p&gt;In this paper, we review recent findings on adversarial examples against deep
neural networks, summarize the methods for generating adversarial examples, and
propose a taxonomy of these methods. Under the taxonomy, applications and
countermeasures for adversarial examples are investigated. We further elaborate
on adversarial examples and explore the challenges and the potential solutions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yuan_X/0/1/0/all/0/1&quot;&gt;Xiaoyong Yuan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_P/0/1/0/all/0/1&quot;&gt;Pan He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_Q/0/1/0/all/0/1&quot;&gt;Qile Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bhat_R/0/1/0/all/0/1&quot;&gt;Rajendra Rana Bhat&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xiaolin Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.00209">
<title>Deep Reinforcement Learning for List-wise Recommendations. (arXiv:1801.00209v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1801.00209</link>
<description rdf:parseType="Literal">&lt;p&gt;Recommender systems play a crucial role in mitigating the problem of
information overload by suggesting users&apos; personalized items or services. The
vast majority of traditional recommender systems consider the recommendation
procedure as a static process and make recommendations following a fixed
strategy. In this paper, we propose a novel recommender system with the
capability of continuously improving its strategies during the interactions
with users. We model the sequential interactions between users and a
recommender system as a Markov Decision Process (MDP) and leverage
Reinforcement Learning (RL) to automatically learn the optimal strategies via
recommending trial-and-error items and receiving reinforcements of these items
from users&apos; feedbacks. In particular, we introduce an online user-agent
interacting environment simulator, which can pre-train and evaluate model
parameters offline before applying the model online. Moreover, we validate the
importance of list-wise recommendations during the interactions between users
and agent, and develop a novel approach to incorporate them into the proposed
framework LIRD for list-wide recommendations. The experimental results based on
a real-world e-commerce dataset demonstrate the effectiveness of the proposed
framework.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1&quot;&gt;Xiangyu Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1&quot;&gt;Liang Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ding_Z/0/1/0/all/0/1&quot;&gt;Zhuoye Ding&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yin_D/0/1/0/all/0/1&quot;&gt;Dawei Yin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_Y/0/1/0/all/0/1&quot;&gt;Yihong Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1&quot;&gt;Jiliang Tang&lt;/a&gt;</dc:creator>
</item></rdf:RDF>