<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Good papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Good Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-05-20T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07249"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.06530"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.11237"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.06962"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.06966"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07008"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07029"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07039"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07107"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07180"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07193"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07274"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07340"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.01244"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.05372"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.10188"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.06822"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07010"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07072"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07091"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07123"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07137"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07159"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07226"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07242"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07252"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07297"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07324"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07337"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1705.00850"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04302"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.04659"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.09060"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.03605"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1805.07249">
<title>Dynamic learning rate using Mutual Information. (arXiv:1805.07249v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.07249</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper demonstrates dynamic hyper-parameter setting, for deep neural
network training, using Mutual Information (MI). The specific hyper-parameter
studied in this paper is the learning rate. MI between the output layer and
true outcomes is used to dynamically set the learning rate of the network
through the training cycle; the idea is also extended to layer-wise setting of
learning rate. Two approaches are demonstrated - tracking relative change in
mutual information and, additionally tracking its value relative to a reference
measure. The paper does not attempt to recommend a specific learning rate
policy. Experiments demonstrate that mutual information may be effectively used
to dynamically set learning rate and achieve competitive to better outcomes in
competitive to better time.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vasudevan_S/0/1/0/all/0/1&quot;&gt;Shrihari Vasudevan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.06530">
<title>Dynamic Weight Alignment for Convolutional Neural Networks. (arXiv:1712.06530v3 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1712.06530</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we propose a method of improving Convolutional Neural Networks
(CNN) by determining the optimal alignment of weights and inputs using dynamic
programming. Conventional CNNs convolve learnable shared weights, or filters,
across the input data. The filters use a linear matching of weights to inputs
using an inner product between the filter and a window of the input. However,
it is possible that there exists a more optimal alignment of weights. Thus, we
propose the use of Dynamic Time Warping (DTW) to dynamically align the weights
to optimized input elements. This dynamic alignment is useful for time series
recognition due to the complexities with temporal distortions, such as varying
rates and sequence lengths. We demonstrate the effectiveness of the proposed
architecture on the Unipen online handwritten digit and character datasets, the
UCI Spoken Arabic Digit dataset, and the UCI Activities of Daily Life dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Iwana_B/0/1/0/all/0/1&quot;&gt;Brian Kenji Iwana&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Uchida_S/0/1/0/all/0/1&quot;&gt;Seiichi Uchida&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.11237">
<title>Deep learning improved by biological activation functions. (arXiv:1804.11237v2 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1804.11237</link>
<description rdf:parseType="Literal">&lt;p&gt;`Biologically inspired&apos; activation functions, such as the logistic sigmoid,
have been instrumental in the historical advancement of machine learning.
However in the field of deep learning, they have been largely displaced by
rectified linear units (ReLU) or similar functions, such as its exponential
linear unit (ELU) variant, to mitigate the effects of vanishing gradients
associated with error back-propagation. The logistic sigmoid however does not
represent the true input-output relation in neuronal cells under physiological
conditions. Here, bionodal root unit (BRU) activation functions are introduced,
exhibiting input-output non-linearities that are substantially more
biologically plausible since their functional form is based on known
biophysical properties of neuronal cells.
&lt;/p&gt;
&lt;p&gt;In order to evaluate the learning performance of BRU activations, deep
networks are constructed with identical architectures except differing in their
transfer functions (ReLU, ELU, and BRU). Multilayer perceptrons, stacked
auto-encoders, and convolutional networks are used to test supervised and
unsupervised learning based on the MNIST and CIFAR-10/100 datasets. Comparisons
of learning performance, quantified using loss and error measurements,
demonstrate that bionodal networks both train faster than their ReLU and ELU
counterparts and result in the best generalised models even in the absence of
formal regularisation. These results therefore suggest that revisiting the
detailed properties of biological neurones and their circuitry might prove
invaluable in the field of deep learning for the future.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bhumbra_G/0/1/0/all/0/1&quot;&gt;Gardave S Bhumbra&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.06962">
<title>Counterexample-Guided Data Augmentation. (arXiv:1805.06962v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.06962</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a novel framework for augmenting data sets for machine learning
based on counterexamples. Counterexamples are misclassified examples that have
important properties for retraining and improving the model. Key components of
our framework include a counterexample generator, which produces data items
that are misclassified by the model and error tables, a novel data structure
that stores information pertaining to misclassifications. Error tables can be
used to explain the model&apos;s vulnerabilities and are used to efficiently
generate counterexamples for augmentation. We show the efficacy of the proposed
framework by comparing it to classical augmentation techniques on a case study
of object detection in autonomous driving based on deep neural networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dreossi_T/0/1/0/all/0/1&quot;&gt;Tommaso Dreossi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghosh_S/0/1/0/all/0/1&quot;&gt;Shromona Ghosh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yue_X/0/1/0/all/0/1&quot;&gt;Xiangyu Yue&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Keutzer_K/0/1/0/all/0/1&quot;&gt;Kurt Keutzer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sangiovanni_Vincentelli_A/0/1/0/all/0/1&quot;&gt;Alberto Sangiovanni-Vincentelli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Seshia_S/0/1/0/all/0/1&quot;&gt;Sanjit A. Seshia&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.06966">
<title>Neural User Simulation for Corpus-based Policy Optimisation for Spoken Dialogue Systems. (arXiv:1805.06966v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1805.06966</link>
<description rdf:parseType="Literal">&lt;p&gt;User Simulators are one of the major tools that enable offline training of
task-oriented dialogue systems. For this task the Agenda-Based User Simulator
(ABUS) is often used. The ABUS is based on hand-crafted rules and its output is
in semantic form. Issues arise from both properties such as limited diversity
and the inability to interface a text-level belief tracker. This paper
introduces the Neural User Simulator (NUS) whose behaviour is learned from a
corpus and which generates natural language, hence needing a less labelled
dataset than simulators generating a semantic output. In comparison to much of
the past work on this topic, which evaluates user simulators on corpus-based
metrics, we use the NUS to train the policy of a reinforcement learning based
Spoken Dialogue System. The NUS is compared to the ABUS by evaluating the
policies that were trained using the simulators. Cross-model evaluation is
performed i.e. training on one simulator and testing on the other. Furthermore,
the trained policies are tested on real users. In both evaluation tasks the NUS
outperformed the ABUS.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kreyssig_F/0/1/0/all/0/1&quot;&gt;Florian Kreyssig&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Casanueva_I/0/1/0/all/0/1&quot;&gt;Inigo Casanueva&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Budzianowski_P/0/1/0/all/0/1&quot;&gt;Pawel Budzianowski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gasic_M/0/1/0/all/0/1&quot;&gt;Milica Gasic&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07008">
<title>Hierarchical Reinforcement Learning with Deep Nested Agents. (arXiv:1805.07008v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1805.07008</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep hierarchical reinforcement learning has gained a lot of attention in
recent years due to its ability to produce state-of-the-art results in
challenging environments where non-hierarchical frameworks fail to learn useful
policies. However, as problem domains become more complex, deep hierarchical
reinforcement learning can become inefficient, leading to longer convergence
times and poor performance. We introduce the Deep Nested Agent framework, which
is a variant of deep hierarchical reinforcement learning where information from
the main agent is propagated to the low level $nested$ agent by incorporating
this information into the nested agent&apos;s state. We demonstrate the
effectiveness and performance of the Deep Nested Agent framework by applying it
to three scenarios in Minecraft with comparisons to a deep non-hierarchical
single agent framework, as well as, a deep hierarchical framework.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brittain_M/0/1/0/all/0/1&quot;&gt;Marc Brittain&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wei_P/0/1/0/all/0/1&quot;&gt;Peng Wei&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07029">
<title>Scene Understanding Networks for Autonomous Driving based on Around View Monitoring System. (arXiv:1805.07029v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1805.07029</link>
<description rdf:parseType="Literal">&lt;p&gt;Modern driver assistance systems rely on a wide range of sensors (RADAR,
LIDAR, ultrasound and cameras) for scene understanding and prediction. These
sensors are typically used for detecting traffic participants and scene
elements required for navigation. In this paper we argue that relying on camera
based systems, specifically Around View Monitoring (AVM) system has great
potential to achieve these goals in both parking and driving modes with
decreased costs. The contributions of this paper are as follows: we present a
new end-to-end solution for delimiting the safe drivable area for each frame by
means of identifying the closest obstacle in each direction from the driving
vehicle, we use this approach to calculate the distance to the nearest
obstacles and we incorporate it into a unified end-to-end architecture capable
of joint object detection, curb detection and safe drivable area detection.
Furthermore, we describe the family of networks for both a high accuracy
solution and a low complexity solution. We also introduce further augmentation
of the base architecture with 3D object detection.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Baek_J/0/1/0/all/0/1&quot;&gt;JeongYeol Baek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chelu_I/0/1/0/all/0/1&quot;&gt;Ioana Veronica Chelu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Iordache_L/0/1/0/all/0/1&quot;&gt;Livia Iordache&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Paunescu_V/0/1/0/all/0/1&quot;&gt;Vlad Paunescu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ryu_H/0/1/0/all/0/1&quot;&gt;HyunJoo Ryu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghiuta_A/0/1/0/all/0/1&quot;&gt;Alexandru Ghiuta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Petreanu_A/0/1/0/all/0/1&quot;&gt;Andrei Petreanu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Soh_Y/0/1/0/all/0/1&quot;&gt;YunSung Soh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leica_A/0/1/0/all/0/1&quot;&gt;Andrei Leica&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jeon_B/0/1/0/all/0/1&quot;&gt;ByeongMoon Jeon&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07039">
<title>A Theoretical Explanation for Perplexing Behaviors of Backpropagation-based Visualizations. (arXiv:1805.07039v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1805.07039</link>
<description rdf:parseType="Literal">&lt;p&gt;Backpropagation-based visualizations have been proposed to interpret
convolutional neural networks (CNNs), however a theory is missing to justify
their behaviors: Guided backpropagation(GBP) and deconvolutional network
(DeconvNet) generate more human-interpretable but less class-sensitive
visualizations than saliency map. Motivated by this, we develop a theoretical
explanation revealing that GBP and DeconvNet are essentially doing (partial)
image recovery and thus are unrelated to the network decisions. Specifically,
our analysis shows that the backward ReLU introduced by GBP and DeconvNet, and
the local connections in CNNs are the two main causes of compelling
visualizations. Extensive experiments are provided that support the theoretical
analysis.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nie_W/0/1/0/all/0/1&quot;&gt;Weili Nie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yang Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Patel_A/0/1/0/all/0/1&quot;&gt;Ankit Patel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07107">
<title>Extending Dynamic Bayesian Networks for Anomaly Detection in Complex Logs. (arXiv:1805.07107v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1805.07107</link>
<description rdf:parseType="Literal">&lt;p&gt;Checking various log files from different processes can be a tedious task as
these logs contain lots of events, each with a (possibly large) number of
attributes. We developed a way to automatically model log files and detect
outlier traces in the data. For that we extend Dynamic Bayesian Networks to
model the normal behavior found in log files. We introduce a new algorithm that
is able to learn a model of a log file starting from the data itself. The model
is capable of scoring traces even when new values or new combinations of values
appear in the log file.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pauwels_S/0/1/0/all/0/1&quot;&gt;Stephen Pauwels&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Calders_T/0/1/0/all/0/1&quot;&gt;Toon Calders&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07180">
<title>Approximate Model Counting by Partial Knowledge Compilation. (arXiv:1805.07180v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1805.07180</link>
<description rdf:parseType="Literal">&lt;p&gt;Model counting is the problem of computing the number of satisfying
assignments of a given propositional formula. Although exact model counters can
be naturally furnished by most of the knowledge compilation (KC) methods, in
practice, they fail to generate the compiled results for the exact counting of
models for certain formulas due to the explosion in sizes. Decision-DNNF is an
important KC language that captures most of the practical compilers. We propose
a generalized Decision-DNNF (referred to as partial Decision-DNNF) via
introducing a class of new leaf vertices (called unknown vertices), and then
propose an algorithm called PartialKC to generate randomly partial
Decision-DNNF formulas from the given formulas. An unbiased estimate of the
model number can be computed via a randomly partial Decision-DNNF formula. Each
calling of PartialKC consists of multiple callings of MicroKC, while each of
the latter callings is a process of importance sampling equipped with KC
technologies. The experimental results show that PartialKC is more accurate
than both SampleSearch and SearchTreeSampler, PartialKC scales better than
SearchTreeSampler, and the KC technologies can obviously accelerate sampling.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lai_Y/0/1/0/all/0/1&quot;&gt;Yong Lai&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07193">
<title>The EuroCity Persons Dataset: A Novel Benchmark for Object Detection. (arXiv:1805.07193v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1805.07193</link>
<description rdf:parseType="Literal">&lt;p&gt;Big data has had a great share in the success of deep learning in computer
vision. Recent works suggest that there is significant further potential to
increase object detection performance by utilizing even bigger datasets. In
this paper, we introduce the EuroCity Persons dataset, which provides a large
number of highly diverse, accurate and detailed annotations of pedestrians,
cyclists and other riders in urban traffic scenes. The images for this dataset
were collected on-board a moving vehicle in 31 cities of 12 European countries.
With over 238200 person instances manually labeled in over 47300 images,
EuroCity Persons is nearly one order of magnitude larger than person datasets
used previously for benchmarking. The dataset furthermore contains a large
number of person orientation annotations (over 211200). We optimize four
state-of-the-art deep learning approaches (Faster R-CNN, R-FCN, SSD and YOLOv3)
to serve as baselines for the new object detection benchmark. In experiments
with previous datasets we analyze the generalization capabilities of these
detectors when trained with the new dataset. We furthermore study the effect of
the training set size, the dataset diversity (day- vs. night-time, geographical
region), the dataset detail (i.e. availability of object orientation
information) and the annotation quality on the detector performance. Finally,
we analyze error sources and discuss the road ahead.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Braun_M/0/1/0/all/0/1&quot;&gt;Markus Braun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Krebs_S/0/1/0/all/0/1&quot;&gt;Sebastian Krebs&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Flohr_F/0/1/0/all/0/1&quot;&gt;Fabian Flohr&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gavrila_D/0/1/0/all/0/1&quot;&gt;Dariu M. Gavrila&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07274">
<title>Language Expansion In Text-Based Games. (arXiv:1805.07274v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1805.07274</link>
<description rdf:parseType="Literal">&lt;p&gt;Text-based games are suitable test-beds for designing agents that can learn
by interaction with the environment in the form of natural language text. Very
recently, deep reinforcement learning based agents have been successfully
applied for playing text-based games. In this paper, we explore the possibility
of designing a single agent to play several text-based games and of expanding
the agent&apos;s vocabulary using the vocabulary of agents trained for multiple
games. To this extent, we explore the application of recently proposed policy
distillation method for video games to the text-based game setting. We also use
text-based games as a test-bed to analyze and hence understand policy
distillation approach in detail.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ansari_G/0/1/0/all/0/1&quot;&gt;Ghulam Ahmed Ansari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+P_S/0/1/0/all/0/1&quot;&gt;Sagar J P&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chandar_S/0/1/0/all/0/1&quot;&gt;Sarath Chandar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ravindran_B/0/1/0/all/0/1&quot;&gt;Balaraman Ravindran&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07340">
<title>Suffix Bidirectional Long Short-Term Memory. (arXiv:1805.07340v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.07340</link>
<description rdf:parseType="Literal">&lt;p&gt;Recurrent neural networks have become ubiquitous in computing representations
of sequential data, especially textual data in natural language processing. In
particular, Bidirectional LSTMs are at the heart of several neural models
achieving state-of-the-art performance in a wide variety of tasks in NLP. We
propose a general and effective improvement to the BiLSTM model which encodes
each suffix and prefix of a sequence of tokens in both forward and reverse
directions. We call our model Suffix BiLSTM or SuBiLSTM. Using an extensive set
of experiments, we demonstrate that using SuBiLSTM instead of a BiLSTM in
existing base models leads to improvements in performance in learning general
sentence representations, text classification, textual entailment and named
entity recognition. We achieve new state-of-the-art results for fine-grained
sentiment classification and question classification using SuBiLSTM.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brahma_S/0/1/0/all/0/1&quot;&gt;Siddhartha Brahma&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.01244">
<title>Meta-Learning by Adjusting Priors Based on Extended PAC-Bayes Theory. (arXiv:1711.01244v4 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1711.01244</link>
<description rdf:parseType="Literal">&lt;p&gt;In meta-learning an agent extracts knowledge from observed tasks, aiming to
facilitate learning of novel future tasks. Under the assumption that future
tasks are &apos;related&apos; to previous tasks, representations should be learned in a
way which captures the common structure across learned tasks, while allowing
the learner sufficient flexibility to adapt to novel aspects of new tasks. We
present a framework for meta-learning that is based on generalization error
bounds, allowing us to extend various PAC-Bayes bounds to meta-learning.
Learning takes place through the construction of a distribution over hypotheses
based on the observed tasks, and its utilization for learning a new task. Thus,
prior knowledge is incorporated through setting an experience-dependent prior
for novel tasks. We develop a gradient-based algorithm which minimizes an
objective function derived from the bounds and demonstrate its effectiveness
numerically with deep neural networks. In addition to establishing the improved
performance available through meta-learning, we demonstrate the intuitive way
by which prior information is manifested at different levels of the network.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Amit_R/0/1/0/all/0/1&quot;&gt;Ron Amit&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Meir_R/0/1/0/all/0/1&quot;&gt;Ron Meir&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.05372">
<title>Neural Feature Learning From Relational Database. (arXiv:1801.05372v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1801.05372</link>
<description rdf:parseType="Literal">&lt;p&gt;Feature engineering is one of the most important but most tedious tasks in
data science. This work studies automation of feature learning from relational
database. We first prove theoretically that finding the optimal features from
relational data for predictive tasks is NP-hard. We propose an efficient
rule-based approach based on heuristics and a deep neural network to
automatically learn appropriate features from relational data. We benchmark our
approaches in ensembles in past Kaggle competitions. Our new approach wins late
medals and beats the state-of-the-art solutions with significant margins. To
the best of our knowledge, this is the first time an automated data science
system could win medals in Kaggle competitions with complex relational
database.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lam_H/0/1/0/all/0/1&quot;&gt;Hoang Thanh Lam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Minh_T/0/1/0/all/0/1&quot;&gt;Tran Ngoc Minh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sinn_M/0/1/0/all/0/1&quot;&gt;Mathieu Sinn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Buesser_B/0/1/0/all/0/1&quot;&gt;Beat Buesser&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wistuba_M/0/1/0/all/0/1&quot;&gt;Martin Wistuba&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.10188">
<title>Dialogue Modeling Via Hash Functions: Applications to Psychotherapy. (arXiv:1804.10188v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1804.10188</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a novel machine-learning framework for dialogue modeling which
uses representations based on hash functions. More specifically, each person&apos;s
response is represented by a binary hashcode where each bit reflects presence
or absence of a certain text pattern in the response. Hashcodes serve as
compressed text representations, allowing for efficient similarity search.
Moreover, hashcode of one person&apos;s response can be used as a feature vector for
predicting the hashcode representing another person&apos;s response. The proposed
hashing model of dialogue is obtained by maximizing a novel lower bound on the
mutual information between the hashcodes of consecutive responses. We apply our
approach in psychotherapy domain, evaluating its effectiveness on a real-life
dataset consisting of therapy sessions with patients suffering from depression.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garg_S/0/1/0/all/0/1&quot;&gt;Sahil Garg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cecchi_G/0/1/0/all/0/1&quot;&gt;Guillermo Cecchi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rish_I/0/1/0/all/0/1&quot;&gt;Irina Rish&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_S/0/1/0/all/0/1&quot;&gt;Shuyang Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Steeg_G/0/1/0/all/0/1&quot;&gt;Greg Ver Steeg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goyal_P/0/1/0/all/0/1&quot;&gt;Palash Goyal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Galstyan_A/0/1/0/all/0/1&quot;&gt;Aram Galstyan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.06822">
<title>DNN or $k$-NN: That is the Generalize vs. Memorize Question. (arXiv:1805.06822v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.06822</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper studies the relationship between the classification performed by
deep neural networks and the $k$-NN decision at the embedding space of these
networks. This simple important connection shown here provides a better
understanding of the relationship between the ability of neural networks to
generalize and their tendency to memorize the training data, which are
traditionally considered to be contradicting to each other and here shown to be
compatible and complementary. Our results support the conjecture that deep
neural networks approach Bayes optimal error rates.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cohen_G/0/1/0/all/0/1&quot;&gt;Gilad Cohen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sapiro_G/0/1/0/all/0/1&quot;&gt;Guillermo Sapiro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Giryes_R/0/1/0/all/0/1&quot;&gt;Raja Giryes&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07010">
<title>Learning Permutations with Sinkhorn Policy Gradient. (arXiv:1805.07010v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.07010</link>
<description rdf:parseType="Literal">&lt;p&gt;Many problems at the intersection of combinatorics and computer science
require solving for a permutation that optimally matches, ranks, or sorts some
data. These problems usually have a task-specific, often non-differentiable
objective function that data-driven algorithms can use as a learning signal. In
this paper, we propose the Sinkhorn Policy Gradient (SPG) algorithm for
learning policies on permutation matrices. The actor-critic neural network
architecture we introduce for SPG uniquely decouples representation learning of
the state space from the highly-structured action space of permutations with a
temperature-controlled Sinkhorn layer. The Sinkhorn layer produces continuous
relaxations of permutation matrices so that the actor-critic architecture can
be trained end-to-end. Our empirical results show that agents trained with SPG
can perform competitively on sorting, the Euclidean TSP, and matching tasks. We
also observe that SPG is significantly more data efficient at the matching task
than the baseline methods, which indicates that SPG is conducive to learning
representations that are useful for reasoning about permutations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Emami_P/0/1/0/all/0/1&quot;&gt;Patrick Emami&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ranka_S/0/1/0/all/0/1&quot;&gt;Sanjay Ranka&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07072">
<title>Optimizing for Generalization in Machine Learning with Cross-Validation Gradients. (arXiv:1805.07072v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.07072</link>
<description rdf:parseType="Literal">&lt;p&gt;Cross-validation is the workhorse of modern applied statistics and machine
learning, as it provides a principled framework for selecting the model that
maximizes generalization performance. In this paper, we show that the
cross-validation risk is differentiable with respect to the hyperparameters and
training data for many common machine learning algorithms, including logistic
regression, elastic-net regression, and support vector machines. Leveraging
this property of differentiability, we propose a cross-validation gradient
method (CVGM) for hyperparameter optimization. Our method enables efficient
optimization in high-dimensional hyperparameter spaces of the cross-validation
risk, the best surrogate of the true generalization ability of our learning
algorithm.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Barratt_S/0/1/0/all/0/1&quot;&gt;Shane Barratt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sharma_R/0/1/0/all/0/1&quot;&gt;Rishi Sharma&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07091">
<title>Tropical Geometry of Deep Neural Networks. (arXiv:1805.07091v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.07091</link>
<description rdf:parseType="Literal">&lt;p&gt;We establish, for the first time, connections between feedforward neural
networks with ReLU activation and tropical geometry --- we show that the family
of such neural networks is equivalent to the family of tropical rational maps.
Among other things, we deduce that feedforward ReLU neural networks with one
hidden layer can be characterized by zonotopes, which serve as building blocks
for deeper networks; we relate decision boundaries of such neural networks to
tropical hypersurfaces, a major object of study in tropical geometry; and we
prove that linear regions of such neural networks correspond to vertices of
polytopes associated with tropical rational functions. An insight from our
tropical formulation is that a deeper network is exponentially more expressive
than a shallow network.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1&quot;&gt;Liwen Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Naitzat_G/0/1/0/all/0/1&quot;&gt;Gregory Naitzat&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lim_L/0/1/0/all/0/1&quot;&gt;Lek-Heng Lim&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07123">
<title>Tree Edit Distance Learning via Adaptive Symbol Embeddings: Supplementary Materials and Results. (arXiv:1805.07123v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.07123</link>
<description rdf:parseType="Literal">&lt;p&gt;Metric learning has the aim to improve classification accuracy by learning a
distance measure which brings data points from the same class closer together
and pushes data points from different classes further apart. Recent research
has demonstrated that metric learning approaches can also be applied to trees,
such as molecular structures, abstract syntax trees of computer programs, or
syntax trees of natural language, by learning the cost function of an edit
distance, i.e. the costs of replacing, deleting, or inserting nodes in a tree.
However, learning such costs directly may yield an edit distance which violates
metric axioms, is challenging to interpret, and may not generalize well. In
this contribution, we propose a novel metric learning approach for trees which
learns an edit distance indirectly by embedding the tree nodes as vectors, such
that the Euclidean distance between those vectors supports class
discrimination. We learn such embeddings by reducing the distance to
prototypical trees from the same class and increasing the distance to
prototypical trees from different classes. In our experiments, we show that our
proposed metric learning approach improves upon the state-of-the-art in metric
learning for trees on six benchmark data sets, ranging from computer science
over biomedical data to a natural-language processing data set containing over
300,000 nodes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Paassen_B/0/1/0/all/0/1&quot;&gt;Benjamin Paa&amp;#xdf;en&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07137">
<title>Knowledge Discovery from Layered Neural Networks based on Non-negative Task Decomposition. (arXiv:1805.07137v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.07137</link>
<description rdf:parseType="Literal">&lt;p&gt;Interpretability has become an important issue in the machine learning field,
along with the success of layered neural networks in various practical tasks.
Since a trained layered neural network consists of a complex nonlinear
relationship between large number of parameters, we failed to understand how
they could achieve input-output mappings with a given data set. In this paper,
we propose the non-negative task decomposition method, which applies
non-negative matrix factorization to a trained layered neural network. This
enables us to decompose the inference mechanism of a trained layered neural
network into multiple principal tasks of input-output mapping, and reveal the
roles of hidden units in terms of their contribution to each principal task.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Watanabe_C/0/1/0/all/0/1&quot;&gt;Chihiro Watanabe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hiramatsu_K/0/1/0/all/0/1&quot;&gt;Kaoru Hiramatsu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kashino_K/0/1/0/all/0/1&quot;&gt;Kunio Kashino&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07159">
<title>Low-Cost Recurrent Neural Network Expected Performance Evaluation. (arXiv:1805.07159v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.07159</link>
<description rdf:parseType="Literal">&lt;p&gt;Recurrent neural networks are strong dynamic systems, but they are very
sensitive to their hyper-parameter configuration. Moreover, training properly a
recurrent neural network is a tough task, therefore selecting an appropriate
configuration is critical. There have been proposed varied strategies to tackle
this issue, however most of them are still impractical because of the
time/resources needed. In this study, we propose a low computational cost model
to evaluate the expected performance of a given architecture based on the
distribution of the error of random samples. We validate empirically our
proposal using three use case.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Camero_A/0/1/0/all/0/1&quot;&gt;Andr&amp;#xe9;s Camero&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Toutouh_J/0/1/0/all/0/1&quot;&gt;Jamal Toutouh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alba_E/0/1/0/all/0/1&quot;&gt;Enrique Alba&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07226">
<title>Sequential Neural Likelihood: Fast Likelihood-free Inference with Autoregressive Flows. (arXiv:1805.07226v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.07226</link>
<description rdf:parseType="Literal">&lt;p&gt;We present Sequential Neural Likelihood (SNL), a new method for Bayesian
inference in simulator models, where the likelihood is intractable but
simulating data from the model is possible. SNL trains an autoregressive flow
on simulated data in order to learn a model of the likelihood in the region of
high posterior density. A sequential training procedure guides simulations and
reduces simulation cost by orders of magnitude. We show that SNL is more
robust, more accurate and requires less tuning than related state-of-the-art
methods which target the posterior, and discuss diagnostics for assessing
calibration, convergence and goodness-of-fit.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Papamakarios_G/0/1/0/all/0/1&quot;&gt;George Papamakarios&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sterratt_D/0/1/0/all/0/1&quot;&gt;David C. Sterratt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Murray_I/0/1/0/all/0/1&quot;&gt;Iain Murray&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07242">
<title>Siamese Capsule Networks. (arXiv:1805.07242v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.07242</link>
<description rdf:parseType="Literal">&lt;p&gt;Capsule Networks have shown encouraging results on \textit{defacto} benchmark
computer vision datasets such as MNIST, CIFAR and smallNORB. Although, they are
yet to be tested on tasks where (1) the entities detected inherently have more
complex internal representations and (2) there are very few instances per class
to learn from and (3) where point-wise classification is not suitable. Hence,
this paper carries out experiments on face verification in both controlled and
uncontrolled settings that together address these points. In doing so we
introduce \textit{Siamese Capsule Networks}, a new variant that can be used for
pairwise learning tasks. The model is trained using contrastive loss with
$\ell_2$-normalized capsule encoded pose features. We find that \textit{Siamese
Capsule Networks} perform well against strong baselines on both pairwise
learning datasets, yielding best results in the few-shot learning setting where
image pairs in the test set contain unseen subjects.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Neill_J/0/1/0/all/0/1&quot;&gt;James O&amp;#x27; Neill&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07252">
<title>Learning and Inference Movement with Deep Generative Model. (arXiv:1805.07252v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.07252</link>
<description rdf:parseType="Literal">&lt;p&gt;Learning and inference movement is a very challenging problem due to its high
dimensionality and dependency to varied environments or tasks. In this paper,
we propose an effective probabilistic method for learning and inference of
basic movements. The motion planning problem is formulated as learning on a
directed graphic model and deep generative model is used to perform learning
and inference from demonstrations. An important characteristic of this method
is that it flexibly incorporates the task descriptors and context information
for long-term planning and it can be combined with dynamic systems for robot
control. The experimental validations on robotic approaching path planning
tasks show the advantages over the base methods with limited training data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jing_M/0/1/0/all/0/1&quot;&gt;Mingxuan Jing&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1&quot;&gt;Xiaojian Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_F/0/1/0/all/0/1&quot;&gt;Fuchun Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1&quot;&gt;Huaping Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07297">
<title>General solutions for nonlinear differential equations: a deep reinforcement learning approach. (arXiv:1805.07297v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.07297</link>
<description rdf:parseType="Literal">&lt;p&gt;Physicists use differential equations to describe the physical dynamical
world, and the solutions of these equations constitute our understanding of the
world. During the hundreds of years, scientists developed several ways to solve
these equations, i.e., the analytical solutions and the numerical solutions.
However, for some complex equations, there may be no analytical solutions, and
the numerical solutions may encounter the curse of the extreme computational
cost if the accuracy is the first consideration. Solving equations is a
high-level human intelligence work and a crucial step towards general
artificial intelligence (AI), where deep reinforcement learning (DRL) may
contribute. This work makes the first attempt of applying (DRL) to solve
nonlinear differential equations both in discretized and continuous format with
the governing equations (physical laws) embedded in the DRL network, including
ordinary differential equations (ODEs) and partial differential equations
(PDEs). The DRL network consists of an actor that outputs solution
approximations policy and a critic that outputs the critic of the actor&apos;s
output solution. Deterministic policy network is employed as the actor, and
governing equations are embedded in the critic. The effectiveness of the DRL
solver in Schr\&quot;odinger equation, Navier-Stocks, Van der Pol equation, Burgers&apos;
equation and the equation of motion are discussed.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wei_S/0/1/0/all/0/1&quot;&gt;Shiyin Wei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jin_X/0/1/0/all/0/1&quot;&gt;Xiaowei Jin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1&quot;&gt;Hui Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07324">
<title>GANE: A Generative Adversarial Network Embedding. (arXiv:1805.07324v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.07324</link>
<description rdf:parseType="Literal">&lt;p&gt;Network embedding has become a hot research topic recently which can provide
low-dimensional feature representations for many machine learning applications.
Current work focuses on either (1) whether the embedding is designed as an
unsupervised learning task by explicitly preserving the structural connectivity
in the network, or (2) whether the embedding is a by-product during the
supervised learning of a specific discriminative task in a deep neural network.
In this paper, we focus on bridging the gap of the two lines of the research.
We propose to adapt the Generative Adversarial model to perform network
embedding, in which the generator is trying to generate vertex pairs, while the
discriminator tries to distinguish the generated vertex pairs from real
connections (edges) in the network. Wasserstein-1 distance is adopted to train
the generator to gain better stability. We develop three variations of models,
including GANE which applies cosine similarity, GANE-O1 which preserves the
first-order proximity, and GANE-O2 which tries to preserves the second-order
proximity of the network in the low-dimensional embedded vector space. We later
prove that GANE-O2 has the same objective function as GANE-O1 when negative
sampling is applied to simplify the training process in GANE-O2. Experiments
with real-world network datasets demonstrate that our models constantly
outperform state-of-the-art solutions with significant improvements on
precision in link prediction, as well as on visualizations and accuracy in
clustering tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hong_H/0/1/0/all/0/1&quot;&gt;Huiting Hong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xin Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1&quot;&gt;Mingzhong Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheung_W/0/1/0/all/0/1&quot;&gt;William K. Cheung&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07337">
<title>Reconstruction of training samples from loss functions. (arXiv:1805.07337v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.07337</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents a new mathematical framework to analyze the loss
functions of deep neural networks with ReLU functions. Furthermore, as as
application of this theory, we prove that the loss functions can reconstruct
the inputs of the training samples up to scalar multiplication (as vectors) and
can provide the number of layers and nodes of the deep neural network. Namely,
if we have all input and output of a loss function (or equivalently all
possible learning process), for all input of each training sample $x_i \in
\mathbb{R}^n$, we can obtain vectors $x&apos;_i\in \mathbb{R}^n$ satisfying
$x_i=c_ix&apos;_i$ for some $c_i \neq 0$. To prove theorem, we introduce the notion
of virtual polynomials, which are polynomials written as the output of a node
in a deep neural network. Using virtual polynomials, we find an algebraic
structure for the loss surfaces, called semi-algebraic sets. We analyze these
loss surfaces from the algebro-geometric point of view. Factorization of
polynomials is one of the most standard ideas in algebra. Hence, we express the
factorization of the virtual polynomials in terms of their active paths. This
framework can be applied to the leakage problem in the training of deep neural
networks. The main theorem in this paper indicates that there are many risks
associated with the training of deep neural networks. For example, if we have N
(the dimension of weight space) + 1 nonsmooth points on the loss surface, which
are sufficiently close to each other, we can obtain the input of training
sample up to scalar multiplication. We also point out that the structures of
the loss surfaces depend on the shape of the deep neural network and not on the
training samples.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sannai_A/0/1/0/all/0/1&quot;&gt;Akiyoshi Sannai&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1705.00850">
<title>Random active path model of deep neural networks with diluted binary synapses. (arXiv:1705.00850v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1705.00850</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep learning has become a powerful and popular tool for a variety of machine
learning tasks. However, it is challenging to understand the mechanism of deep
learning from a theoretical perspective. In this work, we propose a random
active path model to study collective properties of deep neural networks with
binary synapses, under the removal perturbation of connections between layers.
In the model, the path from input to output is randomly activated, and the
corresponding input unit constrains the weights along the path into the form of
a $p$-weight interaction glass model. A critical value of the perturbation is
observed to separate a spin glass regime from a paramagnetic regime, with the
transition being of the first order. The paramagnetic phase is conjectured to
have a poor generalization performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1&quot;&gt;Haiping Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goudarzi_A/0/1/0/all/0/1&quot;&gt;Alireza Goudarzi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04302">
<title>Evaluating Compositionality in Sentence Embeddings. (arXiv:1802.04302v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1802.04302</link>
<description rdf:parseType="Literal">&lt;p&gt;An important challenge for human-like AI is compositional semantics. Recent
research has attempted to address this by using deep neural networks to learn
vector space embeddings of sentences, which then serve as input to other tasks.
We present a new dataset for one such task, `natural language inference&apos; (NLI),
that cannot be solved using only word-level knowledge and requires some
compositionality. We find that the performance of state of the art sentence
embeddings (InferSent; Conneau et al., 2017) on our new dataset is poor. We
analyze the decision rules learned by InferSent and find that they are
consistent with simple heuristics that are ecologically valid in its training
dataset. Further, we find that augmenting training with our dataset improves
test performance on our dataset without loss of performance on the original
training dataset. This highlights the importance of structured datasets in
better understanding and improving AI systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dasgupta_I/0/1/0/all/0/1&quot;&gt;Ishita Dasgupta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_D/0/1/0/all/0/1&quot;&gt;Demi Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stuhlmuller_A/0/1/0/all/0/1&quot;&gt;Andreas Stuhlm&amp;#xfc;ller&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gershman_S/0/1/0/all/0/1&quot;&gt;Samuel J. Gershman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goodman_N/0/1/0/all/0/1&quot;&gt;Noah D. Goodman&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.04659">
<title>Asynch-SGBDT: Asynchronous Parallel Stochastic Gradient Boosting Decision Tree based on Parameters Server. (arXiv:1804.04659v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1804.04659</link>
<description rdf:parseType="Literal">&lt;p&gt;Gradient Boosting Decision Tree, i.e. GBDT, becomes one of the most important
machine learning algorithms. However, the training process of GBDT needs a lot
of computational resources and time even using fork-join parallel method and
sampling technology. In order to accelerate the training process of GBDT,
asynchronous parallel stochastic gradient boosting decision tree, abbr.
asynch-SGBDT is proposed in this paper. Via changing the view of sampling, we
adapt the numerical optimization process of traditional GBDT training process
into stochastic optimization process and use asynchronous parallel stochastic
gradient descent to accelerate the GBDT training process. Asynch-SGBDT provides
good compatibility with Parameters Server. Meanwhile, the theoretical analysis
of asynch-SGBDT is provided by us in this paper. Experimental results show that
GBDT training process could be accelerated by asynch-SGBDT. Our asynchronous
parallel strategy achieves an almost linear speedup, especially for
high-dimensional sparse datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Daning_C/0/1/0/all/0/1&quot;&gt;Cheng Daning&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fen_X/0/1/0/all/0/1&quot;&gt;Xia Fen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shigang_L/0/1/0/all/0/1&quot;&gt;Li Shigang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yunquan_Z/0/1/0/all/0/1&quot;&gt;Zhang Yunquan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.09060">
<title>An Information-Theoretic View for Deep Learning. (arXiv:1804.09060v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1804.09060</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep learning has transformed computer vision, natural language processing,
and speech recognition. However, two critical questions remain obscure: (1) why
do deep neural networks generalize better than shallow networks; and (2) does
it always hold that a deeper network leads to better performance? Specifically,
letting $L$ be the number of convolutional and pooling layers in a deep neural
network, and $n$ be the size of the training sample, we derive the upper bound
on the expected generalization error for this network, i.e.,
&lt;/p&gt;
&lt;p&gt;\begin{eqnarray*}
&lt;/p&gt;
&lt;p&gt;\mathbb{E}[R(W)-R_S(W)] \leq
\exp{\left(-\frac{L}{2}\log{\frac{1}{\eta}}\right)}\sqrt{\frac{2\sigma^2}{n}I(S,W)
}
&lt;/p&gt;
&lt;p&gt;\end{eqnarray*} where $\sigma &amp;gt;0$ is a constant depending on the loss
function, $0&amp;lt;\eta&amp;lt;1$ is a constant depending on the information loss for each
convolutional or pooling layer, and $I(S, W)$ is the mutual information between
the training sample $S$ and the output hypothesis $W$. This upper bound shows
that as the number of convolutional and pooling layers $L$ increases in the
network, the expected generalization error will decrease exponentially to zero.
Layers with strict information loss, such as the convolutional layers, reduce
the generalization error for the whole network; this answers the first
question. However, algorithms with zero expected generalization error does not
imply a small test error or $\mathbb{E}[R(W)]$. This is because
$\mathbb{E}[R_S(W)]$ is large when the information for fitting the data is lost
as the number of layers increases. This suggests that the claim &quot;the deeper the
better&quot; is conditioned on a small training error or $\mathbb{E}[R_S(W)]$.
Finally, we show that deep learning algorithms satisfy a weak notion of
stability and the sample complexity of deep learning algorithms will decrease
as L increases.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Jingwei Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Liu_T/0/1/0/all/0/1&quot;&gt;Tongliang Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tao_D/0/1/0/all/0/1&quot;&gt;Dacheng Tao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.03605">
<title>Combinets: Learning New Models via Recombination. (arXiv:1802.03605v2 [cs.LG] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1802.03605</link>
<description rdf:parseType="Literal">&lt;p&gt;Modern machine learning methods struggle with problems with small amounts of
training data. One solution to is to reuse existing data through transfer
methods such as one-shot or transfer learning. However these approaches tend to
require an explicit hand-authored or learned definition of how reuse can occur.
We present a new representation called conceptual expansions that serves as a
general representation for reuse from existing machine-learned knowledge. We
evaluate our approach by building conceptual expansions for image classifiers
and Generative Adversarial Networks for new classes with as few as ten samples.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guzdial_M/0/1/0/all/0/1&quot;&gt;Matthew Guzdial&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Riedl_M/0/1/0/all/0/1&quot;&gt;Mark O. Riedl&lt;/a&gt;</dc:creator>
</item></rdf:RDF>