<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Good papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Good Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-09-09T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.02393"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.02444"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.02755"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.08878"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11703"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.00193"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.02145"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.02232"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.02306"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.02394"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.02441"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.02494"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.02591"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1411.5878"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.08588"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07476"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09655"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09657"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.10729"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.04359"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.08079"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.00263"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.02077"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.02112"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.02130"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.02131"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.02209"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.02270"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.02352"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.02383"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.03605"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.08118"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.08685"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08462"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10341"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11770"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.09186"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.06148"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.08316"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.01829"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1809.02393">
<title>Improving Neural Question Generation using Answer Separation. (arXiv:1809.02393v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1809.02393</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural question generation (NQG) is the task of generating a question from a
given passage with deep neural networks. Previous NQG models suffer from a
problem that a significant proportion of the generated questions include words
in the question target, resulting in the generation of unintended questions. In
this paper, we propose answer-separated seq2seq, which better utilizes the
information from both the passage and the target answer. By replacing the
target answer in the original passage with a special token, our model learns to
identify which interrogative word should be used. We also propose a new module
termed keyword-net, which helps the model better capture the key information in
the target answer and generate an appropriate question. Experimental results
demonstrate that our answer separation method significantly reduces the number
of improper questions which include answers. Consequently, our model
significantly outperforms previous state-of-the-art NQG models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1&quot;&gt;Yanghoon Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1&quot;&gt;Hwanhee Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shin_J/0/1/0/all/0/1&quot;&gt;Joongbo Shin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jung_K/0/1/0/all/0/1&quot;&gt;Kyomin Jung&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.02444">
<title>Metamorphic Relation Based Adversarial Attacks on Differentiable Neural Computer. (arXiv:1809.02444v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1809.02444</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep neural networks (DNN), while becoming the driving force of many novel
technology and achieving tremendous success in many cutting-edge applications,
are still vulnerable to adversarial attacks. Differentiable neural computer
(DNC) is a novel computing machine with DNN as its central controller operating
on an external memory module for data processing. The unique architecture of
DNC contributes to its state-of-the-art performance in tasks which requires the
ability to represent variables and data structure as well as to store data over
long timescales. However, there still lacks a comprehensive study on how
adversarial examples affect DNC in terms of robustness. In this paper, we
propose metamorphic relation based adversarial techniques for a range of tasks
described in the natural processing language domain. We show that the
near-perfect performance of the DNC in bAbI logical question answering tasks
can be degraded by adversarially injected sentences. We further perform
in-depth study on the role of DNC&apos;s memory size in its robustness and analyze
the potential reason causing why DNC fails. Our study demonstrates the current
challenges and potential opportunities towards constructing more robust DNCs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chan_A/0/1/0/all/0/1&quot;&gt;Alvin Chan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_L/0/1/0/all/0/1&quot;&gt;Lei Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Juefei_Xu_F/0/1/0/all/0/1&quot;&gt;Felix Juefei-Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1&quot;&gt;Xiaofei Xie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yang Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ong_Y/0/1/0/all/0/1&quot;&gt;Yew Soon Ong&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.02755">
<title>Simple Recurrent Units for Highly Parallelizable Recurrence. (arXiv:1709.02755v5 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1709.02755</link>
<description rdf:parseType="Literal">&lt;p&gt;Common recurrent neural architectures scale poorly due to the intrinsic
difficulty in parallelizing their state computations. In this work, we propose
the Simple Recurrent Unit (SRU), a light recurrent unit that balances model
capacity and scalability. SRU is designed to provide expressive recurrence,
enable highly parallelized implementation, and comes with careful
initialization to facilitate training of deep models. We demonstrate the
effectiveness of SRU on multiple NLP tasks. SRU achieves 5--9x speed-up over
cuDNN-optimized LSTM on classification and question answering datasets, and
delivers stronger results than LSTM and convolutional models. We also obtain an
average of 0.7 BLEU improvement over the Transformer model on translation by
incorporating SRU into the architecture.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lei_T/0/1/0/all/0/1&quot;&gt;Tao Lei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yu Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1&quot;&gt;Sida I. Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dai_H/0/1/0/all/0/1&quot;&gt;Hui Dai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Artzi_Y/0/1/0/all/0/1&quot;&gt;Yoav Artzi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.08878">
<title>Generating Sentences by Editing Prototypes. (arXiv:1709.08878v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1709.08878</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a new generative model of sentences that first samples a prototype
sentence from the training corpus and then edits it into a new sentence.
Compared to traditional models that generate from scratch either left-to-right
or by first sampling a latent sentence vector, our prototype-then-edit model
improves perplexity on language modeling and generates higher quality outputs
according to human evaluation. Furthermore, the model gives rise to a latent
edit vector that captures interpretable semantics such as sentence similarity
and sentence-level analogies.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guu_K/0/1/0/all/0/1&quot;&gt;Kelvin Guu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hashimoto_T/0/1/0/all/0/1&quot;&gt;Tatsunori B. Hashimoto&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oren_Y/0/1/0/all/0/1&quot;&gt;Yonatan Oren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_P/0/1/0/all/0/1&quot;&gt;Percy Liang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11703">
<title>Biologically Motivated Algorithms for Propagating Local Target Representations. (arXiv:1805.11703v2 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1805.11703</link>
<description rdf:parseType="Literal">&lt;p&gt;Finding biologically plausible alternatives to back-propagation of errors is
a fundamentally important challenge in artificial neural network research. In
this paper, we propose a simple learning algorithm called error-driven Local
Representation Alignment (LRA-E), which has strong connections to predictive
coding, a theory that offers a mechanistic way of describing neurocomputational
machinery. In addition, we propose an improved variant of Difference Target
Propagation, another procedure that comes from the same family of algorithms as
Local Representation Alignment. We compare our learning procedures to several
other biologically-motivated algorithms, including two feedback alignment
algorithms and Equilibrium Propagation. In two benchmark datasets, we find that
both of our proposed learning algorithms yield stable performance and strong
generalization abilities in comparison to other competing back-propagation
alternatives when training deeper, highly nonlinear networks, with LRA-E
performing the best overall.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ororbia_A/0/1/0/all/0/1&quot;&gt;Alexander G. Ororbia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mali_A/0/1/0/all/0/1&quot;&gt;Ankur Mali&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.00193">
<title>Reinforced Evolutionary Neural Architecture Search. (arXiv:1808.00193v2 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1808.00193</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural architecture search (NAS) is an important yet challenging task in
network design due to its high computational consumption and low stability. To
address these two issues, we propose the Reinforced Evolutionary Neural
Architecture Search (RENAS), which is an evolutionary method with reinforced
mutation for NAS. Our method integrates reinforced mutation into an evolution
algorithm for neural architecture exploration, in which a mutation controller
to learn the effects of slight modifications and make mutation actions. The
reinforced mutation controller instructs the model population to evolve
efficiently in a suitable direction. Furthermore, as child models can inherit
parameters from their parents during evolution, our method requires very
limited computational resources. We conduct the proposed search method on
CIFAR-10 with 4 GPUs (Titan Xp) across 1.5 days and discover a powerful network
architecture. This architecture achieves a competitive result on CIFAR-10. We
further apply the explored network architecture to the mobile setting ImageNet.
The network achieves a new state-of-the-art accuracy, i.e., 75.7\% top-1
accuracy with 5.36M parameters.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yukang Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1&quot;&gt;Qian Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_C/0/1/0/all/0/1&quot;&gt;Chang Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mu_L/0/1/0/all/0/1&quot;&gt;Lisen Mu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meng_G/0/1/0/all/0/1&quot;&gt;Gaofeng Meng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;Xinggang Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.02145">
<title>GANs beyond divergence minimization. (arXiv:1809.02145v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1809.02145</link>
<description rdf:parseType="Literal">&lt;p&gt;Generative adversarial networks (GANs) can be interpreted as an adversarial
game between two players, a discriminator D and a generator G, in which D
learns to classify real from fake data and G learns to generate realistic data
by &quot;fooling&quot; D into thinking that fake data is actually real data. Currently, a
dominating view is that G actually learns by minimizing a divergence given that
the general objective function is a divergence when D is optimal. However, this
view has been challenged due to inconsistencies between theory and practice. In
this paper, we discuss of the properties associated with most loss functions
for G (e.g., saturating/non-saturating f-GAN, LSGAN, WGAN, etc.). We show that
these loss functions are not divergences and do not have the same equilibrium
as expected of divergences. This suggests that G does not need to minimize the
same objective function as D maximize, nor maximize the objective of D after
swapping real data with fake data (non-saturating GAN) but can instead use a
wide range of possible loss functions to learn to generate realistic data. We
define GANs through two separate and independent D maximization and G
minimization steps. We generalize the generator step to four new classes of
loss functions, most of which are actual divergences (while traditional G loss
functions are not). We test a wide variety of loss functions from these four
classes on a synthetic dataset and on CIFAR-10. We observe that most loss
functions converge well and provide comparable data generation quality to
non-saturating GAN, LSGAN, and WGAN-GP generator loss functions, whether we use
divergences or non-divergences. These results suggest that GANs do not conform
well to the divergence minimization theory and form a much broader range of
models than previously assumed.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jolicoeur_Martineau_A/0/1/0/all/0/1&quot;&gt;Alexia Jolicoeur-Martineau&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.02232">
<title>Automated Game Design via Conceptual Expansion. (arXiv:1809.02232v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1809.02232</link>
<description rdf:parseType="Literal">&lt;p&gt;Automated game design has remained a key challenge within the field of Game
AI. In this paper, we introduce a method for recombining existing games to
create new games through a process called conceptual expansion. Prior automated
game design approaches have relied on hand-authored or crowd-sourced knowledge,
which limits the scope and applications of such systems. Our approach instead
relies on machine learning to learn approximate representations of games. Our
approach recombines knowledge from these learned representations to create new
games via conceptual expansion. We evaluate this approach by demonstrating the
ability for the system to recreate existing games. To the best of our
knowledge, this represents the first machine learning-based automated game
design system.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guzdial_M/0/1/0/all/0/1&quot;&gt;Matthew Guzdial&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Riedl_M/0/1/0/all/0/1&quot;&gt;Mark Riedl&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.02306">
<title>Unsupervised Cross-lingual Word Embedding by Multilingual Neural Language Models. (arXiv:1809.02306v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1809.02306</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose an unsupervised method to obtain cross-lingual embeddings without
any parallel data or pre-trained word embeddings. The proposed model, which we
call multilingual neural language models, takes sentences of multiple languages
as an input. The proposed model contains bidirectional LSTMs that perform as
forward and backward language models, and these networks are shared among all
the languages. The other parameters, i.e. word embeddings and linear
transformation between hidden states and outputs, are specific to each
language. The shared LSTMs can capture the common sentence structure among all
languages. Accordingly, word embeddings of each language are mapped into a
common latent space, making it possible to measure the similarity of words
across multiple languages. We evaluate the quality of the cross-lingual word
embeddings on a word alignment task. Our experiments demonstrate that our model
can obtain cross-lingual embeddings of much higher quality than existing
unsupervised models when only a small amount of monolingual data (i.e. 50k
sentences) are available, or the domains of monolingual data are different
across languages.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wada_T/0/1/0/all/0/1&quot;&gt;Takashi Wada&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Iwata_T/0/1/0/all/0/1&quot;&gt;Tomoharu Iwata&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.02394">
<title>Deep Feature Learning of Multi-Network Topology for Node Classification. (arXiv:1809.02394v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1809.02394</link>
<description rdf:parseType="Literal">&lt;p&gt;Networks are ubiquitous structure that describes complex relationships
between different entities in the real world. As a critical component of
prediction task over nodes in networks, learning the feature representation of
nodes has become one of the most active areas recently. Network Embedding,
aiming to learn non-linear and low-dimensional feature representation based on
network topology, has been proved to be helpful on tasks of network analysis,
especially node classification. For many real-world systems, multiple types of
relations are naturally represented by multiple networks. However, existing
network embedding methods mainly focus on single network embedding and neglect
the information shared among different networks. In this paper, we propose a
novel multiple network embedding method based on semisupervised autoencoder,
named DeepMNE, which captures complex topological structures of multi-networks
and takes the correlation among multi-networks into account. We evaluate
DeepMNE on the task of node classification with two real-world datasets. The
experimental results demonstrate the superior performance of our method over
four state-of-the-art algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xue_H/0/1/0/all/0/1&quot;&gt;Hansheng Xue&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peng_J/0/1/0/all/0/1&quot;&gt;Jiajie Peng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shang_X/0/1/0/all/0/1&quot;&gt;Xuequn Shang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.02441">
<title>HC-Net: Memory-based Incremental Dual-Network System for Continual learning. (arXiv:1809.02441v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1809.02441</link>
<description rdf:parseType="Literal">&lt;p&gt;Training a neural network for a classification task typically assumes that
the data to train are given from the beginning. However, in the real world,
additional data accumulate gradually and the model requires additional training
without accessing the old training data. This usually leads to the catastrophic
forgetting problem which is inevitable for the traditional training methodology
of neural networks. In this paper, we propose a memory-based continual learning
method that is able to learn additional tasks while retaining the performance
of previously learned tasks. Composed of two complementary networks, the
Hippocampus-net (H-net) and the Cortex-net (C-net), our model estimates the
index of the corresponding task for an input sample and utilizes a particular
portion of itself with the estimated index. The C-net guarantees no degradation
in the performance of the previously learned tasks and the H-net shows high
confidence in finding the origin of the input sample
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1&quot;&gt;Jangho Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1&quot;&gt;Jeesoo Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kwak_N/0/1/0/all/0/1&quot;&gt;Nojun Kwak&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.02494">
<title>Meteorologists and Students: A resource for language grounding of geographical descriptors. (arXiv:1809.02494v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1809.02494</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a data resource which can be useful for research purposes on
language grounding tasks in the context of geographical referring expression
generation. The resource is composed of two data sets that encompass 25
different geographical descriptors and a set of associated graphical
representations, drawn as polygons on a map by two groups of human subjects:
teenage students and expert meteorologists.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ramos_Soto_A/0/1/0/all/0/1&quot;&gt;Alejandro Ramos-Soto&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Reiter_E/0/1/0/all/0/1&quot;&gt;Ehud Reiter&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deemter_K/0/1/0/all/0/1&quot;&gt;Kees van Deemter&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alonso_J/0/1/0/all/0/1&quot;&gt;Jose M. Alonso&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gatt_A/0/1/0/all/0/1&quot;&gt;Albert Gatt&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.02591">
<title>Learning Invariances for Policy Generalization. (arXiv:1809.02591v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1809.02591</link>
<description rdf:parseType="Literal">&lt;p&gt;While recent progress has spawned very powerful machine learning systems,
those agents remain extremely specialized and fail to transfer the knowledge
they gain to similar yet unseen tasks. In this paper, we study a simple
reinforcement learning problem and focus on learning policies that encode the
proper invariances for generalization to different settings. We evaluate three
potential methods for policy generalization: data augmentation, meta-learning
and adversarial training. We find our data augmentation method to be effective,
and study the potential of meta-learning and adversarial learning as
alternative task-agnostic approaches.
&lt;/p&gt;
&lt;p&gt;Keywords: reinforcement learning, generalization, data augmentation,
meta-learning, adversarial learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Combes_R/0/1/0/all/0/1&quot;&gt;Remi Tachet des Combes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bachman_P/0/1/0/all/0/1&quot;&gt;Philip Bachman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Seijen_H/0/1/0/all/0/1&quot;&gt;Harm van Seijen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1411.5878">
<title>Salient Object Detection: A Survey. (arXiv:1411.5878v5 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1411.5878</link>
<description rdf:parseType="Literal">&lt;p&gt;Detecting and segmenting salient objects in natural scenes, often referred to
as salient object detection, has attracted a lot of interest in computer
vision. While many models have been proposed and several applications have
emerged, yet a deep understanding of achievements and issues is lacking. We aim
to provide a comprehensive review of the recent progress in salient object
detection and situate this field among other closely related areas such as
generic scene segmentation, object proposal generation, and saliency for
fixation prediction. Covering 228 publications, we survey i) roots, key
concepts, and tasks, ii) core techniques and main modeling trends, and iii)
datasets and evaluation metrics in salient object detection. We also discuss
open problems such as evaluation metrics and dataset bias in model performance
and suggest future research directions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Borji_A/0/1/0/all/0/1&quot;&gt;Ali Borji&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_M/0/1/0/all/0/1&quot;&gt;Ming-Ming Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hou_Q/0/1/0/all/0/1&quot;&gt;Qibin Hou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1&quot;&gt;Huaizu Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jia Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.08588">
<title>Rank Pruning for Dominance Queries in CP-Nets. (arXiv:1712.08588v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1712.08588</link>
<description rdf:parseType="Literal">&lt;p&gt;Conditional preference networks (CP-nets) are a graphical representation of a
person&apos;s (conditional) preferences over a set of discrete variables. In this
paper, we introduce a novel method of quantifying preference for any given
outcome based on a CP-net representation of a user&apos;s preferences. We
demonstrate that these values are useful for reasoning about user preferences.
In particular, they allow us to order (any subset of) the possible outcomes in
accordance with the user&apos;s preferences. Further, these values can be used to
improve the efficiency of outcome dominance testing. That is, given a pair of
outcomes, we can determine which the user prefers more efficiently. Through
experimental results, we show that this method is more effective than existing
techniques for improving dominance testing efficiency. We show that the above
results also hold for CP-nets that express indifference between variable
values.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Laing_K/0/1/0/all/0/1&quot;&gt;Kathryn Laing&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Thwaites_P/0/1/0/all/0/1&quot;&gt;Peter Adam Thwaites&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gosling_J/0/1/0/all/0/1&quot;&gt;John Paul Gosling&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07476">
<title>Two geometric input transformation methods for fast online reinforcement learning with neural nets. (arXiv:1805.07476v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.07476</link>
<description rdf:parseType="Literal">&lt;p&gt;We apply neural nets with ReLU gates in online reinforcement learning. Our
goal is to train these networks in an incremental manner, without the
computationally expensive experience replay. By studying how individual neural
nodes behave in online training, we recognize that the global nature of ReLU
gates can cause undesirable learning interference in each node&apos;s learning
behavior. We propose reducing such interferences with two efficient input
transformation methods that are geometric in nature and match well the
geometric property of ReLU gates. The first one is tile coding, a classic
binary encoding scheme originally designed for local generalization based on
the topological structure of the input space. The second one (EmECS) is a new
method we introduce; it is based on geometric properties of convex sets and
topological embedding of the input space into the boundary of a convex set. We
discuss the behavior of the network when it operates on the transformed inputs.
We also compare it experimentally with some neural nets that do not use the
same input transformations, and with the classic algorithm of tile coding plus
a linear function approximator, and on several online reinforcement learning
tasks, we show that the neural net with tile coding or EmECS can achieve not
only faster learning but also more accurate approximations. Our results
strongly suggest that geometric input transformation of this type can be
effective for interference reduction and takes us a step closer to fully
incremental reinforcement learning with neural nets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghiassian_S/0/1/0/all/0/1&quot;&gt;Sina Ghiassian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1&quot;&gt;Huizhen Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rafiee_B/0/1/0/all/0/1&quot;&gt;Banafsheh Rafiee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sutton_R/0/1/0/all/0/1&quot;&gt;Richard S. Sutton&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09655">
<title>Global-Locally Self-Attentive Dialogue State Tracker. (arXiv:1805.09655v3 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1805.09655</link>
<description rdf:parseType="Literal">&lt;p&gt;Dialogue state tracking, which estimates user goals and requests given the
dialogue context, is an essential part of task-oriented dialogue systems. In
this paper, we propose the Global-Locally Self-Attentive Dialogue State Tracker
(GLAD), which learns representations of the user utterance and previous system
actions with global-local modules. Our model uses global modules to share
parameters between estimators for different types (called slots) of dialogue
states, and uses local modules to learn slot-specific features. We show that
this significantly improves tracking of rare states and achieves
state-of-the-art performance on the WoZ and DSTC2 state tracking tasks. GLAD
obtains 88.1% joint goal accuracy and 97.1% request accuracy on WoZ,
outperforming prior work by 3.7% and 5.5%. On DSTC2, our model obtains 74.5%
joint goal accuracy and 97.5% request accuracy, outperforming prior work by
1.1% and 1.0%.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhong_V/0/1/0/all/0/1&quot;&gt;Victor Zhong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiong_C/0/1/0/all/0/1&quot;&gt;Caiming Xiong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Socher_R/0/1/0/all/0/1&quot;&gt;Richard Socher&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09657">
<title>Learning compositionally through attentive guidance. (arXiv:1805.09657v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1805.09657</link>
<description rdf:parseType="Literal">&lt;p&gt;While neural network models have been successfully applied to domains that
require substantial generalisation skills, recent studies have implied that
they struggle when solving the task they are trained on requires inferring its
underlying compositional structure. In this paper, we introduce Attentive
Guidance, a mechanism to direct a sequence to sequence model equipped with
attention to find more compositional solutions. We test it on two tasks,
devised precisely to assess the compositional capabilities of neural models,
and we show that vanilla sequence to sequence models with attention overfit the
training distribution, while the guided versions come up with compositional
solutions that fit the training and testing distributions almost equally well.
Moreover, the learned solutions generalise even in cases where the training and
testing distributions strongly diverge. In this way, we demonstrate that
sequence to sequence models are capable of finding compositional solutions
without requiring extra components. These results helps to disentangle the
causes for the lack of systematic compositionality in neural networks, which
can in turn fuel future work.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hupkes_D/0/1/0/all/0/1&quot;&gt;Dieuwke Hupkes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1&quot;&gt;Anand Singh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Korrel_K/0/1/0/all/0/1&quot;&gt;Kris Korrel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kruszewski_G/0/1/0/all/0/1&quot;&gt;German Kruszewski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bruni_E/0/1/0/all/0/1&quot;&gt;Elia Bruni&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.10729">
<title>Illuminating Generalization in Deep Reinforcement Learning through Procedural Level Generation. (arXiv:1806.10729v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1806.10729</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep reinforcement learning (RL) has shown impressive results in a variety of
domains, learning directly from high-dimensional sensory streams. However, when
neural networks are trained in a fixed environment, such as a single level in a
video game, they will usually overfit and fail to generalize to new levels.
When RL models overfit, even slight modifications to the environment can result
in poor agent performance. In this paper, we explore how procedurally generated
levels during training increase generality. We show that for some games
procedural level generation enables generalization to new levels within the
same distribution. Additionally, it is possible to achieve better performance
with less data by manipulating the difficulty of the levels in response to the
performance of the agent. The generality of the learned behaviors is also
evaluated on a set of human-designed levels. Our results show that the ability
to generalize to human-designed levels highly depends on the design of the
level generators. We apply dimensionality reduction and clustering techniques
to visualize the generators&apos; distributions of levels and analyze to what degree
they can produce levels similar to those designed by a human.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Justesen_N/0/1/0/all/0/1&quot;&gt;Niels Justesen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Torrado_R/0/1/0/all/0/1&quot;&gt;Ruben Rodriguez Torrado&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bontrager_P/0/1/0/all/0/1&quot;&gt;Philip Bontrager&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khalifa_A/0/1/0/all/0/1&quot;&gt;Ahmed Khalifa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Togelius_J/0/1/0/all/0/1&quot;&gt;Julian Togelius&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Risi_S/0/1/0/all/0/1&quot;&gt;Sebastian Risi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.04359">
<title>Community Regularization of Visually-Grounded Dialog. (arXiv:1808.04359v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1808.04359</link>
<description rdf:parseType="Literal">&lt;p&gt;The task of conducting visually grounded dialog involves learning
goal-oriented cooperative dialog between autonomous agents who exchange
information about a scene through several rounds of questions and answers in
natural language. We posit that requiring artificial agents to adhere to the
rules of human language, while also requiring them to maximize information
exchange through dialog is an ill-posed problem. We observe that humans do not
stray from a common language because they are social creatures who live in
communities, and have to communicate with many people everyday, so it is far
easier to stick to a common language even at the cost of some efficiency loss.
Using this as inspiration, we propose and evaluate a multi-agent
community-based dialog framework where each agent interacts with, and learns
from, multiple agents, and show that this community-enforced regularization
results in more relevant and coherent dialog (as judged by human evaluators)
without sacrificing task performance (as judged by quantitative metrics).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Agarwal_A/0/1/0/all/0/1&quot;&gt;Akshat Agarwal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gurumurthy_S/0/1/0/all/0/1&quot;&gt;Swaminathan Gurumurthy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sharma_V/0/1/0/all/0/1&quot;&gt;Vasu Sharma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lewis_M/0/1/0/all/0/1&quot;&gt;Mike Lewis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sycara_K/0/1/0/all/0/1&quot;&gt;Katia Sycara&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.08079">
<title>Under the Hood: Using Diagnostic Classifiers to Investigate and Improve how Language Models Track Agreement Information. (arXiv:1808.08079v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1808.08079</link>
<description rdf:parseType="Literal">&lt;p&gt;How do neural language models keep track of number agreement between subject
and verb? We show that `diagnostic classifiers&apos;, trained to predict number from
the internal states of a language model, provide a detailed understanding of
how, when, and where this information is represented. Moreover, they give us
insight into when and where number information is corrupted in cases where the
language model ends up making agreement errors. To demonstrate the causal role
played by the representations we find, we then use agreement information to
influence the course of the LSTM during the processing of difficult sentences.
Results from such an intervention reveal a large increase in the language
model&apos;s accuracy. Together, these results show that diagnostic classifiers give
us an unrivalled detailed look into the representation of linguistic
information in neural models, and demonstrate that this knowledge can be used
to improve their performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Giulianelli_M/0/1/0/all/0/1&quot;&gt;Mario Giulianelli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Harding_J/0/1/0/all/0/1&quot;&gt;Jack Harding&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mohnert_F/0/1/0/all/0/1&quot;&gt;Florian Mohnert&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hupkes_D/0/1/0/all/0/1&quot;&gt;Dieuwke Hupkes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zuidema_W/0/1/0/all/0/1&quot;&gt;Willem Zuidema&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.00263">
<title>Stochastic Video Long-term Interpolation. (arXiv:1809.00263v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1809.00263</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we introduce a stochastic learning framework for long-term
video interpolation. While most existing interpolation models require two
reference frames with a short interval, our framework predicts a plausible
intermediate sequence between a long interval. Our model consists of two parts:
(1) a deterministic estimation to guarantee the spatial and temporal coherency
among frames, (2) a stochastic sampling process to generate dynamics from
inferred distributions. Experimental results show that our model is able to
generate sharp and clear sequences with variations. Moreover, motions in the
generated sequence are realistic and able to transfer smoothly from the
referenced start frame to the end frame.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Q/0/1/0/all/0/1&quot;&gt;Qiangeng Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1&quot;&gt;Hanwang Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1&quot;&gt;Weiyue Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Belhumeur_P/0/1/0/all/0/1&quot;&gt;Peter N. Belhumeur&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Neumann_U/0/1/0/all/0/1&quot;&gt;Ulrich Neumann&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.02077">
<title>IDSGAN: Generative Adversarial Networks for Attack Generation against Intrusion Detection. (arXiv:1809.02077v2 [cs.CR] UPDATED)</title>
<link>http://arxiv.org/abs/1809.02077</link>
<description rdf:parseType="Literal">&lt;p&gt;As an important tool in security, the intrusion detection system bears the
responsibility of the defense to network attacks performed by malicious
traffic. Nowadays, with the help of machine learning algorithms, the intrusion
detection system develops rapidly. However, the robustness of this system is
questionable when it faces the adversarial attacks. To improve the detection
system, more potential attack approaches should be researched. In this paper, a
framework of the generative adversarial networks, IDSGAN, is proposed to
generate the adversarial attacks, which can deceive and evade the intrusion
detection system. Considering that the internal structure of the detection
system is unknown to attackers, adversarial attack examples perform the
black-box attacks against the detection system. IDSGAN leverages a generator to
transform original malicious traffic into adversarial malicious traffic. A
discriminator classifies traffic examples and simulates the black-box detection
system. More significantly, we only modify part of the attacks&apos; nonfunctional
features to guarantee the validity of the intrusion. Based on the dataset
NSL-KDD, the feasibility of the model is demonstrated to attack many detection
systems with different attacks and the excellent results are achieved.
Moreover, the robustness of IDSGAN is verified by changing the amount of the
unmodified features.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_Z/0/1/0/all/0/1&quot;&gt;Zilong Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1&quot;&gt;Yong Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xue_Z/0/1/0/all/0/1&quot;&gt;Zhi Xue&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.02112">
<title>ANS: Adaptive Network Scaling for Deep Rectifier Reinforcement Learning Models. (arXiv:1809.02112v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1809.02112</link>
<description rdf:parseType="Literal">&lt;p&gt;This work provides a thorough study on how reward scaling can affect
performance of deep reinforcement learning agents. In particular, we would like
to answer the question that how does reward scaling affect non-saturating ReLU
networks in RL? This question matters because ReLU is one of the most effective
activation functions for deep learning models. We also propose an Adaptive
Network Scaling framework to find a suitable scale of the rewards during
learning for better performance. We conducted empirical studies to justify the
solution.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1&quot;&gt;Yueh-Hua Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_F/0/1/0/all/0/1&quot;&gt;Fan-Yun Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chang_Y/0/1/0/all/0/1&quot;&gt;Yen-Yu Chang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_S/0/1/0/all/0/1&quot;&gt;Should-De Lin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.02130">
<title>Deep neural network marketplace recommenders in online experiments. (arXiv:1809.02130v1 [cs.IR])</title>
<link>http://arxiv.org/abs/1809.02130</link>
<description rdf:parseType="Literal">&lt;p&gt;Recommendations are broadly used in marketplaces to match users with items
relevant to their interests and needs. To understand user intent and tailor
recommendations to their needs, we use deep learning to explore various
heterogeneous data available in marketplaces. This paper focuses on the
challenge of measuring recommender performance and summarizes the online
experiment results with several promising types of deep neural network
recommenders - hybrid item representation models combining features from user
engagement and content, sequence-based models, and multi-armed bandit models
that optimize user engagement by re-ranking proposals from multiple submodels.
The recommenders are currently running in production at the leading Norwegian
marketplace FINN.no and serves over one million visitors everyday.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Eide_S/0/1/0/all/0/1&quot;&gt;Simen Eide&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_N/0/1/0/all/0/1&quot;&gt;Ning Zhou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.02131">
<title>Five lessons from building a deep neural network recommender. (arXiv:1809.02131v1 [cs.IR])</title>
<link>http://arxiv.org/abs/1809.02131</link>
<description rdf:parseType="Literal">&lt;p&gt;Recommendation algorithms are widely adopted in marketplaces to help users
find the items they are looking for. The sparsity of the items by user matrix
and the cold-start issue in marketplaces pose challenges for the off-the-shelf
matrix factorization based recommender systems. To understand user intent and
tailor recommendations to their needs, we use deep learning to explore various
heterogeneous data available in marketplaces. This paper summarizes five
lessons we learned from experimenting with state-of-the-art deep learning
recommenders at the leading Norwegian marketplace \textit{FINN.no}. We design a
hybrid recommender system that takes the user-generated contents of a
marketplace (including text, images and meta attributes) and combines them with
user behavior data such as page views and messages to provide recommendations
for marketplace items. Among various tactics we experimented with, the
following five show the best impact: staged training instead of end-to-end
training, leveraging rich user behaviors beyond page views, using user
behaviors as noisy labels to train embeddings, using transfer learning to solve
the unbalanced data problem, and using attention mechanisms in the hybrid
model. This system is currently running with around 20\% click-through-rate in
production at \textit{FINN.no} and serves over one million visitors everyday.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Eide_S/0/1/0/all/0/1&quot;&gt;Simen Eide&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oygaard_A/0/1/0/all/0/1&quot;&gt;Audun M. &amp;#xd8;yg&amp;#xe5;rd&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_N/0/1/0/all/0/1&quot;&gt;Ning Zhou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.02209">
<title>ProdSumNet: reducing model parameters in deep neural networks via product-of-sums matrix decompositions. (arXiv:1809.02209v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1809.02209</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider a general framework for reducing the number of trainable model
parameters in deep learning networks by decomposing linear operators as a
product of sums of simpler linear operators. Recently proposed deep learning
architectures such as CNN, KFC, Dilated CNN, etc. are all subsumed in this
framework and we illustrate other types of neural network architectures within
this framework. We show that good accuracy on MNIST and Fashion MNIST can be
obtained using a relatively small number of trainable parameters. In addition,
since implementation of the convolutional layer is resource-heavy, we consider
an approach in the transform domain that obviates the need for convolutional
layers. One of the advantages of this general framework over prior approaches
is that the number of trainable parameters is not fixed and can be varied
arbitrarily. In particular, we illustrate the tradeoff of varying the number of
trainable variables and the corresponding error rate. As an example, by using
this decomposition on a reference CNN architecture for MNIST with over 3x10^6
trainable parameters, we are able to obtain an accuracy of 98.44% using only
3554 trainable parameters.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1&quot;&gt;Chai Wah Wu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.02270">
<title>Learning Embeddings of Directed Networks with Text-Associated Nodes---with Applications in Software Package Dependency Networks. (arXiv:1809.02270v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1809.02270</link>
<description rdf:parseType="Literal">&lt;p&gt;A network embedding consists of a vector representation for each node in the
network. Network embeddings have shown their usefulness in node classification
and visualization in many real-world application domains, such as social
networks and web networks. While directed networks with text associated with
each node, such as citation networks and software package dependency networks,
are commonplace, to the best of our knowledge, their embeddings have not been
specifically studied. In this paper, we create PCTADW-1 and PCTADW-2, two
algorithms based on NNs that learn embeddings of directed networks with text
associated with each node. We create two new labeled directed networks with
text-associated node: The package dependency networks in two popular GNU/Linux
distributions, Debian and Fedora. We experimentally demonstrate that the
embeddings produced by our NNs resulted in node classification with better
quality than those of various baselines on these two networks. We observe that
there exist systematic presence of analogies (similar to those in word
embeddings) in the network embeddings of software package dependency networks.
To the best of our knowledge, this is the first time that such a systematic
presence of analogies is observed in network and document embeddings. This may
potentially open up a new venue for better understanding networks and documents
algorithmically using their embeddings as well as for better human
understanding of network and document embeddings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhong_S/0/1/0/all/0/1&quot;&gt;Shudan Zhong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1&quot;&gt;Hong Xu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.02352">
<title>Multi-Target Prediction: A Unifying View on Problems and Methods. (arXiv:1809.02352v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1809.02352</link>
<description rdf:parseType="Literal">&lt;p&gt;Multi-target prediction (MTP) is concerned with the simultaneous prediction
of multiple target variables of diverse type. Due to its enormous application
potential, it has developed into an active and rapidly expanding research field
that combines several subfields of machine learning, including multivariate
regression, multi-label classification, multi-task learning, dyadic prediction,
zero-shot learning, network inference, and matrix completion. In this paper, we
present a unifying view on MTP problems and methods. First, we formally discuss
commonalities and differences between existing MTP problems. To this end, we
introduce a general framework that covers the above subfields as special cases.
As a second contribution, we provide a structured overview of MTP methods. This
is accomplished by identifying a number of key properties, which distinguish
such methods and determine their suitability for different types of problems.
Finally, we also discuss a few challenges for future research.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Waegeman_W/0/1/0/all/0/1&quot;&gt;Willem Waegeman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Dembczynski_K/0/1/0/all/0/1&quot;&gt;Krzysztof Dembczynski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Huellermeier_E/0/1/0/all/0/1&quot;&gt;Eyke Huellermeier&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.02383">
<title>A simple probabilistic deep generative model for learning generalizable disentangled representations from grouped data. (arXiv:1809.02383v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1809.02383</link>
<description rdf:parseType="Literal">&lt;p&gt;The disentangling problem is to discover multiple complex factors of
variations hidden in data. One recent approach is to take a dataset with
grouping structure and separately estimate a factor common within a group
(content) and a factor specific to each group member (transformation). Notably,
this approach can learn to represent a continuous space of contents, which
allows for generalization to data with unseen contents. In this study, we aim
at cultivating this approach within probabilistic deep generative models.
Motivated by technical complication in existing group-based methods, we propose
a simpler probabilistic method, called group-contrastive variational
autoencoders. Despite its simplicity, our approach achieves reasonable
disentanglement with generalizability for three grouped datasets of 3D object
images. In comparison with a previous model, although conventional qualitative
evaluation shows little difference, our qualitative evaluation using few-shot
classification exhibits superior performances for some datasets. We analyze the
content representations from different methods and discuss their
transformation-dependency and potential performance impacts.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hosoya_H/0/1/0/all/0/1&quot;&gt;Haruo Hosoya&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.03605">
<title>Combinets: Creativity via Recombination of Neural Networks. (arXiv:1802.03605v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1802.03605</link>
<description rdf:parseType="Literal">&lt;p&gt;One of the defining characteristics of human creativity is the ability to
make conceptual leaps, creating something surprising from typical knowledge. In
comparison, deep neural networks often struggle to handle cases outside of
their training data, which is especially problematic for problems with limited
training data. Approaches exist to transfer knowledge from problems with
sufficient data to those with insufficient data, but they tend to require
additional training or a domain-specific method of transfer. We present a new
approach, conceptual expansion, that serves as a general representation for
reusing existing trained models to derive new models without backpropagation.
We evaluate our approach on few-shot variations of two tasks: image
classification and image generation, and outperform standard transfer learning
approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guzdial_M/0/1/0/all/0/1&quot;&gt;Matthew Guzdial&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Riedl_M/0/1/0/all/0/1&quot;&gt;Mark O. Riedl&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.08118">
<title>Seglearn: A Python Package for Learning Sequences and Time Series. (arXiv:1803.08118v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1803.08118</link>
<description rdf:parseType="Literal">&lt;p&gt;Seglearn is an open-source python package for machine learning time series or
sequences using a sliding window segmentation approach. The implementation
provides a flexible pipeline for tackling classification, regression, and
forecasting problems with multivariate sequence and contextual data. This
package is compatible with scikit-learn and is listed under scikit-learn
Related Projects. The package depends on numpy, scipy, and scikit-learn.
Seglearn is distributed under the BSD 3-Clause License. Documentation includes
a detailed API description, user guide, and examples. Unit tests provide a high
degree of code coverage.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Burns_D/0/1/0/all/0/1&quot;&gt;David M. Burns&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Whyne_C/0/1/0/all/0/1&quot;&gt;Cari M. Whyne&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.08685">
<title>Crawling in Rogue&apos;s dungeons with (partitioned) A3C. (arXiv:1804.08685v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1804.08685</link>
<description rdf:parseType="Literal">&lt;p&gt;Rogue is a famous dungeon-crawling video-game of the 80ies, the ancestor of
its gender. Rogue-like games are known for the necessity to explore partially
observable and always different randomly-generated labyrinths, preventing any
form of level replay. As such, they serve as a very natural and challenging
task for reinforcement learning, requiring the acquisition of complex,
non-reactive behaviors involving memory and planning. In this article we show
how, exploiting a version of A3C partitioned on different situations, the agent
is able to reach the stairs and descend to the next level in 98% of cases.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Asperti_A/0/1/0/all/0/1&quot;&gt;Andrea Asperti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cortesi_D/0/1/0/all/0/1&quot;&gt;Daniele Cortesi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sovrano_F/0/1/0/all/0/1&quot;&gt;Francesco Sovrano&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08462">
<title>Meta-Learning with Hessian-Free Approach in Deep Neural Nets Training. (arXiv:1805.08462v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.08462</link>
<description rdf:parseType="Literal">&lt;p&gt;Meta-learning is a promising method to achieve efficient training method
towards deep neural net and has been attracting increases interests in recent
years. But most of the current methods are still not capable to train complex
neuron net model with long-time training process. In this paper, a novel
second-order meta-optimizer, named Meta-learning with Hessian-Free(MLHF)
approach, is proposed based on the Hessian-Free approach. Two recurrent neural
networks are established to generate the damping and the precondition matrix of
this Hessian-Free framework. A series of techniques to meta-train the MLHF
towards stable and reinforce the meta-training of this optimizer, including the
gradient calculation of $H$. Numerical experiments on deep convolution neural
nets, including CUDA-convnet and ResNet18(v2), with datasets of CIFAR10 and
ILSVRC2012, indicate that the MLHF shows good and continuous training
performance during the whole long-time training process, i.e., both the
rapid-decreasing early stage and the steadily-deceasing later stage, and so is
a promising meta-learning framework towards elevating the training efficiency
in real-world deep neural nets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1&quot;&gt;Boyu Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_W/0/1/0/all/0/1&quot;&gt;Wenlian Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fokoue_E/0/1/0/all/0/1&quot;&gt;Ernest Fokoue&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.10341">
<title>An end-to-end Differentially Private Latent Dirichlet Allocation Using a Spectral Algorithm. (arXiv:1805.10341v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1805.10341</link>
<description rdf:parseType="Literal">&lt;p&gt;We plan to make major modifications to this paper including rewriting the
entire text, rewriting the proofs and adding experiments. Given that the paper
will be completely different and the first author of this paper is no longer
interested in working on this paper, we decided to take this paper down
unfortunately.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Esmaeili_S/0/1/0/all/0/1&quot;&gt;Seyed A. Esmaeili&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Huang_F/0/1/0/all/0/1&quot;&gt;Furong Huang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11770">
<title>AutoZOOM: Autoencoder-based Zeroth Order Optimization Method for Attacking Black-box Neural Networks. (arXiv:1805.11770v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1805.11770</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent studies have shown that adversarial examples in state-of-the-art image
classifiers trained by deep neural networks (DNN) can be easily generated when
the target model is transparent to an attacker, known as the white-box setting.
However, when attacking a deployed machine learning service, one can only
acquire the input-output correspondences of the target model; this is the
so-called black-box attack setting. The major drawback of existing black-box
attacks is the need for excessive model queries, which may give a false sense
of model robustness due to inefficient query designs. To bridge this gap, we
propose a generic framework for query-efficient black-box attacks. Our
framework, AutoZOOM, which is short for Autoencoder-based Zeroth Order
Optimization Method, has two novel building blocks towards efficient black-box
attacks: (i) an adaptive random gradient estimation strategy to balance query
counts and distortion, and (ii) an autoencoder that is either trained offline
with unlabeled data or a bilinear resizing operation for attack acceleration.
Experimental results suggest that, by applying AutoZOOM to a state-of-the-art
black-box attack (ZOO), a significant reduction in model queries can be
achieved without sacrificing the attack success rate and the visual quality of
the resulting adversarial examples. In particular, when compared to the
standard ZOO method, AutoZOOM can consistently reduce the mean query counts in
finding successful adversarial examples (or reaching the same distortion level)
by at least 93% on MNIST, CIFAR-10 and ImageNet datasets, leading to novel
insights on adversarial robustness.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tu_C/0/1/0/all/0/1&quot;&gt;Chun-Chen Tu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ting_P/0/1/0/all/0/1&quot;&gt;Paishun Ting&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_P/0/1/0/all/0/1&quot;&gt;Pin-Yu Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1&quot;&gt;Sijia Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1&quot;&gt;Huan Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yi_J/0/1/0/all/0/1&quot;&gt;Jinfeng Yi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hsieh_C/0/1/0/all/0/1&quot;&gt;Cho-Jui Hsieh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_S/0/1/0/all/0/1&quot;&gt;Shin-Ming Cheng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.09186">
<title>Detection based Defense against Adversarial Examples from the Steganalysis Point ot View. (arXiv:1806.09186v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1806.09186</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep Neural Networks (DNNs) have recently led to significant improvements in
many fields. However, DNNs are vulnerable to adversarial examples which are
samples with imperceptible perturbations while dramatically misleading the
DNNs. Moreover, adversarial examples can be used to perform an attack on
various kinds of DNN based systems, even if the adversary has no access to the
underlying model. Many defense methods have been proposed, such as obfuscating
gradients of the networks or detecting adversarial examples. However it is
proved out that these defense methods are not effective or cannot resist
secondary adversarial attacks. In this paper, we point out that steganalysis
can be applied to adversarial examples detection, and propose a method to
enhance steganalysis features by estimating the probability of modifications
caused by adversarial attacks. Experimental results show that the proposed
method can accurately detect adversarial examples. Moreover, secondary
adversarial attacks cannot be directly performed to our method because our
method is not based on a neural network but based on high-dimensional
artificial features and FLD (Fisher Linear Discriminant) ensemble.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Jiayang Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1&quot;&gt;Weiming Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yiwei Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hou_D/0/1/0/all/0/1&quot;&gt;Dongdong Hou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yujia Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zha_H/0/1/0/all/0/1&quot;&gt;Hongyue Zha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_N/0/1/0/all/0/1&quot;&gt;Nenghai Yu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.06148">
<title>Generalized Bregman and Jensen divergences which include some f-divergences. (arXiv:1808.06148v3 [math.ST] UPDATED)</title>
<link>http://arxiv.org/abs/1808.06148</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we introduce new classes of divergences by extending the
definitions of the Bregman divergence and the skew Jensen divergence. These new
divergence classes (g-Bregman divergence and skew g-Jensen divergence) satisfy
some properties similar to the Bregman or skew Jensen divergence. We show these
g-divergences include divergences which belong to a class of f-divergence (the
Hellinger distance, the chi-square divergence and the alpha-divergence in
addition to the Kullback-Leibler divergence). Moreover, we derive an inequality
between the g-Bregman divergence and the skew g-Jensen divergence and show this
inequality is a generalization of Lin&apos;s inequality.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Nishiyama_T/0/1/0/all/0/1&quot;&gt;Tomohiro Nishiyama&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.08316">
<title>A Trio Neural Model for Dynamic Entity Relatedness Ranking. (arXiv:1808.08316v3 [cs.IR] UPDATED)</title>
<link>http://arxiv.org/abs/1808.08316</link>
<description rdf:parseType="Literal">&lt;p&gt;Measuring entity relatedness is a fundamental task for many natural language
processing and information retrieval applications. Prior work often studies
entity relatedness in static settings and an unsupervised manner. However,
entities in real-world are often involved in many different relationships,
consequently entity-relations are very dynamic over time. In this work, we
propose a neural networkbased approach for dynamic entity relatedness,
leveraging the collective attention as supervision. Our model is capable of
learning rich and different entity representations in a joint framework.
Through extensive experiments on large-scale datasets, we demonstrate that our
method achieves better results than competitive baselines.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_T/0/1/0/all/0/1&quot;&gt;Tu Ngoc Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tran_T/0/1/0/all/0/1&quot;&gt;Tuan Tran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nejdl_W/0/1/0/all/0/1&quot;&gt;Wolfgang Nejdl&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.01829">
<title>Adversarial Reprogramming of Sequence Classification Neural Networks. (arXiv:1809.01829v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1809.01829</link>
<description rdf:parseType="Literal">&lt;p&gt;Adversarial Reprogramming has demonstrated success in utilizing pre-trained
neural network classifiers for alternative classification tasks without
modification to the original network. An adversary in such an attack scenario
trains an additive contribution to the inputs to repurpose the neural network
for the new classification task. While this reprogramming approach works for
neural networks with a continuous input space such as that of images, it is not
directly applicable to neural networks trained for tasks such as text
classification, where the input space is discrete. Repurposing such
classification networks would require the attacker to learn an adversarial
program that maps inputs from one discrete space to the other. In this work, we
introduce a context-based vocabulary remapping model to reprogram neural
networks trained on a specific sequence classification task, for a new sequence
classification task desired by the adversary. We propose training procedures
for this adversarial program in both white-box and black-box settings. We
demonstrate the application of our model by adversarially repurposing various
text-classification models including LSTM, bi-directional LSTM and CNN for
alternate classification tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Neekhara_P/0/1/0/all/0/1&quot;&gt;Paarth Neekhara&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hussain_S/0/1/0/all/0/1&quot;&gt;Shehzeen Hussain&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dubnov_S/0/1/0/all/0/1&quot;&gt;Shlomo Dubnov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koushanfar_F/0/1/0/all/0/1&quot;&gt;Farinaz Koushanfar&lt;/a&gt;</dc:creator>
</item></rdf:RDF>