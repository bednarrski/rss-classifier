<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Good papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Good Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-05-28T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10338"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10636"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1603.09002"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.01563"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08394"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08574"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09943"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10354"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10407"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10408"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10528"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10548"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10587"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10693"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10768"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10852"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10872"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10956"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10966"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11004"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11025"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11080"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1606.08362"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.08163"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.08028"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09089"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.05262"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.03317"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.06822"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10352"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10369"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10402"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10413"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10451"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10487"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10559"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10561"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10627"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10652"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10727"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10769"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10829"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10842"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10844"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10863"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10886"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10896"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10981"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11016"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11046"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11057"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11063"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.09492"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.09060"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.04234"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.04928"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07594"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07984"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08090"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08402"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1805.10338">
<title>Zero-Shot Dual Machine Translation. (arXiv:1805.10338v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1805.10338</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural Machine Translation (NMT) systems rely on large amounts of parallel
data. This is a major challenge for low-resource languages. Building on recent
work on unsupervised and semi-supervised methods, we present an approach that
combines zero-shot and dual learning. The latter relies on reinforcement
learning, to exploit the duality of the machine translation task, and requires
only monolingual data for the target language pair. Experiments show that a
zero-shot dual system, trained on English-French and English-Spanish,
outperforms by large margins a standard NMT system in zero-shot translation
performance on Spanish-French (both directions). The zero-shot dual method
approaches the performance, within 2.2 BLEU points, of a comparable supervised
setting. Our method can obtain improvements also on the setting where a small
amount of parallel data for the zero-shot language pair is available. Adding
Russian, to extend our experiments to jointly modeling 6 zero-shot translation
directions, all directions improve between 4 and 15 BLEU points, again,
reaching performance near that of the supervised setting.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sestorain_L/0/1/0/all/0/1&quot;&gt;Lierni Sestorain&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ciaramita_M/0/1/0/all/0/1&quot;&gt;Massimiliano Ciaramita&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Buck_C/0/1/0/all/0/1&quot;&gt;Christian Buck&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hofmann_T/0/1/0/all/0/1&quot;&gt;Thomas Hofmann&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.10636">
<title>Contextual Graph Markov Model: A Deep and Generative Approach to Graph Processing. (arXiv:1805.10636v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.10636</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce the Contextual Graph Markov Model, an approach combining ideas
from generative models and neural networks for the processing of graph data. It
founds on a constructive methodology to build a deep architecture comprising
layers of probabilistic models that learn to encode the structured information
in an incremental fashion. Context is diffused in an efficient and scalable way
across the graph vertexes and edges. The resulting graph encoding is used in
combination with discriminative models to address structure classification
benchmarks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bacciu_D/0/1/0/all/0/1&quot;&gt;Davide Bacciu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Errica_F/0/1/0/all/0/1&quot;&gt;Federico Errica&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Micheli_A/0/1/0/all/0/1&quot;&gt;Alessio Micheli&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1603.09002">
<title>Dataflow Matrix Machines as a Generalization of Recurrent Neural Networks. (arXiv:1603.09002v2 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1603.09002</link>
<description rdf:parseType="Literal">&lt;p&gt;Dataflow matrix machines are a powerful generalization of recurrent neural
networks. They work with multiple types of arbitrary linear streams, multiple
types of powerful neurons, and allow to incorporate higher-order constructions.
We expect them to be useful in machine learning and probabilistic programming,
and in the synthesis of dynamic systems and of deterministic and probabilistic
programs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bukatin_M/0/1/0/all/0/1&quot;&gt;Michael Bukatin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Matthews_S/0/1/0/all/0/1&quot;&gt;Steve Matthews&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Radul_A/0/1/0/all/0/1&quot;&gt;Andrey Radul&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.01563">
<title>DENSER: Deep Evolutionary Network Structured Representation. (arXiv:1801.01563v2 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1801.01563</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep Evolutionary Network Structured Representation (DENSER) is a novel
approach to automatically design Artificial Neural Networks (ANNs) using
Evolutionary Computation. The algorithm not only searches for the best network
topology (e.g., number of layers, type of layers), but also tunes
hyper-parameters, such as, learning parameters or data augmentation parameters.
The automatic design is achieved using a representation with two distinct
levels, where the outer level encodes the general structure of the network,
i.e., the sequence of layers, and the inner level encodes the parameters
associated with each layer. The allowed layers and range of the
hyper-parameters values are defined by means of a human-readable Context-Free
Grammar. DENSER was used to evolve ANNs for CIFAR-10, obtaining an average test
accuracy of 94.13%. The networks evolved for the CIFAR-10 are tested on the
MNIST, Fashion-MNIST, and CIFAR-100; the results are highly competitive, and on
the CIFAR-100 we report a test accuracy of 78.75%. To the best of our
knowledge, our CIFAR-100 results are the highest performing models generated by
methods that aim at the automatic design of Convolutional Neural Networks
(CNNs), and is amongst the best for manually designed and fine-tuned CNNs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Assuncao_F/0/1/0/all/0/1&quot;&gt;Filipe Assun&amp;#xe7;&amp;#xe3;o&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lourenco_N/0/1/0/all/0/1&quot;&gt;Nuno Louren&amp;#xe7;o&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Machado_P/0/1/0/all/0/1&quot;&gt;Penousal Machado&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ribeiro_B/0/1/0/all/0/1&quot;&gt;Bernardete Ribeiro&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08394">
<title>State-Denoised Recurrent Neural Networks. (arXiv:1805.08394v2 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1805.08394</link>
<description rdf:parseType="Literal">&lt;p&gt;Recurrent neural networks (RNNs) are difficult to train on sequence
processing tasks, not only because input noise may be amplified through
feedback, but also because any inaccuracy in the weights has similar
consequences as input noise. We describe a method for denoising the hidden
state during training to achieve more robust representations thereby improving
generalization performance. Attractor dynamics are incorporated into the hidden
state to `clean up&apos; representations at each step of a sequence. The attractor
dynamics are trained through an auxillary denoising loss to recover previously
experienced hidden states from noisy versions of those states. This
state-denoised recurrent neural network {SDRNN} performs multiple steps of
internal processing for each external sequence step. On a range of tasks, we
show that the SDRNN outperforms a generic RNN as well as a variant of the SDRNN
with attractor dynamics on the hidden state but without the auxillary loss. We
argue that attractor dynamics---and corresponding connectivity
constraints---are an essential component of the deep learning arsenal and
should be invoked not only for recurrent networks but also for improving deep
feedforward nets and intertask transfer.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mozer_M/0/1/0/all/0/1&quot;&gt;Michael C.Mozer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kazakov_D/0/1/0/all/0/1&quot;&gt;Denis Kazakov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lindsey_R/0/1/0/all/0/1&quot;&gt;Robert V. Lindsey&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08574">
<title>Breaking the Activation Function Bottleneck through Adaptive Parameterization. (arXiv:1805.08574v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.08574</link>
<description rdf:parseType="Literal">&lt;p&gt;Standard neural network architectures are non-linear only by virtue of a
simple element-wise activation function, making them both brittle and
excessively large. In this paper, we consider methods for making the
feed-forward layer more flexible while preserving its basic structure. We
develop simple drop-in replacements that learn to adapt their parameterization
conditional on the input, thereby increasing statistical efficiency
significantly. We present an adaptive LSTM that advances the state of the art
for the Penn Treebank and WikiText-2 word-modeling tasks while using fewer
parameters and converging in less than half as many iterations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Flennerhag_S/0/1/0/all/0/1&quot;&gt;Sebastian Flennerhag&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yin_H/0/1/0/all/0/1&quot;&gt;Hujun Yin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Keane_J/0/1/0/all/0/1&quot;&gt;John Keane&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Elliot_M/0/1/0/all/0/1&quot;&gt;Mark Elliot&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09943">
<title>Training of photonic neural networks through in situ backpropagation. (arXiv:1805.09943v1 [physics.optics] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1805.09943</link>
<description rdf:parseType="Literal">&lt;p&gt;Recently, integrated optics has gained interest as a hardware platform for
implementing machine learning algorithms. Of particular interest are artificial
neural networks, since matrix-vector multi- plications, which are used heavily
in artificial neural networks, can be done efficiently in photonic circuits.
The training of an artificial neural network is a crucial step in its
application. However, currently on the integrated photonics platform there is
no efficient protocol for the training of these networks. In this work, we
introduce a method that enables highly efficient, in situ training of a
photonic neural network. We use adjoint variable methods to derive the photonic
analogue of the backpropagation algorithm, which is the standard method for
computing gradients of conventional neural networks. We further show how these
gradients may be obtained exactly by performing intensity measurements within
the device. As an application, we demonstrate the training of a numerically
simulated photonic artificial neural network. Beyond the training of photonic
machine learning implementations, our method may also be of broad interest to
experimental sensitivity analysis of photonic systems and the optimization of
reconfigurable optics platforms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Hughes_T/0/1/0/all/0/1&quot;&gt;Tyler W. Hughes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Minkov_M/0/1/0/all/0/1&quot;&gt;Momchil Minkov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Shi_Y/0/1/0/all/0/1&quot;&gt;Yu Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Fan_S/0/1/0/all/0/1&quot;&gt;Shanhui Fan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.10354">
<title>A Scalable Approach to Multi-Context Continual Learning via Lifelong Skill Encoding. (arXiv:1805.10354v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.10354</link>
<description rdf:parseType="Literal">&lt;p&gt;Continual or lifelong learning (CL) is one of the most challenging problems
in machine learning. In this paradigm, a system must learn new tasks, contexts,
or data without forgetting previously learned information. We present a
scalable approach to multi-context continual learning (MCCL) in which we
decouple how a system learns to solve new tasks (i.e., acquires skills) from
how it stores them. Our approach leverages two types of artificial networks:
(1) a set of reusable, \textit{task-specific networks} (TN) that can be trained
as needed to learn new skills, and (2) a lifelong, \textit{autoencoder network}
(EN) that stores all learned skills in a compact, latent space. To learn a new
skill, we first train a TN using conventional backpropagation, thus placing no
restrictions on the system&apos;s ability to encode the new task. We then
incorporate the newly learned skill into the latent space by first recalling
previously learned skills using our EN and then retraining it on both the new
and recalled skills. Our approach can efficiently store an arbitrary number of
skills without compromising previously learned information because each skill
is stored as a separate latent vector. Whenever a particular skill is needed,
we recall the necessary weights using our EN and then load them into the
corresponding TN. Experiments on the MNIST and CIFAR datasets show that we can
continually learn new skills without compromising the performance of existing
skills. To the best of our knowledge, we are the first to demonstrate the
feasibility of encoding entire networks in order to facilitate efficient
continual learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Camp_B/0/1/0/all/0/1&quot;&gt;Blake Camp&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mandivarapu_J/0/1/0/all/0/1&quot;&gt;Jaya Krishna Mandivarapu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Estrada_R/0/1/0/all/0/1&quot;&gt;Rolando Estrada&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.10407">
<title>Semi-supervised Deep Kernel Learning: Regression with Unlabeled Data by Minimizing Predictive Variance. (arXiv:1805.10407v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.10407</link>
<description rdf:parseType="Literal">&lt;p&gt;Large amounts of labeled data are typically required to train deep learning
models. For many real-world problems, however, acquiring additional data can be
expensive or even impossible. We present semi-supervised deep kernel learning
(SSDKL), a semi-supervised regression model based on minimizing predictive
variance in the posterior regularization framework. SSDKL combines the
hierarchical representation learning of neural networks with the probabilistic
modeling capabilities of Gaussian processes. By leveraging unlabeled data, we
show improvements on a diverse set of real-world regression tasks over
supervised deep kernel learning and semi-supervised methods such as VAT and
mean teacher adapted for regression.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jean_N/0/1/0/all/0/1&quot;&gt;Neal Jean&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_S/0/1/0/all/0/1&quot;&gt;Sang Michael Xie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ermon_S/0/1/0/all/0/1&quot;&gt;Stefano Ermon&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.10408">
<title>The Singular Values of Convolutional Layers. (arXiv:1805.10408v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.10408</link>
<description rdf:parseType="Literal">&lt;p&gt;We characterize the singular values of the linear transformation associated
with a convolution applied to a two-dimensional feature map with multiple
channels. Our characterization enables efficient computation of the singular
values of convolutional layers used in popular deep neural network
architectures. It also leads to an algorithm for projecting a convolutional
layer onto the set of layers obeying a bound on the operator norm of the layer.
We show that this is an effective regularizer; periodically applying these
projections during training improves the test error of a residual network on
CIFAR-10 from 6.2\% to 5.3\%.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sedghi_H/0/1/0/all/0/1&quot;&gt;Hanie Sedghi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gupta_V/0/1/0/all/0/1&quot;&gt;Vineet Gupta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Long_P/0/1/0/all/0/1&quot;&gt;Philip M. Long&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.10528">
<title>Dependent Gated Reading for Cloze-Style Question Answering. (arXiv:1805.10528v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1805.10528</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a novel deep learning architecture to address the cloze-style
question answering task. Existing approaches employ reading mechanisms that do
not fully exploit the interdependency between the document and the query. In
this paper, we propose a novel \emph{dependent gated reading} bidirectional GRU
network (DGR) to efficiently model the relationship between the document and
the query during encoding and decision making. Our evaluation shows that DGR
obtains highly competitive performance on well-known machine comprehension
benchmarks such as the Children&apos;s Book Test (CBT-NE and CBT-CN) and Who DiD
What (WDW, Strict and Relaxed). Finally, we extensively analyze and validate
our model by ablation and attention studies.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghaeini_R/0/1/0/all/0/1&quot;&gt;Reza Ghaeini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fern_X/0/1/0/all/0/1&quot;&gt;Xiaoli Z. Fern&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shahbazi_H/0/1/0/all/0/1&quot;&gt;Hamed Shahbazi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tadepalli_P/0/1/0/all/0/1&quot;&gt;Prasad Tadepalli&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.10548">
<title>Deep Watershed Detector for Music Object Recognition. (arXiv:1805.10548v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1805.10548</link>
<description rdf:parseType="Literal">&lt;p&gt;Optical Music Recognition (OMR) is an important and challenging area within
music information retrieval, the accurate detection of music symbols in digital
images is a core functionality of any OMR pipeline. In this paper, we introduce
a novel object detection method, based on synthetic energy maps and the
watershed transform, called Deep Watershed Detector (DWD). Our method is
specifically tailored to deal with high resolution images that contain a large
number of very small objects and is therefore able to process full pages of
written music. We present state-of-the-art detection results of common music
symbols and show DWD&apos;s ability to work with synthetic scores equally well as on
handwritten music.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tuggener_L/0/1/0/all/0/1&quot;&gt;Lukas Tuggener&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Elezi_I/0/1/0/all/0/1&quot;&gt;Ismail Elezi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schmidhuber_J/0/1/0/all/0/1&quot;&gt;Jurgen Schmidhuber&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stadelmann_T/0/1/0/all/0/1&quot;&gt;Thilo Stadelmann&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.10587">
<title>Semantic Explanations of Predictions. (arXiv:1805.10587v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1805.10587</link>
<description rdf:parseType="Literal">&lt;p&gt;The main objective of explanations is to transmit knowledge to humans. This
work proposes to construct informative explanations for predictions made from
machine learning models. Motivated by the observations from social sciences,
our approach selects data points from the training sample that exhibit special
characteristics crucial for explanation, for instance, ones contrastive to the
classification prediction and ones representative of the models. Subsequently,
semantic concepts are derived from the selected data points through the use of
domain ontologies. These concepts are filtered and ranked to produce
informative explanations that improves human understanding. The main features
of our approach are that (1) knowledge about explanations is captured in the
form of ontological concepts, (2) explanations include contrastive evidences in
addition to normal evidences, and (3) explanations are user relevant.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lecue_F/0/1/0/all/0/1&quot;&gt;Freddy Lecue&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_J/0/1/0/all/0/1&quot;&gt;Jiewen Wu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.10693">
<title>Strategyproof Linear Regression in High Dimensions. (arXiv:1805.10693v1 [cs.GT])</title>
<link>http://arxiv.org/abs/1805.10693</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper is part of an emerging line of work at the intersection of machine
learning and mechanism design, which aims to avoid noise in training data by
correctly aligning the incentives of data sources. Specifically, we focus on
the ubiquitous problem of linear regression, where strategyproof mechanisms
have previously been identified in two dimensions. In our setting, agents have
single-peaked preferences and can manipulate only their response variables. Our
main contribution is the discovery of a family of group strategyproof linear
regression mechanisms in any number of dimensions, which we call generalized
resistant hyperplane mechanisms. The game-theoretic properties of these
mechanisms -- and, in fact, their very existence -- are established through a
connection to a discrete version of the Ham Sandwich Theorem.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yiling Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Podimata_C/0/1/0/all/0/1&quot;&gt;Chara Podimata&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Procaccia_A/0/1/0/all/0/1&quot;&gt;Ariel D. Procaccia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shah_N/0/1/0/all/0/1&quot;&gt;Nisarg Shah&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.10768">
<title>Intelligent Knowledge Tracing: More Like a Real Learning Process of a Student. (arXiv:1805.10768v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1805.10768</link>
<description rdf:parseType="Literal">&lt;p&gt;Knowledge tracing (KT) refers to a machine learning technique to assess a
student&apos;s level of understanding (so-called knowledge state) of a certain
concept based on the student performance on problem solving. KT accepts a
series of question-answer pairs as an input and iteratively updates the
knowledge state of the student, eventually returning the probability of the
student solving an unseen question. From the viewpoint of neuroeducation (the
field of applying neuroscience, cognitive science, and psychology to
education), however, KT leaves much room for improvement in terms of explaining
the complex process of human learning. In this paper, we identify three
problems of KT (namely non adaptive knowledge growth, neglected latent
information, and unintended negative influence) and propose a
memory-network-based technique named intelligent knowledge tracing (IKT) to
address them, thus approaching one step closer to understanding the complex
mechanism underlying human learning. In addition, we propose a new performance
metric called correct update count (CUC) that can measure the degree of
unintended negative influence, thus quantifying how closely a student model
resembles the human learning process. The proposed CUC metric can complement
the area under the curve (AUC) metric, allowing us to evaluate competing models
more effectively. According to our experiments using a widely used public
benchmark, IKT significantly (over two times) outperformed the existing KT
approaches in terms of CUC, while preserving the correctness behavior measured
in AUC.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ha_H/0/1/0/all/0/1&quot;&gt;Heonseok Ha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hong_Y/0/1/0/all/0/1&quot;&gt;Yongjun Hong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hwang_U/0/1/0/all/0/1&quot;&gt;Uiwon Hwang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yoon_S/0/1/0/all/0/1&quot;&gt;Sungroh Yoon&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.10852">
<title>A Pragmatic AI Approach to Creating Artistic Visual Variations by Neural Style Transfer. (arXiv:1805.10852v1 [cs.CY])</title>
<link>http://arxiv.org/abs/1805.10852</link>
<description rdf:parseType="Literal">&lt;p&gt;On a constant quest for inspiration, designers can become more effective with
tools that facilitate their creative process and let them overcome design
fixation. This paper explores the practicality of applying neural style
transfer as an emerging design tool for generating creative digital content. To
this aim, the present work explores a well-documented neural style transfer
algorithm (Johnson 2016) in four experiments on four relevant visual
parameters: number of iterations, learning rate, total variation, content vs.
style weight. The results allow a pragmatic recommendation of parameter
configuration (number of iterations: 200 to 300, learning rate: 2e-1 to 4e-1,
total variation: 1e-4 to 1e-8, content weights vs. style weights: 50:100 to
200:100) that saves extensive experimentation time and lowers the technical
entry barrier. With this rule-of-thumb insight, visual designers can
effectively apply deep learning to create artistic visual variations of digital
content. This could enable designers to leverage AI for creating design works
as state-of-the-art.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+So_C/0/1/0/all/0/1&quot;&gt;Chaehan So&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.10872">
<title>DeepProbLog: Neural Probabilistic Logic Programming. (arXiv:1805.10872v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1805.10872</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce DeepProbLog, a probabilistic logic programming language that
incorporates deep learning by means of neural predicates. We show how existing
inference and learning techniques can be adapted for the new language. Our
experiments demonstrate that DeepProbLog supports both symbolic and subsymbolic
representations and inference, 1) program induction, 2) probabilistic (logic)
programming, and 3) (deep) learning from examples. To the best of our
knowledge, this work is the first to propose a framework where general-purpose
neural networks and expressive probabilistic-logical modeling and reasoning are
integrated in a way that exploits the full expressiveness and strengths of both
worlds and can be trained end-to-end based on examples.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Manhaeve_R/0/1/0/all/0/1&quot;&gt;Robin Manhaeve&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dumancic_S/0/1/0/all/0/1&quot;&gt;Sebastijan Duman&amp;#x10d;i&amp;#x107;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kimmig_A/0/1/0/all/0/1&quot;&gt;Angelika Kimmig&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Demeester_T/0/1/0/all/0/1&quot;&gt;Thomas Demeester&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Raedt_L/0/1/0/all/0/1&quot;&gt;Luc De Raedt&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.10956">
<title>Temporal Event Knowledge Acquisition via Identifying Narratives. (arXiv:1805.10956v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1805.10956</link>
<description rdf:parseType="Literal">&lt;p&gt;Inspired by the double temporality characteristic of narrative texts, we
propose a novel approach for acquiring rich temporal &quot;before/after&quot; event
knowledge across sentences in narrative stories. The double temporality states
that a narrative story often describes a sequence of events following the
chronological order and therefore, the temporal order of events matches with
their textual order. We explored narratology principles and built a weakly
supervised approach that identifies 287k narrative paragraphs from three large
text corpora. We then extracted rich temporal event knowledge from these
narrative paragraphs. Such event knowledge is shown useful to improve temporal
relation classification and outperform several recent neural network models on
the narrative cloze task.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yao_W/0/1/0/all/0/1&quot;&gt;Wenlin Yao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_R/0/1/0/all/0/1&quot;&gt;Ruihong Huang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.10966">
<title>Lifelong Learning of Spatiotemporal Representations with Dual-Memory Recurrent Self-Organization. (arXiv:1805.10966v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1805.10966</link>
<description rdf:parseType="Literal">&lt;p&gt;Humans excel at continually acquiring and fine-tuning knowledge over
sustained time spans. This ability, typically referred to as lifelong learning,
is crucial for artificial agents interacting in real-world, dynamic
environments where i) the number of tasks to be learned is not pre-defined, ii)
training samples become progressively available over time, and iii) annotated
samples may be very sparse. In this paper, we propose a dual-memory
self-organizing system that learns spatiotemporal representations from videos.
The architecture draws inspiration from the interplay of the hippocampal and
neocortical systems in the mammalian brain argued to mediate the complementary
tasks of quickly integrating specific experiences, i.e., episodic memory (EM),
and slowly learning generalities from episodic events, i.e., semantic memory
(SM). The complementary memories are modeled as recurrent self-organizing
neural networks: The EM quickly adapts to incoming novel sensory observations
via competitive Hebbian Learning, whereas the SM progressively learns compact
representations by using task-relevant signals to regulate intrinsic levels of
neurogenesis and neuroplasticity. For the consolidation of knowledge,
trajectories of neural reactivations are periodically replayed to both
networks. We analyze and evaluate the performance of our approach with the
CORe50 benchmark dataset for continuous object recognition from videos. We show
that the proposed approach significantly outperforms current (supervised)
methods of lifelong learning in three different incremental learning scenarios,
and that due to the unsupervised nature of neural network self-organization,
our approach can be used in scenarios where sample annotations are sparse.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Parisi_G/0/1/0/all/0/1&quot;&gt;German I. Parisi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tani_J/0/1/0/all/0/1&quot;&gt;Jun Tani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Weber_C/0/1/0/all/0/1&quot;&gt;Cornelius Weber&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wermter_S/0/1/0/all/0/1&quot;&gt;Stefan Wermter&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11004">
<title>Soft Layer-Specific Multi-Task Summarization with Entailment and Question Generation. (arXiv:1805.11004v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1805.11004</link>
<description rdf:parseType="Literal">&lt;p&gt;An accurate abstractive summary of a document should contain all its salient
information and should be logically entailed by the input document. We improve
these important aspects of abstractive summarization via multi-task learning
with the auxiliary tasks of question generation and entailment generation,
where the former teaches the summarization model how to look for salient
questioning-worthy details, and the latter teaches the model how to rewrite a
summary which is a directed-logical subset of the input document. We also
propose novel multi-task architectures with high-level (semantic)
layer-specific sharing across multiple encoder and decoder layers of the three
tasks, as well as soft-sharing mechanisms (and show performance ablations and
analysis examples of each contribution). Overall, we achieve statistically
significant improvements over the state-of-the-art on both the CNN/DailyMail
and Gigaword datasets, as well as on the DUC-2002 transfer setup. We also
present several quantitative and qualitative analysis studies of our model&apos;s
learned saliency and entailment skills.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_H/0/1/0/all/0/1&quot;&gt;Han Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pasunuru_R/0/1/0/all/0/1&quot;&gt;Ramakanth Pasunuru&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bansal_M/0/1/0/all/0/1&quot;&gt;Mohit Bansal&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11025">
<title>Think Visually: Question Answering through Virtual Imagery. (arXiv:1805.11025v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1805.11025</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we study the problem of geometric reasoning in the context of
question-answering. We introduce Dynamic Spatial Memory Network (DSMN), a new
deep network architecture designed for answering questions that admit latent
visual representations. DSMN learns to generate and reason over such
representations. Further, we propose two synthetic benchmarks, FloorPlanQA and
ShapeIntersection, to evaluate the geometric reasoning capability of QA
systems. Experimental results validate the effectiveness of our proposed DSMN
for visual thinking tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goyal_A/0/1/0/all/0/1&quot;&gt;Ankit Goyal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jian Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deng_J/0/1/0/all/0/1&quot;&gt;Jia Deng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11080">
<title>Fast Abstractive Summarization with Reinforce-Selected Sentence Rewriting. (arXiv:1805.11080v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1805.11080</link>
<description rdf:parseType="Literal">&lt;p&gt;Inspired by how humans summarize long documents, we propose an accurate and
fast summarization model that first selects salient sentences and then rewrites
them abstractively (i.e., compresses and paraphrases) to generate a concise
overall summary. We use a novel sentence-level policy gradient method to bridge
the non-differentiable computation between these two neural networks in a
hierarchical way, while maintaining language fluency. Empirically, we achieve
the new state-of-the-art on all metrics (including human evaluation) on the
CNN/Daily Mail dataset, as well as significantly higher abstractiveness scores.
Moreover, by first operating at the sentence-level and then the word-level, we
enable parallel decoding of our neural generative model that results in
substantially faster (10-20x) inference speed as well as 4x faster training
convergence than previous long-paragraph encoder-decoder models. We also
demonstrate the generalization of our model on the test-only DUC-2002 dataset,
where we achieve higher scores than a state-of-the-art model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yen-Chun Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bansal_M/0/1/0/all/0/1&quot;&gt;Mohit Bansal&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1606.08362">
<title>A Reduction for Optimizing Lattice Submodular Functions with Diminishing Returns. (arXiv:1606.08362v2 [cs.DS] UPDATED)</title>
<link>http://arxiv.org/abs/1606.08362</link>
<description rdf:parseType="Literal">&lt;p&gt;A function $f: \mathbb{Z}_+^E \rightarrow \mathbb{R}_+$ is DR-submodular if
it satisfies $f({\bf x} + \chi_i) -f ({\bf x}) \ge f({\bf y} + \chi_i) - f({\bf
y})$ for all ${\bf x}\le {\bf y}, i\in E$. Recently, the problem of maximizing
a DR-submodular function $f: \mathbb{Z}_+^E \rightarrow \mathbb{R}_+$ subject
to a budget constraint $\|{\bf x}\|_1 \leq B$ as well as additional constraints
has received significant attention \cite{SKIK14,SY15,MYK15,SY16}.
&lt;/p&gt;
&lt;p&gt;In this note, we give a generic reduction from the DR-submodular setting to
the submodular setting. The running time of the reduction and the size of the
resulting submodular instance depends only \emph{logarithmically} on $B$. Using
this reduction, one can translate the results for unconstrained and constrained
submodular maximization to the DR-submodular setting for many types of
constraints in a unified manner.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ene_A/0/1/0/all/0/1&quot;&gt;Alina Ene&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_H/0/1/0/all/0/1&quot;&gt;Huy L. Nguyen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.08163">
<title>A Renewal Model of Intrusion. (arXiv:1709.08163v5 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1709.08163</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a probabilistic model of an intrusion in a renewal process. Given
a process and a sequence of events, an intrusion is a subsequence of events
that is not produced by the process. Applications of the model are, for
example, online payment fraud with the fraudster taking over a user&apos;s account
and performing payments on the user&apos;s behalf, or unexpected equipment failures
due to unintended use.
&lt;/p&gt;
&lt;p&gt;We adopt Bayesian approach to infer the probability of an intrusion in a
sequence of events, a MAP subsequence of events constituting the intrusion, and
the marginal probability of each event in a sequence to belong to the
intrusion. We evaluate the model for intrusion detection on synthetic data and
on anonymized data from an online payment system.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tolpin_D/0/1/0/all/0/1&quot;&gt;David Tolpin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.08028">
<title>Recurrent Relational Networks. (arXiv:1711.08028v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1711.08028</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper is concerned with learning to solve tasks that require a chain of
interdependent steps of relational inference, like answering complex questions
about the relationships between objects, or solving puzzles where the smaller
elements of a solution mutually constrain each other. We introduce the
recurrent relational network, a general purpose module that operates on a graph
representation of objects. As a generalization of Santoro et al. [2017]&apos;s
relational network, it can augment any neural network model with the capacity
to do many-step relational reasoning. We achieve state of the art results on
the bAbI textual question-answering dataset with the recurrent relational
network, consistently solving 20/20 tasks. As bAbI is not particularly
challenging from a relational reasoning point of view, we introduce
Pretty-CLEVR, a new diagnostic dataset for relational reasoning. In the
Pretty-CLEVR set-up, we can vary the question to control for the number of
relational reasoning steps that are required to obtain the answer. Using
Pretty-CLEVR, we probe the limitations of multi-layer perceptrons, relational
and recurrent relational networks. Finally, we show how recurrent relational
networks can learn to solve Sudoku puzzles from supervised training data, a
challenging task requiring upwards of 64 steps of relational reasoning. We
achieve state-of-the-art results amongst comparable methods by solving 96.6% of
the hardest Sudoku puzzles.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Palm_R/0/1/0/all/0/1&quot;&gt;Rasmus Berg Palm&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Paquet_U/0/1/0/all/0/1&quot;&gt;Ulrich Paquet&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Winther_O/0/1/0/all/0/1&quot;&gt;Ole Winther&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09089">
<title>Kitsune: An Ensemble of Autoencoders for Online Network Intrusion Detection. (arXiv:1802.09089v2 [cs.CR] UPDATED)</title>
<link>http://arxiv.org/abs/1802.09089</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural networks have become an increasingly popular solution for network
intrusion detection systems (NIDS). Their capability of learning complex
patterns and behaviors make them a suitable solution for differentiating
between normal traffic and network attacks. However, a drawback of neural
networks is the amount of resources needed to train them. Many network gateways
and routers devices, which could potentially host an NIDS, simply do not have
the memory or processing power to train and sometimes even execute such models.
More importantly, the existing neural network solutions are trained in a
supervised manner. Meaning that an expert must label the network traffic and
update the model manually from time to time.
&lt;/p&gt;
&lt;p&gt;In this paper, we present Kitsune: a plug and play NIDS which can learn to
detect attacks on the local network, without supervision, and in an efficient
online manner. Kitsune&apos;s core algorithm (KitNET) uses an ensemble of neural
networks called autoencoders to collectively differentiate between normal and
abnormal traffic patterns. KitNET is supported by a feature extraction
framework which efficiently tracks the patterns of every network channel. Our
evaluations show that Kitsune can detect various attacks with a performance
comparable to offline anomaly detectors, even on a Raspberry PI. This
demonstrates that Kitsune can be a practical and economic NIDS.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mirsky_Y/0/1/0/all/0/1&quot;&gt;Yisroel Mirsky&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Doitshman_T/0/1/0/all/0/1&quot;&gt;Tomer Doitshman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Elovici_Y/0/1/0/all/0/1&quot;&gt;Yuval Elovici&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shabtai_A/0/1/0/all/0/1&quot;&gt;Asaf Shabtai&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.05262">
<title>Learning to Play General Video-Games via an Object Embedding Network. (arXiv:1803.05262v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1803.05262</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep reinforcement learning (DRL) has proven to be an effective tool for
creating general video-game AI. However most current DRL video-game agents
learn end-to-end from the video-output of the game, which is superfluous for
many applications and creates a number of additional problems. More
importantly, directly working on pixel-based raw video data is substantially
distinct from what a human player does.In this paper, we present a novel method
which enables DRL agents to learn directly from object information. This is
obtained via use of an object embedding network (OEN) that compresses a set of
object feature vectors of different lengths into a single fixed-length unified
feature vector representing the current game-state and fulfills the DRL
simultaneously. We evaluate our OEN-based DRL agent by comparing to several
state-of-the-art approaches on a selection of games from the GVG-AI
Competition. Experimental results suggest that our object-based DRL agent
yields performance comparable to that of those approaches used in our
comparative study.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Woof_W/0/1/0/all/0/1&quot;&gt;William Woof&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1&quot;&gt;Ke Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.03317">
<title>Question Answering over Freebase via Attentive RNN with Similarity Matrix based CNN. (arXiv:1804.03317v3 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1804.03317</link>
<description rdf:parseType="Literal">&lt;p&gt;With the rapid growth of knowledge bases (KBs), question answering over
knowledge base, a.k.a. KBQA has drawn huge attention in recent years. Most of
the existing KBQA methods follow so called encoder-compare framework. They map
the question and the KB facts to a common embedding space, in which the
similarity between the question vector and the fact vectors can be conveniently
computed. This, however, inevitably loses original words interaction
information. To preserve more original information, we propose an attentive
recurrent neural network with similarity matrix based convolutional neural
network (AR-SMCNN) model, which is able to capture comprehensive hierarchical
information utilizing the advantages of both RNN and CNN. We use RNN to capture
semantic-level correlation by its sequential modeling nature, and use an
attention mechanism to keep track of the entities and relations simultaneously.
Meanwhile, we use a similarity matrix based CNN with two-directions pooling to
extract literal-level words interaction matching utilizing CNNs strength of
modeling spatial correlation among data. Moreover, we have developed a new
heuristic extension method for entity detection, which significantly decreases
the effect of noise. Our method has outperformed the state-of-the-arts on
SimpleQuestion benchmark in both accuracy and efficiency.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qu_Y/0/1/0/all/0/1&quot;&gt;Yingqi Qu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Jie Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kang_L/0/1/0/all/0/1&quot;&gt;Liangyi Kang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_Q/0/1/0/all/0/1&quot;&gt;Qinfeng Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ye_D/0/1/0/all/0/1&quot;&gt;Dan Ye&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.06822">
<title>DNN or $k$-NN: That is the Generalize vs. Memorize Question. (arXiv:1805.06822v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.06822</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper studies the relationship between the classification performed by
deep neural networks and the $k$-NN decision at the embedding space of these
networks. This simple important connection shown here provides a better
understanding of the relationship between the ability of neural networks to
generalize and their tendency to memorize the training data, which are
traditionally considered to be contradicting to each other and here shown to be
compatible and complementary. Our results support the conjecture that deep
neural networks approach Bayes optimal error rates.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cohen_G/0/1/0/all/0/1&quot;&gt;Gilad Cohen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sapiro_G/0/1/0/all/0/1&quot;&gt;Guillermo Sapiro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Giryes_R/0/1/0/all/0/1&quot;&gt;Raja Giryes&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.10352">
<title>Tensorized Spectrum Preserving Compression for Neural Networks. (arXiv:1805.10352v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.10352</link>
<description rdf:parseType="Literal">&lt;p&gt;Modern neural networks can have tens of millions of parameters, and are often
ill-suited for smartphones or IoT devices. In this paper, we describe an
efficient mechanism for compressing large networks by {\em tensorizing\/}
network layers: i.e. mapping layers on to high-order matrices, for which we
introduce new tensor decomposition methods. Compared to previous compression
methods, some of which use tensor decomposition, our techniques preserve more
of the networks invariance structure. Coupled with a new data
reconstruction-based learning method, we show that tensorized compression
outperforms existing techniques for both convolutional and fully-connected
layers on state-of-the art networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Su_J/0/1/0/all/0/1&quot;&gt;Jiahao Su&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jingling Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bhattacharjee_B/0/1/0/all/0/1&quot;&gt;Bobby Bhattacharjee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Huang_F/0/1/0/all/0/1&quot;&gt;Furong Huang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.10369">
<title>When Recurrent Models Don&apos;t Need To Be Recurrent. (arXiv:1805.10369v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.10369</link>
<description rdf:parseType="Literal">&lt;p&gt;We prove stable recurrent neural networks are well approximated by
feed-forward networks for the purpose of both inference and training by
gradient descent. Our result applies to a broad range of non-linear recurrent
neural networks under a natural stability condition, which we observe is also
necessary. Complementing our theoretical findings, we verify the conclusions of
our theory on both real and synthetic tasks. Furthermore, we demonstrate
recurrent models satisfying the stability assumption of our theory can have
excellent performance on real sequence learning tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Miller_J/0/1/0/all/0/1&quot;&gt;John Miller&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hardt_M/0/1/0/all/0/1&quot;&gt;Moritz Hardt&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.10402">
<title>Deep Convolutional Neural Networks for Map-Type Classification. (arXiv:1805.10402v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.10402</link>
<description rdf:parseType="Literal">&lt;p&gt;Maps are an important medium that enable people to comprehensively understand
the configuration of cultural activities and natural elements over different
times and places. Although massive maps are available in the digital era, how
to effectively and accurately access the required map remains a challenge
today. Previous works partially related to map-type classification mainly
focused on map comparison and map matching at the local scale. The features
derived from local map areas might be insufficient to characterize map content.
To facilitate establishing an automatic approach for accessing the needed map,
this paper reports our investigation into using deep learning techniques to
recognize seven types of map, including topographic map, terrain map, physical
map, urban scene map, the National Map, 3D map, nighttime map, orthophoto map,
and land cover classification map. Experimental results show that the
state-of-the-art deep convolutional neural networks can support automatic
map-type classification. Additionally, the classification accuracy varies
according to different map-types. We hope our work can contribute to the
implementation of deep learning techniques in cartographical community and
advance the progress of Geographical Artificial Intelligence (GeoAI).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhou_X/0/1/0/all/0/1&quot;&gt;Xiran Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Li_W/0/1/0/all/0/1&quot;&gt;Wenwen Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Arundel_S/0/1/0/all/0/1&quot;&gt;Samantha T. Arundel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Jun Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.10413">
<title>Fast Policy Learning through Imitation and Reinforcement. (arXiv:1805.10413v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.10413</link>
<description rdf:parseType="Literal">&lt;p&gt;Imitation learning (IL) consists of a set of tools that leverage expert
demonstrations to quickly learn policies. However, if the expert is suboptimal,
IL can yield policies with inferior performance compared to reinforcement
learning (RL). In this paper, we aim to provide an algorithm that combines the
best aspects of RL and IL. We accomplish this by formulating several popular RL
and IL algorithms in a common mirror descent framework, showing that these
algorithms can be viewed as a variation on a single approach. We then propose
LOKI, a strategy for policy learning that first performs a small but random
number of IL iterations before switching to a policy gradient RL method. We
show that if the switching time is properly randomized, LOKI can learn to
outperform a suboptimal expert and converge faster than running policy gradient
from scratch. Finally, we evaluate the performance of LOKI experimentally in
several simulated environments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_C/0/1/0/all/0/1&quot;&gt;Ching-An Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yan_X/0/1/0/all/0/1&quot;&gt;Xinyan Yan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wagener_N/0/1/0/all/0/1&quot;&gt;Nolan Wagener&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Boots_B/0/1/0/all/0/1&quot;&gt;Byron Boots&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.10451">
<title>Geometric Understanding of Deep Learning. (arXiv:1805.10451v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.10451</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep learning is the mainstream technique for many machine learning tasks,
including image recognition, machine translation, speech recognition, and so
on. It has outperformed conventional methods in various fields and achieved
great successes. Unfortunately, the understanding on how it works remains
unclear. It has the central importance to lay down the theoretic foundation for
deep learning. In this work, we give a geometric view to understand deep
learning: we show that the fundamental principle attributing to the success is
the manifold structure in data, namely natural high dimensional data
concentrates close to a low-dimensional manifold, deep learning learns the
manifold and the probability distribution on it. We further introduce the
concepts of rectified linear complexity for deep neural network measuring its
learning capability, rectified linear complexity of an embedding manifold
describing the difficulty to be learned. Then we show for any deep neural
network with fixed architecture, there exists a manifold that cannot be learned
by the network. By empirical evidences, we also demonstrate the learning
accuracies of the-state-of-art autoencoders are reasonably good but still leave
large spaces to be improved. Finally, we propose to apply optimal mass
transportation theory to control the probability distribution in the latent
space.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lei_N/0/1/0/all/0/1&quot;&gt;Na Lei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_Z/0/1/0/all/0/1&quot;&gt;Zhongxuan Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yau_S/0/1/0/all/0/1&quot;&gt;Shing-Tung Yau&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gu_D/0/1/0/all/0/1&quot;&gt;David Xianfeng Gu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.10487">
<title>Stable Geodesic Update on Hyperbolic Space and its Application to Poincare Embeddings. (arXiv:1805.10487v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.10487</link>
<description rdf:parseType="Literal">&lt;p&gt;A hyperbolic space has been shown to be more capable of modeling complex
networks than a Euclidean space. This paper proposes an explicit update rule
along geodesics in a hyperbolic space. The convergence of our algorithm is
theoretically guaranteed, and the convergence rate is better than the
conventional Euclidean gradient descent algorithm. Moreover, our algorithm
avoids the &quot;bias&quot; problem of existing methods using the Riemannian gradient.
Experimental results demonstrate the good performance of our algorithm in the
\Poincare embeddings of knowledge base data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Enokida_Y/0/1/0/all/0/1&quot;&gt;Yosuke Enokida&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Suzuki_A/0/1/0/all/0/1&quot;&gt;Atsushi Suzuki&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yamanishi_K/0/1/0/all/0/1&quot;&gt;Kenji Yamanishi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.10559">
<title>cpSGD: Communication-efficient and differentially-private distributed SGD. (arXiv:1805.10559v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.10559</link>
<description rdf:parseType="Literal">&lt;p&gt;Distributed stochastic gradient descent is an important subroutine in
distributed learning. A setting of particular interest is when the clients are
mobile devices, where two important concerns are communication efficiency and
the privacy of the clients. Several recent works have focused on reducing the
communication cost or introducing privacy guarantees, but none of the proposed
communication efficient methods are known to be privacy preserving and none of
the known privacy mechanisms are known to be communication efficient. To this
end, we study algorithms that achieve both communication efficiency and
differential privacy. For $d$ variables and $n \approx d$ clients, the proposed
method uses $O(\log \log(nd))$ bits of communication per client per coordinate
and ensures constant privacy.
&lt;/p&gt;
&lt;p&gt;We also extend and improve previous analysis of the \emph{Binomial mechanism}
showing that it achieves nearly the same utility as the Gaussian mechanism,
while requiring fewer representation bits, which can be of independent
interest.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Agarwal_N/0/1/0/all/0/1&quot;&gt;Naman Agarwal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Suresh_A/0/1/0/all/0/1&quot;&gt;Ananda Theertha Suresh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yu_F/0/1/0/all/0/1&quot;&gt;Felix Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kumar_S/0/1/0/all/0/1&quot;&gt;Sanjiv Kumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mcmahan_H/0/1/0/all/0/1&quot;&gt;H. Brendan Mcmahan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.10561">
<title>Adversarial Constraint Learning for Structured Prediction. (arXiv:1805.10561v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.10561</link>
<description rdf:parseType="Literal">&lt;p&gt;Constraint-based learning reduces the burden of collecting labels by having
users specify general properties of structured outputs, such as constraints
imposed by physical laws. We propose a novel framework for simultaneously
learning these constraints and using them for supervision, bypassing the
difficulty of using domain expertise to manually specify constraints. Learning
requires a black-box simulator of structured outputs, which generates valid
labels, but need not model their corresponding inputs or the input-label
relationship. At training time, we constrain the model to produce outputs that
cannot be distinguished from simulated labels by adversarial training.
Providing our framework with a small number of labeled inputs gives rise to a
new semi-supervised structured prediction model; we evaluate this model on
multiple tasks --- tracking, pose estimation and time series prediction --- and
find that it achieves high accuracy with only a small number of labeled inputs.
In some cases, no labels are required at all.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ren_H/0/1/0/all/0/1&quot;&gt;Hongyu Ren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stewart_R/0/1/0/all/0/1&quot;&gt;Russell Stewart&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_J/0/1/0/all/0/1&quot;&gt;Jiaming Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kuleshov_V/0/1/0/all/0/1&quot;&gt;Volodymyr Kuleshov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ermon_S/0/1/0/all/0/1&quot;&gt;Stefano Ermon&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.10627">
<title>Reliability and Learnability of Human Bandit Feedback for Sequence-to-Sequence Reinforcement Learning. (arXiv:1805.10627v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1805.10627</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a study on reinforcement learning (RL) from human bandit feedback
for sequence-to-sequence learning, exemplified by the task of bandit neural
machine translation (NMT). We investigate the reliability of human bandit
feedback, and analyze the influence of reliability on the learnability of a
reward estimator, and the effect of the quality of reward estimates on the
overall RL task. Our analysis of cardinal (5-point ratings) and ordinal
(pairwise preferences) feedback shows that their intra- and inter-annotator
$\alpha$-agreement is comparable. Best reliability is obtained for standardized
cardinal feedback, and cardinal feedback is also easiest to learn and
generalize from. Finally, improvements of over 1 BLEU can be obtained by
integrating a regression-based reward estimator trained on cardinal feedback
for 800 translations into RL for NMT. This shows that RL is possible even from
small amounts of fairly reliable human feedback, pointing to a great potential
for applications at larger scale.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kreutzer_J/0/1/0/all/0/1&quot;&gt;Julia Kreutzer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Uyheng_J/0/1/0/all/0/1&quot;&gt;Joshua Uyheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Riezler_S/0/1/0/all/0/1&quot;&gt;Stefan Riezler&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.10652">
<title>Defending Against Adversarial Attacks by Leveraging an Entire GAN. (arXiv:1805.10652v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.10652</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent work has shown that state-of-the-art models are highly vulnerable to
adversarial perturbations of the input. We propose cowboy, an approach to
detecting and defending against adversarial attacks by using both the
discriminator and generator of a GAN trained on the same dataset. We show that
the discriminator consistently scores the adversarial samples lower than the
real samples across multiple attacks and datasets. We provide empirical
evidence that adversarial samples lie outside of the data manifold learned by
the GAN. Based on this, we propose a cleaning method which uses both the
discriminator and generator of the GAN to project the samples back onto the
data manifold. This cleaning procedure is independent of the classifier and
type of attack and thus can be deployed in existing systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Santhanam_G/0/1/0/all/0/1&quot;&gt;Gokula Krishnan Santhanam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Grnarova_P/0/1/0/all/0/1&quot;&gt;Paulina Grnarova&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.10727">
<title>Perceive Your Users in Depth: Learning Universal User Representations from Multiple E-commerce Tasks. (arXiv:1805.10727v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.10727</link>
<description rdf:parseType="Literal">&lt;p&gt;Tasks such as search and recommendation have become increas- ingly important
for E-commerce to deal with the information over- load problem. To meet the
diverse needs of di erent users, person- alization plays an important role. In
many large portals such as Taobao and Amazon, there are a bunch of di erent
types of search and recommendation tasks operating simultaneously for person-
alization. However, most of current techniques address each task separately.
This is suboptimal as no information about users shared across di erent tasks.
In this work, we propose to learn universal user representations across
multiple tasks for more e ective personalization. In partic- ular, user
behavior sequences (e.g., click, bookmark or purchase of products) are modeled
by LSTM and attention mechanism by integrating all the corresponding content,
behavior and temporal information. User representations are shared and learned
in an end-to-end setting across multiple tasks. Bene ting from better
information utilization of multiple tasks, the user representations are more e
ective to re ect their interests and are more general to be transferred to new
tasks. We refer this work as Deep User Perception Network (DUPN) and conduct an
extensive set of o ine and online experiments. Across all tested ve di erent
tasks, our DUPN consistently achieves better results by giving more e ective
user representations. Moreover, we deploy DUPN in large scale operational tasks
in Taobao. Detailed implementations, e.g., incre- mental model updating, are
also provided to address the practical issues for the real world applications.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ni_Y/0/1/0/all/0/1&quot;&gt;Yabo Ni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ou_D/0/1/0/all/0/1&quot;&gt;Dan Ou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Liu_S/0/1/0/all/0/1&quot;&gt;Shichen Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xiang Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ou_W/0/1/0/all/0/1&quot;&gt;Wenwu Ou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zeng_A/0/1/0/all/0/1&quot;&gt;Anxiang Zeng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Si_L/0/1/0/all/0/1&quot;&gt;Luo Si&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.10769">
<title>Universality of Deep Convolutional Neural Networks. (arXiv:1805.10769v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.10769</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep learning has been widely applied and brought breakthroughs in speech
recognition, computer vision, and many other domains. The involved deep neural
network architectures and computational issues have been well studied in
machine learning. But there lacks a theoretical foundation for understanding
the approximation or generalization ability of deep learning methods generated
by the network architectures such as deep convolutional neural networks having
convolutional structures. Here we show that a deep convolutional neural network
(CNN) is universal, meaning that it can be used to approximate any continuous
function to an arbitrary accuracy when the depth of the neural network is large
enough. This answers an open question in learning theory. Our quantitative
estimate, given tightly in terms of the number of free parameters to be
computed, verifies the efficiency of deep CNNs in dealing with large
dimensional data. Our study also demonstrates the role of convolutions in deep
CNNs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_D/0/1/0/all/0/1&quot;&gt;Ding-Xuan Zhou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.10829">
<title>Sigsoftmax: Reanalysis of the Softmax Bottleneck. (arXiv:1805.10829v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.10829</link>
<description rdf:parseType="Literal">&lt;p&gt;Softmax is an output activation function for modeling categorical probability
distributions in many applications of deep learning. However, a recent study
revealed that softmax can be a bottleneck of representational capacity of
neural networks in language modeling (the softmax bottleneck). In this paper,
we propose an output activation function for breaking the softmax bottleneck
without additional parameters. We re-analyze the softmax bottleneck from the
perspective of the output set of log-softmax and identify the cause of the
softmax bottleneck. On the basis of this analysis, we propose sigsoftmax, which
is composed of a multiplication of an exponential function and sigmoid
function. Sigsoftmax can break the softmax bottleneck. The experiments on
language modeling demonstrate that sigsoftmax and mixture of sigsoftmax
outperform softmax and mixture of softmax, respectively.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kanai_S/0/1/0/all/0/1&quot;&gt;Sekitoshi Kanai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Fujiwara_Y/0/1/0/all/0/1&quot;&gt;Yasuhiro Fujiwara&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yamanaka_Y/0/1/0/all/0/1&quot;&gt;Yuki Yamanaka&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Adachi_S/0/1/0/all/0/1&quot;&gt;Shuichi Adachi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.10842">
<title>Approximating Real-Time Recurrent Learning with Random Kronecker Factors. (arXiv:1805.10842v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.10842</link>
<description rdf:parseType="Literal">&lt;p&gt;Despite all the impressive advances of recurrent neural networks, sequential
data is still in need of better modelling. Truncated backpropagation through
time (TBPTT), the learning algorithm most widely used in practice, suffers from
the truncation bias, which drastically limits its ability to learn long-term
dependencies.The Real-Time Recurrent Learning algorithm (RTRL) addresses this
issue, but its high computational requirements make it infeasible in practice.
The Unbiased Online Recurrent Optimization algorithm (UORO) approximates RTRL
with a smaller runtime and memory cost, but with the disadvantage of obtaining
noisy gradients that also limit its practical applicability. In this paper we
propose the Kronecker Factored RTRL (KF-RTRL) algorithm that uses a Kronecker
product decomposition to approximate the gradients for a large class of RNNs.
We show that KF-RTRL is an unbiased and memory efficient online learning
algorithm. Our theoretical analysis shows that, under reasonable assumptions,
the noise introduced by our algorithm is not only stable over time but also
asymptotically much smaller than the one of the UORO algorithm. We also confirm
these theoretical results experimentally. Further, we show empirically that the
KF-RTRL algorithm captures long-term dependencies and almost matches the
performance of TBPTT on real world tasks by training Recurrent Highway Networks
on a synthetic string memorization task and on the Penn TreeBank task,
respectively. These results indicate that RTRL based approaches might be a
promising future alternative to TBPTT.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mujika_A/0/1/0/all/0/1&quot;&gt;Asier Mujika&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meier_F/0/1/0/all/0/1&quot;&gt;Florian Meier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Steger_A/0/1/0/all/0/1&quot;&gt;Angelika Steger&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.10844">
<title>A Stochastic Decoder for Neural Machine Translation. (arXiv:1805.10844v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.10844</link>
<description rdf:parseType="Literal">&lt;p&gt;The process of translation is ambiguous, in that there are typically many
valid trans- lations for a given sentence. This gives rise to significant
variation in parallel cor- pora, however, most current models of machine
translation do not account for this variation, instead treating the prob- lem
as a deterministic process. To this end, we present a deep generative model of
machine translation which incorporates a chain of latent variables, in order to
ac- count for local lexical and syntactic varia- tion in parallel corpora. We
provide an in- depth analysis of the pitfalls encountered in variational
inference for training deep generative models. Experiments on sev- eral
different language pairs demonstrate that the model consistently improves over
strong baselines.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Schulz_P/0/1/0/all/0/1&quot;&gt;Philip Schulz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Aziz_W/0/1/0/all/0/1&quot;&gt;Wilker Aziz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Cohn_T/0/1/0/all/0/1&quot;&gt;Trevor Cohn&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.10863">
<title>Parallel Weight Consolidation: A Brain Segmentation Case Study. (arXiv:1805.10863v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.10863</link>
<description rdf:parseType="Literal">&lt;p&gt;Collecting the large datasets needed to train deep neural networks can be
very difficult, particularly for the many applications for which sharing and
pooling data is complicated by practical, ethical, or legal concerns. However,
it may be the case that derivative datasets or predictive models developed
within individual sites can be shared and combined with fewer restrictions.
Training on distributed datasets and combining the resulting networks is often
viewed as continual learning, but these methods require networks to be trained
sequentially. In this paper, we introduce parallel weight consolidation (PWC),
a continual learning method to consolidate the weights of neural networks
trained in parallel on independent datasets. We perform a brain segmentation
case study using PWC to consolidate several dilated convolutional neural
networks trained in parallel on independent structural magnetic resonance
imaging (sMRI) datasets from different sites. We found that PWC led to
increased performance on held-out test sets from the different sites, as well
as on a very large and completely independent multi-site dataset. This
demonstrates the feasibility of PWC for combining the knowledge learned by
networks trained on different datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+McClure_P/0/1/0/all/0/1&quot;&gt;Patrick McClure&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_C/0/1/0/all/0/1&quot;&gt;Charles Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pereira_F/0/1/0/all/0/1&quot;&gt;Francisco Pereira&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kaczmarzyk_J/0/1/0/all/0/1&quot;&gt;Jakub Kaczmarzyk&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rogers_Lee_J/0/1/0/all/0/1&quot;&gt;John Rogers-Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nielson_D/0/1/0/all/0/1&quot;&gt;Dylan Nielson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bandettini_P/0/1/0/all/0/1&quot;&gt;Peter Bandettini&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.10886">
<title>Importance Weighted Transfer of Samples in Reinforcement Learning. (arXiv:1805.10886v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.10886</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the transfer of experience samples (i.e., tuples &amp;lt; s, a, s&apos;, r &amp;gt;)
in reinforcement learning (RL), collected from a set of source tasks to improve
the learning process in a given target task. Most of the related approaches
focus on selecting the most relevant source samples for solving the target
task, but then all the transferred samples are used without considering anymore
the discrepancies between the task models. In this paper, we propose a
model-based technique that automatically estimates the relevance (importance
weight) of each source sample for solving the target task. In the proposed
approach, all the samples are transferred and used by a batch RL algorithm to
solve the target task, but their contribution to the learning process is
proportional to their importance weight. By extending the results for
importance weighting provided in supervised learning literature, we develop a
finite-sample analysis of the proposed batch RL algorithm. Furthermore, we
empirically compare the proposed algorithm to state-of-the-art approaches,
showing that it achieves better learning performance and is very robust to
negative transfer, even when some source tasks are significantly different from
the target task.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tirinzoni_A/0/1/0/all/0/1&quot;&gt;Andrea Tirinzoni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sessa_A/0/1/0/all/0/1&quot;&gt;Andrea Sessa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pirotta_M/0/1/0/all/0/1&quot;&gt;Matteo Pirotta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Restelli_M/0/1/0/all/0/1&quot;&gt;Marcello Restelli&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.10896">
<title>Adaptive Network Sparsification via Dependent Variational Beta-Bernoulli Dropout. (arXiv:1805.10896v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.10896</link>
<description rdf:parseType="Literal">&lt;p&gt;While variational dropout approaches have been shown to be effective for
network sparsification, they are still suboptimal in the sense that they set
the dropout rate for each neuron without consideration of the input data. With
such input-independent dropout, each neuron is evolved to be generic across
inputs, which makes it difficult to sparsify networks without accuracy loss. To
overcome this limitation, we propose adaptive variational dropout whose
probabilities are drawn from sparsity-inducing beta-Bernoulli prior. It allows
each neuron to be evolved either to be generic or specific for certain inputs,
or dropped altogether. Such input-adaptive sparsity- inducing dropout allows
the resulting network to tolerate larger degree of sparsity without losing its
expressive power by removing redundancies among features. We validate our
dependent variational beta-Bernoulli dropout on multiple public datasets, on
which it obtains significantly more compact networks than baseline methods,
with consistent accuracy improvements over the base networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lee_J/0/1/0/all/0/1&quot;&gt;Juho Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kim_S/0/1/0/all/0/1&quot;&gt;Saehoon Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yoon_J/0/1/0/all/0/1&quot;&gt;Jaehong Yoon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lee_H/0/1/0/all/0/1&quot;&gt;Hae Beom Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yang_E/0/1/0/all/0/1&quot;&gt;Eunho Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hwang_S/0/1/0/all/0/1&quot;&gt;Sungjoo Hwang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.10981">
<title>Robust and highly adaptable brain-computer interface with convolutional net architecture based on a generative model of neuromagnetic measurements. (arXiv:1805.10981v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.10981</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep Neural Networks have been applied very successfully in image recognition
and natural language processing. Recently these powerful methods have received
attention also in the brain-computer interface (BCI) community. Here, we
introduce a convolutional neural network (CNN) architecture optimized for
classification of brain states from non-invasive magnetoencephalographic (MEG)
measurements. The model structure is motivated by a state-of-the-art generative
model of the MEG signal and is thus readily interpretable in neurophysiological
terms. We demonstrate that the proposed model is highly accurate in decoding
event-related responses as well as modulations of oscillatory brain activity,
and is robust with respect to inter-individual differences. Importantly, the
model generalizes well across users: when trained on data pooled from previous
users, it can successfully perform on new users. Thus, the time-consuming BCI
calibration can be omitted. Moreover, the model can be incrementally updated,
resulting in +8.9% average accuracy improvement in offline experiments and
+17.0% in a real-time BCI. We argue that this model can be used in practical
BCIs and basic neuroscience research.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zubarev_I/0/1/0/all/0/1&quot;&gt;Ivan Zubarev&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zetter_R/0/1/0/all/0/1&quot;&gt;Rasmus Zetter&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Halme_H/0/1/0/all/0/1&quot;&gt;Hanna-Leena Halme&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Parkkonen_L/0/1/0/all/0/1&quot;&gt;Lauri Parkkonen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11016">
<title>Memory Augmented Self-Play. (arXiv:1805.11016v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.11016</link>
<description rdf:parseType="Literal">&lt;p&gt;Self-play is an unsupervised training procedure which enables the
reinforcement learning agents to explore the environment without requiring any
external rewards. We augment the self-play setting by providing an external
memory where the agent can store experience from the previous tasks. This
enables the agent to come up with more diverse self-play tasks resulting in
faster exploration of the environment. The agent pretrained in the memory
augmented self-play setting easily outperforms the agent pretrained in
no-memory self-play setting.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sodhani_S/0/1/0/all/0/1&quot;&gt;Shagun Sodhani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pahuja_V/0/1/0/all/0/1&quot;&gt;Vardaan Pahuja&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11046">
<title>Scalable Methods for 8-bit Training of Neural Networks. (arXiv:1805.11046v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.11046</link>
<description rdf:parseType="Literal">&lt;p&gt;Quantized Neural Networks (QNNs) are often used to improve network efficiency
during the inference phase, i.e. after the network has been trained. Extensive
research in the field suggests many different quantization schemes. Still, the
number of bits required, as well as the best quantization scheme, are yet
unknown. Our theoretical analysis suggests that most of the training process is
robust to substantial precision reduction, and points to only a few specific
operations that require higher precision. Armed with this knowledge, we
quantize the model parameters, activations and layer gradients to 8-bit,
leaving at a higher precision only the final step in the computation of the
weight gradients. Additionally, as QNNs require batch-normalization to be
trained at high precision, we introduce Range Batch-Normalization (BN) which
has significantly higher tolerance to quantization noise and improved
computational complexity. Our simulations show that Range BN is equivalent to
the traditional batch norm if a precise scale adjustment, which can be
approximated analytically, is applied. To the best of the authors&apos; knowledge,
this work is the first to quantize the weights, activations, as well as a
substantial volume of the gradients stream, in all layers (including batch
normalization) to 8-bit while showing state-of-the-art results over the
ImageNet-1K dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Banner_R/0/1/0/all/0/1&quot;&gt;Ron Banner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hubara_I/0/1/0/all/0/1&quot;&gt;Itay Hubara&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hoffer_E/0/1/0/all/0/1&quot;&gt;Elad Hoffer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Soudry_D/0/1/0/all/0/1&quot;&gt;Daniel Soudry&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11057">
<title>Deep Generative Models for Distribution-Preserving Lossy Compression. (arXiv:1805.11057v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.11057</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose and study the problem of distribution-preserving lossy
compression. Motivated by the recent advances in extreme image compression
which allow to maintain artifact-free reconstructions even at very low
bitrates, we propose to optimize the rate-distortion tradeoff under the
constraint that the reconstructed samples follow the distribution of the
training data. Such a compression system recovers both ends of the spectrum: On
one hand, at zero bitrate it learns a generative model of the data, and at high
enough bitrates it achieves perfect reconstruction. Furthermore, for
intermediate bitrates it smoothly interpolates between matching the
distribution of the training data and perfectly reconstructing the training
samples. We study several methods to approximately solve the proposed
optimization problem, including a novel combination of Wasserstein GAN and
Wasserstein Autoencoder, and present strong theoretical and empirical results
for the proposed compression system.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tschannen_M/0/1/0/all/0/1&quot;&gt;Michael Tschannen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Agustsson_E/0/1/0/all/0/1&quot;&gt;Eirikur Agustsson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lucic_M/0/1/0/all/0/1&quot;&gt;Mario Lucic&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11063">
<title>Theory and Experiments on Vector Quantized Autoencoders. (arXiv:1805.11063v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.11063</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep neural networks with discrete latent variables offer the promise of
better symbolic reasoning, and learning abstractions that are more useful to
new tasks. There has been a surge in interest in discrete latent variable
models, however, despite several recent improvements, the training of discrete
latent variable models has remained challenging and their performance has
mostly failed to match their continuous counterparts. Recent work on vector
quantized autoencoders (VQ-VAE) has made substantial progress in this
direction, with its perplexity almost matching that of a VAE on datasets such
as CIFAR-10. In this work, we investigate an alternate training technique for
VQ-VAE, inspired by its connection to the Expectation Maximization (EM)
algorithm. Training the discrete bottleneck with EM helps us achieve better
image generation results on CIFAR-10, and together with knowledge distillation,
allows us to develop a non-autoregressive machine translation model whose
accuracy almost matches a strong greedy autoregressive baseline Transformer,
while being 3.3 times faster at inference.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roy_A/0/1/0/all/0/1&quot;&gt;Aurko Roy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vaswani_A/0/1/0/all/0/1&quot;&gt;Ashish Vaswani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Neelakantan_A/0/1/0/all/0/1&quot;&gt;Arvind Neelakantan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Parmar_N/0/1/0/all/0/1&quot;&gt;Niki Parmar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.09492">
<title>Robust PCA, Subspace Learning, and Tracking. (arXiv:1711.09492v3 [cs.IT] UPDATED)</title>
<link>http://arxiv.org/abs/1711.09492</link>
<description rdf:parseType="Literal">&lt;p&gt;PCA is one of the most widely used dimension reduction techniques. A related
easier problem is &quot;subspace learning&quot; or &quot;subspace estimation&quot;. Given
relatively clean data, both are easily solved via singular value decomposition
(SVD). The problem of subspace learning or PCA in the presence of outliers is
called robust subspace learning or robust PCA (RPCA). For long data sequences,
if one tries to use a single lower dimensional subspace to represent the data,
the required subspace dimension may end up being quite large. For such data, a
better model is to assume that it lies in a low-dimensional subspace that can
change over time, albeit gradually. The problem of tracking such data (and the
subspaces) while being robust to outliers is called robust subspace tracking
(RST). This article provides a magazine-style overview of the entire field of
robust subspace learning and tracking. In particular solutions for three
problems are discussed in detail: RPCA via sparse+low-rank matrix decomposition
(S+LR), RST via S+LR, and &quot;robust subspace recovery (RSR)&quot;. RSR assumes that an
entire data vector is either an outlier or an inlier. The S+LR formulation
instead assumes that outliers occur on only a few data vector indices and hence
are well modeled as sparse corruptions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vaswani_N/0/1/0/all/0/1&quot;&gt;Namrata Vaswani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bouwmans_T/0/1/0/all/0/1&quot;&gt;Thierry Bouwmans&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Javed_S/0/1/0/all/0/1&quot;&gt;Sajid Javed&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Narayanamurthy_P/0/1/0/all/0/1&quot;&gt;Praneeth Narayanamurthy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.09060">
<title>An Information-Theoretic View for Deep Learning. (arXiv:1804.09060v4 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1804.09060</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep learning has transformed computer vision, natural language processing,
and speech recognition. However, two critical questions remain obscure: (1) why
do deep neural networks generalize better than shallow networks, and (2) does
it always hold that a deeper network leads to better performance? Specifically,
letting $L$ be the number of convolutional and pooling layers in a deep neural
network, and $n$ be the size of the training sample, we derive an upper bound
on the expected generalization error for this network, i.e.,
&lt;/p&gt;
&lt;p&gt;\begin{eqnarray*}
&lt;/p&gt;
&lt;p&gt;\mathbb{E}[R(W)-R_S(W)] \leq
\exp{\left(-\frac{L}{2}\log{\frac{1}{\eta}}\right)}\sqrt{\frac{2\sigma^2}{n}I(S,W)}
&lt;/p&gt;
&lt;p&gt;\end{eqnarray*} where $\sigma &amp;gt;0$ is a constant depending on the loss
function, $0&amp;lt;\eta&amp;lt;1$ is a constant depending on the information loss for each
convolutional or pooling layer, and $I(S, W)$ is the mutual information between
the training sample $S$ and the output hypothesis $W$. This upper bound shows
that as the number of convolutional and pooling layers $L$ increases in the
network, the expected generalization error will decrease exponentially to zero.
Layers with strict information loss, such as the convolutional layers, reduce
the generalization error for the whole network, this answers the first
question. However, algorithms with zero expected generalization error does not
imply a small test error or $\mathbb{E}[R(W)]$. This is because
$\mathbb{E}[R_S(W)]$ is large when the information for fitting the data is lost
as the number of layers increases. This suggests that the claim &quot;the deeper the
better&quot; is conditioned on a small training error or $\mathbb{E}[R_S(W)]$.
Finally, we show that deep learning satisfies a weak notion of stability and
the sample complexity of deep neural networks will decrease as $L$ increases.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Jingwei Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Liu_T/0/1/0/all/0/1&quot;&gt;Tongliang Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tao_D/0/1/0/all/0/1&quot;&gt;Dacheng Tao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.04234">
<title>Distributed Deep Forest and its Application to Automatic Detection of Cash-out Fraud. (arXiv:1805.04234v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.04234</link>
<description rdf:parseType="Literal">&lt;p&gt;Internet companies are facing the need of handling large scale machine
learning applications in a daily basis, and distributed system which can handle
extra-large scale tasks is needed. Deep forest is a recently proposed deep
learning framework which uses tree ensembles as its building blocks and it has
achieved highly competitive results on various domains of tasks. However, it
has not been tested on extremely large scale tasks. In this work, based on our
parameter server system and platform of artificial intelligence, we developed
the distributed version of deep forest with an easy-to-use GUI. To the best of
our knowledge, this is the first implementation of distributed deep forest. To
meet the need of real-world tasks, many improvements are introduced to the
original deep forest model. We tested the deep forest model on an extra-large
scale task, i.e., automatic detection of cash-out fraud, with more than 100
millions of training samples. Experimental results showed that the deep forest
model has the best performance according to the evaluation metrics from
different perspectives even with very little effort for parameter tuning. This
model can block fraud transactions in a large amount of money \footnote{detail
is business confidential} each day. Even compared with the best deployed model,
deep forest model can additionally bring into a significant decrease of
economic loss.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Ya-Lin Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1&quot;&gt;Jun Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_W/0/1/0/all/0/1&quot;&gt;Wenhao Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1&quot;&gt;Ji Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1&quot;&gt;Longfei Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1&quot;&gt;Ziqi Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1&quot;&gt;Ming Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1&quot;&gt;Zhiqiang Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1&quot;&gt;Chaochao Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xiaolong Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1&quot;&gt;Zhi-Hua Zhou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.04928">
<title>Doing the impossible: Why neural networks can be trained at all. (arXiv:1805.04928v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.04928</link>
<description rdf:parseType="Literal">&lt;p&gt;As deep neural networks grow in size, from thousands to millions to billions
of weights, the performance of those networks becomes limited by our ability to
accurately train them. A common naive question arises: if we have a system with
billions of degrees of freedom, don&apos;t we also need billions of samples to train
it? Of course, the success of deep learning indicates that reliable models can
be learned with reasonable amounts of data. Similar questions arise in protein
folding, spin glasses and biological neural networks. With effectively infinite
potential folding/spin/wiring configurations, how does the system find the
precise arrangement that leads to useful and robust results? Simple sampling of
the possible configurations until an optimal one is reached is not a viable
option even if one waited for the age of the universe. On the contrary, there
appears to be a mechanism in the above phenomena that forces them to achieve
configurations that live on a low-dimensional manifold, avoiding the curse of
dimensionality. In the current work we use the concept of mutual information
between successive layers of a deep neural network to elucidate this mechanism
and suggest possible ways of exploiting it to accelerate training. We show that
adding structure to the neural network that enforces higher mutual information
between layers speeds training and leads to more accurate results. High mutual
information between layers implies that the effective number of free parameters
is exponentially smaller than the raw number of tunable weights.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hodas_N/0/1/0/all/0/1&quot;&gt;Nathan O. Hodas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stinis_P/0/1/0/all/0/1&quot;&gt;Panos Stinis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07594">
<title>Generalizing Point Embeddings using the Wasserstein Space of Elliptical Distributions. (arXiv:1805.07594v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1805.07594</link>
<description rdf:parseType="Literal">&lt;p&gt;Embedding complex objects as vectors in low dimensional spaces is a
longstanding problem in machine learning. We propose in this work an extension
of that approach, which consists in embedding objects as elliptical probability
distributions, namely distributions whose densities have elliptical level sets.
We endow these measures with the 2-Wasserstein metric, with two important
benefits: (i) For such measures, the squared 2-Wasserstein metric has a closed
form, equal to the sum of the squared Euclidean distance between means and the
squared Bures metric between covariance matrices. The latter is a Riemannian
metric between positive semi-definite matrices, which turns out to be Euclidean
on a suitable factor representation of such matrices, which is valid on the
entire geodesic between these matrices. (ii) The 2-Wasserstein distance boils
down to the usual Euclidean metric when comparing Diracs, and therefore
provides the natural framework to extend point embeddings. We show that for
these reasons Wasserstein elliptical embeddings are more intuitive and yield
tools that are better behaved numerically than the alternative choice of
Gaussian embeddings with the Kullback-Leibler divergence. In particular, and
unlike previous work based on the KL geometry, we learn elliptical
distributions that are not necessarily diagonal. We demonstrate the interest of
elliptical embeddings by using them for visualization, to compute embeddings of
words, and to reflect entanglement or hypernymy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Muzellec_B/0/1/0/all/0/1&quot;&gt;Boris Muzellec&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Cuturi_M/0/1/0/all/0/1&quot;&gt;Marco Cuturi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07984">
<title>Adversarial Attacks on Neural Networks for Graph Data. (arXiv:1805.07984v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1805.07984</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep learning models for graphs have achieved strong performance for the task
of node classification. Despite their proliferation, currently there is no
study of their robustness to adversarial attacks. Yet, in domains where they
are likely to be used, e.g. the web, adversaries are common. Can deep learning
models for graphs be easily fooled? In this work, we introduce the first study
of adversarial attacks on attributed graphs, specifically focusing on models
exploiting ideas of graph convolutions. In addition to attacks at test time, we
tackle the more challenging class of poisoning/causative attacks, which focus
on the training phase of a machine learning model. We generate adversarial
perturbations targeting the node&apos;s features and the graph structure, thus,
taking the dependencies between instances in account. Moreover, we ensure that
the perturbations remain unnoticeable by preserving important data
characteristics. To cope with the underlying discrete domain we propose an
efficient algorithm Nettack exploiting incremental computations. Our
experimental study shows that accuracy of node classification significantly
drops even when performing only few perturbations. Even more, our attacks are
transferable: the learned attacks generalize to other state-of-the-art node
classification models and unsupervised approaches, and likewise are successful
even when only limited knowledge about the graph is given.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zugner_D/0/1/0/all/0/1&quot;&gt;Daniel Z&amp;#xfc;gner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Akbarnejad_A/0/1/0/all/0/1&quot;&gt;Amir Akbarnejad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gunnemann_S/0/1/0/all/0/1&quot;&gt;Stephan G&amp;#xfc;nnemann&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08090">
<title>Graph Capsule Convolutional Neural Networks. (arXiv:1805.08090v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1805.08090</link>
<description rdf:parseType="Literal">&lt;p&gt;Graph Convolutional Neural Networks (GCNNs) are the most recent exciting
advancement in deep learning field and their applications are quickly spreading
in multi-cross-domains including bioinformatics, chemoinformatics, social
networks, natural language processing and computer vision. In this paper, we
expose and tackle some of the basic weaknesses of a GCNN model with a capsule
idea presented in \cite{hinton2011transforming} and propose our Graph Capsule
Network (GCAPS-CNN) model. In addition, we design our GCAPS-CNN model to solve
especially graph classification problem which current GCNN models find
challenging. Through extensive experiments, we show that our proposed Graph
Capsule Network can significantly outperforms both the existing state-of-art
deep learning methods and graph kernels on graph classification benchmark
datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Verma_S/0/1/0/all/0/1&quot;&gt;Saurabh Verma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhang_Z/0/1/0/all/0/1&quot;&gt;Zhi-Li Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08402">
<title>Adapted Deep Embeddings: A Synthesis of Methods for $k$-Shot Inductive Transfer Learning. (arXiv:1805.08402v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.08402</link>
<description rdf:parseType="Literal">&lt;p&gt;The focus in machine learning has branched beyond training classifiers on a
single task to investigating how previously acquired knowledge in a source
domain can be leveraged to facilitate learning in a related target domain,
known as inductive transfer learning. Three active lines of research have
independently explored transfer learning using neural networks. In weight
transfer, a model trained on the source domain is used as an initialization
point for a network to be trained on the target domain. In deep metric
learning, the source domain is used to construct an embedding that captures
class structure in both the source and target domains. In few-shot learning,
the focus is on generalizing well in the target domain based on a limited
number of labeled examples. We compare state-of-the-art methods from these
three paradigms and also explore hybrid adapted-embedding methods that use
limited target-domain data to fine tune embeddings constructed from
source-domain data. We conduct a systematic comparison of methods in a variety
of domains, varying the number of labeled instances available in the target
domain ($k$), as well as the number of target-domain classes. We reach three
principal conclusions: (1) Deep embeddings are far superior, compared to weight
transfer, as a starting point for inter-domain transfer or model re-use (2) Our
hybrid methods robustly outperform every few-shot learning and every deep
metric learning method previously proposed, with a mean error reduction of 30%
over state-of-the-art. (3) Among loss functions for discovering embeddings, the
histogram loss (Ustinova &amp;amp; Lempitsky, 2016) is most robust. We hope our results
will motivate a unification of research in weight transfer, deep metric
learning, and few-shot learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Scott_T/0/1/0/all/0/1&quot;&gt;Tyler R. Scott&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ridgeway_K/0/1/0/all/0/1&quot;&gt;Karl Ridgeway&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mozer_M/0/1/0/all/0/1&quot;&gt;Michael C. Mozer&lt;/a&gt;</dc:creator>
</item></rdf:RDF>