<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Boring papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Bad Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-09-06T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.01674"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.02032"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.02195"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.00838"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.01703"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.01774"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.01807"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.01816"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.01819"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.01843"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.01852"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.01898"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.01926"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.01942"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.01943"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.01991"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.02040"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.02070"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1708.01867"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.06196"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.06870"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.11112"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.03096"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.11284"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.00647"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.01697"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.01706"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.01712"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.01728"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.01733"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.01738"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.01740"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.01772"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.01796"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.01804"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.01817"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.01818"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.01859"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.01890"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.01906"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.01921"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.02010"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.02052"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.02066"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.02069"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.02105"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1604.03887"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.05829"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09691"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.08021"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.05345"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10111"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.01445"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.06497"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.08725"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.02266"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.06356"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1809.01674">
<title>Hierarchical Selective Recruitment in Linear-Threshold Brain Networks - Part I: Intra-Layer Dynamics and Selective Inhibition. (arXiv:1809.01674v1 [cs.SY])</title>
<link>http://arxiv.org/abs/1809.01674</link>
<description rdf:parseType="Literal">&lt;p&gt;Goal-driven selective attention (GDSA) refers to the brain&apos;s function of
prioritizing, according to one&apos;s internal goals and desires, the activity of a
task-relevant subset of its overall network to efficiently process relevant
information while inhibiting the effects of distractions. Despite decades of
research in neuroscience, a comprehensive understanding of GDSA is still
lacking. We propose a novel framework for GDSA using concepts and tools from
control theory as well as insights and structures from neuroscience. Central to
this framework is an information-processing hierarchy with two main components:
selective inhibition of task-irrelevant activity and top-down recruitment of
task-relevant activity. We analyze the internal dynamics of each layer of the
hierarchy described as a network with linear-threshold dynamics and derive
conditions on its structure to guarantee existence and uniqueness of
equilibria, asymptotic stability, and boundedness of trajectories. We also
provide mechanisms that enforce selective inhibition using the
biologically-inspired schemes of feedforward and feedback inhibition. Despite
their differences, both schemes lead to the same conclusion: the intrinsic
dynamical properties of the (not-inhibited) task-relevant subnetworks are the
sole determiner of the dynamical properties that are achievable under selective
inhibition.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nozari_E/0/1/0/all/0/1&quot;&gt;Erfan Nozari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cortes_J/0/1/0/all/0/1&quot;&gt;Jorge Cort&amp;#xe9;s&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.02032">
<title>Latent Molecular Optimization for Targeted Therapeutic Design. (arXiv:1809.02032v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1809.02032</link>
<description rdf:parseType="Literal">&lt;p&gt;We devise an approach for targeted molecular design, a problem of interest in
computational drug discovery: given a target protein site, we wish to generate
a chemical with both high binding affinity to the target and satisfactory
pharmacological properties. This problem is made difficult by the enormity and
discreteness of the space of potential therapeutics, as well as the
graph-structured nature of biomolecular surface sites. Using a dataset of
protein-ligand complexes, we surmount these issues by extracting a signature of
the target site with a graph convolutional network and by encoding the discrete
chemical into a continuous latent vector space. The latter embedding permits
gradient-based optimization in molecular space, which we perform using learned
differentiable models of binding affinity and other pharmacological properties.
We show that our approach is able to efficiently optimize these multiple
objectives and discover new molecules with potentially useful binding
properties, validated via docking methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aumentado_Armstrong_T/0/1/0/all/0/1&quot;&gt;Tristan Aumentado-Armstrong&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.02195">
<title>Granger-causal Attentive Mixtures of Experts: Learning Important Features with Neural Networks. (arXiv:1802.02195v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1802.02195</link>
<description rdf:parseType="Literal">&lt;p&gt;Knowledge of the importance of input features towards decisions made by
machine-learning models is essential to increase our understanding of both the
models and the underlying data. Here, we present a new approach to estimating
feature importance with neural networks based on the idea of distributing the
features of interest among experts in an attentive mixture of experts (AME).
AMEs use attentive gating networks trained with a Granger-causal objective to
learn to jointly produce accurate predictions as well as estimates of feature
importance in a single model. Our experiments on an established benchmark and
two real-world datasets show (i) that the feature importance estimates provided
by AMEs compare favourably to those provided by state-of-the-art methods, (ii)
that AMEs are significantly faster than existing methods, and (iii) that the
associations discovered by AMEs are consistent with those reported by domain
experts.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schwab_P/0/1/0/all/0/1&quot;&gt;Patrick Schwab&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Miladinovic_D/0/1/0/all/0/1&quot;&gt;Djordje Miladinovic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Karlen_W/0/1/0/all/0/1&quot;&gt;Walter Karlen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.00838">
<title>A multi-instance deep neural network classifier: application to Higgs boson CP measurement. (arXiv:1803.00838v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1803.00838</link>
<description rdf:parseType="Literal">&lt;p&gt;We investigate properties of a classifier applied to the measurements of the
CP state of the Higgs boson in $H\rightarrow\tau\tau$ decays. The problem is
framed as binary classifier applied to individual instances. Then the prior
knowledge that the instances belong to the same class is used to define the
multi-instance classifier. Its final score is calculated as multiplication of
single instance scores for a given series of instances. In the paper we discuss
properties of such classifier, notably its dependence on the number of
instances in the series. This classifier exhibits very strong random dependence
on the number of epochs used for training and requires careful tuning of the
classification threshold. We derive formula for this optimal threshold.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bialas_P/0/1/0/all/0/1&quot;&gt;P. Bialas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nemeth_D/0/1/0/all/0/1&quot;&gt;D. Nemeth&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Richter_Was_E/0/1/0/all/0/1&quot;&gt;E. Richter-W&amp;#x105;s&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.01703">
<title>Hyperbolic Recommender Systems. (arXiv:1809.01703v1 [cs.IR])</title>
<link>http://arxiv.org/abs/1809.01703</link>
<description rdf:parseType="Literal">&lt;p&gt;Many well-established recommender systems are based on representation
learning in Euclidean space. In these models, matching functions such as the
Euclidean distance or inner product are typically used for computing similarity
scores between user and item embeddings. This paper investigates the notion of
learning user and item representations in Hyperbolic space. In this paper, we
argue that Hyperbolic space is more suitable for learning user-item embeddings
in the recommendation domain. Unlike Euclidean spaces, Hyperbolic spaces are
intrinsically equipped to handle hierarchical structure, encouraged by its
property of exponentially increasing distances away from origin. We propose
HyperBPR (Hyperbolic Bayesian Personalized Ranking), a conceptually simple but
highly effective model for the task at hand. Our proposed HyperBPR not only
outperforms their Euclidean counterparts, but also achieves state-of-the-art
performance on multiple benchmark datasets, demonstrating the effectiveness of
personalized recommendation in Hyperbolic space.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vinh_T/0/1/0/all/0/1&quot;&gt;Tran Dang Quang Vinh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tay_Y/0/1/0/all/0/1&quot;&gt;Yi Tay&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1&quot;&gt;Shuai Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cong_G/0/1/0/all/0/1&quot;&gt;Gao Cong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xiao-Li Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.01774">
<title>Deep Recurrent Electricity Theft Detection in AMI Networks with Random Tuning of Hyper-parameters. (arXiv:1809.01774v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1809.01774</link>
<description rdf:parseType="Literal">&lt;p&gt;Modern smart grids rely on advanced metering infrastructure (AMI) networks
for monitoring and billing pur- poses. However, such an approach suffers from
electricity theft cyberattacks. Different from the existing research that
utilizes shallow, static, and customer-specific-based electricity theft de-
tectors, this paper proposes a generalized deep recurrent neural network
(RNN)-based electricity theft detector that can effectively thwart these
cyberattacks. The proposed model exploits the time series nature of the
customers&apos; electricity consumption to implement a gated recurrent unit
(GRU)-RNN, hence, improving the detection performance. In addition, the
proposed RNN-based detector adopts a random search analysis in its learning
stage to appropriately fine-tune its hyper-parameters. Extensive test studies
are carried out to investigate the detector&apos;s performance using publicly
available real data of 107,200 energy consumption days from 200 customers.
Simulation results demonstrate the superior performance of the proposed
detector compared with state-of-the-art electricity theft detectors.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nabil_M/0/1/0/all/0/1&quot;&gt;Mahmoud Nabil&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ismail_M/0/1/0/all/0/1&quot;&gt;Muhammad Ismail&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mahmoud_M/0/1/0/all/0/1&quot;&gt;Mohamed Mahmoud&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shahin_M/0/1/0/all/0/1&quot;&gt;Mostafa Shahin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qaraqe_K/0/1/0/all/0/1&quot;&gt;Khalid Qaraqe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Serpedin_E/0/1/0/all/0/1&quot;&gt;Erchin Serpedin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.01807">
<title>Improbotics: Exploring the Imitation Game using Machine Intelligence in Improvised Theatre. (arXiv:1809.01807v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1809.01807</link>
<description rdf:parseType="Literal">&lt;p&gt;Theatrical improvisation (impro or improv) is a demanding form of live,
collaborative performance. Improv is a humorous and playful artform built on an
open-ended narrative structure which simultaneously celebrates effort and
failure. It is thus an ideal test bed for the development and deployment of
interactive artificial intelligence (AI)-based conversational agents, or
artificial improvisors. This case study introduces an improv show experiment
featuring human actors and artificial improvisors. We have previously developed
a deep-learning-based artificial improvisor, trained on movie subtitles, that
can generate plausible, context-based, lines of dialogue suitable for theatre
(Mathewson and Mirowski 2017). In this work, we have employed it to control
what a subset of human actors say during an improv performance. We also give
human-generated lines to a different subset of performers. All lines are
provided to actors with headphones and all performers are wearing headphones.
This paper describes a Turing test, or imitation game, taking place in a
theatre, with both the audience members and the performers left to guess who is
a human and who is a machine. In order to test scientific hypotheses about the
perception of humans versus machines we collect anonymous feedback from
volunteer performers and audience members. Our results suggest that rehearsal
increases proficiency and possibility to control events in the performance.
That said, consistency with real world experience is limited by the interface
and the mechanisms used to perform the show. We also show that human-generated
lines are shorter, more positive, and have less difficult words with more
grammar and spelling mistakes than the artificial improvisor generated lines.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mathewson_K/0/1/0/all/0/1&quot;&gt;Kory W. Mathewson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mirowski_P/0/1/0/all/0/1&quot;&gt;Piotr Mirowski&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.01816">
<title>Visual Coreference Resolution in Visual Dialog using Neural Module Networks. (arXiv:1809.01816v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1809.01816</link>
<description rdf:parseType="Literal">&lt;p&gt;Visual dialog entails answering a series of questions grounded in an image,
using dialog history as context. In addition to the challenges found in visual
question answering (VQA), which can be seen as one-round dialog, visual dialog
encompasses several more. We focus on one such problem called visual
coreference resolution that involves determining which words, typically noun
phrases and pronouns, co-refer to the same entity/object instance in an image.
This is crucial, especially for pronouns (e.g., `it&apos;), as the dialog agent must
first link it to a previous coreference (e.g., `boat&apos;), and only then can rely
on the visual grounding of the coreference `boat&apos; to reason about the pronoun
`it&apos;. Prior work (in visual dialog) models visual coreference resolution either
(a) implicitly via a memory network over history, or (b) at a coarse level for
the entire question; and not explicitly at a phrase level of granularity. In
this work, we propose a neural module network architecture for visual dialog by
introducing two novel modules - Refer and Exclude - that perform explicit,
grounded, coreference resolution at a finer word level. We demonstrate the
effectiveness of our model on MNIST Dialog, a visually simple yet
coreference-wise complex dataset, by achieving near perfect accuracy, and on
VisDial, a large and challenging visual dialog dataset on real images, where
our model outperforms other approaches, and is more interpretable, grounded,
and consistent qualitatively.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kottur_S/0/1/0/all/0/1&quot;&gt;Satwik Kottur&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moura_J/0/1/0/all/0/1&quot;&gt;Jos&amp;#xe9; M. F. Moura&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Parikh_D/0/1/0/all/0/1&quot;&gt;Devi Parikh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Batra_D/0/1/0/all/0/1&quot;&gt;Dhruv Batra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rohrbach_M/0/1/0/all/0/1&quot;&gt;Marcus Rohrbach&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.01819">
<title>CASC: Context-Aware Segmentation and Clustering for Motif Discovery in Noisy Time Series Data. (arXiv:1809.01819v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1809.01819</link>
<description rdf:parseType="Literal">&lt;p&gt;Complex systems, such as airplanes, cars, or financial markets, produce
multivariate time series data consisting of system observations over a period
of time. Such data can be interpreted as a sequence of segments, where each
segment is associated with a certain state of the system. An important problem
in this domain is to identify repeated sequences of states, known as motifs.
Such motifs correspond to complex behaviors that capture common sequences of
state transitions. For example, a motif of &quot;making a turn&quot; might manifest in
sensor data as a sequence of states: slowing down, turning the wheel, and then
speeding back up. However, discovering these motifs is challenging, because the
individual states are unknown and need to be learned from the noisy time
series. Simultaneously, the time series also needs to be precisely segmented
and each segment needs to be associated with a state. Here we develop
context-aware segmentation and clustering (CASC), a method for discovering
common motifs in time series data. We formulate the problem of motif discovery
as a large optimization problem, which we then solve using a greedy alternating
minimization-based approach. CASC performs well in the presence of noise in the
input data and is scalable to very large datasets. Furthermore, CASC leverages
common motifs to more robustly segment the time series and assign segments to
states. Experiments on synthetic data show that CASC outperforms
state-of-the-art baselines by up to 38.2%, and two case studies demonstrate how
our approach discovers insightful motifs in real-world time series data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jain_S/0/1/0/all/0/1&quot;&gt;Saachi Jain&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hallac_D/0/1/0/all/0/1&quot;&gt;David Hallac&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sosic_R/0/1/0/all/0/1&quot;&gt;Rok Sosic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leskovec_J/0/1/0/all/0/1&quot;&gt;Jure Leskovec&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.01843">
<title>How to Combine Tree-Search Methods in Reinforcement Learning. (arXiv:1809.01843v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1809.01843</link>
<description rdf:parseType="Literal">&lt;p&gt;Finite-horizon lookahead policies are abundantly used in Reinforcement
Learning and demonstrate impressive empirical success. Usually, the lookahead
policies are implemented with specific planning methods such as Monte Carlo
Tree Search (e.g. in AlphaZero). Referring to the planning problem as tree
search, a reasonable practice in these implementations is to back up the value
only at the leaves while the information obtained at the root is not leveraged
other than for updating the policy. Here, we question the potency of this
approach.Namely, the latter procedure is non-contractive in general, and its
convergence is not guaranteed. Our proposed enhancement is straightforward and
simple: use the return from the optimal tree path to back up the values at the
descendants of the root. This leads to a \gamma^h-contracting procedure, where
\gamma is the discount factor and $h$ is the tree depth. To establish our
results, we first introduce a notion called multiple-step greedy consistency.
We then provide convergence rates for two algorithmic instantiations of the
above enhancement in the presence of noise injected to both the tree search
stage and value estimation stage.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Efroni_Y/0/1/0/all/0/1&quot;&gt;Yonathan Efroni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dalal_G/0/1/0/all/0/1&quot;&gt;Gal Dalal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Scherrer_B/0/1/0/all/0/1&quot;&gt;Bruno Scherrer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mannor_S/0/1/0/all/0/1&quot;&gt;Shie Mannor&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.01852">
<title>GAMENet: Graph Augmented MEmory Networks for Recommending Medication Combination. (arXiv:1809.01852v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1809.01852</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent progress in deep learning is revolutionizing the healthcare domain
including providing solutions to medication recommendations, especially
recommending medication combination for patients with complex health
conditions. Existing approaches either do not customize based on patient health
history, or ignore existing knowledge on drug-drug interactions (DDI) that
might lead to adverse outcomes. To fill this gap, we propose the Graph
Augmented Memory Networks (GAMENet), which integrates the drug-drug
interactions knowledge graph by a memory module implemented as a graph
convolutional networks, and models longitudinal patient records as the query.
It is trained end-to-end to provide safe and personalized recommendation of
medication combination. We demonstrate the effectiveness and safety of GAMENet
by comparing with several state-of-the-art methods on real EHR data. GAMENet
outperformed all baselines in all effectiveness measures, and also achieved
3.60% DDI rate reduction from existing EHR data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shang_J/0/1/0/all/0/1&quot;&gt;Junyuan Shang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1&quot;&gt;Cao Xiao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_T/0/1/0/all/0/1&quot;&gt;Tengfei Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1&quot;&gt;Hongyan Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1&quot;&gt;Jimeng Sun&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.01898">
<title>Propheticus: Generalizable Machine Learning Framework. (arXiv:1809.01898v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1809.01898</link>
<description rdf:parseType="Literal">&lt;p&gt;Due to recent technological developments, Machine Learning (ML), a subfield
of Artificial Intelligence (AI), has been successfully used to process and
extract knowledge from a variety of complex problems. However, a thorough ML
approach is complex and highly dependent on the problem at hand. Additionally,
implementing the logic required to execute the experiments is no small nor
trivial deed, consequentially increasing the probability of faulty code which
can compromise the results. Propheticus is a data-driven framework which
results of the need for a tool that abstracts some of the inherent complexity
of ML, whilst being easy to understand and use, as well as to adapt and expand
to assist the user&apos;s specific needs. Propheticus systematizes and enforces
various complex concepts of an ML experiment workflow, taking into account the
nature of both the problem and the data. It contains functionalities to execute
all the different tasks, from data preprocessing, to results analysis and
comparison. Notwithstanding, it can be fairly easily adapted to different
problems due to its flexible architecture, and customized as needed to address
the user&apos;s needs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Campos_J/0/1/0/all/0/1&quot;&gt;Jo&amp;#xe3;o R. Campos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vieira_M/0/1/0/all/0/1&quot;&gt;Marco Vieira&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Costa_E/0/1/0/all/0/1&quot;&gt;Ernesto Costa&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.01926">
<title>One-shot Learning for iEEG Seizure Detection Using End-to-end Binary Operations: Local Binary Patterns with Hyperdimensional Computing. (arXiv:1809.01926v1 [eess.SP])</title>
<link>http://arxiv.org/abs/1809.01926</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents an efficient binarized algorithm for both learning and
classification of human epileptic seizures from intracranial
electroencephalography (iEEG). The algorithm combines local binary patterns
with brain-inspired hyperdimensional computing to enable end-to-end learning
and inference with binary operations. The algorithm first transforms iEEG time
series from each electrode into local binary pattern codes. Then atomic
high-dimensional binary vectors are used to construct composite representations
of seizures across all electrodes. For the majority of our patients (10 out of
16), the algorithm quickly learns from one or two seizures (i.e., one-/few-shot
learning) and perfectly generalizes on 27 further seizures. For other patients,
the algorithm requires three to six seizures for learning. Overall, our
algorithm surpasses the state-of-the-art methods for detecting 65 novel
seizures with higher specificity and sensitivity, and lower memory footprint.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Burrello_A/0/1/0/all/0/1&quot;&gt;Alessio Burrello&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Schindler_K/0/1/0/all/0/1&quot;&gt;Kaspar Schindler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Benini_L/0/1/0/all/0/1&quot;&gt;Luca Benini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Rahimi_A/0/1/0/all/0/1&quot;&gt;Abbas Rahimi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.01942">
<title>A tutorial on Particle Swarm Optimization Clustering. (arXiv:1809.01942v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1809.01942</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper proposes a tutorial on the Data Clustering technique using the
Particle Swarm Optimization approach. Following the work proposed by Merwe et
al. here we present an in-deep analysis of the algorithm together with a Matlab
implementation and a short tutorial that explains how to modify the proposed
implementation and the effect of the parameters of the original algorithm.
Moreover, we provide a comparison against the results obtained using the well
known K-Means approach. All the source code presented in this paper is publicly
available under the GPL-v2 license.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ballardini_A/0/1/0/all/0/1&quot;&gt;Augusto Luis Ballardini&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.01943">
<title>Cascaded Mutual Modulation for Visual Reasoning. (arXiv:1809.01943v1 [cs.IR])</title>
<link>http://arxiv.org/abs/1809.01943</link>
<description rdf:parseType="Literal">&lt;p&gt;Visual reasoning is a special visual question answering problem that is
multi-step and compositional by nature, and also requires intensive text-vision
interactions. We propose CMM: Cascaded Mutual Modulation as a novel end-to-end
visual reasoning model. CMM includes a multi-step comprehension process for
both question and image. In each step, we use a Feature-wise Linear Modulation
(FiLM) technique to enable textual/visual pipeline to mutually control each
other. Experiments show that CMM significantly outperforms most related models,
and reach state-of-the-arts on two visual reasoning benchmarks: CLEVR and NLVR,
collected from both synthetic and natural languages. Ablation studies confirm
that both our multistep framework and our visual-guided language modulation are
critical to the task. Our code is available at
https://github.com/FlamingHorizon/CMM-VR.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yao_Y/0/1/0/all/0/1&quot;&gt;Yiqun Yao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1&quot;&gt;Jiaming Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1&quot;&gt;Feng Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_B/0/1/0/all/0/1&quot;&gt;Bo Xu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.01991">
<title>Evaluation Measures for Quantification: An Axiomatic Approach. (arXiv:1809.01991v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1809.01991</link>
<description rdf:parseType="Literal">&lt;p&gt;Quantification is the task of estimating, given a set $\sigma$ of unlabelled
items and a set of classes $\mathcal{C}=\{c_{1}, \ldots, c_{|\mathcal{C}|}\}$,
the prevalence (or `relative frequency&apos;) in $\sigma$ of each class $c_{i}\in
\mathcal{C}$. While quantification may in principle be solved by classifying
each item in $\sigma$ and counting how many such items have been labelled with
$c_{i}$, it has long been shown that this `classify and count&apos; (CC) method
yields suboptimal quantification accuracy. As a result, quantification is no
longer considered a mere byproduct of classification, and has evolved as a task
of its own. While the scientific community has devoted a lot of attention to
devising more accurate quantification methods, it has not devoted much to
discussing what properties an \emph{evaluation measure for quantification}
(EMQ) should enjoy, and which EMQs should be adopted as a result. This paper
lies down a number of interesting properties that an EMQ may or may not enjoy,
discusses if (and when) each of these properties is desirable, surveys the EMQs
that have been used so far, and discusses whether they enjoy or not the above
properties. As a result of this investigation, some of the EMQs that have been
used in the literature turn out to be severely unfit, while others emerge as
closer to what the quantification community actually needs. However, a
significant result is that no existing EMQ satisfies all the properties
identified as desirable, thus indicating that more research is needed in order
to identify (or synthesize) a truly adequate EMQ.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sebastiani_F/0/1/0/all/0/1&quot;&gt;Fabrizio Sebastiani&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.02040">
<title>Exploring Graph-structured Passage Representation for Multi-hop Reading Comprehension with Graph Neural Networks. (arXiv:1809.02040v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1809.02040</link>
<description rdf:parseType="Literal">&lt;p&gt;Multi-hop reading comprehension focuses on one type of factoid question,
where a system needs to properly integrate multiple pieces of evidence to
correctly answer a question. Previous work approximates global evidence with
local coreference information, encoding coreference chains with DAG-styled GRU
layers within a gated-attention reader. However, coreference is limited in
providing information for rich inference. We introduce a new method for better
connecting global evidence, which forms more complex graphs compared to DAGs.
To perform evidence integration on our graphs, we investigate two recent graph
neural networks, namely graph convolutional network (GCN) and graph recurrent
network (GRN). Experiments on two standard datasets show that richer global
information leads to better answers. Our method performs better than all
published results on these datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_L/0/1/0/all/0/1&quot;&gt;Linfeng Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zhiguo Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_M/0/1/0/all/0/1&quot;&gt;Mo Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yue Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Florian_R/0/1/0/all/0/1&quot;&gt;Radu Florian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gildea_D/0/1/0/all/0/1&quot;&gt;Daniel Gildea&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.02070">
<title>ARCHER: Aggressive Rewards to Counter bias in Hindsight Experience Replay. (arXiv:1809.02070v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1809.02070</link>
<description rdf:parseType="Literal">&lt;p&gt;Experience replay is an important technique for addressing
sample-inefficiency in deep reinforcement learning (RL), but faces difficulty
in learning from binary and sparse rewards due to disproportionately few
successful experiences in the replay buffer. Hindsight experience replay (HER)
was recently proposed to tackle this difficulty by manipulating unsuccessful
transitions, but in doing so, HER introduces a significant bias in the replay
buffer experiences and therefore achieves a suboptimal improvement in
sample-efficiency. In this paper, we present an analysis on the source of bias
in HER, and propose a simple and effective method to counter the bias, to most
effectively harness the sample-efficiency provided by HER. Our method,
motivated by counter-factual reasoning and called ARCHER, extends HER with a
trade-off to make rewards calculated for hindsight experiences numerically
greater than real rewards. We validate our algorithm on two continuous control
environments from DeepMind Control Suite - Reacher and Finger, which simulate
manipulation tasks with a robotic arm - in combination with various reward
functions, task complexities and goal sampling strategies. Our experiments
consistently demonstrate that countering bias using more aggressive hindsight
rewards increases sample efficiency, thus establishing the greater benefit of
ARCHER in RL applications with limited computing budget.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lanka_S/0/1/0/all/0/1&quot;&gt;Sameera Lanka&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_T/0/1/0/all/0/1&quot;&gt;Tianfu Wu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1708.01867">
<title>Regularised Deep Reinforcement Learning with Guaranteed Convergence. (arXiv:1708.01867v4 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1708.01867</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep Q-networks (DQNs) suffer from two important challenges hindering their
application in real-world scenarios. First, DQNs overestimate Q-values which
leads to increased sample complexity, and second, no theoretical convergence
guarantees have been established. In this paper, we address both problems by
introducing an intrinsic penalty signal arising from a Kullback-Leibler (KL)
constraint that encourages reduced Q-value estimates. We then prove, for the
first time, convergence to a stationary point under a specific scheduling of
the penalisation magnitude. Our proofs operate in the deep reinforcement
learning setting that considers convolutional and dense layers for Q-function
approximation. Furthermore, we prove divergence of standard DQNs using a
counter example that relates to the non-optimal choice of the
history-scheduling parameter adopted by `vanilla&apos; DQNs. We believe this can
shed the light on some of the difficulties reported by researchers and
practitioners in the field.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leibfried_F/0/1/0/all/0/1&quot;&gt;Felix Leibfried&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tutunov_R/0/1/0/all/0/1&quot;&gt;Rasul Tutunov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grau_Moya_J/0/1/0/all/0/1&quot;&gt;Jordi Grau-Moya&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bou_Ammar_H/0/1/0/all/0/1&quot;&gt;Haitham Bou-Ammar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.06196">
<title>Online algorithms for POMDPs with continuous state, action, and observation spaces. (arXiv:1709.06196v6 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1709.06196</link>
<description rdf:parseType="Literal">&lt;p&gt;Online solvers for partially observable Markov decision processes have been
applied to problems with large discrete state spaces, but continuous state,
action, and observation spaces remain a challenge. This paper begins by
investigating double progressive widening (DPW) as a solution to this
challenge. However, we prove that this modification alone is not sufficient
because the belief representations in the search tree collapse to a single
particle causing the algorithm to converge to a policy that is suboptimal
regardless of the computation time. This paper proposes and evaluates two new
algorithms, POMCPOW and PFT-DPW, that overcome this deficiency by using
weighted particle filtering. Simulation results show that these modifications
allow the algorithms to be successful where previous approaches fail.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sunberg_Z/0/1/0/all/0/1&quot;&gt;Zachary Sunberg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kochenderfer_M/0/1/0/all/0/1&quot;&gt;Mykel Kochenderfer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.06870">
<title>Object Ordering with Bidirectional Matchings for Visual Reasoning. (arXiv:1804.06870v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1804.06870</link>
<description rdf:parseType="Literal">&lt;p&gt;Visual reasoning with compositional natural language instructions, e.g.,
based on the newly-released Cornell Natural Language Visual Reasoning (NLVR)
dataset, is a challenging task, where the model needs to have the ability to
create an accurate mapping between the diverse phrases and the several objects
placed in complex arrangements in the image. Further, this mapping needs to be
processed to answer the question in the statement given the ordering and
relationship of the objects across three similar images. In this paper, we
propose a novel end-to-end neural model for the NLVR task, where we first use
joint bidirectional attention to build a two-way conditioning between the
visual information and the language phrases. Next, we use an RL-based pointer
network to sort and process the varying number of unordered objects (so as to
match the order of the statement phrases) in each of the three images and then
pool over the three decisions. Our model achieves strong improvements (of 4-6%
absolute) over the state-of-the-art on both the structured representation and
raw image versions of the dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tan_H/0/1/0/all/0/1&quot;&gt;Hao Tan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bansal_M/0/1/0/all/0/1&quot;&gt;Mohit Bansal&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.11112">
<title>Is One Hyperparameter Optimizer Enough?. (arXiv:1807.11112v3 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1807.11112</link>
<description rdf:parseType="Literal">&lt;p&gt;Hyperparameter tuning is the black art of automatically finding a good
combination of control parameters for a data miner. While widely applied in
empirical Software Engineering, there has not been much discussion on which
hyperparameter tuner is best for software analytics. To address this gap in the
literature, this paper applied a range of hyperparameter optimizers (grid
search, random search, differential evolution, and Bayesian optimization) to
defect prediction problem. Surprisingly, no hyperparameter optimizer was
observed to be `best&apos; and, for one of the two evaluation measures studied here
(F-measure), hyperparameter optimization, in 50\% cases, was no better than
using default configurations.
&lt;/p&gt;
&lt;p&gt;We conclude that hyperparameter optimization is more nuanced than previously
believed. While such optimization can certainly lead to large improvements in
the performance of classifiers used in software analytics, it remains to be
seen which specific optimizers should be applied to a new dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tu_H/0/1/0/all/0/1&quot;&gt;Huy Tu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nair_V/0/1/0/all/0/1&quot;&gt;Vivek Nair&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.03096">
<title>On feature selection and evaluation of transportation mode prediction strategies. (arXiv:1808.03096v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1808.03096</link>
<description rdf:parseType="Literal">&lt;p&gt;Transportation modes prediction is a fundamental task for decision making in
smart cities and traffic management systems. Traffic policies designed based on
trajectory mining can save money and time for authorities and the public. It
may reduce the fuel consumption and commute time and moreover, may provide more
pleasant moments for residents and tourists. Since the number of features that
may be used to predict a user transportation mode can be substantial, finding a
subset of features that maximizes a performance measure is worth investigating.
In this work, we explore wrapper and information retrieval methods to find the
best subset of trajectory features. After finding the best classifier and the
best feature subset, our results were compared with two related papers that
applied deep learning methods and the results showed that our framework
achieved better performance. Furthermore, two types of cross-validation
approaches were investigated, and the performance results show that the random
cross-validation method provides optimistic results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Etemad_M/0/1/0/all/0/1&quot;&gt;Mohammad Etemad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Junior_A/0/1/0/all/0/1&quot;&gt;Amilcar Soares Junior&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Matwin_S/0/1/0/all/0/1&quot;&gt;Stan Matwin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.11284">
<title>Deep Recurrent Neural Networks for Product Attribute Extraction in eCommerce. (arXiv:1803.11284v1 [cs.CL] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1803.11284</link>
<description rdf:parseType="Literal">&lt;p&gt;Extracting accurate attribute qualities from product titles is a vital
component in delivering eCommerce customers with a rewarding online shopping
experience via an enriched faceted search. We demonstrate the potential of Deep
Recurrent Networks in this domain, primarily models such as Bidirectional LSTMs
and Bidirectional LSTM-CRF with or without an attention mechanism. These have
improved overall F1 scores, as compared to the previous benchmarks (More et
al.) by at least 0.0391, showcasing an overall precision of 97.94%, recall of
94.12% and the F1 score of 0.9599. This has made us achieve a significant
coverage of important facets or attributes of products which not only shows the
efficacy of deep recurrent models over previous machine learning benchmarks but
also greatly enhances the overall customer experience while shopping online.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Majumder_B/0/1/0/all/0/1&quot;&gt;Bodhisattwa Prasad Majumder&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Subramanian_A/0/1/0/all/0/1&quot;&gt;Aditya Subramanian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Krishnan_A/0/1/0/all/0/1&quot;&gt;Abhinandan Krishnan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gandhi_S/0/1/0/all/0/1&quot;&gt;Shreyansh Gandhi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+More_A/0/1/0/all/0/1&quot;&gt;Ajinkya More&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.00647">
<title>Automatic Event Salience Identification. (arXiv:1809.00647v1 [cs.AI] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1809.00647</link>
<description rdf:parseType="Literal">&lt;p&gt;Identifying the salience (i.e. importance) of discourse units is an important
task in language understanding. While events play important roles in text
documents, little research exists on analyzing their saliency status. This
paper empirically studies the Event Salience task and proposes two salience
detection models based on content similarities and discourse relations. The
first is a feature based salience model that incorporates similarities among
discourse units. The second is a neural model that captures more complex
relations between discourse units. Tested on our new large-scale event salience
corpus, both methods significantly outperform the strong frequency baseline,
while our neural model further improves the feature based one by a large
margin. Our analyses demonstrate that our neural model captures interesting
connections between salience and discourse unit relations (e.g., scripts and
frame structures).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1&quot;&gt;Zhengzhong Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiong_C/0/1/0/all/0/1&quot;&gt;Chenyan Xiong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mitamura_T/0/1/0/all/0/1&quot;&gt;Teruko Mitamura&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hovy_E/0/1/0/all/0/1&quot;&gt;Eduard Hovy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.01697">
<title>HASP: A High-Performance Adaptive Mobile Security Enhancement Against Malicious Speech Recognition. (arXiv:1809.01697v1 [cs.CR])</title>
<link>http://arxiv.org/abs/1809.01697</link>
<description rdf:parseType="Literal">&lt;p&gt;Nowadays, machine learning based Automatic Speech Recognition (ASR) technique
has widely spread in smartphones, home devices, and public facilities. As
convenient as this technology can be, a considerable security issue also raises
-- the users&apos; speech content might be exposed to malicious ASR monitoring and
cause severe privacy leakage. In this work, we propose HASP -- a
high-performance security enhancement approach to solve this security issue on
mobile devices. Leveraging ASR systems&apos; vulnerability to the adversarial
examples, HASP is designed to cast human imperceptible adversarial noises to
real-time speech and effectively perturb malicious ASR monitoring by increasing
the Word Error Rate (WER). To enhance the practical performance on mobile
devices, HASP is also optimized for effective adaptation to the human speech
characteristics, environmental noises, and mobile computation scenarios. The
experiments show that HASP can achieve optimal real-time security enhancement:
it can lead an average WER of 84.55% for perturbing the malicious ASR
monitoring, and the data processing speed is 15x to 40x faster compared to the
state-of-the-art methods. Moreover, HASP can effectively perturb various ASR
systems, demonstrating a strong transferability.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1&quot;&gt;Zirui Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_F/0/1/0/all/0/1&quot;&gt;Fuxun Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1&quot;&gt;Chenchen Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1&quot;&gt;Xiang Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.01706">
<title>A Limitation of V-Matrix based Methods. (arXiv:1809.01706v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1809.01706</link>
<description rdf:parseType="Literal">&lt;p&gt;To estimate the conditional probability functions based on the direct problem
setting, V-matrix based method was proposed. We construct V-matrix based
constrained quadratic programming problems for which the inequality constraints
are inconsistent. In particular, we would like to present that the constrained
quadratic optimization problem for conditional probability estimation using
V-matrix method may not have a consistent solution always.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gauraha_N/0/1/0/all/0/1&quot;&gt;Niharika Gauraha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chaturvedi_A/0/1/0/all/0/1&quot;&gt;Akshay Chaturvedi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.01712">
<title>Controlled Random Search Improves Sample Mining and Hyper-Parameter Optimization. (arXiv:1809.01712v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1809.01712</link>
<description rdf:parseType="Literal">&lt;p&gt;A common challenge in machine learning and related fields is the need to
efficiently explore high dimensional parameter spaces using small numbers of
samples. Typical examples are hyper-parameter optimization in deep learning and
sample mining in predictive modeling tasks. All such problems trade-off
exploration, which samples the space without knowledge of the target function,
and exploitation where information from previous evaluations is used in an
adaptive feedback loop. Much of the recent focus has been on the exploitation
while exploration is done with simple designs such as Latin hypercube or even
uniform random sampling. In this paper, we introduce optimal space-filling
sample designs for effective exploration of high dimensional spaces.
Specifically, we propose a new parameterized family of sample designs called
space-filling spectral designs, and introduce a framework to choose optimal
designs for a given sample size and dimension. Furthermore, we present an
efficient algorithm to synthesize a given spectral design. Finally, we evaluate
the performance of spectral designs in both data space and model space
applications. The data space exploration is targeted at recovering complex
regression functions in high dimensional spaces. The model space exploration
focuses on selecting hyper-parameters for a given neural network architecture.
Our empirical studies demonstrate that the proposed approach consistently
outperforms state-of-the-art techniques, particularly with smaller design
sizes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Muniraju_G/0/1/0/all/0/1&quot;&gt;Gowtham Muniraju&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kailkhura_B/0/1/0/all/0/1&quot;&gt;Bhavya Kailkhura&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Thiagarajan_J/0/1/0/all/0/1&quot;&gt;Jayaraman J. Thiagarajan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bremer_P/0/1/0/all/0/1&quot;&gt;Peer-Timo Bremer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.01728">
<title>Attention-based Audio-Visual Fusion for Robust Automatic Speech Recognition. (arXiv:1809.01728v1 [eess.AS])</title>
<link>http://arxiv.org/abs/1809.01728</link>
<description rdf:parseType="Literal">&lt;p&gt;Automatic speech recognition can potentially benefit from the lip motion
patterns, complementing acoustic speech to improve the overall recognition
performance, particularly in noise. In this paper we propose an audio-visual
fusion strategy that goes beyond simple feature concatenation and learns to
automatically align the two modalities, leading to enhanced representations
which increase the recognition accuracy in both clean and noisy conditions. We
test our strategy on the TCD-TIMIT and LRS2 datasets, designed for large
vocabulary continuous speech recognition, applying three types of noise at
different power ratios. We also exploit state of the art Sequence-to-Sequence
architectures, showing that our method can be easily integrated. Results show
relative improvements from 7% up to 30% on TCD-TIMIT over the acoustic modality
alone, depending on the acoustic noise level. We anticipate that the fusion
strategy can easily generalise to many other multimodal tasks which involve
correlated modalities.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Sterpu_G/0/1/0/all/0/1&quot;&gt;George Sterpu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Saam_C/0/1/0/all/0/1&quot;&gt;Christian Saam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Harte_N/0/1/0/all/0/1&quot;&gt;Naomi Harte&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.01733">
<title>Deep Joint Source-Channel Coding for Wireless Image Transmission. (arXiv:1809.01733v1 [cs.IT])</title>
<link>http://arxiv.org/abs/1809.01733</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a joint source and channel coding (JSCC) technique for wireless
image transmission that does not rely on explicit codes for either compression
or error correction; instead, it directly maps the image pixel values to the
real/complex - valued channel input symbols. We parameterize the encoder and
decoder functions by two convolutional neural networks (CNNs), which are
trained jointly, and can be considered as an autoencoder with a non-trainable
layer in the middle that represents the noisy communication channel. Our
results show that the proposed deep JSCC scheme outperforms digital
transmission concatenating JPEG or JPEG2000 compression with a capacity
achieving channel code at low signal-to-noise ratio (SNR) and channel bandwidth
values in the presence of additive white Gaussian noise. More strikingly, deep
JSCC does not suffer from the `cliff effect&apos;, and it provides a graceful
performance degradation as the channel SNR varies with respect to the training
SNR. In the case of a slow Rayleigh fading channel, deep JSCC can learn to
communicate without explicit pilot signals or channel estimation, and
significantly outperforms separation-based digital communication at all SNR and
channel bandwidth values.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bourtsoulatze_E/0/1/0/all/0/1&quot;&gt;Eirina Bourtsoulatze&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kurka_D/0/1/0/all/0/1&quot;&gt;David Burth Kurka&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gunduz_D/0/1/0/all/0/1&quot;&gt;Deniz Gunduz&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.01738">
<title>Recovering a Single Community with Side Information. (arXiv:1809.01738v1 [cs.IT])</title>
<link>http://arxiv.org/abs/1809.01738</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the effect of the quality and quantity of side information on the
recovery of a hidden community of size $K=o(n)$ in a graph of size $n$. Side
information for each node in the graph is modeled by a random vector with the
following features: either the dimension of the vector is allowed to vary with
$n$, while log-likelihood ratio (LLR) of each component with respect to the
node label is fixed, or the LLR is allowed to vary and the vector dimension is
fixed. These two models represent the variation in quality and quantity of side
information. Under maximum likelihood detection, we calculate tight necessary
and sufficient conditions for exact recovery of the labels. We demonstrate how
side information needs to evolve with $n$ in terms of either its quantity, or
quality, to improve the exact recovery threshold. A similar set of results are
obtained for weak recovery. Under belief propagation, tight necessary and
sufficient conditions for weak recovery are calculated when the LLRs are
constant, and sufficient conditions when the LLRs vary with $n$. Moreover, we
design and analyze a local voting procedure using side information that can
achieve exact recovery when applied after belief propagation. The results for
belief propagation are validated via simulations on finite synthetic data-sets,
showing that the asymptotic results of this paper can also shed light on the
performance at finite $n$.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saad_H/0/1/0/all/0/1&quot;&gt;Hussein Saad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nosratinia_A/0/1/0/all/0/1&quot;&gt;Aria Nosratinia&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.01740">
<title>Predicting Smoking Events with a Time-Varying Semi-Parametric Hawkes Process Model. (arXiv:1809.01740v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1809.01740</link>
<description rdf:parseType="Literal">&lt;p&gt;Health risks from cigarette smoking -- the leading cause of preventable death
in the United States -- can be substantially reduced by quitting. Although most
smokers are motivated to quit, the majority of quit attempts fail. A number of
studies have explored the role of self-reported symptoms, physiologic
measurements, and environmental context on smoking risk, but less work has
focused on the temporal dynamics of smoking events, including daily patterns
and related nicotine effects. In this work, we examine these dynamics and
improve risk prediction by modeling smoking as a self-triggering process, in
which previous smoking events modify current risk. Specifically, we fit smoking
events self-reported by 42 smokers to a time-varying semi-parametric Hawkes
process (TV-SPHP) developed for this purpose. Results show that the TV-SPHP
achieves superior prediction performance compared to related and existing
models, with the incorporation of time-varying predictors having greatest
benefit over longer prediction windows. Moreover, the impact function
illustrates previously unknown temporal dynamics of smoking, with possible
connections to nicotine metabolism to be explored in future work through a
randomized study design. By more effectively predicting smoking events and
exploring a self-triggering component of smoking risk, this work supports
development of novel or improved cessation interventions that aim to reduce
death from smoking.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Engelhard_M/0/1/0/all/0/1&quot;&gt;Matthew Engelhard&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Xu_H/0/1/0/all/0/1&quot;&gt;Hongteng Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Carin_L/0/1/0/all/0/1&quot;&gt;Lawrence Carin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Oliver_J/0/1/0/all/0/1&quot;&gt;Jason A Oliver&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hallyburton_M/0/1/0/all/0/1&quot;&gt;Matthew Hallyburton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+McClernon_F/0/1/0/all/0/1&quot;&gt;F Joseph McClernon&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.01772">
<title>Multi-view Factorization AutoEncoder with Network Constraints for Multi-omic Integrative Analysis. (arXiv:1809.01772v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1809.01772</link>
<description rdf:parseType="Literal">&lt;p&gt;Multi-omic data provides multiple views of the same patients. Integrative
analysis of multi-omic data is crucial to elucidate the molecular underpinning
of disease etiology. However, multi-omic data has the &quot;big p, small N&quot; problem
(the number of features is large, but the number of samples is small), it is
challenging to train a complicated machine learning model from the multi-omic
data alone and make it generalize well. Here we propose a framework termed
Multi-view Factorization AutoEncoder with network constraints to integrate
multi-omic data with domain knowledge (biological interactions networks). Our
framework employs deep representation learning to learn feature embeddings and
patient embeddings simultaneously, enabling us to integrate feature interaction
network and patient view similarity network constraints into the training
objective. The whole framework is end-to-end differentiable. We applied our
approach to the TCGA Pan-cancer dataset and achieved satisfactory results to
predict disease progression-free interval (PFI) and patient overall survival
(OS) events. Code will be made publicly available.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_T/0/1/0/all/0/1&quot;&gt;Tianle Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_A/0/1/0/all/0/1&quot;&gt;Aidong Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.01796">
<title>Optimal Sparse Singular Value Decomposition for High-dimensional High-order Data. (arXiv:1809.01796v1 [math.ST])</title>
<link>http://arxiv.org/abs/1809.01796</link>
<description rdf:parseType="Literal">&lt;p&gt;In this article, we consider the sparse tensor singular value decomposition,
which aims for dimension reduction on high-dimensional high-order data with
certain sparsity structure. A method named \underline{s}parse
\underline{t}ensor \underline{a}lternating \underline{t}hresholding for
\underline{s}ingular \underline{v}alue \underline{d}ecomposition (STAT-SVD) is
proposed. The proposed procedure features a novel double projection \&amp;amp;
thresholding scheme, which provides a sharp criterion for thresholding in each
iteration. Compared with regular tensor SVD model, STAT-SVD permits more robust
estimation under weaker assumptions. Both the upper and lower bounds for
estimation accuracy are developed. The proposed procedure is shown to be
minimax rate-optimal in a general class of situations. Simulation studies show
that STAT-SVD performs well under a variety of configurations. We also
illustrate the merits of the proposed procedure on a longitudinal tensor
dataset on European country mortality rates.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Zhang_A/0/1/0/all/0/1&quot;&gt;Anru Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Han_R/0/1/0/all/0/1&quot;&gt;Rungang Han&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.01804">
<title>Discovering Influential Factors in Variational Autoencoder. (arXiv:1809.01804v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1809.01804</link>
<description rdf:parseType="Literal">&lt;p&gt;In the field of machine learning, it is still a critical issue to identify
and supervise the learned representation without manually intervention or
intuition assistance to extract useful knowledge or serve for the latter tasks
in machine learning. In this work, we focus on supervising the influential
factors extracted by the variational autoencoder(VAE). The VAE is proposed to
learn independent low dimension representation while facing the problem that
sometimes pre-set factors are ignored. We argue that the mutual information of
the input and each learned factor of the representation plays a necessary
indicator. We find the VAE objective inclines to induce mutual information
sparsity in factor dimension over the data intrinsic dimension and results in
some non-influential factors whose function on data reconstruction could be
ignored. We show mutual information also influences the lower bound of VAE&apos;s
reconstruction error and latter classification task. To make such indicator
applicable, we design an algorithm on calculating the mutual information for
VAE and prove its consistency. Experimental results on Mnist, CelebA and Deap
datasets show that mutual information can help determine influential factors,
of which some are interpretable and can be used to further generation and
classification tasks, and help discover the variant that connects with emotion
on Deap dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1&quot;&gt;Shiqi Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Jingxin Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_Q/0/1/0/all/0/1&quot;&gt;Qian Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cao_X/0/1/0/all/0/1&quot;&gt;Xiangyong Cao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1&quot;&gt;Huibin Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meng_H/0/1/0/all/0/1&quot;&gt;Hongying Meng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1&quot;&gt;Sheng Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meng_D/0/1/0/all/0/1&quot;&gt;Deyu Meng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.01817">
<title>Online Adaptive Image Reconstruction (OnAIR) Using Dictionary Models. (arXiv:1809.01817v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1809.01817</link>
<description rdf:parseType="Literal">&lt;p&gt;Sparsity and low-rank models have been popular for reconstructing images and
videos from limited or corrupted measurements. Dictionary or transform learning
methods are useful in applications such as denoising, inpainting, and medical
image reconstruction. This paper proposes a framework for online (or
time-sequential) adaptive reconstruction of dynamic image sequences from linear
(typically undersampled) measurements. We model the spatiotemporal patches of
the underlying dynamic image sequence as sparse in a dictionary, and we
simultaneously estimate the dictionary and the images sequentially from
streaming measurements. Multiple constraints on the adapted dictionary are also
considered such as a unitary matrix, or low-rank dictionary atoms that provide
additional efficiency or robustness. The proposed online algorithms are memory
efficient and involve simple updates of the dictionary atoms, sparse
coefficients, and images. Numerical experiments demonstrate the usefulness of
the proposed methods in inverse problems such as video reconstruction or
inpainting from noisy, subsampled pixels, and dynamic magnetic resonance image
reconstruction from very limited measurements.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Moore_B/0/1/0/all/0/1&quot;&gt;Brian E. Moore&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ravishankar_S/0/1/0/all/0/1&quot;&gt;Saiprasad Ravishankar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Nadakuditi_R/0/1/0/all/0/1&quot;&gt;Raj Rao Nadakuditi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Fessler_J/0/1/0/all/0/1&quot;&gt;Jeffrey A. Fessler&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.01818">
<title>Improving Explorability in Variational Inference with Annealed Variational Objectives. (arXiv:1809.01818v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1809.01818</link>
<description rdf:parseType="Literal">&lt;p&gt;Despite the advances in the representational capacity of approximate
distributions for variational inference, the optimization process can still
limit the density that is ultimately learned. We demonstrate the drawbacks of
biasing the true posterior to be unimodal, and introduce Annealed Variational
Objectives (AVO) into the training of hierarchical variational methods.
Inspired by Annealed Importance Sampling, the proposed method facilitates
learning by incorporating energy tempering into the optimization objective. In
our experiments, we demonstrate our method&apos;s robustness to deterministic warm
up, and the benefits of encouraging exploration in the latent space.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_C/0/1/0/all/0/1&quot;&gt;Chin-Wei Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tan_S/0/1/0/all/0/1&quot;&gt;Shawn Tan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lacoste_A/0/1/0/all/0/1&quot;&gt;Alexandre Lacoste&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Courville_A/0/1/0/all/0/1&quot;&gt;Aaron Courville&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.01859">
<title>Deep Learning-Based Decoding for Constrained Sequence Codes. (arXiv:1809.01859v1 [cs.IT])</title>
<link>http://arxiv.org/abs/1809.01859</link>
<description rdf:parseType="Literal">&lt;p&gt;Constrained sequence codes have been widely used in modern communication and
data storage systems. Sequences encoded with constrained sequence codes satisfy
constraints imposed by the physical channel, hence enabling efficient and
reliable transmission of coded symbols. Traditional encoding and decoding of
constrained sequence codes rely on table look-up, which is prone to errors that
occur during transmission. In this paper, we introduce constrained sequence
decoding based on deep learning. With multiple layer perception (MLP) networks
and convolutional neural networks (CNNs), we are able to achieve low bit error
rates that are close to maximum a posteriori probability (MAP) decoding as well
as improve the system throughput. Moreover, implementation of
capacity-achieving fixed-length codes, where the complexity is prohibitively
high with table look-up decoding, becomes practical with deep learning-based
decoding.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cao_C/0/1/0/all/0/1&quot;&gt;Congzhe Cao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1&quot;&gt;Duanshun Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fair_I/0/1/0/all/0/1&quot;&gt;Ivan Fair&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.01890">
<title>Full-body High-resolution Anime Generation with Progressive Structure-conditional Generative Adversarial Networks. (arXiv:1809.01890v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1809.01890</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose Progressive Structure-conditional Generative Adversarial Networks
(PSGAN), a new framework that can generate full-body and high-resolution
character images based on structural information. Recent progress in generative
adversarial networks with progressive training has made it possible to generate
high-resolution images. However, existing approaches have limitations in
achieving both high image quality and structural consistency at the same time.
Our method tackles the limitations by progressively increasing the resolution
of both generated images and structural conditions during training. In this
paper, we empirically demonstrate the effectiveness of this method by showing
the comparison with existing approaches and video generation results of diverse
anime characters at 1024x1024 based on target pose sequences. We also create a
novel dataset containing full-body 1024x1024 high-resolution images and exact
2D pose keypoints using Unity 3D Avatar models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hamada_K/0/1/0/all/0/1&quot;&gt;Koichi Hamada&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tachibana_K/0/1/0/all/0/1&quot;&gt;Kentaro Tachibana&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1&quot;&gt;Tianqi Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Honda_H/0/1/0/all/0/1&quot;&gt;Hiroto Honda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Uchida_Y/0/1/0/all/0/1&quot;&gt;Yusuke Uchida&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.01906">
<title>Model-Based Stabilisation of Deep Reinforcement Learning. (arXiv:1809.01906v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1809.01906</link>
<description rdf:parseType="Literal">&lt;p&gt;Though successful in high-dimensional domains, deep reinforcement learning
exhibits high sample complexity and suffers from stability issues as reported
by researchers and practitioners in the field. These problems hinder the
application of such algorithms in real-world and safety-critical scenarios. In
this paper, we take steps towards stable and efficient reinforcement learning
by following a model-based approach that is known to reduce agent-environment
interactions. Namely, our method augments deep Q-networks (DQNs) with model
predictions for transitions, rewards, and termination flags.
&lt;/p&gt;
&lt;p&gt;Having the model at hand, we then conduct a rigorous theoretical study of our
algorithm and show, for the first time, convergence to a stationary point. En
route, we provide a counter-example showing that &apos;vanilla&apos; DQNs can diverge
confirming practitioners&apos; and researchers&apos; experiences. Our proof is novel in
its own right and can be extended to other forms of deep reinforcement
learning. In particular, we believe exploiting the relation between
reinforcement (with deep function approximators) and online learning can serve
as a recipe for future proofs in the domain. Finally, we validate our
theoretical results in 20 games from the Atari benchmark. Our results show that
following the proposed model-based learning approach not only ensures
convergence but leads to a reduction in sample complexity and superior
performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leibfried_F/0/1/0/all/0/1&quot;&gt;Felix Leibfried&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tutunov_R/0/1/0/all/0/1&quot;&gt;Rasul Tutunov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vrancx_P/0/1/0/all/0/1&quot;&gt;Peter Vrancx&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bou_Ammar_H/0/1/0/all/0/1&quot;&gt;Haitham Bou-Ammar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.01921">
<title>RDPD: Rich Data Helps Poor Data via Imitation. (arXiv:1809.01921v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1809.01921</link>
<description rdf:parseType="Literal">&lt;p&gt;In many situations, we have both rich- and poor- data environments: in a
rich-data environment (e.g., intensive care units), we have high-quality
multi-modality data. On the other hand, in a poor-data environment (e.g., at
home), we often only have access to a single data modality with low quality.
How can we learn an accurate and efficient model for the poor-data environment
by leveraging multi-modality data from the rich-data environment? In this work,
we propose a knowledge distillation model RDPD to enhance a small model trained
on poor data with a complex model trained on rich data. In an end-to-end
fashion, RDPD trains a student model built on a single modality data (poor
data) to imitate the behavior and performance of a teacher model from
multimodal data (rich data) via jointly optimizing the combined loss of
attention imitation and target imitation. We evaluated RDPD on three real-world
datasets. RDPD consistently outperformed all baselines across all three
datasets, especially achieving the greatest performance improvement over a
standard neural network model trained on the common features (Direct model) by
24.56% on PR-AUC and 12.21% on ROC-AUC, and over the standard knowledge
distillation model by 5.91% on PR-AUC and 4.44% on ROC-AUC.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hong_S/0/1/0/all/0/1&quot;&gt;Shenda Hong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1&quot;&gt;Cao Xiao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_T/0/1/0/all/0/1&quot;&gt;Tengfei Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1&quot;&gt;Hongyan Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1&quot;&gt;Jimeng Sun&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.02010">
<title>Gaussian Process Regression for Binned Data. (arXiv:1809.02010v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1809.02010</link>
<description rdf:parseType="Literal">&lt;p&gt;Many datasets are in the form of tables of binned data. Performing regression
on these data usually involves either reading off bin heights, ignoring data
from neighbouring bins or interpolating between bins thus over or
underestimating the true bin integrals.
&lt;/p&gt;
&lt;p&gt;In this paper we propose an elegant method for performing Gaussian Process
(GP) regression given such binned data, allowing one to make probabilistic
predictions of the latent function which produced the binned data.
&lt;/p&gt;
&lt;p&gt;We look at several applications. First, for differentially private
regression; second, to make predictions over other integrals; and third when
the input regions are irregularly shaped collections of polytopes.
&lt;/p&gt;
&lt;p&gt;In summary, our method provides an effective way of analysing binned data
such that one can use more information from the histogram representation, and
thus reconstruct a more useful and precise density for making predictions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Smith_M/0/1/0/all/0/1&quot;&gt;Michael Thomas Smith&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Alvarez_M/0/1/0/all/0/1&quot;&gt;Mauricio A Alvarez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lawrence_N/0/1/0/all/0/1&quot;&gt;Neil D Lawrence&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.02052">
<title>Eigenvalue analogy for confidence estimation in item-based recommender systems. (arXiv:1809.02052v1 [cs.IR])</title>
<link>http://arxiv.org/abs/1809.02052</link>
<description rdf:parseType="Literal">&lt;p&gt;Item-item collaborative filtering (CF) models are a well known and studied
family of recommender systems, however current literature does not provide any
theoretical explanation of the conditions under which item-based
recommendations will succeed or fail.
&lt;/p&gt;
&lt;p&gt;We investigate the existence of an ideal item-based CF method able to make
perfect recommendations. This CF model is formalized as an eigenvalue problem,
where estimated ratings are equivalent to the true (unknown) ratings multiplied
by a user-specific eigenvalue of the similarity matrix. Preliminary experiments
show that the magnitude of the eigenvalue is proportional to the accuracy of
recommendations for that user and therefore it can provide reliable measure of
confidence.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dacrema_M/0/1/0/all/0/1&quot;&gt;Maurizio Ferrari Dacrema&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cremonesi_P/0/1/0/all/0/1&quot;&gt;Paolo Cremonesi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.02066">
<title>Two Dimensional Stochastic Configuration Networks for Image Data Analytics. (arXiv:1809.02066v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1809.02066</link>
<description rdf:parseType="Literal">&lt;p&gt;Stochastic configuration networks (SCNs) as a class of randomized learner
model have been successfully employed in data analytics due to its universal
approximation capability and fast modelling property. The technical essence
lies in stochastically configuring hidden nodes (or basis functions) based on a
supervisory mechanism rather than data-independent randomization as usually
adopted for building randomized neural networks. Given image data modelling
tasks, the use of one-dimensional SCNs potentially demolishes the spatial
information of images, and may result in undesirable performance. This paper
extends the original SCNs to two-dimensional version, termed 2DSCNs, for fast
building randomized learners with matrix-inputs. Some theoretical analyses on
the goodness of 2DSCNs against SCNs, including the complexity of the random
parameter space, and the superiority of generalization, are presented.
Empirical results over one regression, four benchmark handwritten digits
classification, and two human face recognition datasets demonstrate that the
proposed 2DSCNs perform favourably and show good potential for image data
analytics.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1&quot;&gt;Ming Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1&quot;&gt;Dianhui Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.02069">
<title>Deep learning for in vitro prediction of pharmaceutical formulations. (arXiv:1809.02069v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1809.02069</link>
<description rdf:parseType="Literal">&lt;p&gt;Current pharmaceutical formulation development still strongly relies on the
traditional trial-and-error approach by individual experiences of
pharmaceutical scientists, which is laborious, time-consuming and costly.
Recently, deep learning has been widely applied in many challenging domains
because of its important capability of automatic feature extraction. The aim of
this research is to use deep learning to predict pharmaceutical formulations.
In this paper, two different types of dosage forms were chosen as model
systems. Evaluation criteria suitable for pharmaceutics were applied to
assessing the performance of the models. Moreover, an automatic dataset
selection algorithm was developed for selecting the representative data as
validation and test datasets. Six machine learning methods were compared with
deep learning. The result shows the accuracies of both two deep neural networks
were above 80% and higher than other machine learning models, which showed good
prediction in pharmaceutical formulations. In summary, deep learning with the
automatic data splitting algorithm and the evaluation criteria suitable for
pharmaceutical formulation data was firstly developed for the prediction of
pharmaceutical formulations. The cross-disciplinary integration of
pharmaceutics and artificial intelligence may shift the paradigm of
pharmaceutical researches from experience-dependent studies to data-driven
methodologies.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1&quot;&gt;Yilong Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ye_Z/0/1/0/all/0/1&quot;&gt;Zhuyifan Ye&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Su_Y/0/1/0/all/0/1&quot;&gt;Yan Su&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_Q/0/1/0/all/0/1&quot;&gt;Qianqian Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xiaoshan Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ouyang_D/0/1/0/all/0/1&quot;&gt;Defang Ouyang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.02105">
<title>A Memory-Network Based Solution for Multivariate Time-Series Forecasting. (arXiv:1809.02105v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1809.02105</link>
<description rdf:parseType="Literal">&lt;p&gt;Multivariate time series forecasting is extensively studied throughout the
years with ubiquitous applications in areas such as finance, traffic,
environment, etc. Still, concerns have been raised on traditional methods for
incapable of modeling complex patterns or dependencies lying in real word data.
To address such concerns, various deep learning models, mainly Recurrent Neural
Network (RNN) based methods, are proposed. Nevertheless, capturing extremely
long-term patterns while effectively incorporating information from other
variables remains a challenge for time-series forecasting. Furthermore,
lack-of-explainability remains one serious drawback for deep neural network
models. Inspired by Memory Network proposed for solving the question-answering
task, we propose a deep learning based model named Memory Time-series network
(MTNet) for time series forecasting. MTNet consists of a large memory
component, three separate encoders, and an autoregressive component to train
jointly. Additionally, the attention mechanism designed enable MTNet to be
highly interpretable. We can easily tell which part of the historic data is
referenced the most.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chang_Y/0/1/0/all/0/1&quot;&gt;Yen-Yu Chang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_F/0/1/0/all/0/1&quot;&gt;Fan-Yun Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1&quot;&gt;Yueh-Hua Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_S/0/1/0/all/0/1&quot;&gt;Shou-De Lin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1604.03887">
<title>Algorithms for stochastic optimization with expectation constraints. (arXiv:1604.03887v4 [math.OC] UPDATED)</title>
<link>http://arxiv.org/abs/1604.03887</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper considers the problem of minimizing an expectation function over a
closed convex set, coupled with a functional or expectation constraint on
either decision variables or problem parameters. We first present a new
stochastic approximation (SA) type algorithm, namely the cooperative SA (CSA),
to handle problems with the constraint on devision variables. We show that this
algorithm exhibits the optimal O(1/\epsilon^2 ) rate of convergence, in terms
of both optimality gap and constraint violation, when the objective and
constraint functions are generally convex, where ? denotes the optimality gap
and infeasibility. Moreover, we show that this rate of convergence can be
improved to O(1/\epsilon) if the objective and constraint functions are
strongly convex. We then present a variant of CSA, namely the cooperative
stochastic parameter approximation (CSPA) algorithm, to deal with the situation
when the constraint is defined over problem parameters and show that it
exhibits similar optimal rate of convergence to CSA. It is worth noting that
CSA and CSPA are primal methods which do not require the iterations on the dual
space and/or the estimation on the size of the dual variables. To the best of
our knowledge, this is the first time that such optimal SA methods for solving
functional and expectation constrained stochastic optimization are presented in
the literature.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Lan_G/0/1/0/all/0/1&quot;&gt;Guanghui Lan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Zhou_Z/0/1/0/all/0/1&quot;&gt;Zhiqiang Zhou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.05829">
<title>Non-Euclidean Conditional Expectation and Filtering. (arXiv:1710.05829v3 [q-fin.MF] UPDATED)</title>
<link>http://arxiv.org/abs/1710.05829</link>
<description rdf:parseType="Literal">&lt;p&gt;A non-Euclidean generalization of conditional expectation is introduced and
characterized as the minimizer of expected intrinsic squared-distance from a
manifold-valued target. The computational tractable formulation expresses the
non-convex optimization problem as transformations of Euclidean conditional
expectation. This gives computationally tractable filtering equations for the
dynamics of the intrinsic conditional expectation of a manifold-valued signal
and is used to obtain accurate numerical forecasts of efficient portfolios by
incorporating their geometric structure into the estimates.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-fin/1/au:+Kratsios_A/0/1/0/all/0/1&quot;&gt;Anastasis Kratsios&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-fin/1/au:+Hyndman_C/0/1/0/all/0/1&quot;&gt;Cody B. Hyndman&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09691">
<title>Link Prediction Based on Graph Neural Networks. (arXiv:1802.09691v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1802.09691</link>
<description rdf:parseType="Literal">&lt;p&gt;Link prediction is a key problem for network-structured data. Link prediction
heuristics use some score functions, such as common neighbors and Katz index,
to measure the likelihood of links. They have obtained wide practical uses due
to their simplicity, interpretability, and for some of them, scalability.
However, every heuristic has a strong assumption on when two nodes are likely
to link, which limits their effectiveness on networks where these assumptions
fail. In this regard, a more reasonable way should be learning a suitable
heuristic from a given network instead of using predefined ones. By extracting
a local subgraph around each target link, we aim to learn a function mapping
the subgraph patterns to link existence, thus automatically learning a
`heuristic&apos; that suits the current network. In this paper, we study this
heuristic learning paradigm for link prediction. First, we develop a novel
$\gamma$-decaying heuristic theory. The theory unifies a wide range of
heuristics in a single framework, and proves that all these heuristics can be
well approximated from local subgraphs. Our results show that local subgraphs
reserve rich information related to link existence. Second, based on the
$\gamma$-decaying theory, we propose a new algorithm to learn heuristics from
local subgraphs using a graph neural network (GNN). Its experimental results
show unprecedented performance, working consistently well on a wide range of
problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1&quot;&gt;Muhan Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yixin Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.08021">
<title>Error Estimation for Randomized Least-Squares Algorithms via the Bootstrap. (arXiv:1803.08021v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1803.08021</link>
<description rdf:parseType="Literal">&lt;p&gt;Over the course of the past decade, a variety of randomized algorithms have
been proposed for computing approximate least-squares (LS) solutions in
large-scale settings. A longstanding practical issue is that, for any given
input, the user rarely knows the actual error of an approximate solution
(relative to the exact solution). Likewise, it is difficult for the user to
know precisely how much computation is needed to achieve the desired error
tolerance. Consequently, the user often appeals to worst-case error bounds that
tend to offer only qualitative guidance. As a more practical alternative, we
propose a bootstrap method to compute a posteriori error estimates for
randomized LS algorithms. These estimates permit the user to numerically assess
the error of a given solution, and to predict how much work is needed to
improve a &quot;preliminary&quot; solution. In addition, we provide theoretical
consistency results for the method, which are the first such results in this
context (to the best of our knowledge). From a practical standpoint, the method
also has considerable flexibility, insofar as it can be applied to several
popular sketching algorithms, as well as a variety of error metrics. Moreover,
the extra step of error estimation does not add much cost to an underlying
sketching algorithm. Finally, we demonstrate the effectiveness of the method
with empirical results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lopes_M/0/1/0/all/0/1&quot;&gt;Miles E. Lopes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wang_S/0/1/0/all/0/1&quot;&gt;Shusen Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mahoney_M/0/1/0/all/0/1&quot;&gt;Michael W. Mahoney&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.05345">
<title>Data-Dependent Coresets for Compressing Neural Networks with Applications to Generalization Bounds. (arXiv:1804.05345v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1804.05345</link>
<description rdf:parseType="Literal">&lt;p&gt;We present an efficient coresets-based neural network compression algorithm
that provably sparsifies the parameters of a trained fully-connected neural
network in a manner that approximately preserves the network&apos;s output. Our
approach is based on an importance sampling scheme that judiciously defines a
sampling distribution over the neural network parameters, and as a result,
retains parameters of high importance while discarding redundant ones. We
leverage a novel, empirical notion of sensitivity and extend traditional
coreset constructions to the application of compressing parameters. Our
theoretical analysis establishes guarantees on the size and accuracy of the
resulting compressed neural network and gives rise to new generalization bounds
that may provide novel insights on the generalization properties of neural
networks. We demonstrate the practical effectiveness of our algorithm on a
variety of neural network configurations and real-world data sets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Baykal_C/0/1/0/all/0/1&quot;&gt;Cenk Baykal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liebenwein_L/0/1/0/all/0/1&quot;&gt;Lucas Liebenwein&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gilitschenski_I/0/1/0/all/0/1&quot;&gt;Igor Gilitschenski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feldman_D/0/1/0/all/0/1&quot;&gt;Dan Feldman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rus_D/0/1/0/all/0/1&quot;&gt;Daniela Rus&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.10111">
<title>Exploring Fast Algorithms for Composite Optimization with Serial and Asynchronous Realizations. (arXiv:1805.10111v2 [math.OC] UPDATED)</title>
<link>http://arxiv.org/abs/1805.10111</link>
<description rdf:parseType="Literal">&lt;p&gt;We provide a comprehensive analysis of stochastic variance reduced gradient
(SVRG) based proximal algorithms, both with and without momentum, in serial and
asynchronous realizations. Specifically, we propose the Prox-SVRG$^{++}$
algorithm, and prove that it has a linear convergence rate with a smaller epoch
length (than condition number). Then, we propose a momentum accelerated
algorithm, called Prox-MSVRG$^{++}$, and show that it achieves a complexity of
$O(\frac{1}{\sqrt{\epsilon}})$. After that, we develop two asynchronous
versions of the above serial algorithms and provide a general analysis under
nonconvex and non-strongly convex cases respectively. Our theoretical results
indicate that the algorithms can achieve a significant speedup when implemented
with multiple servers. We conduct extensive experiments based on $4$ real-world
datasets on an experiment platform with $11$ physical machines. The experiments
validate our theoretical findings and demonstrate the effectiveness of our
algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Yu_Y/0/1/0/all/0/1&quot;&gt;Yue Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Huang_L/0/1/0/all/0/1&quot;&gt;Longbo Huang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.01445">
<title>Embedding Logical Queries on Knowledge Graphs. (arXiv:1806.01445v2 [cs.SI] UPDATED)</title>
<link>http://arxiv.org/abs/1806.01445</link>
<description rdf:parseType="Literal">&lt;p&gt;Learning low-dimensional embeddings of knowledge graphs is a powerful
approach used to predict unobserved or missing edges between entities. However,
an open challenge in this area is developing techniques that can go beyond
simple edge prediction and handle more complex logical queries, which might
involve multiple unobserved edges, entities, and variables. For instance, given
an incomplete biological knowledge graph, we might want to predict &quot;em what
drugs are likely to target proteins involved with both diseases X and Y?&quot; -- a
query that requires reasoning about all possible proteins that {\em might}
interact with diseases X and Y. Here we introduce a framework to efficiently
make predictions about conjunctive logical queries -- a flexible but tractable
subset of first-order logic -- on incomplete knowledge graphs. In our approach,
we embed graph nodes in a low-dimensional space and represent logical operators
as learned geometric operations (e.g., translation, rotation) in this embedding
space. By performing logical operations within a low-dimensional embedding
space, our approach achieves a time complexity that is linear in the number of
query variables, compared to the exponential complexity required by a naive
enumeration-based approach. We demonstrate the utility of this framework in two
application studies on real-world datasets with millions of relations:
predicting logical relationships in a network of drug-gene-disease interactions
and in a graph-based representation of social interactions derived from a
popular web forum.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hamilton_W/0/1/0/all/0/1&quot;&gt;William L. Hamilton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bajaj_P/0/1/0/all/0/1&quot;&gt;Payal Bajaj&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zitnik_M/0/1/0/all/0/1&quot;&gt;Marinka Zitnik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jurafsky_D/0/1/0/all/0/1&quot;&gt;Dan Jurafsky&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leskovec_J/0/1/0/all/0/1&quot;&gt;Jure Leskovec&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.06497">
<title>Continuous Assortment Optimization with Logit Choice Probabilities under Incomplete Information. (arXiv:1807.06497v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1807.06497</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider assortment optimization of a product for which a particular
attribute can be adjusted in a continuous fashion. Examples include the
duration of a loan, the data limit for a cell phone subscription and the
greenness of paint. We represent the collection of all product variants as the
unit interval and consider the question which subset of products a retailer
should offer to customers, in order to maximize profit. We model customer
choice behavior by a continuous extension of the multinomial logit model and
allow for a capacity constraint on the offered assortment. We study this
problem under incomplete information, which constitutes an instance of a
continuous combinatorial multi-armed bandit problem. The unknown quantities in
the model are estimated by kernel density estimation with Legendre kernels and
bounded support, for which we derive new convergence rates. We present an
explore-then-exploit policy and show that it endures regret of order $T^{2/3}$
(neglecting logarithmic factors). Also, by showing that any policy in the worst
case must endure at least a regret of order $T^{2/3}$, we conclude that our
policy is asymptotically optimal.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Peeters_Y/0/1/0/all/0/1&quot;&gt;Yannik Peeters&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Boer_A/0/1/0/all/0/1&quot;&gt;Arnoud V. den Boer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mandjes_M/0/1/0/all/0/1&quot;&gt;Michel Mandjes&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.08725">
<title>Scalable Tensor Completion with Nonconvex Regularization. (arXiv:1807.08725v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1807.08725</link>
<description rdf:parseType="Literal">&lt;p&gt;Low-rank tensor completion problem aims to recover a tensor from limited
observations, which has many real-world applications. Due to the easy
optimization, the convex overlapping nuclear norm has been popularly used for
tensor completion. However, it over-penalizes top singular values and lead to
biased estimations. In this paper, we propose to use the nonconvex regularizer,
which can less penalize large singular values, instead of the convex one for
tensor completion. However, as the new regularizer is nonconvex and overlapped
with each other, existing algorithms are either too slow or suffer from the
huge memory cost. To address these issues, we develop an efficient and scalable
algorithm, which is based on the proximal average (PA) algorithm, for
real-world problems. Compared with the direct usage of PA algorithm, the
proposed algorithm runs orders faster and needs orders less space. We further
speed up the proposed algorithm with the acceleration technique, and show the
convergence to critical points is still guaranteed. Experimental comparisons of
the proposed approach are made with various other tensor completion approaches.
Empirical results show that the proposed algorithm is very fast and can produce
much better recovery performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yao_Q/0/1/0/all/0/1&quot;&gt;Quanming Yao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kwok_J/0/1/0/all/0/1&quot;&gt;James T Kwok&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Han_B/0/1/0/all/0/1&quot;&gt;Bo Han&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tu_W/0/1/0/all/0/1&quot;&gt;Weiwei Tu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.02266">
<title>Multi-Output Convolution Spectral Mixture for Gaussian Processes. (arXiv:1808.02266v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1808.02266</link>
<description rdf:parseType="Literal">&lt;p&gt;Multi-output Gaussian processes (MOGPs) are recently extended by using
spectral mixture kernel, which enables expressively pattern extrapolation with
a strong interpretation. In particular, Multi-Output Spectral Mixture kernel
(MOSM) is a recent, powerful state of the art method. However, MOSM cannot
reduce to the ordinary spectral mixture kernel (SM) when using a single
channel. Moreover, when the spectral density of different channels is either
very close or very far from each other in the frequency domain, MOSM generates
unreasonable scale effects on cross weights which produces an incorrect
description of the channel correlation structure. In this paper, we tackle
these drawbacks and introduce a principled multi-output convolution spectral
mixture kernel (MOCSM) framework. In our framework, we model channel
dependencies through convolution of time and phase delayed spectral mixtures
between different channels. Results of extensive experiments on synthetic and
real datasets demontrate the advantages of MOCSM and its state of the art
performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1&quot;&gt;Kai Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Groot_P/0/1/0/all/0/1&quot;&gt;Perry Groot&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1&quot;&gt;Jinsong Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Marchiori_E/0/1/0/all/0/1&quot;&gt;Elena Marchiori&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.06356">
<title>Causal Discovery by Telling Apart Parents and Children. (arXiv:1808.06356v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1808.06356</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the problem of inferring the directed, causal graph from
observational data, assuming no hidden confounders. We take an information
theoretic approach, and make three main contributions.
&lt;/p&gt;
&lt;p&gt;First, we show how through algorithmic information theory we can obtain SCI,
a highly robust, effective and computationally efficient test for conditional
independence---and show it outperforms the state of the art when applied in
constraint-based inference methods such as stable PC.
&lt;/p&gt;
&lt;p&gt;Second, building upon on SCI, we show how to tell apart the parents and
children of a given node based on the algorithmic Markov condition. We give the
Climb algorithm to efficiently discover the directed, causal Markov
blanket---and show it is at least as accurate as inferring the global network,
while being much more efficient.
&lt;/p&gt;
&lt;p&gt;Last, but not least, we detail how we can use the Climb score to direct those
edges that state of the art causal discovery algorithms based on PC or GES
leave undirected---and show this improves their precision, recall and F1 scores
by up to 20%.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Marx_A/0/1/0/all/0/1&quot;&gt;Alexander Marx&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Vreeken_J/0/1/0/all/0/1&quot;&gt;Jilles Vreeken&lt;/a&gt;</dc:creator>
</item></rdf:RDF>