<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Boring papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Bad Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-02-26T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08729"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08760"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08788"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08792"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08989"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09046"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09047"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09121"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09332"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1612.00472"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.10089"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.06487"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.05043"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06093"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06591"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04741"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08705"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08718"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08737"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08757"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08773"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08802"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08822"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08925"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08938"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08974"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09100"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09119"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09158"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09159"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09184"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09296"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09317"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09355"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09464"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09477"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1705.07120"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1707.02729"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1708.08113"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.04328"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.07492"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.02543"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.06169"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.07903"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.11089"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.01711"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.03243"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.10401"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.10563"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.11565"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.06365"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08183"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08365"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08545"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06306"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08686"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08735"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08736"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08761"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08762"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08855"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08898"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08976"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09052"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09086"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09127"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09188"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09210"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09225"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09246"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09371"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09511"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1308.1269"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1610.00843"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1701.04389"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1702.06818"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1702.07305"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1705.10762"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1706.02690"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1706.03446"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1707.09049"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1708.08587"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.00598"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.08079"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.10551"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.02283"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.02771"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.09325"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.02390"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.03558"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.02550"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04145"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04712"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.07796"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08598"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08678"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1802.08729">
<title>Review: Metaheuristic Search-Based Fuzzy Clustering Algorithms. (arXiv:1802.08729v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1802.08729</link>
<description rdf:parseType="Literal">&lt;p&gt;Fuzzy clustering is a famous unsupervised learning method used to collecting
similar data elements within cluster according to some similarity measurement.
But, clustering algorithms suffer from some drawbacks. Among the main weakness
including, selecting the initial cluster centres and the appropriate clusters
number is normally unknown. These weaknesses are considered the most
challenging tasks in clustering algorithms. This paper introduces a
comprehensive review of metahueristic search to solve fuzzy clustering
algorithms problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alomoush_W/0/1/0/all/0/1&quot;&gt;Waleed Alomoush&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alrosan_A/0/1/0/all/0/1&quot;&gt;Ayat Alrosan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08760">
<title>Sensitivity and Generalization in Neural Networks: an Empirical Study. (arXiv:1802.08760v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.08760</link>
<description rdf:parseType="Literal">&lt;p&gt;In practice it is often found that large over-parameterized neural networks
generalize better than their smaller counterparts, an observation that appears
to conflict with classical notions of function complexity, which typically
favor smaller models. In this work, we investigate this tension between
complexity and generalization through an extensive empirical exploration of two
natural metrics of complexity related to sensitivity to input perturbations.
Our experiments survey thousands of models with various fully-connected
architectures, optimizers, and other hyper-parameters, as well as four
different image classification datasets.
&lt;/p&gt;
&lt;p&gt;We find that trained neural networks are more robust to input perturbations
in the vicinity of the training data manifold, as measured by the norm of the
input-output Jacobian of the network, and that it correlates well with
generalization. We further establish that factors associated with poor
generalization $-$ such as full-batch training or using random labels $-$
correspond to lower robustness, while factors associated with good
generalization $-$ such as data augmentation and ReLU non-linearities $-$ give
rise to more robust functions. Finally, we demonstrate how the input-output
Jacobian norm can be predictive of generalization at the level of individual
test points.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Novak_R/0/1/0/all/0/1&quot;&gt;Roman Novak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bahri_Y/0/1/0/all/0/1&quot;&gt;Yasaman Bahri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Abolafia_D/0/1/0/all/0/1&quot;&gt;Daniel A. Abolafia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pennington_J/0/1/0/all/0/1&quot;&gt;Jeffrey Pennington&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sohl_Dickstein_J/0/1/0/all/0/1&quot;&gt;Jascha Sohl-Dickstein&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08788">
<title>Improved Regularity Model-based EDA for Many-objective Optimization. (arXiv:1802.08788v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1802.08788</link>
<description rdf:parseType="Literal">&lt;p&gt;The performance of multi-objective evolutionary algorithms deteriorates
appreciably in solving many-objective optimization problems which encompass
more than three objectives. One of the known rationales is the loss of
selection pressure which leads to the selected parents not generating promising
offspring towards Pareto-optimal front with diversity. Estimation of
distribution algorithms sample new solutions with a probabilistic model built
from the statistics extracting over the existing solutions so as to mitigate
the adverse impact of genetic operators. In this paper, an improved
regularity-based estimation of distribution algorithm is proposed to
effectively tackle unconstrained many-objective optimization problems. In the
proposed algorithm, \emph{diversity repairing mechanism} is utilized to mend
the areas where need non-dominated solutions with a closer proximity to the
Pareto-optimal front. Then \emph{favorable solutions} are generated by the
model built from the regularity of the solutions surrounding a group of
representatives. These two steps collectively enhance the selection pressure
which gives rise to the superior convergence of the proposed algorithm. In
addition, dimension reduction technique is employed in the decision space to
speed up the estimation search of the proposed algorithm. Finally, by assigning
the Pareto-optimal solutions to the uniformly distributed reference vectors, a
set of solutions with excellent diversity and convergence is obtained. To
measure the performance, NSGA-III, GrEA, MOEA/D, HypE, MBN-EDA, and RM-MEDA are
selected to perform comparison experiments over DTLZ and DTLZ$^-$ test suites
with $3$-, $5$-, $8$-, $10$-, and $15$-objective. Experimental results
quantified by the selected performance metrics reveal that the proposed
algorithm shows considerable competitiveness in addressing unconstrained
many-objective optimization problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1&quot;&gt;Yanan Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yen_G/0/1/0/all/0/1&quot;&gt;Gary G. Yen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yi_Z/0/1/0/all/0/1&quot;&gt;Zhang Yi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08792">
<title>IGD Indicator-based Evolutionary Algorithm for Many-objective Optimization Problems. (arXiv:1802.08792v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1802.08792</link>
<description rdf:parseType="Literal">&lt;p&gt;Inverted Generational Distance (IGD) has been widely considered as a reliable
performance indicator to concurrently quantify the convergence and diversity of
multi- and many-objective evolutionary algorithms. In this paper, an IGD
indicator-based evolutionary algorithm for solving many-objective optimization
problems (MaOPs) has been proposed. Specifically, the IGD indicator is employed
in each generation to select the solutions with favorable convergence and
diversity. In addition, a computationally efficient dominance comparison method
is designed to assign the rank values of solutions along with three newly
proposed proximity distance assignments. Based on these two designs, the
solutions are selected from a global view by linear assignment mechanism to
concern the convergence and diversity simultaneously. In order to facilitate
the accuracy of the sampled reference points for the calculation of IGD
indicator, we also propose an efficient decomposition-based nadir point
estimation method for constructing the Utopian Pareto front which is regarded
as the best approximate Pareto front for real-world MaOPs at the early stage of
the evolution. To evaluate the performance, a series of experiments is
performed on the proposed algorithm against a group of selected
state-of-the-art many-objective optimization algorithms over optimization
problems with $8$-, $15$-, and $20$-objective. Experimental results measured by
the chosen performance metrics indicate that the proposed algorithm is very
competitive in addressing MaOPs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1&quot;&gt;Yanan Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yen_G/0/1/0/all/0/1&quot;&gt;Gary G. Yen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yi_Z/0/1/0/all/0/1&quot;&gt;Zhang Yi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08989">
<title>Enhancing Gaussian Estimation of Distribution Algorithm by Exploiting Evolution Direction with Archive. (arXiv:1802.08989v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1802.08989</link>
<description rdf:parseType="Literal">&lt;p&gt;As a typical model-based evolutionary algorithm (EA), estimation of
distribution algorithm (EDA) possesses unique characteristics and has been
widely applied to global optimization. However, the common-used Gaussian EDA
(GEDA) usually suffers from premature convergence which severely limits its
search efficiency. This study first systematically analyses the reasons for the
deficiency of the traditional GEDA, then tries to enhance its performance by
exploiting its evolution direction, and finally develops a new GEDA variant
named EDA2. Instead of only utilizing some good solutions produced in the
current generation when estimating the Gaussian model, EDA2 preserves a certain
number of high-quality solutions generated in previous generations into an
archive and takes advantage of these historical solutions to assist estimating
the covariance matrix of Gaussian model. By this means, the evolution direction
information hidden in the archive is naturally integrated into the estimated
model which in turn can guide EDA2 towards more promising solution regions.
Moreover, the new estimation method significantly reduces the population size
of EDA2 since it needs fewer individuals in the current population for model
estimation. As a result, a fast convergence can be achieved. To verify the
efficiency of EDA2, we tested it on a variety of benchmark functions and
compared it with several state-of-the-art EAs, including IPOP-CMAES, AMaLGaM,
three high-powered DE algorithms, and a new PSO algorithm. The experimental
results demonstrate that EDA2 is efficient and competitive.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1&quot;&gt;Yongsheng Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ren_Z/0/1/0/all/0/1&quot;&gt;Zhigang Ren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yao_X/0/1/0/all/0/1&quot;&gt;Xianghua Yao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feng_Z/0/1/0/all/0/1&quot;&gt;Zuren Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_A/0/1/0/all/0/1&quot;&gt;An Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09046">
<title>Multiclass Common Spatial Pattern for EEG based Brain Computer Interface with Adaptive Learning Classifier. (arXiv:1802.09046v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1802.09046</link>
<description rdf:parseType="Literal">&lt;p&gt;In Brain Computer Interface (BCI), data generated from Electroencephalogram
(EEG) is non-stationary with low signal to noise ratio and contaminated with
artifacts. Common Spatial Pattern (CSP) algorithm has been proved to be
effective in BCI for extracting features in motor imagery tasks, but it is
prone to overfitting. Many algorithms have been devised to regularize CSP for
two class problem, however they have not been effective when applied to
multiclass CSP. Outliers present in data affect extracted CSP features and
reduces performance of the system. In addition to this non-stationarity present
in the features extracted from the CSP present a challenge in classification.
We propose a method to identify and remove artifact present in the data during
pre-processing stage, this helps in calculating eigenvectors which in turn
generates better CSP features. To handle the non-stationarity, Self-Regulated
Interval Type-2 Neuro-Fuzzy Inference System (SRIT2NFIS) was proposed in the
literature for two class EEG classification problem. This paper extends the
SRIT2NFIS to multiclass using Joint Approximate Diagonalization (JAD). The
results on standard data set from BCI competition IV shows significant increase
in the accuracies from the current state of the art methods for multiclass
classification.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meisheri_H/0/1/0/all/0/1&quot;&gt;Hardik Meisheri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ramrao_N/0/1/0/all/0/1&quot;&gt;Nagraj Ramrao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mitra_S/0/1/0/all/0/1&quot;&gt;Suman Mitra&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09047">
<title>Power efficient Spiking Neural Network Classifier based on memristive crossbar network for spike sorting application. (arXiv:1802.09047v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1802.09047</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper authors have presented a power efficient scheme for
implementing a spike sorting module. Spike sorting is an important application
in the field of neural signal acquisition for implantable biomedical systems
whose function is to map the Neural-spikes (N-spikes) correctly to the neurons
from which it originates. The accurate classification is a pre-requisite for
the succeeding systems needed in Brain-Machine-Interfaces (BMIs) to give better
performance. The primary design constraint to be satisfied for the spike sorter
module is low power with good accuracy. There lies a trade-off in terms of
power consumption between the on-chip and off-chip training of the N-spike
features. In the former case care has to be taken to make the computational
units power efficient whereas in the later the data rate of wireless
transmission should be minimized to reduce the power consumption due to the
transceivers. In this work a 2-step shared training scheme involving a K-means
sorter and a Spiking Neural Network (SNN) is elaborated for on-chip training
and classification. Also, a low power SNN classifier scheme using memristive
crossbar type architecture is compared with a fully digital implementation. The
advantage of the former classifier is that it is power efficient while
providing comparable accuracy as that of the digital implementation due to the
robustness of the SNN training algorithm which has a good tolerance for
variation in memristance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mukhopadhyay_A/0/1/0/all/0/1&quot;&gt;Anand Kumar Mukhopadhyay&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chakrabarti_I/0/1/0/all/0/1&quot;&gt;Indrajit Chakrabarti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Basu_A/0/1/0/all/0/1&quot;&gt;Arindam Basu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sharad_M/0/1/0/all/0/1&quot;&gt;Mrigank Sharad&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09121">
<title>Limits on representing Boolean functions by linear combinations of simple functions: thresholds, ReLUs, and low-degree polynomials. (arXiv:1802.09121v1 [cs.CC])</title>
<link>http://arxiv.org/abs/1802.09121</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the problem of representing Boolean functions exactly by &quot;sparse&quot;
linear combinations (over $\mathbb{R}$) of functions from some &quot;simple&quot; class
${\cal C}$. In particular, given ${\cal C}$ we are interested in finding
low-complexity functions lacking sparse representations. When ${\cal C}$ is the
set of PARITY functions or the set of conjunctions, this sort of problem has a
well-understood answer, the problem becomes interesting when ${\cal C}$ is
&quot;overcomplete&quot; and the set of functions is not linearly independent. We focus
on the cases where ${\cal C}$ is the set of linear threshold functions, the set
of rectified linear units (ReLUs), and the set of low-degree polynomials over a
finite field, all of which are well-studied in different contexts.
&lt;/p&gt;
&lt;p&gt;We provide generic tools for proving lower bounds on representations of this
kind. Applying these, we give several new lower bounds for &quot;semi-explicit&quot;
Boolean functions. For example, we show there are functions in nondeterministic
quasi-polynomial time that require super-polynomial size:
&lt;/p&gt;
&lt;p&gt;$\bullet$ Depth-two neural networks with sign activation function, a special
case of depth-two threshold circuit lower bounds.
&lt;/p&gt;
&lt;p&gt;$\bullet$ Depth-two neural networks with ReLU activation function.
&lt;/p&gt;
&lt;p&gt;$\bullet$ $\mathbb{R}$-linear combinations of $O(1)$-degree
$\mathbb{F}_p$-polynomials, for every prime $p$ (related to problems regarding
Higher-Order &quot;Uncertainty Principles&quot;). We also obtain a function in $E^{NP}$
requiring $2^{\Omega(n)}$ linear combinations.
&lt;/p&gt;
&lt;p&gt;$\bullet$ $\mathbb{R}$-linear combinations of $ACC \circ THR$ circuits of
polynomial size (further generalizing the recent lower bounds of Murray and the
author).
&lt;/p&gt;
&lt;p&gt;(The above is a shortened abstract. For the full abstract, see the paper.)
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Williams_R/0/1/0/all/0/1&quot;&gt;R. Ryan Williams&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09332">
<title>Parsimonious Network based on Fuzzy Inference System (PANFIS) for Time Series Feature Prediction of Low Speed Slew Bearing Prognosis. (arXiv:1802.09332v1 [eess.SP])</title>
<link>http://arxiv.org/abs/1802.09332</link>
<description rdf:parseType="Literal">&lt;p&gt;In recent years, the utilization of rotating parts, e.g. bearings and gears,
has been continuously supporting the manufacturing line to produce consistent
output quality. Due to their critical role, the breakdown of these components
might significantly impact the production rate. A proper condition based
monitoring (CBM) is among a few ways to maintain and monitor the rotating
systems. Prognosis, as one of the major tasks in CBM that predicts and
estimates the remaining useful life of the machine, has attracted significant
interest in decades. This paper presents a literature review on prognosis
approaches from published papers in the last decade. The prognostic approaches
are described comprehensively to provide a better idea on how to select an
appropriate prognosis method for specific needs. An advanced predictive
analytics, namely Parsimonious Network Based on Fuzzy Inference System
(PANFIS), was proposed and tested into the low speed slew bearing data. PANFIS
differs itself from conventional prognostic approaches in which it supports for
online lifelong prognostics without the requirement of retraining or
reconfiguration phase. The method is applied to normal-to-failure bearing
vibration data collected for 139 days and to predict the time-domain features
of vibration slew bearing signals. The performance of the proposed method is
compared to some established methods such as ANFIS, eTS, and Simp_eTS. From the
results, it is suggested that PANFIS offers outstanding performance compared to
those of other methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Caesarendra_W/0/1/0/all/0/1&quot;&gt;Wahyu Caesarendra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Pratama_M/0/1/0/all/0/1&quot;&gt;Mahardhika Pratama&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Tjahjowidodo_T/0/1/0/all/0/1&quot;&gt;Tegoeh Tjahjowidodo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Tieud_K/0/1/0/all/0/1&quot;&gt;Kiet Tieud&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Kosasih_B/0/1/0/all/0/1&quot;&gt;Buyung Kosasih&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1612.00472">
<title>Understanding image motion with group representations. (arXiv:1612.00472v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1612.00472</link>
<description rdf:parseType="Literal">&lt;p&gt;Motion is an important signal for agents in dynamic environments, but
learning to represent motion from unlabeled video is a difficult and
underconstrained problem. We propose a model of motion based on elementary
group properties of transformations and use it to train a representation of
image motion. While most methods of estimating motion are based on pixel-level
constraints, we use these group properties to constrain the abstract
representation of motion itself. We demonstrate that a deep neural network
trained using this method captures motion in both synthetic 2D sequences and
real-world sequences of vehicle motion, without requiring any labels. Networks
trained to respect these constraints implicitly identify the image
characteristic of motion in different sequence types. In the context of vehicle
motion, this method extracts information useful for localization, tracking, and
odometry. Our results demonstrate that this representation is useful for
learning motion in the general setting where explicit labels are difficult to
obtain.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jaegle_A/0/1/0/all/0/1&quot;&gt;Andrew Jaegle&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Phillips_S/0/1/0/all/0/1&quot;&gt;Stephen Phillips&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ippolito_D/0/1/0/all/0/1&quot;&gt;Daphne Ippolito&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Daniilidis_K/0/1/0/all/0/1&quot;&gt;Kostas Daniilidis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.10089">
<title>Overcoming Exploration in Reinforcement Learning with Demonstrations. (arXiv:1709.10089v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1709.10089</link>
<description rdf:parseType="Literal">&lt;p&gt;Exploration in environments with sparse rewards has been a persistent problem
in reinforcement learning (RL). Many tasks are natural to specify with a sparse
reward, and manually shaping a reward function can result in suboptimal
performance. However, finding a non-zero reward is exponentially more difficult
with increasing task horizon or action dimensionality. This puts many
real-world tasks out of practical reach of RL methods. In this work, we use
demonstrations to overcome the exploration problem and successfully learn to
perform long-horizon, multi-step robotics tasks with continuous control such as
stacking blocks with a robot arm. Our method, which builds on top of Deep
Deterministic Policy Gradients and Hindsight Experience Replay, provides an
order of magnitude of speedup over RL on simulated robotics tasks. It is simple
to implement and makes only the additional assumption that we can collect a
small set of demonstrations. Furthermore, our method is able to solve tasks not
solvable by either RL or behavior cloning alone, and often ends up
outperforming the demonstrator policy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nair_A/0/1/0/all/0/1&quot;&gt;Ashvin Nair&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+McGrew_B/0/1/0/all/0/1&quot;&gt;Bob McGrew&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Andrychowicz_M/0/1/0/all/0/1&quot;&gt;Marcin Andrychowicz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zaremba_W/0/1/0/all/0/1&quot;&gt;Wojciech Zaremba&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1&quot;&gt;Pieter Abbeel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.06487">
<title>Classification and Geometry of General Perceptual Manifolds. (arXiv:1710.06487v2 [cond-mat.dis-nn] UPDATED)</title>
<link>http://arxiv.org/abs/1710.06487</link>
<description rdf:parseType="Literal">&lt;p&gt;Perceptual manifolds arise when a neural population responds to an ensemble
of sensory signals associated with different physical features (e.g.,
orientation, pose, scale, location, and intensity) of the same perceptual
object. Object recognition and discrimination requires classifying the
manifolds in a manner that is insensitive to variability within a manifold. How
neuronal systems give rise to invariant object classification and recognition
is a fundamental problem in brain theory as well as in machine learning. Here
we study the ability of a readout network to classify objects from their
perceptual manifold representations. We develop a statistical mechanical theory
for the linear classification of manifolds with arbitrary geometry revealing a
remarkable relation to the mathematics of conic decomposition. Novel
geometrical measures of manifold radius and manifold dimension are introduced
which can explain the classification capacity for manifolds of various
geometries. The general theory is demonstrated on a number of representative
manifolds, including L2 ellipsoids prototypical of strictly convex manifolds,
L1 balls representing polytopes consisting of finite sample points, and
orientation manifolds which arise from neurons tuned to respond to a continuous
angle variable, such as object orientation. The effects of label sparsity on
the classification capacity of manifolds are elucidated, revealing a scaling
relation between label sparsity and manifold radius. Theoretical predictions
are corroborated by numerical simulations using recently developed algorithms
to compute maximum margin solutions for manifold dichotomies. Our theory and
its extensions provide a powerful and rich framework for applying statistical
mechanics of linear classification to data arising from neuronal responses to
object stimuli, as well as to artificial deep networks trained for object
recognition tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Chung_S/0/1/0/all/0/1&quot;&gt;SueYeon Chung&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Lee_D/0/1/0/all/0/1&quot;&gt;Daniel D. Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Sompolinsky_H/0/1/0/all/0/1&quot;&gt;Haim Sompolinsky&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.05043">
<title>Evolving Unsupervised Deep Neural Networks for Learning Meaningful Representations. (arXiv:1712.05043v2 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1712.05043</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep Learning (DL) aims at learning the \emph{meaningful representations}. A
meaningful representation refers to the one that gives rise to significant
performance improvement of associated Machine Learning (ML) tasks by replacing
the raw data as the input. However, optimal architecture design and model
parameter estimation in DL algorithms are widely considered to be intractable.
Evolutionary algorithms are much preferable for complex and non-convex problems
due to its inherent characteristics of gradient-free and insensitivity to local
optimum. In this paper, we propose a computationally economical algorithm for
evolving \emph{unsupervised deep neural networks} to efficiently learn
\emph{meaningful representations}, which is very suitable in the current Big
Data era where sufficient labeled data for training is often expensive to
acquire. In the proposed algorithm, finding an appropriate architecture and the
initialized parameter values for a ML task at hand is modeled by one
computational efficient gene encoding approach, which is employed to
effectively model the task with a large number of parameters. In addition, a
local search strategy is incorporated to facilitate the exploitation search for
further improving the performance. Furthermore, a small proportion labeled data
is utilized during evolution search to guarantee the learnt representations to
be meaningful. The performance of the proposed algorithm has been thoroughly
investigated over classification tasks. Specifically, error classification rate
on MNIST with $1.15\%$ is reached by the proposed algorithm consistently, which
is a very promising result against state-of-the-art unsupervised DL algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1&quot;&gt;Yanan Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yen_G/0/1/0/all/0/1&quot;&gt;Gary G. Yen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yi_Z/0/1/0/all/0/1&quot;&gt;Zhang Yi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06093">
<title>Gradient descent with identity initialization efficiently learns positive definite linear transformations by deep residual networks. (arXiv:1802.06093v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1802.06093</link>
<description rdf:parseType="Literal">&lt;p&gt;We analyze algorithms for approximating a function $f(x) = \Phi x$ mapping
$\Re^d$ to $\Re^d$ using deep linear neural networks, i.e. that learn a
function $h$ parameterized by matrices $\Theta_1,...,\Theta_L$ and defined by
$h(x) = \Theta_L \Theta_{L-1} ... \Theta_1 x$. We focus on algorithms that
learn through gradient descent on the population quadratic loss in the case
that the distribution over the inputs is isotropic.
&lt;/p&gt;
&lt;p&gt;We provide polynomial bounds on the number of iterations for gradient descent
to approximate the optimum, in the case where the initial hypothesis $\Theta_1
= ... = \Theta_L = I$ has loss bounded by a small enough constant. On the other
hand, we show that gradient descent fails to converge for $\Phi$ whose distance
from the identity is a larger constant, and we show that some forms of
regularization toward the identity in each layer do not help.
&lt;/p&gt;
&lt;p&gt;If $\Phi$ is symmetric positive definite, we show that an algorithm that
initializes $\Theta_i = I$ learns an $\epsilon$-approximation of $f$ using a
number of updates polynomial in $L$, the condition number of $\Phi$, and
$\log(d/\epsilon)$. In contrast, we show that if the target $\Phi$ is symmetric
and has a negative eigenvalue, then all members of a class of algorithms that
perform gradient descent with identity initialization, and optionally
regularize toward the identity in each layer, fail to converge.
&lt;/p&gt;
&lt;p&gt;We analyze an algorithm for the case that $\Phi$ satisfies $u^{\top} \Phi u &amp;gt;
0$ for all $u$, but may not be symmetric. This algorithm uses two regularizers:
one that maintains the invariant $u^{\top} \Theta_L \Theta_{L-1} ... \Theta_1 u
&amp;gt; 0$ for all $u$, and another that &quot;balances&quot; $\Theta_1 ... \Theta_L$ so that
they have the same singular values.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bartlett_P/0/1/0/all/0/1&quot;&gt;Peter L. Bartlett&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Helmbold_D/0/1/0/all/0/1&quot;&gt;David P. Helmbold&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Long_P/0/1/0/all/0/1&quot;&gt;Philip M. Long&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06591">
<title>Closing the loop on multisensory interactions: A neural architecture for multisensory causal inference and recalibration. (arXiv:1802.06591v2 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1802.06591</link>
<description rdf:parseType="Literal">&lt;p&gt;When the brain receives input from multiple sensory systems, it is faced with
the question of whether it is appropriate to process the inputs in combination,
as if they originated from the same event, or separately, as if they originated
from distinct events. Furthermore, it must also have a mechanism through which
it can keep sensory inputs calibrated to maintain the accuracy of its internal
representations. We have developed a neural network architecture capable of i)
approximating optimal multisensory spatial integration, based on Bayesian
causal inference, and ii) recalibrating the spatial encoding of sensory
systems. The architecture is based on features of the dorsal processing
hierarchy, including the spatial tuning properties of unisensory neurons and
the convergence of different sensory inputs onto multisensory neurons.
Furthermore, we propose that these unisensory and multisensory neurons play
dual roles in i) encoding spatial location as separate or integrated estimates
and ii) accumulating evidence for the independence or relatedness of
multisensory stimuli. We further propose that top-down feedback connections
spanning the dorsal pathway play key a role in recalibrating spatial encoding
at the level of early unisensory cortices. Our proposed architecture provides
possible explanations for a number of human electrophysiological and
neuroimaging results and generates testable predictions linking neurophysiology
with behaviour.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tong_J/0/1/0/all/0/1&quot;&gt;Jonathan Tong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Parisi_G/0/1/0/all/0/1&quot;&gt;German I. Parisi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wermter_S/0/1/0/all/0/1&quot;&gt;Stefan Wermter&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roder_B/0/1/0/all/0/1&quot;&gt;Brigitte R&amp;#xf6;der&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04741">
<title>Deep Learning for Decoding of Linear Codes - A Syndrome-Based Approach. (arXiv:1802.04741v1 [cs.IT] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1802.04741</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a novel framework for applying deep neural networks (DNN) to soft
decoding of linear codes at arbitrary block lengths. Unlike other approaches,
our framework allows unconstrained DNN design, enabling the free application of
powerful designs that were developed in other contexts. Our method is robust to
overfitting that inhibits many competing methods, which follows from the
exponentially large number of codewords required for their training. We achieve
this by transforming the channel output before feeding it to the network,
extracting only the syndrome of the hard decisions and the channel output
reliabilities. We prove analytically that this approach does not involve any
intrinsic performance penalty, and guarantees the generalization of performance
obtained during training. Our best results are obtained using a recurrent
neural network (RNN) architecture combined with simple preprocessing by
permutation. We provide simulation results that demonstrate performance that
sometimes approaches that of the ordered statistics decoding (OSD) algorithm.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bennatan_A/0/1/0/all/0/1&quot;&gt;Amir Bennatan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Choukroun_Y/0/1/0/all/0/1&quot;&gt;Yoni Choukroun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kisilev_P/0/1/0/all/0/1&quot;&gt;Pavel Kisilev&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08705">
<title>STRIPStream: Integrating Symbolic Planners and Blackbox Samplers. (arXiv:1802.08705v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.08705</link>
<description rdf:parseType="Literal">&lt;p&gt;Many planning applications involve complex relationships defined on
high-dimensional, continuous variables. For example, robotic manipulation
requires planning with kinematic, collision, and motion constraints involving
robot configurations, object transforms, and robot trajectories. These
constraints typically require specialized procedures to sample satisfying
values. We extend the STRIPS planning language to support a generic,
declarative specification for these procedures while treating their
implementation as blackboxes. We provide several domain-independent algorithms
that reduce STRIPStream problems to a sequence of finite-domain STRIPS planning
problems. Additionally, we describe cost-sensitive planning within this
framework. Finally, we evaluate our algorithms on three robotic task and motion
planning domains.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garrett_C/0/1/0/all/0/1&quot;&gt;Caelan Reed Garrett&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lozano_Perez_T/0/1/0/all/0/1&quot;&gt;Tom&amp;#xe1;s Lozano-P&amp;#xe9;rez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kaelbling_L/0/1/0/all/0/1&quot;&gt;Leslie Pack Kaelbling&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08718">
<title>Learning with Abandonment. (arXiv:1802.08718v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.08718</link>
<description rdf:parseType="Literal">&lt;p&gt;Consider a platform that wants to learn a personalized policy for each user,
but the platform faces the risk of a user abandoning the platform if she is
dissatisfied with the actions of the platform. For example, a platform is
interested in personalizing the number of newsletters it sends, but faces the
risk that the user unsubscribes forever. We propose a general thresholded
learning model for scenarios like this, and discuss the structure of optimal
policies. We describe salient features of optimal personalization algorithms
and how feedback the platform receives impacts the results. Furthermore, we
investigate how the platform can efficiently learn the heterogeneity across
users by interacting with a population and provide performance guarantees.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Johari_R/0/1/0/all/0/1&quot;&gt;Ramesh Johari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Schmit_S/0/1/0/all/0/1&quot;&gt;Sven Schmit&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08737">
<title>Contextual Bandits with Stochastic Experts. (arXiv:1802.08737v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.08737</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the problem of contextual bandits with stochastic experts, which
is a variation of the traditional stochastic contextual bandit with experts
problem. In our problem setting, we assume access to a class of stochastic
experts, where each expert is a conditional distribution over the arms given a
context. We propose upper-confidence bound (UCB) algorithms for this problem,
which employ two different importance sampling based estimators for the mean
reward for each expert. Both these estimators leverage information leakage
among the experts, thus using samples collected under all the experts to
estimate the mean reward of any given expert. This leads to instance dependent
regret bounds of $\mathcal{O}\left(\lambda(\pmb{\mu})\mathcal{M}\log T/\Delta
\right)$, where $\lambda(\pmb{\mu})$ is a term that depends on the mean rewards
of the experts, $\Delta$ is the smallest gap between the mean reward of the
optimal expert and the rest, and $\mathcal{M}$ quantifies the information
leakage among the experts. We show that under some assumptions
$\lambda(\pmb{\mu})$ is typically $\mathcal{O}(\log N)$. We implement our
algorithm with stochastic experts generated from cost-sensitive classification
oracles and show superior empirical performance on real-world datasets, when
compared to other state of the art contextual bandit algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sen_R/0/1/0/all/0/1&quot;&gt;Rajat Sen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Shanmugam_K/0/1/0/all/0/1&quot;&gt;Karthikeyan Shanmugam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Shakkottai_S/0/1/0/all/0/1&quot;&gt;Sanjay Shakkottai&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08757">
<title>Fully Decentralized Multi-Agent Reinforcement Learning with Networked Agents. (arXiv:1802.08757v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.08757</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the problem of \emph{fully decentralized} multi-agent
reinforcement learning (MARL), where the agents are located at the nodes of a
time-varying communication network. Specifically, we assume that the reward
functions of the agents might correspond to different tasks, and are only known
to the corresponding agent. Moreover, each agent makes individual decisions
based on both the information observed locally and the messages received from
its neighbors over the network. Within this setting, the collective goal of the
agents is to maximize the globally averaged return over the network through
exchanging information with their neighbors. To this end, we propose two
decentralized actor-critic algorithms with function approximation, which are
applicable to large-scale MARL problems where both the number of states and the
number of agents are massively large. Under the decentralized structure, the
actor step is performed individually by each agent with no need to infer the
policies of others. For the critic step, we propose a consensus update via
communication over the network. Our algorithms are fully incremental and can be
implemented in an online fashion. Convergence analyses of the algorithms are
provided when the value functions are approximated within the class of linear
functions. Extensive simulation results with both linear and nonlinear function
approximations are presented to validate the proposed algorithms. Our work
appears to be the first study of fully decentralized MARL algorithms for
networked agents with function approximation, with provable convergence
guarantees.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1&quot;&gt;Kaiqing Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1&quot;&gt;Zhuoran Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1&quot;&gt;Han Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1&quot;&gt;Tong Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Basar_T/0/1/0/all/0/1&quot;&gt;Tamer Ba&amp;#x15f;ar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08773">
<title>GraphRNN: A Deep Generative Model for Graphs. (arXiv:1802.08773v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.08773</link>
<description rdf:parseType="Literal">&lt;p&gt;Modeling and generating graphs is fundamental for studying networks in
biology, engineering, and social sciences. However, modeling complex
distributions over graphs and then efficiently sampling from these
distributions is challenging due to the non-unique, high-dimensional nature of
graphs and the complex, non-local dependencies that exist between edges in a
given graph. Here we propose GraphRNN, a deep autoregressive model that
addresses the above challenges and approximates any distribution of graphs with
minimal assumptions about their structure. GraphRNN learns to generate graphs
by training on a representative set of graphs and decomposes the graph
generation process into a sequence of node and edge formations, conditioned on
the graph structure generated so far.
&lt;/p&gt;
&lt;p&gt;In order to quantitatively evaluate the performance of GraphRNN, we introduce
a benchmark suite of datasets, baselines and novel evaluation metrics based on
Maximum Mean Discrepancy, which measure distances between sets of graphs. Our
experiments show that GraphRNN significantly outperforms all baselines,
learning to generate diverse graphs that match the structural characteristics
of a target set, while also scaling to graphs 50 times larger than previous
deep models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+You_J/0/1/0/all/0/1&quot;&gt;Jiaxuan You&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ying_R/0/1/0/all/0/1&quot;&gt;Rex Ying&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1&quot;&gt;Xiang Ren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hamilton_W/0/1/0/all/0/1&quot;&gt;William L. Hamilton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leskovec_J/0/1/0/all/0/1&quot;&gt;Jure Leskovec&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08802">
<title>Reinforcement Learning on Web Interfaces Using Workflow-Guided Exploration. (arXiv:1802.08802v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.08802</link>
<description rdf:parseType="Literal">&lt;p&gt;Reinforcement learning (RL) agents improve through trial-and-error, but when
reward is sparse and the agent cannot discover successful action sequences,
learning stagnates. This has been a notable problem in training deep RL agents
to perform web-based tasks, such as booking flights or replying to emails,
where a single mistake can ruin the entire sequence of actions. A common remedy
is to &quot;warm-start&quot; the agent by pre-training it to mimic expert demonstrations,
but this is prone to overfitting. Instead, we propose to constrain exploration
using demonstrations. From each demonstration, we induce high-level &quot;workflows&quot;
which constrain the allowable actions at each time step to be similar to those
in the demonstration (e.g., &quot;Step 1: click on a textbox; Step 2: enter some
text&quot;). Our exploration policy then learns to identify successful workflows and
samples actions that satisfy these workflows. Workflows prune out bad
exploration directions and accelerate the agent&apos;s ability to discover rewards.
We use our approach to train a novel neural policy designed to handle the
semi-structured nature of websites, and evaluate on a suite of web tasks,
including the recent World of Bits benchmark. We achieve new state-of-the-art
results, and show that workflow-guided exploration improves sample efficiency
over behavioral cloning by more than 100x.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_E/0/1/0/all/0/1&quot;&gt;Evan Zheran Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guu_K/0/1/0/all/0/1&quot;&gt;Kelvin Guu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pasupat_P/0/1/0/all/0/1&quot;&gt;Panupong Pasupat&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_T/0/1/0/all/0/1&quot;&gt;Tianlin Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_P/0/1/0/all/0/1&quot;&gt;Percy Liang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08822">
<title>PSO-based Fuzzy Markup Language for Student Learning Performance Evaluation and Educational Application. (arXiv:1802.08822v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.08822</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper proposes an agent with particle swarm optimization (PSO) based on
a Fuzzy Markup Language (FML) for students learning performance evaluation and
educational applications, and the proposed agent is according to the response
data from a conventional test and an item response theory. First, we apply a
GS-based parameter estimation mechanism to estimate the items parameters
according to the response data, and then to compare its results with those of
an IRT-based Bayesian parameter estimation mechanism. In addition, we propose a
static-IRT test assembly mechanism to assemble a form for the conventional
test. The presented FML-based dynamic assessment mechanism infers the
probability of making a correct response to the item for a student with various
abilities. Moreover, this paper also proposes a novel PFML learning mechanism
for optimizing the parameters between items and students. Finally, we adopt a
K-fold cross validation mechanism to evaluate the performance of the proposed
agent. Experimental results show that the novel PFML learning mechanism for the
parameter estimation and learning optimization performs favorably. We believe
the proposed PFML will be a reference for education research and pedagogy and
an important co-learning mechanism for future human-machine educational
applications.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_C/0/1/0/all/0/1&quot;&gt;Chang-Shing Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1&quot;&gt;Mei-Hui Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1&quot;&gt;Chi-Shiang Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Teytaud_O/0/1/0/all/0/1&quot;&gt;Olivier Teytaud&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Jialin Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_S/0/1/0/all/0/1&quot;&gt;Su-Wei Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hung_P/0/1/0/all/0/1&quot;&gt;Pi-Hsia Hung&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08925">
<title>Generating retinal flow maps from structural optical coherence tomography with artificial intelligence. (arXiv:1802.08925v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1802.08925</link>
<description rdf:parseType="Literal">&lt;p&gt;Despite significant advances in artificial intelligence (AI) for computer
vision, its application in medical imaging has been limited by the burden and
limits of expert-generated labels. We used images from optical coherence
tomography angiography (OCTA), a relatively new imaging modality that measures
perfusion of the retinal vasculature, to train an AI algorithm to generate
vasculature maps from standard structural optical coherence tomography (OCT)
images of the same retinae, both exceeding the ability and bypassing the need
for expert labeling. Deep learning was able to infer perfusion of
microvasculature from structural OCT images with similar fidelity to OCTA and
significantly better than expert clinicians (P &amp;lt; 0.00001). OCTA suffers from
need of specialized hardware, laborious acquisition protocols, and motion
artifacts; whereas our model works directly from standard OCT which are
ubiquitous and quick to obtain, and allows unlocking of large volumes of
previously collected standard OCT data both in existing clinical trials and
clinical practice. This finding demonstrates a novel application of AI to
medical imaging, whereby subtle regularities between different modalities are
used to image the same body part and AI is used to generate detailed and
accurate inferences of tissue function from structure imaging.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_C/0/1/0/all/0/1&quot;&gt;Cecilia S. Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tyring_A/0/1/0/all/0/1&quot;&gt;Ariel J. Tyring&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1&quot;&gt;Yue Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiao_S/0/1/0/all/0/1&quot;&gt;Sa Xiao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rokem_A/0/1/0/all/0/1&quot;&gt;Ariel S. Rokem&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deruyter_N/0/1/0/all/0/1&quot;&gt;Nicolaas P. Deruyter&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1&quot;&gt;Qinqin Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tufail_A/0/1/0/all/0/1&quot;&gt;Adnan Tufail&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1&quot;&gt;Ruikang K. Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_A/0/1/0/all/0/1&quot;&gt;Aaron Y. Lee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08938">
<title>DID: Distributed Incremental Block Coordinate Descent for Nonnegative Matrix Factorization. (arXiv:1802.08938v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.08938</link>
<description rdf:parseType="Literal">&lt;p&gt;Nonnegative matrix factorization (NMF) has attracted much attention in the
last decade as a dimension reduction method in many applications. Due to the
explosion in the size of data, naturally the samples are collected and stored
distributively in local computational nodes. Thus, there is a growing need to
develop algorithms in a distributed memory architecture. We propose a novel
distributed algorithm, called \textit{distributed incremental block coordinate
descent} (DID), to solve the problem. By adapting the block coordinate descent
framework, closed-form update rules are obtained in DID. Moreover, DID performs
updates incrementally based on the most recently updated residual matrix. As a
result, only one communication step per iteration is required. The correctness,
efficiency, and scalability of the proposed algorithm are verified in a series
of numerical experiments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_T/0/1/0/all/0/1&quot;&gt;Tianxiang Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chu_C/0/1/0/all/0/1&quot;&gt;Chris Chu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08974">
<title>A Framework in CRM Customer Lifecycle: Identify Downward Trend and Potential Issues Detection. (arXiv:1802.08974v1 [cs.CY])</title>
<link>http://arxiv.org/abs/1802.08974</link>
<description rdf:parseType="Literal">&lt;p&gt;Customer retention is one of the primary goals in the area of customer
relationship management. A mass of work exists in which machine learning models
or business rules are established to predict churn. However, targeting users at
an early stage when they start to show a downward trend is a better strategy.
In downward trend prediction, the reasons why customers show a downward trend
is of great interest in the industry as it helps the business to understand the
pain points that customers suffer and to take early action to prevent them from
churning. A commonly used method is to collect feedback from customers by
either aggressively reaching out to them or by passively hearing from them.
However, it is believed that there are a large number of customers who have
unpleasant experiences and never speak out. In the literature, there is limited
research work that provides a comprehensive and scientific approach to identify
these &quot;silent suffers&quot;. In this study, we propose a novel two-part framework:
developing the downward prediction process and establishing the methodology to
identify the reasons why customers are in the downward trend. In the first
prediction part, we focus on predicting the downward trend, which is an earlier
stage of the customer lifecycle compared to churn. In the second part, we
propose an approach to figuring out the cause (of the downward trend) based on
a causal inference method and semi-supervised learning. The proposed approach
is capable of identifying potential silent sufferers. We take bad shopping
experiences as inputs to develop the framework and validate it via a marketing
A/B test in the real world. The test readout demonstrates the effectiveness of
the framework by driving 88.5% incremental lift in purchase volume.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_K/0/1/0/all/0/1&quot;&gt;Kun Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Zhe Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Ying Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_L/0/1/0/all/0/1&quot;&gt;Luyin Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Q/0/1/0/all/0/1&quot;&gt;Qi Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yan Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09100">
<title>Can a Chatbot Determine My Diet?: Addressing Challenges of Chatbot Application for Meal Recommendation. (arXiv:1802.09100v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.09100</link>
<description rdf:parseType="Literal">&lt;p&gt;Poor nutrition can lead to reduced immunity, increased susceptibility to
disease, impaired physical and mental development, and reduced productivity. A
conversational agent can support people as a virtual coach, however building
such systems still have its associated challenges and limitations. This paper
describes the background and motivation for chatbot systems in the context of
healthy nutrition recommendation. We discuss current challenges associated with
chatbot application, we tackled technical, theoretical, behavioural, and social
aspects of the challenges. We then propose a pipeline to be used as guidelines
by developers to implement theoretically and technically robust chatbot
systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fadhil_A/0/1/0/all/0/1&quot;&gt;Ahmed Fadhil&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09119">
<title>Prototyping Virtual Reality Serious Games for Building Earthquake Preparedness: The Auckland City Hospital Case Study. (arXiv:1802.09119v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.09119</link>
<description rdf:parseType="Literal">&lt;p&gt;Enhancing evacuee safety is a key factor in reducing the number of injuries
and deaths that result from earthquakes. One way this can be achieved is by
training occupants. Virtual Reality (VR) and Serious Games (SGs), represent
novel techniques that may overcome the limitations of traditional training
approaches. VR and SGs have been examined in the fire emergency context,
however, their application to earthquake preparedness has not yet been
extensively examined. We provide a theoretical discussion of the advantages and
limitations of using VR SGs to investigate how building occupants behave during
earthquake evacuations and to train building occupants to cope with such
emergencies. We explore key design components for developing a VR SG framework:
(a) what features constitute an earthquake event, (b) which building types can
be selected and represented within the VR environment, (c) how damage to the
building can be determined and represented, (d) how non-player characters (NPC)
can be designed, and (e) what level of interaction there can be between NPC and
the human participants. We illustrate the above by presenting the Auckland City
Hospital, New Zealand as a case study, and propose a possible VR SG training
tool to enhance earthquake preparedness in public buildings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lovreglio_R/0/1/0/all/0/1&quot;&gt;Ruggiero Lovreglio&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gonzalez_V/0/1/0/all/0/1&quot;&gt;Vicente Gonzalez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feng_Z/0/1/0/all/0/1&quot;&gt;Zhenan Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Amor_R/0/1/0/all/0/1&quot;&gt;Robert Amor&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Spearpoint_M/0/1/0/all/0/1&quot;&gt;Michael Spearpoint&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Thomas_J/0/1/0/all/0/1&quot;&gt;Jared Thomas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Trotter_M/0/1/0/all/0/1&quot;&gt;Margaret Trotter&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sacks_R/0/1/0/all/0/1&quot;&gt;Rafael Sacks&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09158">
<title>Surrogate Scoring Rules and a Dominant Truth Serum for Information Elicitation. (arXiv:1802.09158v1 [cs.GT])</title>
<link>http://arxiv.org/abs/1802.09158</link>
<description rdf:parseType="Literal">&lt;p&gt;We study information elicitation without verification (IEWV) and ask the
following question: Can we achieve truthfulness in dominant strategy in IEWV?
This paper considers two elicitation settings. The first setting is when the
mechanism designer has access to a random variable that is a noisy or proxy
version of the ground truth, with known biases. The second setting is the
standard peer prediction setting where agents&apos; reports are the only source of
information that the mechanism designer has. We introduce surrogate scoring
rules (SSR) for the first setting, which use the noisy ground truth to evaluate
quality of elicited information, and show that SSR achieve truthful elicitation
in dominant strategy. Built upon SSR, we develop a multi-task mechanism,
dominant truth serum (DTS), to achieve truthful elicitation in dominant
strategy when the mechanism designer only has access to agents&apos; reports (the
second setting). The method relies on an estimation procedure to accurately
estimate the average bias in the reports of other agents. With the accurate
estimation, a random peer agent&apos;s report serves as a noisy ground truth and SSR
can then be applied to achieve truthfulness in dominant strategy. A salient
feature of SSR and DTS is that they both quantify the quality or value of
information despite lack of ground truth, just as proper scoring rules do for
the with verification setting. Our work complements both the strictly proper
scoring rule literature by solving the case where the mechanism designer only
has access to a noisy or proxy version of the ground truth, and the peer
prediction literature by achieving truthful elicitation in dominant strategy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yang Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yiling Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09159">
<title>Antifragility for Intelligent Autonomous Systems. (arXiv:1802.09159v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.09159</link>
<description rdf:parseType="Literal">&lt;p&gt;Antifragile systems grow measurably better in the presence of hazards. This
is in contrast to fragile systems which break down in the presence of hazards,
robust systems that tolerate hazards up to a certain degree, and resilient
systems that -- like self-healing systems -- revert to their earlier expected
behavior after a period of convalescence. The notion of antifragility was
introduced by Taleb for economics systems, but its applicability has been
illustrated in biological and engineering domains as well. In this paper, we
propose an architecture that imparts antifragility to intelligent autonomous
systems, specifically those that are goal-driven and based on AI-planning. We
argue that this architecture allows the system to self-improve by uncovering
new capabilities obtained either through the hazards themselves (opportunistic)
or through deliberation (strategic). An AI planning-based case study of an
autonomous wheeled robot is presented. We show that with the proposed
architecture, the robot develops antifragile behaviour with respect to an oil
spill hazard.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mujumdar_A/0/1/0/all/0/1&quot;&gt;Anusha Mujumdar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mohalik_S/0/1/0/all/0/1&quot;&gt;Swarup Kumar Mohalik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Badrinath_R/0/1/0/all/0/1&quot;&gt;Ramamurthy Badrinath&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09184">
<title>Variance Reduction Methods for Sublinear Reinforcement Learning. (arXiv:1802.09184v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.09184</link>
<description rdf:parseType="Literal">&lt;p&gt;This work considers the problem of provably optimal reinforcement learning
for (episodic) finite horizon MDPs, i.e. how an agent learns to maximize
his/her (long term) reward in an uncertain environment. The main contribution
is in providing a novel algorithm --- Variance-reduced Upper Confidence
Q-learning (vUCQ) --- which enjoys a regret bound of $\widetilde{O}(\sqrt{HSAT}
+ H^5SA)$, where the $T$ is the number of time steps the agent acts in the MDP,
$S$ is the number of states, $A$ is the number of actions, and $H$ is the
(episodic) horizon time.
&lt;/p&gt;
&lt;p&gt;This is the first regret bound that is both sub-linear in the model size and
asymptotically optimal. The algorithm is sub-linear in that the time to achieve
$\epsilon$-average regret (for any constant $\epsilon$) is $O(SA)$, which is a
number of samples that is far less than that required to learn any
(non-trivial) estimate of the transition model (the transition model is
specified by $O(S^2A)$ parameters). The importance of sub-linear algorithms is
largely the motivation for algorithms such as $Q$-learning and other &quot;model
free&quot; approaches. vUCQ algorithm also enjoys minimax optimal regret in the long
run, matching the $\Omega(\sqrt{HSAT})$ lower bound.
&lt;/p&gt;
&lt;p&gt;Variance-reduced Upper Confidence Q-learning (vUCQ) is a successive
refinement method in which the algorithm reduces the variance in $Q$-value
estimates and couples this estimation scheme with an upper confidence based
algorithm. Technically, the coupling of both of these techniques is what leads
to the algorithm enjoying both the sub-linear regret property and the
(asymptotically) optimal regret.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kakade_S/0/1/0/all/0/1&quot;&gt;Sham Kakade&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1&quot;&gt;Mengdi Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1&quot;&gt;Lin F. Yang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09296">
<title>AMUSE: Multilingual Semantic Parsing for Question Answering over Linked Data. (arXiv:1802.09296v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.09296</link>
<description rdf:parseType="Literal">&lt;p&gt;The task of answering natural language questions over RDF data has received
wide interest in recent years, in particular in the context of the series of
QALD benchmarks. The task consists of mapping a natural language question to an
executable form, e.g. SPARQL, so that answers from a given KB can be extracted.
So far, most systems proposed are i) monolingual and ii) rely on a set of
hard-coded rules to interpret questions and map them into a SPARQL query. We
present the first multilingual QALD pipeline that induces a model from training
data for mapping a natural language question into logical form as probabilistic
inference. In particular, our approach learns to map universal syntactic
dependency representations to a language-independent logical form based on
DUDES (Dependency-based Underspecified Discourse Representation Structures)
that are then mapped to a SPARQL query as a deterministic second step. Our
model builds on factor graphs that rely on features extracted from the
dependency graph and corresponding semantic representations. We rely on
approximate inference techniques, Markov Chain Monte Carlo methods in
particular, as well as Sample Rank to update parameters using a ranking
objective. Our focus lies on developing methods that overcome the lexical gap
and present a novel combination of machine translation and word embedding
approaches for this purpose. As a proof of concept for our approach, we
evaluate our approach on the QALD-6 datasets for English, German &amp;amp; Spanish.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hakimov_S/0/1/0/all/0/1&quot;&gt;Sherzod Hakimov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jebbara_S/0/1/0/all/0/1&quot;&gt;Soufian Jebbara&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cimiano_P/0/1/0/all/0/1&quot;&gt;Philipp Cimiano&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09317">
<title>A Model of Free Will for Artificial Entities. (arXiv:1802.09317v1 [cs.MA])</title>
<link>http://arxiv.org/abs/1802.09317</link>
<description rdf:parseType="Literal">&lt;p&gt;The impression of free will is the feeling according to which our choices are
neither imposed from our inside nor from outside. It is the sense we are the
ultimate cause of our acts. In direct opposition with the universal
determinism, the existence of free will continues to be discussed. In this
paper, free will is linked to a decisional mechanism: an agent is provided with
free will if having performed a predictable choice Cp, it can immediately
perform another choice Cr in a random way. The intangible feeling of free will
is replaced by a decision-making process including a predictable
decision-making process immediately followed by an unpredictable decisional
one.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sanchis_E/0/1/0/all/0/1&quot;&gt;Eric Sanchis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09355">
<title>Teaching Autonomous Driving Using a Modular and Integrated Approach. (arXiv:1802.09355v1 [cs.CY])</title>
<link>http://arxiv.org/abs/1802.09355</link>
<description rdf:parseType="Literal">&lt;p&gt;Autonomous driving is not one single technology but rather a complex system
integrating many technologies, which means that teaching autonomous driving is
a challenging task. Indeed, most existing autonomous driving classes focus on
one of the technologies involved. This not only fails to provide a
comprehensive coverage, but also sets a high entry barrier for students with
different technology backgrounds. In this paper, we present a modular,
integrated approach to teaching autonomous driving. Specifically, we organize
the technologies used in autonomous driving into modules. This is described in
the textbook we have developed as well as a series of multimedia online
lectures designed to provide technical overview for each module. Then, once the
students have understood these modules, the experimental platforms for
integration we have developed allow the students to fully understand how the
modules interact with each other. To verify this teaching approach, we present
three case studies: an introductory class on autonomous driving for students
with only a basic technology background; a new session in an existing embedded
systems class to demonstrate how embedded system technologies can be applied to
autonomous driving; and an industry professional training session to quickly
bring up experienced engineers to work in autonomous driving. The results show
that students can maintain a high interest level and make great progress by
starting with familiar concepts before moving onto other modules.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1&quot;&gt;Jie Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1&quot;&gt;Shaoshan Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pei_S/0/1/0/all/0/1&quot;&gt;Songwen Pei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zuckerman_S/0/1/0/all/0/1&quot;&gt;Stephane Zuckerman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1&quot;&gt;Chen Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gaudiot_J/0/1/0/all/0/1&quot;&gt;Jean-Luc Gaudiot&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09464">
<title>Multi-Goal Reinforcement Learning: Challenging Robotics Environments and Request for Research. (arXiv:1802.09464v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.09464</link>
<description rdf:parseType="Literal">&lt;p&gt;The purpose of this technical report is two-fold. First of all, it introduces
a suite of challenging continuous control tasks (integrated with OpenAI Gym)
based on currently existing robotics hardware. The tasks include pushing,
sliding and pick &amp;amp; place with a Fetch robotic arm as well as in-hand object
manipulation with a Shadow Dexterous Hand. All tasks have sparse binary rewards
and follow a Multi-Goal Reinforcement Learning (RL) framework in which an agent
is told what to do using an additional input.
&lt;/p&gt;
&lt;p&gt;The second part of the paper presents a set of concrete research ideas for
improving RL algorithms, most of which are related to Multi-Goal RL and
Hindsight Experience Replay.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Plappert_M/0/1/0/all/0/1&quot;&gt;Matthias Plappert&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Andrychowicz_M/0/1/0/all/0/1&quot;&gt;Marcin Andrychowicz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ray_A/0/1/0/all/0/1&quot;&gt;Alex Ray&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+McGrew_B/0/1/0/all/0/1&quot;&gt;Bob McGrew&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Baker_B/0/1/0/all/0/1&quot;&gt;Bowen Baker&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Powell_G/0/1/0/all/0/1&quot;&gt;Glenn Powell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schneider_J/0/1/0/all/0/1&quot;&gt;Jonas Schneider&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tobin_J/0/1/0/all/0/1&quot;&gt;Josh Tobin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chociej_M/0/1/0/all/0/1&quot;&gt;Maciek Chociej&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Welinder_P/0/1/0/all/0/1&quot;&gt;Peter Welinder&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kumar_V/0/1/0/all/0/1&quot;&gt;Vikash Kumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zaremba_W/0/1/0/all/0/1&quot;&gt;Wojciech Zaremba&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09477">
<title>Addressing Function Approximation Error in Actor-Critic Methods. (arXiv:1802.09477v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.09477</link>
<description rdf:parseType="Literal">&lt;p&gt;In value-based reinforcement learning methods such as deep Q-learning,
function approximation errors are known to lead to overestimated value
estimates and suboptimal policies. We show that this problem persists in an
actor-critic setting and propose novel mechanisms to minimize its effects on
both the actor and critic. Our algorithm takes the minimum value between a pair
of critics to restrict overestimation and delays policy updates to reduce
per-update error. We evaluate our method on the suite of OpenAI gym tasks,
outperforming the state of the art in every environment tested.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fujimoto_S/0/1/0/all/0/1&quot;&gt;Scott Fujimoto&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hoof_H/0/1/0/all/0/1&quot;&gt;Herke van Hoof&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meger_D/0/1/0/all/0/1&quot;&gt;Dave Meger&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1705.07120">
<title>VAE with a VampPrior. (arXiv:1705.07120v5 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1705.07120</link>
<description rdf:parseType="Literal">&lt;p&gt;Many different methods to train deep generative models have been introduced
in the past. In this paper, we propose to extend the variational auto-encoder
(VAE) framework with a new type of prior which we call &quot;Variational Mixture of
Posteriors&quot; prior, or VampPrior for short. The VampPrior consists of a mixture
distribution (e.g., a mixture of Gaussians) with components given by
variational posteriors conditioned on learnable pseudo-inputs. We further
extend this prior to a two layer hierarchical model and show that this
architecture with a coupled prior and posterior, learns significantly better
models. The model also avoids the usual local optima issues related to useless
latent dimensions that plague VAEs. We provide empirical studies on six
datasets, namely, static and binary MNIST, OMNIGLOT, Caltech 101 Silhouettes,
Frey Faces and Histopathology patches, and show that applying the hierarchical
VampPrior delivers state-of-the-art results on all datasets in the unsupervised
permutation invariant setting and the best results or comparable to SOTA
methods for the approach with convolutional networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tomczak_J/0/1/0/all/0/1&quot;&gt;Jakub M. Tomczak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Welling_M/0/1/0/all/0/1&quot;&gt;Max Welling&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1707.02729">
<title>Best-Effort Inductive Logic Programming via Fine-grained Cost-based Hypothesis Generation. (arXiv:1707.02729v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1707.02729</link>
<description rdf:parseType="Literal">&lt;p&gt;We describe the Inspire system which participated in the first competition on
Inductive Logic Programming (ILP). Inspire is based on Answer Set Programming
(ASP). The distinguishing feature of Inspire is an ASP encoding for hypothesis
space generation: given a set of facts representing the mode bias, and a set of
cost configuration parameters, each answer set of this encoding represents a
single rule that is considered for finding a hypothesis that entails the given
examples. Compared with state-of-the-art methods that use the length of the
rule body as a metric for rule complexity, our approach permits a much more
fine-grained specification of the shape of hypothesis candidate rules. The
Inspire system iteratively increases the rule cost limit and thereby increases
the search space until it finds a suitable hypothesis. The system searches for
a hypothesis that entails a single example at a time, utilizing an ASP encoding
derived from the encoding used in XHAIL. We perform experiments with the
development and test set of the ILP competition. For comparison we also adapted
the ILASP system to process competition instances. Experimental results show
that the cost parameters for the hypothesis search space are an important
factor for finding hypotheses to competition instances within tight resource
bounds.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schuller_P/0/1/0/all/0/1&quot;&gt;Peter Sch&amp;#xfc;ller&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Benz_M/0/1/0/all/0/1&quot;&gt;Mishal Benz&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1708.08113">
<title>Novel Sensor Scheduling Scheme for Intruder Tracking in Energy Efficient Sensor Networks. (arXiv:1708.08113v3 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1708.08113</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the problem of tracking an intruder using a network of wireless
sensors. For tracking the intruder at each instant, the optimal number and the
right configuration of sensors has to be powered. As powering the sensors
consumes energy, there is a trade off between accurately tracking the position
of the intruder at each instant and the energy consumption of sensors. This
problem has been formulated in the framework of Partially Observable Markov
Decision Process (POMDP). Even for the state-of-the-art algorithm in the
literature, the curse of dimensionality renders the problem intractable. In
this paper, we formulate the Intrusion Detection (ID) problem with a suitable
state-action space in the framework of POMDP and develop a Reinforcement
Learning (RL) algorithm utilizing the Upper Confidence Tree Search (UCT) method
to solve the ID problem. Through simulations, we show that our algorithm
performs and scales well with the increasing state and action spaces.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Diddigi_R/0/1/0/all/0/1&quot;&gt;Raghuram Bharadwaj Diddigi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+J%2E_P/0/1/0/all/0/1&quot;&gt;Prabuchandran K.J.&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bhatnagar_S/0/1/0/all/0/1&quot;&gt;Shalabh Bhatnagar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.04328">
<title>Generating OWA weights using truncated distributions. (arXiv:1709.04328v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1709.04328</link>
<description rdf:parseType="Literal">&lt;p&gt;Ordered weighted averaging (OWA) operators have been widely used in decision
making these past few years. An important issue facing the OWA operators&apos; users
is the determination of the OWA weights. This paper introduces an OWA
determination method based on truncated distributions that enables intuitive
generation of OWA weights according to a certain level of risk and trade-off.
These two dimensions are represented by the two first moments of the truncated
distribution. We illustrate our approach with the well-know normal distribution
and the definition of a continuous parabolic decision-strategy space. We
finally study the impact of the number of criteria on the results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lenormand_M/0/1/0/all/0/1&quot;&gt;Maxime Lenormand&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.07492">
<title>Sparse-to-Dense: Depth Prediction from Sparse Depth Samples and a Single Image. (arXiv:1709.07492v2 [cs.RO] UPDATED)</title>
<link>http://arxiv.org/abs/1709.07492</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the problem of dense depth prediction from a sparse set of depth
measurements and a single RGB image. Since depth estimation from monocular
images alone is inherently ambiguous and unreliable, to attain a higher level
of robustness and accuracy, we introduce additional sparse depth samples, which
are either acquired with a low-resolution depth sensor or computed via visual
Simultaneous Localization and Mapping (SLAM) algorithms. We propose the use of
a single deep regression network to learn directly from the RGB-D raw data, and
explore the impact of number of depth samples on prediction accuracy. Our
experiments show that, compared to using only RGB images, the addition of 100
spatially random depth samples reduces the prediction root-mean-square error by
50% on the NYU-Depth-v2 indoor dataset. It also boosts the percentage of
reliable prediction from 59% to 92% on the KITTI dataset. We demonstrate two
applications of the proposed algorithm: a plug-in module in SLAM to convert
sparse maps to dense maps, and super-resolution for LiDARs. Software and video
demonstration are publicly available.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_F/0/1/0/all/0/1&quot;&gt;Fangchang Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Karaman_S/0/1/0/all/0/1&quot;&gt;Sertac Karaman&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.02543">
<title>Socially Compliant Navigation through Raw Depth Inputs with Generative Adversarial Imitation Learning. (arXiv:1710.02543v2 [cs.RO] UPDATED)</title>
<link>http://arxiv.org/abs/1710.02543</link>
<description rdf:parseType="Literal">&lt;p&gt;We present an approach for mobile robots to learn to navigate in dynamic
environments with pedestrians via raw depth inputs, in a socially compliant
manner. To achieve this, we adopt a generative adversarial imitation learning
(GAIL) strategy, which improves upon a pre-trained behavior cloning policy. Our
approach overcomes the disadvantages of previous methods, as they heavily
depend on the full knowledge of the location and velocity information of nearby
pedestrians, which not only requires specific sensors, but also the extraction
of such state information from raw sensory input could consume much computation
time. In this paper, our proposed GAIL-based model performs directly on raw
depth inputs and plans in real-time. Experiments show that our GAIL-based
approach greatly improves the safety and efficiency of the behavior of mobile
robots from pure behavior cloning. The real-world deployment also shows that
our method is capable of guiding autonomous vehicles to navigate in a socially
compliant manner directly through raw depth inputs. In addition, we release a
simulation plugin for modeling pedestrian behaviors based on the social force
model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tai_L/0/1/0/all/0/1&quot;&gt;Lei Tai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Jingwei Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1&quot;&gt;Ming Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Burgard_W/0/1/0/all/0/1&quot;&gt;Wolfram Burgard&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.06169">
<title>Auditing Black-Box Models Using Transparent Model Distillation With Side Information. (arXiv:1710.06169v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1710.06169</link>
<description rdf:parseType="Literal">&lt;p&gt;Black-box risk scoring models permeate our lives, yet are typically
proprietary or opaque. We propose a transparent model distillation approach to
audit such models. Model distillation was first introduced to transfer
knowledge from a large, complex teacher model to a faster, simpler student
model without significant loss in prediction accuracy. To this we add a third
criterion - transparency. To gain insight into black-box models, we treat them
as teachers, training transparent student models to mimic the risk scores
assigned by the teacher. Moreover, we use side information in the form of the
actual outcomes the teacher scoring model was intended to predict in the first
place. By training a second transparent model on the outcomes, we can compare
the two models to each other. When comparing models trained on risk scores to
models trained on outcomes, we show that it is necessary to calibrate the
risk-scoring model&apos;s predictions to remove distortion that may have been added
to the black-box risk-scoring model during or after its training process. We
also show how to compute confidence intervals for the particular class of
transparent student models we use - tree-based additive models with pairwise
interactions (GA2Ms) - to support comparison of the two transparent models. We
demonstrate the methods on four public datasets: COMPAS, Lending Club,
Stop-and-Frisk, and Chicago Police.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tan_S/0/1/0/all/0/1&quot;&gt;Sarah Tan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Caruana_R/0/1/0/all/0/1&quot;&gt;Rich Caruana&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hooker_G/0/1/0/all/0/1&quot;&gt;Giles Hooker&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lou_Y/0/1/0/all/0/1&quot;&gt;Yin Lou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.07903">
<title>The Complexity of Graph-Based Reductions for Reachability in Markov Decision Processes. (arXiv:1710.07903v4 [cs.LO] UPDATED)</title>
<link>http://arxiv.org/abs/1710.07903</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the never-worse relation (NWR) for Markov decision processes with an
infinite-horizon reachability objective. A state q is never worse than a state
p if the maximal probability of reaching the target set of states from p is at
most the same value from q, regard- less of the probabilities labelling the
transitions. Extremal-probability states, end components, and essential states
are all special cases of the equivalence relation induced by the NWR. Using the
NWR, states in the same equivalence class can be collapsed. Then, actions
leading to sub- optimal states can be removed. We show the natural decision
problem associated to computing the NWR is coNP-complete. Finally, we ex- tend
a previously known incomplete polynomial-time iterative algorithm to
under-approximate the NWR.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roux_S/0/1/0/all/0/1&quot;&gt;Stephane Le Roux&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Perez_G/0/1/0/all/0/1&quot;&gt;Guillermo A. Perez&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.11089">
<title>Eigenoption Discovery through the Deep Successor Representation. (arXiv:1710.11089v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1710.11089</link>
<description rdf:parseType="Literal">&lt;p&gt;Options in reinforcement learning allow agents to hierarchically decompose a
task into subtasks, having the potential to speed up learning and planning.
However, autonomously learning effective sets of options is still a major
challenge in the field. In this paper we focus on the recently introduced idea
of using representation learning methods to guide the option discovery process.
Specifically, we look at eigenoptions, options obtained from representations
that encode diffusive information flow in the environment. We extend the
existing algorithms for eigenoption discovery to settings with stochastic
transitions and in which handcrafted features are not available. We propose an
algorithm that discovers eigenoptions while learning non-linear state
representations from raw pixels. It exploits recent successes in the deep
reinforcement learning literature and the equivalence between proto-value
functions and the successor representation. We use traditional tabular domains
to provide intuition about our approach and Atari 2600 games to demonstrate its
potential.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Machado_M/0/1/0/all/0/1&quot;&gt;Marlos C. Machado&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rosenbaum_C/0/1/0/all/0/1&quot;&gt;Clemens Rosenbaum&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_X/0/1/0/all/0/1&quot;&gt;Xiaoxiao Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1&quot;&gt;Miao Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tesauro_G/0/1/0/all/0/1&quot;&gt;Gerald Tesauro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Campbell_M/0/1/0/all/0/1&quot;&gt;Murray Campbell&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.01711">
<title>Coding-theorem Like Behaviour and Emergence of the Universal Distribution from Resource-bounded Algorithmic Probability. (arXiv:1711.01711v9 [cs.IT] UPDATED)</title>
<link>http://arxiv.org/abs/1711.01711</link>
<description rdf:parseType="Literal">&lt;p&gt;Previously referred to as `miraculous&apos; in the scientific literature because
of its powerful properties and its wide application as optimal solution to the
problem of induction/inference, (approximations to) Algorithmic Probability
(AP) and the associated Universal Distribution are (or should be) of the
greatest importance in science. Here we investigate the emergence, the rates of
emergence and convergence, and the Coding-theorem like behaviour of AP in
Turing-subuniversal models of computation. We investigate empirical
distributions of computing models in the Chomsky hierarchy. We introduce
measures of algorithmic probability and algorithmic complexity based upon
resource-bounded computation, in contrast to previously thoroughly investigated
distributions produced from the output distribution of Turing machines. This
approach allows for numerical approximations to algorithmic
(Kolmogorov-Chaitin) complexity-based estimations at each of the levels of a
computational hierarchy. We demonstrate that all these estimations are
correlated in rank and that they converge both in rank and values as a function
of computational power, despite fundamental differences between computational
models. In the context of natural processes that operate below the Turing
universal level because of finite resources and physical degradation, the
investigation of natural biases stemming from algorithmic rules may shed light
on the distribution of outcomes. We show that up to 60\% of the
simplicity/complexity bias in distributions produced even by the weakest of the
computational models can be accounted for by Algorithmic Probability in its
approximation to the Universal Distribution.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zenil_H/0/1/0/all/0/1&quot;&gt;Hector Zenil&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Badillo_L/0/1/0/all/0/1&quot;&gt;Liliana Badillo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hernandez_Orozco_S/0/1/0/all/0/1&quot;&gt;Santiago Hern&amp;#xe1;ndez-Orozco&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hernandez_Quiroz_F/0/1/0/all/0/1&quot;&gt;Francisco Hern&amp;#xe1;ndez-Quiroz&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.03243">
<title>Discovering Representative Examples for Program Synthesis. (arXiv:1711.03243v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1711.03243</link>
<description rdf:parseType="Literal">&lt;p&gt;Program synthesis is a class of regression problems where one seeks a
solution, in the form of a source-code program, mapping the inputs to their
corresponding outputs exactly. Due to its precise and combinatorial nature,
program synthesis is commonly formulated as a constraint satisfaction problem,
where input-output examples are encoded as constraints and solved with a
constraint solver. A key challenge of this formulation is scalability: while
constraint solvers work well with a few well-chosen examples, a large set of
examples can incur significant overhead in both time and memory. We describe a
method to discover a subset of examples that is both small and representative:
the subset is constructed iteratively, using a neural network to predict the
probability of unchosen examples conditioned on the chosen examples in the
subset, and greedily adding the least probable example. We empirically evaluate
the representativeness of the subsets constructed by our method, and
demonstrate such subsets can significantly improve synthesis time and
stability.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pu_Y/0/1/0/all/0/1&quot;&gt;Yewen Pu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Miranda_Z/0/1/0/all/0/1&quot;&gt;Zachery Miranda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Solar_Lezama_A/0/1/0/all/0/1&quot;&gt;Armando Solar-Lezama&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kaelbling_L/0/1/0/all/0/1&quot;&gt;Leslie Pack Kaelbling&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.10401">
<title>A Modification of Particle Swarm Optimization using Random Walk. (arXiv:1711.10401v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1711.10401</link>
<description rdf:parseType="Literal">&lt;p&gt;Particle swarm optimization comes under lot of changes after James Kennedy
and Russell Eberhart first proposes the idea in 1995. The changes has been done
mainly on Inertia parameters in velocity updating equation so that the
convergence rate will be higher. We are proposing a novel approach where
particles movement will not be depend on its velocity rather it will be decided
by constrained biased random walk of particles. In random walk every particles
movement based on two significant parameters, one is random process like toss
of a coin and other is how much displacement a particle should have. In our
approach we exploit this idea by performing a biased random operation and based
on the outcome of that random operation, PSO particles choose the direction of
the path and move non-uniformly into the solution space. This constrained,
non-uniform movement helps the random walking particle to converge quicker then
classical PSO. In our constrained biased random walking approach, we no longer
needed velocity term (Vi), rather we introduce a new parameter (K) which is a
probabilistic function. No global best particle (PGbest), local best particle
(PLbest), Constriction parameter (W) are required rather we use a new term
called Ptarg which is loosely influenced by PGbest.We test our algorithm on
five different benchmark functions, and also compare its performance with
classical PSO and Quantum Particle Swarm Optimization (QPSO).This new approach
have been shown significantly better than basic PSO and sometime outperform
QPSO in terms of convergence, search space, number of iterations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Misra_R/0/1/0/all/0/1&quot;&gt;Rajesh Misra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ray_K/0/1/0/all/0/1&quot;&gt;Kumar S. Ray&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.10563">
<title>FearNet: Brain-Inspired Model for Incremental Learning. (arXiv:1711.10563v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1711.10563</link>
<description rdf:parseType="Literal">&lt;p&gt;Incremental class learning involves sequentially learning classes in bursts
of examples from the same class. This violates the assumptions that underlie
methods for training standard deep neural networks, and will cause them to
suffer from catastrophic forgetting. Arguably, the best method for incremental
class learning is iCaRL, but it requires storing training examples for each
class, making it challenging to scale. Here, we propose FearNet for incremental
class learning. FearNet is a generative model that does not store previous
examples, making it memory efficient. FearNet uses a brain-inspired dual-memory
system in which new memories are consolidated from a network for recent
memories inspired by the mammalian hippocampal complex to a network for
long-term storage inspired by medial prefrontal cortex. Memory consolidation is
inspired by mechanisms that occur during sleep. FearNet also uses a module
inspired by the basolateral amygdala for determining which memory system to use
for recall. FearNet achieves state-of-the-art performance at incremental class
learning on image (CIFAR-100, CUB-200) and audio classification (AudioSet)
benchmarks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kemker_R/0/1/0/all/0/1&quot;&gt;Ronald Kemker&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kanan_C/0/1/0/all/0/1&quot;&gt;Christopher Kanan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.11565">
<title>Deep Neural Networks for Multiple Speaker Detection and Localization. (arXiv:1711.11565v3 [cs.SD] UPDATED)</title>
<link>http://arxiv.org/abs/1711.11565</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose to use neural networks for simultaneous detection and localization
of multiple sound sources in human-robot interaction. In contrast to
conventional signal processing techniques, neural network-based sound source
localization methods require fewer strong assumptions about the environment.
Previous neural network-based methods have been focusing on localizing a single
sound source, which do not extend to multiple sources in terms of detection and
localization. In this paper, we thus propose a likelihood-based encoding of the
network output, which naturally allows the detection of an arbitrary number of
sources. In addition, we investigate the use of sub-band cross-correlation
information as features for better localization in sound mixtures, as well as
three different network architectures based on different motivations.
Experiments on real data recorded from a robot show that our proposed methods
significantly outperform the popular spatial spectrum-based approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_W/0/1/0/all/0/1&quot;&gt;Weipeng He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Motlicek_P/0/1/0/all/0/1&quot;&gt;Petr Motlicek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Odobez_J/0/1/0/all/0/1&quot;&gt;Jean-Marc Odobez&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.06365">
<title>&apos;Indifference&apos; methods for managing agent rewards. (arXiv:1712.06365v3 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1712.06365</link>
<description rdf:parseType="Literal">&lt;p&gt;`Indifference&apos; refers to a class of methods that are used to control a reward
based agent. These methods of control work even if the implications of the
agent&apos;s reward are otherwise not fully understood. Though they all come out of
similar ideas, indifference techniques can be classified as way of achieving
one or more of three distinct goals: rewards dependent on certain events (with
no motivation for the agent to manipulate the probability of those events),
effective disbelief that an event will ever occur, and seamless transition from
one behaviour to another. This paper analyses methods of achieving these goals
in the POMDP setting, and establishes their uses, strengths, and limitations.
It aims to make the tools of indifference generally accessible and usable to
agent designers.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Armstrong_S/0/1/0/all/0/1&quot;&gt;Stuart Armstrong&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08183">
<title>Projection-Free Online Optimization with Stochastic Gradient: From Convexity to Submodularity. (arXiv:1802.08183v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1802.08183</link>
<description rdf:parseType="Literal">&lt;p&gt;Online optimization has been a successful framework for solving large-scale
problems under computational constraints and partial information. Current
methods for online convex optimization require either a projection or exact
gradient computation at each step, both of which can be prohibitively expensive
for large-scale applications. At the same time, there is a growing trend of
non-convex optimization in machine learning community and a need for online
methods. Continuous submodular functions, which exhibit a natural diminishing
returns condition, have recently been proposed as a broad class of non-convex
functions which may be efficiently optimized. Although online methods have been
introduced, they suffer from similar problems. In this work, we propose
Meta-Frank-Wolfe, the first online projectionfree algorithm that uses
stochastic gradient estimates. The algorithm relies on a careful sampling of
gradients in each round and achieves the optimal $O(\sqrt{T})$ adversarial
regret bounds for convex and continuous submodular optimization. We also
propose One-Shot Frank-Wolfe, a simpler algorithm which requires only a single
stochastic gradient estimate in each round and achieves a $O(T^{2/3})$
stochastic regret bound for convex and continuous submodular optimization. We
apply our methods to develop a novel &quot;lifting&quot; framework for the online
discrete submodular maximization and also see that they outperform current
state of the art techniques on an extensive set of experiments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chen_L/0/1/0/all/0/1&quot;&gt;Lin Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Harshaw_C/0/1/0/all/0/1&quot;&gt;Christopher Harshaw&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hassani_H/0/1/0/all/0/1&quot;&gt;Hamed Hassani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Karbasi_A/0/1/0/all/0/1&quot;&gt;Amin Karbasi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08365">
<title>Budget Constrained Bidding by Model-free Reinforcement Learning in Display Advertising. (arXiv:1802.08365v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1802.08365</link>
<description rdf:parseType="Literal">&lt;p&gt;Real-time bidding (RTB) is almost the most important mechanism in online
display advertising, where proper bid for each page view plays a vital and
essential role for good marketing results. Budget constrained bidding is a
typical scenario in RTB mechanism where the advertisers hope to maximize total
value of winning impressions under a pre-set budget constraint. However, the
optimal strategy is hard to be derived due to complexity and volatility of the
auction environment. To address the challenges, in this paper, we formulate
budget constrained bidding as a Markov Decision Process. Quite different from
prior model-based work, we propose a novel framework based on model-free
reinforcement learning which sequentially regulates the bidding parameter
rather than directly producing bid. Along this line, we further innovate a
reward function which deploys a deep neural network to learn appropriate reward
and thus leads the agent to deliver the optimal policy effectively; we also
design an adaptive $\epsilon$-greedy strategy which adjusts the exploration
behaviour dynamically and further improves the performance. Experimental
results on real dataset demonstrate the effectiveness of our framework.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_D/0/1/0/all/0/1&quot;&gt;Di Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1&quot;&gt;Xiujun Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1&quot;&gt;Xun Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1&quot;&gt;Hao Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tan_Q/0/1/0/all/0/1&quot;&gt;Qing Tan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xiaoxun Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gai_K/0/1/0/all/0/1&quot;&gt;Kun Gai&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08545">
<title>Unsupervised Grammar Induction with Depth-bounded PCFG. (arXiv:1802.08545v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1802.08545</link>
<description rdf:parseType="Literal">&lt;p&gt;There has been recent interest in applying cognitively or empirically
motivated bounds on recursion depth to limit the search space of grammar
induction models (Ponvert et al., 2011; Noji and Johnson, 2016; Shain et al.,
2016). This work extends this depth-bounding approach to probabilistic
context-free grammar induction (DB-PCFG), which has a smaller parameter space
than hierarchical sequence models, and therefore more fully exploits the space
reductions of depth-bounding. Results for this model on grammar acquisition
from transcribed child-directed speech and newswire text exceed or are
competitive with those of other models when evaluated on parse accuracy.
Moreover, gram- mars acquired from this model demonstrate a consistent use of
category labels, something which has not been demonstrated by other acquisition
models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jin_L/0/1/0/all/0/1&quot;&gt;Lifeng Jin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Doshi_Velez_F/0/1/0/all/0/1&quot;&gt;Finale Doshi-Velez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Miller_T/0/1/0/all/0/1&quot;&gt;Timothy Miller&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schuler_W/0/1/0/all/0/1&quot;&gt;William Schuler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schwartz_L/0/1/0/all/0/1&quot;&gt;Lane Schwartz&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06306">
<title>Optimizing Interactive Systems with Data-Driven Objectives. (arXiv:1802.06306v2 [cs.AI] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1802.06306</link>
<description rdf:parseType="Literal">&lt;p&gt;Effective optimization is essential for interactive systems to provide a
satisfactory user experience. However, it is often challenging to find an
objective to optimize for. Generally, such objectives are manually crafted and
rarely capture complex user needs accurately. Conversely, we propose an
approach that infers the objective directly from observed user interactions.
These inferences can be made regardless of prior knowledge and across different
types of user behavior. Then we introduce: Interactive System Optimizer (ISO),
a novel algorithm that uses these inferred objectives for optimization. Our
main contribution is a new general principled approach to optimizing
interactive systems using data-driven objectives. We demonstrate the high
effectiveness of ISO over several GridWorld simulations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Ziming Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grotov_A/0/1/0/all/0/1&quot;&gt;Artem Grotov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kiseleva_J/0/1/0/all/0/1&quot;&gt;Julia Kiseleva&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rijke_M/0/1/0/all/0/1&quot;&gt;Maarten de Rijke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oosterhuis_H/0/1/0/all/0/1&quot;&gt;Harrie Oosterhuis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08686">
<title>Adversarial vulnerability for any classifier. (arXiv:1802.08686v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.08686</link>
<description rdf:parseType="Literal">&lt;p&gt;Despite achieving impressive and often superhuman performance on multiple
benchmarks, state-of-the-art deep networks remain highly vulnerable to
perturbations: adding small, imperceptible, adversarial perturbations can lead
to very high error rates. Provided the data distribution is defined using a
generative model mapping latent vectors to datapoints in the distribution, we
prove that no classifier can be robust to adversarial perturbations when the
latent space is sufficiently large and the generative model sufficiently
smooth. Under the same conditions, we prove the existence of adversarial
perturbations that transfer well across different models with small risk. We
conclude the paper with experiments validating the theoretical bounds.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fawzi_A/0/1/0/all/0/1&quot;&gt;Alhussein Fawzi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fawzi_H/0/1/0/all/0/1&quot;&gt;Hamza Fawzi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fawzi_O/0/1/0/all/0/1&quot;&gt;Omar Fawzi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08735">
<title>A DIRT-T Approach to Unsupervised Domain Adaptation. (arXiv:1802.08735v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.08735</link>
<description rdf:parseType="Literal">&lt;p&gt;Domain adaptation refers to the problem of leveraging labeled data in a
source domain to learn an accurate model in a target domain where labels are
scarce or unavailable. A recent approach for finding a common representation of
the two domains is via domain adversarial training (Ganin &amp;amp; Lempitsky, 2015),
which attempts to induce a feature extractor that matches the source and target
feature distributions in some feature space. However, domain adversarial
training faces two critical limitations: 1) if the feature extraction function
has high-capacity, then feature distribution matching is a weak constraint, 2)
in non-conservative domain adaptation (where no single classifier can perform
well in both the source and target domains), training the model to do well on
the source domain hurts performance on the target domain. In this paper, we
address these issues through the lens of the cluster assumption, i.e., decision
boundaries should not cross high-density data regions. We propose two novel and
related models: 1) the Virtual Adversarial Domain Adaptation (VADA) model,
which combines domain adversarial training with a penalty term that punishes
the violation the cluster assumption; 2) the Decision-boundary Iterative
Refinement Training with a Teacher (DIRT-T) model, which takes the VADA model
as initialization and employs natural gradient steps to further minimize the
cluster assumption violation. Extensive empirical results demonstrate that the
combination of these two models significantly improve the state-of-the-art
performance on the digit, traffic sign, and Wi-Fi recognition domain adaptation
benchmarks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Shu_R/0/1/0/all/0/1&quot;&gt;Rui Shu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bui_H/0/1/0/all/0/1&quot;&gt;Hung H. Bui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Narui_H/0/1/0/all/0/1&quot;&gt;Hirokazu Narui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ermon_S/0/1/0/all/0/1&quot;&gt;Stefano Ermon&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08736">
<title>Estimating Graphlet Statistics via Lifting. (arXiv:1802.08736v1 [stat.ME])</title>
<link>http://arxiv.org/abs/1802.08736</link>
<description rdf:parseType="Literal">&lt;p&gt;Exploratory analysis over network data is often limited by our ability to
efficiently calculate graph statistics, which can provide a model-free
understanding of macroscopic properties of a network. This work introduces a
framework for estimating the graphlet count - the number of occurrences of a
small subgraph motif (e.g. a wedge or a triangle) in the network. For massive
graphs, where accessing the whole graph is not possible, the only viable
algorithms are those which act locally by making a limited number of vertex
neighborhood queries.
&lt;/p&gt;
&lt;p&gt;We introduce a Monte Carlo sampling technique for graphlet counts, called
lifting, which can simultaneously sample all graphlets of size up to $k$
vertices. We outline three variants of lifted graphlet counts: the ordered,
unordered, and shotgun estimators. We prove that our graphlet count updates are
unbiased for the true graphlet count, have low correlation between samples, and
have a controlled variance. We compare the experimental performance of lifted
graphlet counts to the state-of-the art graphlet sampling procedures: Waddling
and the pairwise subgraph random walk.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Paramonov_K/0/1/0/all/0/1&quot;&gt;Kirill Paramonov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sharpnack_J/0/1/0/all/0/1&quot;&gt;James Sharpnack&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08761">
<title>Behavioral-clinical phenotyping with type 2 diabetes self-monitoring data. (arXiv:1802.08761v1 [stat.AP])</title>
<link>http://arxiv.org/abs/1802.08761</link>
<description rdf:parseType="Literal">&lt;p&gt;Objective: To evaluate unsupervised clustering methods for identifying
individual-level behavioral-clinical phenotypes that relate personal biomarkers
and behavioral traits in type 2 diabetes (T2DM) self-monitoring data. Materials
and Methods: We used hierarchical clustering (HC) to identify groups of meals
with similar nutrition and glycemic impact for 6 individuals with T2DM who
collected self-monitoring data. We evaluated clusters on: 1) correspondence to
gold standards generated by certified diabetes educators (CDEs) for 3
participants; 2) face validity, rated by CDEs, and 3) impact on CDEs&apos; ability
to identify patterns for another 3 participants. Results: Gold standard (GS)
included 9 patterns across 3 participants. Of these, all 9 were re-discovered
using HC: 4 GS patterns were consistent with patterns identified by HC (over
50% of meals in a cluster followed the pattern); another 5 were included as
sub-groups in broader clusers. 50% (9/18) of clusters were rated over 3 on
5-point Likert scale for validity, significance, and being actionable. After
reviewing clusters, CDEs identified patterns that were more consistent with
data (70% reduction in contradictions between patterns and participants&apos;
records). Discussion: Hierarchical clustering of blood glucose and
macronutrient consumption appears suitable for discovering behavioral-clinical
phenotypes in T2DM. Most clusters corresponded to gold standard and were rated
positively by CDEs for face validity. Cluster visualizations helped CDEs
identify more robust patterns in nutrition and glycemic impact, creating new
possibilities for visual analytic solutions. Conclusion: Machine learning
methods can use diabetes self-monitoring data to create personalized
behavioral-clinical phenotypes, which may prove useful for delivering
personalized medicine.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Levine_M/0/1/0/all/0/1&quot;&gt;Matthew E. Levine&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Albers_D/0/1/0/all/0/1&quot;&gt;David J. Albers&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Burgermaster_M/0/1/0/all/0/1&quot;&gt;Marissa Burgermaster&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Davidson_P/0/1/0/all/0/1&quot;&gt;Patricia G. Davidson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Smaldone_A/0/1/0/all/0/1&quot;&gt;Arlene M. Smaldone&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mamykina_L/0/1/0/all/0/1&quot;&gt;Lena Mamykina&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08762">
<title>Diffusion Maps meet Nystr\&quot;om. (arXiv:1802.08762v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.08762</link>
<description rdf:parseType="Literal">&lt;p&gt;Diffusion maps are an emerging data-driven technique for non-linear
dimensionality reduction, which are especially useful for the analysis of
coherent structures and nonlinear embeddings of dynamical systems. However, the
computational complexity of the diffusion maps algorithm scales with the number
of observations. Thus, long time-series data presents a significant challenge
for fast and efficient embedding. We propose integrating the Nystr\&quot;om method
with diffusion maps in order to ease the computational demand. We achieve a
speedup of roughly two to four times when approximating the dominant diffusion
map components.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Erichson_N/0/1/0/all/0/1&quot;&gt;N. Benjamin Erichson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mathelin_L/0/1/0/all/0/1&quot;&gt;Lionel Mathelin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Brunton_S/0/1/0/all/0/1&quot;&gt;Steven L. Brunton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kutz_J/0/1/0/all/0/1&quot;&gt;J. Nathan Kutz&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08855">
<title>Minimax Distribution Estimation in Wasserstein Distance. (arXiv:1802.08855v1 [math.ST])</title>
<link>http://arxiv.org/abs/1802.08855</link>
<description rdf:parseType="Literal">&lt;p&gt;The Wasserstein metric is an important measure of distance between
probability distributions, with several applications in machine learning,
statistics, probability theory, and data analysis. In this paper, we upper and
lower bound minimax rates for the problem of estimating a probability
distribution under Wasserstein loss, in terms of metric properties, such as
covering and packing numbers, of the underlying sample space.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Singh_S/0/1/0/all/0/1&quot;&gt;Shashank Singh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Poczos_B/0/1/0/all/0/1&quot;&gt;Barnab&amp;#xe1;s P&amp;#xf3;czos&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08898">
<title>Dimensionally Tight Running Time Bounds for Second-Order Hamiltonian Monte Carlo. (arXiv:1802.08898v1 [cs.DS])</title>
<link>http://arxiv.org/abs/1802.08898</link>
<description rdf:parseType="Literal">&lt;p&gt;Hamiltonian Monte Carlo (HMC) is a widely deployed method to sample from a
given high-dimensional distribution in Statistics and Machine learning. HMC is
known to run very efficiently in practice and its second-order variant was
conjectured to run in $d^{1/4}$ steps in 1988. Here we show that this
conjecture is true when sampling from strongly log-concave target distributions
that satisfy weak third-order regularity properties associated with the input
data. This improves upon a recent result that shows that the number of steps of
the second-order discretization of HMC grows like $d^{1/4}$ under the much
stronger assumption that the distribution is separable and its first four
Fr\&apos;echet derivatives are bounded. Our result also compares favorably with the
best available running time bounds for the class of strongly log-concave
distributions, namely the current best bounds for both the overdamped and
underdamped Langevin, and first-order HMC Algorithms, which all grow like
$d^{{1}/{2}}$ with the dimension. Key to our result is a new regularity
condition for the Hessian that may be of independent interest. The class of
distributions that satisfy this condition are natural and include posterior
distributions used in Bayesian logistic &quot;ridge&quot; regression.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mangoubi_O/0/1/0/all/0/1&quot;&gt;Oren Mangoubi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vishnoi_N/0/1/0/all/0/1&quot;&gt;Nisheeth K. Vishnoi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08976">
<title>Dynamic Bidding for Advance Commitments in Truckload Brokerage Markets. (arXiv:1802.08976v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.08976</link>
<description rdf:parseType="Literal">&lt;p&gt;Truckload brokerages, a $100 billion/year industry in the U.S., plays the
critical role of matching shippers with carriers, often to move loads several
days into the future. Brokerages not only have to find companies that will
agree to move a load, the brokerage often has to find a price that both the
shipper and carrier will agree to. The price not only varies by shipper and
carrier, but also by the traffic lanes and other variables such as commodity
type. Brokerages have to learn about shipper and carrier response functions by
offering a price and observing whether each accepts the quote. We propose a
knowledge gradient policy with bootstrap aggregation for high-dimensional
contextual settings to guide price experimentation by maximizing the value of
information. The learning policy is tested using a newly developed, carefully
calibrated fleet simulator that includes a stochastic lookahead policy that
simulates fleet movements, as well as the stochastic modeling of driver
assignments and the carrier&apos;s load commitment policies with advance booking.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yingfei Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Nascimento_J/0/1/0/all/0/1&quot;&gt;Juliana Martins Do Nascimento&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Powell_W/0/1/0/all/0/1&quot;&gt;Warren Powell&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09052">
<title>Wide Compression: Tensor Ring Nets. (arXiv:1802.09052v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.09052</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep neural networks have demonstrated state-of-the-art performance in a
variety of real-world applications. In order to obtain performance gains, these
networks have grown larger and deeper, containing millions or even billions of
parameters and over a thousand layers. The trade-off is that these large
architectures require an enormous amount of memory, storage, and computation,
thus limiting their usability. Inspired by the recent tensor ring
factorization, we introduce Tensor Ring Networks (TR-Nets), which significantly
compress both the fully connected layers and the convolutional layers of deep
neural networks. Our results show that our TR-Nets approach {is able to
compress LeNet-5 by $11\times$ without losing accuracy}, and can compress the
state-of-the-art Wide ResNet by $243\times$ with only 2.3\% degradation in
{Cifar10 image classification}. Overall, this compression scheme shows promise
in scientific computing and deep learning, especially for emerging
resource-constrained devices such as smartphones, wearables, and IoT devices.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1&quot;&gt;Wenqi Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1&quot;&gt;Yifan Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Eriksson_B/0/1/0/all/0/1&quot;&gt;Brian Eriksson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1&quot;&gt;Wenlin Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aggarwal_V/0/1/0/all/0/1&quot;&gt;Vaneet Aggarwal&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09086">
<title>Conditionally Independent Multiresolution Gaussian Processes. (arXiv:1802.09086v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.09086</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a multiresolution Gaussian process (GP) model which assumes
conditional independence among GPs across resolutions. We characterize each GP
using a particular representation of the Karhunen-Lo\`eve expansion where each
basis vector of the representation consists of an axis and a scale factor,
referred to as the basis axis and the basis-axis scale. The basis axes have
unique characteristics: They are zero-mean by construction and are on the unit
sphere. The axes are modeled using Bingham distributions---a natural choice for
modeling axial data. Given the axes, all GPs across resolutions are
independent---this is in direct contrast to the common assumption of full
independence between GPs. More specifically, all GPs are tied to the same set
of axes but the basis-axis scales of each GP are specific to the resolution on
which they are defined. Relaxing the full independence assumption helps in
reducing overfitting which can be of a problem in an otherwise identical model
architecture with full independence assumption. We consider a Bayesian
treatment of the model using variational inference.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Taghia_J/0/1/0/all/0/1&quot;&gt;Jalil Taghia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Schon_T/0/1/0/all/0/1&quot;&gt;Thomas B. Sch&amp;#xf6;n&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09127">
<title>Deep Bayesian Bandits Showdown: An Empirical Comparison of Bayesian Deep Networks for Thompson Sampling. (arXiv:1802.09127v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.09127</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent advances in deep reinforcement learning have made significant strides
in performance on applications such as Go and Atari games. However, developing
practical methods to balance exploration and exploitation in complex domains
remains largely unsolved. Thompson Sampling and its extension to reinforcement
learning provide an elegant approach to exploration that only requires access
to posterior samples of the model. At the same time, advances in approximate
Bayesian methods have made posterior approximation for flexible neural network
models practical. Thus, it is attractive to consider approximate Bayesian
neural networks in a Thompson Sampling framework. To understand the impact of
using an approximate posterior on Thompson Sampling, we benchmark
well-established and recently developed methods for approximate posterior
sampling combined with Thompson Sampling over a series of contextual bandit
problems. We found that many approaches that have been successful in the
supervised learning setting underperformed in the sequential decision-making
scenario. In particular, we highlight the challenge of adapting slowly
converging uncertainty estimates to the online setting.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Riquelme_C/0/1/0/all/0/1&quot;&gt;Carlos Riquelme&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tucker_G/0/1/0/all/0/1&quot;&gt;George Tucker&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Snoek_J/0/1/0/all/0/1&quot;&gt;Jasper Snoek&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09188">
<title>Analysis of Langevin Monte Carlo via convex optimization. (arXiv:1802.09188v1 [stat.CO])</title>
<link>http://arxiv.org/abs/1802.09188</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we provide new insights on the Unadjusted Langevin Algorithm.
We show that this method can be formulated as a first order optimization
algorithm of an objective functional defined on the Wasserstein space of order
$2$. Using this interpretation and techniques borrowed from convex
optimization, we give a non-asymptotic analysis of this method to sample from
logconcave smooth target distribution on $\mathbb{R}^d$. Our proofs are then
easily extended to the Stochastic Gradient Langevin Dynamics, which is a
popular extension of the Unadjusted Langevin Algorithm. Finally, this
interpretation leads to a new methodology to sample from a non-smooth target
distribution, for which a similar study is done.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Durmus_A/0/1/0/all/0/1&quot;&gt;Alain Durmus&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Majewski_S/0/1/0/all/0/1&quot;&gt;Szymon Majewski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Miasojedow_B/0/1/0/all/0/1&quot;&gt;B&amp;#x142;a&amp;#x17c;ej Miasojedow&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09210">
<title>A representer theorem for deep neural networks. (arXiv:1802.09210v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.09210</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose to optimize the activation functions of a deep neural network by
adding a corresponding functional regularization to the cost function. We
justify the use of a second-order total-variation criterion. This allows us to
derive a general representer theorem for deep neural networks that makes a
direct connection with splines and sparsity. Specifically, we show that the
optimal network configuration can be achieved with activation functions that
are nonuniform linear splines with adaptive knots. The bottom line is that the
action of each neuron is encoded by a spline whose parameters (including the
number of knots) are optimized during the training procedure. The scheme
results in a computational structure that is compatible with the existing
deep-ReLU and MaxOut architectures. It also suggests novel optimization
challenges, while making the link with $\ell_1$ minimization and
sparsity-promoting techniques explicit.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Unser_M/0/1/0/all/0/1&quot;&gt;Michael Unser&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09225">
<title>Interpreting Complex Regression Models. (arXiv:1802.09225v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.09225</link>
<description rdf:parseType="Literal">&lt;p&gt;Interpretation of a machine learning induced models is critical for feature
engineering, debugging, and, arguably, compliance. Yet, best of breed machine
learning models tend to be very complex. This paper presents a method for model
interpretation which has the main benefit that the simple interpretations it
provides are always grounded in actual sets of learning examples. The method is
validated on the task of interpreting a complex regression model in the context
of both an academic problem -- predicting the year in which a song was recorded
and an industrial one -- predicting mail user churn.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Avigdor_Elgrabli_N/0/1/0/all/0/1&quot;&gt;Noa Avigdor-Elgrabli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Libov_A/0/1/0/all/0/1&quot;&gt;Alex Libov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Viderman_M/0/1/0/all/0/1&quot;&gt;Michael Viderman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wolff_R/0/1/0/all/0/1&quot;&gt;Ran Wolff&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09246">
<title>Scalable kernel-based variable selection with sparsistency. (arXiv:1802.09246v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.09246</link>
<description rdf:parseType="Literal">&lt;p&gt;Variable selection is central to high-dimensional data analysis, and various
algorithms have been developed. Ideally, a variable selection algorithm shall
be flexible, scalable, and with theoretical guarantee, yet most existing
algorithms cannot attain these properties at the same time. In this article, a
three-step variable selection algorithm is developed, involving kernel-based
estimation of the regression function and its gradient functions as well as a
hard thresholding. Its key advantage is that it assumes no explicit model
assumption, admits general predictor effects, allows for scalable computation,
and attains desirable asymptotic sparsistency. The proposed algorithm can be
adapted to any reproducing kernel Hilbert space (RKHS) with different kernel
functions, and can be extended to interaction selection with slight
modification. Its computational cost is only linear in the data dimension, and
can be further improved through parallel computing. The sparsistency of the
proposed algorithm is established for general RKHS under mild conditions,
including linear and Gaussian kernels as special cases. Its effectiveness is
also supported by a variety of simulated and real examples.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+He_X/0/1/0/all/0/1&quot;&gt;Xin He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Junhui Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lv_S/0/1/0/all/0/1&quot;&gt;Shaogao Lv&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09371">
<title>Autoencoder based image compression: can the learning be quantization independent?. (arXiv:1802.09371v1 [eess.IV])</title>
<link>http://arxiv.org/abs/1802.09371</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper explores the problem of learning transforms for image compression
via autoencoders. Usually, the rate-distortion performances of image
compression are tuned by varying the quantization step size. In the case of
autoen-coders, this in principle would require learning one transform per
rate-distortion point at a given quantization step size. Here, we show that
comparable performances can be obtained with a unique learned transform. The
different rate-distortion points are then reached by varying the quantization
step size at test time. This approach saves a lot of training time.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Dumas_T/0/1/0/all/0/1&quot;&gt;Thierry Dumas&lt;/a&gt; (Sirocco), &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Roumy_A/0/1/0/all/0/1&quot;&gt;Aline Roumy&lt;/a&gt; (Sirocco), &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Guillemot_C/0/1/0/all/0/1&quot;&gt;Christine Guillemot&lt;/a&gt; (Sirocco)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09511">
<title>Missing Data in Sparse Transition Matrix Estimation for Sub-Gaussian Vector Autoregressive Processes. (arXiv:1802.09511v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.09511</link>
<description rdf:parseType="Literal">&lt;p&gt;High-dimensional time series data exist in numerous areas such as finance,
genomics, healthcare, and neuroscience. An unavoidable aspect of all such
datasets is missing data, and dealing with this issue has been an important
focus in statistics, control, and machine learning. In this work, we consider a
high-dimensional estimation problem where a dynamical system, governed by a
stable vector autoregressive model, is randomly and only partially observed at
each time point. Our task amounts to estimating the transition matrix, which is
assumed to be sparse. In such a scenario, where covariates are highly
interdependent and partially missing, new theoretical challenges arise. While
transition matrix estimation in vector autoregressive models has been studied
previously, the missing data scenario requires separate efforts. Moreover,
while transition matrix estimation can be studied from a high-dimensional
sparse linear regression perspective, the covariates are highly dependent and
existing results on regularized estimation with missing data from
i.i.d.~covariates are not applicable. At the heart of our analysis lies 1) a
novel concentration result when the innovation noise satisfies the convex
concentration property, as well as 2) a new quantity for characterizing the
interactions of the time-varying observation process with the underlying
dynamical system.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Jalali_A/0/1/0/all/0/1&quot;&gt;Amin Jalali&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Willett_R/0/1/0/all/0/1&quot;&gt;Rebecca Willett&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1308.1269">
<title>On b-bit min-wise hashing for large-scale regression and classification with sparse data. (arXiv:1308.1269v4 [math.ST] UPDATED)</title>
<link>http://arxiv.org/abs/1308.1269</link>
<description rdf:parseType="Literal">&lt;p&gt;Large-scale regression problems where both the number of variables, $p$, and
the number of observations, $n$, may be large and in the order of millions or
more, are becoming increasingly more common. Typically the data are sparse:
only a fraction of a percent of the entries in the design matrix are non-zero.
Nevertheless, often the only computationally feasible approach is to perform
dimension reduction to obtain a new design matrix with far fewer columns and
then work with this compressed data.
&lt;/p&gt;
&lt;p&gt;$b$-bit min-wise hashing (Li and Konig, 2011) is a promising dimension
reduction scheme for sparse matrices which produces a set of random features
such that regression on the resulting design matrix approximates a kernel
regression with the resemblance kernel. In this work, we derive bounds on the
prediction error of such regressions. For both linear and logistic models we
show that the average prediction error vanishes asymptotically as long as $q
\|\beta^*\|_2^2 /n \rightarrow 0$, where $q$ is the average number of non-zero
entries in each row of the design matrix and $\beta^*$ is the coefficient of
the linear predictor.
&lt;/p&gt;
&lt;p&gt;We also show that ordinary least squares or ridge regression applied to the
reduced data can in fact allow us fit more flexible models. We obtain
non-asymptotic prediction error bounds for interaction models and for models
where an unknown row normalisation must be applied in order for the signal to
be linear in the predictors.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Shah_R/0/1/0/all/0/1&quot;&gt;Rajen D. Shah&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Meinshausen_N/0/1/0/all/0/1&quot;&gt;Nicolai Meinshausen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1610.00843">
<title>The Search Problem in Mixture Models. (arXiv:1610.00843v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1610.00843</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the task of learning the parameters of a {\em single} component
of a mixture model, for the case when we are given {\em side information} about
that component, we call this the &quot;search problem&quot; in mixture models. We would
like to solve this with computational and sample complexity lower than solving
the overall original problem, where one learns parameters of all components.
&lt;/p&gt;
&lt;p&gt;Our main contributions are the development of a simple but general model for
the notion of side information, and a corresponding simple matrix-based
algorithm for solving the search problem in this general setting. We then
specialize this model and algorithm to four common scenarios: Gaussian mixture
models, LDA topic models, subspace clustering, and mixed linear regression. For
each one of these we show that if (and only if) the side information is
informative, we obtain parameter estimates with greater accuracy, and also
improved computation complexity than existing moment based mixture model
algorithms (e.g. tensor methods). We also illustrate several natural ways one
can obtain such side information, for specific problem instances. Our
experiments on real data sets (NY Times, Yelp, BSDS500) further demonstrate the
practicality of our algorithms showing significant improvement in runtime and
accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ray_A/0/1/0/all/0/1&quot;&gt;Avik Ray&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Neeman_J/0/1/0/all/0/1&quot;&gt;Joe Neeman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sanghavi_S/0/1/0/all/0/1&quot;&gt;Sujay Sanghavi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Shakkottai_S/0/1/0/all/0/1&quot;&gt;Sanjay Shakkottai&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1701.04389">
<title>Real-Time Energy Disaggregation of a Distribution Feeder&apos;s Demand Using Online Learning. (arXiv:1701.04389v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1701.04389</link>
<description rdf:parseType="Literal">&lt;p&gt;Though distribution system operators have been adding more sensors to their
networks, they still often lack an accurate real-time picture of the behavior
of distributed energy resources such as demand responsive electric loads and
residential solar generation. Such information could improve system
reliability, economic efficiency, and environmental impact. Rather than
installing additional, costly sensing and communication infrastructure to
obtain additional real-time information, it may be possible to use existing
sensing capabilities and leverage knowledge about the system to reduce the need
for new infrastructure. In this paper, we disaggregate a distribution feeder&apos;s
demand measurements into: 1) the demand of a population of air conditioners,
and 2) the demand of the remaining loads connected to the feeder. We use an
online learning algorithm, Dynamic Fixed Share (DFS), that uses the real-time
distribution feeder measurements as well as models generated from historical
building- and device-level data. We develop two implementations of the
algorithm and conduct case studies using real demand data from households and
commercial buildings to investigate the effectiveness of the algorithm. The
case studies demonstrate that DFS can effectively perform online disaggregation
and the choice and construction of models included in the algorithm affects its
accuracy, which is comparable to that of a set of Kalman filters.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ledva_G/0/1/0/all/0/1&quot;&gt;Gregory S. Ledva&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Balzano_L/0/1/0/all/0/1&quot;&gt;Laura Balzano&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mathieu_J/0/1/0/all/0/1&quot;&gt;Johanna L. Mathieu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1702.06818">
<title>Stochastic Approximation for Canonical Correlation Analysis. (arXiv:1702.06818v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1702.06818</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose novel first-order stochastic approximation algorithms for
canonical correlation analysis (CCA). Algorithms presented are instances of
inexact matrix stochastic gradient (MSG) and inexact matrix exponentiated
gradient (MEG), and achieve $\epsilon$-suboptimality in the population
objective in $\operatorname{poly}(\frac{1}{\epsilon})$ iterations. We also
consider practical variants of the proposed algorithms and compare them with
other methods for CCA both theoretically and empirically.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Arora_R/0/1/0/all/0/1&quot;&gt;Raman Arora&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Marinov_T/0/1/0/all/0/1&quot;&gt;Teodor V. Marinov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mianjy_P/0/1/0/all/0/1&quot;&gt;Poorya Mianjy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Srebro_N/0/1/0/all/0/1&quot;&gt;Nathan Srebro&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1702.07305">
<title>Online Multiclass Boosting. (arXiv:1702.07305v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1702.07305</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent work has extended the theoretical analysis of boosting algorithms to
multiclass problems and to online settings. However, the multiclass extension
is in the batch setting and the online extensions only consider binary
classification. We fill this gap in the literature by defining, and justifying,
a weak learning condition for online multiclass boosting. This condition leads
to an optimal boosting algorithm that requires the minimal number of weak
learners to achieve a certain accuracy. Additionally, we propose an adaptive
algorithm which is near optimal and enjoys an excellent performance on real
data due to its adaptive property.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Jung_Y/0/1/0/all/0/1&quot;&gt;Young Hun Jung&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Goetz_J/0/1/0/all/0/1&quot;&gt;Jack Goetz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tewari_A/0/1/0/all/0/1&quot;&gt;Ambuj Tewari&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1705.10762">
<title>Generative Models of Visually Grounded Imagination. (arXiv:1705.10762v7 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1705.10762</link>
<description rdf:parseType="Literal">&lt;p&gt;It is easy for people to imagine what a man with pink hair looks like, even
if they have never seen such a person before. We call the ability to create
images of novel semantic concepts visually grounded imagination. In this paper,
we show how we can modify variational auto-encoders to perform this task. Our
method uses a novel training objective, and a novel product-of-experts
inference network, which can handle partially specified (abstract) concepts in
a principled and efficient way. We also propose a set of easy-to-compute
evaluation metrics that capture our intuitive notions of what it means to have
good visual imagination, namely correctness, coverage, and compositionality
(the 3 C&apos;s). Finally, we perform a detailed comparison of our method with two
existing joint image-attribute VAE methods (the JMVAE method of Suzuki et.al.
and the BiVCCA method of Wang et.al.) by applying them to two datasets: the
MNIST-with-attributes dataset (which we introduce here), and the CelebA
dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vedantam_R/0/1/0/all/0/1&quot;&gt;Ramakrishna Vedantam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fischer_I/0/1/0/all/0/1&quot;&gt;Ian Fischer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1&quot;&gt;Jonathan Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Murphy_K/0/1/0/all/0/1&quot;&gt;Kevin Murphy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1706.02690">
<title>Enhancing The Reliability of Out-of-distribution Image Detection in Neural Networks. (arXiv:1706.02690v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1706.02690</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the problem of detecting out-of-distribution images in neural
networks. We propose ODIN, a simple and effective method that does not require
any change to a pre-trained neural network. Our method is based on the
observation that using temperature scaling and adding small perturbations to
the input can separate the softmax score distributions between in- and
out-of-distribution images, allowing for more effective detection. We show in a
series of experiments that ODIN is compatible with diverse network
architectures and datasets. It consistently outperforms the baseline approach
by a large margin, establishing a new state-of-the-art performance on this
task. For example, ODIN reduces the false positive rate from the baseline 34.7%
to 4.3% on the DenseNet (applied to CIFAR-10) when the true positive rate is
95%.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_S/0/1/0/all/0/1&quot;&gt;Shiyu Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yixuan Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Srikant_R/0/1/0/all/0/1&quot;&gt;R. Srikant&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1706.03446">
<title>Deep EHR: A Survey of Recent Advances in Deep Learning Techniques for Electronic Health Record (EHR) Analysis. (arXiv:1706.03446v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1706.03446</link>
<description rdf:parseType="Literal">&lt;p&gt;The past decade has seen an explosion in the amount of digital information
stored in electronic health records (EHR). While primarily designed for
archiving patient clinical information and administrative healthcare tasks,
many researchers have found secondary use of these records for various clinical
informatics tasks. Over the same period, the machine learning community has
seen widespread advances in deep learning techniques, which also have been
successfully applied to the vast amount of EHR data. In this paper, we review
these deep EHR systems, examining architectures, technical aspects, and
clinical applications. We also identify shortcomings of current techniques and
discuss avenues of future research for EHR-based deep learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shickel_B/0/1/0/all/0/1&quot;&gt;Benjamin Shickel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tighe_P/0/1/0/all/0/1&quot;&gt;Patrick Tighe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bihorac_A/0/1/0/all/0/1&quot;&gt;Azra Bihorac&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rashidi_P/0/1/0/all/0/1&quot;&gt;Parisa Rashidi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1707.09049">
<title>Variational Recursive Dual Filtering. (arXiv:1707.09049v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1707.09049</link>
<description rdf:parseType="Literal">&lt;p&gt;State space models provide an interpretable framework for complex time series
by combining an intuitive dynamical system model with a probabilistic
observation model. We developed a flexible online learning framework for latent
nonlinear state dynamics and filtered latent states. Our method utilizes the
stochastic gradient variational Bayes method to jointly optimize the parameters
of the nonlinear dynamics, observation model, and the black-box recognition
model. Unlike previous approaches, our framework can incorporate non-trivial
observation noise models and infer in real-time. We test our method on point
process observations driven by continuous attractor dynamics, demonstrating its
ability to recover the phase portrait, filtered trajectory, and produce
long-term predictions for real-time machine learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhao_Y/0/1/0/all/0/1&quot;&gt;Yuan Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Park_I/0/1/0/all/0/1&quot;&gt;Il Memming Park&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1708.08587">
<title>On the Reconstruction Risk of Convolutional Sparse Dictionary Learning. (arXiv:1708.08587v2 [math.ST] UPDATED)</title>
<link>http://arxiv.org/abs/1708.08587</link>
<description rdf:parseType="Literal">&lt;p&gt;Sparse dictionary learning (SDL) has become a popular method for adaptively
identifying parsimonious representations of a dataset, a fundamental problem in
machine learning and signal processing. While most work on SDL assumes a
training dataset of independent and identically distributed samples, a variant
known as convolutional sparse dictionary learning (CSDL) relaxes this
assumption, allowing more general sequential data sources, such as time series
or other dependent data. Although recent work has explored the statistical
properties of classical SDL, the statistical properties of CSDL remain
unstudied. This paper begins to study this by identifying the minimax
convergence rate of CSDL in terms of reconstruction risk, by both upper
bounding the risk of an established CSDL estimator and proving a matching
information-theoretic lower bound. Our results indicate that consistency in
reconstruction risk is possible precisely in the `ultra-sparse&apos; setting, in
which the sparsity (i.e., the number of feature occurrences) is in $o(N)$ in
terms of the length N of the training sequence. Notably, our results make very
weak assumptions, allowing arbitrary dictionaries and dependent measurement
noise. Finally, we verify our theoretical results with numerical experiments on
synthetic data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Singh_S/0/1/0/all/0/1&quot;&gt;Shashank Singh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Poczos_B/0/1/0/all/0/1&quot;&gt;Barnab&amp;#xe1;s P&amp;#xf3;czos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Ma_J/0/1/0/all/0/1&quot;&gt;Jian Ma&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.00598">
<title>Lasso Regularization Paths for NARMAX Models via Coordinate Descent. (arXiv:1710.00598v2 [cs.SY] UPDATED)</title>
<link>http://arxiv.org/abs/1710.00598</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a new algorithm for estimating NARMAX models with $L_1$
regularization for models represented as a linear combination of basis
functions. Due to the $L_1$-norm penalty the Lasso estimation tends to produce
some coefficients that are exactly zero and hence gives interpretable models.
The novelty of the contribution is the inclusion of error regressors in the
Lasso estimation (which yields a nonlinear regression problem). The proposed
algorithm uses cyclical coordinate descent to compute the parameters of the
NARMAX models for the entire regularization path. It deals with the error terms
by updating the regressor matrix along with the parameter vector. In
comparative timings we find that the modification does not reduce the
computational efficiency of the original algorithm and can provide the most
important regressors in very few inexpensive iterations. The method is
illustrated for linear and polynomial models by means of two examples.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ribeiro_A/0/1/0/all/0/1&quot;&gt;Ant&amp;#xf4;nio H. Ribeiro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aguirre_L/0/1/0/all/0/1&quot;&gt;Luis A. Aguirre&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.08079">
<title>Online Boosting Algorithms for Multi-label Ranking. (arXiv:1710.08079v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1710.08079</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the multi-label ranking approach to multi-label learning.
Boosting is a natural method for multi-label ranking as it aggregates weak
predictions through majority votes, which can be directly used as scores to
produce a ranking of the labels. We design online boosting algorithms with
provable loss bounds for multi-label ranking. We show that our first algorithm
is optimal in terms of the number of learners required to attain a desired
accuracy, but it requires knowledge of the edge of the weak learners. We also
design an adaptive algorithm that does not require this knowledge and is hence
more practical. Experimental results on real data sets demonstrate that our
algorithms are at least as good as existing batch boosting algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Jung_Y/0/1/0/all/0/1&quot;&gt;Young Hun Jung&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tewari_A/0/1/0/all/0/1&quot;&gt;Ambuj Tewari&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.10551">
<title>Stochastic Zeroth-order Optimization in High Dimensions. (arXiv:1710.10551v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1710.10551</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the problem of optimizing a high-dimensional convex function
using stochastic zeroth-order queries. Under sparsity assumptions on the
gradients or function values, we present two algorithms: a successive
component/feature selection algorithm and a noisy mirror descent algorithm
using Lasso gradient estimates, and show that both algorithms have convergence
rates that de- pend only logarithmically on the ambient dimension of the
problem. Empirical results confirm our theoretical findings and show that the
algorithms we design outperform classical zeroth-order optimization methods in
the high-dimensional setting.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yining Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Du_S/0/1/0/all/0/1&quot;&gt;Simon Du&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Balakrishnan_S/0/1/0/all/0/1&quot;&gt;Sivaraman Balakrishnan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Singh_A/0/1/0/all/0/1&quot;&gt;Aarti Singh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.02283">
<title>Large-Scale Optimal Transport and Mapping Estimation. (arXiv:1711.02283v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1711.02283</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents a novel two-step approach for the fundamental problem of
learning an optimal map from one distribution to another. First, we learn an
optimal transport (OT) plan, which can be thought as a one-to-many map between
the two distributions. To that end, we propose a stochastic dual approach of
regularized OT, and show empirically that it scales better than a recent
related approach when the amount of samples is very large. Second, we estimate
a \textit{Monge map} as a deep neural network learned by approximating the
barycentric projection of the previously-obtained OT plan. This
parameterization allows generalization of the mapping outside the support of
the input measure. We prove two theoretical stability results of regularized OT
which show that our estimations converge to the OT plan and Monge map between
the underlying continuous measures. We showcase our proposed approach on two
applications: domain adaptation and generative modeling.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Seguy_V/0/1/0/all/0/1&quot;&gt;Vivien Seguy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Damodaran_B/0/1/0/all/0/1&quot;&gt;Bharath Bhushan Damodaran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Flamary_R/0/1/0/all/0/1&quot;&gt;R&amp;#xe9;mi Flamary&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Courty_N/0/1/0/all/0/1&quot;&gt;Nicolas Courty&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rolet_A/0/1/0/all/0/1&quot;&gt;Antoine Rolet&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Blondel_M/0/1/0/all/0/1&quot;&gt;Mathieu Blondel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.02771">
<title>On the Discrimination-Generalization Tradeoff in GANs. (arXiv:1711.02771v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1711.02771</link>
<description rdf:parseType="Literal">&lt;p&gt;Generative adversarial training can be generally understood as minimizing
certain moment matching loss defined by a set of discriminator functions,
typically neural networks. The discriminator set should be large enough to be
able to uniquely identify the true distribution (discriminative), and also be
small enough to go beyond memorizing samples (generalizable). In this paper, we
show that a discriminator set is guaranteed to be discriminative whenever its
linear span is dense in the set of bounded continuous functions. This is a very
mild condition satisfied even by neural networks with a single neuron. Further,
we develop generalization bounds between the learned distribution and true
distribution under different evaluation metrics. When evaluated with neural
distance, our bounds show that generalization is guaranteed as long as the
discriminator set is small enough, regardless of the size of the generator or
hypothesis set. When evaluated with KL divergence, our bound provides an
explanation on the counter-intuitive behaviors of testing likelihood in GAN
training. Our analysis sheds lights on understanding the practical performance
of GANs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1&quot;&gt;Pengchuan Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1&quot;&gt;Qiang Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_D/0/1/0/all/0/1&quot;&gt;Dengyong Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_T/0/1/0/all/0/1&quot;&gt;Tao Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1&quot;&gt;Xiaodong He&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.09325">
<title>Training Confidence-calibrated Classifiers for Detecting Out-of-Distribution Samples. (arXiv:1711.09325v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1711.09325</link>
<description rdf:parseType="Literal">&lt;p&gt;The problem of detecting whether a test sample is from in-distribution (i.e.,
training distribution by a classifier) or out-of-distribution sufficiently
different from it arises in many real-world machine learning applications.
However, the state-of-art deep neural networks are known to be highly
overconfident in their predictions, i.e., do not distinguish in- and
out-of-distributions. Recently, to handle this issue, several threshold-based
detectors have been proposed given pre-trained neural classifiers. However, the
performance of prior works highly depends on how to train the classifiers since
they only focus on improving inference procedures. In this paper, we develop a
novel training method for classifiers so that such inference algorithms can
work better. In particular, we suggest two additional terms added to the
original loss (e.g., cross entropy). The first one forces samples from
out-of-distribution less confident by the classifier and the second one is for
(implicitly) generating most effective training samples for the first one. In
essence, our method jointly trains both classification and generative neural
networks for out-of-distribution. We demonstrate its effectiveness using deep
convolutional neural networks on various popular image datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lee_K/0/1/0/all/0/1&quot;&gt;Kimin Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lee_H/0/1/0/all/0/1&quot;&gt;Honglak Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lee_K/0/1/0/all/0/1&quot;&gt;Kibok Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Shin_J/0/1/0/all/0/1&quot;&gt;Jinwoo Shin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.02390">
<title>Noisy Natural Gradient as Variational Inference. (arXiv:1712.02390v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1712.02390</link>
<description rdf:parseType="Literal">&lt;p&gt;Variational Bayesian neural nets combine the flexibility of deep learning
with Bayesian uncertainty estimation. Unfortunately, there is a tradeoff
between cheap but simple variational families (e.g.~fully factorized) or
expensive and complicated inference procedures. We show that natural gradient
ascent with adaptive weight noise implicitly fits a variational posterior to
maximize the evidence lower bound (ELBO). This insight allows us to train
full-covariance, fully factorized, or matrix-variate Gaussian variational
posteriors using noisy versions of natural gradient, Adam, and K-FAC,
respectively, making it possible to scale up to modern-size ConvNets. On
standard regression benchmarks, our noisy K-FAC algorithm makes better
predictions and matches Hamiltonian Monte Carlo&apos;s predictive variances better
than existing methods. Its improved uncertainty estimates lead to more
efficient exploration in active learning, and intrinsic motivation for
reinforcement learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_G/0/1/0/all/0/1&quot;&gt;Guodong Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_S/0/1/0/all/0/1&quot;&gt;Shengyang Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Duvenaud_D/0/1/0/all/0/1&quot;&gt;David Duvenaud&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grosse_R/0/1/0/all/0/1&quot;&gt;Roger Grosse&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.03558">
<title>Inference Suboptimality in Variational Autoencoders. (arXiv:1801.03558v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1801.03558</link>
<description rdf:parseType="Literal">&lt;p&gt;Amortized inference allows latent-variable models trained via variational
learning to scale to large datasets. The quality of approximate inference is
determined by two factors: a) the capacity of the variational distribution to
match the true posterior and b) the ability of the recognition network to
produce good variational parameters for each datapoint. We examine approximate
inference in variational autoencoders in terms of these factors. We find that
divergence from the true posterior is often due to imperfect recognition
networks, rather than the limited complexity of the approximating distribution.
We show that this is due partly to the generator learning to accommodate the
choice of approximation. Furthermore, we show that the parameters used to
increase the expressiveness of the approximation play a role in generalizing
inference rather than simply improving the complexity of the approximation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cremer_C/0/1/0/all/0/1&quot;&gt;Chris Cremer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xuechen Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Duvenaud_D/0/1/0/all/0/1&quot;&gt;David Duvenaud&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.02550">
<title>Semi-Amortized Variational Autoencoders. (arXiv:1802.02550v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1802.02550</link>
<description rdf:parseType="Literal">&lt;p&gt;Amortized variational inference (AVI) replaces instance-specific local
inference with a global inference network. While AVI has enabled efficient
training of deep generative models such as variational autoencoders (VAE),
recent empirical work suggests that inference networks can produce suboptimal
variational parameters. We propose a hybrid approach, to use AVI to initialize
the variational parameters and run stochastic variational inference (SVI) to
refine them. Crucially, the local SVI procedure is itself differentiable, so
the inference network and generative model can be trained end-to-end with
gradient-based optimization. This semi-amortized approach enables the use of
rich generative models without experiencing the posterior-collapse phenomenon
common in training VAEs for problems like text generation. Experiments show
this approach outperforms strong autoregressive and variational baselines on
standard text and image datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kim_Y/0/1/0/all/0/1&quot;&gt;Yoon Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wiseman_S/0/1/0/all/0/1&quot;&gt;Sam Wiseman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Miller_A/0/1/0/all/0/1&quot;&gt;Andrew C. Miller&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sontag_D/0/1/0/all/0/1&quot;&gt;David Sontag&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rush_A/0/1/0/all/0/1&quot;&gt;Alexander M. Rush&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04145">
<title>DCFNet: Deep Neural Network with Decomposed Convolutional Filters. (arXiv:1802.04145v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1802.04145</link>
<description rdf:parseType="Literal">&lt;p&gt;Filters in a Convolutional Neural Network (CNN) contain model parameters
learned from enormous amounts of data. In this paper, we suggest to decompose
convolutional filters in CNN as a truncated expansion with pre-fixed bases,
namely the Decomposed Convolutional Filters network (DCFNet), where the
expansion coefficients remain learned from data. Such a structure not only
reduces the number of trainable parameters and computation, but also imposes
filter regularity by bases truncation. Through extensive experiments, we
consistently observe that DCFNet maintains accuracy for image classification
tasks with a significant reduction of model parameters, particularly with
Fourier-Bessel (FB) bases, and even with random bases. Theoretically, we
analyze the representation stability of DCFNet with respect to input
variations, and prove representation stability under generic assumptions on the
expansion coefficients. The analysis is consistent with the empirical
observations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Qiu_Q/0/1/0/all/0/1&quot;&gt;Qiang Qiu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Cheng_X/0/1/0/all/0/1&quot;&gt;Xiuyuan Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Calderbank_R/0/1/0/all/0/1&quot;&gt;Robert Calderbank&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sapiro_G/0/1/0/all/0/1&quot;&gt;Guillermo Sapiro&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04712">
<title>Attention-based Deep Multiple Instance Learning. (arXiv:1802.04712v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1802.04712</link>
<description rdf:parseType="Literal">&lt;p&gt;Multiple instance learning (MIL) is a variation of supervised learning where
a single class label is assigned to a bag of instances. In this paper, we state
the MIL problem as learning the Bernoulli distribution of the bag label where
the bag label probability is fully parameterized by neural networks.
Furthermore, we propose a neural network-based permutation-invariant
aggregation operator that corresponds to the attention mechanism. Notably, an
application of the proposed attention-based operator provides insight into the
contribution of each instance to the bag label. We show empirically that our
approach achieves comparable performance to the best MIL methods on benchmark
MIL datasets and it outperforms other methods on a MNIST-based MIL dataset and
two real-life histopathology datasets without sacrificing interpretability.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ilse_M/0/1/0/all/0/1&quot;&gt;Maximilian Ilse&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tomczak_J/0/1/0/all/0/1&quot;&gt;Jakub M. Tomczak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Welling_M/0/1/0/all/0/1&quot;&gt;Max Welling&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.07796">
<title>Continuous Relaxation of MAP Inference: A Nonconvex Perspective. (arXiv:1802.07796v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1802.07796</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we study a nonconvex continuous relaxation of MAP inference in
discrete Markov random fields (MRFs). We show that for arbitrary MRFs, this
relaxation is tight, and a discrete stationary point of it can be easily
reached by a simple block coordinate descent algorithm. In addition, we study
the resolution of this relaxation using popular gradient methods, and further
propose a more effective solution using a multilinear decomposition framework
based on the alternating direction method of multipliers (ADMM). Experiments on
many real-world problems demonstrate that the proposed ADMM significantly
outperforms other nonconvex relaxation based methods, and compares favorably
with state of the art MRF optimization algorithms in different settings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Le_Huu_D/0/1/0/all/0/1&quot;&gt;D. Khu&amp;#xea; L&amp;#xea;-Huu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Paragios_N/0/1/0/all/0/1&quot;&gt;Nikos Paragios&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08598">
<title>Learning Weighted Representations for Generalization Across Designs. (arXiv:1802.08598v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1802.08598</link>
<description rdf:parseType="Literal">&lt;p&gt;Predictive models that generalize well under distributional shift are often
desirable and sometimes crucial to building robust and reliable machine
learning applications. We focus on distributional shift that arises in causal
inference from observational data and in unsupervised domain adaptation. We
pose both of these problems as prediction under a shift in design. Popular
methods for overcoming distributional shift make unrealistic assumptions such
as having a well-specified model or knowing the policy that gave rise to the
observed data. Other methods are hindered by their need for a pre-specified
metric for comparing observations, or by poor asymptotic properties. We devise
a bound on the generalization error under design shift, incorporating both
representation learning and sample re-weighting. Based on the bound, we propose
an algorithmic framework that does not require any of the above assumptions and
which is asymptotically consistent. We empirically study the new framework
using two synthetic datasets, and demonstrate its effectiveness compared to
previous methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Johansson_F/0/1/0/all/0/1&quot;&gt;Fredrik D. Johansson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kallus_N/0/1/0/all/0/1&quot;&gt;Nathan Kallus&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Shalit_U/0/1/0/all/0/1&quot;&gt;Uri Shalit&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sontag_D/0/1/0/all/0/1&quot;&gt;David Sontag&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08678">
<title>Verifying Controllers Against Adversarial Examples with Bayesian Optimization. (arXiv:1802.08678v2 [cs.SY] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1802.08678</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent successes in reinforcement learning have lead to the development of
complex controllers for real-world robots. As these robots are deployed in
safety-critical applications and interact with humans, it becomes critical to
ensure safety in order to avoid causing harm. A first step in this direction is
to test the controllers in simulation. To be able to do this, we need to
capture what we mean by safety and then efficiently search the space of all
behaviors to see if they are safe. In this paper, we present an active-testing
framework based on Bayesian Optimization. We specify safety constraints using
logic and exploit structure in the problem in order to test the system for
adversarial counter examples that violate the safety specifications. These
specifications are defined as complex boolean combinations of smooth functions
on the trajectories and, unlike reward functions in reinforcement learning, are
expressive and impose hard constraints on the system. In our framework, we
exploit regularity assumptions on individual functions in form of a Gaussian
Process (GP) prior. We combine these into a coherent optimization framework
using problem structure. The resulting algorithm is able to provably verify
complex safety specifications or alternatively find counter examples.
Experimental results show that the proposed method is able to find adversarial
examples quickly.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghosh_S/0/1/0/all/0/1&quot;&gt;Shromona Ghosh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Berkenkamp_F/0/1/0/all/0/1&quot;&gt;Felix Berkenkamp&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ranade_G/0/1/0/all/0/1&quot;&gt;Gireeja Ranade&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qadeer_S/0/1/0/all/0/1&quot;&gt;Shaz Qadeer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kapoor_A/0/1/0/all/0/1&quot;&gt;Ashish Kapoor&lt;/a&gt;</dc:creator>
</item></rdf:RDF>