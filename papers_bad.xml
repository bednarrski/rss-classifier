<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Boring papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Bad Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-01-18T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.05984"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.06007"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.00746"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.05950"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.06043"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.05788"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.05825"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.02225"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.05707"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.05852"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.05856"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.05935"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.06146"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.06147"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.06159"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1505.04252"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1605.02408"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1612.00099"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1702.07958"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1703.04455"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1708.01432"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.02030"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.04126"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1801.05984">
<title>Prediction of the Optimal Threshold Value in DF Relay Selection Schemes Based on Artificial Neural Networks. (arXiv:1801.05984v1 [eess.SP])</title>
<link>http://arxiv.org/abs/1801.05984</link>
<description rdf:parseType="Literal">&lt;p&gt;In wireless communications, the cooperative communication (CC) technology
promises performance gains compared to traditional Single-Input Single Output
(SISO) techniques. Therefore, the CC technique is one of the nominees for 5G
networks. In the Decode-and-Forward (DF) relaying scheme which is one of the CC
techniques, determination of the threshold value at the relay has a key role
for the system performance and power usage. In this paper, we propose
prediction of the optimal threshold values for the best relay selection scheme
in cooperative communications, based on Artificial Neural Networks (ANNs) for
the first time in literature. The average link qualities and number of relays
have been used as inputs in the prediction of optimal threshold values using
Artificial Neural Networks (ANNs): Multi-Layer Perceptron (MLP) and Radial
Basis Function (RBF) networks. The MLP network has better performance from the
RBF network on the prediction of optimal threshold value when the same number
of neurons is used at the hidden layer for both networks. Besides, the optimal
threshold values obtained using ANNs are verified by the optimal threshold
values obtained numerically using the closed form expression derived for the
system. The results show that the optimal threshold values obtained by ANNs on
the best relay selection scheme provide a minimum Bit-Error-Rate (BER) because
of the reduction of the probability that error propagation may occur. Also, for
the same BER performance goal, prediction of optimal threshold values provides
2dB less power usage, which is great gain in terms of green communicationBER
performance goal, prediction of optimal threshold values provides 2dB less
power usage, which is great gain in terms of green communication.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Kara_F/0/1/0/all/0/1&quot;&gt;Ferdi Kara&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Kaya_H/0/1/0/all/0/1&quot;&gt;Hakan Kaya&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Erkaymaz_O/0/1/0/all/0/1&quot;&gt;Okan Erkaymaz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Ozturk_E/0/1/0/all/0/1&quot;&gt;Ertan Ozturk&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.06007">
<title>Layered TPOT: Speeding up Tree-based Pipeline Optimization. (arXiv:1801.06007v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1801.06007</link>
<description rdf:parseType="Literal">&lt;p&gt;With the demand for machine learning increasing, so does the demand for tools
which make it easier to use. Automated machine learning (AutoML) tools have
been developed to address this need, such as the Tree-Based Pipeline
Optimization Tool (TPOT) which uses genetic programming to build optimal
pipelines. We introduce Layered TPOT, a modification to TPOT which aims to
create pipelines equally good as the original, but in significantly less time.
This approach evaluates candidate pipelines on increasingly large subsets of
the data according to their fitness, using a modified evolutionary algorithm to
allow for separate competition between pipelines trained on different sample
sizes. Empirical evaluation shows that, on sufficiently large datasets, Layered
TPOT indeed finds better models faster.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gijsbers_P/0/1/0/all/0/1&quot;&gt;Pieter Gijsbers&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vanschoren_J/0/1/0/all/0/1&quot;&gt;Joaquin Vanschoren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Olson_R/0/1/0/all/0/1&quot;&gt;Randal S. Olson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.00746">
<title>Bridging the Gap Between Neural Networks and Neuromorphic Hardware with A Neural Network Compiler. (arXiv:1801.00746v3 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1801.00746</link>
<description rdf:parseType="Literal">&lt;p&gt;Different from developing neural networks (NNs) for general-purpose
processors, the development for NN chips usually faces with some
hardware-specific restrictions, such as limited precision of network signals
and parameters, constrained computation scale, and limited types of non-linear
functions.
&lt;/p&gt;
&lt;p&gt;This paper proposes a general methodology to address the challenges. We
decouple the NN applications from the target hardware by introducing a compiler
that can transform an existing trained, unrestricted NN into an equivalent
network that meets the given hardware&apos;s constraints. We propose multiple
techniques to make the transformation adaptable to different kinds of NN chips,
and reliable for restrict hardware constraints.
&lt;/p&gt;
&lt;p&gt;We have built such a software tool that supports both spiking neural networks
(SNNs) and traditional artificial neural networks (ANNs). We have demonstrated
its effectiveness with a fabricated neuromorphic chip and a
processing-in-memory (PIM) design. Tests show that the inference error caused
by this solution is insignificant and the transformation time is much shorter
than the retraining time. Also, we have studied the parameter-sensitivity
evaluations to explore the tradeoffs between network error and resource
utilization for different transformation strategies, which could provide
insights for co-design optimization of neuromorphic hardware and software.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ji_Y/0/1/0/all/0/1&quot;&gt;Yu Ji&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;YouHui Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1&quot;&gt;WenGuang Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1&quot;&gt;Yuan Xie&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.05950">
<title>Toward Scalable Verification for Safety-Critical Deep Networks. (arXiv:1801.05950v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1801.05950</link>
<description rdf:parseType="Literal">&lt;p&gt;The increasing use of deep neural networks for safety-critical applications,
such as autonomous driving and flight control, raises concerns about their
safety and reliability. Formal verification can address these concerns by
guaranteeing that a deep learning system operates as intended, but the
state-of-the-art is limited to small systems. In this work-in-progress report
we give an overview of our work on mitigating this difficulty, by pursuing two
complementary directions: devising scalable verification techniques, and
identifying design choices that result in deep learning systems that are more
amenable to verification.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kuper_L/0/1/0/all/0/1&quot;&gt;Lindsey Kuper&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Katz_G/0/1/0/all/0/1&quot;&gt;Guy Katz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gottschlich_J/0/1/0/all/0/1&quot;&gt;Justin Gottschlich&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Julian_K/0/1/0/all/0/1&quot;&gt;Kyle Julian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barrett_C/0/1/0/all/0/1&quot;&gt;Clark Barrett&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kochenderfer_M/0/1/0/all/0/1&quot;&gt;Mykel Kochenderfer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.06043">
<title>Optimal Weighting for Exam Composition. (arXiv:1801.06043v1 [cs.CY])</title>
<link>http://arxiv.org/abs/1801.06043</link>
<description rdf:parseType="Literal">&lt;p&gt;A problem faced by many instructors is that of designing exams that
accurately assess the abilities of the students. Typically these exams are
prepared several days in advance, and generic question scores are used based on
rough approximation of the question difficulty and length. For example, for a
recent class taught by the author, there were 30 multiple choice questions
worth 3 points, 15 true/false with explanation questions worth 4 points, and 5
analytical exercises worth 10 points. We describe a novel framework where
algorithms from machine learning are used to modify the exam question weights
in order to optimize the exam scores, using the overall class grade as a proxy
for a student&apos;s true ability. We show that significant error reduction can be
obtained by our approach over standard weighting schemes, and we make several
new observations regarding the properties of the &quot;good&quot; and &quot;bad&quot; exam
questions that can have impact on the design of improved future evaluation
methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ganzfried_S/0/1/0/all/0/1&quot;&gt;Sam Ganzfried&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yusuf_F/0/1/0/all/0/1&quot;&gt;Farzana Yusuf&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.05788">
<title>Quantile Markov Decision Process. (arXiv:1711.05788v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1711.05788</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we consider the problem of optimizing the quantiles of the
cumulative rewards of Markov Decision Processes (MDP), to which we refers as
Quantile Markov Decision Processes (QMDP). Traditionally, the goal of a Markov
Decision Process (MDP) is to maximize expected cumulative reward over a defined
horizon (possibly to be infinite). In many applications, however, a decision
maker may be interested in optimizing a specific quantile of the cumulative
reward instead of its expectation. Our framework of QMDP provides analytical
results characterizing the optimal QMDP solution and presents the algorithm for
solving the QMDP. We provide analytical results characterizing the optimal QMDP
solution and present the algorithms for solving the QMDP. We illustrate the
model with two experiments: a grid game and a HIV optimal treatment experiment.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xiaocheng Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhong_H/0/1/0/all/0/1&quot;&gt;Huaiyang Zhong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brandeau_M/0/1/0/all/0/1&quot;&gt;Margaret L. Brandeau&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.05825">
<title>Bootstrapped synthetic likelihood. (arXiv:1711.05825v2 [stat.CO] UPDATED)</title>
<link>http://arxiv.org/abs/1711.05825</link>
<description rdf:parseType="Literal">&lt;p&gt;Approximate Bayesian computation (ABC) and synthetic likelihood (SL)
techniques have enabled the use of Bayesian inference for models that may be
simulated, but for which the likelihood cannot be evaluated pointwise at values
of an unknown parameter $\theta$. The main idea in ABC and SL is to, for
different values of $\theta$ (usually chosen using a Monte Carlo algorithm),
build estimates of the likelihood based on simulations from the model
conditional on $\theta$. The quality of these estimates determines the
efficiency of an ABC/SL algorithm. In standard ABC/SL, the only means to
improve an estimated likelihood at $\theta$ is to simulate more times from the
model conditional on $\theta$, which is infeasible in cases where the simulator
is computationally expensive. In this paper we describe how to use
bootstrapping as a means for improving SL estimates whilst using fewer
simulations from the model, and also investigate its use in ABC. Further, we
investigate the use of the bag of little bootstraps as a means for applying
this approach to large datasets, yielding Monte Carlo algorithms that
accurately approximate posterior distributions whilst only simulating
subsamples of the full data. Examples of the approach applied to i.i.d.,
temporal and spatial data are given.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Everitt_R/0/1/0/all/0/1&quot;&gt;Richard G. Everitt&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.02225">
<title>Pose-Normalized Image Generation for Person Re-identification. (arXiv:1712.02225v3 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1712.02225</link>
<description rdf:parseType="Literal">&lt;p&gt;Person Re-identification (re-id) faces two major challenges: the lack of
cross-view paired training data and learning discriminative identity-sensitive
and view-invariant features in the presence of large pose variations. In this
work, we address both problems by proposing a novel deep person image
generation model for synthesizing realistic person images conditional on pose.
The model is based on a generative adversarial network (GAN) and used
specifically for pose normalization in re-id, thus termed pose-normalization
GAN (PN-GAN). With the synthesized images, we can learn a new type of deep
re-id feature free of the influence of pose variations. We show that this
feature is strong on its own and highly complementary to features learned with
the original images. Importantly, we now have a model that generalizes to any
new re-id dataset without the need for collecting any training data for model
fine-tuning, thus making a deep re-id model truly scalable. Extensive
experiments on five benchmarks show that our model outperforms the
state-of-the-art models, often significantly. In particular, the features
learned on Market-1501 can achieve a Rank-1 accuracy of 68.67% on VIPeR without
any model fine-tuning, beating almost all existing models fine-tuned on the
dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qian_X/0/1/0/all/0/1&quot;&gt;Xuelin Qian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1&quot;&gt;Yanwei Fu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1&quot;&gt;Wenxuan Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiang_T/0/1/0/all/0/1&quot;&gt;Tao Xiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1&quot;&gt;Yang Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1&quot;&gt;Yu-Gang Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xue_X/0/1/0/all/0/1&quot;&gt;Xiangyang Xue&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.05707">
<title>A Generalized Dempster--Shafer Evidence Theory. (arXiv:1801.05707v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1801.05707</link>
<description rdf:parseType="Literal">&lt;p&gt;Dempster-Shafer evidence theory has been widely used in various fields of
applications. Besides, it has been proven that the quantum theory has powerful
capabilities of solving the decision making problems. However, due to the
inconsistency of the expression, the classical Dempster-Shafer evidence theory
modelled by real numbers can not be integrated directly with the quantum theory
modelled by complex numbers. The main contribution in this study is that,
unlike the existing evidence theory, a mass function in the generalized
Dempster-Shafer evidence theory is modelled by a complex number, called as a
complex mass function. When the complex mass function is degenerated from
complex numbers to real numbers, the generalized Dempster&apos;s combination rule
degenerates to the classical evidence theory. This generalized Dempster-Shafer
evidence theory provides a promising way to model and handle more uncertain
information. Numerical examples are illustrated to show the efficiency of the
generalized Dempster-Shafer evidence theory.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiao_F/0/1/0/all/0/1&quot;&gt;Fuyuan Xiao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.05852">
<title>Network Representation Learning: A Survey. (arXiv:1801.05852v1 [cs.SI])</title>
<link>http://arxiv.org/abs/1801.05852</link>
<description rdf:parseType="Literal">&lt;p&gt;With the widespread use of information technologies, information networks
have increasingly become popular to capture complex relationships across
various disciplines, such as social networks, citation networks,
telecommunication networks, and biological networks. Analyzing these networks
sheds light on different aspects of social life such as the structure of
society, information diffusion, and different patterns of communication.
However, the large scale of information networks often makes network analytic
tasks computationally expensive and intractable. Recently, network
representation learning has been proposed as a new learning paradigm that
embeds network vertices into a low-dimensional vector space, by preserving
network topology structure, vertex content, and other side information. This
facilitates the original network to be easily handled in the new vector space
for further analysis. In this survey, we perform a thorough review of the
current literature on network representation learning in the field of data
mining and machine learning. We propose a new categorization to analyze and
summarize state-of-the-art network representation learning techniques according
to the methodology they employ and the network information they preserve.
Finally, to facilitate research on this topic, we summarize benchmark datasets
and evaluation methodologies, and discuss open issues and future research
directions in this field.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1&quot;&gt;Daokun Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yin_J/0/1/0/all/0/1&quot;&gt;Jie Yin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1&quot;&gt;Xingquan Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1&quot;&gt;Chengqi Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.05856">
<title>Active Community Detection: A Maximum Likelihood Approach. (arXiv:1801.05856v1 [cs.SI])</title>
<link>http://arxiv.org/abs/1801.05856</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose novel semi-supervised and active learning algorithms for the
problem of community detection on networks. The algorithms are based on
optimizing the likelihood function of the community assignments given a graph
and an estimate of the statistical model that generated it. The optimization
framework is inspired by prior work on the unsupervised community detection
problem in Stochastic Block Models (SBM) using Semi-Definite Programming (SDP).
In this paper we provide the next steps in the evolution of learning
communities in this context which involves a constrained semi-definite
programming algorithm, and a newly presented active learning algorithm. The
active learner intelligently queries nodes that are expected to maximize the
change in the model likelihood. Experimental results show that this active
learning algorithm outperforms the random-selection semi-supervised version of
the same algorithm as well as other state-of-the-art active learning
algorithms. Our algorithms significantly improved performance is demonstrated
on both real-world and SBM-generated networks even when the SBM has a signal to
noise ratio (SNR) below the known unsupervised detectability threshold.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mirabelli_B/0/1/0/all/0/1&quot;&gt;Benjamin Mirabelli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kushnir_D/0/1/0/all/0/1&quot;&gt;Dan Kushnir&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.05935">
<title>Computation of the Maximum Likelihood estimator in low-rank Factor Analysis. (arXiv:1801.05935v1 [math.OC])</title>
<link>http://arxiv.org/abs/1801.05935</link>
<description rdf:parseType="Literal">&lt;p&gt;Factor analysis, a classical multivariate statistical technique is popularly
used as a fundamental tool for dimensionality reduction in statistics,
econometrics and data science. Estimation is often carried out via the Maximum
Likelihood (ML) principle, which seeks to maximize the likelihood under the
assumption that the positive definite covariance matrix can be decomposed as
the sum of a low rank positive semidefinite matrix and a diagonal matrix with
nonnegative entries. This leads to a challenging rank constrained nonconvex
optimization problem. We reformulate the low rank ML Factor Analysis problem as
a nonlinear nonsmooth semidefinite optimization problem, study various
structural properties of this reformulation and propose fast and scalable
algorithms based on difference of convex (DC) optimization. Our approach has
computational guarantees, gracefully scales to large problems, is applicable to
situations where the sample covariance matrix is rank deficient and adapts to
variants of the ML problem with additional constraints on the problem
parameters. Our numerical experiments demonstrate the significant usefulness of
our approach over existing state-of-the-art approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Khamaru_K/0/1/0/all/0/1&quot;&gt;Koulik Khamaru&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Mazumder_R/0/1/0/all/0/1&quot;&gt;Rahul Mazumder&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.06146">
<title>Fine-tuned Language Models for Text Classification. (arXiv:1801.06146v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1801.06146</link>
<description rdf:parseType="Literal">&lt;p&gt;Transfer learning has revolutionized computer vision, but existing approaches
in NLP still require task-specific modifications and training from scratch. We
propose Fine-tuned Language Models (FitLaM), an effective transfer learning
method that can be applied to any task in NLP, and introduce techniques that
are key for fine-tuning a state-of-the-art language model. Our method
significantly outperforms the state-of-the-art on five text classification
tasks, reducing the error by 18-24% on the majority of datasets. We open-source
our pretrained models and code to enable adoption by the community.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Howard_J/0/1/0/all/0/1&quot;&gt;Jeremy Howard&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ruder_S/0/1/0/all/0/1&quot;&gt;Sebastian Ruder&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.06147">
<title>Upgrading from Gaussian Processes to Student&apos;s-T Processes. (arXiv:1801.06147v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1801.06147</link>
<description rdf:parseType="Literal">&lt;p&gt;Gaussian process priors are commonly used in aerospace design for performing
Bayesian optimization. Nonetheless, Gaussian processes suffer two significant
drawbacks: outliers are a priori assumed unlikely, and the posterior variance
conditioned on observed data depends only on the locations of those data, not
the associated sample values. Student&apos;s-T processes are a generalization of
Gaussian processes, founded on the Student&apos;s-T distribution instead of the
Gaussian distribution. Student&apos;s-T processes maintain the primary advantages of
Gaussian processes (kernel function, analytic update rule) with additional
benefits beyond Gaussian processes. The Student&apos;s-T distribution has higher
Kurtosis than a Gaussian distribution and so outliers are much more likely, and
the posterior variance increases or decreases depending on the variance of
observed data sample values. Here, we describe Student&apos;s-T processes, and
discuss their advantages in the context of aerospace optimization. We show how
to construct a Student&apos;s-T process using a kernel function and how to update
the process given new samples. We provide a clear derivation of
optimization-relevant quantities such as expected improvement, and contrast
with the related computations for Gaussian processes. Finally, we compare the
performance of Student&apos;s-T processes against Gaussian process on canonical test
problems in Bayesian optimization, and apply the Student&apos;s-T process to the
optimization of an aerostructural design problem.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tracey_B/0/1/0/all/0/1&quot;&gt;Brendan D. Tracey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wolpert_D/0/1/0/all/0/1&quot;&gt;David H. Wolpert&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.06159">
<title>When Does Stochastic Gradient Algorithm Work Well?. (arXiv:1801.06159v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1801.06159</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we consider a general stochastic optimization problem which is
often at the core of supervised learning, such as deep learning and linear
classification. We consider a standard stochastic gradient descent (SGD) method
with a fixed, large step size and propose a novel assumption on the objective
function, under which this method has the improved convergence rates (to a
neighborhood of the optimal solutions). We then empirically demonstrate that
these assumptions hold for logistic regression and standard deep neural
networks on classical data sets. Thus our analysis helps to explain when
efficient behavior can be expected from the SGD method in training
classification models and deep neural networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Nguyen_L/0/1/0/all/0/1&quot;&gt;Lam M. Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Nguyen_N/0/1/0/all/0/1&quot;&gt;Nam H. Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Phan_D/0/1/0/all/0/1&quot;&gt;Dzung T. Phan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kalagnanam_J/0/1/0/all/0/1&quot;&gt;Jayant R. Kalagnanam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Scheinberg_K/0/1/0/all/0/1&quot;&gt;Katya Scheinberg&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1505.04252">
<title>Global Convergence of Unmodified 3-Block ADMM for a Class of Convex Minimization Problems. (arXiv:1505.04252v4 [math.OC] UPDATED)</title>
<link>http://arxiv.org/abs/1505.04252</link>
<description rdf:parseType="Literal">&lt;p&gt;The alternating direction method of multipliers (ADMM) has been successfully
applied to solve structured convex optimization problems due to its superior
practical performance. The convergence properties of the 2-block ADMM have been
studied extensively in the literature. Specifically, it has been proven that
the 2-block ADMM globally converges for any penalty parameter $\gamma&amp;gt;0$. In
this sense, the 2-block ADMM allows the parameter to be free, i.e., there is no
need to restrict the value for the parameter when implementing this algorithm
in order to ensure convergence. However, for the 3-block ADMM, Chen \etal
\cite{Chen-admm-failure-2013} recently constructed a counter-example showing
that it can diverge if no further condition is imposed. The existing results on
studying further sufficient conditions on guaranteeing the convergence of the
3-block ADMM usually require $\gamma$ to be smaller than a certain bound, which
is usually either difficult to compute or too small to make it a practical
algorithm. In this paper, we show that the 3-block ADMM still globally
converges with any penalty parameter $\gamma&amp;gt;0$ if the third function $f_3$ in
the objective is smooth and strongly convex, and its condition number is in
$[1,1.0798)$, besides some other mild conditions. This requirement covers an
important class of problems to be called regularized least squares
decomposition (RLSD) in this paper.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Lin_T/0/1/0/all/0/1&quot;&gt;Tianyi Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Ma_S/0/1/0/all/0/1&quot;&gt;Shiqian Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Zhang_S/0/1/0/all/0/1&quot;&gt;Shuzhong Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1605.02408">
<title>Structured Nonconvex and Nonsmooth Optimization: Algorithms and Iteration Complexity Analysis. (arXiv:1605.02408v5 [math.OC] UPDATED)</title>
<link>http://arxiv.org/abs/1605.02408</link>
<description rdf:parseType="Literal">&lt;p&gt;Nonconvex and nonsmooth optimization problems are frequently encountered in
much of statistics, business, science and engineering, but they are not yet
widely recognized as a technology in the sense of scalability. A reason for
this relatively low degree of popularity is the lack of a well developed system
of theory and algorithms to support the applications, as is the case for its
convex counterpart. This paper aims to take one step in the direction of
disciplined nonconvex and nonsmooth optimization. In particular, we consider in
this paper some constrained nonconvex optimization models in block decision
variables, with or without coupled affine constraints. In the case of without
coupled constraints, we show a sublinear rate of convergence to an
$\epsilon$-stationary solution in the form of variational inequality for a
generalized conditional gradient method, where the convergence rate is shown to
be dependent on the H\&quot;olderian continuity of the gradient of the smooth part
of the objective. For the model with coupled affine constraints, we introduce
corresponding $\epsilon$-stationarity conditions, and apply two proximal-type
variants of the ADMM to solve such a model, assuming the proximal ADMM updates
can be implemented for all the block variables except for the last block, for
which either a gradient step or a majorization-minimization step is
implemented. We show an iteration complexity bound of $O(1/\epsilon^2)$ to
reach an $\epsilon$-stationary solution for both algorithms. Moreover, we show
that the same iteration complexity of a proximal BCD method follows
immediately. Numerical results are provided to illustrate the efficacy of the
proposed algorithms for tensor robust PCA.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Jiang_B/0/1/0/all/0/1&quot;&gt;Bo Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Lin_T/0/1/0/all/0/1&quot;&gt;Tianyi Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Ma_S/0/1/0/all/0/1&quot;&gt;Shiqian Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Zhang_S/0/1/0/all/0/1&quot;&gt;Shuzhong Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1612.00099">
<title>PAG2ADMG: An Algorithm for the Complete Causal Enumeration of a Markov Equivalence Class. (arXiv:1612.00099v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1612.00099</link>
<description rdf:parseType="Literal">&lt;p&gt;Causal graphs, such as directed acyclic graphs (DAGs) and partial ancestral
graphs (PAGs), represent causal relationships among variables in a model.
Methods exist for learning DAGs and PAGs from data and for converting DAGs to
PAGs. However, these methods are significantly limited in that they only output
a single causal graph consistent with the independencies and dependencies (the
Markov equivalence class $M$) estimated from the data. This is problematic and
insufficient because many distinct graphs may be consistent with $M$. A data
modeler may wish to select among these numerous consistent graphs using domain
knowledge or other model selection algorithms. Enumeration of the set of
consistent graphs is the bottleneck. In this paper, we present a method that
makes this desired enumeration possible. We introduce PAG2ADMG, the first
algorithm for enumerating all causal graphs consistent with $M$. PAG2ADMG
converts a given PAG into the complete set of acyclic directed mixed graphs
(ADMGs) consistent with $M$. We prove the correctness of the approach and
demonstrate its efficiency relative to brute-force enumeration.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Subramani_N/0/1/0/all/0/1&quot;&gt;Nishant Subramani&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1702.07958">
<title>Efficient Online Bandit Multiclass Learning with $\tilde{O}(\sqrt{T})$ Regret. (arXiv:1702.07958v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1702.07958</link>
<description rdf:parseType="Literal">&lt;p&gt;We present an efficient second-order algorithm with
$\tilde{O}(\frac{1}{\eta}\sqrt{T})$ regret for the bandit online multiclass
problem. The regret bound holds simultaneously with respect to a family of loss
functions parameterized by $\eta$, for a range of $\eta$ restricted by the norm
of the competitor. The family of loss functions ranges from hinge loss
($\eta=0$) to squared hinge loss ($\eta=1$). This provides a solution to the
open problem of (J. Abernethy and A. Rakhlin. An efficient bandit algorithm for
$\sqrt{T}$-regret in online multiclass prediction? In COLT, 2009). We test our
algorithm experimentally, showing that it also performs favorably against
earlier algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Beygelzimer_A/0/1/0/all/0/1&quot;&gt;Alina Beygelzimer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Orabona_F/0/1/0/all/0/1&quot;&gt;Francesco Orabona&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1&quot;&gt;Chicheng Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1703.04455">
<title>Multivariate Gaussian and Student$-t$ Process Regression for Multi-output Prediction. (arXiv:1703.04455v5 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1703.04455</link>
<description rdf:parseType="Literal">&lt;p&gt;Gaussian process for vector-valued function model has been shown to be a
useful method for multi-output prediction. The existing method for this model
is to re-formulate the matrix-variate Gaussian distribution as a multivariate
normal distribution. Although it is effective in many cases, re-formulation is
not always workable and difficult to extend because not all matrix-variate
distributions can be transformed to related multivariate distributions, such as
the case for matrix-variate Student$-t$ distribution. In this paper, we propose
a new derivation of multivariate Gaussian process regression (MV-GPR), where
the model settings, derivations and computations are all directly performed in
matrix form, rather than vectorizing the matrices as done in the existing
methods. Furthermore, we introduce the multivariate Student$-t$ process and
then derive a new method, multivariate Student$-t$ process regression (MV-TPR)
for multi-output prediction. Both MV-GPR and MV-TPR have closed-form
expressions for the marginal likelihoods and predictive distributions. The
usefulness of the proposed methods is illustrated through several simulated
examples. In particular, we verify empirically that MV-TPR has superiority for
the datasets considered, including air quality prediction and bike rent
prediction. At last, the proposed methods are shown to produce profitable
investment strategies in the stock markets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chen_Z/0/1/0/all/0/1&quot;&gt;Zexun Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wang_B/0/1/0/all/0/1&quot;&gt;Bo Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gorban_A/0/1/0/all/0/1&quot;&gt;Alexander N. Gorban&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1708.01432">
<title>Nonparametric weighted stochastic block models. (arXiv:1708.01432v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1708.01432</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a Bayesian formulation of weighted stochastic block models that
can be used to infer the large-scale modular structure of weighted networks,
including their hierarchical organization. Our method is nonparametric, and
thus does not require the prior knowledge of the number of groups or other
dimensions of the model, which are instead inferred from data. We give a
comprehensive treatment of different kinds of edge weights (i.e. continuous or
discrete, signed or unsigned, bounded or unbounded), as well as arbitrary
weight transformations, and describe an unsupervised model selection approach
to choose the best network description. We illustrate the application of our
method to a variety of empirical weighted networks, such as global migrations,
voting patterns in congress, and neural connections in the human brain.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Peixoto_T/0/1/0/all/0/1&quot;&gt;Tiago P. Peixoto&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.02030">
<title>McDiarmid Drift Detection Methods for Evolving Data Streams. (arXiv:1710.02030v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1710.02030</link>
<description rdf:parseType="Literal">&lt;p&gt;Increasingly, Internet of Things (IoT) domains, such as sensor networks,
smart cities, and social networks, generate vast amounts of data. Such data are
not only unbounded and rapidly evolving. Rather, the content thereof
dynamically evolves over time, often in unforeseen ways. These variations are
due to so-called concept drifts, caused by changes in the underlying data
generation mechanisms. In a classification setting, concept drift causes the
previously learned models to become inaccurate, unsafe and even unusable.
Accordingly, concept drifts need to be detected, and handled, as soon as
possible. In medical applications and emergency response settings, for example,
change in behaviours should be detected in near real-time, to avoid potential
loss of life. To this end, we introduce the McDiarmid Drift Detection Method
(MDDM), which utilizes McDiarmid&apos;s inequality in order to detect concept drift.
The MDDM approach proceeds by sliding a window over prediction results, and
associate window entries with weights. Higher weights are assigned to the most
recent entries, in order to emphasize their importance. As instances are
processed, the detection algorithm compares a weighted mean of elements inside
the sliding window with the maximum weighted mean observed so far. A
significant difference between the two weighted means, upper-bounded by the
McDiarmid inequality, implies a concept drift. Our extensive experimentation
against synthetic and real-world data streams show that our novel method
outperforms the state-of-the-art. Specifically, MDDM yields shorter detection
delays as well as lower false negative rates, while maintaining high
classification accuracies.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pesaranghader_A/0/1/0/all/0/1&quot;&gt;Ali Pesaranghader&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Viktor_H/0/1/0/all/0/1&quot;&gt;Herna Viktor&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Paquet_E/0/1/0/all/0/1&quot;&gt;Eric Paquet&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.04126">
<title>Disease Prediction from Electronic Health Records Using Generative Adversarial Networks. (arXiv:1711.04126v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1711.04126</link>
<description rdf:parseType="Literal">&lt;p&gt;Electronic health records (EHRs) have contributed to the computerization of
patient records so that they can be used not only for efficient and systematic
medical services, but also for research on data science. In this paper, we
compared the disease prediction performance of generative adversarial networks
(GANs) and conventional learning algorithms in combination with missing value
prediction methods. As a result, the highest accuracy of 98.05% was obtained
using a stacked autoencoder as the missing value prediction method and an
auxiliary classifier GANs (AC-GANs) as the disease predicting method. Our
results show that the combination of the stacked autoencoder and the AC-GANs
significantly outperforms existing algorithms for the problem of disease
prediction in which missing values and class imbalance exist.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hwang_U/0/1/0/all/0/1&quot;&gt;Uiwon Hwang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Choi_S/0/1/0/all/0/1&quot;&gt;Sungwoon Choi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yoon_S/0/1/0/all/0/1&quot;&gt;Sungroh Yoon&lt;/a&gt;</dc:creator>
</item></rdf:RDF>