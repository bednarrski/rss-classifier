<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Boring papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Bad Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-01-10T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.03373"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.06541"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.03132"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.03138"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.03150"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.03160"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.03164"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.03168"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.03233"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.03239"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.03326"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.03331"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.03354"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.03355"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.03454"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1704.03296"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.02225"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.09381"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.03137"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.03222"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.03226"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.03437"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1705.09866"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1707.03269"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1708.07485"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.10571"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.09988"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.02612"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1801.03373">
<title>Data-driven forecasting of solar irradiance. (arXiv:1801.03373v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1801.03373</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper describes a flexible approach to short term prediction of
meteorological variables. In particular, we focus on the prediction of the
solar irradiance one hour ahead, a task that has high practical value when
optimizing solar energy resources. As D\&apos;efi EGC 2018 provides us with time
series data for multiple sensors (e.g. solar irradiance, temperature,
hygrometry), recorded every minute for two years and 5 geographical sites from
La R\&apos;eunion island, we test the value of using recently observed data as input
for prediction models, as well as the performance of models across sites. After
describing our data cleaning and normalization process, we combine a variable
selection step based on AutoRegressive Integrated Moving Average (ARIMA)
models, to using general purpose regression techniques such as neural networks
and regression trees.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bruneau_P/0/1/0/all/0/1&quot;&gt;Pierrick Bruneau&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pinheiro_P/0/1/0/all/0/1&quot;&gt;Philippe Pinheiro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Didry_Y/0/1/0/all/0/1&quot;&gt;Yoann Didry&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.06541">
<title>Size-Independent Sample Complexity of Neural Networks. (arXiv:1712.06541v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1712.06541</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the sample complexity of learning neural networks, by providing new
bounds on their Rademacher complexity assuming norm constraints on the
parameter matrix of each layer. Compared to previous work, these complexity
bounds have improved dependence on the network depth, and under some additional
assumptions, are fully independent of the network size (both depth and width).
These results are derived using some novel techniques, which may be of
independent interest.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Golowich_N/0/1/0/all/0/1&quot;&gt;Noah Golowich&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rakhlin_A/0/1/0/all/0/1&quot;&gt;Alexander Rakhlin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shamir_O/0/1/0/all/0/1&quot;&gt;Ohad Shamir&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.03132">
<title>Robust Propensity Score Computation Method based on Machine Learning with Label-corrupted Data. (arXiv:1801.03132v1 [stat.ME])</title>
<link>http://arxiv.org/abs/1801.03132</link>
<description rdf:parseType="Literal">&lt;p&gt;In biostatistics, propensity score is a common approach to analyze the
imbalance of covariate and process confounding covariates to eliminate
differences between groups. While there are an abundant amount of methods to
compute propensity score, a common issue of them is the corrupted labels in the
dataset. For example, the data collected from the patients could contain
samples that are treated mistakenly, and the computing methods could
incorporate them as a misleading information. In this paper, we propose a
Machine Learning-based method to handle the problem. Specifically, we utilize
the fact that the majority of sample should be labeled with the correct
instance and design an approach to first cluster the data with spectral
clustering and then sample a new dataset with a distribution processed from the
clustering results. The propensity score is computed by Xgboost, and a
mathematical justification of our method is provided in this paper. The
experimental results illustrate that xgboost propensity scores computing with
the data processed by our method could outperform the same method with original
data, and the advantages of our method increases as we add some artificial
corruptions to the dataset. Meanwhile, the implementation of xgboost to compute
propensity score for multiple treatments is also a pioneering work in the area.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wang_C/0/1/0/all/0/1&quot;&gt;Chen Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wang_S/0/1/0/all/0/1&quot;&gt;Suzhen Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Shi_F/0/1/0/all/0/1&quot;&gt;Fuyan Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zaixiang Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.03138">
<title>Deep In-GPU Experience Replay. (arXiv:1801.03138v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1801.03138</link>
<description rdf:parseType="Literal">&lt;p&gt;Experience replay allows a reinforcement learning agent to train on samples
from a large amount of the most recent experiences. A simple in-RAM experience
replay stores these most recent experiences in a list in RAM, and then copies
sampled batches to the GPU for training. I moved this list to the GPU, thus
creating an in-GPU experience replay, and a training step that no longer has
inputs copied from the CPU. I trained an agent to play Super Smash Bros. Melee,
using internal game memory values as inputs and outputting controller button
presses. A single state in Melee contains 27 floats, so the full experience
replay fits on a single GPU. For a batch size of 128, the in-GPU experience
replay trained twice as fast as the in-RAM experience replay. As far as I know,
this is the first in-GPU implementation of experience replay. Finally, I note a
few ideas for fitting the experience replay inside the GPU when the environment
state requires more memory.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Parr_B/0/1/0/all/0/1&quot;&gt;Ben Parr&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.03150">
<title>Moments in Time Dataset: one million videos for event understanding. (arXiv:1801.03150v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1801.03150</link>
<description rdf:parseType="Literal">&lt;p&gt;We present the Moments in Time Dataset, a large-scale human-annotated
collection of one million short videos corresponding to dynamic events
unfolding within three seconds. Modeling the spatial-audio-temporal dynamics
even for actions occurring in 3 second videos poses many challenges: meaningful
events do not include only people, but also objects, animals, and natural
phenomena; visual and auditory events can be symmetrical or not in time
(&quot;opening&quot; means &quot;closing&quot; in reverse order), and transient or sustained. We
describe the annotation process of our dataset (each video is tagged with one
action or activity label among 339 different classes), analyze its scale and
diversity in comparison to other large-scale video datasets for action
recognition, and report results of several baseline models addressing
separately and jointly three modalities: spatial, temporal and auditory. The
Moments in Time dataset designed to have a large coverage and diversity of
events in both visual and auditory modalities, can serve as a new challenge to
develop models that scale to the level of complexity and abstract reasoning
that a human processes on a daily basis.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Monfort_M/0/1/0/all/0/1&quot;&gt;Mathew Monfort&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_B/0/1/0/all/0/1&quot;&gt;Bolei Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bargal_S/0/1/0/all/0/1&quot;&gt;Sarah Adel Bargal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Andonian_A/0/1/0/all/0/1&quot;&gt;Alex Andonian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yan_T/0/1/0/all/0/1&quot;&gt;Tom Yan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ramakrishnan_K/0/1/0/all/0/1&quot;&gt;Kandan Ramakrishnan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brown_L/0/1/0/all/0/1&quot;&gt;Lisa Brown&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fan_Q/0/1/0/all/0/1&quot;&gt;Quanfu Fan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gutfruend_D/0/1/0/all/0/1&quot;&gt;Dan Gutfruend&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vondrick_C/0/1/0/all/0/1&quot;&gt;Carl Vondrick&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oliva_A/0/1/0/all/0/1&quot;&gt;Aude Oliva&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.03160">
<title>A Formalization of Kant&apos;s Second Formulation of the Categorical Imperative. (arXiv:1801.03160v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1801.03160</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a formalization and computational implementation of the second
formulation of Kant&apos;s categorical imperative. This ethical principle requires
an agent to never treat someone merely as a means but always also as an end.
Here we interpret this principle in terms of how persons are causally affected
by actions. We introduce Kantian causal agency models in which moral patients,
actions, goals, and causal influence are represented, and we show how to
formalize several readings of Kant&apos;s categorical imperative that correspond to
Kant&apos;s concept of strict and wide duties towards oneself and others. Stricter
versions handle cases where an action directly causally affects oneself or
others, whereas the wide version maximizes the number of persons being treated
as an end. We discuss limitations of our formalization by pointing to one of
Kant&apos;s cases that the machinery cannot handle in a satisfying way.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bentzen_M/0/1/0/all/0/1&quot;&gt;Martin Mose Bentzen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lindner_F/0/1/0/all/0/1&quot;&gt;Felix Lindner&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.03164">
<title>Paranom: A Parallel Anomaly Dataset Generator. (arXiv:1801.03164v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1801.03164</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we present Paranom, a parallel anomaly dataset generator. We
discuss its design and provide brief experimental results demonstrating its
usefulness in improving the classification correctness of LSTM-AD, a
state-of-the-art anomaly detection model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gottschlich_J/0/1/0/all/0/1&quot;&gt;Justin Gottschlich&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.03168">
<title>Greenhouse: A Zero-Positive Machine Learning System for Time-Series Anomaly Detection. (arXiv:1801.03168v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1801.03168</link>
<description rdf:parseType="Literal">&lt;p&gt;This short paper describes our ongoing research on Greenhouse - a
zero-positive machine learning system for time-series anomaly detection.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_T/0/1/0/all/0/1&quot;&gt;Tae Jun Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gottschlich_J/0/1/0/all/0/1&quot;&gt;Justin Gottschlich&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tatbul_N/0/1/0/all/0/1&quot;&gt;Nesime Tatbul&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Metcalf_E/0/1/0/all/0/1&quot;&gt;Eric Metcalf&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zdonik_S/0/1/0/all/0/1&quot;&gt;Stan Zdonik&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.03233">
<title>Eliciting Worker Preference for Task Completion. (arXiv:1801.03233v1 [cs.DB])</title>
<link>http://arxiv.org/abs/1801.03233</link>
<description rdf:parseType="Literal">&lt;p&gt;Current crowdsourcing platforms provide little support for worker feedback.
Workers are sometimes invited to post free text describing their experience and
preferences in completing tasks. They can also use forums such as Turker
Nation1 to exchange preferences on tasks and requesters. In fact, crowdsourcing
platforms rely heavily on observing workers and inferring their preferences
implicitly. In this work, we believe that asking workers to indicate their
preferences explicitly improve their experience in task completion and hence,
the quality of their contributions. Explicit elicitation can indeed help to
build more accurate worker models for task completion that captures the
evolving nature of worker preferences. We design a worker model whose accuracy
is improved iteratively by requesting preferences for task factors such as
required skills, task payment, and task relevance. We propose a generic
framework, develop efficient solutions in realistic scenarios, and run
extensive experiments that show the benefit of explicit preference elicitation
over implicit ones with statistical significance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Esfandiari_M/0/1/0/all/0/1&quot;&gt;Mohammadreza Esfandiari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roy_S/0/1/0/all/0/1&quot;&gt;Senjuti Basu Roy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Amer_Yahia_S/0/1/0/all/0/1&quot;&gt;Sihem Amer-Yahia&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.03239">
<title>Chameleon: A Hybrid Secure Computation Framework for Machine Learning Applications. (arXiv:1801.03239v1 [cs.CR])</title>
<link>http://arxiv.org/abs/1801.03239</link>
<description rdf:parseType="Literal">&lt;p&gt;We present Chameleon, a novel hybrid (mixed-protocol) framework for secure
function evaluation (SFE) which enables two parties to jointly compute a
function without disclosing their private inputs. Chameleon combines the best
aspects of generic SFE protocols with the ones that are based upon additive
secret sharing. In particular, the framework performs linear operations in the
ring $\mathbb{Z}_{2^l}$ using additively secret shared values and nonlinear
operations using Yao&apos;s Garbled Circuits or the Goldreich-Micali-Wigderson
protocol. Chameleon departs from the common assumption of additive or linear
secret sharing models where three or more parties need to communicate in the
online phase: the framework allows two parties with private inputs to
communicate in the online phase under the assumption of a third node generating
correlated randomness in an offline phase. Almost all of the heavy
cryptographic operations are precomputed in an offline phase which
substantially reduces the communication overhead. Chameleon is both scalable
and significantly more efficient than the ABY framework (NDSS&apos;15) it is based
on. Our framework supports signed fixed-point numbers. In particular,
Chameleon&apos;s vector dot product of signed fixed-point numbers improves the
efficiency of mining and classification of encrypted data for algorithms based
upon heavy matrix multiplications. Our evaluation of Chameleon on a 5 layer
convolutional deep neural network shows 133x and 4.2x faster executions than
Microsoft CryptoNets (ICML&apos;16) and MiniONN (CCS&apos;17), respectively.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Riazi_M/0/1/0/all/0/1&quot;&gt;M. Sadegh Riazi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Weinert_C/0/1/0/all/0/1&quot;&gt;Christian Weinert&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tkachenko_O/0/1/0/all/0/1&quot;&gt;Oleksandr Tkachenko&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Songhori_E/0/1/0/all/0/1&quot;&gt;Ebrahim M. Songhori&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schneider_T/0/1/0/all/0/1&quot;&gt;Thomas Schneider&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koushanfar_F/0/1/0/all/0/1&quot;&gt;Farinaz Koushanfar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.03326">
<title>Expected Policy Gradients for Reinforcement Learning. (arXiv:1801.03326v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1801.03326</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose expected policy gradients (EPG), which unify stochastic policy
gradients (SPG) and deterministic policy gradients (DPG) for reinforcement
learning. Inspired by expected sarsa, EPG integrates (or sums) across actions
when estimating the gradient, instead of relying only on the action in the
sampled trajectory. For continuous action spaces, we first derive a practical
result for Gaussian policies and quadric critics and then extend it to an
analytical method for the universal case, covering a broad class of actors and
critics, including Gaussian, exponential families, and reparameterised policies
with bounded support. For Gaussian policies, we show that it is optimal to
explore using covariance proportional to the matrix exponential of the scaled
Hessian of the critic with respect to the actions. EPG also provides a general
framework for reasoning about policy gradient methods, which we use to
establish a new general policy gradient theorem, of which the stochastic and
deterministic policy gradient theorems are special cases. Furthermore, we prove
that EPG reduces the variance of the gradient estimates without requiring
deterministic policies and with little computational overhead. Finally, we show
that EPG outperforms existing approaches on six challenging domains involving
the simulated control of physical systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ciosek_K/0/1/0/all/0/1&quot;&gt;Kamil Ciosek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Whiteson_S/0/1/0/all/0/1&quot;&gt;Shimon Whiteson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.03331">
<title>Reasoning about Unforeseen Possibilities During Policy Learning. (arXiv:1801.03331v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1801.03331</link>
<description rdf:parseType="Literal">&lt;p&gt;Methods for learning optimal policies in autonomous agents often assume that
the way the domain is conceptualised---its possible states and actions and
their causal structure---is known in advance and does not change during
learning. This is an unrealistic assumption in many scenarios, because new
evidence can reveal important information about what is possible, possibilities
that the agent was not aware existed prior to learning. We present a model of
an agent which both discovers and learns to exploit unforeseen possibilities
using two sources of evidence: direct interaction with the world and
communication with a domain expert. We use a combination of probabilistic and
symbolic reasoning to estimate all components of the decision problem,
including its set of random variables and their causal dependencies. Agent
simulations show that the agent converges on optimal polices even when it
starts out unaware of factors that are critical to behaving optimally.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Innes_C/0/1/0/all/0/1&quot;&gt;Craig Innes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lascarides_A/0/1/0/all/0/1&quot;&gt;Alex Lascarides&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Albrecht_S/0/1/0/all/0/1&quot;&gt;Stefano V Albrecht&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ramamoorthy_S/0/1/0/all/0/1&quot;&gt;Subramanian Ramamoorthy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rosman_B/0/1/0/all/0/1&quot;&gt;Benjamin Rosman&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.03354">
<title>Planning with Pixels in (Almost) Real Time. (arXiv:1801.03354v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1801.03354</link>
<description rdf:parseType="Literal">&lt;p&gt;Recently, width-based planning methods have been shown to yield
state-of-the-art results in the Atari 2600 video games. For this, the states
were associated with the (RAM) memory states of the simulator. In this work, we
consider the same planning problem but using the screen instead. By using the
same visual inputs, the planning results can be compared with those of humans
and learning methods. We show that the planning approach, out of the box and
without training, results in scores that compare well with those obtained by
humans and learning methods, and moreover, by developing an episodic, rollout
version of the IW(k) algorithm, we show that such scores can be obtained in
almost real time.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bandres_W/0/1/0/all/0/1&quot;&gt;Wilmer Bandres&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bonet_B/0/1/0/all/0/1&quot;&gt;Blai Bonet&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Geffner_H/0/1/0/all/0/1&quot;&gt;Hector Geffner&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.03355">
<title>Axiomatizations of inconsistency indices for triads. (arXiv:1801.03355v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1801.03355</link>
<description rdf:parseType="Literal">&lt;p&gt;Pairwise comparison matrices often exhibit inconsistency, therefore, a number
of indices has been introduced to measure their deviation from a consistent
matrix. Since inconsistency first emerges in the case of three alternatives,
several inconsistency indices are based on triads. Recently, a set of axioms
has been proposed, and is required to be satisfied by any reasonable
inconsistency index. We illustrate by an example that this set seems to be not
exhaustive, hence expand it by adding two new properties. We consider all
axioms on the set of triads, and choose the logically independent ones.
Finally, it is proved that they characterize the inconsistency ranking induced
by the Koczkodaj inconsistency index on this domain.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Csato_L/0/1/0/all/0/1&quot;&gt;L&amp;#xe1;szl&amp;#xf3; Csat&amp;#xf3;&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.03454">
<title>Net2Vec: Quantifying and Explaining how Concepts are Encoded by Filters in Deep Neural Networks. (arXiv:1801.03454v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1801.03454</link>
<description rdf:parseType="Literal">&lt;p&gt;In an effort to understand the meaning of the intermediate representations
captured by deep networks, recent papers have tried to associate specific
semantic concepts to individual neural network filter responses, where
interesting correlations are often found, largely by focusing on extremal
filter responses. In this paper, we show that this approach can favor
easy-to-interpret cases that are not necessarily representative of the average
behavior of a representation.
&lt;/p&gt;
&lt;p&gt;A more realistic but harder-to-study hypothesis is that semantic
representations are distributed, and thus filters must be studied in
conjunction. In order to investigate this idea while enabling systematic
visualization and quantification of multiple filter responses, we introduce the
Net2Vec framework, in which semantic concepts are mapped to vectorial
embeddings based on corresponding filter responses. By studying such
embeddings, we are able to show that 1., in most cases, multiple filters are
required to code for a concept, that 2., often filters are not concept specific
and help encode multiple concepts, and that 3., compared to single filter
activations, filter embeddings are able to better characterize the meaning of a
representation and its relationship to other concepts.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fong_R/0/1/0/all/0/1&quot;&gt;Ruth Fong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vedaldi_A/0/1/0/all/0/1&quot;&gt;Andrea Vedaldi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1704.03296">
<title>Interpretable Explanations of Black Boxes by Meaningful Perturbation. (arXiv:1704.03296v3 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1704.03296</link>
<description rdf:parseType="Literal">&lt;p&gt;As machine learning algorithms are increasingly applied to high impact yet
high risk tasks, such as medical diagnosis or autonomous driving, it is
critical that researchers can explain how such algorithms arrived at their
predictions. In recent years, a number of image saliency methods have been
developed to summarize where highly complex neural networks &quot;look&quot; in an image
for evidence for their predictions. However, these techniques are limited by
their heuristic nature and architectural constraints. In this paper, we make
two main contributions: First, we propose a general framework for learning
different kinds of explanations for any black box algorithm. Second, we
specialise the framework to find the part of an image most responsible for a
classifier decision. Unlike previous works, our method is model-agnostic and
testable because it is grounded in explicit and interpretable image
perturbations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fong_R/0/1/0/all/0/1&quot;&gt;Ruth Fong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vedaldi_A/0/1/0/all/0/1&quot;&gt;Andrea Vedaldi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.02225">
<title>Pose-Normalized Image Generation for Person Re-identification. (arXiv:1712.02225v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1712.02225</link>
<description rdf:parseType="Literal">&lt;p&gt;Person Re-identification (re-id) faces two major challenges: the lack of
cross-view paired training data and learning discriminative identity-sensitive
and view-invariant features in the presence of large pose variations. In this
work, we address both problems by proposing a novel deep person image
generation model for synthesizing realistic person images conditional on pose.
The model is based on a generative adversarial network (GAN) and used
specifically for pose normalization in re-id, thus termed pose-normalization
GAN (PN-GAN). With the synthesized images, we can learn a new type of deep
re-id feature free of the influence of pose variations. We show that this
feature is strong on its own and highly complementary to features learned with
the original images. Importantly, we now have a model that generalizes to any
new re-id dataset without the need for collecting any training data for model
fine-tuning, thus making a deep re-id model truly scalable. Extensive
experiments on five benchmarks show that our model outperforms the
state-of-the-art models, often significantly. In particular, the features
learned on Market-1501 can achieve a Rank-1 accuracy of 68.67% on VIPeR without
any model fine-tuning, beating almost all existing models fine-tuned on the
dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qian_X/0/1/0/all/0/1&quot;&gt;Xuelin Qian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1&quot;&gt;Yanwei Fu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1&quot;&gt;Wenxuan Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiang_T/0/1/0/all/0/1&quot;&gt;Tao Xiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1&quot;&gt;Yang Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1&quot;&gt;Yu-Gang Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xue_X/0/1/0/all/0/1&quot;&gt;Xiangyang Xue&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.09381">
<title>Ray RLlib: A Composable and Scalable Reinforcement Learning Library. (arXiv:1712.09381v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1712.09381</link>
<description rdf:parseType="Literal">&lt;p&gt;Reinforcement learning (RL) algorithms involve the deep nesting of distinct
components, where each component typically exhibits opportunities for
distributed computation. Current RL libraries offer parallelism at the level of
the entire program, coupling all the components together and making existing
implementations difficult to extend, combine, and reuse. We argue for building
composable RL components by encapsulating parallelism and resource requirements
within individual components, which can be achieved by building on top of a
flexible task-based programming model. We demonstrate this principle by
building Ray RLlib on top of Ray and show that we can implement a wide range of
state-of-the-art algorithms by composing and reusing a handful of standard
components. This composability does not come at the cost of performance --- in
our experiments, RLlib matches or exceeds the performance of highly optimized
reference implementations. Ray RLlib is available as part of Ray at
https://github.com/ray-project/ray/.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_E/0/1/0/all/0/1&quot;&gt;Eric Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liaw_R/0/1/0/all/0/1&quot;&gt;Richard Liaw&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nishihara_R/0/1/0/all/0/1&quot;&gt;Robert Nishihara&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moritz_P/0/1/0/all/0/1&quot;&gt;Philipp Moritz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fox_R/0/1/0/all/0/1&quot;&gt;Roy Fox&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gonzalez_J/0/1/0/all/0/1&quot;&gt;Joseph Gonzalez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goldberg_K/0/1/0/all/0/1&quot;&gt;Ken Goldberg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stoica_I/0/1/0/all/0/1&quot;&gt;Ion Stoica&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.03137">
<title>Convergence Analysis of Gradient Descent Algorithms with Proportional Updates. (arXiv:1801.03137v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1801.03137</link>
<description rdf:parseType="Literal">&lt;p&gt;The rise of deep learning in recent years has brought with it increasingly
clever optimization methods to deal with complex, non-linear loss functions.
These methods are often designed with convex optimization in mind, but have
been shown to work well in practice even for the highly non-convex optimization
associated with neural networks. However, one significant drawback of these
methods when they are applied to deep learning is that the magnitude of the
update step is sometimes disproportionate to the magnitude of the weights (much
smaller or larger), leading to training instabilities such as vanishing and
exploding gradients. An idea to combat this issue is gradient descent with
proportional updates. Gradient descent with proportional updates was introduced
in 2017. It was independently developed by You et al (Layer-wise Adaptive Rate
Scaling (LARS) algorithm) and by Abu-El-Haija (PercentDelta algorithm). The
basic idea of both of these algorithms is to make each step of the gradient
descent proportional to the current weight norm and independent of the gradient
magnitude. It is common in the context of new optimization methods to prove
convergence or derive regret bounds under the assumption of Lipschitz
continuity and convexity. However, even though LARS and PercentDelta were shown
to work well in practice, there is no theoretical analysis of the convergence
properties of these algorithms. Thus it is not clear if the idea of gradient
descent with proportional updates is used in the optimal way, or if it could be
improved by using a different norm or specific learning rate schedule, for
example. Moreover, it is not clear if these algorithms can be extended to other
problems, besides neural networks. We attempt to answer these questions by
establishing the theoretical analysis of gradient descent with proportional
updates, and verifying this analysis with empirical examples.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gitman_I/0/1/0/all/0/1&quot;&gt;Igor Gitman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dilipkumar_D/0/1/0/all/0/1&quot;&gt;Deepak Dilipkumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Parr_B/0/1/0/all/0/1&quot;&gt;Ben Parr&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.03222">
<title>Multivariate Bayesian Structural Time Series Model. (arXiv:1801.03222v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1801.03222</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper deals with inference and prediction for multiple correlated time
series, where one has also the choice of using a candidate pool of
contemporaneous predictors for each target series. Starting with a structural
model for the time-series, Bayesian tools are used for model fitting,
prediction, and feature selection, thus extending some recent work along these
lines for the univariate case. The Bayesian paradigm in this multivariate
setting helps the model avoid overfitting as well as capture correlations among
the multiple time series with the various state components. The model provides
needed flexibility to choose a different set of components and available
predictors for each target series. The cyclical component in the model can
handle large variations in the short term, which may be caused by external
shocks. We run extensive simulations to investigate properties such as
estimation accuracy and performance in forecasting. We then run an empirical
study with one-step-ahead prediction on the max log return of a portfolio of
stocks that involve four leading financial institutions. Both the simulation
studies and the extensive empirical study confirm that this multivariate model
outperforms three other benchmark models, viz. a model that treats each target
series as independent, the autoregressive integrated moving average model with
regression (ARIMAX), and the multivariate ARIMAX (MARIMAX) model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Jammalamadaka_S/0/1/0/all/0/1&quot;&gt;S. Rao Jammalamadaka&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Qiu_J/0/1/0/all/0/1&quot;&gt;Jinwen Qiu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ning_N/0/1/0/all/0/1&quot;&gt;Ning Ning&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.03226">
<title>Adaptive Graph Convolutional Neural Networks. (arXiv:1801.03226v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1801.03226</link>
<description rdf:parseType="Literal">&lt;p&gt;Graph Convolutional Neural Networks (Graph CNNs) are generalizations of
classical CNNs to handle graph data such as molecular data, point could and
social networks. Current filters in graph CNNs are built for fixed and shared
graph structure. However, for most real data, the graph structures varies in
both size and connectivity. The paper proposes a generalized and flexible graph
CNN taking data of arbitrary graph structure as input. In that way a
task-driven adaptive graph is learned for each graph data while training. To
efficiently learn the graph, a distance metric learning is proposed. Extensive
experiments on nine graph-structured datasets have demonstrated the superior
performance improvement on both convergence speed and predictive accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1&quot;&gt;Ruoyu Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1&quot;&gt;Sheng Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_F/0/1/0/all/0/1&quot;&gt;Feiyun Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1&quot;&gt;Junzhou Huang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.03437">
<title>Approximation beats concentration? An approximation view on inference with smooth radial kernels. (arXiv:1801.03437v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1801.03437</link>
<description rdf:parseType="Literal">&lt;p&gt;Positive definite kernels and their associated Reproducing Kernel Hilbert
Spaces provide a mathematically compelling and practically competitive
framework for learning from data.
&lt;/p&gt;
&lt;p&gt;In this paper we take the approximation theory point of view to explore
various aspects of smooth kernels related to their inferential properties. We
analyze eigenvalue decay of kernels operators and matrices, properties of
eigenfunctions/eigenvectors and &quot;Fourier&quot; coefficients of functions in the
kernel space restricted to a discrete set of data points. We also investigate
the fitting capacity of kernels, giving explicit bounds on the fat shattering
dimension of the balls in Reproducing Kernel Hilbert spaces. Interestingly, the
same properties that make kernels very effective approximators for functions in
their &quot;native&quot; kernel space, also limit their capacity to represent arbitrary
functions. We discuss various implications, including those for gradient
descent type methods.
&lt;/p&gt;
&lt;p&gt;It is important to note that most of our bounds are measure independent.
Moreover, at least in moderate dimension, the bounds for eigenvalues are much
tighter than the bounds which can be obtained from the usual matrix
concentration results. For example, we see that the eigenvalues of kernel
matrices show nearly exponential decay with constants depending only on the
kernel and the domain. We call this &quot;approximation beats concentration&quot;
phenomenon as even when the data are sampled from a probability distribution,
some of their aspects are better understood in terms of approximation theory.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Belkin_M/0/1/0/all/0/1&quot;&gt;Mikhail Belkin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1705.09866">
<title>Machine learning for graph-based representations of three-dimensional discrete fracture networks. (arXiv:1705.09866v2 [physics.geo-ph] UPDATED)</title>
<link>http://arxiv.org/abs/1705.09866</link>
<description rdf:parseType="Literal">&lt;p&gt;Structural and topological information play a key role in modeling flow and
transport through fractured rock in the subsurface. Discrete fracture network
(DFN) computational suites such as dfnWorks are designed to simulate flow and
transport in such porous media. Flow and transport calculations reveal that a
small backbone of fractures exists, where most flow and transport occurs.
Restricting the flowing fracture network to this backbone provides a
significant reduction in the network&apos;s effective size. However, the particle
tracking simulations needed to determine the reduction are computationally
intensive. Such methods may be impractical for large systems or for robust
uncertainty quantification of fracture networks, where thousands of forward
simulations are needed to bound system behavior.
&lt;/p&gt;
&lt;p&gt;In this paper, we develop an alternative network reduction approach to
characterizing transport in DFNs, by combining graph theoretical and machine
learning methods. We consider a graph representation where nodes signify
fractures and edges denote their intersections. Using random forest and support
vector machines, we rapidly identify a subnetwork that captures the flow
patterns of the full DFN, based primarily on node centrality features in the
graph. Our supervised learning techniques train on particle-tracking backbone
paths found by dfnWorks, but run in negligible time compared to those
simulations. We find that our predictions can reduce the network to
approximately 20% of its original size, while still generating breakthrough
curves consistent with those of the original network.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Valera_M/0/1/0/all/0/1&quot;&gt;Manuel Valera&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Guo_Z/0/1/0/all/0/1&quot;&gt;Zhengyang Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Kelly_P/0/1/0/all/0/1&quot;&gt;Priscilla Kelly&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Matz_S/0/1/0/all/0/1&quot;&gt;Sean Matz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Cantu_A/0/1/0/all/0/1&quot;&gt;Adrian Cantu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Percus_A/0/1/0/all/0/1&quot;&gt;Allon G. Percus&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Hyman_J/0/1/0/all/0/1&quot;&gt;Jeffrey D. Hyman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Srinivasan_G/0/1/0/all/0/1&quot;&gt;Gowri Srinivasan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Viswanathan_H/0/1/0/all/0/1&quot;&gt;Hari S. Viswanathan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1707.03269">
<title>Improving Downlink Coordinated Multipoint Performance in Heterogeneous Networks. (arXiv:1707.03269v3 [cs.NI] UPDATED)</title>
<link>http://arxiv.org/abs/1707.03269</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a novel method for practical Joint Processing downlink coordinated
multipoint (DL CoMP) implementation in LTE/LTE-A systems using supervised
machine learning. DL CoMP has not been thoroughly studied in previous work
although cluster formation and interference mitigation have been studied
extensively. In this paper, we attempt to improve the cell edge data rate
served by a heterogeneous network cluster by means of dynamically changing the
DL SINR threshold at which the DL CoMP feature is triggered. We do so by using
a support vector machine (SVM) classifier. The simulation results show a cell
edge user throughput improvement of 33.3\% for pico cells and more than
four-fold improvement in user throughput in the cluster. This has resulted from
a reduction in the downlink block error rate (DL BLER) and an improvement in
the spectral efficiency due to the informed triggering of the multiple radio
streams as part of DL CoMP.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mismar_F/0/1/0/all/0/1&quot;&gt;Faris B. Mismar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Evans_B/0/1/0/all/0/1&quot;&gt;Brian L. Evans&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1708.07485">
<title>Multivariate Dependency Measure based on Copula and Gaussian Kernel. (arXiv:1708.07485v2 [math.ST] UPDATED)</title>
<link>http://arxiv.org/abs/1708.07485</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a new multivariate dependency measure. It is obtained by
considering a Gaussian kernel based distance between the copula transform of
the given d-dimensional distribution and the uniform copula and then
appropriately normalizing it. The resulting measure is shown to satisfy a
number of desirable properties. A nonparametric estimate is proposed for this
dependency measure and its properties (finite sample as well as asymptotic) are
derived. Some comparative studies of the proposed dependency measure estimate
with some widely used dependency measure estimates on artificial datasets are
included. A non-parametric test of independence between two or more random
variables based on this measure is proposed. A comparison of the proposed test
with some existing nonparametric multivariate test for independence is
presented.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Roy_A/0/1/0/all/0/1&quot;&gt;Angshuman Roy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Goswami_A/0/1/0/all/0/1&quot;&gt;Alok Goswami&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Murthy_C/0/1/0/all/0/1&quot;&gt;C. A. Murthy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.10571">
<title>Certifiable Distributional Robustness with Principled Adversarial Training. (arXiv:1710.10571v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1710.10571</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural networks are vulnerable to adversarial examples and researchers have
proposed many heuristic attack and defense mechanisms. We take the principled
view of distributionally robust optimization, which guarantees performance
under adversarial input perturbations. By considering a Lagrangian penalty
formulation of perturbation of the underlying data distribution in a
Wasserstein ball, we provide a training procedure that augments model parameter
updates with worst-case perturbations of training data. For smooth losses, our
procedure provably achieves moderate levels of robustness with little
computational or statistical cost relative to empirical risk minimization.
Furthermore, our statistical guarantees allow us to efficiently certify
robustness for the population loss. For imperceptible perturbations, our method
matches or outperforms heuristic approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sinha_A/0/1/0/all/0/1&quot;&gt;Aman Sinha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Namkoong_H/0/1/0/all/0/1&quot;&gt;Hongseok Namkoong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Duchi_J/0/1/0/all/0/1&quot;&gt;John Duchi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.09988">
<title>Orthogonal Machine Learning for Demand Estimation: High Dimensional Causal Inference in Dynamic Panels. (arXiv:1712.09988v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1712.09988</link>
<description rdf:parseType="Literal">&lt;p&gt;There has been growing interest in how economists can import machine learning
tools designed for prediction to accelerate and automate the model selection
process, while still retaining desirable inference properties for causal
parameters. Focusing on partially linear models, we extend the Double ML
framework to allow for (1) a number of treatments that may grow with the sample
size and (2) the analysis of panel data under sequentially exogenous errors.
Our low-dimensional treatment (LD) regime directly extends the work in
[Chernozhukov et al., 2016], by showing that the coefficients from a second
stage, ordinary least squares estimator attain root-n convergence and desired
coverage even if the dimensionality of treatment is allowed to grow. In a
high-dimensional sparse (HDS) regime, we show that second stage LASSO and
debiased LASSO have asymptotic properties equivalent to oracle estimators with
no upstream error. We argue that these advances make Double ML methods a
desirable alternative for practitioners estimating short-term demand
elasticities in non-contractual settings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chernozhukov_V/0/1/0/all/0/1&quot;&gt;Victor Chernozhukov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Goldman_M/0/1/0/all/0/1&quot;&gt;Matt Goldman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Semenova_V/0/1/0/all/0/1&quot;&gt;Vira Semenova&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Taddy_M/0/1/0/all/0/1&quot;&gt;Matt Taddy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.02612">
<title>Spatially Transformed Adversarial Examples. (arXiv:1801.02612v2 [cs.CR] UPDATED)</title>
<link>http://arxiv.org/abs/1801.02612</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent studies show that widely used deep neural networks (DNNs) are
vulnerable to carefully crafted adversarial examples. Many advanced algorithms
have been proposed to generate adversarial examples by leveraging the
$\mathcal{L}_p$ distance for penalizing perturbations. Researchers have
explored different defense methods to defend against such adversarial attacks.
While the effectiveness of $\mathcal{L}_p$ distance as a metric of perceptual
quality remains an active research area, in this paper we will instead focus on
a different type of perturbation, namely spatial transformation, as opposed to
manipulating the pixel values directly as in prior works. Perturbations
generated through spatial transformation could result in large $\mathcal{L}_p$
distance measures, but our extensive experiments show that such spatially
transformed adversarial examples are perceptually realistic and more difficult
to defend against with existing defense systems. This potentially provides a
new direction in adversarial example generation and the design of corresponding
defenses. We visualize the spatial transformation based perturbation for
different examples and show that our technique can produce realistic
adversarial examples with smooth image deformation. Finally, we visualize the
attention of deep networks with different types of adversarial examples to
better understand how these examples are interpreted.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiao_C/0/1/0/all/0/1&quot;&gt;Chaowei Xiao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1&quot;&gt;Jun-Yan Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1&quot;&gt;Bo Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_W/0/1/0/all/0/1&quot;&gt;Warren He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1&quot;&gt;Mingyan Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_D/0/1/0/all/0/1&quot;&gt;Dawn Song&lt;/a&gt;</dc:creator>
</item></rdf:RDF>