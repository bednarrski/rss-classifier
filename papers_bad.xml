<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Boring papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Bad Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-06-27T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.10230"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.10551"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.02301"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.02844"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.08804"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.10244"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.10270"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.10282"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.10293"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.10561"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1603.03491"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1705.10219"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.09644"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.02969"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08263"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.10174"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.10175"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.10188"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.10206"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.10222"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.10234"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.10283"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.10410"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.10474"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.10547"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.10586"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1704.03976"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.02840"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08626"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.03154"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.09046"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.02587"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.05751"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08593"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02199"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1806.10230">
<title>Guided evolutionary strategies: escaping the curse of dimensionality in random search. (arXiv:1806.10230v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1806.10230</link>
<description rdf:parseType="Literal">&lt;p&gt;Many applications in machine learning require optimizing a function whose
true gradient is unknown, but where surrogate gradient information (directions
that may be correlated with, but not necessarily identical to, the true
gradient) is available instead. This arises when an approximate gradient is
easier to compute than the full gradient (e.g. in meta-learning or unrolled
optimization), or when a true gradient is intractable and is replaced with a
surrogate (e.g. in certain reinforcement learning applications, or when using
synthetic gradients). We propose Guided Evolutionary Strategies, a method for
optimally using surrogate gradient directions along with random search. We
define a search distribution for evolutionary strategies that is elongated
along a guiding subspace spanned by the surrogate gradients. This allows us to
estimate a descent direction which can then be passed to a first-order
optimizer. We analytically and numerically characterize the tradeoffs that
result from tuning how strongly the search distribution is stretched along the
guiding subspace, and we use this to derive a setting of the hyperparameters
that works well across problems. Finally, we apply our method to example
problems including truncated unrolled optimization and a synthetic gradient
problem, demonstrating improvement over both standard evolutionary strategies
and first-order methods that directly follow the surrogate gradient. We provide
a demo of Guided ES at:
https://github.com/brain-research/guided-evolutionary-strategies.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Maheswaranathan_N/0/1/0/all/0/1&quot;&gt;Niru Maheswaranathan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Metz_L/0/1/0/all/0/1&quot;&gt;Luke Metz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tucker_G/0/1/0/all/0/1&quot;&gt;George Tucker&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sohl_Dickstein_J/0/1/0/all/0/1&quot;&gt;Jascha Sohl-Dickstein&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.10551">
<title>A Tunable Particle Swarm Size Optimization Algorithm for Feature Selection. (arXiv:1806.10551v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1806.10551</link>
<description rdf:parseType="Literal">&lt;p&gt;Feature selection is the process of identifying statistically most relevant
features to improve the predictive capabilities of the classifiers. To find the
best features subsets, the population based approaches like Particle Swarm
Optimization(PSO) and genetic algorithms are being widely employed. However, it
is a general observation that not having right set of particles in the swarm
may result in sub-optimal solutions, affecting the accuracies of classifiers.
To address this issue, we propose a novel tunable swarm size approach to
reconfigure the particles in a standard PSO, based on the data sets, in real
time. The proposed algorithm is named as Tunable Particle Swarm Size
Optimization Algorithm (TPSO). It is a wrapper based approach wherein an
Alternating Decision Tree (ADT) classifier is used for identifying influential
feature subset, which is further evaluated by a new objective function which
integrates the Classification Accuracy (CA) with a modified F-Score, to ensure
better classification accuracy over varying population sizes. Experimental
studies on bench mark data sets and Wilcoxon statistical test have proved the
fact that the proposed algorithm (TPSO) is efficient in identifying optimal
feature subsets that improve classification accuracies of base classifiers in
comparison to its standalone form.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mallenahalli_N/0/1/0/all/0/1&quot;&gt;Naresh Mallenahalli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sarma_T/0/1/0/all/0/1&quot;&gt;T. Hitendra Sarma&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.02301">
<title>Can Deep Reinforcement Learning Solve Erdos-Selfridge-Spencer Games?. (arXiv:1711.02301v4 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1711.02301</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep reinforcement learning has achieved many recent successes, but our
understanding of its strengths and limitations is hampered by the lack of rich
environments in which we can fully characterize optimal behavior, and
correspondingly diagnose individual actions against such a characterization.
Here we consider a family of combinatorial games, arising from work of Erdos,
Selfridge, and Spencer, and we propose their use as environments for evaluating
and comparing different approaches to reinforcement learning. These games have
a number of appealing features: they are challenging for current learning
approaches, but they form (i) a low-dimensional, simply parametrized
environment where (ii) there is a linear closed form solution for optimal
behavior from any state, and (iii) the difficulty of the game can be tuned by
changing environment parameters in an interpretable way. We use these
Erdos-Selfridge-Spencer games not only to compare different algorithms, but
test for generalization, make comparisons to supervised learning, analyse
multiagent play, and even develop a self play algorithm.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Raghu_M/0/1/0/all/0/1&quot;&gt;Maithra Raghu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Irpan_A/0/1/0/all/0/1&quot;&gt;Alex Irpan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Andreas_J/0/1/0/all/0/1&quot;&gt;Jacob Andreas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kleinberg_R/0/1/0/all/0/1&quot;&gt;Robert Kleinberg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Le_Q/0/1/0/all/0/1&quot;&gt;Quoc V. Le&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kleinberg_J/0/1/0/all/0/1&quot;&gt;Jon Kleinberg&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.02844">
<title>Using a reservoir computer to learn chaotic attractors, with applications to chaos synchronisation and cryptography. (arXiv:1802.02844v2 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1802.02844</link>
<description rdf:parseType="Literal">&lt;p&gt;Using the machine learning approach known as reservoir computing, it is
possible to train one dynamical system to emulate another. We show that such
trained reservoir computers reproduce the properties of the attractor of the
chaotic system sufficiently well to exhibit chaos synchronisation. That is, the
trained reservoir computer, weakly driven by the chaotic system, will
synchronise with the chaotic system. Conversely, the chaotic system, weakly
driven by a trained reservoir computer, will synchronise with the reservoir
computer. We illustrate this behaviour on the Mackey-Glass and Lorenz systems.
We then show that trained reservoir computers can be used to crack chaos based
cryptography and illustrate this on a chaos cryptosystem based on the
Mackey-Glass system. We conclude by discussing why reservoir computers are so
good at emulating chaotic systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Antonik_P/0/1/0/all/0/1&quot;&gt;Piotr Antonik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gulina_M/0/1/0/all/0/1&quot;&gt;Marvyn Gulina&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pauwels_J/0/1/0/all/0/1&quot;&gt;Ja&amp;#xeb;l Pauwels&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Massar_S/0/1/0/all/0/1&quot;&gt;Serge Massar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.08804">
<title>Hierarchical Graph Representation Learning with Differentiable Pooling. (arXiv:1806.08804v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1806.08804</link>
<description rdf:parseType="Literal">&lt;p&gt;Recently, graph neural networks (GNNs) have revolutionized the field of graph
representation learning through effectively learned node embeddings, and
achieved state-of-the-art results in tasks such as node classification and link
prediction. However, current GNN methods are inherently flat and do not learn
hierarchical representations of graphs---a limitation that is especially
problematic for the task of graph classification, where the goal is to predict
the label associated with an entire graph. Here we propose DiffPool, a
differentiable graph pooling module that can generate hierarchical
representations of graphs and can be combined with various graph neural network
architectures in an end-to-end fashion. DiffPool learns a differentiable soft
cluster assignment for nodes at each layer of a deep GNN, mapping nodes to a
set of clusters, which then form the coarsened input for the next GNN layer.
Our experimental results show that combining existing GNN methods with DiffPool
yields an average improvement of 5-10% accuracy on graph classification
benchmarks, compared to all existing pooling approaches, achieving a new
state-of-the-art on four out of five benchmark data sets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ying_R/0/1/0/all/0/1&quot;&gt;Rex Ying&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+You_J/0/1/0/all/0/1&quot;&gt;Jiaxuan You&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Morris_C/0/1/0/all/0/1&quot;&gt;Christopher Morris&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ren_X/0/1/0/all/0/1&quot;&gt;Xiang Ren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hamilton_W/0/1/0/all/0/1&quot;&gt;William L. Hamilton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leskovec_J/0/1/0/all/0/1&quot;&gt;Jure Leskovec&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.10244">
<title>Phase transition in the knapsack problem. (arXiv:1806.10244v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1806.10244</link>
<description rdf:parseType="Literal">&lt;p&gt;We examine the phase transition phenomenon for the Knapsack problem from both
a computational and a human perspective. We first provide, via an empirical and
a theoretical analysis, a characterization of the phenomenon in terms of two
instance properties; normalised capacity and normalised profit. Then, we show
evidence that average time spent by human decision makers in solving an
instance peaks near the phase transition. Given the ubiquity of the Knapsack
problem in every-day life, a better understanding of its structure can improve
our understanding not only of computational techniques but also of human
behavior, including the use and development of heuristics and occurrence of
biases.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yadav_N/0/1/0/all/0/1&quot;&gt;Nitin Yadav&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Murawski_C/0/1/0/all/0/1&quot;&gt;Carsten Murawski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sardina_S/0/1/0/all/0/1&quot;&gt;Sebastian Sardina&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bossaerts_P/0/1/0/all/0/1&quot;&gt;Peter Bossaerts&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.10270">
<title>Piecewise Approximations of Black Box Models for Model Interpretation. (arXiv:1806.10270v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.10270</link>
<description rdf:parseType="Literal">&lt;p&gt;Machine Learning models have proved extremely successful for a wide variety
of supervised learning problems, but the predictions of many of these models
are difficult to interpret. A recent literature interprets the predictions of
more general &quot;black-box&quot; machine learning models by approximating these models
in terms of simpler models such as piecewise linear or piecewise constant
models. Existing literature constructs these approximations in an ad-hoc
manner. We provide a tractable dynamic programming algorithm that partitions
the feature space into clusters in a principled way and then uses this
partition to provide both piecewise constant and piecewise linear
interpretations of an arbitrary &quot;black-box&quot; model. When loss is measured in
terms of mean squared error, our approximation is optimal (under certain
conditions); for more general loss functions, our interpretation is probably
approximately optimal (in the sense of PAC learning). Experiments with real and
synthetic data show that it continues to provide significant improvements (in
terms of mean squared error) over competing approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ahuja_K/0/1/0/all/0/1&quot;&gt;Kartik Ahuja&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zame_W/0/1/0/all/0/1&quot;&gt;William R. Zame&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schaar_M/0/1/0/all/0/1&quot;&gt;Mihaela van der Schaar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.10282">
<title>Efficient Neural Architecture Search with Network Morphism. (arXiv:1806.10282v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.10282</link>
<description rdf:parseType="Literal">&lt;p&gt;While neural architecture search (NAS) has drawn increasing attention for
automatically tuning deep neural networks, existing search algorithms usually
suffer from expensive computational cost. Network morphism, which keeps the
functionality of a neural network while changing its neural architecture, could
be helpful for NAS by enabling a more efficient training during the search.
However, network morphism based NAS is still computationally expensive due to
the inefficient process of selecting the proper morph operation for existing
architectures. As we know, Bayesian optimization has been widely used to
optimize functions based on a limited number of observations, motivating us to
explore the possibility of making use of Bayesian optimization to accelerate
the morph operation selection process. In this paper, we propose a novel
framework enabling Bayesian optimization to guide the network morphism for
efficient neural architecture search by introducing a neural network kernel and
a tree-structured acquisition function optimization algorithm. With Bayesian
optimization to select the network morphism operations, the exploration of the
search space is more efficient. Moreover, we carefully wrapped our method into
an open-source software, namely Auto-Keras for people without rich machine
learning background to use. Intensive experiments on real-world datasets have
been done to demonstrate the superior performance of the developed framework
over the state-of-the-art baseline methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jin_H/0/1/0/all/0/1&quot;&gt;Haifeng Jin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_Q/0/1/0/all/0/1&quot;&gt;Qingquan Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1&quot;&gt;Xia Hu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.10293">
<title>QT-Opt: Scalable Deep Reinforcement Learning for Vision-Based Robotic Manipulation. (arXiv:1806.10293v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.10293</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we study the problem of learning vision-based dynamic
manipulation skills using a scalable reinforcement learning approach. We study
this problem in the context of grasping, a longstanding challenge in robotic
manipulation. In contrast to static learning behaviors that choose a grasp
point and then execute the desired grasp, our method enables closed-loop
vision-based control, whereby the robot continuously updates its grasp strategy
based on the most recent observations to optimize long-horizon grasp success.
To that end, we introduce QT-Opt, a scalable self-supervised vision-based
reinforcement learning framework that can leverage over 580k real-world grasp
attempts to train a deep neural network Q-function with over 1.2M parameters to
perform closed-loop, real-world grasping that generalizes to 96% grasp success
on unseen objects. Aside from attaining a very high success rate, our method
exhibits behaviors that are quite distinct from more standard grasping systems:
using only RGB vision-based perception from an over-the-shoulder camera, our
method automatically learns regrasping strategies, probes objects to find the
most effective grasps, learns to reposition objects and perform other
non-prehensile pre-grasp manipulations, and responds dynamically to
disturbances and perturbations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kalashnikov_D/0/1/0/all/0/1&quot;&gt;Dmitry Kalashnikov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Irpan_A/0/1/0/all/0/1&quot;&gt;Alex Irpan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pastor_P/0/1/0/all/0/1&quot;&gt;Peter Pastor&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ibarz_J/0/1/0/all/0/1&quot;&gt;Julian Ibarz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Herzog_A/0/1/0/all/0/1&quot;&gt;Alexander Herzog&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jang_E/0/1/0/all/0/1&quot;&gt;Eric Jang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Quillen_D/0/1/0/all/0/1&quot;&gt;Deirdre Quillen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Holly_E/0/1/0/all/0/1&quot;&gt;Ethan Holly&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kalakrishnan_M/0/1/0/all/0/1&quot;&gt;Mrinal Kalakrishnan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vanhoucke_V/0/1/0/all/0/1&quot;&gt;Vincent Vanhoucke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1&quot;&gt;Sergey Levine&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.10561">
<title>Knowledge Compilation in Multi-Agent Epistemic Logics. (arXiv:1806.10561v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1806.10561</link>
<description rdf:parseType="Literal">&lt;p&gt;Epistemic logics are a primary formalism for multi-agent systems but major
reasoning tasks in such epistemic logics are intractable, which impedes
applications of multi-agent epistemic logics in automatic planning. Knowledge
compilation provides a promising way of resolving the intractability by
identifying expressive fragments of epistemic logics that are tractable for
important reasoning tasks such as satisfiability and forgetting. The property
of logical separability allows to decompose a formula into some of its
subformulas and thus modular algorithms for various reasoning tasks can be
developed. In this paper, by employing logical separability, we propose an
approach to knowledge compilation for the logic Kn by defining a normal form
SDNF. Among several novel results, we show that every epistemic formula can be
equivalently compiled into a formula in SDNF, major reasoning tasks in SDNF are
tractable, and formulas in SDNF enjoy the logical separability. Our results
shed some lights on modular approaches to knowledge compilation. Furthermore,
we apply our results in the multi-agent epistemic planning. Finally, we extend
the above result to the logic K45n that is Kn extended by introspection axioms
4 and 5.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fang_L/0/1/0/all/0/1&quot;&gt;Liangda Fang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1&quot;&gt;Kewen Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zhe Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wen_X/0/1/0/all/0/1&quot;&gt;Ximing Wen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1603.03491">
<title>Bayesian Opponent Exploitation in Imperfect-Information Games. (arXiv:1603.03491v5 [cs.GT] UPDATED)</title>
<link>http://arxiv.org/abs/1603.03491</link>
<description rdf:parseType="Literal">&lt;p&gt;Two fundamental problems in computational game theory are computing a Nash
equilibrium and learning to exploit opponents given observations of their play
(opponent exploitation). The latter is perhaps even more important than the
former: Nash equilibrium does not have a compelling theoretical justification
in game classes other than two-player zero-sum, and for all games one can
potentially do better by exploiting perceived weaknesses of the opponent than
by following a static equilibrium strategy throughout the match. The natural
setting for opponent exploitation is the Bayesian setting where we have a prior
model that is integrated with observations to create a posterior opponent model
that we respond to. The most natural, and a well-studied prior distribution is
the Dirichlet distribution. An exact polynomial-time algorithm is known for
best-responding to the posterior distribution for an opponent assuming a
Dirichlet prior with multinomial sampling in normal-form games; however, for
imperfect-information games the best known algorithm is based on approximating
an infinite integral without theoretical guarantees. We present the first exact
algorithm for a natural class of imperfect-information games. We demonstrate
that our algorithm runs quickly in practice and outperforms the best prior
approaches. We also present an algorithm for the uniform prior setting.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ganzfried_S/0/1/0/all/0/1&quot;&gt;Sam Ganzfried&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_Q/0/1/0/all/0/1&quot;&gt;Qingyun Sun&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1705.10219">
<title>Automatic White-Box Testing of First-Order Logic Ontologies. (arXiv:1705.10219v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1705.10219</link>
<description rdf:parseType="Literal">&lt;p&gt;Formal ontologies are axiomatizations in a logic-based formalism. The
development of formal ontologies, and their important role in the Semantic Web
area, is generating considerable research on the use of automated reasoning
techniques and tools that help in ontology engineering. One of the main aims is
to refine and to improve axiomatizations for enabling automated reasoning tools
to efficiently infer reliable information. Defects in the axiomatization can
not only cause wrong inferences, but can also hinder the inference of expected
information, either by increasing the computational cost of, or even
preventing, the inference. In this paper, we introduce a novel, fully automatic
white-box testing framework for first-order logic ontologies. Our methodology
is based on the detection of inference-based redundancies in the given
axiomatization. The application of the proposed testing method is fully
automatic since a) the automated generation of tests is guided only by the
syntax of axioms and b) the evaluation of tests is performed by automated
theorem provers. Our proposal enables the detection of defects and serves to
certify the grade of suitability --for reasoning purposes-- of every axiom. We
formally define the set of tests that are generated from any axiom and prove
that every test is logically related to redundancies in the axiom from which
the test has been generated. We have implemented our method and used this
implementation to automatically detect several non-trivial defects that were
hidden in various first-order logic ontologies. Throughout the paper we provide
illustrative examples of these defects, explain how they were found, and how
each proof --given by an automated theorem-prover-- provides useful hints on
the nature of each defect. Additionally, by correcting all the detected
defects, we have obtained an improved version of one of the tested ontologies:
Adimen-SUMO.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alvez_J/0/1/0/all/0/1&quot;&gt;Javier &amp;#xc1;lvez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hermo_M/0/1/0/all/0/1&quot;&gt;Montserrat Hermo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lucio_P/0/1/0/all/0/1&quot;&gt;Paqui Lucio&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rigau_G/0/1/0/all/0/1&quot;&gt;German Rigau&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.09644">
<title>PyPhi: A toolbox for integrated information theory. (arXiv:1712.09644v3 [q-bio.NC] UPDATED)</title>
<link>http://arxiv.org/abs/1712.09644</link>
<description rdf:parseType="Literal">&lt;p&gt;Integrated information theory provides a mathematical framework to fully
characterize the cause-effect structure of a physical system. Here, we
introduce PyPhi, a Python software package that implements this framework for
causal analysis and unfolds the full cause-effect structure of discrete
dynamical systems of binary elements. The software allows users to easily study
these structures, serves as an up-to-date reference implementation of the
formalisms of integrated information theory, and has been applied in research
on complexity, emergence, and certain biological questions. We first provide an
overview of the main algorithm and demonstrate PyPhi&apos;s functionality in the
course of analyzing an example system, and then describe details of the
algorithm&apos;s design and implementation.
&lt;/p&gt;
&lt;p&gt;PyPhi can be installed with Python&apos;s package manager via the command &apos;pip
install pyphi&apos; on Linux and macOS systems equipped with Python 3.4 or higher.
PyPhi is open-source and licensed under the GPLv3; the source code is hosted on
GitHub at https://github.com/wmayner/pyphi . Comprehensive and
continually-updated documentation is available at https://pyphi.readthedocs.io/
. The pyphi-users mailing list can be joined at
https://groups.google.com/forum/#!forum/pyphi-users . A web-based graphical
interface to the software is available at
&lt;a href=&quot;http://integratedinformationtheory.org/calculate.html&quot;&gt;this http URL&lt;/a&gt; .
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Mayner_W/0/1/0/all/0/1&quot;&gt;William G. P. Mayner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Marshall_W/0/1/0/all/0/1&quot;&gt;William Marshall&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Albantakis_L/0/1/0/all/0/1&quot;&gt;Larissa Albantakis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Findlay_G/0/1/0/all/0/1&quot;&gt;Graham Findlay&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Marchman_R/0/1/0/all/0/1&quot;&gt;Robert Marchman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Tononi_G/0/1/0/all/0/1&quot;&gt;Giulio Tononi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.02969">
<title>A review of possible effects of cognitive biases on interpretation of rule-based machine learning models. (arXiv:1804.02969v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1804.02969</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper investigates to what extent cognitive biases may affect human
understanding of interpretable machine learning models, in particular of rules
discovered from data. Twenty cognitive biases are covered, as are possible
debiasing techniques that can be adopted by designers of machine learning
algorithms and software. Our review transfers results obtained in cognitive
psychology to the domain of machine learning, aiming to bridge the current gap
between these two areas. It needs to be followed by empirical studies
specifically aimed at the machine learning domain.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kliegr_T/0/1/0/all/0/1&quot;&gt;Tom&amp;#xe1;&amp;#x161; Kliegr&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bahnik_S/0/1/0/all/0/1&quot;&gt;&amp;#x160;t&amp;#x11b;p&amp;#xe1;n Bahn&amp;#xed;k&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Furnkranz_J/0/1/0/all/0/1&quot;&gt;Johannes F&amp;#xfc;rnkranz&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08263">
<title>Planning to Give Information in Partially Observed Domains with a Learned Weighted Entropy Model. (arXiv:1805.08263v3 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1805.08263</link>
<description rdf:parseType="Literal">&lt;p&gt;In many robotic applications, an autonomous agent must act within and explore
a partially observed environment that is unobserved by its human teammate. We
consider such a setting in which the agent can, while acting, transmit
declarative information to the human that helps them understand aspects of this
unseen environment. Naturally, the human will have preferences about what
information they are given. This work adopts an information-theoretic view of
the human&apos;s preferences: the human scores information based on the induced
change in weighted entropy of their belief about the environment state. We
formulate this setting as a belief MDP and give an algorithm for solving it
approximately. Then, we give an algorithm that allows the agent to learn the
human&apos;s preferences online. We validate our approach experimentally in
simulated discrete and continuous partially observed search-and-recover
domains.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chitnis_R/0/1/0/all/0/1&quot;&gt;Rohan Chitnis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kaelbling_L/0/1/0/all/0/1&quot;&gt;Leslie Pack Kaelbling&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lozano_Perez_T/0/1/0/all/0/1&quot;&gt;Tom&amp;#xe1;s Lozano-P&amp;#xe9;rez&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.10174">
<title>Semantically Enhanced Dynamic Bayesian Network for Detecting Sepsis Mortality Risk in ICU Patients with Infection. (arXiv:1806.10174v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.10174</link>
<description rdf:parseType="Literal">&lt;p&gt;Although timely sepsis diagnosis and prompt interventions in Intensive Care
Unit (ICU) patients are associated with reduced mortality, early clinical
recognition is frequently impeded by non-specific signs of infection and
failure to detect signs of sepsis-induced organ dysfunction in a constellation
of dynamically changing physiological data. The goal of this work is to
identify patient at risk of life-threatening sepsis utilizing a data-centered
and machine learning-driven approach. We derive a mortality risk predictive
dynamic Bayesian network (DBN) guided by a customized sepsis knowledgebase and
compare the predictive accuracy of the derived DBN with the Sepsis-related
Organ Failure Assessment (SOFA) score, the Quick SOFA (qSOFA) score, the
Simplified Acute Physiological Score (SAPS-II) and the Modified Early Warning
Score (MEWS) tools.
&lt;/p&gt;
&lt;p&gt;A customized sepsis ontology was used to derive the DBN node structure and
semantically characterize temporal features derived from both structured
physiological data and unstructured clinical notes. We assessed the performance
in predicting mortality risk of the DBN predictive model and compared
performance to other models using Receiver Operating Characteristic (ROC)
curves, area under curve (AUROC), calibration curves, and risk distributions.
&lt;/p&gt;
&lt;p&gt;The derived dataset consists of 24,506 ICU stays from 19,623 patients with
evidence of suspected infection, with 2,829 patients deceased at discharge. The
DBN AUROC was found to be 0.91, which outperformed the SOFA (0.843), qSOFA
(0.66), MEWS (0.73), and SAPS-II (0.77) scoring tools. Continuous Net
Reclassification Index and Integrated Discrimination Improvement analysis
supported the superiority DBN. Compared with conventional rule-based risk
scoring tools, the sepsis knowledgebase-driven DBN algorithm offers improved
performance for predicting mortality of infected patients in ICUs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1&quot;&gt;Tony Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Velez_T/0/1/0/all/0/1&quot;&gt;Tom Velez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Apostolova_E/0/1/0/all/0/1&quot;&gt;Emilia Apostolova&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tschampel_T/0/1/0/all/0/1&quot;&gt;Tim Tschampel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ngo_T/0/1/0/all/0/1&quot;&gt;Thuy L. Ngo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hardison_J/0/1/0/all/0/1&quot;&gt;Joy Hardison&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.10175">
<title>The Sparse Recovery Autoencoder. (arXiv:1806.10175v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.10175</link>
<description rdf:parseType="Literal">&lt;p&gt;Linear encoding of sparse vectors is widely popular, but is most commonly
data-independent -- missing any possible extra (but a-priori unknown) structure
beyond sparsity. In this paper we present a new method to learn linear encoders
that adapt to data, while still performing well with the widely used $\ell_1$
decoder. The convex $\ell_1$ decoder prevents gradient propagation as needed in
standard autoencoder training. Our method is based on the insight that
unfolding the convex decoder into $T$ projected gradient steps can address this
issue. Our method can be seen as a data-driven way to learn a compressed
sensing matrix. Our experiments show that there is indeed additional structure
beyond sparsity in several real datasets. Our autoencoder is able to discover
it and exploit it to create excellent reconstructions with fewer measurements
compared to the previous state of the art methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wu_S/0/1/0/all/0/1&quot;&gt;Shanshan Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Dimakis_A/0/1/0/all/0/1&quot;&gt;Alexandros G. Dimakis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sanghavi_S/0/1/0/all/0/1&quot;&gt;Sujay Sanghavi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yu_F/0/1/0/all/0/1&quot;&gt;Felix X. Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Holtmann_Rice_D/0/1/0/all/0/1&quot;&gt;Daniel Holtmann-Rice&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Storcheus_D/0/1/0/all/0/1&quot;&gt;Dmitry Storcheus&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rostamizadeh_A/0/1/0/all/0/1&quot;&gt;Afshin Rostamizadeh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kumar_S/0/1/0/all/0/1&quot;&gt;Sanjiv Kumar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.10188">
<title>A Tight Convergence Analysis for Stochastic Gradient Descent with Delayed Updates. (arXiv:1806.10188v1 [math.OC])</title>
<link>http://arxiv.org/abs/1806.10188</link>
<description rdf:parseType="Literal">&lt;p&gt;We provide tight finite-time convergence bounds for gradient descent and
stochastic gradient descent on quadratic functions, when the gradients are
delayed and reflect iterates from $\tau$ rounds ago. First, we show that
without stochastic noise, delays strongly affect the attainable optimization
error: In fact, the error can be as bad as non-delayed gradient descent ran on
only $1/\tau$ of the gradients. In sharp contrast, we quantify how stochastic
noise makes the effect of delays negligible, improving on previous work which
only showed this phenomenon asymptotically or for much smaller delays. Also, in
the context of distributed optimization, the results indicate that the
performance of gradient descent with delays is competitive with synchronous
approaches such as mini-batching. Our results are based on a novel technique
for analyzing convergence of optimization algorithms using generating
functions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Arjevani_Y/0/1/0/all/0/1&quot;&gt;Yossi Arjevani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Shamir_O/0/1/0/all/0/1&quot;&gt;Ohad Shamir&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Srebro_N/0/1/0/all/0/1&quot;&gt;Nathan Srebro&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.10206">
<title>Deep Feature Factorization For Concept Discovery. (arXiv:1806.10206v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.10206</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose Deep Feature Factorization (DFF), a method capable of localizing
similar semantic concepts within an image or a set of images. We use DFF to
gain insight into a deep convolutional neural network&apos;s learned features, where
we detect hierarchical cluster structures in feature space. This is visualized
as heat maps, which highlight semantically matching regions across a set of
images, revealing what the network `perceives&apos; as similar. DFF can also be used
to perform co-segmentation and co-localization, and we report state-of-the-art
results on these tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Collins_E/0/1/0/all/0/1&quot;&gt;Edo Collins&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Achanta_R/0/1/0/all/0/1&quot;&gt;Radhakrishna Achanta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Susstrunk_S/0/1/0/all/0/1&quot;&gt;Sabine S&amp;#xfc;sstrunk&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.10222">
<title>Conditional Sparse $\ell_p$-norm Regression With Optimal Probability. (arXiv:1806.10222v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.10222</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the following conditional linear regression problem: the task is
to identify both (i) a $k$-DNF condition $c$ and (ii) a linear rule $f$ such
that the probability of $c$ is (approximately) at least some given bound $\mu$,
and $f$ minimizes the $\ell_p$ loss of predicting the target $z$ in the
distribution of examples conditioned on $c$. Thus, the task is to identify a
portion of the distribution on which a linear rule can provide a good fit.
Algorithms for this task are useful in cases where simple, learnable rules only
accurately model portions of the distribution. The prior state-of-the-art for
such algorithms could only guarantee finding a condition of probability
$\Omega(\mu/n^k)$ when a condition of probability $\mu$ exists, and achieved an
$O(n^k)$-approximation to the target loss, where $n$ is the number of Boolean
attributes. Here, we give efficient algorithms for solving this task with a
condition $c$ that nearly matches the probability of the ideal condition, while
also improving the approximation to the target loss. We also give an algorithm
for finding a $k$-DNF reference class for prediction at a given query point,
that obtains a sparse regression fit that has loss within $O(n^k)$ of optimal
among all sparse regression parameters and sufficiently large $k$-DNF reference
classes containing the query point.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hainline_J/0/1/0/all/0/1&quot;&gt;John Hainline&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Juba_B/0/1/0/all/0/1&quot;&gt;Brendan Juba&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Le_H/0/1/0/all/0/1&quot;&gt;Hai S.Le&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Woodruff_D/0/1/0/all/0/1&quot;&gt;David Woodruff&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.10234">
<title>Scalable Gaussian Process Inference with Finite-data Mean and Variance Guarantees. (arXiv:1806.10234v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.10234</link>
<description rdf:parseType="Literal">&lt;p&gt;Gaussian processes (GPs) offer a flexible class of priors for nonparametric
Bayesian regression, but popular GP posterior inference methods are typically
prohibitively slow or lack desirable finite-data guarantees on quality. We
develop an approach to scalable approximate GP regression with finite-data
guarantees on the accuracy of pointwise posterior mean and variance estimates.
Our main contribution is a novel objective for approximate inference in the
nonparametric setting: the &quot;preconditioned Fisher (pF) divergence.&quot; We show
that unlike popular divergences such as Kullback--Leibler (used in variational
inference), the pF divergence bounds the 2-Wasserstein distance, which in turn
bounds the pointwise difference of the mean and variance functions. We
demonstrate that, for sparse GP likelihood approximations, we can minimize the
pF divergence efficiently. Our experiments show that optimizing the pF
divergence has the same computational requirements as variational sparse GPs
while providing comparable empirical performance---in addition to our novel
finite-data quality guarantees.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Huggins_J/0/1/0/all/0/1&quot;&gt;Jonathan H. Huggins&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Campbell_T/0/1/0/all/0/1&quot;&gt;Trevor Campbell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kasprzak_M/0/1/0/all/0/1&quot;&gt;Miko&amp;#x142;aj Kasprzak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Broderick_T/0/1/0/all/0/1&quot;&gt;Tamara Broderick&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.10283">
<title>Optimal Scheduling of Electrolyzer in Power Market with Dynamic Prices. (arXiv:1806.10283v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.10283</link>
<description rdf:parseType="Literal">&lt;p&gt;Optimal scheduling of hydrogen production in dynamic pricing power market can
maximize the profit of hydrogen producer; however, it highly depends on the
accurate forecast of hydrogen consumption. In this paper, we propose a deep
leaning based forecasting approach for predicting hydrogen consumption of fuel
cell vehicles in future taxi industry. The cost of hydrogen production is
minimized by utilizing the proposed forecasting tool to reduce the hydrogen
produced during high cost on-peak hours and guide hydrogen producer to store
sufficient hydrogen during low cost off-peak hours.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_Y/0/1/0/all/0/1&quot;&gt;Yusheng Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xian_M/0/1/0/all/0/1&quot;&gt;Min Xian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mohanpurkar_M/0/1/0/all/0/1&quot;&gt;Manish Mohanpurkar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bhattarai_B/0/1/0/all/0/1&quot;&gt;Bishnu P. Bhattarai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Medam_A/0/1/0/all/0/1&quot;&gt;Anudeep Medam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kadavil_R/0/1/0/all/0/1&quot;&gt;Rahul Kadavil&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hovsapian_R/0/1/0/all/0/1&quot;&gt;Rob Hovsapian&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.10410">
<title>Dynamic Assortment Selection under the Nested Logit Models. (arXiv:1806.10410v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.10410</link>
<description rdf:parseType="Literal">&lt;p&gt;We study a stylized dynamic assortment planning problem during a selling
season of finite length $T$, by considering a nested multinomial logit model
with $M$ nests and $N$ items per nest. Our policy simultaneously learns
customers&apos; choice behavior and makes dynamic decisions on assortments based on
the current knowledge. It achieves the regret at the order of
$\tilde{O}(\sqrt{MNT}+MN^2)$, where $M$ is the number of nests and $N$ is the
number of products in each nest. We further provide a lower bound result of
$\Omega(\sqrt{MT})$, which shows the optimality of the upper bound when $T&amp;gt;M$
and $N$ is small. However, the $N^2$ term in the upper bound is not ideal for
applications where $N$ is large as compared to $T$. To address this issue, we
further generalize our first policy by introducing a discretization technique,
which leads to a regret of $\tilde{O}(\sqrt{M}T^{2/3}+MNT^{1/3})$ with a
specific choice of discretization granularity. It improves the previous regret
bound whenever $N&amp;gt;T^{1/3}$. We provide numerical results to demonstrate the
empirical performance of both proposed policies.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chen_X/0/1/0/all/0/1&quot;&gt;Xi Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yining Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhou_Y/0/1/0/all/0/1&quot;&gt;Yuan Zhou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.10474">
<title>The challenge of realistic music generation: modelling raw audio at scale. (arXiv:1806.10474v1 [cs.SD])</title>
<link>http://arxiv.org/abs/1806.10474</link>
<description rdf:parseType="Literal">&lt;p&gt;Realistic music generation is a challenging task. When building generative
models of music that are learnt from data, typically high-level representations
such as scores or MIDI are used that abstract away the idiosyncrasies of a
particular performance. But these nuances are very important for our perception
of musicality and realism, so in this work we embark on modelling music in the
raw audio domain. It has been shown that autoregressive models excel at
generating raw audio waveforms of speech, but when applied to music, we find
them biased towards capturing local signal structure at the expense of
modelling long-range correlations. This is problematic because music exhibits
structure at many different timescales. In this work, we explore autoregressive
discrete autoencoders (ADAs) as a means to enable autoregressive models to
capture long-range correlations in waveforms. We find that they allow us to
unconditionally generate piano music directly in the raw audio domain, which
shows stylistic consistency across tens of seconds.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dieleman_S/0/1/0/all/0/1&quot;&gt;Sander Dieleman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oord_A/0/1/0/all/0/1&quot;&gt;A&amp;#xe4;ron van den Oord&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Simonyan_K/0/1/0/all/0/1&quot;&gt;Karen Simonyan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.10547">
<title>Online optimal task offloading with one-bit feedback. (arXiv:1806.10547v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.10547</link>
<description rdf:parseType="Literal">&lt;p&gt;Task offloading is an emerging technology in fog-enabled networks. It allows
users transmit tasks to neighbor fog nodes so as to utilize the computing
resource of the networks. In this paper, we investigate a stochastic task
offloading model and propose a multi-armed bandit framework to formulate this
model. We consider different helper nodes prefer different kinds of tasks and
feedback one-bit information to task node named happiness of nodes. The key
challenge of this problem is an exploration-exploitation tradeoff. Thus we
implement a UCB-type algorithm to maximize the long-term happiness metric.
Further more, we prove that this UCB-type algorithm is asymptotically optimal.
Numerical simulations are given in the end of the paper to corroborate our
strategy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_S/0/1/0/all/0/1&quot;&gt;Shangshu Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_Z/0/1/0/all/0/1&quot;&gt;Zhaowei Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_F/0/1/0/all/0/1&quot;&gt;Fuqian Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_X/0/1/0/all/0/1&quot;&gt;Xiliang Luo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.10586">
<title>Approximability of Discriminators Implies Diversity in GANs. (arXiv:1806.10586v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.10586</link>
<description rdf:parseType="Literal">&lt;p&gt;While Generative Adversarial Networks (GANs) have empirically produced
impressive results on learning complex real-world distributions, recent work
has shown that they suffer from lack of diversity or mode collapse. The
theoretical work of Arora et al.~\cite{AroraGeLiMaZh17} suggests a dilemma
about GANs&apos; statistical properties: powerful discriminators cause overfitting,
whereas weak discriminators cannot detect mode collapse.
&lt;/p&gt;
&lt;p&gt;In contrast, we show in this paper that GANs can in principle learn
distributions in Wasserstein distance (or KL-divergence in many cases) with
polynomial sample complexity, if the discriminator class has strong
distinguishing power against the particular generator class (instead of against
all possible generators). For various generator classes such as mixture of
Gaussians, exponential families, and invertible neural networks generators, we
design corresponding discriminators (which are often neural nets of specific
architectures) such that the Integral Probability Metric (IPM) induced by the
discriminators can provably approximate the Wasserstein distance and/or
KL-divergence. This implies that if the training is successful, then the
learned distribution is close to the true distribution in Wasserstein distance
or KL divergence, and thus cannot drop modes. Our preliminary experiments show
that on synthetic datasets the test IPM is well correlated with KL divergence,
indicating that the lack of diversity may be caused by the sub-optimality in
optimization instead of statistical inefficiency.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bai_Y/0/1/0/all/0/1&quot;&gt;Yu Bai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_T/0/1/0/all/0/1&quot;&gt;Tengyu Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Risteski_A/0/1/0/all/0/1&quot;&gt;Andrej Risteski&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1704.03976">
<title>Virtual Adversarial Training: A Regularization Method for Supervised and Semi-Supervised Learning. (arXiv:1704.03976v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1704.03976</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a new regularization method based on virtual adversarial loss: a
new measure of local smoothness of the conditional label distribution given
input. Virtual adversarial loss is defined as the robustness of the conditional
label distribution around each input data point against local perturbation.
Unlike adversarial training, our method defines the adversarial direction
without label information and is hence applicable to semi-supervised learning.
Because the directions in which we smooth the model are only &quot;virtually&quot;
adversarial, we call our method virtual adversarial training (VAT). The
computational cost of VAT is relatively low. For neural networks, the
approximated gradient of virtual adversarial loss can be computed with no more
than two pairs of forward- and back-propagations. In our experiments, we
applied VAT to supervised and semi-supervised learning tasks on multiple
benchmark datasets. With a simple enhancement of the algorithm based on the
entropy minimization principle, our VAT achieves state-of-the-art performance
for semi-supervised learning tasks on SVHN and CIFAR-10.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Miyato_T/0/1/0/all/0/1&quot;&gt;Takeru Miyato&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Maeda_S/0/1/0/all/0/1&quot;&gt;Shin-ichi Maeda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Koyama_M/0/1/0/all/0/1&quot;&gt;Masanori Koyama&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ishii_S/0/1/0/all/0/1&quot;&gt;Shin Ishii&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.02840">
<title>Neural Network Renormalization Group. (arXiv:1802.02840v3 [cond-mat.stat-mech] UPDATED)</title>
<link>http://arxiv.org/abs/1802.02840</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a variational renormalization group (RG) approach using a deep
generative model based on normalizing flows. The model performs hierarchical
change-of-variables transformations from the physical space to a latent space
with reduced mutual information. Conversely, the neural net directly maps
independent Gaussian noises to physical configurations following the inverse RG
flow. The model has an exact and tractable likelihood, which allows unbiased
training and direct access to the renormalized energy function of the latent
variables. To train the model, we employ probability density distillation for
the bare energy function of the physical problem, in which the training loss
provides a variational upper bound of the physical free energy. We demonstrate
practical usage of the approach by identifying mutually independent collective
variables of the Ising model and performing accelerated hybrid Monte Carlo
sampling in the latent space. Lastly, we comment on the connection of the
present approach to the wavelet formulation of RG and the modern pursuit of
information preserving RG.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Li_S/0/1/0/all/0/1&quot;&gt;Shuo-Hui Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Wang_L/0/1/0/all/0/1&quot;&gt;Lei Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08626">
<title>Empirical Risk Minimization under Fairness Constraints. (arXiv:1802.08626v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1802.08626</link>
<description rdf:parseType="Literal">&lt;p&gt;We address the problem of algorithmic fairness: ensuring that sensitive
variables do not unfairly influence the outcome of a classifier. We present an
approach based on empirical risk minimization, which incorporates a fairness
constraint into the learning problem. It encourages the conditional risk of the
learned classifier to be approximately constant with respect to the sensitive
variable. We derive both risk and fairness bounds that support the statistical
consistency of our approach. We specify our approach to kernel methods and
observe that the fairness requirement implies an orthogonality constraint which
can be easily added to these methods. We further observe that for linear models
the constraint translates into a simple data preprocessing step. Experiments
indicate that the method is empirically effective and performs favorably
against state-of-the-art approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Donini_M/0/1/0/all/0/1&quot;&gt;Michele Donini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Oneto_L/0/1/0/all/0/1&quot;&gt;Luca Oneto&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ben_David_S/0/1/0/all/0/1&quot;&gt;Shai Ben-David&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Shawe_Taylor_J/0/1/0/all/0/1&quot;&gt;John Shawe-Taylor&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pontil_M/0/1/0/all/0/1&quot;&gt;Massimiliano Pontil&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.03154">
<title>Cauchy noise loss for stochastic optimization of random matrix models via free deterministic equivalents. (arXiv:1804.03154v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1804.03154</link>
<description rdf:parseType="Literal">&lt;p&gt;For random matrix models, the parameter estimation based on the traditional
likelihood is not straightforward in particular when there is only one sample
matrix. We introduce a new parameter optimization method of random matrix
models which works even in such a case not based on the traditional likelihood,
instead based on the spectral distribution. We use the spectral distribution
perturbed by Cauchy noises because the free deterministic equivalent, which is
a tool in free probability theory, allows us to approximate it by a smooth and
accessible density function.
&lt;/p&gt;
&lt;p&gt;Moreover, we study an asymptotic property of a determination gap, which has a
similar role as the generalization gap. In addition, we propose a new
dimensionality recovery method for the signal-plus-noise model, and
experimentally demonstrate that it recovers the rank of the signal part even if
the rank is not low. It is a simultaneous rank selection and parameter
estimation procedure.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hayase_T/0/1/0/all/0/1&quot;&gt;Tomohiro Hayase&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.09046">
<title>Developing a machine learning framework for estimating soil moisture with VNIR hyperspectral data. (arXiv:1804.09046v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1804.09046</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we investigate the potential of estimating the soil-moisture
content based on VNIR hyperspectral data combined with IR data. Measurements
from a multi-sensor field campaign represent the benchmark dataset which
contains measured hyperspectral, IR, and soil-moisture data. We introduce a
regression framework with three steps consisting of feature selection,
preprocessing, and well-chosen regression models. The latter are mainly
supervised machine learning models. An exception are the self-organizing maps
which are a combination of unsupervised and supervised learning. We analyze the
impact of the distinct preprocessing methods on the regression results. Of all
regression models, the extremely randomized trees model without preprocessing
provides the best estimation performance. Our results reveal the potential of
the respective regression framework combined with the VNIR hyperspectral data
to estimate soil moisture. In conclusion, the results of this paper provide a
basis for further improvements in different research directions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Keller_S/0/1/0/all/0/1&quot;&gt;Sina Keller&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Riese_F/0/1/0/all/0/1&quot;&gt;Felix M. Riese&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stotzer_J/0/1/0/all/0/1&quot;&gt;Johanna St&amp;#xf6;tzer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Maier_P/0/1/0/all/0/1&quot;&gt;Philipp M. Maier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hinz_S/0/1/0/all/0/1&quot;&gt;Stefan Hinz&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.02587">
<title>Complete Analysis of a Random Forest Model. (arXiv:1805.02587v4 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1805.02587</link>
<description rdf:parseType="Literal">&lt;p&gt;Random forests have become an important tool for improving accuracy in
regression problems since their popularization by [Breiman, 2001] and others.
In this paper, we revisit a random forest model originally proposed by
[Breiman, 2004] and later studied by [Biau, 2012], where a feature is selected
at random and the split occurs at the midpoint of the box containing the chosen
feature. If the Lipschitz regression function is sparse and only depends on a
small, unknown subset of $S$ out of $d$ features, we show that given $n$
observations, this random forest model outputs a predictor that has a
mean-squared prediction error $O((n(\sqrt{\log
n})^{S-1})^{-\frac{1}{S\log2+1}})$. When $S \leq \lfloor 0.72 d \rfloor$, this
rate is significantly better than the minimax optimal rate
$\Theta(n^{-\frac{2}{d+2}})$ for Lipschitz function classes in $ d $
dimensions. The second part of this article shows that the prediction error for
this random forest model cannot generally be improved. As a striking
consequence of our analysis, we show that if $\ell_{avg}$ (resp. $\ell_{max}$)
is the average (resp. maximum) number of observations per leaf node, then the
variance of this forest is $\Theta(\ell^{-1}_{avg}(\sqrt{\log n})^{-(S-1)})$.
When $S = d$, this variance is similar in form to the best-case variance lower
bound $\Omega(\ell^{-1}_{max}(\log n)^{-(d-1)})$ of [Lin and Jeon, 2006] for
any random forest model with a nonadaptive splitting scheme (i.e., where the
split protocol is independent of the data). We also show that the bias is tight
for any linear model with nonzero parameter vector. Finally, a side consequence
of our analysis is that if the regression function is square-integrable (e.g.,
it need not be continuous or bounded), then the random forest predictor is
pointwise consistent almost everywhere.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Klusowski_J/0/1/0/all/0/1&quot;&gt;Jason M. Klusowski&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.05751">
<title>Local Saddle Point Optimization: A Curvature Exploitation Approach. (arXiv:1805.05751v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.05751</link>
<description rdf:parseType="Literal">&lt;p&gt;Gradient-based optimization methods are the most popular choice for finding
local optima for classical minimization and saddle point problems. Here, we
highlight a systemic issue of gradient dynamics that arise for saddle point
problems, namely the presence of undesired stable stationary points that are no
local optima. We propose a novel optimization approach that exploits curvature
information in order to escape from these undesired stationary points. We prove
that different optimization methods, including gradient method and adagrad,
equipped with curvature exploitation can escape non-optimal stationary points.
We also provide empirical results on common saddle point problems which confirm
the advantage of using curvature exploitation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Adolphs_L/0/1/0/all/0/1&quot;&gt;Leonard Adolphs&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Daneshmand_H/0/1/0/all/0/1&quot;&gt;Hadi Daneshmand&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lucchi_A/0/1/0/all/0/1&quot;&gt;Aurelien Lucchi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hofmann_T/0/1/0/all/0/1&quot;&gt;Thomas Hofmann&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08593">
<title>Confounding-Robust Policy Improvement. (arXiv:1805.08593v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.08593</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the problem of learning personalized decision policies from
observational data while accounting for possible unobserved confounding in the
data-generating process. Previous approaches, which assume unconfoundedness,
i.e., that no unobserved confounders affect both the treatment assignment as
well as outcome, can lead to policies that actually introduce significant harm
rather then benefit due to overeager intervention when some unobserved
confounding is present, as is actually the case in most applications dealing
with observational data. Instead, we calibrate policy learning for realistic
violations of this unverifiable assumption with uncertainty sets motivated by
sensitivity analysis in causal inference. Our framework for confounding-robust
policy improvement optimizes the minimax regret of a candidate policy against a
baseline standard-of-care policy over an uncertainty set for propensity
weights. We prove that if the uncertainty set is well-specified, our robust
policy, when applied in practice, will do no worse than the baseline and
improve upon it if possible. We characterize the adversarial optimization
subproblem and use efficient algorithmic solutions to optimize over
parametrized spaces of decision policies such as logistic treatment assignment
and decision trees. We assess our methods on synthetic data and on a large
clinical trial of acute ischaemic stroke treatment, demonstrating that hidden
confounding can hinder existing policy learning approaches and lead to
unwarranted harm, while our robust approach guarantees safety and focuses on
well-evidenced improvement, a necessity for making personalized treatment
policies learned from observational data reliable in practice.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kallus_N/0/1/0/all/0/1&quot;&gt;Nathan Kallus&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_A/0/1/0/all/0/1&quot;&gt;Angela Zhou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02199">
<title>Deep Self-Organization: Interpretable Discrete Representation Learning on Time Series. (arXiv:1806.02199v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1806.02199</link>
<description rdf:parseType="Literal">&lt;p&gt;Human professionals are often required to make decisions based on complex
multivariate time series measurements in an online setting, e.g. in health
care. Since human cognition is not optimized to work well in high-dimensional
spaces, these decisions benefit from interpretable low-dimensional
representations. However, many representation learning algorithms for time
series data are difficult to interpret. This is due to non-intuitive mappings
from data features to salient properties of the representation and
non-smoothness over time. To address this problem, we propose to couple a
variational autoencoder to a discrete latent space and introduce a topological
structure through the use of self-organizing maps. This allows us to learn
discrete representations of time series, which give rise to smooth and
interpretable embeddings with superior clustering performance. Furthermore, to
allow for a probabilistic interpretation of our method, we integrate a Markov
model in the latent space. This model uncovers the temporal transition
structure, improves clustering performance even further and provides additional
explanatory insights as well as a natural representation of uncertainty. We
evaluate our model on static (Fashion-)MNIST data, a time series of linearly
interpolated (Fashion-)MNIST images, a chaotic Lorenz attractor system with two
macro states, as well as on a challenging real world medical time series
application. In the latter experiment, our representation uncovers meaningful
structure in the acute physiological state of a patient.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fortuin_V/0/1/0/all/0/1&quot;&gt;Vincent Fortuin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huser_M/0/1/0/all/0/1&quot;&gt;Matthias H&amp;#xfc;ser&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Locatello_F/0/1/0/all/0/1&quot;&gt;Francesco Locatello&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Strathmann_H/0/1/0/all/0/1&quot;&gt;Heiko Strathmann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ratsch_G/0/1/0/all/0/1&quot;&gt;Gunnar R&amp;#xe4;tsch&lt;/a&gt;</dc:creator>
</item></rdf:RDF>