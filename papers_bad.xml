<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Boring papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Bad Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-02-25T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08370"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08478"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08590"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1705.07904"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1705.10119"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1707.01495"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.00436"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08254"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08328"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08365"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08540"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08545"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08554"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08614"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08674"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08679"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1607.06667"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1704.06676"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1707.01891"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.07643"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08249"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08318"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08323"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08334"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08363"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08372"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08380"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08397"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08404"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08406"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08407"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08429"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08471"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08539"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08598"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08626"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08665"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08667"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08680"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1308.1196"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1705.07107"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1706.00754"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.06382"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.10568"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.11198"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.01769"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.04802"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.05382"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.08104"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.07648"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1802.08370">
<title>Do WaveNets Dream of Acoustic Waves?. (arXiv:1802.08370v1 [cs.SD])</title>
<link>http://arxiv.org/abs/1802.08370</link>
<description rdf:parseType="Literal">&lt;p&gt;Various sources have reported the WaveNet deep learning architecture being
able to generate high-quality speech, but to our knowledge there haven&apos;t been
studies on the interpretation or visualization of trained WaveNets. This study
investigates the possibility that WaveNet understands speech by unsupervisedly
learning an acoustically meaningful latent representation of the speech signals
in its receptive field; we also attempt to interpret the mechanism by which the
feature extraction is performed. Suggested by singular value decomposition and
linear regression analysis on the activations and known acoustic features (e.g.
F0), the key findings are (1) activations in the higher layers are highly
correlated with spectral features; (2) WaveNet explicitly performs pitch
extraction despite being trained to directly predict the next audio sample and
(3) for the said feature analysis to take place, the latent signal
representation is converted back and forth between baseband and wideband
components.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hua_K/0/1/0/all/0/1&quot;&gt;Kanru Hua&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08478">
<title>Coloring black boxes: visualization of neural network decisions. (arXiv:1802.08478v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1802.08478</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural networks are commonly regarded as black boxes performing
incomprehensible functions. For classification problems networks provide maps
from high dimensional feature space to K-dimensional image space. Images of
training vector are projected on polygon vertices, providing visualization of
network function. Such visualization may show the dynamics of learning, allow
for comparison of different networks, display training vectors around which
potential problems may arise, show differences due to regularization and
optimization procedures, investigate stability of network classification under
perturbation of original vectors, and place new data sample in relation to
training data, allowing for estimation of confidence in classification of a
given sample. An illustrative example for the three-class Wine data and
five-class Satimage data is described. The visualization method proposed here
is applicable to any black box system that provides continuous outputs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Duch_W/0/1/0/all/0/1&quot;&gt;Wlodzislaw Duch&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08590">
<title>Reservoir computing with simple oscillators: Virtual and real networks. (arXiv:1802.08590v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1802.08590</link>
<description rdf:parseType="Literal">&lt;p&gt;The reservoir computing scheme is a machine learning mechanism which utilizes
the naturally occuring computational capabilities of dynamical systems. One
important subset of systems that has proven powerful both in experiments and
theory are delay-systems. In this work, we investigate the reservoir computing
performance of hybrid network-delay systems systematically by evaluating the
NARMA10 and the Sante Fe task.. We construct &apos;multiplexed networks&apos; that can be
seen as intermediate steps on the scale from classical networks to the &apos;virtual
networks&apos; of delay systems. We find that the delay approach can be extended to
the network case without loss of computational power, enabling the construction
of faster reservoir computing substrates.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rohm_A/0/1/0/all/0/1&quot;&gt;Andr&amp;#xe9; R&amp;#xf6;hm&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ludge_K/0/1/0/all/0/1&quot;&gt;Kathy L&amp;#xfc;dge&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1705.07904">
<title>Semantically Decomposing the Latent Spaces of Generative Adversarial Networks. (arXiv:1705.07904v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1705.07904</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a new algorithm for training generative adversarial networks that
jointly learns latent codes for both identities (e.g. individual humans) and
observations (e.g. specific photographs). By fixing the identity portion of the
latent codes, we can generate diverse images of the same subject, and by fixing
the observation portion, we can traverse the manifold of subjects while
maintaining contingent aspects such as lighting and pose. Our algorithm
features a pairwise training scheme in which each sample from the generator
consists of two images with a common identity code. Corresponding samples from
the real dataset consist of two distinct photographs of the same subject. In
order to fool the discriminator, the generator must produce pairs that are
photorealistic, distinct, and appear to depict the same individual. We augment
both the DCGAN and BEGAN approaches with Siamese discriminators to facilitate
pairwise training. Experiments with human judges and an off-the-shelf face
verification system demonstrate our algorithm&apos;s ability to generate convincing,
identity-matched photographs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Donahue_C/0/1/0/all/0/1&quot;&gt;Chris Donahue&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lipton_Z/0/1/0/all/0/1&quot;&gt;Zachary C. Lipton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Balsubramani_A/0/1/0/all/0/1&quot;&gt;Akshay Balsubramani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+McAuley_J/0/1/0/all/0/1&quot;&gt;Julian McAuley&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1705.10119">
<title>Kernel Implicit Variational Inference. (arXiv:1705.10119v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1705.10119</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent progress in variational inference has paid much attention to the
flexibility of variational posteriors. One promising direction is to use
implicit distributions, i.e., distributions without tractable densities as the
variational posterior. However, existing methods on implicit posteriors still
face challenges of noisy estimation and computational infeasibility when
applied to models with high-dimensional latent variables. In this paper, we
present a new approach named Kernel Implicit Variational Inference that
addresses these challenges. As far as we know, for the first time implicit
variational inference is successfully applied to Bayesian neural networks,
which shows promising results on both regression and classification tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Shi_J/0/1/0/all/0/1&quot;&gt;Jiaxin Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sun_S/0/1/0/all/0/1&quot;&gt;Shengyang Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhu_J/0/1/0/all/0/1&quot;&gt;Jun Zhu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1707.01495">
<title>Hindsight Experience Replay. (arXiv:1707.01495v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1707.01495</link>
<description rdf:parseType="Literal">&lt;p&gt;Dealing with sparse rewards is one of the biggest challenges in Reinforcement
Learning (RL). We present a novel technique called Hindsight Experience Replay
which allows sample-efficient learning from rewards which are sparse and binary
and therefore avoid the need for complicated reward engineering. It can be
combined with an arbitrary off-policy RL algorithm and may be seen as a form of
implicit curriculum.
&lt;/p&gt;
&lt;p&gt;We demonstrate our approach on the task of manipulating objects with a
robotic arm. In particular, we run experiments on three different tasks:
pushing, sliding, and pick-and-place, in each case using only binary rewards
indicating whether or not the task is completed. Our ablation studies show that
Hindsight Experience Replay is a crucial ingredient which makes training
possible in these challenging environments. We show that our policies trained
on a physics simulation can be deployed on a physical robot and successfully
complete the task.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Andrychowicz_M/0/1/0/all/0/1&quot;&gt;Marcin Andrychowicz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wolski_F/0/1/0/all/0/1&quot;&gt;Filip Wolski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ray_A/0/1/0/all/0/1&quot;&gt;Alex Ray&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schneider_J/0/1/0/all/0/1&quot;&gt;Jonas Schneider&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fong_R/0/1/0/all/0/1&quot;&gt;Rachel Fong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Welinder_P/0/1/0/all/0/1&quot;&gt;Peter Welinder&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+McGrew_B/0/1/0/all/0/1&quot;&gt;Bob McGrew&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tobin_J/0/1/0/all/0/1&quot;&gt;Josh Tobin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1&quot;&gt;Pieter Abbeel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zaremba_W/0/1/0/all/0/1&quot;&gt;Wojciech Zaremba&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.00436">
<title>Hierarchical Representations for Efficient Architecture Search. (arXiv:1711.00436v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1711.00436</link>
<description rdf:parseType="Literal">&lt;p&gt;We explore efficient neural architecture search methods and show that a
simple yet powerful evolutionary algorithm can discover new architectures with
excellent performance. Our approach combines a novel hierarchical genetic
representation scheme that imitates the modularized design pattern commonly
adopted by human experts, and an expressive search space that supports complex
topologies. Our algorithm efficiently discovers architectures that outperform a
large number of manually designed models for image classification, obtaining
top-1 error of 3.6% on CIFAR-10 and 20.3% when transferred to ImageNet, which
is competitive with the best existing neural architecture search approaches. We
also present results using random search, achieving 0.3% less top-1 accuracy on
CIFAR-10 and 0.1% less on ImageNet whilst reducing the search time from 36
hours down to 1 hour.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1&quot;&gt;Hanxiao Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Simonyan_K/0/1/0/all/0/1&quot;&gt;Karen Simonyan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vinyals_O/0/1/0/all/0/1&quot;&gt;Oriol Vinyals&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fernando_C/0/1/0/all/0/1&quot;&gt;Chrisantha Fernando&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kavukcuoglu_K/0/1/0/all/0/1&quot;&gt;Koray Kavukcuoglu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08254">
<title>BigDataBench: A Dwarf-based Big Data and AI Benchmark Suite. (arXiv:1802.08254v1 [cs.DC])</title>
<link>http://arxiv.org/abs/1802.08254</link>
<description rdf:parseType="Literal">&lt;p&gt;As architecture, system, data management, and machine learning communities
pay greater attention to innovative big data and data-driven artificial
intelligence (in short, AI) algorithms, architecture, and systems, the pressure
of benchmarking rises. However, complexity, diversity, frequently changed
workloads, and rapid evolution of big data, especially AI systems raise great
challenges in benchmarking. First, for the sake of conciseness, benchmarking
scalability, portability cost, reproducibility, and better interpretation of
performance data, we need understand what are the abstractions of
frequently-appearing units of computation, which we call dwarfs, among big data
and AI workloads. Second, for the sake of fairness, the benchmarks must include
diversity of data and workloads. Third, for co-design of software and hardware,
the benchmarks should be consistent across different communities. Other than
creating a new benchmark or proxy for every possible workload, we propose using
dwarf-based benchmarks--the combination of eight dwarfs--to represent diversity
of big data and AI workloads. The current version--BigDataBench 4.0 provides 13
representative real-world data sets and 47 big data and AI benchmarks,
including seven workload types: online service, offline analytics, graph
analytics, AI, data warehouse, NoSQL, and streaming. BigDataBench 4.0 is
publicly available from &lt;a href=&quot;http://prof.ict.ac.cn/BigDataBench.&quot;&gt;this http URL&lt;/a&gt; Also, for the first
time, we comprehensively characterize the benchmarks of seven workload types in
BigDataBench 4.0 in addition to traditional benchmarks like SPECCPU, PARSEC and
HPCC in a hierarchical manner and drill down on five levels, using the Top-Down
analysis from an architecture perspective.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_W/0/1/0/all/0/1&quot;&gt;Wanling Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhan_J/0/1/0/all/0/1&quot;&gt;Jianfeng Zhan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1&quot;&gt;Lei Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_C/0/1/0/all/0/1&quot;&gt;Chunjie Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_D/0/1/0/all/0/1&quot;&gt;Daoyi Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ren_R/0/1/0/all/0/1&quot;&gt;Rui Ren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_C/0/1/0/all/0/1&quot;&gt;Chen Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_G/0/1/0/all/0/1&quot;&gt;Gang Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jingwei Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cao_Z/0/1/0/all/0/1&quot;&gt;Zheng Cao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1&quot;&gt;Shujie Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_H/0/1/0/all/0/1&quot;&gt;Haoning Tang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08328">
<title>On Looking for Local Expansion Invariants in Argumentation Semantics. (arXiv:1802.08328v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.08328</link>
<description rdf:parseType="Literal">&lt;p&gt;We study invariant local expansion operators for conflict-free and admissible
sets in Abstract Argumentation Frameworks (AFs). Such operators are directly
applied on AFs, and are invariant with respect to a chosen &quot;semantics&quot; (that is
w.r.t. each of the conflict free/admissible set of arguments). Accordingly, we
derive a definition of robustness for AFs in terms of the number of times such
operators can be applied without producing any change in the chosen semantics.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bistarelli_S/0/1/0/all/0/1&quot;&gt;Stefano Bistarelli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Santini_F/0/1/0/all/0/1&quot;&gt;Francesco Santini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Taticchi_C/0/1/0/all/0/1&quot;&gt;Carlo Taticchi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08365">
<title>Budget Constrained Bidding by Model-free Reinforcement Learning in Display Advertising. (arXiv:1802.08365v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.08365</link>
<description rdf:parseType="Literal">&lt;p&gt;Real-time bidding (RTB) is almost the most important mechanism in online
display advertising, where proper bid for each page view plays a vital and
essential role for good marketing results. Budget constrained bidding is a
typical scenario in RTB mechanism where the advertisers hope to maximize total
value of winning impressions under a pre-set budget constraint. However, the
optimal strategy is hard to be derived due to complexity and volatility of the
auction environment. To address the challenges, in this paper, we formulate
budget constrained bidding as a Markov Decision Process. Quite different from
prior model-based work, we propose a novel framework based on model-free
reinforcement learning which sequentially regulates the bidding parameter
rather than directly producing bid. Along this line, we further innovate a
reward function which deploys a deep neural network to learn appropriate reward
and thus leads the agent to deliver the optimal policy effectively; we also
design an adaptive $\epsilon$-greedy strategy which adjusts the exploration
behaviour dynamically and further improves the performance. Experimental
results on real dataset demonstrate the effectiveness of our framework.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_D/0/1/0/all/0/1&quot;&gt;Di Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1&quot;&gt;Xiujun Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1&quot;&gt;Xun Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1&quot;&gt;Hao Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tan_Q/0/1/0/all/0/1&quot;&gt;Qing Tan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xiaoxun Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gai_K/0/1/0/all/0/1&quot;&gt;Kun Gai&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08540">
<title>Optimal Stochastic Delivery Planning in Full-Truckload and Less-Than-Truckload Delivery. (arXiv:1802.08540v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.08540</link>
<description rdf:parseType="Literal">&lt;p&gt;With an increasing demand from emerging logistics businesses, Vehicle Routing
Problem with Private fleet and common Carrier (VRPPC) has been introduced to
manage package delivery services from a supplier to customers. However, almost
all of existing studies focus on the deterministic problem that assumes all
parameters are known perfectly at the time when the planning and routing
decisions are made. In reality, some parameters are random and unknown.
Therefore, in this paper, we consider VRPPC with hard time windows and random
demand, called Optimal Delivery Planning (ODP). The proposed ODP aims to
minimize the total package delivery cost while meeting the customer time window
constraints. We use stochastic integer programming to formulate the
optimization problem incorporating the customer demand uncertainty. Moreover,
we evaluate the performance of the ODP using test data from benchmark dataset
and from actual Singapore road map.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sawadsitang_S/0/1/0/all/0/1&quot;&gt;Suttinee Sawadsitang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kaewpuang_R/0/1/0/all/0/1&quot;&gt;Rakpong Kaewpuang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_S/0/1/0/all/0/1&quot;&gt;Siwei Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Niyato_D/0/1/0/all/0/1&quot;&gt;Dusit Niyato&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_P/0/1/0/all/0/1&quot;&gt;Ping Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08545">
<title>Unsupervised Grammar Induction with Depth-bounded PCFG. (arXiv:1802.08545v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1802.08545</link>
<description rdf:parseType="Literal">&lt;p&gt;There has been recent interest in applying cognitively or empirically
motivated bounds on recursion depth to limit the search space of grammar
induction models (Ponvert et al., 2011; Noji and Johnson, 2016; Shain et al.,
2016). This work extends this depth- bounding approach to probabilistic
context- free grammar induction (DB-PCFG), which has a smaller parameter space
than hierar- chical sequence models, and therefore more fully exploits the
space reductions of depth- bounding. Results for this model on grammar
acquisition from transcribed child-directed speech and newswire text exceed or
are com- petitive with those of other models when eval- uated on parse
accuracy. Moreover, gram- mars acquired from this model demonstrate a
consistent use of category labels, something which has not been demonstrated by
other ac- quisition models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jin_L/0/1/0/all/0/1&quot;&gt;Lifeng Jin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Doshi_Velez_F/0/1/0/all/0/1&quot;&gt;Finale Doshi-Velez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Miller_T/0/1/0/all/0/1&quot;&gt;Timothy Miller&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schuler_W/0/1/0/all/0/1&quot;&gt;William Schuler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schwartz_L/0/1/0/all/0/1&quot;&gt;Lane Schwartz&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08554">
<title>Semantic Vector Spaces for Broadening Consideration of Consequences. (arXiv:1802.08554v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.08554</link>
<description rdf:parseType="Literal">&lt;p&gt;Reasoning systems with too simple a model of the world and human intent are
unable to consider potential negative side effects of their actions and modify
their plans to avoid them (e.g., avoiding potential errors). However,
hand-encoding the enormous and subtle body of facts that constitutes common
sense into a knowledge base has proved too difficult despite decades of work.
Distributed semantic vector spaces learned from large text corpora, on the
other hand, can learn representations that capture shades of meaning of
common-sense concepts and perform analogical and associational reasoning in
ways that knowledge bases are too rigid to perform, by encoding concepts and
the relations between them as geometric structures. These have, however, the
disadvantage of being unreliable, poorly understood, and biased in their view
of the world by the source material. This chapter will discuss how these
approaches may be combined in a way that combines the best properties of each
for understanding the world and human intentions in a richer way.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stay_D/0/1/0/all/0/1&quot;&gt;Douglas Summers Stay&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08614">
<title>Visualizing the Flow of Discourse with a Concept Ontology. (arXiv:1802.08614v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1802.08614</link>
<description rdf:parseType="Literal">&lt;p&gt;Understanding and visualizing human discourse has long being a challenging
task. Although recent work on argument mining have shown success in classifying
the role of various sentences, the task of recognizing concepts and
understanding the ways in which they are discussed remains challenging. Given
an email thread or a transcript of a group discussion, our task is to extract
the relevant concepts and understand how they are referenced and re-referenced
throughout the discussion. In the present work, we present a preliminary
approach for extracting and visualizing group discourse by adapting Wikipedia&apos;s
category hierarchy to be an external concept ontology. From a user study, we
found that our method achieved better results than 4 strong alternative
approaches, and we illustrate our visualization method based on the extracted
discourse flows.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_B/0/1/0/all/0/1&quot;&gt;Baoxu Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Weninger_T/0/1/0/all/0/1&quot;&gt;Tim Weninger&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08674">
<title>An Algorithmic Framework to Control Bias in Bandit-based Personalization. (arXiv:1802.08674v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.08674</link>
<description rdf:parseType="Literal">&lt;p&gt;Personalization is pervasive in the online space as it leads to higher
efficiency and revenue by allowing the most relevant content to be served to
each user. However, recent studies suggest that personalization methods can
propagate societal or systemic biases and polarize opinions; this has led to
calls for regulatory mechanisms and algorithms to combat bias and inequality.
Algorithmically, bandit optimization has enjoyed great success in learning user
preferences and personalizing content or feeds accordingly. We propose an
algorithmic framework that allows for the possibility to control bias or
discrimination in such bandit-based personalization. Our model allows for the
specification of general fairness constraints on the sensitive types of the
content that can be displayed to a user. The challenge, however, is to come up
with a scalable and low regret algorithm for the constrained optimization
problem that arises. Our main technical contribution is a provably fast and
low-regret algorithm for the fairness-constrained bandit optimization problem.
Our proofs crucially leverage the special structure of our problem. Experiments
on synthetic and real-world data sets show that our algorithmic framework can
control bias with only a minor loss to revenue.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Celis_L/0/1/0/all/0/1&quot;&gt;L. Elisa Celis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kapoor_S/0/1/0/all/0/1&quot;&gt;Sayash Kapoor&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Salehi_F/0/1/0/all/0/1&quot;&gt;Farnood Salehi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vishnoi_N/0/1/0/all/0/1&quot;&gt;Nisheeth K. Vishnoi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08679">
<title>Learning Optimal Policies from Observational Data. (arXiv:1802.08679v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.08679</link>
<description rdf:parseType="Literal">&lt;p&gt;Choosing optimal (or at least better) policies is an important problem in
domains from medicine to education to finance and many others. One approach to
this problem is through controlled experiments/trials - but controlled
experiments are expensive. Hence it is important to choose the best policies on
the basis of observational data. This presents two difficult challenges: (i)
missing counterfactuals, and (ii) selection bias. This paper presents
theoretical bounds on estimation errors of counterfactuals from observational
data by making connections to domain adaptation theory. It also presents a
principled way of choosing optimal policies using domain adversarial neural
networks. We illustrate the effectiveness of domain adversarial training
together with various features of our algorithm on a semi-synthetic breast
cancer dataset and a supervised UCI dataset (Statlog).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Atan_O/0/1/0/all/0/1&quot;&gt;Onur Atan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zame_W/0/1/0/all/0/1&quot;&gt;William R. Zame&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schaar_M/0/1/0/all/0/1&quot;&gt;M van der Schaar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1607.06667">
<title>Inpainting of long audio segments with similarity graphs. (arXiv:1607.06667v4 [cs.SD] UPDATED)</title>
<link>http://arxiv.org/abs/1607.06667</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a novel method for the compensation of long duration data loss in
audio signals, in particular music. The concealment of such signal defects is
based on a graph that encodes signal structure in terms of time-persistent
spectral similarity. A suitable candidate segment for the substitution of the
lost content is proposed by an intuitive optimization scheme and smoothly
inserted into the gap, i.e. the lost or distorted signal region. Extensive
listening tests show that the proposed algorithm provides highly promising
results when applied to a variety of real-world music signals.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Perraudin_N/0/1/0/all/0/1&quot;&gt;Nathanael Perraudin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Holighaus_N/0/1/0/all/0/1&quot;&gt;Nicki Holighaus&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Majdak_P/0/1/0/all/0/1&quot;&gt;Piotr Majdak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Balazs_P/0/1/0/all/0/1&quot;&gt;Peter Balazs&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1704.06676">
<title>Modular Multi-Objective Deep Reinforcement Learning with Decision Values. (arXiv:1704.06676v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1704.06676</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work we present a method for using Deep Q-Networks (DQNs) in
multi-objective environments. Deep Q-Networks provide remarkable performance in
single objective problems learning from high-level visual state
representations. However, in many scenarios (e.g in robotics, games), the agent
needs to pursue multiple objectives simultaneously. We propose an architecture
in which separate DQNs are used to control the agent&apos;s behaviour with respect
to particular objectives. In this architecture we introduce decision values to
improve the scalarization of multiple DQNs into a single action. Our
architecture enables the decomposition of the agent&apos;s behaviour into
controllable and replaceable sub-behaviours learned by distinct modules.
Moreover, it allows to change the priorities of particular objectives
post-learning, while preserving the overall performance of the agent. To
evaluate our solution we used a game-like simulator in which an agent -
provided with high-level visual input - pursues multiple objectives in a 2D
world.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tajmajer_T/0/1/0/all/0/1&quot;&gt;Tomasz Tajmajer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1707.01891">
<title>Trust-PCL: An Off-Policy Trust Region Method for Continuous Control. (arXiv:1707.01891v3 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1707.01891</link>
<description rdf:parseType="Literal">&lt;p&gt;Trust region methods, such as TRPO, are often used to stabilize policy
optimization algorithms in reinforcement learning (RL). While current trust
region strategies are effective for continuous control, they typically require
a prohibitively large amount of on-policy interaction with the environment. To
address this problem, we propose an off-policy trust region method, Trust-PCL.
The algorithm is the result of observing that the optimal policy and state
values of a maximum reward objective with a relative-entropy regularizer
satisfy a set of multi-step pathwise consistencies along any path. Thus,
Trust-PCL is able to maintain optimization stability while exploiting
off-policy data to improve sample efficiency. When evaluated on a number of
continuous control tasks, Trust-PCL improves the solution quality and sample
efficiency of TRPO.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nachum_O/0/1/0/all/0/1&quot;&gt;Ofir Nachum&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Norouzi_M/0/1/0/all/0/1&quot;&gt;Mohammad Norouzi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_K/0/1/0/all/0/1&quot;&gt;Kelvin Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schuurmans_D/0/1/0/all/0/1&quot;&gt;Dale Schuurmans&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.07643">
<title>OptLayer - Practical Constrained Optimization for Deep Reinforcement Learning in the Real World. (arXiv:1709.07643v2 [cs.RO] UPDATED)</title>
<link>http://arxiv.org/abs/1709.07643</link>
<description rdf:parseType="Literal">&lt;p&gt;While deep reinforcement learning techniques have recently produced
considerable achievements on many decision-making problems, their use in
robotics has largely been limited to simulated worlds or restricted motions,
since unconstrained trial-and-error interactions in the real world can have
undesirable consequences for the robot or its environment. To overcome such
limitations, we propose a novel reinforcement learning architecture, OptLayer,
that takes as inputs possibly unsafe actions predicted by a neural network and
outputs the closest actions that satisfy chosen constraints. While learning
control policies often requires carefully crafted rewards and penalties while
exploring the range of possible actions, OptLayer ensures that only safe
actions are actually executed and unsafe predictions are penalized during
training. We demonstrate the effectiveness of our approach on robot reaching
tasks, both simulated and in the real world.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pham_T/0/1/0/all/0/1&quot;&gt;Tu-Hoa Pham&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Magistris_G/0/1/0/all/0/1&quot;&gt;Giovanni De Magistris&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tachibana_R/0/1/0/all/0/1&quot;&gt;Ryuki Tachibana&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08249">
<title>Solving Approximate Wasserstein GANs to Stationarity. (arXiv:1802.08249v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.08249</link>
<description rdf:parseType="Literal">&lt;p&gt;Generative Adversarial Networks (GANs) are one of the most practical
strategies to learn data distributions. A popular GAN formulation is based on
the use of Wasserstein distance as a metric between probability distributions.
Unfortunately, minimizing the Wasserstein distance between the data
distribution and the generative model distribution is a challenging problem as
its objective is non-convex, non-smooth, and even hard to compute. In this
work, we propose to use a smooth approximation of the Wasserstein GANs. We show
that this smooth approximation is close to the original objective. Moreover,
obtaining gradient information of this approximate formulation is
computationally effortless and hence one can easily apply first order
optimization methods to optimize this objective. Based on this observation, we
proposed a class of algorithms with guaranteed theoretical convergence to
stationarity. Unlike the original non-smooth objective, our proposed algorithm
only requires solving the discriminator to approximate optimality. We applied
our method to learning Gaussian mixtures on a grid and also to learning MNIST
digits. Our method allows the use of powerful cost functions based on latent
representations of the data, where this latent representation could also be
optimized adversarially.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sanjabi_M/0/1/0/all/0/1&quot;&gt;Maziar Sanjabi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ba_J/0/1/0/all/0/1&quot;&gt;Jimmy Ba&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Razaviyayn_M/0/1/0/all/0/1&quot;&gt;Meisam Razaviyayn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1&quot;&gt;Jason D. Lee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08318">
<title>Proportional Volume Sampling and Approximation Algorithms for A-Optimal Design. (arXiv:1802.08318v1 [cs.DS])</title>
<link>http://arxiv.org/abs/1802.08318</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the $A$-optimal design problem where we are given vectors
$v_1,\ldots,v_n\in\mathbb{R}^d$, an integer $k\geq d$, and the goal is to
select a set $S$ of $k$ vectors that minimizes the trace of $(\sum_{i\in
S}v_iv_i^\top)^{-1}$. Traditionally, the problem is an instance of optimal
design of experiments in statistics where each vector corresponds to a linear
measurement of an unknown vector and the goal is to pick $k$ of them that
minimize the average variance of the error in the maximum likelihood estimate
of the vector being measured. The problem also finds applications in sensor
placement in wireless networks, sparse least squares regression, feature
selection for $k$-means clustering, and matrix approximation. In this paper, we
introduce proportional volume sampling to obtain improved approximation
algorithms for $A$-optimal design.
&lt;/p&gt;
&lt;p&gt;Given a matrix, proportional volume sampling picks a set of columns $S$ of
size $k$ with probability proportional to $\mu(S)$ times $\det(\sum_{i\in
S}v_iv_i^\top)$ for some measure $\mu$. Our main result is to show the
approximability of the $A$-optimal design problem can be reduced to approximate
independence properties of the measure $\mu$. We appeal to hard-core
distributions as candidate distributions $\mu$ that allow us to obtain improved
approximation algorithms for the $A$-optimal design. Our results include a
$d$-approximation when $k=d$, an $(1+\epsilon)$-approximation when
$k=\Omega\left(\frac{d}{\epsilon}+\frac{1}{\epsilon^2}\log\frac{1}{\epsilon}\right)$
and $\frac{k}{k-d+1}$-approximation when repetitions of vectors are allowed in
the solution. We consider generalization of the problem for $k\leq d$ and
obtain a $k$-approximation. The last result implies a restricted invertibility
principle for the harmonic mean of singular values. We also show that the
problem is $\mathsf{NP}$-hard to approximate within a fixed constant when
$k=d$.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nikolov_A/0/1/0/all/0/1&quot;&gt;Aleksandar Nikolov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singh_M/0/1/0/all/0/1&quot;&gt;Mohit Singh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tantipongpipat_U/0/1/0/all/0/1&quot;&gt;Uthaipon Tao Tantipongpipat&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08323">
<title>Deep learning algorithm for data-driven simulation of noisy dynamical system. (arXiv:1802.08323v1 [physics.comp-ph])</title>
<link>http://arxiv.org/abs/1802.08323</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a deep learning model, DE-LSTM, for the simulation of a stochastic
process with underlying nonlinear dynamics. The deep learning model aims to
approximate the probability density function of a stochastic process via
numerical discretization and the underlying nonlinear dynamics is modeled by
the Long Short-Term Memory (LSTM) network. After the numerical discretization
by a softmax function, the function estimation problem is solved by a
multi-label classification problem. A penalized maximum log likelihood method
is proposed to impose smoothness in the predicted probability distribution. It
is shown that LSTM is a state space model, where the internal dynamics consists
of a system of relaxation processes. A sequential Monte Carlo method is
outlined to compute the time evolution of the probability distribution. The
behavior of DE-LSTM is investigated by using the Ornstein-Uhlenbeck process and
noisy observations of Mackey-Glass equation and forced Van der Pol oscillators.
While the probability distribution computed by the conventional maximum log
likelihood method makes a good prediction of the first and second moments, the
Kullback-Leibler divergence shows that the penalized maximum log likelihood
method results in a probability distribution closer to the ground truth. It is
shown that DE-LSTM makes a good prediction of the probability distribution
without assuming any distributional properties of the noise. For a
multiple-step forecast, it is found that the prediction uncertainty, denoted by
the 95% confidence interval, does not grow monotonically in time. For a chaotic
system, Mackey-Glass time series, the 95% confidence interval first grows, then
exhibits an oscillatory behavior, instead of growing indefinitely, while for
the forced Van der Pol oscillator, the prediction uncertainty does not grow in
time even for 3,000-step forecast.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Yeo_K/0/1/0/all/0/1&quot;&gt;Kyongmin Yeo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Melnyk_I/0/1/0/all/0/1&quot;&gt;Igor Melnyk&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08334">
<title>Learning Without Mixing: Towards A Sharp Analysis of Linear System Identification. (arXiv:1802.08334v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.08334</link>
<description rdf:parseType="Literal">&lt;p&gt;We prove that the ordinary least-squares (OLS) estimator attains nearly
minimax optimal performance for the identification of linear dynamical systems
from a single observed trajectory. Our upper bound relies on a generalization
of Mendelson&apos;s small-ball method to dependent data, eschewing the use of
standard mixing-time arguments. Our lower bounds reveal that these upper bounds
match up to logarithmic factors. In particular, we capture the correct
signal-to-noise behavior of the problem, showing that more unstable linear
systems are easier to estimate. This behavior is qualitatively different from
arguments which rely on mixing-time calculations that suggest that unstable
systems are more difficult to estimate. We generalize our technique to provide
bounds for a more general class of linear response time-series.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Simchowitz_M/0/1/0/all/0/1&quot;&gt;Max Simchowitz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mania_H/0/1/0/all/0/1&quot;&gt;Horia Mania&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tu_S/0/1/0/all/0/1&quot;&gt;Stephen Tu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jordan_M/0/1/0/all/0/1&quot;&gt;Michael I. Jordan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Recht_B/0/1/0/all/0/1&quot;&gt;Benjamin Recht&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08363">
<title>An efficient $k$-means-type algorithm for clustering datasets with incomplete records. (arXiv:1802.08363v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.08363</link>
<description rdf:parseType="Literal">&lt;p&gt;The $k$-means algorithm is the most popular nonparametric clustering method
in use, but cannot generally be applied to data sets with missing observations.
The usual practice with such data sets is to either impute the values under an
assumption of a missing-at-random mechanism or to ignore the incomplete
records, and then to use the desired clustering method. We develop an efficient
version of the $k$-means algorithm that allows for clustering cases where not
all the features have observations recorded. Our extension is called
$k_m$-means and reduces to the $k$-means algorithm when all records are
complete. We also provide strategies to initialize our algorithm and to
estimate the number of groups in the data set. Illustrations and simulations
demonstrate the efficacy of our approach in a variety of settings and patterns
of missing data. Our methods are also applied to the clustering of gamma-ray
bursts and to the analysis of activation images obtained from a functional
Magnetic Resonance Imaging experiment.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lithio_A/0/1/0/all/0/1&quot;&gt;Andrew Lithio&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Maitra_R/0/1/0/all/0/1&quot;&gt;Ranjan Maitra&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08372">
<title>Approximate Positively Correlated Distributions and Approximation Algorithms for D-optimal Design. (arXiv:1802.08372v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.08372</link>
<description rdf:parseType="Literal">&lt;p&gt;Experimental design is a classical problem in statistics and has also found
new applications in machine learning. In the experimental design problem, the
aim is to estimate an unknown vector x in m-dimensions from linear measurements
where a Gaussian noise is introduced in each measurement. The goal is to pick k
out of the given n experiments so as to make the most accurate estimate of the
unknown parameter x. Given a set S of chosen experiments, the most likelihood
estimate x&apos; can be obtained by a least squares computation. One of the robust
measures of error estimation is the D-optimality criterion which aims to
minimize the generalized variance of the estimator. This corresponds to
minimizing the volume of the standard confidence ellipsoid for the estimation
error x-x&apos;. The problem gives rise to two natural variants depending on whether
repetitions are allowed or not. The latter variant, while being more general,
has also found applications in the geographical location of sensors. In this
work, we first show that a 1/e-approximation for the D-optimal design problem
with and without repetitions giving us the first constant factor approximation
for the problem. We also consider the case when the number of experiments
chosen is much larger than the dimension of the measurements and provide an
asymptotically optimal approximation algorithm.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Singh_M/0/1/0/all/0/1&quot;&gt;Mohit Singh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Xie_W/0/1/0/all/0/1&quot;&gt;Weijun Xie&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08380">
<title>On Abruptly-Changing and Slowly-Varying Multiarmed Bandit Problems. (arXiv:1802.08380v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.08380</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the non-stationary stochastic multiarmed bandit (MAB) problem and
propose two generic algorithms, namely, the limited memory deterministic
sequencing of exploration and exploitation (LM-DSEE) and the Sliding-Window
Upper Confidence Bound# (SW-UCB#). We rigorously analyze these algorithms in
abruptly-changing and slowly-varying environments and characterize their
performance. We show that the expected cumulative regret for these algorithms
under either of the environments is upper bounded by sublinear functions of
time, i.e., the time average of the regret asymptotically converges to zero. We
complement our analytic results with numerical illustrations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wei_L/0/1/0/all/0/1&quot;&gt;Lai Wei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Srivastava_V/0/1/0/all/0/1&quot;&gt;Vaibhav Srivastava&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08397">
<title>Harnessing Structures in Big Data via Guaranteed Low-Rank Matrix Estimation. (arXiv:1802.08397v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.08397</link>
<description rdf:parseType="Literal">&lt;p&gt;Low-rank modeling plays a pivotal role in signal processing and machine
learning, with applications ranging from collaborative filtering, video
surveillance, medical imaging, to dimensionality reduction and adaptive
filtering. Many modern high-dimensional data and interactions thereof can be
modeled as lying approximately in a low-dimensional subspace or manifold,
possibly with additional structures, and its proper exploitations lead to
significant reduction of costs in sensing, computation and storage. In recent
years, there is a plethora of progress in understanding how to exploit low-rank
structures using computationally efficient procedures in a provable manner,
including both convex and nonconvex approaches. On one side, convex relaxations
such as nuclear norm minimization often lead to statistically optimal
procedures for estimating low-rank matrices, where first-order methods are
developed to address the computational challenges; on the other side, there is
emerging evidence that properly designed nonconvex procedures, such as
projected gradient descent, often provide globally optimal solutions with a
much lower computational cost in many problems. This survey article will
provide a unified overview of these recent advances on low-rank matrix
estimation from incomplete measurements. Attention is paid to rigorous
characterization of the performance of these algorithms, and to problems where
the low-rank matrix have additional structural properties that require new
algorithmic designs and theoretical analysis.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yudong Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chi_Y/0/1/0/all/0/1&quot;&gt;Yuejie Chi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08404">
<title>Kernel Recursive ABC: Point Estimation with Intractable Likelihood. (arXiv:1802.08404v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.08404</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a novel approach to parameter estimation for simulator-based
statistical models with intractable likelihoods. The proposed method is
recursive application of kernel ABC and kernel herding to the same observed
data. We provide a theoretical explanation regarding why this approach works,
showing (for the population setting) that the point estimate obtained with this
method converges to the true parameter as recursion proceeds, under a certain
assumption. We conduct a variety of numerical experiments, including parameter
estimation for a real-world pedestrian flow simulator, and show that our method
outperforms existing approaches in most cases.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kajihara_T/0/1/0/all/0/1&quot;&gt;Takafumi Kajihara&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yamazaki_K/0/1/0/all/0/1&quot;&gt;Keisuke Yamazaki&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kanagawa_M/0/1/0/all/0/1&quot;&gt;Motonobu Kanagawa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Fukumizu_K/0/1/0/all/0/1&quot;&gt;Kenji Fukumizu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08406">
<title>Solving Linear Inverse Problems Using GAN Priors: An Algorithm with Provable Guarantees. (arXiv:1802.08406v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.08406</link>
<description rdf:parseType="Literal">&lt;p&gt;In recent works, both sparsity-based methods as well as learning-based
methods have proven to be successful in solving several challenging linear
inverse problems. However, sparsity priors for natural signals and images
suffer from poor discriminative capability, while learning-based methods seldom
provide concrete theoretical guarantees. In this work, we advocate the idea of
replacing hand-crafted priors, such as sparsity, with a Generative Adversarial
Network (GAN) to solve linear inverse problems such as compressive sensing. In
particular, we propose a projected gradient descent (PGD) algorithm for
effective use of GAN priors for linear inverse problems, and also provide
theoretical guarantees on the rate of convergence of this algorithm. Moreover,
we show empirically that our algorithm demonstrates superior performance over
an existing method of leveraging GANs for compressive sensing.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Shah_V/0/1/0/all/0/1&quot;&gt;Viraj Shah&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hegde_C/0/1/0/all/0/1&quot;&gt;Chinmay Hegde&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08407">
<title>Exponentially Consistent Kernel Two-Sample Tests. (arXiv:1802.08407v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.08407</link>
<description rdf:parseType="Literal">&lt;p&gt;Given two sets of independent samples from unknown distributions $P$ and $Q$,
a two-sample test decides whether to reject the null hypothesis that $P=Q$.
Recent attention has focused on kernel two-sample tests as the test statistics
are easy to compute, converge fast, and have low bias with their finite sample
estimates. However, there still lacks an exact characterization on the
asymptotic performance of such tests, and in particular, the rate at which the
type-II error probability decays to zero in the large sample limit. In this
work, we show that a class of kernel two-sample tests are exponentially
consistent on Polish, locally compact Hausdorff space, e.g., $\mathbb R^d$. The
obtained exponential decay rate is further shown to be optimal among all
two-sample tests meeting the given level constraint, and is independent of
particular kernels provided that they are bounded continuous and
characteristic. Key to our approach are an extended version of Sanov&apos;s theorem
and a recent result that identifies the Maximum Mean Discrepancy as a metric of
weak convergence of probability measures.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhu_S/0/1/0/all/0/1&quot;&gt;Shengyu Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chen_B/0/1/0/all/0/1&quot;&gt;Biao Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chen_Z/0/1/0/all/0/1&quot;&gt;Zhitang Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08429">
<title>Exact Sampling of Determinantal Point Processes without Eigendecomposition. (arXiv:1802.08429v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.08429</link>
<description rdf:parseType="Literal">&lt;p&gt;Determinantal point processes (DPPs) enable the modelling of repulsion: they
provide diverse sets of points. This repulsion is encoded in a kernel K that we
can see as a matrix storing the similarity between points. The usual algorithm
to sample DPPs is exact but it uses the spectral decomposition of K, a
computation that becomes costly when dealing with a high number of points.
Here, we present an alternative exact algorithm that avoids the eigenvalues and
the eigenvectors computation and that is, for some applications, faster than
the original algorithm.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Launay_C/0/1/0/all/0/1&quot;&gt;Claire Launay&lt;/a&gt; (MAP5), &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Galerne_B/0/1/0/all/0/1&quot;&gt;Bruno Galerne&lt;/a&gt; (MAP5), &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Desolneux_A/0/1/0/all/0/1&quot;&gt;Agn&amp;#xe8;s Desolneux&lt;/a&gt; (CMLA, CNRS)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08471">
<title>Optimized Algorithms to Sample Determinantal Point Processes. (arXiv:1802.08471v1 [stat.CO])</title>
<link>http://arxiv.org/abs/1802.08471</link>
<description rdf:parseType="Literal">&lt;p&gt;In this technical report, we discuss several sampling algorithms for
Determinantal Point Processes (DPP). DPPs have recently gained a broad interest
in the machine learning and statistics literature as random point processes
with negative correlation, i.e., ones that can generate a &quot;diverse&quot; sample from
a set of items. They are parametrized by a matrix $\mathbf{L}$, called
$L$-ensemble, that encodes the correlations between items. The standard
sampling algorithm is separated in three phases: 1/~eigendecomposition of
$\mathbf{L}$, 2/~an eigenvector sampling phase where $\mathbf{L}$&apos;s
eigenvectors are sampled independently via a Bernoulli variable parametrized by
their associated eigenvalue, 3/~a Gram-Schmidt-type orthogonalisation procedure
of the sampled eigenvectors.
&lt;/p&gt;
&lt;p&gt;In a naive implementation, the computational cost of the third step is on
average $\mathcal{O}(N\mu^3)$ where $\mu$ is the average number of samples of
the DPP. We give an algorithm which runs in $\mathcal{O}(N\mu^2)$ and is
extremely simple to implement. If memory is a constraint, we also describe a
dual variant with reduced memory costs. In addition, we discuss implementation
details often missing in the literature.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tremblay_N/0/1/0/all/0/1&quot;&gt;Nicolas Tremblay&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Barthelme_S/0/1/0/all/0/1&quot;&gt;Simon Barthelme&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Amblard_P/0/1/0/all/0/1&quot;&gt;Pierre-Olivier Amblard&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08539">
<title>Computation of optimal transport and related hedging problems via penalization and neural networks. (arXiv:1802.08539v1 [math.OC])</title>
<link>http://arxiv.org/abs/1802.08539</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents a widely applicable approach to solving (multi-marginal,
martingale) optimal transport and related problems via neural networks. The
core idea is to penalize the optimization problem in its dual formulation and
reduce it to a finite dimensional one which corresponds to optimizing a neural
network with smooth objective function. We present numerical examples from
optimal transport, martingale optimal transport, portfolio optimization under
uncertainty and generative adversarial networks that showcase the generality
and effectiveness of the approach.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Eckstein_S/0/1/0/all/0/1&quot;&gt;Stephan Eckstein&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Kupper_M/0/1/0/all/0/1&quot;&gt;Michael Kupper&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08598">
<title>Learning Weighted Representations for Generalization Across Designs. (arXiv:1802.08598v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.08598</link>
<description rdf:parseType="Literal">&lt;p&gt;Predictive models that generalize well under distributional shift are often
desirable and sometimes crucial to building robust and reliable machine
learning applications. We focus on distributional shift that arises in causal
inference from observational data and in unsupervised domain adaptation. We
pose both of these problems as prediction under a shift in design. Popular
methods for overcoming distributional shift make unrealistic assumptions such
as having a well-specified model or knowing the policy that gave rise to the
observed data. Other methods are hindered by their need for a pre-specified
metric for comparing observations, or by poor asymptotic properties. We devise
a bound on the generalization error under design shift, incorporating both
representation learning and sample re-weighting. Based on the bound, we propose
an algorithmic framework that does not require any of the above assumptions and
which is asymptotically consistent. We empirically study the new framework
using two synthetic datasets, and demonstrate its effectiveness compared to
previous methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Johansson_F/0/1/0/all/0/1&quot;&gt;Fredrik D. Johansson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kallus_N/0/1/0/all/0/1&quot;&gt;Nathan Kallus&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Shalit_U/0/1/0/all/0/1&quot;&gt;Uri Shalit&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sontag_D/0/1/0/all/0/1&quot;&gt;David Sontag&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08626">
<title>Empirical Risk Minimization under Fairness Constraints. (arXiv:1802.08626v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.08626</link>
<description rdf:parseType="Literal">&lt;p&gt;We address the problem of algorithmic fairness: ensuring that sensitive
variables do not unfairly influence the outcome of a classifier. We present an
approach based on empirical risk minimization, which incorporates a fairness
constraint into the learning problem. It encourages the conditional risk of the
learned classifier to be approximately constant with respect to the sensitive
variable. We derive both risk and fairness bounds that support the statistical
consistency of our approach. We specify our approach to kernel methods and
observe that the fairness requirement implies an orthogonality constraint which
can be easily added to these methods. We further observe that for linear models
the constraint translates into a simple data preprocessing step. Experiments
indicate that the method is empirically effective and performs favorably
against state-of-the-art approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Donini_M/0/1/0/all/0/1&quot;&gt;Michele Donini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Oneto_L/0/1/0/all/0/1&quot;&gt;Luca Oneto&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ben_David_S/0/1/0/all/0/1&quot;&gt;Shai Ben-David&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Shawe_Taylor_J/0/1/0/all/0/1&quot;&gt;John Shawe-Taylor&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pontil_M/0/1/0/all/0/1&quot;&gt;Massimiliano Pontil&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08665">
<title>Learning Latent Permutations with Gumbel-Sinkhorn Networks. (arXiv:1802.08665v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.08665</link>
<description rdf:parseType="Literal">&lt;p&gt;Permutations and matchings are core building blocks in a variety of latent
variable models, as they allow us to align, canonicalize, and sort data.
Learning in such models is difficult, however, because exact marginalization
over these combinatorial objects is intractable. In response, this paper
introduces a collection of new methods for end-to-end learning in such models
that approximate discrete maximum-weight matching using the continuous Sinkhorn
operator. Sinkhorn iteration is attractive because it functions as a simple,
easy-to-implement analog of the softmax operator. With this, we can define the
Gumbel-Sinkhorn method, an extension of the Gumbel-Softmax method (Jang et al.
2016, Maddison2016 et al. 2016) to distributions over latent matchings. We
demonstrate the effectiveness of our method by outperforming competitive
baselines on a range of qualitatively different tasks: sorting numbers, solving
jigsaw puzzles, and identifying neural signals in worms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mena_G/0/1/0/all/0/1&quot;&gt;Gonzalo Mena&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Belanger_D/0/1/0/all/0/1&quot;&gt;David Belanger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Linderman_S/0/1/0/all/0/1&quot;&gt;Scott Linderman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Snoek_J/0/1/0/all/0/1&quot;&gt;Jasper Snoek&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08667">
<title>Double/De-Biased Machine Learning Using Regularized Riesz Representers. (arXiv:1802.08667v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.08667</link>
<description rdf:parseType="Literal">&lt;p&gt;We provide adaptive inference methods for linear functionals of sparse linear
approximations to the conditional expectation function. Examples of such
functionals include average derivatives, policy effects, average treatment
effects, and many others. The construction relies on building Neyman-orthogonal
equations that are approximately invariant to perturbations of the nuisance
parameters, including the Riesz representer for the linear functionals. We use
L1-regularized methods to learn approximations to the regression function and
the Riesz representer, and construct the estimator for the linear functionals
as the solution to the orthogonal estimating equations. We establish that under
weak assumptions the estimator concentrates in a 1/root n neighborhood of the
target with deviations controlled by the normal laws, and the estimator attains
the semi-parametric efficiency bound in many cases. In particular, either the
approximation to the regression function or the approximation to the Rietz
representer can be &quot;dense&quot; as long as one of them is sufficiently &quot;sparse&quot;. Our
main results are non-asymptotic and imply asymptotic uniform validity over
large classes of models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chernozhukov_V/0/1/0/all/0/1&quot;&gt;Victor Chernozhukov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Newey_W/0/1/0/all/0/1&quot;&gt;Whitney Newey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Robins_J/0/1/0/all/0/1&quot;&gt;James Robins&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08680">
<title>Advantages of versatile neural-network decoding for topological codes. (arXiv:1802.08680v1 [quant-ph])</title>
<link>http://arxiv.org/abs/1802.08680</link>
<description rdf:parseType="Literal">&lt;p&gt;Finding optimal correction of errors in generic stabilizer codes is a
computationally hard problem, even for simple noise models. While this task can
be simplified for codes with some structure, such as topological stabilizer
codes, developing good and efficient decoders still remains a challenge. In our
work, we systematically study a very versatile class of decoders based on
feedforward neural networks. To demonstrate adaptability, we apply neural
decoders to the triangular color and toric codes under various noise models
with realistic features, such as spatially-correlated errors. We report that
neural decoders provide significant improvement over leading efficient decoders
in terms of the error-correction threshold. Using neural networks simplifies
the process of designing well-performing decoders, and does not require prior
knowledge of the underlying noise model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Maskara_N/0/1/0/all/0/1&quot;&gt;Nishad Maskara&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Kubica_A/0/1/0/all/0/1&quot;&gt;Aleksander Kubica&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/quant-ph/1/au:+Jochym_OConnor_T/0/1/0/all/0/1&quot;&gt;Tomas Jochym-O&amp;#x27;Connor&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1308.1196">
<title>The Group Lasso for Design of Experiments. (arXiv:1308.1196v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1308.1196</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce an application of the group lasso to design of experiments. Note
that we are NOT trying to explain experimental design for the group lasso.
Conversely, we explain how we can use the idea of the group lasso in
experimental design, showing that the problem of constructing an optimal design
matrix can be transformed into a problem of the group lasso. In some numerical
examples, we show that we can obtain the orthogonal arrays as the solutions of
the group lasso problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tanaka_K/0/1/0/all/0/1&quot;&gt;Kentaro Tanaka&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Miyakawa_M/0/1/0/all/0/1&quot;&gt;Masami Miyakawa&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1705.07107">
<title>Gradient Estimators for Implicit Models. (arXiv:1705.07107v4 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1705.07107</link>
<description rdf:parseType="Literal">&lt;p&gt;Implicit models, which allow for the generation of samples but not for
point-wise evaluation of probabilities, are omnipresent in real-world problems
tackled by machine learning and a hot topic of current research. Some examples
include data simulators that are widely used in engineering and scientific
research, generative adversarial networks (GANs) for image synthesis, and
hot-off-the-press approximate inference techniques relying on implicit
distributions. The majority of existing approaches to learning implicit models
rely on approximating the intractable distribution or optimisation objective
for gradient-based optimisation, which is liable to produce inaccurate updates
and thus poor models. This paper alleviates the need for such approximations by
proposing the Stein gradient estimator, which directly estimates the score
function of the implicitly defined distribution. The efficacy of the proposed
estimator is empirically demonstrated by examples that include meta-learning
for approximate inference, and entropy regularised GANs that provide improved
sample diversity.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yingzhen Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Turner_R/0/1/0/all/0/1&quot;&gt;Richard E. Turner&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1706.00754">
<title>Learning causal Bayes networks using interventional path queries in polynomial time and sample complexity. (arXiv:1706.00754v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1706.00754</link>
<description rdf:parseType="Literal">&lt;p&gt;Causal discovery from empirical data is a fundamental problem in many
scientific domains. Observational data allows for identifiability only up to
Markov equivalence class. In this paper we first propose a polynomial time
algorithm for learning the exact correctly-oriented structure of the transitive
reduction of any causal Bayesian networks with high probability, by using
interventional path queries. Each path query takes as input an origin node and
a target node, and answers whether there is a directed path from the origin to
the target. This is done by intervening the origin node and observing samples
from the target node. We theoretically show the logarithmic sample complexity
for the size of interventional data per path query, for continuous and discrete
networks. We further extend our work to learn the transitive edges using
logarithmic sample complexity (albeit in time exponential in the maximum number
of parents for discrete networks). This allows us to learn the full network. We
also provide an analysis of imperfect interventions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bello_K/0/1/0/all/0/1&quot;&gt;Kevin Bello&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Honorio_J/0/1/0/all/0/1&quot;&gt;Jean Honorio&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.06382">
<title>Convergence diagnostics for stochastic gradient descent with constant step size. (arXiv:1710.06382v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1710.06382</link>
<description rdf:parseType="Literal">&lt;p&gt;Many iterative procedures in stochastic optimization exhibit a transient
phase followed by a stationary phase. During the transient phase the procedure
converges towards a region of interest, and during the stationary phase the
procedure oscillates in that region, commonly around a single point. In this
paper, we develop a statistical diagnostic test to detect such phase transition
in the context of stochastic gradient descent with constant learning rate. We
present theory and experiments suggesting that the region where the proposed
diagnostic is activated coincides with the convergence region. For a class of
loss functions, we derive a closed-form solution describing such region.
Finally, we suggest an application to speed up convergence of stochastic
gradient descent by halving the learning rate each time stationarity is
detected. This leads to a new variant of stochastic gradient descent, which in
many settings is comparable to state-of-art.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chee_J/0/1/0/all/0/1&quot;&gt;Jerry Chee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Toulis_P/0/1/0/all/0/1&quot;&gt;Panos Toulis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.10568">
<title>Stochastic Training of Graph Convolutional Networks with Variance Reduction. (arXiv:1710.10568v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1710.10568</link>
<description rdf:parseType="Literal">&lt;p&gt;Graph convolutional networks (GCNs) are powerful deep neural networks for
graph-structured data. However, GCN computes the representation of a node
recursively from its neighbors, making the receptive field size grow
exponentially with the number of layers. Previous attempts on reducing the
receptive field size by subsampling neighbors do not have a convergence
guarantee, and their receptive field size per node is still in the order of
hundreds. In this paper, we develop control variate based algorithms which
allow sampling an arbitrarily small neighbor size. Furthermore, we prove new
theoretical guarantee for our algorithms to converge to a local optimum of GCN.
Empirical results show that our algorithms enjoy a similar convergence with the
exact algorithm using only two neighbors per node. The runtime of our
algorithms on a large Reddit dataset is only one seventh of previous neighbor
sampling algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chen_J/0/1/0/all/0/1&quot;&gt;Jianfei Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhu_J/0/1/0/all/0/1&quot;&gt;Jun Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Song_L/0/1/0/all/0/1&quot;&gt;Le Song&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.11198">
<title>Action-depedent Control Variates for Policy Optimization via Stein&apos;s Identity. (arXiv:1710.11198v4 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1710.11198</link>
<description rdf:parseType="Literal">&lt;p&gt;Policy gradient methods have achieved remarkable successes in solving
challenging reinforcement learning problems. However, it still often suffers
from the large variance issue on policy gradient estimation, which leads to
poor sample efficiency during training. In this work, we propose a control
variate method to effectively reduce variance for policy gradient methods.
Motivated by the Stein&apos;s identity, our method extends the previous control
variate methods used in REINFORCE and advantage actor-critic by introducing
more general action-dependent baseline functions. Empirical studies show that
our method significantly improves the sample efficiency of the state-of-the-art
policy gradient approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Liu_H/0/1/0/all/0/1&quot;&gt;Hao Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Feng_Y/0/1/0/all/0/1&quot;&gt;Yihao Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mao_Y/0/1/0/all/0/1&quot;&gt;Yi Mao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhou_D/0/1/0/all/0/1&quot;&gt;Dengyong Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Peng_J/0/1/0/all/0/1&quot;&gt;Jian Peng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Liu_Q/0/1/0/all/0/1&quot;&gt;Qiang Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.01769">
<title>State-of-the-art Speech Recognition With Sequence-to-Sequence Models. (arXiv:1712.01769v6 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1712.01769</link>
<description rdf:parseType="Literal">&lt;p&gt;Attention-based encoder-decoder architectures such as Listen, Attend, and
Spell (LAS), subsume the acoustic, pronunciation and language model components
of a traditional automatic speech recognition (ASR) system into a single neural
network. In previous work, we have shown that such architectures are comparable
to state-of-theart ASR systems on dictation tasks, but it was not clear if such
architectures would be practical for more challenging tasks such as voice
search. In this work, we explore a variety of structural and optimization
improvements to our LAS model which significantly improve performance. On the
structural side, we show that word piece models can be used instead of
graphemes. We also introduce a multi-head attention architecture, which offers
improvements over the commonly-used single-head attention. On the optimization
side, we explore synchronous training, scheduled sampling, label smoothing, and
minimum word error rate optimization, which are all shown to improve accuracy.
We present results with a unidirectional LSTM encoder for streaming
recognition. On a 12, 500 hour voice search task, we find that the proposed
changes improve the WER from 9.2% to 5.6%, while the best conventional system
achieves 6.7%; on a dictation task our model achieves a WER of 4.1% compared to
5% for the conventional system.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chiu_C/0/1/0/all/0/1&quot;&gt;Chung-Cheng Chiu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sainath_T/0/1/0/all/0/1&quot;&gt;Tara N. Sainath&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1&quot;&gt;Yonghui Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Prabhavalkar_R/0/1/0/all/0/1&quot;&gt;Rohit Prabhavalkar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_P/0/1/0/all/0/1&quot;&gt;Patrick Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1&quot;&gt;Zhifeng Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kannan_A/0/1/0/all/0/1&quot;&gt;Anjuli Kannan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Weiss_R/0/1/0/all/0/1&quot;&gt;Ron J. Weiss&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rao_K/0/1/0/all/0/1&quot;&gt;Kanishka Rao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gonina_E/0/1/0/all/0/1&quot;&gt;Ekaterina Gonina&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jaitly_N/0/1/0/all/0/1&quot;&gt;Navdeep Jaitly&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1&quot;&gt;Bo Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chorowski_J/0/1/0/all/0/1&quot;&gt;Jan Chorowski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bacchiani_M/0/1/0/all/0/1&quot;&gt;Michiel Bacchiani&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.04802">
<title>Generic Machine Learning Inference on Heterogenous Treatment Effects in Randomized Experiments. (arXiv:1712.04802v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1712.04802</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose strategies to estimate and make inference on key features of
heterogeneous effects in randomized experiments. These key features include
best linear predictors of the effects using machine learning proxies, average
effects sorted by impact groups, and average characteristics of most and least
impacted units. The approach is valid in high dimensional settings, where the
effects are proxied by machine learning methods. We post-process these proxies
into the estimates of the key features. Our approach is generic, it can be used
in conjunction with penalized methods, deep and shallow neural networks,
canonical and new random forests, boosted trees, and ensemble methods. Our
approach is agnostic and does not make unrealistic or hard-to-check
assumptions; we don&apos;t require conditions for consistency of the ML methods.
Estimation and inference relies on repeated data splitting to avoid overfitting
and achieve validity. For inference, we take medians of p-values and medians of
confidence intervals, resulting from many different data splits, and then
adjust their nominal level to guarantee uniform validity. This variational
inference method is shown to be uniformly valid and quantifies the uncertainty
coming from both parameter estimation and data splitting. The inference method
could be of substantial independent interest in many machine learning
applications. An empirical application to the impact of micro-credit on
economic development illustrates the use of the approach in randomized
experiments. An additional application to the impact of the gender
discrimination on wages illustrates the potential use of the approach in
observational studies, where machine learning methods can be used to condition
flexibly on very high-dimensional controls.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chernozhukov_V/0/1/0/all/0/1&quot;&gt;Victor Chernozhukov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Demirer_M/0/1/0/all/0/1&quot;&gt;Mert Demirer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Duflo_E/0/1/0/all/0/1&quot;&gt;Esther Duflo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Fernandez_Val_I/0/1/0/all/0/1&quot;&gt;Ivan Fernandez-Val&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.05382">
<title>Monotonic Chunkwise Attention. (arXiv:1712.05382v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1712.05382</link>
<description rdf:parseType="Literal">&lt;p&gt;Sequence-to-sequence models with soft attention have been successfully
applied to a wide variety of problems, but their decoding process incurs a
quadratic time and space cost and is inapplicable to real-time sequence
transduction. To address these issues, we propose Monotonic Chunkwise Attention
(MoChA), which adaptively splits the input sequence into small chunks over
which soft attention is computed. We show that models utilizing MoChA can be
trained efficiently with standard backpropagation while allowing online and
linear-time decoding at test time. When applied to online speech recognition,
we obtain state-of-the-art results and match the performance of a model using
an offline soft attention mechanism. In document summarization experiments
where we do not expect monotonic alignments, we show significantly improved
performance compared to a baseline monotonic attention-based model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chiu_C/0/1/0/all/0/1&quot;&gt;Chung-Cheng Chiu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Raffel_C/0/1/0/all/0/1&quot;&gt;Colin Raffel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.08104">
<title>Truncated Variational Sampling for &quot;Black Box&quot; Optimization of Generative Models. (arXiv:1712.08104v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1712.08104</link>
<description rdf:parseType="Literal">&lt;p&gt;We investigate the optimization of two probabilistic generative models with
binary latent variables using a novel variational EM approach. The approach
distinguishes itself from previous variational approaches by using latent
states as variational parameters. Here we use efficient and general purpose
sampling procedures to vary the latent states, and investigate the &quot;black box&quot;
applicability of the resulting optimization procedure. For general purpose
applicability, samples are drawn from approximate marginal distributions of the
considered generative model as well as from the model&apos;s prior distribution. As
such, variational sampling is defined in a generic form, and is directly
executable for a given model. As a proof of concept, we then apply the novel
procedure (A) to Binary Sparse Coding (a model with continuous observables),
and (B) to basic Sigmoid Belief Networks (which are models with binary
observables). Numerical experiments verify that the investigated approach
efficiently as well as effectively increases a variational free energy
objective without requiring any additional analytical steps.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lucke_J/0/1/0/all/0/1&quot;&gt;J&amp;#xf6;rg L&amp;#xfc;cke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Dai_Z/0/1/0/all/0/1&quot;&gt;Zhenwen Dai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Exarchakis_G/0/1/0/all/0/1&quot;&gt;Georgios Exarchakis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.07648">
<title>Scalable and Robust Sparse Subspace Clustering Using Randomized Clustering and Multilayer Graphs. (arXiv:1802.07648v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1802.07648</link>
<description rdf:parseType="Literal">&lt;p&gt;Sparse subspace clustering (SSC) is one of the current state-of-the-art
methods for partitioning data points into the union of subspaces, with strong
theoretical guarantees. However, it is not practical for large data sets as it
requires solving a LASSO problem for each data point, where the number of
variables in each LASSO problem is the number of data points. To improve the
scalability of SSC, we propose to select a few sets of anchor points using a
randomized hierarchical clustering method, and, for each set of anchor points,
solve the LASSO problems for each data point allowing only anchor points to
have a non-zero weight (this reduces drastically the number of variables). This
generates a multilayer graph where each layer corresponds to a different set of
anchor points. Using the Grassmann manifold of orthogonal matrices, the shared
connectivity among the layers is summarized within a single subspace. Finally,
we use $k$-means clustering within that subspace to cluster the data points,
similarly as done by spectral clustering in SSC. We show on both synthetic and
real-world data sets that the proposed method not only allows SSC to scale to
large-scale data sets, but that it is also much more robust as it performs
significantly better on noisy data and on data with close susbspaces and
outliers, while it is not prone to oversegmentation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abdolali_M/0/1/0/all/0/1&quot;&gt;Maryam Abdolali&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gillis_N/0/1/0/all/0/1&quot;&gt;Nicolas Gillis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rahmati_M/0/1/0/all/0/1&quot;&gt;Mohammad Rahmati&lt;/a&gt;</dc:creator>
</item></rdf:RDF>