<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Boring papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Bad Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-01-11T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1602.08313"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.02148"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.03612"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.03825"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1602.06347"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1703.01671"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.05207"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.01843"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.03137"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.03533"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.03558"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.03714"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.03765"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.03773"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.03815"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.03816"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.03851"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1602.07800"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1608.08306"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1705.07057"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1705.09952"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.00885"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1706.01498"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.03265"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1602.08313">
<title>Enhancing Genetic Algorithms using Multi Mutations. (arXiv:1602.08313v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1602.08313</link>
<description rdf:parseType="Literal">&lt;p&gt;Mutation is one of the most important stages of the genetic algorithm because
of its impact on the exploration of global optima, and to overcome premature
convergence. There are many types of mutation, and the problem lies in
selection of the appropriate type, where the decision becomes more difficult
and needs more trial and error. This paper investigates the use of more than
one mutation operator to enhance the performance of genetic algorithms. Novel
mutation operators are proposed, in addition to two selection strategies for
the mutation operators, one of which is based on selecting the best mutation
operator and the other randomly selects any operator. Several experiments on
some Travelling Salesman Problems (TSP) were conducted to evaluate the proposed
methods, and these were compared to the well-known exchange mutation and
rearrangement mutation. The results show the importance of some of the proposed
methods, in addition to the significant enhancement of the genetic algorithm&apos;s
performance, particularly when using more than one mutation operator.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hassanat_A/0/1/0/all/0/1&quot;&gt;Ahmad B. A. Hassanat&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alkafaween_E/0/1/0/all/0/1&quot;&gt;Esra&amp;#x27;a Alkafaween&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Al_Nawaiseh_N/0/1/0/all/0/1&quot;&gt;Nedal A. Al-Nawaiseh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abbadi_M/0/1/0/all/0/1&quot;&gt;Mohammad A. Abbadi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alkasassbeh_M/0/1/0/all/0/1&quot;&gt;Mouhammd Alkasassbeh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alhasanat_M/0/1/0/all/0/1&quot;&gt;Mahmoud B. Alhasanat&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.02148">
<title>Australia&apos;s long-term electricity demand forecasting using deep neural networks. (arXiv:1801.02148v2 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1801.02148</link>
<description rdf:parseType="Literal">&lt;p&gt;Accurate prediction of long-term electricity demand has a significant role in
demand side management and electricity network planning and operation. Demand
over-estimation results in over-investment in network assets, driving up the
electricity prices, while demand under-estimation may lead to under-investment
resulting in unreliable and insecure electricity. In this manuscript, we apply
deep neural networks to predict Australia&apos;s long-term electricity demand. A
stacked autoencoder is used in combination with multilayer perceptrons or
cascade-forward multilayer perceptrons to predict the nation-wide electricity
consumption rates for 1-24 months ahead of time. The experimental results show
that the deep structures have better performance than classical neural
networks, especially for 12-month to 24-month prediction horizon.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hamedmoghadam_H/0/1/0/all/0/1&quot;&gt;Homayoun Hamedmoghadam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Joorabloo_N/0/1/0/all/0/1&quot;&gt;Nima Joorabloo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jalili_M/0/1/0/all/0/1&quot;&gt;Mahdi Jalili&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.03612">
<title>Using probabilistic programs as proposals. (arXiv:1801.03612v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1801.03612</link>
<description rdf:parseType="Literal">&lt;p&gt;Monte Carlo inference has asymptotic guarantees, but can be slow when using
generic proposals. Handcrafted proposals that rely on user knowledge about the
posterior distribution can be efficient, but are difficult to derive and
implement. This paper proposes to let users express their posterior knowledge
in the form of \emph{proposal programs}, which are samplers written in
probabilistic programming languages. One strategy for writing good proposal
programs is to combine domain-specific heuristic algorithms with neural network
models. The heuristics identify high probability regions, and the neural
networks model the posterior uncertainty around the outputs of the algorithm.
Proposal programs can be used as proposal distributions in importance sampling
and Metropolis-Hastings samplers without sacrificing asymptotic consistency,
and can be optimized offline using inference compilation. Support for
optimizing and using proposal programs is easily implemented in a
sampling-based probabilistic programming runtime. The paper illustrates the
proposed technique with a proposal program that combines RANSAC and neural
networks to accelerate inference in a Bayesian linear regression with outliers
model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cusumano_Towner_M/0/1/0/all/0/1&quot;&gt;Marco F. Cusumano-Towner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mansinghka_V/0/1/0/all/0/1&quot;&gt;Vikash K. Mansinghka&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.03825">
<title>EARL: Joint Entity and Relation Linking for Question Answering over Knowledge Graphs. (arXiv:1801.03825v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1801.03825</link>
<description rdf:parseType="Literal">&lt;p&gt;In order to answer natural language questions over knowledge graphs, most
processing pipelines involve entity and relation linking. Traditionally, entity
linking and relation linking has been performed either as dependent sequential
tasks or independent parallel tasks. In this paper, we propose a framework,
calledEARL, which performs entity linking and relation linking as a joint
single task. EARL is modeled on an optimised variation of GeneralisedTravelling
Salesperson Problem. The system determines the best semantic connection between
all keywords of the question by referring to the knowledge graph. This is
achieved by exploiting the connection density between entity candidates and
relation candidates. We have empirically evaluated the framework on a dataset
with 3000 complex questions. Our system surpasses state-of-the-art scores for
entity linking task by reporting an accuracy of 0.67against 0.40 from the next
best entity linker
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dubey_M/0/1/0/all/0/1&quot;&gt;Mohnish Dubey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Banerjee_D/0/1/0/all/0/1&quot;&gt;Debayan Banerjee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chaudhuri_D/0/1/0/all/0/1&quot;&gt;Debanjan Chaudhuri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lehmann_J/0/1/0/all/0/1&quot;&gt;Jens Lehmann&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1602.06347">
<title>Distributed Constraint Optimization Problems and Applications: A Survey. (arXiv:1602.06347v4 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1602.06347</link>
<description rdf:parseType="Literal">&lt;p&gt;The field of Multi-Agent System (MAS) is an active area of research within
Artificial Intelligence, with an increasingly important impact in industrial
and other real-world applications. Within a MAS, autonomous agents interact to
pursue personal interests and/or to achieve common objectives. Distributed
Constraint Optimization Problems (DCOPs) have emerged as one of the prominent
agent architectures to govern the agents&apos; autonomous behavior, where both
algorithms and communication models are driven by the structure of the specific
problem. During the last decade, several extensions to the DCOP model have
enabled them to support MAS in complex, real-time, and uncertain environments.
This survey aims at providing an overview of the DCOP model, giving a
classification of its multiple extensions and addressing both resolution
methods and applications that find a natural mapping within each class of
DCOPs. The proposed classification suggests several future perspectives for
DCOP extensions, and identifies challenges in the design of efficient
resolution algorithms, possibly through the adaptation of strategies from
different areas.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fioretto_F/0/1/0/all/0/1&quot;&gt;Ferdinando Fioretto&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pontelli_E/0/1/0/all/0/1&quot;&gt;Enrico Pontelli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yeoh_W/0/1/0/all/0/1&quot;&gt;William Yeoh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1703.01671">
<title>Controlling for Unobserved Confounds in Classification Using Correlational Constraints. (arXiv:1703.01671v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1703.01671</link>
<description rdf:parseType="Literal">&lt;p&gt;As statistical classifiers become integrated into real-world applications, it
is important to consider not only their accuracy but also their robustness to
changes in the data distribution. In this paper, we consider the case where
there is an unobserved confounding variable $z$ that influences both the
features $\mathbf{x}$ and the class variable $y$. When the influence of $z$
changes from training to testing data, we find that the classifier accuracy can
degrade rapidly. In our approach, we assume that we can predict the value of
$z$ at training time with some error. The prediction for $z$ is then fed to
Pearl&apos;s back-door adjustment to build our model. Because of the attenuation
bias caused by measurement error in $z$, standard approaches to controlling for
$z$ are ineffective. In response, we propose a method to properly control for
the influence of $z$ by first estimating its relationship with the class
variable $y$, then updating predictions for $z$ to match that estimated
relationship. By adjusting the influence of $z$, we show that we can build a
model that exceeds competing baselines on accuracy as well as on robustness
over a range of confounding relationships.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Landeiro_V/0/1/0/all/0/1&quot;&gt;Virgile Landeiro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Culotta_A/0/1/0/all/0/1&quot;&gt;Aron Culotta&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.05207">
<title>Network Model Selection Using Task-Focused Minimum Description Length. (arXiv:1710.05207v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1710.05207</link>
<description rdf:parseType="Literal">&lt;p&gt;Networks are fundamental models for data used in practically every
application domain. In most instances, several implicit or explicit choices
about the network definition impact the translation of underlying data to a
network representation, and the subsequent question(s) about the underlying
system being represented. Users of downstream network data may not even be
aware of these choices or their impacts. We propose a task-focused network
model selection methodology which addresses several key challenges. Our
approach constructs network models from underlying data and uses minimum
description length (MDL) criteria for selection. Our methodology measures
efficiency, a general and comparable measure of the network&apos;s performance of a
local (i.e. node-level) predictive task of interest. Selection on efficiency
favors parsimonious (e.g. sparse) models to avoid overfitting and can be
applied across arbitrary tasks and representations. We show stability,
sensitivity, and significance testing in our methodology.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brugere_I/0/1/0/all/0/1&quot;&gt;Ivan Brugere&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Berger_Wolf_T/0/1/0/all/0/1&quot;&gt;Tanya Y. Berger-Wolf&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.01843">
<title>Online Tool Condition Monitoring Based on Parsimonious Ensemble+. (arXiv:1711.01843v1 [cs.LG] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1711.01843</link>
<description rdf:parseType="Literal">&lt;p&gt;Accurate diagnosis of tool wear in metal turning process remains an open
challenge for both scientists and industrial practitioners because of
inhomogeneities in workpiece material, nonstationary machining settings to suit
production requirements, and nonlinear relations between measured variables and
tool wear. Common methodologies for tool condition monitoring still rely on
batch approaches which cannot cope with a fast sampling rate of metal cutting
process. Furthermore they require a retraining process to be completed from
scratch when dealing with a new set of machining parameters. This paper
presents an online tool condition monitoring approach based on Parsimonious
Ensemble+, pENsemble+. The unique feature of pENsemble+ lies in its highly
flexible principle where both ensemble structure and base-classifier structure
can automatically grow and shrink on the fly based on the characteristics of
data streams. Moreover, the online feature selection scenario is integrated to
actively sample relevant input attributes. The paper presents advancement of a
newly developed ensemble learning algorithm, pENsemble+, where online active
learning scenario is incorporated to reduce operator labelling effort. The
ensemble merging scenario is proposed which allows reduction of ensemble
complexity while retaining its diversity. Experimental studies utilising
real-world manufacturing data streams and comparisons with well known
algorithms were carried out. Furthermore, the efficacy of pENsemble was
examined using benchmark concept drift data streams. It has been found that
pENsemble+ incurs low structural complexity and results in a significant
reduction of operator labelling effort.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pratama_M/0/1/0/all/0/1&quot;&gt;Mahardhika Pratama&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dimla_E/0/1/0/all/0/1&quot;&gt;Eric Dimla&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lughofer_E/0/1/0/all/0/1&quot;&gt;Edwin Lughofer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pedrycz_W/0/1/0/all/0/1&quot;&gt;Witold Pedrycz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tjahjowidowo_T/0/1/0/all/0/1&quot;&gt;Tegoeh Tjahjowidowo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.03137">
<title>Convergence Analysis of Gradient Descent Algorithms with Proportional Updates. (arXiv:1801.03137v1 [cs.LG] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1801.03137</link>
<description rdf:parseType="Literal">&lt;p&gt;The rise of deep learning in recent years has brought with it increasingly
clever optimization methods to deal with complex, non-linear loss functions.
These methods are often designed with convex optimization in mind, but have
been shown to work well in practice even for the highly non-convex optimization
associated with neural networks. However, one significant drawback of these
methods when they are applied to deep learning is that the magnitude of the
update step is sometimes disproportionate to the magnitude of the weights (much
smaller or larger), leading to training instabilities such as vanishing and
exploding gradients. An idea to combat this issue is gradient descent with
proportional updates. Gradient descent with proportional updates was introduced
in 2017. It was independently developed by You et al (Layer-wise Adaptive Rate
Scaling (LARS) algorithm) and by Abu-El-Haija (PercentDelta algorithm). The
basic idea of both of these algorithms is to make each step of the gradient
descent proportional to the current weight norm and independent of the gradient
magnitude. It is common in the context of new optimization methods to prove
convergence or derive regret bounds under the assumption of Lipschitz
continuity and convexity. However, even though LARS and PercentDelta were shown
to work well in practice, there is no theoretical analysis of the convergence
properties of these algorithms. Thus it is not clear if the idea of gradient
descent with proportional updates is used in the optimal way, or if it could be
improved by using a different norm or specific learning rate schedule, for
example. Moreover, it is not clear if these algorithms can be extended to other
problems, besides neural networks. We attempt to answer these questions by
establishing the theoretical analysis of gradient descent with proportional
updates, and verifying this analysis with empirical examples.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gitman_I/0/1/0/all/0/1&quot;&gt;Igor Gitman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dilipkumar_D/0/1/0/all/0/1&quot;&gt;Deepak Dilipkumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Parr_B/0/1/0/all/0/1&quot;&gt;Ben Parr&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.03533">
<title>Selection Problems in the Presence of Implicit Bias. (arXiv:1801.03533v1 [cs.CY])</title>
<link>http://arxiv.org/abs/1801.03533</link>
<description rdf:parseType="Literal">&lt;p&gt;Over the past two decades, the notion of implicit bias has come to serve as
an important component in our understanding of discrimination in activities
such as hiring, promotion, and school admissions. Research on implicit bias
posits that when people evaluate others -- for example, in a hiring context --
their unconscious biases about membership in particular groups can have an
effect on their decision-making, even when they have no deliberate intention to
discriminate against members of these groups. A growing body of experimental
work has pointed to the effect that implicit bias can have in producing adverse
outcomes.
&lt;/p&gt;
&lt;p&gt;Here we propose a theoretical model for studying the effects of implicit bias
on selection decisions, and a way of analyzing possible procedural remedies for
implicit bias within this model. A canonical situation represented by our model
is a hiring setting: a recruiting committee is trying to choose a set of
finalists to interview among the applicants for a job, evaluating these
applicants based on their future potential, but their estimates of potential
are skewed by implicit bias against members of one group. In this model, we
show that measures such as the Rooney Rule, a requirement that at least one of
the finalists be chosen from the affected group, can not only improve the
representation of this affected group, but also lead to higher payoffs in
absolute terms for the organization performing the recruiting. However,
identifying the conditions under which such measures can lead to improved
payoffs involves subtle trade-offs between the extent of the bias and the
underlying distribution of applicant characteristics, leading to novel
theoretical questions about order statistics in the presence of probabilistic
side information.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kleinberg_J/0/1/0/all/0/1&quot;&gt;Jon Kleinberg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Raghavan_M/0/1/0/all/0/1&quot;&gt;Manish Raghavan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.03558">
<title>Inference Suboptimality in Variational Autoencoders. (arXiv:1801.03558v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1801.03558</link>
<description rdf:parseType="Literal">&lt;p&gt;Amortized inference has led to efficient approximate inference for large
datasets. The quality of posterior inference is largely determined by two
factors: a) the ability of the variational distribution to model the true
posterior and b) the capacity of the recognition network to generalize
inference over all datapoints. We analyze approximate inference in variational
autoencoders in terms of these factors. We find that suboptimal inference is
often due to amortizing inference rather than the limited complexity of the
approximating distribution. We show that this is due partly to the generator
learning to accommodate the choice of approximation. Furthermore, we show that
the parameters used to increase the expressiveness of the approximation play a
role in generalizing inference rather than simply improving the complexity of
the approximation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cremer_C/0/1/0/all/0/1&quot;&gt;Chris Cremer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xuechen Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Duvenaud_D/0/1/0/all/0/1&quot;&gt;David Duvenaud&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.03714">
<title>Multi-Band Covariance Interpolation with Applications in Massive MIMO. (arXiv:1801.03714v1 [cs.IT])</title>
<link>http://arxiv.org/abs/1801.03714</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we study the problem of multi-band (frequency-variant)
covariance interpolation with a particular emphasis towards massive MIMO
applications. In a massive MIMO system, the communication between each BS with
$M \gg 1$ antennas and each single-antenna user occurs through a collection of
scatterers in the environment, where the channel vector of each user at BS
antennas consists in a weighted linear combination of the array responses of
the scatterers, where each scatterer has its own angle of arrival (AoA) and
complex channel gain. The array response at a given AoA depends on the
wavelength of the incoming planar wave and is naturally frequency dependent.
This results in a frequency-dependent distortion where the second order
statistics, i.e., the covariance matrix, of the channel vectors varies with
frequency. In this paper, we show that although this effect is generally
negligible for a small number of antennas $M$, it results in a considerable
distortion of the covariance matrix and especially its dominant signal subspace
in the massive MIMO regime where $M \to \infty$, and can generally incur a
serious degradation of the performance especially in frequency division
duplexing (FDD) massive MIMO systems where the uplink (UL) and the downlink
(DL) communication occur over different frequency bands. We propose a novel
UL-DL covariance interpolation technique that is able to recover the covariance
matrix in the DL from an estimate of the covariance matrix in the UL under a
mild reciprocity condition on the angular power spread function (PSF) of the
users. We analyze the performance of our proposed scheme mathematically and
prove its robustness under a sufficiently large spatial oversampling of the
array. We also propose several simple off-the-shelf algorithms for UL-DL
covariance interpolation and evaluate their performance via numerical
simulations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Haghighatshoar_S/0/1/0/all/0/1&quot;&gt;Saeid Haghighatshoar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khalilsarai_M/0/1/0/all/0/1&quot;&gt;Mahdi Barzegar Khalilsarai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Caire_G/0/1/0/all/0/1&quot;&gt;Giuseppe Caire&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.03765">
<title>Non-stationary Douglas-Rachford and alternating direction method of multipliers: adaptive stepsizes and convergence. (arXiv:1801.03765v1 [math.OC])</title>
<link>http://arxiv.org/abs/1801.03765</link>
<description rdf:parseType="Literal">&lt;p&gt;We revisit the classical Douglas-Rachford (DR) method for finding a zero of
the sum of two maximal monotone operators. Since the practical performance of
the DR method crucially depends on the stepsizes, we aim at developing an
adaptive stepsize rule. To that end, we take a closer look at a linear case of
the problem and use our findings to develop a stepsize strategy that eliminates
the need for stepsize tuning. We analyze a general non-stationary DR scheme and
prove its convergence for a convergent sequence of stepsizes with summable
increments. This, in turn, proves the convergence of the method with the new
adaptive stepsize rule. We also derive the related non-stationary alternating
direction method of multipliers (ADMM) from such a non-stationary DR method. We
illustrate the efficiency of the proposed methods on several numerical
examples.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Lorenz_D/0/1/0/all/0/1&quot;&gt;Dirk A. Lorenz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Tran_Dinh_Q/0/1/0/all/0/1&quot;&gt;Quoc Tran-Dinh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.03773">
<title>Polar $n$-Complex and $n$-Bicomplex Singular Value Decomposition and Principal Component Pursuit. (arXiv:1801.03773v1 [eess.SP])</title>
<link>http://arxiv.org/abs/1801.03773</link>
<description rdf:parseType="Literal">&lt;p&gt;Informed by recent work on tensor singular value decomposition and circulant
algebra matrices, this paper presents a new theoretical bridge that unifies the
hypercomplex and tensor-based approaches to singular value decomposition and
robust principal component analysis. We begin our work by extending the
principal component pursuit to Olariu&apos;s polar $n$-complex numbers as well as
their bicomplex counterparts. In so doing, we have derived the polar
$n$-complex and $n$-bicomplex proximity operators for both the $\ell_1$- and
trace-norm regularizers, which can be used by proximal optimization methods
such as the alternating direction method of multipliers. Experimental results
on two sets of audio data show that our algebraically-informed formulation
outperforms tensor robust principal component analysis. We conclude with the
message that an informed definition of the trace norm can bridge the gap
between the hypercomplex and tensor-based approaches. Our approach can be seen
as a general methodology for generating other principal component pursuit
algorithms with proper algebraic structures.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Chan_T/0/1/0/all/0/1&quot;&gt;Tak-Shing T. Chan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Yang_Y/0/1/0/all/0/1&quot;&gt;Yi-Hsuan Yang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.03815">
<title>Informed Group-Sparse Representation for Singing Voice Separation. (arXiv:1801.03815v1 [eess.AS])</title>
<link>http://arxiv.org/abs/1801.03815</link>
<description rdf:parseType="Literal">&lt;p&gt;Singing voice separation attempts to separate the vocal and instrumental
parts of a music recording, which is a fundamental problem in music information
retrieval. Recent work on singing voice separation has shown that the low-rank
representation and informed separation approaches are both able to improve
separation quality. However, low-rank optimizations are computationally
inefficient due to the use of singular value decompositions. Therefore, in this
paper, we propose a new linear-time algorithm called informed group-sparse
representation, and use it to separate the vocals from music using pitch
annotations as side information. Experimental results on the iKala dataset
confirm the efficacy of our approach, suggesting that the music accompaniment
follows a group-sparse structure given a pre-trained instrumental dictionary.
We also show how our work can be easily extended to accommodate multiple
dictionaries using the DSD100 dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Chan_T/0/1/0/all/0/1&quot;&gt;Tak-Shing T. Chan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Yang_Y/0/1/0/all/0/1&quot;&gt;Yi-Hsuan Yang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.03816">
<title>Complex and Quaternionic Principal Component Pursuit and Its Application to Audio Separation. (arXiv:1801.03816v1 [eess.SP])</title>
<link>http://arxiv.org/abs/1801.03816</link>
<description rdf:parseType="Literal">&lt;p&gt;Recently, the principal component pursuit has received increasing attention
in signal processing research ranging from source separation to video
surveillance. So far, all existing formulations are real-valued and lack the
concept of phase, which is inherent in inputs such as complex spectrograms or
color images. Thus, in this letter, we extend principal component pursuit to
the complex and quaternionic cases to account for the missing phase
information. Specifically, we present both complex and quaternionic proximity
operators for the $\ell_1$- and trace-norm regularizers. These operators can be
used in conjunction with proximal minimization methods such as the inexact
augmented Lagrange multiplier algorithm. The new algorithms are then applied to
the singing voice separation problem, which aims to separate the singing voice
from the instrumental accompaniment. Results on the iKala and MSD100 datasets
confirmed the usefulness of phase information in principal component pursuit.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Chan_T/0/1/0/all/0/1&quot;&gt;Tak-Shing T. Chan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Yang_Y/0/1/0/all/0/1&quot;&gt;Yi-Hsuan Yang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.03851">
<title>Autoencoders and Probabilistic Inference with Missing Data: An Exact Solution for The Factor Analysis Case. (arXiv:1801.03851v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1801.03851</link>
<description rdf:parseType="Literal">&lt;p&gt;Latent variable models can be used to probabilistically &quot;fill-in&quot; missing
data entries. The variational autoencoder architecture (Kingma and Welling,
2014; Rezende et al., 2014) includes a &quot;recognition&quot; or &quot;encoder&quot; network that
infers the latent variables given the data variables. However, it is not clear
how to handle missing data variables in this network. We show how to calculate
exactly the latent posterior distribution for the factor analysis (FA) model in
the presence of missing data, and note that this solution exhibits a
non-trivial dependence on the pattern of missingness. Experiments compare the
effectiveness of various approaches to filling in the missing data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Williams_C/0/1/0/all/0/1&quot;&gt;Christopher K. I. Williams&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nash_C/0/1/0/all/0/1&quot;&gt;Charlie Nash&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1602.07800">
<title>Towards Unifying Hamiltonian Monte Carlo and Slice Sampling. (arXiv:1602.07800v5 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1602.07800</link>
<description rdf:parseType="Literal">&lt;p&gt;We unify slice sampling and Hamiltonian Monte Carlo (HMC) sampling,
demonstrating their connection via the Hamiltonian-Jacobi equation from
Hamiltonian mechanics. This insight enables extension of HMC and slice sampling
to a broader family of samplers, called Monomial Gamma Samplers (MGS). We
provide a theoretical analysis of the mixing performance of such samplers,
proving that in the limit of a single parameter, the MGS draws decorrelated
samples from the desired target distribution. We further show that as this
parameter tends toward this limit, performance gains are achieved at a cost of
increasing numerical difficulty and some practical convergence issues. Our
theoretical results are validated with synthetic data and real-world
applications.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yizhe Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;Xiangyu Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chen_C/0/1/0/all/0/1&quot;&gt;Changyou Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Henao_R/0/1/0/all/0/1&quot;&gt;Ricardo Henao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Fan_K/0/1/0/all/0/1&quot;&gt;Kai Fan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Carin_L/0/1/0/all/0/1&quot;&gt;Lawrence Carin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1608.08306">
<title>Improving Downlink Coordinated Multipoint Performance in Heterogeneous Networks. (arXiv:1608.08306v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1608.08306</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a novel method for practical Joint Processing downlink coordinated
multipoint (DL CoMP) implementation in LTE/LTE-A systems using supervised
machine learning. DL CoMP has not been thoroughly studied in previous work
although cluster formation and interference mitigation have been studied
extensively. In this paper, we attempt to improve the cell edge data rate
served by a heterogeneous network cluster by means of dynamically changing the
DL SINR threshold at which the DL CoMP feature is triggered. We do so by using
a support vector machine (SVM) classifier. The simulation results show a cell
edge user throughput improvement of 33.3% for pico cells and more than
four-fold improvement in user throughput in the cluster. This has resulted from
a reduction in the downlink block error rate (DL BLER) and an improvement in
the spectral efficiency due to the informed triggering of the multiple radio
streams as part of DL CoMP.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mismar_F/0/1/0/all/0/1&quot;&gt;Faris B. Mismar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Evans_B/0/1/0/all/0/1&quot;&gt;Brian L. Evans&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1705.07057">
<title>Masked Autoregressive Flow for Density Estimation. (arXiv:1705.07057v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1705.07057</link>
<description rdf:parseType="Literal">&lt;p&gt;Autoregressive models are among the best performing neural density
estimators. We describe an approach for increasing the flexibility of an
autoregressive model, based on modelling the random numbers that the model uses
internally when generating data. By constructing a stack of autoregressive
models, each modelling the random numbers of the next model in the stack, we
obtain a type of normalizing flow suitable for density estimation, which we
call Masked Autoregressive Flow. This type of flow is closely related to
Inverse Autoregressive Flow and is a generalization of Real NVP. Masked
Autoregressive Flow achieves state-of-the-art performance in a range of
general-purpose density estimation tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Papamakarios_G/0/1/0/all/0/1&quot;&gt;George Papamakarios&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pavlakou_T/0/1/0/all/0/1&quot;&gt;Theo Pavlakou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Murray_I/0/1/0/all/0/1&quot;&gt;Iain Murray&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1705.09952">
<title>Optimal sequential treatment allocation. (arXiv:1705.09952v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1705.09952</link>
<description rdf:parseType="Literal">&lt;p&gt;In a treatment allocation problem the individuals to be treated often arrive
gradually. Initially, when the first treatments are made, little is known about
the effect of the treatments but as more treatments are assigned the policy
maker learns about their effects by observing outcomes. Thus, there is a
tradeoff between exploring the available treatments to learn about their merits
and exploiting the best treatment, i.e. administering it as often as possible,
in order to maximise the cumulative welfare of all the assignments made.
Furthermore, a policy maker may not only be interested in the expected effect
of the treatment but also its riskiness. Thus, we allow the welfare function to
depend on the first and second moments of the distribution of treatment
outcomes. We propose a dynamic treatment policy which attains the minimax
optimal regret relative to the unknown best treatment in this dynamic setting.
We allow for the data to arrive in batches as, say, unemployment programs only
start once a month or blood samples are only send to the laboratory for
investigation in batches. Furthermore, we show that the minimax optimality does
not come at the price of overly aggressive experimentation as we provide upper
bounds on the expected number of times any suboptimal treatment is assigned. We
also consider the case where the outcome of a treatment is only observed with
delay as it may take time for the treatment to work. Thus, a doctor faces a
tradeoff between getting imprecise information quickly by making the
measurement soon after the treatment is given or getting precise information
later at the expense of less information for the individuals who are treated in
the meantime. Finally, using Danish register data, we show how our treatment
policy can be used to assign unemployed to active labor market policy programs
in order to maximise the probability of ending the unemployment spell.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kock_A/0/1/0/all/0/1&quot;&gt;Anders Bredahl Kock&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Thyrsgaard_M/0/1/0/all/0/1&quot;&gt;Martin Thyrsgaard&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.00885">
<title>Gradient-based Optimization for Regression in the Functional Tensor-Train Format. (arXiv:1801.00885v2 [stat.CO] UPDATED)</title>
<link>http://arxiv.org/abs/1801.00885</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the task of low-multilinear-rank functional regression, i.e.,
learning a low-rank parametric representation of functions from scattered
real-valued data. Our first contribution is the development and analysis of an
efficient gradient computation that enables gradient-based optimization
procedures, including stochastic gradient descent and quasi-Newton methods, for
learning the parameters of a functional tensor-train (FT). The functional
tensor-train uses the tensor-train (TT) representation of low-rank arrays as an
ansatz for a class of low-multilinear-rank functions. The FT is represented by
a set of matrix-valued functions that contain a set of univariate functions,
and the regression task is to learn the parameters of these univariate
functions. Our second contribution demonstrates that using nonlinearly
parameterized univariate functions, e.g., symmetric kernels with moving
centers, within each core can outperform the standard approach of using a
linear expansion of basis functions. Our final contributions are new rank
adaptation and group-sparsity regularization procedures to minimize
overfitting. We use several benchmark problems to demonstrate at least an order
of magnitude lower accuracy with gradient-based optimization methods than
standard alternating least squares procedures in the low-sample number regime.
We also demonstrate an order of magnitude reduction in accuracy on a test
problem resulting from using nonlinear parameterizations over linear
parameterizations. Finally we compare regression performance with 22 other
nonparametric and parametric regression methods on 10 real-world data sets. We
achieve top-five accuracy for seven of the data sets and best accuracy for two
of the data sets. These rankings are the best amongst parametric models and
competetive with the best non-parametric methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gorodetsky_A/0/1/0/all/0/1&quot;&gt;Alex A. Gorodetsky&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Jakeman_J/0/1/0/all/0/1&quot;&gt;John D. Jakeman&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1706.01498">
<title>Stochastic Gradient Monomial Gamma Sampler. (arXiv:1706.01498v2 [stat.ML] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1706.01498</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent advances in stochastic gradient techniques have made it possible to
estimate posterior distributions from large datasets via Markov Chain Monte
Carlo (MCMC). However, when the target posterior is multimodal, mixing
performance is often poor. This results in inadequate exploration of the
posterior distribution. A framework is proposed to improve the sampling
efficiency of stochastic gradient MCMC, based on Hamiltonian Monte Carlo. A
generalized kinetic function is leveraged, delivering superior stationary
mixing, especially for multimodal distributions. Techniques are also discussed
to overcome the practical issues introduced by this generalization. It is shown
that the proposed approach is better at exploring complex multimodal posterior
distributions, as demonstrated on multiple applications and in comparison with
other stochastic gradient MCMC methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yizhe Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chen_C/0/1/0/all/0/1&quot;&gt;Changyou Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gan_Z/0/1/0/all/0/1&quot;&gt;Zhe Gan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Henao_R/0/1/0/all/0/1&quot;&gt;Ricardo Henao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Carin_L/0/1/0/all/0/1&quot;&gt;Lawrence Carin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.03265">
<title>More Adaptive Algorithms for Adversarial Bandits. (arXiv:1801.03265v1 [cs.LG] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1801.03265</link>
<description rdf:parseType="Literal">&lt;p&gt;We develop a novel and generic algorithm for the adversarial multi-armed
bandit problem (or more generally the combinatorial semi-bandit problem). When
instantiated differently, our algorithm achieves various new data-dependent
regret bounds improving previous works. Examples include: 1) a regret bound
depending on the variance of only the best arm; 2) a regret bound depending on
the first-order path-length of only the best arm; 3) a regret bound depending
on the sum of first-order path-lengths of all arms as well as an important
negative term, which together lead to faster convergence rates for some normal
form games with partial feedback; 4) a regret bound that simultaneously implies
small regret when the best arm has small loss and logarithmic regret when there
exists an arm whose expected loss is always smaller than those of others by a
fixed gap (e.g. the classic i.i.d. setting). In some cases, such as the last
two results, our algorithm is completely parameter-free.
&lt;/p&gt;
&lt;p&gt;The main idea of our algorithm is to apply the optimism and adaptivity
techniques to the well-known Online Mirror Descent framework with a special
log-barrier regularizer. The challenges are to come up with appropriate
optimistic predictions and correction terms in this framework. Some of our
results also crucially rely on using a sophisticated increasing learning rate
schedule.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wei_C/0/1/0/all/0/1&quot;&gt;Chen-Yu Wei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_H/0/1/0/all/0/1&quot;&gt;Haipeng Luo&lt;/a&gt;</dc:creator>
</item></rdf:RDF>