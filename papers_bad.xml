<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Boring papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Bad Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-06-12T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04278"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04419"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04528"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04552"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04563"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04641"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.00964"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.02037"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.05650"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04212"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04216"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04225"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04234"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04242"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04284"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04325"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04497"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04535"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1703.01327"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1707.06633"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.10494"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.02348"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07431"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10884"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.03600"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1705.08850"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04207"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04209"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04214"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04245"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04308"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04310"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04339"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04398"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04449"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04458"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04465"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04472"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04480"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04498"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04509"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04517"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04522"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04542"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04549"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04561"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04577"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04594"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04609"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04610"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04613"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04642"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1608.04636"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1706.06296"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.00342"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.02982"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.07756"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04065"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05666"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.07167"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08404"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.01905"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.11262"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.02395"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.05170"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.02587"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.05809"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02185"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1806.04278">
<title>The NES Music Database: A multi-instrumental dataset with expressive performance attributes. (arXiv:1806.04278v1 [cs.SD])</title>
<link>http://arxiv.org/abs/1806.04278</link>
<description rdf:parseType="Literal">&lt;p&gt;Existing research on music generation focuses on composition, but often
ignores the expressive performance characteristics required for plausible
renditions of resultant pieces. In this paper, we introduce the Nintendo
Entertainment System Music Database (NES-MDB), a large corpus allowing for
separate examination of the tasks of composition and performance. NES-MDB
contains thousands of multi-instrumental songs composed for playback by the
compositionally-constrained NES audio synthesizer. For each song, the dataset
contains a musical score for four instrument voices as well as expressive
attributes for the dynamics and timbre of each voice. Unlike datasets comprised
of General MIDI files, NES-MDB includes all of the information needed to render
exact acoustic performances of the original compositions. Alongside the
dataset, we provide a tool that renders generated compositions as NES-style
audio by emulating the device&apos;s audio processor. Additionally, we establish
baselines for the tasks of composition, which consists of learning the
semantics of composing for the NES synthesizer, and performance, which involves
finding a mapping between a composition and realistic expressive attributes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Donahue_C/0/1/0/all/0/1&quot;&gt;Chris Donahue&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mao_H/0/1/0/all/0/1&quot;&gt;Huanru Henry Mao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+McAuley_J/0/1/0/all/0/1&quot;&gt;Julian McAuley&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04419">
<title>Using Chaos in Grey Wolf Optimizer and Application to Prime Factorization. (arXiv:1806.04419v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1806.04419</link>
<description rdf:parseType="Literal">&lt;p&gt;The Grey Wolf Optimizer (GWO) is a swarm intelligence meta-heuristic
algorithm inspired by the hunting behaviour and social hierarchy of grey wolves
in nature. This paper analyses the use of chaos theory in this algorithm to
improve its ability to escape local optima by replacing the key parameters by
chaotic variables. The optimal choice of chaotic maps is then used to apply the
Chaotic Grey Wolf Optimizer (CGWO) to the problem of factoring a large semi
prime into its prime factors. Assuming the number of digits of the factors to
be equal, this is a computationally difficult task upon which the
RSA-cryptosystem relies. This work proposes the use of a new objective function
to solve the problem and uses the CGWO to optimize it and compute the factors.
It is shown that this function performs better than its predecessor for large
semi primes and CGWO is an efficient algorithm to optimize it.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mehrotra_H/0/1/0/all/0/1&quot;&gt;Harshit Mehrotra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pal_D/0/1/0/all/0/1&quot;&gt;Dr. Saibal K. Pal&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04528">
<title>Online Parallel Portfolio Selection with Heterogeneous Island Model. (arXiv:1806.04528v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1806.04528</link>
<description rdf:parseType="Literal">&lt;p&gt;We present an online parallel portfolio selection algorithm based on the
island model commonly used for parallelization of evolutionary algorithms. In
our case each of the islands runs a different optimization algorithm. The
distributed computation is managed by a central planner which periodically
changes the running methods during the execution of the algorithm -- less
successful methods are removed while new instances of more successful methods
are added.
&lt;/p&gt;
&lt;p&gt;We compare different types of planners in the heterogeneous island model
among themselves and also to the traditional homogeneous model on a wide set of
problems. The tests include experiments with different representations of the
individuals and different duration of fitness function evaluations. The results
show that heterogeneous models are a more general and universal computational
tool compared to homogeneous models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Balcar_S/0/1/0/all/0/1&quot;&gt;&amp;#x160;t&amp;#x11b;p&amp;#xe1;n Balcar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pilat_M/0/1/0/all/0/1&quot;&gt;Martin Pil&amp;#xe1;t&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04552">
<title>Combining Model-Free Q-Ensembles and Model-Based Approaches for Informed Exploration. (arXiv:1806.04552v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.04552</link>
<description rdf:parseType="Literal">&lt;p&gt;Q-Ensembles are a model-free approach where input images are fed into
different Q-networks and exploration is driven by the assumption that
uncertainty is proportional to the variance of the output Q-values obtained.
They have been shown to perform relatively well compared to other exploration
strategies. Further, model-based approaches, such as encoder-decoder models
have been used successfully for next frame prediction given previous frames.
This paper proposes to integrate the model-free Q-ensembles and model-based
approaches with the hope of compounding the benefits of both and achieving
superior exploration as a result. Results show that a model-based trajectory
memory approach when combined with Q-ensembles produces superior performance
when compared to only using Q-ensembles.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sankaranarayanan_S/0/1/0/all/0/1&quot;&gt;Sreecharan Sankaranarayanan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Annasamy_R/0/1/0/all/0/1&quot;&gt;Raghuram Mandyam Annasamy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sycara_K/0/1/0/all/0/1&quot;&gt;Katia Sycara&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rose_C/0/1/0/all/0/1&quot;&gt;Carolyn Penstein Ros&amp;#xe9;&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04563">
<title>Benchmarking Evolutionary Algorithms For Real-valued Constrained Optimization - A Critical Review. (arXiv:1806.04563v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1806.04563</link>
<description rdf:parseType="Literal">&lt;p&gt;Benchmarking plays an important role in the development of novel search
algorithms as well as for the assessment and comparison of contemporary
algorithmic ideas. This paper presents common principles that need to be taken
into account when considering benchmarking problems for constrained
optimization. Current benchmark environments for testing Evolutionary
Algorithms are reviewed in the light of these principles. Along with this line,
the reader is provided with an overview of the available problem domains in the
field of constrained benchmarking. Hence, the review supports algorithms
developers with information about the merits and demerits of the available
frameworks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hellwig_M/0/1/0/all/0/1&quot;&gt;Michael Hellwig&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Beyer_H/0/1/0/all/0/1&quot;&gt;Hans-Georg Beyer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04641">
<title>Predicting Citation Counts with a Neural Network. (arXiv:1806.04641v1 [cs.DL])</title>
<link>http://arxiv.org/abs/1806.04641</link>
<description rdf:parseType="Literal">&lt;p&gt;We here describe and present results of a simple neutral network that
predicts individual researchers&apos; future citation counts based on a variety of
data from the researchers&apos; past. For publications available on the open
access-server arXiv.org we find a higher predictability than previous studies.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mistele_T/0/1/0/all/0/1&quot;&gt;Tobias Mistele&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Price_T/0/1/0/all/0/1&quot;&gt;Tom Price&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hossenfelder_S/0/1/0/all/0/1&quot;&gt;Sabine Hossenfelder&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.00964">
<title>Drift Analysis. (arXiv:1712.00964v2 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1712.00964</link>
<description rdf:parseType="Literal">&lt;p&gt;Drift analysis is one of the major tools for analysing evolutionary
algorithms and nature-inspired search heuristics. In this chapter we give an
introduction to drift analysis and give some examples of how to use it for the
analysis of evolutionary algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lengler_J/0/1/0/all/0/1&quot;&gt;Johannes Lengler&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.02037">
<title>Complexity Theory for Discrete Black-Box Optimization Heuristics. (arXiv:1801.02037v2 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1801.02037</link>
<description rdf:parseType="Literal">&lt;p&gt;A predominant topic in the theory of evolutionary algorithms and, more
generally, theory of randomized black-box optimization techniques is running
time analysis. Running time analysis aims at understanding the performance of a
given heuristic on a given problem by bounding the number of function
evaluations that are needed by the heuristic to identify a solution of a
desired quality. As in general algorithms theory, this running time perspective
is most useful when it is complemented by a meaningful complexity theory that
studies the limits of algorithmic solutions.
&lt;/p&gt;
&lt;p&gt;In the context of discrete black-box optimization, several black-box
complexity models have been developed to analyze the best possible performance
that a black-box optimization algorithm can achieve on a given problem. The
models differ in the classes of algorithms to which these lower bounds apply.
This way, black-box complexity contributes to a better understanding of how
certain algorithmic choices (such as the amount of memory used by a heuristic,
its selective pressure, or properties of the strategies that it uses to create
new solution candidates) influences performance.
&lt;/p&gt;
&lt;p&gt;In this chapter we review the different black-box complexity models that have
been proposed in the literature, survey the bounds that have been obtained for
these models, and discuss how the interplay of running time analysis and
black-box complexity can inspire new algorithmic solutions to well-researched
problems in evolutionary computation. We also discuss in this chapter several
interesting open questions for future work.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Doerr_C/0/1/0/all/0/1&quot;&gt;Carola Doerr&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.05650">
<title>Theory of Parameter Control for Discrete Black-Box Optimization: Provable Performance Gains Through Dynamic Parameter Choices. (arXiv:1804.05650v2 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1804.05650</link>
<description rdf:parseType="Literal">&lt;p&gt;Parameter control aims at realizing performance gains through a dynamic
choice of the parameters which determine the behavior of the underlying
optimization algorithm. In the context of evolutionary algorithms this research
line has for a long time been dominated by empirical approaches. With the
significant advances in running time analysis achieved in the last ten years,
the parameter control question has become accessible to theoretical
investigations. A number of running time results for a broad range of different
parameter control mechanisms have been obtained in recent years. This book
chapter surveys these works, and puts them into context, by proposing an
updated classification scheme for parameter control.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Doerr_B/0/1/0/all/0/1&quot;&gt;Benjamin Doerr&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Doerr_C/0/1/0/all/0/1&quot;&gt;Carola Doerr&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04212">
<title>How Curiosity can be modeled for a Clickbait Detector. (arXiv:1806.04212v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1806.04212</link>
<description rdf:parseType="Literal">&lt;p&gt;The impact of continually evolving digital technologies and the proliferation
of communications and content has now been widely acknowledged to be central to
understanding our world. What is less acknowledged is that this is based on the
successful arousing of curiosity both at the collective and individual levels.
Advertisers, communication professionals and news editors are in constant
competition to capture attention of the digital population perennially shifty
and distracted. This paper, tries to understand how curiosity works in the
digital world by attempting the first ever work done on quantifying human
curiosity, basing itself on various theories drawn from humanities and social
sciences. Curious communication pushes people to spot, read and click the
message from their social feed or any other form of online presentation. Our
approach focuses on measuring the strength of the stimulus to generate reader
curiosity by using unsupervised and supervised machine learning algorithms, but
is also informed by philosophical, psychological, neural and cognitive studies
on this topic. Manually annotated news headlines - clickbaits - have been
selected for the study, which are known to have drawn huge reader response. A
binary classifier was developed based on human curiosity (unlike the work done
so far using words and other linguistic features). Our classifier shows an
accuracy of 97% . This work is part of the research in computational humanities
on digital politics quantifying the emotions of curiosity and outrage on
digital media.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Venneti_L/0/1/0/all/0/1&quot;&gt;Lasya Venneti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alam_A/0/1/0/all/0/1&quot;&gt;Aniket Alam&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04216">
<title>Multi-Agent Path Finding with Deadlines. (arXiv:1806.04216v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1806.04216</link>
<description rdf:parseType="Literal">&lt;p&gt;We formalize Multi-Agent Path Finding with Deadlines (MAPF-DL). The objective
is to maximize the number of agents that can reach their given goal vertices
from their given start vertices within the deadline, without colliding with
each other. We first show that MAPF-DL is NP-hard to solve optimally. We then
present two classes of optimal algorithms, one based on a reduction of MAPF-DL
to a flow problem and a subsequent compact integer linear programming
formulation of the resulting reduced abstracted multi-commodity flow network
and the other one based on novel combinatorial search algorithms. Our empirical
results demonstrate that these MAPF-DL solvers scale well and each one
dominates the other ones in different scenarios.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_H/0/1/0/all/0/1&quot;&gt;Hang Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wagner_G/0/1/0/all/0/1&quot;&gt;Glenn Wagner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Felner_A/0/1/0/all/0/1&quot;&gt;Ariel Felner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jiaoyang Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kumar_T/0/1/0/all/0/1&quot;&gt;T. K. Satish Kumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koenig_S/0/1/0/all/0/1&quot;&gt;Sven Koenig&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04225">
<title>PAC-Bayes Control: Synthesizing Controllers that Provably Generalize to Novel Environments. (arXiv:1806.04225v1 [cs.RO])</title>
<link>http://arxiv.org/abs/1806.04225</link>
<description rdf:parseType="Literal">&lt;p&gt;Our goal is to synthesize controllers for robots that provably generalize
well to novel environments given a dataset of example environments. The key
technical idea behind our approach is to leverage tools from generalization
theory in machine learning by exploiting a precise analogy (which we present in
the form of a reduction) between robustness of controllers to novel
environments and generalization of hypotheses in supervised learning. In
particular, we utilize the Probably Approximately Correct (PAC)-Bayes
framework, which allows us to obtain upper bounds (that hold with high
probability) on the expected cost of (stochastic) controllers across novel
environments. We propose control synthesis algorithms that explicitly seek to
minimize this upper bound. The corresponding optimization problem can be solved
using convex optimization (Relative Entropy Programming in particular) in the
setting where we are optimizing over a finite control policy space. In the more
general setting of continuously parameterized controllers, we minimize this
upper bound using stochastic gradient descent. We present examples of our
approach in the context of obstacle avoidance control with depth measurements.
Our simulated examples demonstrate the potential of our approach to provide
strong generalization guarantees on controllers for robotic systems with
continuous state and action spaces, complicated (e.g., nonlinear) dynamics, and
rich sensory inputs (e.g., depth measurements).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Majumdar_A/0/1/0/all/0/1&quot;&gt;Anirudha Majumdar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goldstein_M/0/1/0/all/0/1&quot;&gt;Maxwell Goldstein&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04234">
<title>Lecture Notes on Fair Division. (arXiv:1806.04234v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1806.04234</link>
<description rdf:parseType="Literal">&lt;p&gt;Fair division is the problem of dividing one or several goods amongst two or
more agents in a way that satisfies a suitable fairness criterion. These Notes
provide a succinct introduction to the field. We cover three main topics.
First, we need to define what is to be understood by a &quot;fair&quot; allocation of
goods to individuals. We present an overview of the most important fairness
criteria (as well as the closely related criteria for economic efficiency)
developed in the literature, together with a short discussion of their
axiomatic foundations. Second, we give an introduction to cake-cutting
procedures as an example of methods for fairly dividing a single divisible
resource amongst a group of individuals. Third, we discuss the combinatorial
optimisation problem of fairly allocating a set of indivisible goods to a group
of agents, covering both centralised algorithms (similar to auctions) and a
distributed approach based on negotiation.
&lt;/p&gt;
&lt;p&gt;While the classical literature on fair division has largely developed within
Economics, these Notes are specifically written for readers with a background
in Computer Science or similar, and who may be (or may wish to be) engaged in
research in Artificial Intelligence, Multiagent Systems, or Computational
Social Choice. References for further reading, as well as a small number of
exercises, are included.
&lt;/p&gt;
&lt;p&gt;Notes prepared for a tutorial at the 11th European Agent Systems Summer
School (EASSS-2009), Torino, Italy, 31 August and 1 September 2009. Updated for
a tutorial at the COST-ADT Doctoral School on Computational Social Choice,
Estoril, Portugal, 9--14 April 2010.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Endriss_U/0/1/0/all/0/1&quot;&gt;Ulle Endriss&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04242">
<title>The Potential of the Return Distribution for Exploration in RL. (arXiv:1806.04242v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.04242</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper studies the potential of the return distribution for exploration
in deterministic environments. We study network losses and propagation
mechanisms for Gaussian, Categorical and Mixture of Gaussian distributions.
Combined with exploration policies that leverage this return distribution, we
solve, for example, a randomized Chain task of length 100, which has not been
reported before when learning with neural networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moerland_T/0/1/0/all/0/1&quot;&gt;Thomas M. Moerland&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Broekens_J/0/1/0/all/0/1&quot;&gt;Joost Broekens&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jonker_C/0/1/0/all/0/1&quot;&gt;Catholijn M. Jonker&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04284">
<title>iParaphrasing: Extracting Visually Grounded Paraphrases via an Image. (arXiv:1806.04284v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1806.04284</link>
<description rdf:parseType="Literal">&lt;p&gt;A paraphrase is a restatement of the meaning of a text in other words.
Paraphrases have been studied to enhance the performance of many natural
language processing tasks. In this paper, we propose a novel task iParaphrasing
to extract visually grounded paraphrases (VGPs), which are different phrasal
expressions describing the same visual concept in an image. These extracted
VGPs have the potential to improve language and image multimodal tasks such as
visual question answering and image captioning. How to model the similarity
between VGPs is the key of iParaphrasing. We apply various existing methods as
well as propose a novel neural network-based method with image attention, and
report the results of the first attempt toward iParaphrasing.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chu_C/0/1/0/all/0/1&quot;&gt;Chenhui Chu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Otani_M/0/1/0/all/0/1&quot;&gt;Mayu Otani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nakashima_Y/0/1/0/all/0/1&quot;&gt;Yuta Nakashima&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04325">
<title>Augmenting Stream Constraint Programming with Eventuality Conditions. (arXiv:1806.04325v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1806.04325</link>
<description rdf:parseType="Literal">&lt;p&gt;Stream constraint programming is a recent addition to the family of
constraint programming frameworks, where variable domains are sets of infinite
streams over finite alphabets. Previous works showed promising results for its
applicability to real-world planning and control problems. In this paper,
motivated by the modelling of planning applications, we improve the
expressiveness of the framework by introducing 1) the &quot;until&quot; constraint, a new
construct that is adapted from Linear Temporal Logic and 2) the @ operator on
streams, a syntactic sugar for which we provide a more efficient solving
algorithm over simple desugaring. For both constructs, we propose corresponding
novel solving algorithms and prove their correctness. We present competitive
experimental results on the Missionaries and Cannibals logic puzzle and a
standard path planning application on the grid, by comparing with Apt and
Brand&apos;s method for verifying eventuality conditions using a CP approach.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1&quot;&gt;Jasper C.H. Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1&quot;&gt;Jimmy H.M. Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhong_A/0/1/0/all/0/1&quot;&gt;Allen Z. Zhong&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04497">
<title>A Virtual Environment with Multi-Robot Navigation, Analytics, and Decision Support for Critical Incident Investigation. (arXiv:1806.04497v1 [cs.CY])</title>
<link>http://arxiv.org/abs/1806.04497</link>
<description rdf:parseType="Literal">&lt;p&gt;Accidents and attacks that involve chemical, biological, radiological/nuclear
or explosive (CBRNE) substances are rare, but can be of high consequence. Since
the investigation of such events is not anybody&apos;s routine work, a range of AI
techniques can reduce investigators&apos; cognitive load and support
decision-making, including: planning the assessment of the scene; ongoing
evaluation and updating of risks; control of autonomous vehicles for collecting
images and sensor data; reviewing images/videos for items of interest;
identification of anomalies; and retrieval of relevant documentation. Because
of the rare and high-risk nature of these events, realistic simulations can
support the development and evaluation of AI-based tools. We have developed
realistic models of CBRNE scenarios and implemented an initial set of tools.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Smyth_D/0/1/0/all/0/1&quot;&gt;David L. Smyth&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fennell_J/0/1/0/all/0/1&quot;&gt;James Fennell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abinesh_S/0/1/0/all/0/1&quot;&gt;Sai Abinesh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Karimi_N/0/1/0/all/0/1&quot;&gt;Nazli B. Karimi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Glavin_F/0/1/0/all/0/1&quot;&gt;Frank G. Glavin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ullah_I/0/1/0/all/0/1&quot;&gt;Ihsan Ullah&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Drury_B/0/1/0/all/0/1&quot;&gt;Brett Drury&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Madden_M/0/1/0/all/0/1&quot;&gt;Michael G. Madden&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04535">
<title>Automatic Target Recovery for Hindi-English Code Mixed Puns. (arXiv:1806.04535v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1806.04535</link>
<description rdf:parseType="Literal">&lt;p&gt;In order for our computer systems to be more human-like, with a higher
emotional quotient, they need to be able to process and understand intrinsic
human language phenomena like humour. In this paper, we consider a subtype of
humour - puns, which are a common type of wordplay-based jokes. In particular,
we consider code-mixed puns which have become increasingly mainstream on social
media, in informal conversations and advertisements and aim to build a system
which can automatically identify the pun location and recover the target of
such puns. We first study and classify code-mixed puns into two categories
namely intra-sentential and intra-word, and then propose a four-step algorithm
to recover the pun targets for puns belonging to the intra-sentential category.
Our algorithm uses language models, and phonetic similarity-based features to
get the desired results. We test our approach on a small set of code-mixed
punning advertisements, and observe that our system is successfully able to
recover the targets for 67% of the puns.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aggarwal_S/0/1/0/all/0/1&quot;&gt;Srishti Aggarwal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mathur_K/0/1/0/all/0/1&quot;&gt;Kritik Mathur&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mamidi_R/0/1/0/all/0/1&quot;&gt;Radhika Mamidi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1703.01327">
<title>Multi-step Reinforcement Learning: A Unifying Algorithm. (arXiv:1703.01327v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1703.01327</link>
<description rdf:parseType="Literal">&lt;p&gt;Unifying seemingly disparate algorithmic ideas to produce better performing
algorithms has been a longstanding goal in reinforcement learning. As a primary
example, TD($\lambda$) elegantly unifies one-step TD prediction with Monte
Carlo methods through the use of eligibility traces and the trace-decay
parameter $\lambda$. Currently, there are a multitude of algorithms that can be
used to perform TD control, including Sarsa, $Q$-learning, and Expected Sarsa.
These methods are often studied in the one-step case, but they can be extended
across multiple time steps to achieve better performance. Each of these
algorithms is seemingly distinct, and no one dominates the others for all
problems. In this paper, we study a new multi-step action-value algorithm
called $Q(\sigma)$ which unifies and generalizes these existing algorithms,
while subsuming them as special cases. A new parameter, $\sigma$, is introduced
to allow the degree of sampling performed by the algorithm at each step during
its backup to be continuously varied, with Sarsa existing at one extreme (full
sampling), and Expected Sarsa existing at the other (pure expectation).
$Q(\sigma)$ is generally applicable to both on- and off-policy learning, but in
this work we focus on experiments in the on-policy case. Our results show that
an intermediate value of $\sigma$, which results in a mixture of the existing
algorithms, performs better than either extreme. The mixture can also be varied
dynamically which can result in even greater performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Asis_K/0/1/0/all/0/1&quot;&gt;Kristopher De Asis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hernandez_Garcia_J/0/1/0/all/0/1&quot;&gt;J. Fernando Hernandez-Garcia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Holland_G/0/1/0/all/0/1&quot;&gt;G. Zacharias Holland&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sutton_R/0/1/0/all/0/1&quot;&gt;Richard S. Sutton&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1707.06633">
<title>Acting Thoughts: Towards a Mobile Robotic Service Assistant for Users with Limited Communication Skills. (arXiv:1707.06633v4 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1707.06633</link>
<description rdf:parseType="Literal">&lt;p&gt;As autonomous service robots become more affordable and thus available also
for the general public, there is a growing need for user friendly interfaces to
control the robotic system. Currently available control modalities typically
expect users to be able to express their desire through either touch, speech or
gesture commands. While this requirement is fulfilled for the majority of
users, paralyzed users may not be able to use such systems. In this paper, we
present a novel framework, that allows these users to interact with a robotic
service assistant in a closed-loop fashion, using only thoughts. The
brain-computer interface (BCI) system is composed of several interacting
components, i.e., non-invasive neuronal signal recording and decoding,
high-level task planning, motion and manipulation planning as well as
environment perception. In various experiments, we demonstrate its
applicability and robustness in real world scenarios, considering
fetch-and-carry tasks and tasks involving human-robot interaction. As our
results demonstrate, our system is capable of adapting to frequent changes in
the environment and reliably completing given tasks within a reasonable amount
of time. Combined with high-level planning and autonomous robotic systems,
interesting new perspectives open up for non-invasive BCI-based human-robot
interactions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Burget_F/0/1/0/all/0/1&quot;&gt;Felix Burget&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fiederer_L/0/1/0/all/0/1&quot;&gt;Lukas Dominique Josef Fiederer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kuhner_D/0/1/0/all/0/1&quot;&gt;Daniel Kuhner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Volker_M/0/1/0/all/0/1&quot;&gt;Martin V&amp;#xf6;lker&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aldinger_J/0/1/0/all/0/1&quot;&gt;Johannes Aldinger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schirrmeister_R/0/1/0/all/0/1&quot;&gt;Robin Tibor Schirrmeister&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Do_C/0/1/0/all/0/1&quot;&gt;Chau Do&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Boedecker_J/0/1/0/all/0/1&quot;&gt;Joschka Boedecker&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nebel_B/0/1/0/all/0/1&quot;&gt;Bernhard Nebel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ball_T/0/1/0/all/0/1&quot;&gt;Tonio Ball&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Burgard_W/0/1/0/all/0/1&quot;&gt;Wolfram Burgard&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.10494">
<title>Discovery and recognition of motion primitives in human activities. (arXiv:1709.10494v5 [cs.RO] UPDATED)</title>
<link>http://arxiv.org/abs/1709.10494</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a novel framework for the automatic discovery and recognition of
motion primitives in videos of human activities. Given the 3D pose of a human
in a video, human motion primitives are discovered by optimizing the `motion
flux&apos;, a quantity which captures the motion variation of a group of skeletal
joints. A normalization of the primitives is proposed in order to make them
invariant with respect to a subject anatomical variations and data sampling
rate. The discovered primitives are unknown and unlabeled and are
unsupervisedly collected into classes via a hierarchical non-parametric Bayes
mixture model. Once classes are determined and labeled they are further
analyzed for establishing models for recognizing discovered primitives. Each
primitive model is defined by a set of learned parameters.
&lt;/p&gt;
&lt;p&gt;Given new video data and given the estimated pose of the subject appearing on
the video, the motion is segmented into primitives, which are recognized with a
probability given according to the parameters of the learned models.
&lt;/p&gt;
&lt;p&gt;Using our framework we build a publicly available dataset of human motion
primitives, using sequences taken from well-known motion capture datasets. We
expect that our framework, by providing an objective way for discovering and
categorizing human motion, will be a useful tool in numerous research fields
including video analysis, human inspired motion generation, learning by
demonstration, intuitive human-robot interaction, and human behavior analysis.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sanzari_M/0/1/0/all/0/1&quot;&gt;Marta Sanzari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ntouskos_V/0/1/0/all/0/1&quot;&gt;Valsamis Ntouskos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pirri_F/0/1/0/all/0/1&quot;&gt;Fiora Pirri&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.02348">
<title>Smoothed Action Value Functions for Learning Gaussian Policies. (arXiv:1803.02348v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1803.02348</link>
<description rdf:parseType="Literal">&lt;p&gt;State-action value functions (i.e., Q-values) are ubiquitous in reinforcement
learning (RL), giving rise to popular algorithms such as SARSA and Q-learning.
We propose a new notion of action value defined by a Gaussian smoothed version
of the expected Q-value. We show that such smoothed Q-values still satisfy a
Bellman equation, making them learnable from experience sampled from an
environment. Moreover, the gradients of expected reward with respect to the
mean and covariance of a parameterized Gaussian policy can be recovered from
the gradient and Hessian of the smoothed Q-value function. Based on these
relationships, we develop new algorithms for training a Gaussian policy
directly from a learned smoothed Q-value approximator. The approach is
additionally amenable to proximal optimization by augmenting the objective with
a penalty on KL-divergence from a previous policy. We find that the ability to
learn both a mean and covariance during training leads to significantly
improved results on standard continuous control benchmarks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nachum_O/0/1/0/all/0/1&quot;&gt;Ofir Nachum&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Norouzi_M/0/1/0/all/0/1&quot;&gt;Mohammad Norouzi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tucker_G/0/1/0/all/0/1&quot;&gt;George Tucker&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schuurmans_D/0/1/0/all/0/1&quot;&gt;Dale Schuurmans&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07431">
<title>Can machine learning identify interesting mathematics? An exploration using empirically observed laws. (arXiv:1805.07431v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.07431</link>
<description rdf:parseType="Literal">&lt;p&gt;We explore the possibility of using machine learning to identify interesting
mathematical structures by using certain quantities that serve as fingerprints.
In particular, we extract features from integer sequences using two empirical
laws: Benford&apos;s law and Taylor&apos;s law and experiment with various classifiers to
identify whether a sequence is, for example, nice, important, multiplicative,
easy to compute or related to primes or palindromes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1&quot;&gt;Chai Wah Wu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.10884">
<title>Training Medical Image Analysis Systems like Radiologists. (arXiv:1805.10884v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1805.10884</link>
<description rdf:parseType="Literal">&lt;p&gt;The training of medical image analysis systems using machine learning
approaches follows a common script: collect and annotate a large dataset, train
the classifier on the training set, and test it on a hold-out test set. This
process bears no direct resemblance with radiologist training, which is based
on solving a series of tasks of increasing difficulty, where each task involves
the use of significantly smaller datasets than those used in machine learning.
In this paper, we propose a novel training approach inspired by how
radiologists are trained. In particular, we explore the use of meta-training
that models a classifier based on a series of tasks. Tasks are selected using
teacher-student curriculum learning, where each task consists of simple
classification problems containing small training sets. We hypothesize that our
proposed meta-training approach can be used to pre-train medical image analysis
models. This hypothesis is tested on the automatic breast screening
classification from DCE-MRI trained with weakly labeled datasets. The
classification performance achieved by our approach is shown to be the best in
the field for that application, compared to state of art baseline approaches:
DenseNet, multiple instance learning and multi-task learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Maicas_G/0/1/0/all/0/1&quot;&gt;Gabriel Maicas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bradley_A/0/1/0/all/0/1&quot;&gt;Andrew P. Bradley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nascimento_J/0/1/0/all/0/1&quot;&gt;Jacinto C. Nascimento&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Reid_I/0/1/0/all/0/1&quot;&gt;Ian Reid&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Carneiro_G/0/1/0/all/0/1&quot;&gt;Gustavo Carneiro&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.03600">
<title>ML + FV = $\heartsuit$? A Survey on the Application of Machine Learning to Formal Verification. (arXiv:1806.03600v2 [cs.SE] UPDATED)</title>
<link>http://arxiv.org/abs/1806.03600</link>
<description rdf:parseType="Literal">&lt;p&gt;Formal Verification (FV) and Machine Learning (ML) can seem incompatible due
to their opposite mathematical foundations and their use in real-life problems:
FV mostly relies on discrete mathematics and aims at ensuring correctness; ML
often relies on probabilistic models and consists of learning patterns from
training data. In this paper, we postulate that they are complementary in
practice, and explore how ML helps FV in its classical approaches: static
analysis, model-checking, theorem-proving, and SAT solving. We draw a landscape
of the current practice and catalog some of the most prominent uses of ML
inside FV tools, thus offering a new perspective on FV techniques that can help
researchers and practitioners to better locate the possible synergies. We
discuss lessons learned from our work, point to possible improvements and offer
visions for the future of the domain in the light of the science of software
and systems modeling.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Amrani_M/0/1/0/all/0/1&quot;&gt;Moussa Amrani&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lucio_L/0/1/0/all/0/1&quot;&gt;Levi L&amp;#xfa;cio&lt;/a&gt; (2), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bibal_A/0/1/0/all/0/1&quot;&gt;Adrien Bibal&lt;/a&gt; (1) (University of Namur, Faculty of Computer Science, PReCiSE / NaDI, Namur, Belgium (2) fortiss GmbH, M&amp;#xfc;nchen, Germany)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1705.08850">
<title>Semi-supervised Learning with GANs: Manifold Invariance with Improved Inference. (arXiv:1705.08850v2 [cs.LG] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1705.08850</link>
<description rdf:parseType="Literal">&lt;p&gt;Semi-supervised learning methods using Generative Adversarial Networks (GANs)
have shown promising empirical success recently. Most of these methods use a
shared discriminator/classifier which discriminates real examples from fake
while also predicting the class label. Motivated by the ability of the GANs
generator to capture the data manifold well, we propose to estimate the tangent
space to the data manifold using GANs and employ it to inject invariances into
the classifier. In the process, we propose enhancements over existing methods
for learning the inverse mapping (i.e., the encoder) which greatly improves in
terms of semantic similarity of the reconstructed sample with the input sample.
We observe considerable empirical gains in semi-supervised learning over
baselines, particularly in the cases when the number of labeled examples is
low. We also provide insights into how fake examples influence the
semi-supervised learning procedure.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kumar_A/0/1/0/all/0/1&quot;&gt;Abhishek Kumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sattigeri_P/0/1/0/all/0/1&quot;&gt;Prasanna Sattigeri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fletcher_P/0/1/0/all/0/1&quot;&gt;P. Thomas Fletcher&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04207">
<title>Swarming for Faster Convergence in Stochastic Optimization. (arXiv:1806.04207v1 [math.OC])</title>
<link>http://arxiv.org/abs/1806.04207</link>
<description rdf:parseType="Literal">&lt;p&gt;We study a distributed framework for stochastic optimization which is
inspired by models of collective motion found in nature (e.g., swarming) with
mild communication requirements. Specifically, we analyze a scheme in which
each one of $N &amp;gt; 1$ independent threads, implements in a distributed and
unsynchronized fashion, a stochastic gradient-descent algorithm which is
perturbed by a swarming potential. Assuming the overhead caused by
synchronization is not negligible, we show the swarming-based approach exhibits
better performance than a centralized algorithm (based upon the average of $N$
observations) in terms of (real-time) convergence speed. We also derive an
error bound that is monotone decreasing in network size and connectivity. We
characterize the scheme&apos;s finite-time performances for both convex and
non-convex objective functions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Pu_S/0/1/0/all/0/1&quot;&gt;Shi Pu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Garcia_A/0/1/0/all/0/1&quot;&gt;Alfredo Garcia&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04209">
<title>3D Convolutional Neural Networks for Classification of Functional Connectomes. (arXiv:1806.04209v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1806.04209</link>
<description rdf:parseType="Literal">&lt;p&gt;Resting-state functional MRI (rs-fMRI) scans hold the potential to serve as a
diagnostic or prognostic tool for a wide variety of conditions, such as autism,
Alzheimer&apos;s disease, and stroke. While a growing number of studies have
demonstrated the promise of machine learning algorithms for rs-fMRI based
clinical or behavioral prediction, most prior models have been limited in their
capacity to exploit the richness of the data. For example, classification
techniques applied to rs-fMRI often rely on region-based summary statistics
and/or linear models. In this work, we propose a novel volumetric Convolutional
Neural Network (CNN) framework that takes advantage of the full-resolution 3D
spatial structure of rs-fMRI data and fits non-linear predictive models. We
showcase our approach on a challenging large-scale dataset (ABIDE, with N &amp;gt;
2,000) and report state-of-the-art accuracy results on rs-fMRI-based
discrimination of autism patients and healthy controls.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khosla_M/0/1/0/all/0/1&quot;&gt;Meenakshi Khosla&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jamison_K/0/1/0/all/0/1&quot;&gt;Keith Jamison&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kuceyeski_A/0/1/0/all/0/1&quot;&gt;Amy Kuceyeski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sabuncu_M/0/1/0/all/0/1&quot;&gt;Mert Sabuncu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04214">
<title>On the universality of the stochastic block model. (arXiv:1806.04214v1 [physics.soc-ph])</title>
<link>http://arxiv.org/abs/1806.04214</link>
<description rdf:parseType="Literal">&lt;p&gt;Mesoscopic pattern extraction (MPE) is the problem of finding a partition of
the nodes of a complex network that maximizes some objective function. Many
well-known network inference problems fall in this category, including for
instance: community detection, core-periphery identification, imperfect graph
colouring. In this paper, we show that the most popular algorithms designed to
solve MPE problems can in fact be understood as special cases of the maximum
likelihood formulation of the stochastic block model, or one of its direct
generalizations. These equivalence relations show that the SBM is nearly
universal with respect to MPE problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Young_J/0/1/0/all/0/1&quot;&gt;Jean-Gabriel Young&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+St_Onge_G/0/1/0/all/0/1&quot;&gt;Guillaume St-Onge&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Desrosiers_P/0/1/0/all/0/1&quot;&gt;Patrick Desrosiers&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Dube_L/0/1/0/all/0/1&quot;&gt;Louis J. Dub&amp;#xe9;&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04245">
<title>Learning to Speed Up Structured Output Prediction. (arXiv:1806.04245v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.04245</link>
<description rdf:parseType="Literal">&lt;p&gt;Predicting structured outputs can be computationally onerous due to the
combinatorially large output spaces. In this paper, we focus on reducing the
prediction time of a trained black-box structured classifier without losing
accuracy. To do so, we train a speedup classifier that learns to mimic a
black-box classifier under the learning-to-search approach. As the structured
classifier predicts more examples, the speedup classifier will operate as a
learned heuristic to guide search to favorable regions of the output space. We
present a mistake bound for the speedup classifier and identify inference
situations where it can independently make correct judgments without input
features. We evaluate our method on the task of entity and relation extraction
and show that the speedup classifier outperforms even greedy search in terms of
speed without loss of accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pan_X/0/1/0/all/0/1&quot;&gt;Xingyuan Pan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Srikumar_V/0/1/0/all/0/1&quot;&gt;Vivek Srikumar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04308">
<title>Diverse Online Feature Selection. (arXiv:1806.04308v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.04308</link>
<description rdf:parseType="Literal">&lt;p&gt;Online feature selection has been an active research area in recent years. We
propose a novel diverse online feature selection method based on Determinantal
Point Processes (DPP). Our model aims to provide diverse features which can be
composed in either a supervised or unsupervised framework. The framework aims
to promote diversity based on the kernel produced on a feature level, through
at most three stages: feature sampling, local criteria and global criteria for
feature selection. In the feature sampling, we sample incoming stream of
features using conditional DPP. The local criteria is used to assess and select
streamed features (i.e. only when they arrive), we use unsupervised scale
invariant methods to remove redundant features and optionally supervised
methods to introduce label information to assess relevant features. Lastly, the
global criteria uses regularization methods to select a global optimal subset
of features. This three stage procedure continues until there are no more
features arriving or some predefined stopping condition is met. We demonstrate
based on experiments conducted on that this approach yields better compactness,
is comparable and in some instances outperforms other state-of-the-art online
feature selection methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Siu_C/0/1/0/all/0/1&quot;&gt;Chapman Siu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Xu_R/0/1/0/all/0/1&quot;&gt;Richard Yi Da Xu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04310">
<title>MISSION: Ultra Large-Scale Feature Selection using Count-Sketches. (arXiv:1806.04310v1 [cs.DS])</title>
<link>http://arxiv.org/abs/1806.04310</link>
<description rdf:parseType="Literal">&lt;p&gt;Feature selection is an important challenge in machine learning. It plays a
crucial role in the explainability of machine-driven decisions that are rapidly
permeating throughout modern society. Unfortunately, the explosion in the size
and dimensionality of real-world datasets poses a severe challenge to standard
feature selection algorithms. Today, it is not uncommon for datasets to have
billions of dimensions. At such scale, even storing the feature vector is
impossible, causing most existing feature selection methods to fail.
Workarounds like feature hashing, a standard approach to large-scale machine
learning, helps with the computational feasibility, but at the cost of losing
the interpretability of features. In this paper, we present MISSION, a novel
framework for ultra large-scale feature selection that performs stochastic
gradient descent while maintaining an efficient representation of the features
in memory using a Count-Sketch data structure. MISSION retains the simplicity
of feature hashing without sacrificing the interpretability of the features
while using only O(log^2(p)) working memory. We demonstrate that MISSION
accurately and efficiently performs feature selection on real-world,
large-scale datasets with billions of dimensions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aghazadeh_A/0/1/0/all/0/1&quot;&gt;Amirali Aghazadeh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Spring_R/0/1/0/all/0/1&quot;&gt;Ryan Spring&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+LeJeune_D/0/1/0/all/0/1&quot;&gt;Daniel LeJeune&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dasarathy_G/0/1/0/all/0/1&quot;&gt;Gautam Dasarathy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shrivastava_A/0/1/0/all/0/1&quot;&gt;Anshumali Shrivastava&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Baraniuk_R/0/1/0/all/0/1&quot;&gt;Richard G. Baraniuk&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04339">
<title>Convergence of SGD in Learning ReLU Models with Separable Data. (arXiv:1806.04339v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.04339</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the binary classification problem in which the objective function
is the exponential loss with a ReLU model, and study the convergence property
of the stochastic gradient descent (SGD) algorithm on linearly separable data.
We show that the gradient descent (GD) algorithm do not always learn desirable
model parameters due to the nonlinear ReLU model. Then, we identify a certain
condition of data samples, under which we show that SGD can learn a proper
classifier with implicit bias. In specific, we establish the sub-linear
convergence rate of the function value generated by SGD to global minimum. We
further show that SGD actually converges in expectation to the maximum margin
classifier with respect to the samples with +1 label under the ReLU model at
the rate O(1/ln t). We also extend our study to the case of multi-ReLU neurons,
and show that SGD converges to a certain non-linear maximum margin classifier
for a class of non-linearly separable data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_T/0/1/0/all/0/1&quot;&gt;Tengyu Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1&quot;&gt;Yi Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ji_K/0/1/0/all/0/1&quot;&gt;Kaiyi Ji&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1&quot;&gt;Yingbin Liang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04398">
<title>Attentive cross-modal paratope prediction. (arXiv:1806.04398v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.04398</link>
<description rdf:parseType="Literal">&lt;p&gt;Antibodies are a critical part of the immune system, having the function of
directly neutralising or tagging undesirable objects (the antigens) for future
destruction. Being able to predict which amino acids belong to the paratope,
the region on the antibody which binds to the antigen, can facilitate antibody
design and contribute to the development of personalised medicine. The
suitability of deep neural networks has recently been confirmed for this task,
with Parapred outperforming all prior physical models. Our contribution is
twofold: first, we significantly outperform the computational efficiency of
Parapred by leveraging \`a trous convolutions and self-attention. Secondly, we
implement cross-modal attention by allowing the antibody residues to attend
over antigen residues. This leads to new state-of-the-art results on this task,
along with insightful interpretations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Deac_A/0/1/0/all/0/1&quot;&gt;Andreea Deac&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Velickovic_P/0/1/0/all/0/1&quot;&gt;Petar Veli&amp;#x10d;kovi&amp;#x107;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sormanni_P/0/1/0/all/0/1&quot;&gt;Pietro Sormanni&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04449">
<title>ToxicBlend: Virtual Screening of Toxic Compounds with Ensemble Predictors. (arXiv:1806.04449v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.04449</link>
<description rdf:parseType="Literal">&lt;p&gt;Timely assessment of compound toxicity is one of the biggest challenges
facing the pharmaceutical industry today. A significant proportion of compounds
identified as potential leads are ultimately discarded due to the toxicity they
induce. In this paper, we propose a novel machine learning approach for the
prediction of molecular activity on ToxCast targets. We combine extreme
gradient boosting with fully-connected and graph-convolutional neural network
architectures trained on QSAR physical molecular property descriptors, PubChem
molecular fingerprints, and SMILES sequences. Our ensemble predictor leverages
the strengths of each individual technique, significantly outperforming
existing state-of-the art models on the ToxCast and Tox21 toxicity-prediction
datasets. We provide free access to molecule toxicity prediction using our
model at &lt;a href=&quot;http://www.owkin.com/toxicblend.&quot;&gt;this http URL&lt;/a&gt;
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zaslavskiy_M/0/1/0/all/0/1&quot;&gt;Mikhail Zaslavskiy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Jegou_S/0/1/0/all/0/1&quot;&gt;Simon J&amp;#xe9;gou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tramel_E/0/1/0/all/0/1&quot;&gt;Eric W. Tramel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wainrib_G/0/1/0/all/0/1&quot;&gt;Gilles Wainrib&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04458">
<title>Sparse Stochastic Zeroth-Order Optimization with an Application to Bandit Structured Prediction. (arXiv:1806.04458v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.04458</link>
<description rdf:parseType="Literal">&lt;p&gt;Stochastic zeroth-order (SZO), or gradient-free, optimization allows to
optimize arbitrary functions by relying only on function evaluations under
parameter perturbations, however, the iteration complexity of SZO methods
suffers a factor proportional to the dimensionality of the perturbed function.
We show that in scenarios with natural sparsity patterns as in structured
prediction applications, this factor can be reduced to the expected number of
active features over input-output pairs. We give a general proof that applies
sparse SZO optimization to Lipschitz-continuous, nonconvex, stochastic
objectives, and present an experimental evaluation on linear bandit structured
prediction tasks with sparse word-based feature representations that confirm
our theoretical results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sokolov_A/0/1/0/all/0/1&quot;&gt;Artem Sokolov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hitschler_J/0/1/0/all/0/1&quot;&gt;Julian Hitschler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Riezler_S/0/1/0/all/0/1&quot;&gt;Stefan Riezler&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04465">
<title>Gaussian mixture models with Wasserstein distance. (arXiv:1806.04465v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.04465</link>
<description rdf:parseType="Literal">&lt;p&gt;Generative models with both discrete and continuous latent variables are
highly motivated by the structure of many real-world data sets. They present,
however, subtleties in training often manifesting in the discrete latent being
under leveraged. In this paper, we show that such models are more amenable to
training when using the Optimal Transport framework of Wasserstein
Autoencoders. We find our discrete latent variable to be fully leveraged by the
model when trained, without any modifications to the objective function or
significant fine tuning. Our model generates comparable samples to other
approaches while using relatively simple neural networks, since the discrete
latent variable carries much of the descriptive burden. Furthermore, the
discrete latent provides significant control over generation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gaujac_B/0/1/0/all/0/1&quot;&gt;Benoit Gaujac&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Feige_I/0/1/0/all/0/1&quot;&gt;Ilya Feige&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Barber_D/0/1/0/all/0/1&quot;&gt;David Barber&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04472">
<title>Trading algorithms with learning in latent alpha models. (arXiv:1806.04472v1 [q-fin.MF])</title>
<link>http://arxiv.org/abs/1806.04472</link>
<description rdf:parseType="Literal">&lt;p&gt;Alpha signals for statistical arbitrage strategies are often driven by latent
factors. This paper analyses how to optimally trade with latent factors that
cause prices to jump and diffuse. Moreover, we account for the effect of the
trader&apos;s actions on quoted prices and the prices they receive from trading.
Under fairly general assumptions, we demonstrate how the trader can learn the
posterior distribution over the latent states, and explicitly solve the latent
optimal trading problem. We provide a verification theorem, and a methodology
for calibrating the model by deriving a variation of the
expectation-maximization algorithm. To illustrate the efficacy of the optimal
strategy, we demonstrate its performance through simulations and compare it to
strategies which ignore learning in the latent factors. We also provide
calibration results for a particular model using Intel Corporation stock as an
example.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-fin/1/au:+Casgrain_P/0/1/0/all/0/1&quot;&gt;Philippe Casgrain&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-fin/1/au:+Jaimungal_S/0/1/0/all/0/1&quot;&gt;Sebastian Jaimungal&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04480">
<title>Improving latent variable descriptiveness with AutoGen. (arXiv:1806.04480v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.04480</link>
<description rdf:parseType="Literal">&lt;p&gt;Powerful generative models, particularly in Natural Language Modelling, are
commonly trained by maximizing a variational lower bound on the data log
likelihood. These models often suffer from poor use of their latent variable,
with ad-hoc annealing factors used to encourage retention of information in the
latent variable. We discuss an alternative and general approach to latent
variable modelling, based on an objective that combines the data log likelihood
as well as the likelihood of a perfect reconstruction through an autoencoder.
Tying these together ensures by design that the latent variable captures
information about the observations, whilst retaining the ability to generate
well. Interestingly, though this approach is a priori unrelated to VAEs, the
lower bound attained is identical to the standard VAE bound but with the
addition of a simple pre-factor; thus, providing a formal interpretation of the
commonly used, ad-hoc pre-factors in training VAEs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mansbridge_A/0/1/0/all/0/1&quot;&gt;Alex Mansbridge&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Fierimonte_R/0/1/0/all/0/1&quot;&gt;Roberto Fierimonte&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Feige_I/0/1/0/all/0/1&quot;&gt;Ilya Feige&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Barber_D/0/1/0/all/0/1&quot;&gt;David Barber&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04498">
<title>The Unusual Effectiveness of Averaging in GAN Training. (arXiv:1806.04498v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.04498</link>
<description rdf:parseType="Literal">&lt;p&gt;We show empirically that the optimal strategy of parameter averaging in a
minmax convex-concave game setting is also strikingly effective in the non
convex-concave GAN setting, specifically alleviating the convergence issues
associated with cycling behavior observed in GANs. We show that averaging over
generator parameters outside of the trainig loop consistently improves
inception and FID scores on different architectures and for different GAN
objectives. We provide comprehensive experimental results across a range of
datasets, bilinear games, mixture of Gaussians, CIFAR-10, STL-10, CelebA and
ImageNet, to demonstrate its effectiveness. We achieve state-of-the-art results
on CIFAR-10 and produce clean CelebA face images, demonstrating that averaging
is one of the most effective techniques for training highly performant GANs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yazici_Y/0/1/0/all/0/1&quot;&gt;Yasin Yaz&amp;#x131;c&amp;#x131;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Foo_C/0/1/0/all/0/1&quot;&gt;Chuan-Sheng Foo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Winkler_S/0/1/0/all/0/1&quot;&gt;Stefan Winkler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yap_K/0/1/0/all/0/1&quot;&gt;Kim-Hui Yap&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Piliouras_G/0/1/0/all/0/1&quot;&gt;Georgios Piliouras&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chandrasekhar_V/0/1/0/all/0/1&quot;&gt;Vijay Chandrasekhar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04509">
<title>A review on distance based time series classification. (arXiv:1806.04509v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.04509</link>
<description rdf:parseType="Literal">&lt;p&gt;Time series classification is an increasing research topic due to the vast
amount of time series data that are being created over a wide variety of
fields. The particularity of the data makes it a challenging task and different
approaches have been taken, including the distance based approach. 1-NN has
been a widely used method within distance based time series classification due
to it simplicity but still good performance. However, its supremacy may be
attributed to being able to use specific distances for time series within the
classification process and not to the classifier itself. With the aim of
exploiting these distances within more complex classifiers, new approaches have
arisen in the past few years that are competitive or which outperform the 1-NN
based approaches. In some cases, these new methods use the distance measure to
transform the series into feature vectors, bridging the gap between time series
and traditional classifiers. In other cases, the distances are employed to
obtain a time series kernel and enable the use of kernel methods for time
series classification. One of the main challenges is that a kernel function
must be positive semi-definite, a matter that is also addressed within this
review. The presented review includes a taxonomy of all those methods that aim
to classify time series using a distance based approach, as well as a
discussion of the strengths and weaknesses of each method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Abanda_A/0/1/0/all/0/1&quot;&gt;Amaia Abanda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mori_U/0/1/0/all/0/1&quot;&gt;Usue Mori&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lozano_J/0/1/0/all/0/1&quot;&gt;Jose A. Lozano&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04517">
<title>A hybrid econometric-machine learning approach for relative importance analysis: Food inflation. (arXiv:1806.04517v1 [econ.EM])</title>
<link>http://arxiv.org/abs/1806.04517</link>
<description rdf:parseType="Literal">&lt;p&gt;A measure of relative importance of variables is often desired by researchers
when the explanatory aspects of econometric methods are of interest. To this
end, the author briefly reviews the limitations of conventional econometrics in
constructing a reliable measure of variable importance. The author highlights
the relative stature of explanatory and predictive analysis in economics and
the emergence of fruitful collaborations between econometrics and computer
science. Learning lessons from both, the author proposes a hybrid approach
based on conventional econometrics and advanced machine learning (ML)
algorithms, which are otherwise, used in predictive analytics. The purpose of
this article is two-fold, to propose a hybrid approach to assess relative
importance and demonstrate its applicability in addressing policy priority
issues with an example of food inflation in India, followed by a broader aim to
introduce the possibility of conflation of ML and conventional econometrics to
an audience of researchers in economics and social sciences, in general.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/econ/1/au:+Malhotra_A/0/1/0/all/0/1&quot;&gt;Akash Malhotra&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04522">
<title>Meta-Learning for Stochastic Gradient MCMC. (arXiv:1806.04522v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.04522</link>
<description rdf:parseType="Literal">&lt;p&gt;Stochastic gradient Markov chain Monte Carlo (SG-MCMC) has become
increasingly popular for simulating posterior samples in large-scale Bayesian
modeling. However, existing SG-MCMC schemes are not tailored to any specific
probabilistic model, even a simple modification of the underlying dynamical
system requires significant physical intuition. This paper presents the first
meta-learning algorithm that allows automated design for the underlying
continuous dynamics of an SG-MCMC sampler. The learned sampler generalizes
Hamiltonian dynamics with state-dependent drift and diffusion, enabling fast
traversal and efficient exploration of neural network energy landscapes.
Experiments validate the proposed approach on both Bayesian fully connected
neural network and Bayesian recurrent neural network tasks, showing that the
learned sampler out-performs generic, hand-designed SG-MCMC algorithms, and
generalizes to different datasets and larger architectures.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gong_W/0/1/0/all/0/1&quot;&gt;Wenbo Gong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yingzhen Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hernandez_Lobato_J/0/1/0/all/0/1&quot;&gt;Jos&amp;#xe9; Miguel Hern&amp;#xe1;ndez-Lobato&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04542">
<title>Approximate inference with Wasserstein gradient flows. (arXiv:1806.04542v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.04542</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a novel approximate inference method for diffusion processes,
based on the Wasserstein gradient flow formulation of the diffusion. In this
formulation, the time-dependent density of the diffusion is derived as the
limit of implicit Euler steps that follow the gradients of a particular free
energy functional. Existing methods for computing Wasserstein gradient flows
rely on discretization of the domain of the diffusion, prohibiting their
application to domains in more than several dimensions. We propose instead a
discretization-free inference method that computes the Wasserstein gradient
flow directly in a space of continuous functions. We characterize approximation
properties of the proposed method and evaluate it on a nonlinear filtering
task, finding performance comparable to the state-of-the-art for filtering
diffusions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Frogner_C/0/1/0/all/0/1&quot;&gt;Charlie Frogner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Poggio_T/0/1/0/all/0/1&quot;&gt;Tomaso Poggio&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04549">
<title>Early Seizure Detection with an Energy-Efficient Convolutional Neural Network on an Implantable Microcontroller. (arXiv:1806.04549v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.04549</link>
<description rdf:parseType="Literal">&lt;p&gt;Implantable, closed-loop devices for automated early detection and
stimulation of epileptic seizures are promising treatment options for patients
with severe epilepsy that cannot be treated with traditional means. Most
approaches for early seizure detection in the literature are, however, not
optimized for implementation on ultra-low power microcontrollers required for
long-term implantation. In this paper we present a convolutional neural network
for the early detection of seizures from intracranial EEG signals, designed
specifically for this purpose. In addition, we investigate approximations to
comply with hardware limits while preserving accuracy. We compare our approach
to three previously proposed convolutional neural networks and a feature-based
SVM classifier with respect to detection accuracy, latency and computational
needs. Evaluation is based on a comprehensive database with long-term EEG
recordings. The proposed method outperforms the other detectors with a median
sensitivity of 0.96, false detection rate of 10.1 per hour and median detection
delay of 3.7 seconds, while being the only approach suited to be realized on a
low power microcontroller due to its parsimonious use of computational and
memory resources.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hugle_M/0/1/0/all/0/1&quot;&gt;Maria H&amp;#xfc;gle&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Heller_S/0/1/0/all/0/1&quot;&gt;Simon Heller&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Watter_M/0/1/0/all/0/1&quot;&gt;Manuel Watter&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Blum_M/0/1/0/all/0/1&quot;&gt;Manuel Blum&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Manzouri_F/0/1/0/all/0/1&quot;&gt;Farrokh Manzouri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Dumpelmann_M/0/1/0/all/0/1&quot;&gt;Matthias D&amp;#xfc;mpelmann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Schulze_Bonhage_A/0/1/0/all/0/1&quot;&gt;Andreas Schulze-Bonhage&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Woias_P/0/1/0/all/0/1&quot;&gt;Peter Woias&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Boedecker_J/0/1/0/all/0/1&quot;&gt;Joschka Boedecker&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04561">
<title>An Extension of Averaged-Operator-Based Algorithms. (arXiv:1806.04561v1 [math.OC])</title>
<link>http://arxiv.org/abs/1806.04561</link>
<description rdf:parseType="Literal">&lt;p&gt;Many of the algorithms used to solve minimization problems with
sparsity-inducing regularizers are generic in the sense that they do not take
into account the sparsity of the solution in any particular way. However,
algorithms known as semismooth Newton are able to take advantage of this
sparsity to accelerate their convergence. We show how to extend these
algorithms in different directions, and study the convergence of the resulting
algorithms by showing that they are a particular case of an extension of the
well-known Krasnosel&apos;ski\u{\i}--Mann scheme.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Simoes_M/0/1/0/all/0/1&quot;&gt;Miguel Sim&amp;#xf5;es&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Bioucas_Dias_J/0/1/0/all/0/1&quot;&gt;Jos&amp;#xe9; Bioucas-Dias&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Almeida_L/0/1/0/all/0/1&quot;&gt;Luis B. Almeida&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04577">
<title>Using Inherent Structures to design Lean 2-layer RBMs. (arXiv:1806.04577v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.04577</link>
<description rdf:parseType="Literal">&lt;p&gt;Understanding the representational power of Restricted Boltzmann Machines
(RBMs) with multiple layers is an ill-understood problem and is an area of
active research. Motivated from the approach of \emph{Inherent Structure
formalism} (Stillinger &amp;amp; Weber, 1982), extensively used in analysing Spin
Glasses, we propose a novel measure called \emph{Inherent Structure Capacity}
(ISC), which characterizes the representation capacity of a fixed architecture
RBM by the expected number of modes of distributions emanating from the RBM
with parameters drawn from a prior distribution. Though ISC is intractable, we
show that for a single layer RBM architecture ISC approaches a finite constant
as number of hidden units are increased and to further improve the ISC, one
needs to add a second layer. Furthermore, we introduce \emph{Lean} RBMs, which
are multi-layer RBMs where each layer can have at-most $O(n)$ units with the
number of visible units being n. We show that for every single layer RBM with
$\Omega(n^{2+r}), r \ge 0$, hidden units there exists a two-layered \emph{lean}
RBM with $\Theta(n^2)$ parameters with the same ISC, establishing that 2 layer
RBMs can achieve the same representational power as single-layer RBMs but using
far fewer number of parameters. To the best of our knowledge, this is the first
result which quantitatively establishes the need for layering.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bansal_A/0/1/0/all/0/1&quot;&gt;Abhishek Bansal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Anand_A/0/1/0/all/0/1&quot;&gt;Abhinav Anand&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bhattacharyya_C/0/1/0/all/0/1&quot;&gt;Chiranjib Bhattacharyya&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04594">
<title>Exponential Weights on the Hypercube in Polynomial Time. (arXiv:1806.04594v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.04594</link>
<description rdf:parseType="Literal">&lt;p&gt;We address the online linear optimization problem when the decision set is
the entire $\{0,1\}^n$ hypercube. It was previously unknown if it is possible
to run the exponential weights algorithm on this decision set in polynomial
time. In this paper, we show a simple polynomial time algorithm which is
equivalent to running exponential weights on $\{0,1\}^n$. In the Full
Information setting, we show that our algorithm is equivalent to both Exp2 and
Online Mirror Descent with Entropic Regularization. This enables us to prove a
tight regret bound for Exp2 on $\{0,1\}^n$. In the Bandit setting, we show that
our algorithm is equivalent to both Exp2 and OMD with Entropic Regularization
as long as they use the same exploration distribution. In addition, we show a
reduction from the $\{-1,+1\}^n$ hypercube to the $\{0,1\}^n$ hypercube for the
full information and bandit settings. This implies that we can also run
exponential weights on $\{-1,+1\}^n$ in polynomial time, addressing the problem
of sampling from the exponential weights distribution in polynomial time, which
was left as an open question in Bubeck et al. (2012).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Putta_S/0/1/0/all/0/1&quot;&gt;Sudeep Raja Putta&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04609">
<title>Streaming PCA and Subspace Tracking: The Missing Data Case. (arXiv:1806.04609v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.04609</link>
<description rdf:parseType="Literal">&lt;p&gt;For many modern applications in science and engineering, data are collected
in a streaming fashion carrying time-varying information, and practitioners
need to process them with a limited amount of memory and computational
resources in a timely manner for decision making. This often is coupled with
the missing data problem, such that only a small fraction of data attributes
are observed. These complications impose significant, and unconventional,
constraints on the problem of streaming Principal Component Analysis (PCA) and
subspace tracking, which is an essential building block for many inference
tasks in signal processing and machine learning. This survey article reviews a
variety of classical and recent algorithms for solving this problem with low
computational and memory complexities, particularly those applicable in the big
data regime with missing data. We illustrate that streaming PCA and subspace
tracking algorithms can be understood through algebraic and geometric
perspectives, and they need to be adjusted carefully to handle missing data.
Both asymptotic and non-asymptotic convergence guarantees are reviewed.
Finally, we benchmark the performance of several competitive algorithms in the
presence of missing data for both well-conditioned and ill-conditioned systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Balzano_L/0/1/0/all/0/1&quot;&gt;Laura Balzano&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chi_Y/0/1/0/all/0/1&quot;&gt;Yuejie Chi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lu_Y/0/1/0/all/0/1&quot;&gt;Yue M. Lu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04610">
<title>A Novel Bayesian Approach for Latent Variable Modeling from Mixed Data with Missing Values. (arXiv:1806.04610v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.04610</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the problem of learning parameters of latent variable models from
mixed (continuous and ordinal) data with missing values. We propose a novel
Bayesian Gaussian copula factor (BGCF) approach that is consistent under
certain conditions and that is quite robust to the violations of these
conditions. In simulations, BGCF substantially outperforms two state-of-the-art
alternative approaches. An illustration on the `Holzinger &amp;amp; Swineford 1939&apos;
dataset indicates that BGCF is favorable over the so-called robust maximum
likelihood (MLR) even if the data match the assumptions of MLR.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Cui_R/0/1/0/all/0/1&quot;&gt;Ruifei Cui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bucur_I/0/1/0/all/0/1&quot;&gt;Ioan Gabriel Bucur&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Groot_P/0/1/0/all/0/1&quot;&gt;Perry Groot&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Heskes_T/0/1/0/all/0/1&quot;&gt;Tom Heskes&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04613">
<title>Improving Regression Performance with Distributional Losses. (arXiv:1806.04613v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.04613</link>
<description rdf:parseType="Literal">&lt;p&gt;There is growing evidence that converting targets to soft targets in
supervised learning can provide considerable gains in performance. Much of this
work has considered classification, converting hard zero-one values to soft
labels---such as by adding label noise, incorporating label ambiguity or using
distillation. In parallel, there is some evidence from a regression setting in
reinforcement learning that learning distributions can improve performance. In
this work, we investigate the reasons for this improvement, in a regression
setting. We introduce a novel distributional regression loss, and similarly
find it significantly improves prediction accuracy. We investigate several
common hypotheses, around reducing overfitting and improved representations. We
instead find evidence for an alternative hypothesis: this loss is easier to
optimize, with better behaved gradients, resulting in improved generalization.
We provide theoretical support for this alternative hypothesis, by
characterizing the norm of the gradients of this loss.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Imani_E/0/1/0/all/0/1&quot;&gt;Ehsan Imani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+White_M/0/1/0/all/0/1&quot;&gt;Martha White&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04642">
<title>Model-Based Imitation Learning with Accelerated Convergence. (arXiv:1806.04642v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.04642</link>
<description rdf:parseType="Literal">&lt;p&gt;Sample efficiency is critical in solving real-world reinforcement learning
problems, where agent-environment interactions can be costly. Imitation
learning from expert advice has proved to be an effective strategy for reducing
the number of interactions required to train a policy. Online imitation
learning, a specific type of imitation learning that interleaves policy
evaluation and policy optimization, is a particularly effective framework for
training policies with provable performance guarantees. In this work, we seek
to further accelerate the convergence rate of online imitation learning, making
it more sample efficient. We propose two model-based algorithms inspired by
Follow-the-Leader (FTL) with prediction: MoBIL-VI based on solving variational
inequalities and MoBIL-Prox based on stochastic first-order updates. When a
dynamics model is learned online, these algorithms can provably accelerate the
best known convergence rate up to an order. Our algorithms can be viewed as a
generalization of stochastic Mirror-Prox by Juditsky et al. (2011), and admit a
simple constructive FTL-style analysis of performance. The algorithms are also
empirically validated in simulation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_C/0/1/0/all/0/1&quot;&gt;Ching-An Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yan_X/0/1/0/all/0/1&quot;&gt;Xinyan Yan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Theodorou_E/0/1/0/all/0/1&quot;&gt;Evangelos Theodorou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Boots_B/0/1/0/all/0/1&quot;&gt;Byron Boots&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1608.04636">
<title>Linear Convergence of Gradient and Proximal-Gradient Methods Under the Polyak-\L{}ojasiewicz Condition. (arXiv:1608.04636v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1608.04636</link>
<description rdf:parseType="Literal">&lt;p&gt;In 1963, Polyak proposed a simple condition that is sufficient to show a
global linear convergence rate for gradient descent. This condition is a
special case of the \L{}ojasiewicz inequality proposed in the same year, and it
does not require strong convexity (or even convexity). In this work, we show
that this much-older Polyak-\L{}ojasiewicz (PL) inequality is actually weaker
than the main conditions that have been explored to show linear convergence
rates without strong convexity over the last 25 years. We also use the PL
inequality to give new analyses of randomized and greedy coordinate descent
methods, sign-based gradient descent methods, and stochastic gradient methods
in the classic setting (with decreasing or constant step-sizes) as well as the
variance-reduced setting. We further propose a generalization that applies to
proximal-gradient methods for non-smooth optimization, leading to simple proofs
of linear convergence of these methods. Along the way, we give simple
convergence results for a wide variety of problems in machine learning: least
squares, logistic regression, boosting, resilient backpropagation,
L1-regularization, support vector machines, stochastic dual coordinate ascent,
and stochastic variance-reduced gradient methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Karimi_H/0/1/0/all/0/1&quot;&gt;Hamed Karimi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nutini_J/0/1/0/all/0/1&quot;&gt;Julie Nutini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schmidt_M/0/1/0/all/0/1&quot;&gt;Mark Schmidt&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1706.06296">
<title>Approximate Kernel PCA Using Random Features: Computational vs. Statistical Trade-off. (arXiv:1706.06296v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1706.06296</link>
<description rdf:parseType="Literal">&lt;p&gt;Kernel methods are powerful learning methodologies that provide a simple way
to construct nonlinear algorithms from linear ones. Despite their popularity,
they suffer from poor scalability in big data scenarios. Various approximation
methods, including random feature approximation have been proposed to alleviate
the problem. However, the statistical consistency of most of these approximate
kernel methods is not well understood except for kernel ridge regression
wherein it has been shown that the random feature approximation is not only
computationally efficient but also statistically consistent with a minimax
optimal rate of convergence. In this paper, we investigate the efficacy of
random feature approximation in the context of kernel principal component
analysis (KPCA) by studying the trade-off between computational and statistical
behaviors of approximate KPCA. We show that the approximate KPCA is both
computationally and statistically efficient compared to KPCA in terms of the
error associated with reconstructing a kernel function based on its projection
onto the corresponding eigenspaces. Depending on the eigenvalue decay behavior
of the covariance operator, we show that only $n^{2/3}$ features (polynomial
decay) or $\sqrt{n}$ features (exponential decay) are needed to match the
statistical performance of KPCA. We also investigate their statistical
behaviors in terms of the convergence of corresponding eigenspaces wherein we
show that only $\sqrt{n}$ features are required to match the performance of
KPCA and if fewer than $\sqrt{n}$ features are used, then approximate KPCA has
a worse statistical behavior than that of KPCA.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sriperumbudur_B/0/1/0/all/0/1&quot;&gt;Bharath Sriperumbudur&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sterge_N/0/1/0/all/0/1&quot;&gt;Nicholas Sterge&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.00342">
<title>Orthogonal Machine Learning: Power and Limitations. (arXiv:1711.00342v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1711.00342</link>
<description rdf:parseType="Literal">&lt;p&gt;Double machine learning provides $\sqrt{n}$-consistent estimates of
parameters of interest even when high-dimensional or nonparametric nuisance
parameters are estimated at an $n^{-1/4}$ rate. The key is to employ
Neyman-orthogonal moment equations which are first-order insensitive to
perturbations in the nuisance parameters. We show that the $n^{-1/4}$
requirement can be improved to $n^{-1/(2k+2)}$ by employing a $k$-th order
notion of orthogonality that grants robustness to more complex or
higher-dimensional nuisance parameters. In the partially linear regression
setting popular in causal inference, we show that we can construct second-order
orthogonal moments if and only if the treatment residual is not normally
distributed. Our proof relies on Stein&apos;s lemma and may be of independent
interest. We conclude by demonstrating the robustness benefits of an explicit
doubly-orthogonal estimation procedure for treatment effect.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mackey_L/0/1/0/all/0/1&quot;&gt;Lester Mackey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Syrgkanis_V/0/1/0/all/0/1&quot;&gt;Vasilis Syrgkanis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zadik_I/0/1/0/all/0/1&quot;&gt;Ilias Zadik&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.02982">
<title>How To Make the Gradients Small Stochastically: Even Faster Convex and Nonconvex SGD. (arXiv:1801.02982v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1801.02982</link>
<description rdf:parseType="Literal">&lt;p&gt;Stochastic gradient descent (SGD) gives an optimal convergence rate when
minimizing convex stochastic objectives $f(x)$. However, in terms of making the
gradients small, the original SGD does not give an optimal rate, even when
$f(x)$ is convex.
&lt;/p&gt;
&lt;p&gt;If $f(x)$ is convex, to find a point with gradient norm $\varepsilon$, we
design an algorithm SGD3 with a near-optimal rate
$\tilde{O}(\varepsilon^{-2})$, improving the best known rate
$O(\varepsilon^{-8/3})$ of [17].
&lt;/p&gt;
&lt;p&gt;If $f(x)$ is nonconvex, to find its $\varepsilon$-approximate local minimum,
we design an algorithm SGD5 with rate $\tilde{O}(\varepsilon^{-3.5})$, where
previously SGD variants only achieve $\tilde{O}(\varepsilon^{-4})$ [6, 15, 32].
This is no slower than the best known stochastic version of Newton&apos;s method in
all parameter regimes [29].
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Allen_Zhu_Z/0/1/0/all/0/1&quot;&gt;Zeyuan Allen-Zhu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.07756">
<title>Deep Learning for Electromyographic Hand Gesture Signal Classification Using Transfer Learning. (arXiv:1801.07756v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1801.07756</link>
<description rdf:parseType="Literal">&lt;p&gt;In recent years, the use of deep learning algorithms has become increasingly
more prominent for their unparalleled ability to automatically learn
discriminant features from large amounts of data. However, within the field of
electromyography-based gesture recognition, deep learning algorithms are seldom
employed as it requires an unreasonable amount of time for a single person, in
a single session, to generate tens of thousands of examples. This work&apos;s
hypothesis is that general, informative features can be learned from the large
amount of data generated by aggregating the signals of multiple users, thus
reducing the recording burden imposed on a single person while enhancing
gesture recognition. As such, this paper proposes applying transfer learning on
the aggregated data of multiple users, while leveraging the capacity of deep
learning algorithms to learn discriminant features from large dataset, without
the need for in-depth feature engineering. To this end, two datasets are
recorded with the Myo Armband (Thalmic Labs), a low-cost, low-sampling rate
(200Hz), 8-channel, consumer-grade, dry electrode sEMG armband. These two
datasets are comprised of 19 and 17 able-bodied participants respectively. A
third dataset, also recorded with the Myo Armband, was taken from the NinaPro
database and is comprised of 10 able-bodied participants. This transfer
learning scheme is shown to outperform the current state-of-the-art in gesture
recognition. It achieves an average accuracy of 98.31% for 7 hand/wrist
gestures over 17 able-bodied participants and 65.57% for 18 hand/wrist gestures
over 10 able-bodied participants. Finally, a use-case study employing eight
able-bodied participants suggests that real-time feedback reduces the
degradation in accuracy normally experienced over time.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cote_Allard_U/0/1/0/all/0/1&quot;&gt;Ulysse C&amp;#xf4;t&amp;#xe9;-Allard&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fall_C/0/1/0/all/0/1&quot;&gt;Cheikh Latyr Fall&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Drouin_A/0/1/0/all/0/1&quot;&gt;Alexandre Drouin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Campeau_Lecours_A/0/1/0/all/0/1&quot;&gt;Alexandre Campeau-Lecours&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gosselin_C/0/1/0/all/0/1&quot;&gt;Cl&amp;#xe9;ment Gosselin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Glette_K/0/1/0/all/0/1&quot;&gt;Kyrre Glette&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Laviolette_F/0/1/0/all/0/1&quot;&gt;Fran&amp;#xe7;ois Laviolette&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gosselin_B/0/1/0/all/0/1&quot;&gt;Benoit Gosselin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04065">
<title>An experimental study of Bitcoin fluctuation using machine learning methods. (arXiv:1802.04065v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1802.04065</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we study the ability to make the short-term prediction of the
exchange price fluctuations towards the United States dollar for the Bitcoin
market. We use the data of realized volatility collected from one of the
largest Bitcoin digital trading offices in 2016 and 2017 as well as order
information. Experiments are performed to evaluate a variety of statistical and
machine learning approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Guo_T/0/1/0/all/0/1&quot;&gt;Tian Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Antulov_Fantulin_N/0/1/0/all/0/1&quot;&gt;Nino Antulov-Fantulin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05666">
<title>Adversarial Risk and the Dangers of Evaluating Against Weak Attacks. (arXiv:1802.05666v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1802.05666</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper investigates recently proposed approaches for defending against
adversarial examples and evaluating adversarial robustness. We motivate
&apos;adversarial risk&apos; as an objective for achieving models robust to worst-case
inputs. We then frame commonly used attacks and evaluation metrics as defining
a tractable surrogate objective to the true adversarial risk. This suggests
that models may optimize this surrogate rather than the true adversarial risk.
We formalize this notion as &apos;obscurity to an adversary,&apos; and develop tools and
heuristics for identifying obscured models and designing transparent models. We
demonstrate that this is a significant problem in practice by repurposing
gradient-free optimization techniques into adversarial attacks, which we use to
decrease the accuracy of several recently proposed defenses to near zero. Our
hope is that our formulations and results will help researchers to develop more
powerful defenses.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Uesato_J/0/1/0/all/0/1&quot;&gt;Jonathan Uesato&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+ODonoghue_B/0/1/0/all/0/1&quot;&gt;Brendan O&amp;#x27;Donoghue&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oord_A/0/1/0/all/0/1&quot;&gt;Aaron van den Oord&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kohli_P/0/1/0/all/0/1&quot;&gt;Pushmeet Kohli&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.07167">
<title>High-Quality Prediction Intervals for Deep Learning: A Distribution-Free, Ensembled Approach. (arXiv:1802.07167v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1802.07167</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper considers the generation of prediction intervals (PIs) by neural
networks for quantifying uncertainty in regression tasks. It is axiomatic that
high-quality PIs should be as narrow as possible, whilst capturing a specified
portion of data. We derive a loss function directly from this axiom that
requires no distributional assumption. We show how its form derives from a
likelihood principle, that it can be used with gradient descent, and that model
uncertainty is accounted for in ensembled form. Benchmark experiments show the
method outperforms current state-of-the-art uncertainty quantification methods,
reducing average PI width by over 10%.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pearce_T/0/1/0/all/0/1&quot;&gt;Tim Pearce&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zaki_M/0/1/0/all/0/1&quot;&gt;Mohamed Zaki&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Brintrup_A/0/1/0/all/0/1&quot;&gt;Alexandra Brintrup&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Neely_A/0/1/0/all/0/1&quot;&gt;Andy Neely&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08404">
<title>Kernel Recursive ABC: Point Estimation with Intractable Likelihood. (arXiv:1802.08404v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1802.08404</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a novel approach to parameter estimation for simulator-based
statistical models with intractable likelihood. Our proposed method involves
recursive application of kernel ABC and kernel herding to the same observed
data. We provide a theoretical explanation regarding why the approach works,
showing (for the population setting) that, under a certain assumption, point
estimates obtained with this method converge to the true parameter, as
recursion proceeds. We have conducted a variety of numerical experiments,
including parameter estimation for a real-world pedestrian flow simulator, and
show that in most cases our method outperforms existing approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kajihara_T/0/1/0/all/0/1&quot;&gt;Takafumi Kajihara&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kanagawa_M/0/1/0/all/0/1&quot;&gt;Motonobu Kanagawa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yamazaki_K/0/1/0/all/0/1&quot;&gt;Keisuke Yamazaki&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Fukumizu_K/0/1/0/all/0/1&quot;&gt;Kenji Fukumizu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.01905">
<title>Convergence of Gradient Descent on Separable Data. (arXiv:1803.01905v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1803.01905</link>
<description rdf:parseType="Literal">&lt;p&gt;The implicit bias of gradient descent is not fully understood even in simple
linear classification tasks (e.g., logistic regression). Soudry et al. (2018)
studied this bias on separable data, where there are multiple solutions that
correctly classify the data. It was found that, when optimizing monotonically
decreasing loss functions with exponential tails using gradient descent, the
linear classifier specified by the gradient descent iterates converge to the
$L_2$ max margin separator. However, the convergence rate to the maximum margin
solution with fixed step size was found to be extremely slow: $1/\log(t)$.
&lt;/p&gt;
&lt;p&gt;Here we examine how the convergence is influenced by using different loss
functions and by using variable step sizes. First, we calculate the convergence
rate for loss functions with poly-exponential tails near $\exp(-u^{\nu})$. We
prove that $\nu=1$ yields the optimal convergence rate in the range $\nu&amp;gt;0.25$.
Based on further analysis we conjecture that this remains the optimal rate for
$\nu \leq 0.25$, and even for sub-poly-exponential tails --- until loss
functions with polynomial tails no longer converge to the max margin. Second,
we prove the convergence rate could be improved to $(\log t) /\sqrt{t}$ for the
exponential loss, by using aggressive step sizes which compensate for the
rapidly vanishing gradients.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Nacson_M/0/1/0/all/0/1&quot;&gt;Mor Shpigel Nacson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lee_J/0/1/0/all/0/1&quot;&gt;Jason Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gunasekar_S/0/1/0/all/0/1&quot;&gt;Suriya Gunasekar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Savarese_P/0/1/0/all/0/1&quot;&gt;Pedro H. P. Savarese&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Srebro_N/0/1/0/all/0/1&quot;&gt;Nathan Srebro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Soudry_D/0/1/0/all/0/1&quot;&gt;Daniel Soudry&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.11262">
<title>Efficient First-Order Algorithms for Adaptive Signal Denoising. (arXiv:1803.11262v3 [math.ST] UPDATED)</title>
<link>http://arxiv.org/abs/1803.11262</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the problem of discrete-time signal denoising, focusing on a
specific family of non-linear convolution-type estimators. Each such estimator
is associated with a time-invariant filter which is obtained adaptively, by
solving a certain convex optimization problem. Adaptive convolution-type
estimators were demonstrated to have favorable statistical properties. However,
the question of their computational complexity remains largely unexplored, and
in fact we are not aware of any publicly available implementation of these
estimators. Our first contribution is an efficient implementation of these
estimators via some known first-order proximal algorithms. Our second
contribution is a computational complexity analysis of the proposed procedures,
which takes into account their statistical nature and the related notion of
statistical accuracy. The proposed procedures and their analysis are
illustrated on a simulated data benchmark.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Ostrovskii_D/0/1/0/all/0/1&quot;&gt;Dmitrii Ostrovskii&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Harchaoui_Z/0/1/0/all/0/1&quot;&gt;Zaid Harchaoui&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.02395">
<title>Structured Evolution with Compact Architectures for Scalable Policy Optimization. (arXiv:1804.02395v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1804.02395</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a new method of blackbox optimization via gradient approximation
with the use of structured random orthogonal matrices, providing more accurate
estimators than baselines and with provable theoretical guarantees. We show
that this algorithm can be successfully applied to learn better quality compact
policies than those using standard gradient estimation techniques. The compact
policies we learn have several advantages over unstructured ones, including
faster training algorithms and faster inference. These benefits are important
when the policy is deployed on real hardware with limited resources. Further,
compact policies provide more scalable architectures for derivative-free
optimization (DFO) in high-dimensional spaces. We show that most robotics tasks
from the OpenAI Gym can be solved using neural networks with less than 300
parameters, with almost linear time complexity of the inference phase, with up
to 13x fewer parameters relative to the Evolution Strategies (ES) algorithm
introduced by Salimans et al. (2017). We do not need heuristics such as fitness
shaping to learn good quality policies, resulting in a simple and theoretically
motivated training mechanism.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Choromanski_K/0/1/0/all/0/1&quot;&gt;Krzysztof Choromanski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rowland_M/0/1/0/all/0/1&quot;&gt;Mark Rowland&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sindhwani_V/0/1/0/all/0/1&quot;&gt;Vikas Sindhwani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Turner_R/0/1/0/all/0/1&quot;&gt;Richard E. Turner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Weller_A/0/1/0/all/0/1&quot;&gt;Adrian Weller&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.05170">
<title>Model-Free Information Extraction in Enriched Nonlinear Phase-Space. (arXiv:1804.05170v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1804.05170</link>
<description rdf:parseType="Literal">&lt;p&gt;Detecting anomalies and discovering driving signals is an essential component
of scientific research and industrial practice. Often the underlying mechanism
is highly complex, involving hidden evolving nonlinear dynamics and noise
contamination. When representative physical models and large labeled data sets
are unavailable, as is the case with most real-world applications,
model-dependent Bayesian approaches would yield misleading results, and most
supervised learning machines would also fail to reliably resolve the
intricately evolving systems. Here, we propose an unsupervised machine-learning
approach that operates in a well-constructed function space, whereby the
evolving nonlinear dynamics are captured through a linear functional
representation determined by the Koopman operator. This breakthrough leverages
on the time-feature embedding and the ensuing reconstruction of a phase-space
representation of the dynamics, thereby permitting the reliable identification
of critical global signatures from the whole trajectory. This dramatically
improves over commonly used static local features, which are vulnerable to
unknown transitions or noise. Thanks to its data-driven nature, our method
excludes any prior models and training corpus. We benchmark the astonishing
accuracy of our method on three diverse and challenging problems in: biology,
medicine, and engineering. In all cases, it outperforms existing
state-of-the-art methods. As a new unsupervised information processing
paradigm, it is suitable for ubiquitous nonlinear dynamical systems or
end-users with little expertise, which permits an unbiased excavation of
underlying working principles or intrinsic correlations submerged in unlabeled
data flows.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1&quot;&gt;Bin Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lan_Y/0/1/0/all/0/1&quot;&gt;Yueheng Lan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_W/0/1/0/all/0/1&quot;&gt;Weisi Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_C/0/1/0/all/0/1&quot;&gt;Chenglin Zhao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.02587">
<title>Complete Analysis of a Random Forest Model. (arXiv:1805.02587v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1805.02587</link>
<description rdf:parseType="Literal">&lt;p&gt;Random forests have become an important tool for improving accuracy in
regression problems since their popularization by [Breiman, 2001] and others.
In this paper, we revisit a random forest model originally proposed by
[Breiman, 2004] and later studied by [Biau, 2012], where a feature is selected
at random and the split occurs at the midpoint of the box containing the chosen
feature. If the Lipschitz regression function is sparse and only depends on a
small, unknown subset of $S$ out of $d$ features, we show that given $n$
observations, this random forest model outputs a predictor that has a
mean-squared prediction error $O((n(\sqrt{\log
n})^{S-1})^{-\frac{1}{S\log2+1}})$. When $S \leq \lfloor 0.72 d \rfloor$, this
rate is significantly better than the minimax optimal rate
$\Theta(n^{-\frac{2}{d+2}})$ for Lipschitz function classes in $ d $
dimensions. The second part of this article shows that the prediction error for
this random forest model cannot generally be improved. As a striking
consequence of our analysis, we show that if $\ell_{avg}$ (resp. $\ell_{max}$)
is the average (resp. maximum) number of observations per leaf node, then the
variance of this forest is $\Theta(\ell^{-1}_{avg}(\sqrt{\log n})^{-(S-1)})$.
When $S = d$, this variance is similar in form to the best-case variance lower
bound $\Omega(\ell^{-1}_{max}(\log n)^{-(d-1)})$ of [Lin and Jeon, 2006] for
any random forest model with a nonadaptive splitting scheme (i.e., where the
split protocol is independent of the data). We also show that the bias is tight
for any linear model with nonzero parameter vector. Finally, a side consequence
of our analysis is that if the regression function is square-integrable (e.g.,
it need not be continuous or bounded), then the random forest predictor is
pointwise consistent almost everywhere.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Klusowski_J/0/1/0/all/0/1&quot;&gt;Jason M. Klusowski&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.05809">
<title>Efficient end-to-end learning for quantizable representations. (arXiv:1805.05809v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.05809</link>
<description rdf:parseType="Literal">&lt;p&gt;Embedding representation learning via neural networks is at the core
foundation of modern similarity based search. While much effort has been put in
developing algorithms for learning binary hamming code representations for
search efficiency, this still requires a linear scan of the entire dataset per
each query and trades off the search accuracy through binarization. To this
end, we consider the problem of directly learning a quantizable embedding
representation and the sparse binary hash code end-to-end which can be used to
construct an efficient hash table not only providing significant search
reduction in the number of data but also achieving the state of the art search
accuracy outperforming previous state of the art deep metric learning methods.
We also show that finding the optimal sparse binary hash code in a mini-batch
can be computed exactly in polynomial time by solving a minimum cost flow
problem. Our results on Cifar-100 and on ImageNet datasets show the state of
the art search accuracy in precision@k and NMI metrics while providing up to
98X and 478X search speedup respectively over exhaustive linear search. The
source code is available at
https://github.com/maestrojeong/Deep-Hash-Table-ICML18
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jeong_Y/0/1/0/all/0/1&quot;&gt;Yeonwoo Jeong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_H/0/1/0/all/0/1&quot;&gt;Hyun Oh Song&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02185">
<title>Boosting Black Box Variational Inference. (arXiv:1806.02185v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1806.02185</link>
<description rdf:parseType="Literal">&lt;p&gt;Approximating a probability density in a tractable manner is a central task
in Bayesian statistics. Variational Inference (VI) is a popular technique that
achieves tractability by choosing a relatively simple variational family.
Borrowing ideas from the classic boosting framework, recent approaches attempt
to \emph{boost} VI by replacing the selection of a single density with a
greedily constructed mixture of densities. In order to guarantee convergence,
previous works impose stringent assumptions that require significant effort for
practitioners. Specifically, they require a custom implementation of the greedy
step (called the LMO) for every probabilistic model with respect to an
unnatural variational family of truncated distributions. Our work fixes these
issues with novel theoretical and algorithmic insights. On the theoretical
side, we show that boosting VI satisfies a relaxed smoothness assumption which
is sufficient for the convergence of the functional Frank-Wolfe (FW) algorithm.
Furthermore, we rephrase the LMO problem and propose to maximize the Residual
ELBO (RELBO) which replaces the standard ELBO optimization in VI. These
theoretical enhancements allow for black box implementation of the boosting
subroutine. Finally, we present a stopping criterion drawn from the duality gap
in the classic FW analyses and exhaustive experiments to illustrate the
usefulness of our theoretical and algorithmic contributions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Locatello_F/0/1/0/all/0/1&quot;&gt;Francesco Locatello&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Dresdner_G/0/1/0/all/0/1&quot;&gt;Gideon Dresdner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Khanna_R/0/1/0/all/0/1&quot;&gt;Rajiv Khanna&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Valera_I/0/1/0/all/0/1&quot;&gt;Isabel Valera&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ratsch_G/0/1/0/all/0/1&quot;&gt;Gunnar R&amp;#xe4;tsch&lt;/a&gt;</dc:creator>
</item></rdf:RDF>