<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Boring papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Bad Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-06-14T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05236"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05387"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05392"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05098"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06093"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.05192"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.03583"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05180"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05250"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05292"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05337"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05415"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05484"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05502"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05522"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05554"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05631"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05635"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05660"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1611.09414"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.10055"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.07814"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08183"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08322"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05272"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05310"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05356"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05357"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05358"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05382"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05403"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05419"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05437"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05438"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05451"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05490"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05575"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05618"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1702.08420"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1705.05197"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1705.07057"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.02227"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04307"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05214"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06458"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.05589"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.05146"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.10488"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.01811"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04731"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04994"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1806.05236">
<title>Manifold Mixup: Encouraging Meaningful On-Manifold Interpolation as a Regularizer. (arXiv:1806.05236v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.05236</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep networks often perform well on the data manifold on which they are
trained, yet give incorrect (and often very confident) answers when evaluated
on points from off of the training distribution. This is exemplified by the
adversarial examples phenomenon but can also be seen in terms of model
generalization and domain shift. We propose Manifold Mixup which encourages the
network to produce more reasonable and less confident predictions at points
with combinations of attributes not seen in the training set. This is
accomplished by training on convex combinations of the hidden state
representations of data samples. Using this method, we demonstrate improved
semi-supervised learning, learning with limited labeled data, and robustness to
adversarial examples. Manifold Mixup requires no (significant) additional
computation. Analytical experiments on both real data and synthetic data
directly support our hypothesis for why the Manifold Mixup method improves
results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Verma_V/0/1/0/all/0/1&quot;&gt;Vikas Verma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lamb_A/0/1/0/all/0/1&quot;&gt;Alex Lamb&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Beckham_C/0/1/0/all/0/1&quot;&gt;Christopher Beckham&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Courville_A/0/1/0/all/0/1&quot;&gt;Aaron Courville&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mitliagkis_I/0/1/0/all/0/1&quot;&gt;Ioannis Mitliagkis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bengio_Y/0/1/0/all/0/1&quot;&gt;Yoshua Bengio&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05387">
<title>Parameter Learning and Change Detection Using a Particle Filter With Accelerated Adaptation. (arXiv:1806.05387v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.05387</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents the construction of a particle filter, which incorporates
elements inspired by genetic algorithms, in order to achieve accelerated
adaptation of the estimated posterior distribution to changes in model
parameters. Specifically, the filter is designed for the situation where the
subsequent data in online sequential filtering does not match the model
posterior filtered based on data up to a current point in time. The examples
considered encompass parameter regime shifts and stochastic volatility. The
filter adapts to regime shifts extremely rapidly and delivers a clear heuristic
for distinguishing between regime shifts and stochastic volatility, even though
the model dynamics assumed by the filter exhibit neither of those features.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gellert_K/0/1/0/all/0/1&quot;&gt;Karol Gellert&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Schlogl_E/0/1/0/all/0/1&quot;&gt;Erik Schl&amp;#xf6;gl&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05392">
<title>Theory of Estimation-of-Distribution Algorithms. (arXiv:1806.05392v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1806.05392</link>
<description rdf:parseType="Literal">&lt;p&gt;Estimation-of-distribution algorithms (EDAs) are general metaheuristics used
in optimization that represent a more recent alternative to classical
approaches like evolutionary algorithms. In a nutshell, EDAs typically do not
directly evolve populations of search points but build probabilistic models of
promising solutions by repeatedly sampling and selecting points from the
underlying search space. Recently, there has been made significant progress in
the theoretical understanding of EDAs. This article provides an up-to-date
overview of the most commonly analyzed EDAs and the most recent theoretical
results in this area. In particular, emphasis is put on the runtime analysis of
simple univariate EDAs, including a description of typical benchmark functions
and tools for the analysis. Along the way, open problems and directions for
future research are described.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Krejca_M/0/1/0/all/0/1&quot;&gt;Martin S. Krejca&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Witt_C/0/1/0/all/0/1&quot;&gt;Carsten Witt&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05098">
<title>DiCE: The Infinitely Differentiable Monte-Carlo Estimator. (arXiv:1802.05098v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1802.05098</link>
<description rdf:parseType="Literal">&lt;p&gt;The score function estimator is widely used for estimating gradients of
stochastic objectives in stochastic computation graphs (SCG), eg, in
reinforcement learning and meta-learning. While deriving the first-order
gradient estimators by differentiating a surrogate loss (SL) objective is
computationally and conceptually simple, using the same approach for
higher-order derivatives is more challenging. Firstly, analytically deriving
and implementing such estimators is laborious and not compliant with automatic
differentiation. Secondly, repeatedly applying SL to construct new objectives
for each order derivative involves increasingly cumbersome graph manipulations.
Lastly, to match the first-order gradient under differentiation, SL treats part
of the cost as a fixed sample, which we show leads to missing and wrong terms
for estimators of higher-order derivatives. To address all these shortcomings
in a unified way, we introduce DiCE, which provides a single objective that can
be differentiated repeatedly, generating correct estimators of derivatives of
any order in SCGs. Unlike SL, DiCE relies on automatic differentiation for
performing the requisite graph manipulations. We verify the correctness of DiCE
both through a proof and numerical evaluation of the DiCE derivative estimates.
We also use DiCE to propose and evaluate a novel approach for multi-agent
learning. Our code is available at https://goo.gl/xkkGxN.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Foerster_J/0/1/0/all/0/1&quot;&gt;Jakob Foerster&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Farquhar_G/0/1/0/all/0/1&quot;&gt;Gregory Farquhar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Al_Shedivat_M/0/1/0/all/0/1&quot;&gt;Maruan Al-Shedivat&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rocktaschel_T/0/1/0/all/0/1&quot;&gt;Tim Rockt&amp;#xe4;schel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xing_E/0/1/0/all/0/1&quot;&gt;Eric P. Xing&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Whiteson_S/0/1/0/all/0/1&quot;&gt;Shimon Whiteson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06093">
<title>Gradient descent with identity initialization efficiently learns positive definite linear transformations by deep residual networks. (arXiv:1802.06093v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1802.06093</link>
<description rdf:parseType="Literal">&lt;p&gt;We analyze algorithms for approximating a function $f(x) = \Phi x$ mapping
$\Re^d$ to $\Re^d$ using deep linear neural networks, i.e. that learn a
function $h$ parameterized by matrices $\Theta_1,...,\Theta_L$ and defined by
$h(x) = \Theta_L \Theta_{L-1} ... \Theta_1 x$. We focus on algorithms that
learn through gradient descent on the population quadratic loss in the case
that the distribution over the inputs is isotropic.
&lt;/p&gt;
&lt;p&gt;We provide polynomial bounds on the number of iterations for gradient descent
to approximate the least squares matrix $\Phi$, in the case where the initial
hypothesis $\Theta_1 = ... = \Theta_L = I$ has excess loss bounded by a small
enough constant. On the other hand, we show that gradient descent fails to
converge for $\Phi$ whose distance from the identity is a larger constant, and
we show that some forms of regularization toward the identity in each layer do
not help.
&lt;/p&gt;
&lt;p&gt;If $\Phi$ is symmetric positive definite, we show that an algorithm that
initializes $\Theta_i = I$ learns an $\epsilon$-approximation of $f$ using a
number of updates polynomial in $L$, the condition number of $\Phi$, and
$\log(d/\epsilon)$. In contrast, we show that if the least squares matrix
$\Phi$ is symmetric and has a negative eigenvalue, then all members of a class
of algorithms that perform gradient descent with identity initialization, and
optionally regularize toward the identity in each layer, fail to converge.
&lt;/p&gt;
&lt;p&gt;We analyze an algorithm for the case that $\Phi$ satisfies $u^{\top} \Phi u &amp;gt;
0$ for all $u$, but may not be symmetric. This algorithm uses two regularizers:
one that maintains the invariant $u^{\top} \Theta_L \Theta_{L-1} ... \Theta_1 u
&amp;gt; 0$ for all $u$, and another that &quot;balances&quot; $\Theta_1, ..., \Theta_L$ so that
they have the same singular values.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bartlett_P/0/1/0/all/0/1&quot;&gt;Peter L. Bartlett&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Helmbold_D/0/1/0/all/0/1&quot;&gt;David P. Helmbold&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Long_P/0/1/0/all/0/1&quot;&gt;Philip M. Long&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.05192">
<title>Real-time Cardiovascular MR with Spatio-temporal Artifact Suppression using Deep Learning - Proof of Concept in Congenital Heart Disease. (arXiv:1803.05192v3 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1803.05192</link>
<description rdf:parseType="Literal">&lt;p&gt;PURPOSE: Real-time assessment of ventricular volumes requires high
acceleration factors. Residual convolutional neural networks (CNN) have shown
potential for removing artifacts caused by data undersampling. In this study we
investigated the effect of different radial sampling patterns on the accuracy
of a CNN. We also acquired actual real-time undersampled radial data in
patients with congenital heart disease (CHD), and compare CNN reconstruction to
Compressed Sensing (CS).
&lt;/p&gt;
&lt;p&gt;METHODS: A 3D (2D plus time) CNN architecture was developed, and trained
using 2276 gold-standard paired 3D data sets, with 14x radial undersampling.
Four sampling schemes were tested, using 169 previously unseen 3D &apos;synthetic&apos;
test data sets. Actual real-time tiny Golden Angle (tGA) radial SSFP data was
acquired in 10 new patients (122 3D data sets), and reconstructed using the 3D
CNN as well as a CS algorithm; GRASP.
&lt;/p&gt;
&lt;p&gt;RESULTS: Sampling pattern was shown to be important for image quality, and
accurate visualisation of cardiac structures. For actual real-time data,
overall reconstruction time with CNN (including creation of aliased images) was
shown to be more than 5x faster than GRASP. Additionally, CNN image quality and
accuracy of biventricular volumes was observed to be superior to GRASP for the
same raw data.
&lt;/p&gt;
&lt;p&gt;CONCLUSION: This paper has demonstrated the potential for the use of a 3D CNN
for deep de-aliasing of real-time radial data, within the clinical setting.
Clinical measures of ventricular volumes using real-time data with CNN
reconstruction are not statistically significantly different from the
gold-standard, cardiac gated, BH techniques.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hauptmann_A/0/1/0/all/0/1&quot;&gt;Andreas Hauptmann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Arridge_S/0/1/0/all/0/1&quot;&gt;Simon Arridge&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lucka_F/0/1/0/all/0/1&quot;&gt;Felix Lucka&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Muthurangu_V/0/1/0/all/0/1&quot;&gt;Vivek Muthurangu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Steeden_J/0/1/0/all/0/1&quot;&gt;Jennifer A. Steeden&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.03583">
<title>IVUS-Net: An Intravascular Ultrasound Segmentation Network. (arXiv:1806.03583v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1806.03583</link>
<description rdf:parseType="Literal">&lt;p&gt;IntraVascular UltraSound (IVUS) is one of the most effective imaging
modalities that provides assistance to experts in order to diagnose and treat
cardiovascular diseases. We address a central problem in IVUS image analysis
with Fully Convolutional Network (FCN): automatically delineate the lumen and
media-adventitia borders in IVUS images, which is crucial to shorten the
diagnosis process or benefits a faster and more accurate 3D reconstruction of
the artery. Particularly, we propose an FCN architecture, called IVUS-Net,
followed by a post-processing contour extraction step, in order to
automatically segments the interior (lumen) and exterior (media-adventitia)
regions of the human arteries. We evaluated our IVUS-Net on the test set of a
standard publicly available dataset containing 326 IVUS B-mode images with two
measurements, namely Jaccard Measure (JM) and Hausdorff Distances (HD). The
evaluation result shows that IVUS-Net outperforms the state-of-the-art lumen
and media segmentation methods by 4% to 20% in terms of HD distance. IVUS-Net
performs well on images in the test set that contain a significant amount of
major artifacts such as bifurcations, shadows, and side branches that are not
common in the training set. Furthermore, using a modern GPU, IVUS-Net segments
each IVUS frame only in 0.15 seconds. The proposed work, to the best of our
knowledge, is the first deep learning based method for segmentation of both the
lumen and the media vessel walls in 20 MHz IVUS B-mode images that achieves the
best results without any manual intervention. Code is available at
https://github.com/Kulbear/ivus-segmentation-icsm2018
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yang_J/0/1/0/all/0/1&quot;&gt;Ji Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tong_L/0/1/0/all/0/1&quot;&gt;Lin Tong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Faraji_M/0/1/0/all/0/1&quot;&gt;Mehdi Faraji&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Basu_A/0/1/0/all/0/1&quot;&gt;Anup Basu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05180">
<title>A Retrospective Analysis of the Fake News Challenge Stance Detection Task. (arXiv:1806.05180v1 [cs.IR])</title>
<link>http://arxiv.org/abs/1806.05180</link>
<description rdf:parseType="Literal">&lt;p&gt;The 2017 Fake News Challenge Stage 1 (FNC-1) shared task addressed a stance
classification task as a crucial first step towards detecting fake news. To
date, there is no in-depth analysis paper to critically discuss FNC-1&apos;s
experimental setup, reproduce the results, and draw conclusions for
next-generation stance classification methods. In this paper, we provide such
an in-depth analysis for the three top-performing systems. We first find that
FNC-1&apos;s proposed evaluation metric favors the majority class, which can be
easily classified, and thus overestimates the true discriminative power of the
methods. Therefore, we propose a new F1-based metric yielding a changed system
ranking. Next, we compare the features and architectures used, which leads to a
novel feature-rich stacked LSTM model that performs on par with the best
systems, but is superior in predicting minority classes. To understand the
methods&apos; ability to generalize, we derive a new dataset and perform both
in-domain and cross-domain experiments. Our qualitative and quantitative study
helps interpreting the original FNC-1 scores and understand which features help
improving performance and why. Our new dataset and all source code used during
the reproduction study are publicly available for future research.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hanselowski_A/0/1/0/all/0/1&quot;&gt;Andreas Hanselowski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+PVS_A/0/1/0/all/0/1&quot;&gt;Avinesh PVS&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schiller_B/0/1/0/all/0/1&quot;&gt;Benjamin Schiller&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Caspelherr_F/0/1/0/all/0/1&quot;&gt;Felix Caspelherr&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chaudhuri_D/0/1/0/all/0/1&quot;&gt;Debanjan Chaudhuri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meyer_C/0/1/0/all/0/1&quot;&gt;Christian M. Meyer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gurevych_I/0/1/0/all/0/1&quot;&gt;Iryna Gurevych&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05250">
<title>What About Applied Fairness?. (arXiv:1806.05250v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1806.05250</link>
<description rdf:parseType="Literal">&lt;p&gt;Machine learning practitioners are often ambivalent about the ethical aspects
of their products. We believe anything that gets us from that current state to
one in which our systems are achieving some degree of fairness is an
improvement that should be welcomed. This is true even when that progress does
not get us 100% of the way to the goal of &quot;complete&quot; fairness or perfectly
align with our personal belief on which measure of fairness is used. Some
measure of fairness being built would still put us in a better position than
the status quo. Impediments to getting fairness and ethical concerns applied in
real applications, whether they are abstruse philosophical debates or technical
overhead such as the introduction of ever more hyper-parameters, should be
avoided. In this paper we further elaborate on our argument for this viewpoint
and its importance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sylvester_J/0/1/0/all/0/1&quot;&gt;Jared Sylvester&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Raff_E/0/1/0/all/0/1&quot;&gt;Edward Raff&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05292">
<title>Automatic formation of the structure of abstract machines in hierarchical reinforcement learning with state clustering. (arXiv:1806.05292v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1806.05292</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce a new approach to hierarchy formation and task decomposition in
hierarchical reinforcement learning. Our method is based on the Hierarchy Of
Abstract Machines (HAM) framework because HAM approach is able to design
efficient controllers that will realize specific behaviors in real robots. The
key to our algorithm is the introduction of the internal or &quot;mental&quot;
environment in which the state represents the structure of the HAM hierarchy.
The internal action in this environment leads to changes the hierarchy of HAMs.
We propose the classical Q-learning procedure in the internal environment which
allows the agent to obtain an optimal hierarchy. We extends the HAM framework
by adding on-model approach to select the appropriate sub-machine to execute
action sequences for certain class of external environment states. Preliminary
experiments demonstrated the prospects of the method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Panov_A/0/1/0/all/0/1&quot;&gt;Aleksandr I. Panov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Skrynnik_A/0/1/0/all/0/1&quot;&gt;Aleksey Skrynnik&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05337">
<title>Hierarchical interpretations for neural network predictions. (arXiv:1806.05337v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.05337</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep neural networks (DNNs) have achieved impressive predictive performance
due to their ability to learn complex, non-linear relationships between
variables. However, the inability to effectively visualize these relationships
has led to DNNs being characterized as black boxes and consequently limited
their applications. To ameliorate this problem, we introduce the use of
hierarchical interpretations to explain DNN predictions through our proposed
method, agglomerative contextual decomposition (ACD). Given a prediction from a
trained DNN, ACD produces a hierarchical clustering of the input features,
along with the contribution of each cluster to the final prediction. This
hierarchy is optimized to identify clusters of features that the DNN learned
are predictive. Using examples from Stanford Sentiment Treebank and ImageNet,
we show that ACD is effective at diagnosing incorrect predictions and
identifying dataset bias. Through human experiments, we demonstrate that ACD
enables users both to identify the more accurate of two DNNs and to better
trust a DNN&apos;s outputs. We also find that ACD&apos;s hierarchy is largely robust to
adversarial perturbations, implying that it captures fundamental aspects of the
input and ignores spurious noise.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singh_C/0/1/0/all/0/1&quot;&gt;Chandan Singh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Murdoch_W/0/1/0/all/0/1&quot;&gt;W. James Murdoch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_B/0/1/0/all/0/1&quot;&gt;Bin Yu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05415">
<title>Configurable Markov Decision Processes. (arXiv:1806.05415v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1806.05415</link>
<description rdf:parseType="Literal">&lt;p&gt;In many real-world problems, there is the possibility to configure, to a
limited extent, some environmental parameters to improve the performance of a
learning agent. In this paper, we propose a novel framework, Configurable
Markov Decision Processes (Conf-MDPs), to model this new type of interaction
with the environment. Furthermore, we provide a new learning algorithm, Safe
Policy-Model Iteration (SPMI), to jointly and adaptively optimize the policy
and the environment configuration. After having introduced our approach and
derived some theoretical results, we present the experimental evaluation in two
explicative problems to show the benefits of the environment configurability on
the performance of the learned policy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Metelli_A/0/1/0/all/0/1&quot;&gt;Alberto Maria Metelli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mutti_M/0/1/0/all/0/1&quot;&gt;Mirco Mutti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Restelli_M/0/1/0/all/0/1&quot;&gt;Marcello Restelli&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05484">
<title>Nearly Zero-Shot Learning for Semantic Decoding in Spoken Dialogue Systems. (arXiv:1806.05484v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1806.05484</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents two ways of dealing with scarce data in semantic decoding
using N-Best speech recognition hypotheses. First, we learn features by using a
deep learning architecture in which the weights for the unknown and known
categories are jointly optimised. Second, an unsupervised method is used for
further tuning the weights. Sharing weights injects prior knowledge to unknown
categories. The unsupervised tuning (i.e. the risk minimisation) improves the
F-Measure when recognising nearly zero-shot data on the DSTC3 corpus. This
unsupervised method can be applied subject to two assumptions: the rank of the
class marginal is assumed to be known and the class-conditional scores of the
classifier are assumed to follow a Gaussian distribution.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rojas_Barahona_L/0/1/0/all/0/1&quot;&gt;Lina M.Rojas-Barahona&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Casanueva_I/0/1/0/all/0/1&quot;&gt;I&amp;#xf1;igo Casanueva&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Budzianowski_P/0/1/0/all/0/1&quot;&gt;Pawel Budzianowski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ultes_S/0/1/0/all/0/1&quot;&gt;Stefan Ultes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gasic_M/0/1/0/all/0/1&quot;&gt;Milica Gasic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tseng_B/0/1/0/all/0/1&quot;&gt;Bo-Hsiang Tseng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Young_S/0/1/0/all/0/1&quot;&gt;Steve Young&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05502">
<title>Neural Stethoscopes: Unifying Analytic, Auxiliary and Adversarial Network Probing. (arXiv:1806.05502v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.05502</link>
<description rdf:parseType="Literal">&lt;p&gt;Model interpretability and systematic, targeted model adaptation present
central tenets in machine learning for addressing limited or biased datasets.
In this paper, we introduce neural stethoscopes as a framework for quantifying
the degree of importance of specific factors of influence in deep networks as
well as for actively promoting and suppressing information as appropriate. In
doing so we unify concepts from multitask learning as well as training with
auxiliary and adversarial losses. We showcase the efficacy of neural
stethoscopes in an intuitive physics domain. Specifically, we investigate the
challenge of visually predicting stability of block towers and demonstrate that
the network uses visual cues which makes it susceptible to biases in the
dataset. Through the use of stethoscopes we interrogate the accessibility of
specific information throughout the network stack and show that we are able to
actively de-bias network predictions as well as enhance performance via
suitable auxiliary and adversarial stethoscope losses.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Fuchs_F/0/1/0/all/0/1&quot;&gt;Fabian B. Fuchs&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Groth_O/0/1/0/all/0/1&quot;&gt;Oliver Groth&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kosoriek_A/0/1/0/all/0/1&quot;&gt;Adam R. Kosoriek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bewley_A/0/1/0/all/0/1&quot;&gt;Alex Bewley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wulfmeier_M/0/1/0/all/0/1&quot;&gt;Markus Wulfmeier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Vedaldi_A/0/1/0/all/0/1&quot;&gt;Andrea Vedaldi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Posner_I/0/1/0/all/0/1&quot;&gt;Ingmar Posner&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05522">
<title>Improved Density-Based Spatio--Textual Clustering on Social Media. (arXiv:1806.05522v1 [cs.SI])</title>
<link>http://arxiv.org/abs/1806.05522</link>
<description rdf:parseType="Literal">&lt;p&gt;DBSCAN may not be sufficient when the input data type is heterogeneous in
terms of textual description. When we aim to discover clusters of geo-tagged
records relevant to a particular point-of-interest (POI) on social media,
examining only one type of input data (e.g., the tweets relevant to a POI) may
draw an incomplete picture of clusters due to noisy regions. To overcome this
problem, we introduce DBSTexC, a newly defined density-based clustering
algorithm using spatio--textual information. We first characterize POI-relevant
and POI-irrelevant tweets as the texts that include and do not include a POI
name or its semantically coherent variations, respectively. By leveraging the
proportion of POI-relevant and POI-irrelevant tweets, the proposed algorithm
demonstrates much higher clustering performance than the DBSCAN case in terms
of $\mathcal{F}_1$ score and its variants. While DBSTexC performs exactly as
DBSCAN with the textually homogeneous inputs, it far outperforms DBSCAN with
the textually heterogeneous inputs. Furthermore, to further improve the
clustering quality by fully capturing the geographic distribution of tweets, we
present fuzzy DBSTexC (F-DBSTexC), an extension of DBSTexC, which incorporates
the notion of fuzzy clustering into the DBSTexC. We then demonstrate the
robustness of F-DBSTexC via intensive experiments. The computational complexity
of our algorithms is also analytically and numerically shown.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_M/0/1/0/all/0/1&quot;&gt;Minh D. Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shin_W/0/1/0/all/0/1&quot;&gt;Won-Yong Shin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05554">
<title>Adaptive Shooting for Bots in First Person Shooter Games Using Reinforcement Learning. (arXiv:1806.05554v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1806.05554</link>
<description rdf:parseType="Literal">&lt;p&gt;In current state-of-the-art commercial first person shooter games, computer
controlled bots, also known as non player characters, can often be easily
distinguishable from those controlled by humans. Tell-tale signs such as failed
navigation, &quot;sixth sense&quot; knowledge of human players&apos; whereabouts and
deterministic, scripted behaviors are some of the causes of this. We propose,
however, that one of the biggest indicators of non humanlike behavior in these
games can be found in the weapon shooting capability of the bot. Consistently
perfect accuracy and &quot;locking on&quot; to opponents in their visual field from any
distance are indicative capabilities of bots that are not found in human
players. Traditionally, the bot is handicapped in some way with either a timed
reaction delay or a random perturbation to its aim, which doesn&apos;t adapt or
improve its technique over time. We hypothesize that enabling the bot to learn
the skill of shooting through trial and error, in the same way a human player
learns, will lead to greater variation in game-play and produce less
predictable non player characters. This paper describes a reinforcement
learning shooting mechanism for adapting shooting over time based on a dynamic
reward signal from the amount of damage caused to opponents.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Glavin_F/0/1/0/all/0/1&quot;&gt;Frank G. Glavin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Madden_M/0/1/0/all/0/1&quot;&gt;Michael G. Madden&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05631">
<title>Learning in POMDPs with Monte Carlo Tree Search. (arXiv:1806.05631v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1806.05631</link>
<description rdf:parseType="Literal">&lt;p&gt;The POMDP is a powerful framework for reasoning under outcome and information
uncertainty, but constructing an accurate POMDP model is difficult.
Bayes-Adaptive Partially Observable Markov Decision Processes (BA-POMDPs)
extend POMDPs to allow the model to be learned during execution. BA-POMDPs are
a Bayesian RL approach that, in principle, allows for an optimal trade-off
between exploitation and exploration. Unfortunately, BA-POMDPs are currently
impractical to solve for any non-trivial domain. In this paper, we extend the
Monte-Carlo Tree Search method POMCP to BA-POMDPs and show that the resulting
method, which we call BA-POMCP, is able to tackle problems that previous
solution methods have been unable to solve. Additionally, we introduce several
techniques that exploit the BA-POMDP structure to improve the efficiency of
BA-POMCP along with proof of their convergence.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Katt_S/0/1/0/all/0/1&quot;&gt;Sammie Katt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oliehoek_F/0/1/0/all/0/1&quot;&gt;Frans A. Oliehoek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Amato_C/0/1/0/all/0/1&quot;&gt;Christopher Amato&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05635">
<title>Self-Imitation Learning. (arXiv:1806.05635v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.05635</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper proposes Self-Imitation Learning (SIL), a simple off-policy
actor-critic algorithm that learns to reproduce the agent&apos;s past good
decisions. This algorithm is designed to verify our hypothesis that exploiting
past good experiences can indirectly drive deep exploration. Our empirical
results show that SIL significantly improves advantage actor-critic (A2C) on
several hard exploration Atari games and is competitive to the state-of-the-art
count-based exploration methods. We also show that SIL improves proximal policy
optimization (PPO) on MuJoCo tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oh_J/0/1/0/all/0/1&quot;&gt;Junhyuk Oh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1&quot;&gt;Yijie Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1&quot;&gt;Satinder Singh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1&quot;&gt;Honglak Lee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05660">
<title>Interactive Classification for Deep Learning Interpretation. (arXiv:1806.05660v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1806.05660</link>
<description rdf:parseType="Literal">&lt;p&gt;We present an interactive system enabling users to manipulate images to
explore the robustness and sensitivity of deep learning image classifiers.
Using modern web technologies to run in-browser inference, users can remove
image features using inpainting algorithms and obtain new classifications in
real time, which allows them to ask a variety of &quot;what if&quot; questions by
experimentally modifying images and seeing how the model reacts. Our system
allows users to compare and contrast what image regions humans and machine
learning models use for classification, revealing a wide range of surprising
results ranging from spectacular failures (e.g., a &quot;water bottle&quot; image becomes
a &quot;concert&quot; when removing a person) to impressive resilience (e.g., a &quot;baseball
player&quot; image remains correctly classified even without a glove or base). We
demonstrate our system at The 2018 Conference on Computer Vision and Pattern
Recognition (CVPR) for the audience to try it live. Our system is open-sourced
at https://github.com/poloclub/interactive-classification. A video demo is
available at https://youtu.be/llub5GcOF6w.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cabrera_A/0/1/0/all/0/1&quot;&gt;Angel Cabrera&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hohman_F/0/1/0/all/0/1&quot;&gt;Fred Hohman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1&quot;&gt;Jason Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chau_D/0/1/0/all/0/1&quot;&gt;Duen Horng Chau&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1611.09414">
<title>Split-door criterion: Identification of causal effects through auxiliary outcomes. (arXiv:1611.09414v2 [stat.ME] UPDATED)</title>
<link>http://arxiv.org/abs/1611.09414</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a method for estimating causal effects in time series data when
fine-grained information about the outcome of interest is available.
Specifically, we examine what we call the split-door setting, where the outcome
variable can be split into two parts: one that is potentially affected by the
cause being studied and another that is independent of it, with both parts
sharing the same (unobserved) confounders. We show that under these conditions,
the problem of identification reduces to that of testing for independence among
observed variables, and present a method that uses this approach to
automatically find subsets of the data that are causally identified. We
demonstrate the method by estimating the causal impact of Amazon&apos;s recommender
system on traffic to product pages, finding thousands of examples within the
dataset that satisfy the split-door criterion. Unlike past studies based on
natural experiments that were limited to a single product category, our method
applies to a large and representative sample of products viewed on the site. In
line with previous work, we find that the widely-used click-through rate (CTR)
metric overestimates the causal impact of recommender systems; depending on the
product category, we estimate that 50-80\% of the traffic attributed to
recommender systems would have happened even without any recommendations. We
conclude with guidelines for using the split-door criterion as well as a
discussion of other contexts where the method can be applied.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sharma_A/0/1/0/all/0/1&quot;&gt;Amit Sharma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hofman_J/0/1/0/all/0/1&quot;&gt;Jake M. Hofman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Watts_D/0/1/0/all/0/1&quot;&gt;Duncan J. Watts&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.10055">
<title>Features, Projections, and Representation Change for Generalized Planning. (arXiv:1801.10055v4 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1801.10055</link>
<description rdf:parseType="Literal">&lt;p&gt;Generalized planning is concerned with the characterization and computation
of plans that solve many instances at once. In the standard formulation, a
generalized plan is a mapping from feature or observation histories into
actions, assuming that the instances share a common pool of features and
actions. This assumption, however, excludes the standard relational planning
domains where actions and objects change across instances. In this work, we
extend the standard formulation of generalized planning to such domains. This
is achieved by projecting the actions over the features, resulting in a common
set of abstract actions which can be tested for soundness and completeness, and
which can be used for generating general policies such as &quot;if the gripper is
empty, pick the clear block above x and place it on the table&quot; that achieve the
goal clear(x) in any Blocksworld instance. In this policy, &quot;pick the clear
block above x&quot; is an abstract action that may represent the action Unstack(a,
b) in one situation and the action Unstack(b, c) in another. Transformations
are also introduced for computing such policies by means of fully observable
non-deterministic (FOND) planners. The value of generalized representations for
learning general policies is also discussed.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bonet_B/0/1/0/all/0/1&quot;&gt;Blai Bonet&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Geffner_H/0/1/0/all/0/1&quot;&gt;Hector Geffner&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.07814">
<title>Learning to Explain: An Information-Theoretic Perspective on Model Interpretation. (arXiv:1802.07814v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1802.07814</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce instancewise feature selection as a methodology for model
interpretation. Our method is based on learning a function to extract a subset
of features that are most informative for each given example. This feature
selector is trained to maximize the mutual information between selected
features and the response variable, where the conditional distribution of the
response variable given the input is the model to be explained. We develop an
efficient variational approximation to the mutual information, and show the
effectiveness of our method on a variety of synthetic and real data sets using
both quantitative metrics and human evaluation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1&quot;&gt;Jianbo Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_L/0/1/0/all/0/1&quot;&gt;Le Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wainwright_M/0/1/0/all/0/1&quot;&gt;Martin J. Wainwright&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jordan_M/0/1/0/all/0/1&quot;&gt;Michael I. Jordan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08183">
<title>Projection-Free Online Optimization with Stochastic Gradient: From Convexity to Submodularity. (arXiv:1802.08183v4 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1802.08183</link>
<description rdf:parseType="Literal">&lt;p&gt;Online optimization has been a successful framework for solving large-scale
problems under computational constraints and partial information. Current
methods for online convex optimization require either a projection or exact
gradient computation at each step, both of which can be prohibitively expensive
for large-scale applications. At the same time, there is a growing trend of
non-convex optimization in machine learning community and a need for online
methods. Continuous DR-submodular functions, which exhibit a natural
diminishing returns condition, have recently been proposed as a broad class of
non-convex functions which may be efficiently optimized. Although online
methods have been introduced, they suffer from similar problems. In this work,
we propose Meta-Frank-Wolfe, the first online projection-free algorithm that
uses stochastic gradient estimates. The algorithm relies on a careful sampling
of gradients in each round and achieves the optimal $O( \sqrt{T})$ adversarial
regret bounds for convex and continuous submodular optimization. We also
propose One-Shot Frank-Wolfe, a simpler algorithm which requires only a single
stochastic gradient estimate in each round and achieves an $O(T^{2/3})$
stochastic regret bound for convex and continuous submodular optimization. We
apply our methods to develop a novel &quot;lifting&quot; framework for the online
discrete submodular maximization and also see that they outperform current
state-of-the-art techniques on various experiments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chen_L/0/1/0/all/0/1&quot;&gt;Lin Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Harshaw_C/0/1/0/all/0/1&quot;&gt;Christopher Harshaw&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hassani_H/0/1/0/all/0/1&quot;&gt;Hamed Hassani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Karbasi_A/0/1/0/all/0/1&quot;&gt;Amin Karbasi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08322">
<title>Teaching Multiple Concepts to Forgetful Learners. (arXiv:1805.08322v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1805.08322</link>
<description rdf:parseType="Literal">&lt;p&gt;How can we help a forgetful learner learn multiple concepts within a limited
time frame? For long-term learning, it is crucial to devise teaching strategies
that leverage the underlying forgetting mechanisms of the learners. In this
paper, we cast the problem of adaptively teaching a forgetful learner as a
novel discrete optimization problem, where we seek to optimize a natural
objective function that characterizes the learner&apos;s expected performance
throughout the teaching session. We then propose a simple greedy teaching
strategy and derive strong performance guarantees based on two intuitive
data-dependent parameters, which characterize the degree of diminishing returns
of teaching each concept. We show that, given some assumptions of the learner&apos;s
memory model, one can efficiently compute the performance bounds. Furthermore,
we identify parameter settings of our memory models where greedy is guaranteed
to achieve high performance. We have deployed our approach in two concrete
applications, namely (1) an educational app for online vocabulary teaching and
(2) an app for teaching novices how to recognize bird species. We demonstrate
the effectiveness of our algorithm using simulations along with user studies.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hunziker_A/0/1/0/all/0/1&quot;&gt;Anette Hunziker&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yuxin Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aodha_O/0/1/0/all/0/1&quot;&gt;Oisin Mac Aodha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rodriguez_M/0/1/0/all/0/1&quot;&gt;Manuel Gomez Rodriguez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Krause_A/0/1/0/all/0/1&quot;&gt;Andreas Krause&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Perona_P/0/1/0/all/0/1&quot;&gt;Pietro Perona&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yue_Y/0/1/0/all/0/1&quot;&gt;Yisong Yue&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singla_A/0/1/0/all/0/1&quot;&gt;Adish Singla&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05272">
<title>Benchmarks for Image Classification and Other High-dimensional Pattern Recognition Problems. (arXiv:1806.05272v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.05272</link>
<description rdf:parseType="Literal">&lt;p&gt;A good classification method should yield more accurate results than simple
heuristics. But there are classification problems, especially high-dimensional
ones like the ones based on image/video data, for which simple heuristics can
work quite accurately; the structure of the data in such problems is easy to
uncover without any sophisticated or computationally expensive method. On the
other hand, some problems have a structure that can only be found with
sophisticated pattern recognition methods. We are interested in quantifying the
difficulty of a given high-dimensional pattern recognition problem. We consider
the case where the patterns come from two pre-determined classes and where the
objects are represented by points in a high-dimensional vector space. However,
the framework we propose is extendable to an arbitrarily large number of
classes. We propose classification benchmarks based on simple random projection
heuristics. Our benchmarks are 2D curves parameterized by the classification
error and computational cost of these simple heuristics. Each curve divides the
plane into a &quot;positive- gain&quot; and a &quot;negative-gain&quot; region. The latter contains
methods that are ill-suited for the given classification problem. The former is
divided into two by the curve asymptote; methods that lie in the small region
under the curve but right of the asymptote merely provide a computational gain
but no structural advantage over the random heuristics. We prove that the curve
asymptotes are optimal (i.e. at Bayes error) in some cases, and thus no
sophisticated method can provide a structural advantage over the random
heuristics. Such classification problems, an example of which we present in our
numerical experiments, provide poor ground for testing new pattern
classification methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yellamraju_T/0/1/0/all/0/1&quot;&gt;Tarun Yellamraju&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hepp_J/0/1/0/all/0/1&quot;&gt;Jonas Hepp&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Boutin_M/0/1/0/all/0/1&quot;&gt;Mireille Boutin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05310">
<title>Deep Reinforcement Learning for Dynamic Urban Transportation Problems. (arXiv:1806.05310v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.05310</link>
<description rdf:parseType="Literal">&lt;p&gt;We explore the use of deep learning and deep reinforcement learning for
optimization problems in transportation. Many transportation system analysis
tasks are formulated as an optimization problem - such as optimal control
problems in intelligent transportation systems and long term urban planning.
Often transportation models used to represent dynamics of a transportation
system involve large data sets with complex input-output interactions and are
difficult to use in the context of optimization. Use of deep learning
metamodels can produce a lower dimensional representation of those relations
and allow to implement optimization and reinforcement learning algorithms in an
efficient manner. In particular, we develop deep learning models for
calibrating transportation simulators and for reinforcement learning to solve
the problem of optimal scheduling of travelers on the network.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Schultz_L/0/1/0/all/0/1&quot;&gt;Laura Schultz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sokolov_V/0/1/0/all/0/1&quot;&gt;Vadim Sokolov&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05356">
<title>Finding GEMS: Multi-Scale Dictionaries for High-Dimensional Graph Signals. (arXiv:1806.05356v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.05356</link>
<description rdf:parseType="Literal">&lt;p&gt;Modern data introduces new challenges to classic signal processing
approaches, leading to a growing interest in the field of graph signal
processing. A powerful and well established model for real world signals in
various domains is sparse representation over a dictionary, combined with the
ability to train the dictionary from signal examples. This model has been
successfully applied to graph signals as well by integrating the underlying
graph topology into the learned dictionary. Nonetheless, dictionary learning
methods for graph signals are typically restricted to small dimensions due to
the computational constraints that the dictionary learning problem entails, and
due to the direct use of the graph Laplacian matrix. In this paper, we propose
a dictionary learning algorithm that applies to a broader class of graph
signals, and is capable of handling much higher dimensional data. We
incorporate the underlying graph topology both implicitly, by forcing the
learned dictionary atoms to be sparse combinations of graph-wavelet functions,
and explicitly, by adding direct graph constraints to promote smoothness in
both the feature and manifold domains. The resulting atoms are thus adapted to
the data of interest while adhering to the underlying graph structure and
possessing a desired multi-scale property. Experimental results on several
datasets, representing both synthetic and real network data of different
nature, demonstrate the effectiveness of the proposed algorithm for graph
signal processing even in high dimensions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yankelevsky_Y/0/1/0/all/0/1&quot;&gt;Yael Yankelevsky&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Elad_M/0/1/0/all/0/1&quot;&gt;Michael Elad&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05357">
<title>Deep Multi-Output Forecasting: Learning to Accurately Predict Blood Glucose Trajectories. (arXiv:1806.05357v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.05357</link>
<description rdf:parseType="Literal">&lt;p&gt;In many forecasting applications, it is valuable to predict not only the
value of a signal at a certain time point in the future, but also the values
leading up to that point. This is especially true in clinical applications,
where the future state of the patient can be less important than the patient&apos;s
overall trajectory. This requires multi-step forecasting, a forecasting variant
where one aims to predict multiple values in the future simultaneously.
Standard methods to accomplish this can propagate error from prediction to
prediction, reducing quality over the long term. In light of these challenges,
we propose multi-output deep architectures for multi-step forecasting in which
we explicitly model the distribution of future values of the signal over a
prediction horizon. We apply these techniques to the challenging and clinically
relevant task of blood glucose forecasting. Through a series of experiments on
a real-world dataset consisting of 550K blood glucose measurements, we
demonstrate the effectiveness of our proposed approaches in capturing the
underlying signal dynamics. Compared to existing shallow and deep methods, we
find that our proposed approaches improve performance individually and capture
complementary information, leading to a large improvement over the baseline
when combined (4.87 vs. 5.31 absolute percentage error (APE)). Overall, the
results suggest the efficacy of our proposed approach in predicting blood
glucose level and multi-step forecasting more generally.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fox_I/0/1/0/all/0/1&quot;&gt;Ian Fox&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ang_L/0/1/0/all/0/1&quot;&gt;Lynn Ang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jaiswal_M/0/1/0/all/0/1&quot;&gt;Mamta Jaiswal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pop_Busui_R/0/1/0/all/0/1&quot;&gt;Rodica Pop-Busui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wiens_J/0/1/0/all/0/1&quot;&gt;Jenna Wiens&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05358">
<title>Defending Against Saddle Point Attack in Byzantine-Robust Distributed Learning. (arXiv:1806.05358v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.05358</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we study robust large-scale distributed learning in the
presence of saddle points in non-convex loss functions. We consider the
Byzantine setting where some worker machines may have abnormal or even
arbitrary and adversarial behavior. We argue that in the Byzantine setting,
optimizing a non-convex function and escaping saddle points become much more
challenging, even when robust gradient estimators are used. We develop
ByzantinePGD, a robust and communication-efficient algorithm that can provably
escape saddle points and converge to approximate local minimizers. The
iteration complexity of our algorithm in the Byzantine setting matches that of
standard gradient descent in the usual setting. We further provide three robust
aggregation subroutines that can be used in ByzantinePGD, including median,
trimmed mean, and iterative filtering. We characterize their performance in
statistical settings, and argue for their near-optimality in different regimes
including the high dimensional setting.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yin_D/0/1/0/all/0/1&quot;&gt;Dong Yin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yudong Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ramchandran_K/0/1/0/all/0/1&quot;&gt;Kannan Ramchandran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bartlett_P/0/1/0/all/0/1&quot;&gt;Peter Bartlett&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05382">
<title>PCAS: Pruning Channels with Attention Statistics. (arXiv:1806.05382v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.05382</link>
<description rdf:parseType="Literal">&lt;p&gt;To implement deep neural networks on small embedded devices, conventional
techniques use channel pruning looking considering manual compression rate per
layer to reduce parameters. Besides it is difficult to consider the
relationships between layers and it takes a lot of time for deeper models. For
addressing these issues, we propose a new channel pruning technique based on
attention that can evaluate the importance of channels. We improved the method
with the criterion to allow the automatic channel selection using a single
compression rate for the entire model. Experimental results showed that a
parameter reduction of 90.8% and FLOPs reduction of 79.4% was achieved with an
accuracy degradation of around 1% for the compressed ResNet-50 model on the
CIFAR-10 benchmark.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yamamoto_K/0/1/0/all/0/1&quot;&gt;Kohei Yamamoto&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Maeno_K/0/1/0/all/0/1&quot;&gt;Kurato Maeno&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05403">
<title>On the Perceptron&apos;s Compression. (arXiv:1806.05403v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.05403</link>
<description rdf:parseType="Literal">&lt;p&gt;We study and provide exposition to several phenomena that are related to the
perceptron&apos;s compression. One theme concerns modifications of the perceptron
algorithm that yield better guarantees on the margin of the hyperplane it
outputs. These modifications can be useful in training neural networks as well,
and we demonstrate them with some experimental data. In a second theme, we
deduce conclusions from the perceptron&apos;s compression in various contexts.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moran_S/0/1/0/all/0/1&quot;&gt;Shay Moran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nachum_I/0/1/0/all/0/1&quot;&gt;Ido Nachum&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Panasoff_I/0/1/0/all/0/1&quot;&gt;Itai Panasoff&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yehudayoff_A/0/1/0/all/0/1&quot;&gt;Amir Yehudayoff&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05419">
<title>Ranking Recovery from Limited Comparisons using Low-Rank Matrix Completion. (arXiv:1806.05419v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.05419</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper proposes a new method for solving the well-known rank aggregation
problem from pairwise comparisons using the method of low-rank matrix
completion. The partial and noisy data of pairwise comparisons is transformed
into a matrix form. We then use tools from matrix completion, which has served
as a major component in the low-rank completion solution of the Netflix
challenge, to construct the preference of the different objects. In our
approach, the data of multiple comparisons is used to create an estimate of the
probability of object i to win (or be chosen) over object j, where only a
partial set of comparisons between N objects is known. The data is then
transformed into a matrix form for which the noiseless solution has a known
rank of one. An alternating minimization algorithm, in which the target matrix
takes a bilinear form, is then used in combination with maximum likelihood
estimation for both factors. The reconstructed matrix is used to obtain the
true underlying preference intensity. This work demonstrates the improvement of
our proposed algorithm over the current state-of-the-art in both simulated
scenarios and real data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Levy_T/0/1/0/all/0/1&quot;&gt;Tal Levy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Vahid_A/0/1/0/all/0/1&quot;&gt;Alireza Vahid&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Giryes_R/0/1/0/all/0/1&quot;&gt;Raja Giryes&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05437">
<title>ServeNet: A Deep Neural Network for Web Service Classification. (arXiv:1806.05437v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.05437</link>
<description rdf:parseType="Literal">&lt;p&gt;Automated service classification plays a crucial role in service management
such as service discovery, selection, and composition. In recent years, machine
learning techniques have been used for service classification. However, they
can only predict around 10 to 20 service categories due to the quality of
feature engineering and the imbalance problem of service dataset. In this
paper, we present a deep neural network ServeNet with a novel dataset splitting
algorithm to deal with these issues. ServeNet can automatically abstract
low-level representation to high-level features, and then predict service
classification based on the service datasets produced by the proposed splitting
algorithm. To demonstrate the effectiveness of our approach, we conducted a
comprehensive experimental study on 10,000 real-world services in 50
categories. The result shows that ServeNet can achieve higher accuracy than
other machine learning methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1&quot;&gt;Yilong Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_P/0/1/0/all/0/1&quot;&gt;Peng Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ding_L/0/1/0/all/0/1&quot;&gt;Lianchao Ding&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_B/0/1/0/all/0/1&quot;&gt;Bingqing Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1&quot;&gt;Weiru Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05438">
<title>Stochastic Gradient Descent with Exponential Convergence Rates of Expected Classification Errors. (arXiv:1806.05438v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.05438</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider stochastic gradient descent for binary classification problems in
a reproducing kernel Hilbert space. In traditional analysis, it is known that
the expected classification error converges more slowly than the expected risk
even when assuming a low-noise condition on the conditional label
probabilities. Consequently, the resulting rate is sublinear. Therefore, it is
important to consider whether much faster convergence of the expected
classification error can be achieved. In recent research, an exponential
convergence rate for stochastic gradient descent was shown under a strong
low-noise condition, but theoretical analysis of this was limited to the square
loss function, which is somewhat inadequate for binary classification tasks. In
this paper, we show an exponential convergence rate of the expected
classification error in the final phase of learning for a wide class of
differentiable convex loss functions under similar assumptions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Nitanda_A/0/1/0/all/0/1&quot;&gt;Atsushi Nitanda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Suzuki_T/0/1/0/all/0/1&quot;&gt;Taiji Suzuki&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05451">
<title>The committee machine: Computational to statistical gaps in learning a two-layers neural network. (arXiv:1806.05451v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.05451</link>
<description rdf:parseType="Literal">&lt;p&gt;Heuristic tools from statistical physics have been used in the past to locate
the phase transitions and compute the optimal learning and generalization
errors in the teacher-student scenario in multi-layer neural networks. In this
contribution, we provide a rigorous justification of these approaches for a
two-layers neural network model called the committee machine. We also introduce
a version of the approximate message passing (AMP) algorithm for the committee
machine that allows to perform optimal learning in polynomial time for a large
set of parameters. We find that there are regimes in which a low generalization
error is information-theoretically achievable while the AMP algorithm fails to
deliver it, strongly suggesting that no efficient algorithm exists for those
cases, and unveiling a large computational gap.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aubin_B/0/1/0/all/0/1&quot;&gt;Benjamin Aubin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Maillard_A/0/1/0/all/0/1&quot;&gt;Antoine Maillard&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barbier_J/0/1/0/all/0/1&quot;&gt;Jean Barbier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Krzakala_F/0/1/0/all/0/1&quot;&gt;Florent Krzakala&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Macris_N/0/1/0/all/0/1&quot;&gt;Nicolas Macris&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zdeborova_L/0/1/0/all/0/1&quot;&gt;Lenka Zdeborov&amp;#xe1;&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05490">
<title>Inference in Deep Gaussian Processes using Stochastic Gradient Hamiltonian Monte Carlo. (arXiv:1806.05490v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.05490</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep Gaussian Processes (DGPs) are hierarchical generalizations of Gaussian
Pro- cesses that combine well calibrated uncertainty estimates with the high
flexibility of multilayer models. One of the biggest challenges with these
models is that exact inference is intractable. The current state-of-the-art
inference method, Variational Inference (VI), employs a Gaussian approximation
to the posterior distribution. This can be a potentially poor unimodal
approximation of the generally multimodal posterior. In this work, we provide
evidence for the non-Gaussian nature of the posterior and we apply the
Stochastic Gradient Hamiltonian Monte Carlo method to directly sample from it.
To efficiently optimize the hyperparameters, we intro- duce the Moving Window
MCEM algorithm. This results in significantly better predictions at a lower
computational cost than its VI counterpart. Thus our method establishes a new
state-of-the-art for inference in DGPs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Havasi_M/0/1/0/all/0/1&quot;&gt;Marton Havasi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lobato_J/0/1/0/all/0/1&quot;&gt;Jos&amp;#xe9; Miguel Hern&amp;#xe1;ndez Lobato&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Fuentes_J/0/1/0/all/0/1&quot;&gt;Juan Jos&amp;#xe9; Murillo Fuentes&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05575">
<title>Autoregressive Quantile Networks for Generative Modeling. (arXiv:1806.05575v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.05575</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce autoregressive implicit quantile networks (AIQN), a
fundamentally different approach to generative modeling than those commonly
used, that implicitly captures the distribution using quantile regression. AIQN
is able to achieve superior perceptual quality and improvements in evaluation
metrics, without incurring a loss of sample diversity. The method can be
applied to many existing models and architectures. In this work we extend the
PixelCNN model with AIQN and demonstrate results on CIFAR-10 and ImageNet using
Inception score, FID, non-cherry-picked samples, and inpainting results. We
consistently observe that AIQN yields a highly stable algorithm that improves
perceptual quality while maintaining a highly diverse distribution.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ostrovski_G/0/1/0/all/0/1&quot;&gt;Georg Ostrovski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dabney_W/0/1/0/all/0/1&quot;&gt;Will Dabney&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Munos_R/0/1/0/all/0/1&quot;&gt;R&amp;#xe9;mi Munos&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05618">
<title>Stochastic Variance-Reduced Policy Gradient. (arXiv:1806.05618v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.05618</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we propose a novel reinforcement- learning algorithm
consisting in a stochastic variance-reduced version of policy gradient for
solving Markov Decision Processes (MDPs). Stochastic variance-reduced gradient
(SVRG) methods have proven to be very successful in supervised learning.
However, their adaptation to policy gradient is not straightforward and needs
to account for I) a non-concave objective func- tion; II) approximations in the
full gradient com- putation; and III) a non-stationary sampling pro- cess. The
result is SVRPG, a stochastic variance- reduced policy gradient algorithm that
leverages on importance weights to preserve the unbiased- ness of the gradient
estimate. Under standard as- sumptions on the MDP, we provide convergence
guarantees for SVRPG with a convergence rate that is linear under increasing
batch sizes. Finally, we suggest practical variants of SVRPG, and we
empirically evaluate them on continuous MDPs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Papini_M/0/1/0/all/0/1&quot;&gt;Matteo Papini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Binaghi_D/0/1/0/all/0/1&quot;&gt;Damiano Binaghi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Canonaco_G/0/1/0/all/0/1&quot;&gt;Giuseppe Canonaco&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pirotta_M/0/1/0/all/0/1&quot;&gt;Matteo Pirotta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Restelli_M/0/1/0/all/0/1&quot;&gt;Marcello Restelli&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1702.08420">
<title>Embarrassingly Parallel Inference for Gaussian Processes. (arXiv:1702.08420v5 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1702.08420</link>
<description rdf:parseType="Literal">&lt;p&gt;Training Gaussian process-based models typically involves an $ O(N^3)$
computational bottleneck due to inverting the covariance matrix. Popular
methods for overcoming this matrix inversion problem cannot adequately model
all types of latent functions, and are often not parallelizable. However,
judicious choice of model structure can ameliorate this problem. A
mixture-of-experts model that uses a mixture of $K$ Gaussian processes offers
modeling flexibility and opportunities for scalable inference. Our
embarassingly parallel algorithm combines low-dimensional matrix inversions
with importance sampling to yield a flexible, scalable mixture-of-experts model
that offers comparable performance to Gaussian process regression at a much
lower computational cost.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhang_M/0/1/0/all/0/1&quot;&gt;Michael Minyi Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Williamson_S/0/1/0/all/0/1&quot;&gt;Sinead A. Williamson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1705.05197">
<title>Convex Coupled Matrix and Tensor Completion. (arXiv:1705.05197v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1705.05197</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a set of convex low rank inducing norms for a coupled matrices and
tensors (hereafter coupled tensors), which shares information between matrices
and tensors through common modes. More specifically, we propose a mixture of
the overlapped trace norm and the latent norms with the matrix trace norm, and
then, we propose a new completion algorithm based on the proposed norms. A key
advantage of the proposed norms is that it is convex and can find a globally
optimal solution, while existing methods for coupled learning are non-convex.
Furthermore, we analyze the excess risk bounds of the completion model
regularized by our proposed norms which show that our proposed norms can
exploit the low rankness of coupled tensors leading to better bounds compared
to uncoupled norms. Through synthetic and real-world data experiments, we show
that the proposed completion algorithm compares favorably with existing
completion algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wimalawarne_K/0/1/0/all/0/1&quot;&gt;Kishan Wimalawarne&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yamada_M/0/1/0/all/0/1&quot;&gt;Makoto Yamada&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mamitsuka_H/0/1/0/all/0/1&quot;&gt;Hiroshi Mamitsuka&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1705.07057">
<title>Masked Autoregressive Flow for Density Estimation. (arXiv:1705.07057v4 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1705.07057</link>
<description rdf:parseType="Literal">&lt;p&gt;Autoregressive models are among the best performing neural density
estimators. We describe an approach for increasing the flexibility of an
autoregressive model, based on modelling the random numbers that the model uses
internally when generating data. By constructing a stack of autoregressive
models, each modelling the random numbers of the next model in the stack, we
obtain a type of normalizing flow suitable for density estimation, which we
call Masked Autoregressive Flow. This type of flow is closely related to
Inverse Autoregressive Flow and is a generalization of Real NVP. Masked
Autoregressive Flow achieves state-of-the-art performance in a range of
general-purpose density estimation tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Papamakarios_G/0/1/0/all/0/1&quot;&gt;George Papamakarios&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pavlakou_T/0/1/0/all/0/1&quot;&gt;Theo Pavlakou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Murray_I/0/1/0/all/0/1&quot;&gt;Iain Murray&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.02227">
<title>Gradient Layer: Enhancing the Convergence of Adversarial Training for Generative Models. (arXiv:1801.02227v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1801.02227</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a new technique that boosts the convergence of training generative
adversarial networks. Generally, the rate of training deep models reduces
severely after multiple iterations. A key reason for this phenomenon is that a
deep network is expressed using a highly non-convex finite-dimensional model,
and thus the parameter gets stuck in a local optimum. Because of this, methods
often suffer not only from degeneration of the convergence speed but also from
limitations in the representational power of the trained network. To overcome
this issue, we propose an additional layer called the gradient layer to seek a
descent direction in an infinite-dimensional space. Because the layer is
constructed in the infinite-dimensional space, we are not restricted by the
specific model structure of finite-dimensional models. As a result, we can get
out of the local optima in finite-dimensional models and move towards the
global optimal function more directly. In this paper, this phenomenon is
explained from the functional gradient method perspective of the gradient
layer. Interestingly, the optimization procedure using the gradient layer
naturally constructs the deep structure of the network. Moreover, we
demonstrate that this procedure can be regarded as a discretization method of
the gradient flow that naturally reduces the objective function. Finally, the
method is tested using several numerical experiments, which show its fast
convergence.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Nitanda_A/0/1/0/all/0/1&quot;&gt;Atsushi Nitanda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Suzuki_T/0/1/0/all/0/1&quot;&gt;Taiji Suzuki&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04307">
<title>A Fast Proximal Point Method for Computing Wasserstein Distance. (arXiv:1802.04307v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1802.04307</link>
<description rdf:parseType="Literal">&lt;p&gt;Wasserstein distance plays increasingly important roles in machine learning,
stochastic programming and image processing. Major efforts have been under way
to address its high computational complexity, some leading to approximate or
regularized variations such as Sinkhorn distance. However, as we will
demonstrate, regularized variations with large regularization parameter will
degradate the performance in several important machine learning applications,
and small regularization parameter will fail due to numerical stability issues
with existing algorithms. We address this challenge by developing an Inexact
Proximal point method for Optimal Transport (IPOT) with the proximal operator
approximately evaluated at each iteration using projections to the probability
simplex. We prove the algorithm has linear convergence rate. We also apply IPOT
to learning generative models, and generalize the idea of IPOT to a new method
for computing Wasserstein barycenter.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Xie_Y/0/1/0/all/0/1&quot;&gt;Yujia Xie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;Xiangfeng Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wang_R/0/1/0/all/0/1&quot;&gt;Ruijia Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zha_H/0/1/0/all/0/1&quot;&gt;Hongyuan Zha&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05214">
<title>Learning Privacy Preserving Encodings through Adversarial Training. (arXiv:1802.05214v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1802.05214</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a framework to learn privacy-preserving encodings of images (or
other high-dimensional data) to inhibit inference of a chosen private
attribute. Rather than encoding a fixed dataset or inhibiting a fixed
estimator, we aim to to learn an encoding function such that even after this
function is fixed, an estimator with knowledge of the encoding is unable to
learn to accurately predict the private attribute, when generalizing beyond a
training set. We formulate this as adversarial optimization of an encoding
function against a classifier for the private attribute, with both modeled as
deep neural networks. We describe an optimization approach which successfully
yields an encoder that permanently limits inference of the private attribute,
while preserving either a generic notion of information, or the estimation of a
different, desired, attribute. We experimentally validate the efficacy of our
approach on private tasks of real-world complexity, by learning to prevent
detection of scene classes from the Places-365 dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pittaluga_F/0/1/0/all/0/1&quot;&gt;Francesco Pittaluga&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koppal_S/0/1/0/all/0/1&quot;&gt;Sanjeev J. Koppal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chakrabarti_A/0/1/0/all/0/1&quot;&gt;Ayan Chakrabarti&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06458">
<title>A Generative Modeling Approach to Limited Channel ECG Classification. (arXiv:1802.06458v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1802.06458</link>
<description rdf:parseType="Literal">&lt;p&gt;Processing temporal sequences is central to a variety of applications in
health care, and in particular multi-channel Electrocardiogram (ECG) is a
highly prevalent diagnostic modality that relies on robust sequence modeling.
While Recurrent Neural Networks (RNNs) have led to significant advances in
automated diagnosis with time-series data, they perform poorly when models are
trained using a limited set of channels. A crucial limitation of existing
solutions is that they rely solely on discriminative models, which tend to
generalize poorly in such scenarios. In order to combat this limitation, we
develop a generative modeling approach to limited channel ECG classification.
This approach first uses a Seq2Seq model to implicitly generate the missing
channel information, and then uses the latent representation to perform the
actual supervisory task. This decoupling enables the use of unsupervised data
and also provides highly robust metric spaces for subsequent discriminative
learning. Our experiments with the Physionet dataset clearly evidence the
effectiveness of our approach over standard RNNs in disease prediction.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rajan_D/0/1/0/all/0/1&quot;&gt;Deepta Rajan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Thiagarajan_J/0/1/0/all/0/1&quot;&gt;Jayaraman J. Thiagarajan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.05589">
<title>Variational Message Passing with Structured Inference Networks. (arXiv:1803.05589v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1803.05589</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent efforts on combining deep models with probabilistic graphical models
are promising in providing flexible models that are also easy to interpret. We
propose a variational message-passing algorithm for variational inference in
such models. We make three contributions. First, we propose structured
inference networks that incorporate the structure of the graphical model in the
inference network of variational auto-encoders (VAE). Second, we establish
conditions under which such inference networks enable fast amortized inference
similar to VAE. Finally, we derive a variational message passing algorithm to
perform efficient natural-gradient inference while retaining the efficiency of
the amortized inference. By simultaneously enabling structured, amortized, and
natural-gradient inference for deep structured models, our method simplifies
and generalizes existing methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lin_W/0/1/0/all/0/1&quot;&gt;Wu Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hubacher_N/0/1/0/all/0/1&quot;&gt;Nicolas Hubacher&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Khan_M/0/1/0/all/0/1&quot;&gt;Mohammad Emtiyaz Khan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.05146">
<title>A comparison of methods for model selection when estimating individual treatment effects. (arXiv:1804.05146v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1804.05146</link>
<description rdf:parseType="Literal">&lt;p&gt;Practitioners in medicine, business, political science, and other fields are
increasingly aware that decisions should be personalized to each patient,
customer, or voter. A given treatment (e.g. a drug or advertisement) should be
administered only to those who will respond most positively, and certainly not
to those who will be harmed by it. Individual-level treatment effects can be
estimated with tools adapted from machine learning, but different models can
yield contradictory estimates. Unlike risk prediction models, however,
treatment effect models cannot be easily evaluated against each other using a
held-out test set because the true treatment effect itself is never directly
observed. Besides outcome prediction accuracy, several metrics that can
leverage held-out data to evaluate treatment effects models have been proposed,
but they are not widely used. We provide a didactic framework that elucidates
the relationships between the different approaches and compare them all using a
variety of simulations of both randomized and observational data. Our results
show that researchers estimating heterogenous treatment effects need not limit
themselves to a single model-fitting algorithm. Instead of relying on a single
method, multiple models fit by a diverse set of algorithms should be evaluated
against each other using an objective function learned from the validation set.
The model minimizing that objective should be used for estimating the
individual treatment effect for future individuals.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Schuler_A/0/1/0/all/0/1&quot;&gt;Alejandro Schuler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Baiocchi_M/0/1/0/all/0/1&quot;&gt;Michael Baiocchi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tibshirani_R/0/1/0/all/0/1&quot;&gt;Robert Tibshirani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Shah_N/0/1/0/all/0/1&quot;&gt;Nigam Shah&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.10488">
<title>Offline Evaluation of Ranking Policies with Click Models. (arXiv:1804.10488v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1804.10488</link>
<description rdf:parseType="Literal">&lt;p&gt;Many web systems rank and present a list of items to users, from recommender
systems to search and advertising. An important problem in practice is to
evaluate new ranking policies offline and optimize them before they are
deployed. We address this problem by proposing evaluation algorithms for
estimating the expected number of clicks on ranked lists from historical logged
data. The existing algorithms are not guaranteed to be statistically efficient
in our problem because the number of recommended lists can grow exponentially
with their length. To overcome this challenge, we use models of user
interaction with the list of items, the so-called click models, to construct
estimators that learn statistically efficiently. We analyze our estimators and
prove that they are more efficient than the estimators that do not use the
structure of the click model, under the assumption that the click model holds.
We evaluate our estimators in a series of experiments on a real-world dataset
and show that they consistently outperform prior estimators.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1&quot;&gt;Shuai Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abbasi_Yadkori_Y/0/1/0/all/0/1&quot;&gt;Yasin Abbasi-Yadkori&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kveton_B/0/1/0/all/0/1&quot;&gt;Branislav Kveton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Muthukrishnan_S/0/1/0/all/0/1&quot;&gt;S. Muthukrishnan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vinay_V/0/1/0/all/0/1&quot;&gt;Vishwa Vinay&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wen_Z/0/1/0/all/0/1&quot;&gt;Zheng Wen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.01811">
<title>AdaGrad stepsizes: Sharp convergence over nonconvex landscapes, from any initialization. (arXiv:1806.01811v4 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1806.01811</link>
<description rdf:parseType="Literal">&lt;p&gt;Adaptive gradient methods such as AdaGrad and its variants update the
stepsize in stochastic gradient descent on the fly according to the gradients
received along the way; such methods have gained widespread use in large-scale
optimization for their ability to converge robustly, without the need to fine
tune parameters such as the stepsize schedule. Yet, the theoretical guarantees
to date for AdaGrad are for online and convex optimization, which is quite
different from the offline and nonconvex setting where adaptive gradient
methods shine in practice. We bridge this gap by providing strong theoretical
guarantees in batch and stochastic setting, for the convergence of AdaGrad over
smooth, nonconvex landscapes, from any initialization of the stepsize, without
knowledge of Lipschitz constant of the gradient. We show in the stochastic
setting that AdaGrad converges to a stationary point at the optimal
$O(1/\sqrt{N})$ rate (up to a $\log(N)$ factor), and in the batch setting, at
the optimal $O(1/N)$ rate. Moreover, in both settings, the constant in the rate
matches the constant obtained as if the variance of the gradient noise and
Lipschitz constant of the gradient were known in advance and used to tune the
stepsize, up to a logarithmic factor of the mismatch between the optimal
stepsize and the stepsize used to initialize AdaGrad. In particular, our
results imply that AdaGrad is robust to both the unknown Lipschitz constant and
level of stochastic noise on the gradient, in a near-optimal sense. When there
is noise, AdaGrad converges at the rate of $O(1/\sqrt{N})$ with well-tuned
stepsize, and when there is not noise, the same algorithm converges at the rate
of $O(1/N)$ like well-tuned batch gradient descent.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ward_R/0/1/0/all/0/1&quot;&gt;Rachel Ward&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wu_X/0/1/0/all/0/1&quot;&gt;Xiaoxia Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bottou_L/0/1/0/all/0/1&quot;&gt;Leon Bottou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04731">
<title>Deep learning to represent sub-grid processes in climate models. (arXiv:1806.04731v2 [physics.ao-ph] UPDATED)</title>
<link>http://arxiv.org/abs/1806.04731</link>
<description rdf:parseType="Literal">&lt;p&gt;The representation of nonlinear sub-grid processes, especially clouds, has
been a major source of uncertainty in climate models for decades.
Cloud-resolving models better represent many of these processes and can now be
run globally but only for short-term simulations of at most a few years because
of computational limitations. Here we demonstrate that deep learning can be
used to capture many advantages of cloud-resolving modeling at a fraction of
the computational cost. We train a deep neural network to represent all
atmospheric sub-grid processes in a climate model by learning from a
multi-scale model in which convection is treated explicitly. The trained neural
network then replaces the traditional sub-grid parameterizations in a global
general circulation model in which it freely interacts with the resolved
dynamics and the surface-flux scheme. The prognostic multi-year simulations are
stable and closely reproduce not only the mean climate of the cloud-resolving
simulation but also key aspects of variability, including precipitation
extremes and the equatorial wave spectrum. Furthermore, the neural network
approximately conserves energy despite not being explicitly instructed to.
Finally, we show that the neural network parameterization generalizes to new
surface forcing patterns but struggles to cope with temperatures far outside
its training manifold. Our results show the feasibility of using deep learning
for climate model parameterization. In a broader context, we anticipate that
data-driven Earth System Model development could play a key role in reducing
climate prediction uncertainty in the coming decade.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Rasp_S/0/1/0/all/0/1&quot;&gt;Stephan Rasp&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Pritchard_M/0/1/0/all/0/1&quot;&gt;Michael S. Pritchard&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Gentine_P/0/1/0/all/0/1&quot;&gt;Pierre Gentine&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04994">
<title>Only Bayes should learn a manifold (on the estimation of differential geometric structure from data). (arXiv:1806.04994v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1806.04994</link>
<description rdf:parseType="Literal">&lt;p&gt;We investigate learning of the differential geometric structure of a data
manifold embedded in a high-dimensional Euclidean space. We first analyze
kernel-based algorithms and show that under the usual regularizations,
non-probabilistic methods cannot recover the differential geometric structure,
but instead find mostly linear manifolds or spaces equipped with teleports. To
properly learn the differential geometric structure, non-probabilistic methods
must apply regularizations that enforce large gradients, which go against
common wisdom. We repeat the analysis for probabilistic methods and find that
under reasonable priors, the geometric structure can be recovered. Fully
exploiting the recovered structure, however, requires the development of
stochastic extensions to classic Riemannian geometry. We take early steps in
that regard. Finally, we partly extend the analysis to modern models based on
neural networks, thereby highlighting geometric and probabilistic shortcomings
of current deep generative models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hauberg_S/0/1/0/all/0/1&quot;&gt;S&amp;#xf8;ren Hauberg&lt;/a&gt;</dc:creator>
</item></rdf:RDF>