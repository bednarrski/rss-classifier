<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Boring papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Bad Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-05-27T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09874"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10169"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1704.02191"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.01929"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09866"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09880"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09901"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09951"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09964"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09975"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09979"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10000"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10005"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10123"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1708.06832"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.03184"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.10466"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.07632"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.01157"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09864"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09909"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09910"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09916"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09917"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09948"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09949"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09950"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09969"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09978"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09994"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10014"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10050"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10054"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10066"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10074"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10111"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10118"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10122"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10168"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10196"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10204"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10205"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10206"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10211"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10251"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10262"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1602.00522"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1606.04366"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1708.00707"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.01297"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.01193"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.03471"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.06203"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.00857"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.02550"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.03569"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04956"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05451"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.05112"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.04438"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.05981"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1805.09874">
<title>Learning Nonlinear Brain Dynamics: van der Pol Meets LSTM. (arXiv:1805.09874v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.09874</link>
<description rdf:parseType="Literal">&lt;p&gt;Many real-world data sets, especially in biology, are produced by highly
multivariate and nonlinear complex dynamical systems. In this paper, we focus
on brain imaging data, including both calcium imaging and functional MRI data.
Standard vector-autoregressive models are limited by their linearity
assumptions, while nonlinear general-purpose, large-scale temporal models, such
as LSTM networks, typically require large amounts of training data, not always
readily available in biological applications; furthermore, such models have
limited interpretability. We introduce here a novel approach for learning a
nonlinear differential equation model aimed at capturing brain dynamics.
Specifically, we propose a variable-projection optimization approach to
estimate the parameters of the multivariate (coupled) van der Pol oscillator,
and demonstrate that such a model can accurately represent nonlinear dynamics
of the brain data. Furthermore, in order to improve the predictive accuracy
when forecasting future brain-activity time series, we use this analytical
model as an unlimited source of simulated data for pretraining LSTM; such
model-specific data augmentation approach consistently improves LSTM
performance on both calcium and fMRI imaging data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Abrevaya_G/0/1/0/all/0/1&quot;&gt;German Abrevaya&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Aravkin_A/0/1/0/all/0/1&quot;&gt;Aleksandr Aravkin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Cecchi_G/0/1/0/all/0/1&quot;&gt;Guillermo Cecchi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rish_I/0/1/0/all/0/1&quot;&gt;Irina Rish&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Polosecki_P/0/1/0/all/0/1&quot;&gt;Pablo Polosecki&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zheng_P/0/1/0/all/0/1&quot;&gt;Peng Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Dawson_S/0/1/0/all/0/1&quot;&gt;Silvina Ponce Dawson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.10169">
<title>Destructiveness of Lexicographic Parsimony Pressure and Alleviation by a Concatenation Crossover in Genetic Programming. (arXiv:1805.10169v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1805.10169</link>
<description rdf:parseType="Literal">&lt;p&gt;For theoretical analyses there are two specifics distinguishing GP from many
other areas of evolutionary computation. First, the variable size
representations, in particular yielding a possible bloat (i.e. the growth of
individuals with redundant parts). Second, the role and realization of
crossover, which is particularly central in GP due to the tree-based
representation. Whereas some theoretical work on GP has studied the effects of
bloat, crossover had a surprisingly little share in this work. We analyze a
simple crossover operator in combination with local search, where a preference
for small solutions minimizes bloat (lexicographic parsimony pressure); the
resulting algorithm is denoted Concatenation Crossover GP. For this purpose
three variants of the well-studied MAJORITY test function with large plateaus
are considered. We show that the Concatenation Crossover GP can efficiently
optimize these test functions, while local search cannot be efficient for all
three variants independent of employing bloat control.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kotzing_T/0/1/0/all/0/1&quot;&gt;Timo K&amp;#xf6;tzing&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lagodzinski_J/0/1/0/all/0/1&quot;&gt;J.A.Gregor Lagodzinski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lengler_J/0/1/0/all/0/1&quot;&gt;Johannes Lengler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Melnichenko_A/0/1/0/all/0/1&quot;&gt;Anna Melnichenko&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1704.02191">
<title>The (1+$\lambda$) Evolutionary Algorithm with Self-Adjusting Mutation Rate. (arXiv:1704.02191v3 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1704.02191</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a new way to self-adjust the mutation rate in population-based
evolutionary algorithms in discrete search spaces. Roughly speaking, it
consists of creating half the offspring with a mutation rate that is twice the
current mutation rate and the other half with half the current rate. The
mutation rate is then updated to the rate used in that subpopulation which
contains the best offspring.
&lt;/p&gt;
&lt;p&gt;We analyze how the $(1+\lambda)$ evolutionary algorithm with this
self-adjusting mutation rate optimizes the OneMax test function. We prove that
this dynamic version of the $(1+\lambda)$ EA finds the optimum in an expected
optimization time (number of fitness evaluations) of
$O(n\lambda/\log\lambda+n\log n)$. This time is asymptotically smaller than the
optimization time of the classic $(1+\lambda)$ EA. Previous work shows that
this performance is best-possible among all $\lambda$-parallel mutation-based
unbiased black-box algorithms.
&lt;/p&gt;
&lt;p&gt;This result shows that the new way of adjusting the mutation rate can find
optimal dynamic parameter values on the fly. Since our adjustment mechanism is
simpler than the ones previously used for adjusting the mutation rate and does
not have parameters itself, we are optimistic that it will find other
applications.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Doerr_B/0/1/0/all/0/1&quot;&gt;Benjamin Doerr&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Giessen_C/0/1/0/all/0/1&quot;&gt;Christian Gie&amp;#xdf;en&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Witt_C/0/1/0/all/0/1&quot;&gt;Carsten Witt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1&quot;&gt;Jing Yang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.01929">
<title>Superconducting Optoelectronic Neurons I: General Principles. (arXiv:1805.01929v3 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1805.01929</link>
<description rdf:parseType="Literal">&lt;p&gt;The design of neural hardware is informed by the prominence of differentiated
processing and information integration in cognitive systems. The central role
of communication leads to the principal assumption of the hardware platform:
signals between neurons should be optical to enable fanout and communication
with minimal delay. The requirement of energy efficiency leads to the
utilization of superconducting detectors to receive single-photon signals. We
discuss the potential of superconducting optoelectronic hardware to achieve the
spatial and temporal information integration advantageous for cognitive
processing, and we consider physical scaling limits based on light-speed
communication. We introduce the superconducting optoelectronic neurons and
networks that are the subject of the subsequent papers in this series.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shainline_J/0/1/0/all/0/1&quot;&gt;Jeffrey M. Shainline&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Buckley_S/0/1/0/all/0/1&quot;&gt;Sonia M. Buckley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+McCaughan_A/0/1/0/all/0/1&quot;&gt;Adam N. McCaughan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chiles_J/0/1/0/all/0/1&quot;&gt;Jeff Chiles&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mirin_R/0/1/0/all/0/1&quot;&gt;Richard P. Mirin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nam_S/0/1/0/all/0/1&quot;&gt;Sae Woo Nam&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09866">
<title>Pooling of Causal Models under Counterfactual Fairness via Causal Judgement Aggregation. (arXiv:1805.09866v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1805.09866</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper we consider the problem of combining multiple probabilistic
causal models, provided by different experts, under the requirement that the
aggregated model satisfy the criterion of counterfactual fairness. We build
upon the work on causal models and fairness in machine learning, and we express
the problem of combining multiple models within the framework of opinion
pooling. We propose two simple algorithms, grounded in the theory of
counterfactual fairness and causal judgment aggregation, that are guaranteed to
generate aggregated probabilistic causal models respecting the criterion of
fairness, and we compare their behaviors on a toy case study.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zennaro_F/0/1/0/all/0/1&quot;&gt;Fabio Massimo Zennaro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ivanovska_M/0/1/0/all/0/1&quot;&gt;Magdalena Ivanovska&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09880">
<title>On the Computational Complexity of Model Checking for Dynamic Epistemic Logic with S5 Models. (arXiv:1805.09880v1 [cs.CC])</title>
<link>http://arxiv.org/abs/1805.09880</link>
<description rdf:parseType="Literal">&lt;p&gt;Dynamic epistemic logic (DEL) is a logical framework for representing and
reasoning about knowledge change for multiple agents. An important
computational task in this framework is the model checking problem, which has
been shown to be PSPACE-hard even for S5 models and two agents. We answer open
questions in the literature about the complexity of this problem in more
restricted settings. We provide a detailed complexity analysis of the model
checking problem for DEL, where we consider various combinations of
restrictions, such as the number of agents, whether the models are
single-pointed or multi-pointed, and whether postconditions are allowed in the
updates. In particular, we show that the problem is already PSPACE-hard in (1)
the case of one agent, multi-pointed S5 models, and no postconditions, and (2)
the case of two agents, only single-pointed S5 models, and no postconditions.
In addition, we study the setting where only semi-private announcements are
allowed as updates. We show that for this case the problem is already
PSPACE-hard when restricted to two agents and three propositional variables.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Haan_R/0/1/0/all/0/1&quot;&gt;Ronald de Haan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pol_I/0/1/0/all/0/1&quot;&gt;Iris van de Pol&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09901">
<title>Boolean Decision Rules via Column Generation. (arXiv:1805.09901v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1805.09901</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper considers the learning of Boolean rules in either disjunctive
normal form (DNF, OR-of-ANDs, equivalent to decision rule sets) or conjunctive
normal form (CNF, AND-of-ORs) as an interpretable model for classification. An
integer program is formulated to optimally trade classification accuracy for
rule simplicity. Column generation (CG) is used to efficiently search over an
exponential number of candidate clauses (conjunctions or disjunctions) without
the need for heuristic rule mining. This approach also bounds the gap between
the selected rule set and the best possible rule set on the training data. To
handle large datasets, we propose an approximate CG algorithm using
randomization. Compared to three recently proposed alternatives, the CG
algorithm dominates the accuracy-simplicity trade-off in 7 out of 15 datasets.
When maximized for accuracy, CG is competitive with rule learners designed for
this purpose, sometimes finding significantly simpler solutions that are no
less accurate.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dash_S/0/1/0/all/0/1&quot;&gt;Sanjeeb Dash&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gunluk_O/0/1/0/all/0/1&quot;&gt;Oktay G&amp;#xfc;nl&amp;#xfc;k&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wei_D/0/1/0/all/0/1&quot;&gt;Dennis Wei&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09951">
<title>A Data-Driven Approach for Autonomous Motion Planning and Control in Off-Road Driving Scenarios. (arXiv:1805.09951v1 [cs.RO])</title>
<link>http://arxiv.org/abs/1805.09951</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents a novel data-driven approach to vehicle motion planning
and control in off-road driving scenarios. For autonomous off-road driving,
environmental conditions impact terrain traversability as a function of
weather, surface composition, and slope. Geographical information system (GIS)
and National Centers for Environmental Information datasets are processed to
provide this information for interactive planning and control system elements.
A top-level global route planner (GRP) defines optimal waypoints using dynamic
programming (DP). A local path planner (LPP) computes a desired trajectory
between waypoints such that infeasible control states and collisions with
obstacles are avoided. The LPP also updates the GRP with real-time sensing and
control data. A low-level feedback controller applies feedback linearization to
asymptotically track the specified LPP trajectory. Autonomous driving
simulation results are presented for traversal of terrains in Oregon and
Indiana case studies.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rastgoftar_H/0/1/0/all/0/1&quot;&gt;Hossein Rastgoftar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1&quot;&gt;Bingxin Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Atkins_E/0/1/0/all/0/1&quot;&gt;Ella M. Atkins&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09964">
<title>Myopic Bayesian Design of Experiments via Posterior Sampling and Probabilistic Programming. (arXiv:1805.09964v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.09964</link>
<description rdf:parseType="Literal">&lt;p&gt;We design a new myopic strategy for a wide class of sequential design of
experiment (DOE) problems, where the goal is to collect data in order to to
fulfil a certain problem specific goal. Our approach, Myopic Posterior Sampling
(MPS), is inspired by the classical posterior (Thompson) sampling algorithm for
multi-armed bandits and leverages the flexibility of probabilistic programming
and approximate Bayesian inference to address a broad set of problems.
Empirically, this general-purpose strategy is competitive with more specialised
methods in a wide array of DOE tasks, and more importantly, enables addressing
complex DOE goals where no existing method seems applicable. On the theoretical
side, we leverage ideas from adaptive submodularity and reinforcement learning
to derive conditions under which MPS achieves sublinear regret against natural
benchmark policies.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kandasamy_K/0/1/0/all/0/1&quot;&gt;Kirthevasan Kandasamy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Neiswanger_W/0/1/0/all/0/1&quot;&gt;Willie Neiswanger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhang_R/0/1/0/all/0/1&quot;&gt;Reed Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Krishnamurthy_A/0/1/0/all/0/1&quot;&gt;Akshay Krishnamurthy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Schneider_J/0/1/0/all/0/1&quot;&gt;Jeff Schneider&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Poczos_B/0/1/0/all/0/1&quot;&gt;Barnabas Poczos&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09975">
<title>Visceral Machines: Reinforcement Learning with Intrinsic Rewards that Mimic the Human Nervous System. (arXiv:1805.09975v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1805.09975</link>
<description rdf:parseType="Literal">&lt;p&gt;The human autonomic nervous system has evolved over millions of years and is
essential for survival and responding to threats. As people learn to navigate
the world, &quot;fight or flight&quot; responses provide intrinsic feedback about the
potential consequence of action choices (e.g., becoming nervous when close to a
cliff edge or driving fast around a bend.) We present a novel approach to
reinforcement learning that leverages a task-independent intrinsic reward
function that mimics human autonomic nervous system responses based on
peripheral pulse measurements. Our hypothesis is that such reward functions can
circumvent the challenges associated with sparse and skewed rewards in
reinforcement learning settings and can help improve sample efficiency. We test
this in a simulated driving environment and show that it can increase the speed
of learning and reduce the number of collisions during the learning stage.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+McDuff_D/0/1/0/all/0/1&quot;&gt;Daniel McDuff&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kapoor_A/0/1/0/all/0/1&quot;&gt;Ashish Kapoor&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09979">
<title>SOSA: A Lightweight Ontology for Sensors, Observations, Samples, and Actuators. (arXiv:1805.09979v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1805.09979</link>
<description rdf:parseType="Literal">&lt;p&gt;The Sensor, Observation, Sample, and Actuator (SOSA) ontology provides a
formal but lightweight general-purpose specification for modeling the
interaction between the entities involved in the acts of observation,
actuation, and sampling. SOSA is the result of rethinking the W3C-XG Semantic
Sensor Network (SSN) ontology based on changes in scope and target audience,
technical developments, and lessons learned over the past years. SOSA also acts
as a replacement of SSN&apos;s Stimulus Sensor Observation (SSO) core. It has been
developed by the first joint working group of the Open Geospatial Consortium
(OGC) and the World Wide Web Consortium (W3C) on \emph{Spatial Data on the
Web}. In this work, we motivate the need for SOSA, provide an overview of the
main classes and properties, and briefly discuss its integration with the new
release of the SSN ontology as well as various other alignments to
specifications such as OGC&apos;s Observations and Measurements (O\&amp;amp;M),
Dolce-Ultralite (DUL), and other prominent ontologies. We will also touch upon
common modeling problems and application areas related to publishing and
searching observation, sampling, and actuation data on the Web. The SOSA
ontology and standard can be accessed at
\url{https://www.w3.org/TR/vocab-ssn/}.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Janowicz_K/0/1/0/all/0/1&quot;&gt;Krzysztof Janowicz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Haller_A/0/1/0/all/0/1&quot;&gt;Armin Haller&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cox_S/0/1/0/all/0/1&quot;&gt;Simon J D Cox&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Phuoc_D/0/1/0/all/0/1&quot;&gt;Danh Le Phuoc&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lefrancois_M/0/1/0/all/0/1&quot;&gt;Maxime Lefrancois&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.10000">
<title>Virtual-Taobao: Virtualizing Real-world Online Retail Environment for Reinforcement Learning. (arXiv:1805.10000v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1805.10000</link>
<description rdf:parseType="Literal">&lt;p&gt;Applying reinforcement learning in physical-world tasks is extremely
challenging. It is commonly infeasible to sample a large number of trials, as
required by current reinforcement learning methods, in a physical environment.
This paper reports our project on using reinforcement learning for better
commodity search in Taobao, one of the largest online retail platforms and
meanwhile a physical environment with a high sampling cost. Instead of training
reinforcement learning in Taobao directly, we present our approach: first we
build Virtual Taobao, a simulator learned from historical customer behavior
data through the proposed GAN-SD (GAN for Simulating Distributions) and MAIL
(multi-agent adversarial imitation learning), and then we train policies in
Virtual Taobao with no physical costs in which ANC (Action Norm Constraint)
strategy is proposed to reduce over-fitting. In experiments, Virtual Taobao is
trained from hundreds of millions of customers&apos; records, and its properties are
compared with the real environment. The results disclose that Virtual Taobao
faithfully recovers important properties of the real environment. We also show
that the policies trained in Virtual Taobao can have significantly superior
online performance to the traditional supervised approaches. We hope our work
could shed some light on reinforcement learning applications in complex
physical environments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_J/0/1/0/all/0/1&quot;&gt;Jing-Cheng Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1&quot;&gt;Yang Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Da_Q/0/1/0/all/0/1&quot;&gt;Qing Da&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1&quot;&gt;Shi-Yong Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zeng_A/0/1/0/all/0/1&quot;&gt;An-Xiang Zeng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.10005">
<title>Finite Sample Analysis of LSTD with Random Projections and Eligibility Traces. (arXiv:1805.10005v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.10005</link>
<description rdf:parseType="Literal">&lt;p&gt;Policy evaluation with linear function approximation is an important problem
in reinforcement learning. When facing high-dimensional feature spaces, such a
problem becomes extremely hard considering the computation efficiency and
quality of approximations. We propose a new algorithm, LSTD($\lambda$)-RP,
which leverages random projection techniques and takes eligibility traces into
consideration to tackle the above two challenges. We carry out theoretical
analysis of LSTD($\lambda$)-RP, and provide meaningful upper bounds of the
estimation error, approximation error and total generalization error. These
results demonstrate that LSTD($\lambda$)-RP can benefit from random projection
and eligibility traces strategies, and LSTD($\lambda$)-RP can achieve better
performances than prior LSTD-RP and LSTD($\lambda$) algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1&quot;&gt;Haifang Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xia_Y/0/1/0/all/0/1&quot;&gt;Yingce Xia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1&quot;&gt;Wensheng Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.10123">
<title>TADAM: Task dependent adaptive metric for improved few-shot learning. (arXiv:1805.10123v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.10123</link>
<description rdf:parseType="Literal">&lt;p&gt;Few-shot learning has become essential for producing models that generalize
from few examples. In this work, we identify that metric scaling and metric
task conditioning are important to improve the performance of few-shot
algorithms. Our analysis reveals that simple metric scaling completely changes
the nature of few-shot algorithm parameter updates. Metric scaling provides
improvements up to 14% in accuracy for certain metrics on the mini-Imagenet
5-way 5-shot classification task. We further propose a simple and effective way
of conditioning a learner on the task sample set, resulting in learning a
task-dependent metric space. Moreover, we propose and empirically test a
practical end-to-end optimization procedure based on auxiliary task co-training
to learn a task-dependent metric space. The resulting few-shot learning model
based on the task-dependent scaled metric achieves state of the art on
mini-Imagenet. We confirm these results on another few-shot dataset that we
introduce in this paper based on CIFAR100.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oreshkin_B/0/1/0/all/0/1&quot;&gt;Boris N. Oreshkin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lacoste_A/0/1/0/all/0/1&quot;&gt;Alexandre Lacoste&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rodriguez_P/0/1/0/all/0/1&quot;&gt;Pau Rodriguez&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1708.06832">
<title>Learning Anytime Predictions in Neural Networks via Adaptive Loss Balancing. (arXiv:1708.06832v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1708.06832</link>
<description rdf:parseType="Literal">&lt;p&gt;This work considers the trade-off between accuracy and test-time
computational cost of deep neural networks (DNNs) via \emph{anytime}
predictions from auxiliary predictions. Specifically, we optimize auxiliary
losses jointly in an \emph{adaptive} weighted sum, where the weights are
inversely proportional to average of each loss. Intuitively, this balances the
losses to have the same scale. We demonstrate theoretical considerations that
motivate this approach from multiple viewpoints, including connecting it to
optimizing the geometric mean of the expectation of each loss, an objective
that ignores the scale of losses. Experimentally, the adaptive weights induce
more competitive anytime predictions on multiple recognition data-sets and
models than non-adaptive approaches including weighing all losses equally. In
particular, anytime neural networks (ANNs) can achieve the same accuracy faster
using adaptive weights on a small network than using static constant weights on
a large one. For problems with high performance saturation, we also show a
sequence of exponentially deepening ANNscan achieve near-optimal anytime
results at any budget, at the cost of a const fraction of extra computation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1&quot;&gt;Hanzhang Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dey_D/0/1/0/all/0/1&quot;&gt;Debadeepta Dey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hebert_M/0/1/0/all/0/1&quot;&gt;Martial Hebert&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bagnell_J/0/1/0/all/0/1&quot;&gt;J. Andrew Bagnell&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.03184">
<title>On Formalizing Fairness in Prediction with Machine Learning. (arXiv:1710.03184v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1710.03184</link>
<description rdf:parseType="Literal">&lt;p&gt;Machine learning algorithms for prediction are increasingly being used in
critical decisions affecting human lives. Various fairness formalizations, with
no firm consensus yet, are employed to prevent such algorithms from
systematically discriminating against people based on certain attributes
protected by law. The aim of this article is to survey how fairness is
formalized in the machine learning literature for the task of prediction and
present these formalizations with their corresponding notions of distributive
justice from the social sciences literature. We provide theoretical as well as
empirical critiques of these notions from the social sciences literature and
explain how these critiques limit the suitability of the corresponding fairness
formalizations to certain domains. We also suggest two notions of distributive
justice which address some of these critiques and discuss avenues for
prospective fairness formalizations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gajane_P/0/1/0/all/0/1&quot;&gt;Pratik Gajane&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pechenizkiy_M/0/1/0/all/0/1&quot;&gt;Mykola Pechenizkiy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.10466">
<title>Scale-Robust Localization Using General Object Landmarks. (arXiv:1710.10466v2 [cs.RO] UPDATED)</title>
<link>http://arxiv.org/abs/1710.10466</link>
<description rdf:parseType="Literal">&lt;p&gt;Visual localization under large changes in scale is an important capability
in many robotic mapping applications, such as localizing at low altitudes in
maps built at high altitudes, or performing loop closure over long distances.
Existing approaches, however, are robust only up to about a 3x difference in
scale between map and query images.
&lt;/p&gt;
&lt;p&gt;We propose a novel combination of deep-learning-based object features and
state-of-the-art SIFT point-features that yields improved robustness to scale
change. This technique is training-free and class-agnostic, and in principle
can be deployed in any environment out-of-the-box. We evaluate the proposed
technique on the KITTI Odometry benchmark and on a novel dataset of outdoor
images exhibiting changes in visual scale of $7\times$ and greater, which we
have released to the public. Our technique consistently outperforms
localization using either SIFT features or the proposed object features alone,
achieving both greater accuracy and much lower failure rates under large
changes in scale.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Holliday_A/0/1/0/all/0/1&quot;&gt;Andrew Holliday&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dudek_G/0/1/0/all/0/1&quot;&gt;Gregory Dudek&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.07632">
<title>Generating Thematic Chinese Poetry using Conditional Variational Autoencoders with Hybrid Decoders. (arXiv:1711.07632v3 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1711.07632</link>
<description rdf:parseType="Literal">&lt;p&gt;Computer poetry generation is our first step towards computer writing.
Writing must have a theme. The current approaches of using sequence-to-sequence
models with attention often produce non-thematic poems. We present a novel
conditional variational autoencoder with a hybrid decoder adding the
deconvolutional neural networks to the general recurrent neural networks to
fully learn topic information via latent variables. This approach significantly
improves the relevance of the generated poems by representing each line of the
poem not only in a context-sensitive manner but also in a holistic way that is
highly related to the given keyword and the learned topic. A proposed augmented
word2vec model further improves the rhythm and symmetry. Tests show that the
generated poems by our approach are mostly satisfying with regulated rules and
consistent themes, and 73.42% of them receive an Overall score no less than 3
(the highest score is 5).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1&quot;&gt;Xiaopeng Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_X/0/1/0/all/0/1&quot;&gt;Xiaowen Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Suo_S/0/1/0/all/0/1&quot;&gt;Shunda Suo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1&quot;&gt;Ming Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.01157">
<title>Graph Bayesian Optimization: Algorithms, Evaluations and Applications. (arXiv:1805.01157v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1805.01157</link>
<description rdf:parseType="Literal">&lt;p&gt;Network structure optimization is a fundamental task in complex network
analysis. However, almost all the research on Bayesian optimization is aimed at
optimizing the objective functions with vectorial inputs. In this work, we
first present a flexible framework, denoted graph Bayesian optimization, to
handle arbitrary graphs in the Bayesian optimization community. By combining
the proposed framework with graph kernels, it can take full advantage of
implicit graph structural features to supplement explicit features guessed
according to the experience, such as tags of nodes and any attributes of
graphs. The proposed framework can identify which features are more important
during the optimization process. We apply the framework to solve four problems
including two evaluations and two applications to demonstrate its efficacy and
potential applications.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Cui_J/0/1/0/all/0/1&quot;&gt;Jiaxu Cui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yang_B/0/1/0/all/0/1&quot;&gt;Bo Yang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09864">
<title>Inverse POMDP: Inferring What You Think from What You Do. (arXiv:1805.09864v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.09864</link>
<description rdf:parseType="Literal">&lt;p&gt;Complex behaviors are often driven by an internal model, which integrates
sensory information over time and facilitates long-term planning. Inferring the
internal model is a crucial ingredient for interpreting neural activities of
agents and is beneficial for imitation learning. Here we describe a method to
infer an agent&apos;s internal model and dynamic beliefs, and apply it to a
simulated agent performing a foraging task. We assume the agent behaves
rationally according to their understanding of the task and the relevant causal
variables that cannot be fully observed. We model this rational solution as a
Partially Observable Markov Decision Process (POMDP). However, we allow that
the agent may have wrong assumptions about the task, and our method learns
these assumptions from the agent&apos;s actions.Given the agent&apos;s sensory
observations and actions, we learn its internal model by maximum likelihood
estimation over a set of task-relevant parameters. The Markov property of the
POMDP enables us to characterize the transition probabilities between internal
states and iteratively estimate the agent&apos;s policy using a constrained
Expectation-Maximization algorithm. We validate our method on simulated agents
performing suboptimally on a foraging task, and successfully recover the
agent&apos;s actual model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1&quot;&gt;Zhengwei Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schrater_P/0/1/0/all/0/1&quot;&gt;Paul Schrater&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pitkow_X/0/1/0/all/0/1&quot;&gt;Xaq Pitkow&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09909">
<title>Structure Learning from Time Series with False Discovery Control. (arXiv:1805.09909v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.09909</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the Granger causal structure learning problem from time series
data. Granger causal algorithms predict a &apos;Granger causal effect&apos; between two
variables by testing if prediction error of one decreases significantly in the
absence of the other variable among the predictor covariates. Almost all
existing Granger causal algorithms condition on a large number of variables
(all but two variables) to test for effects between a pair of variables. We
propose a new structure learning algorithm called MMPC-p inspired by the well
known MMHC algorithm for non-time series data. We show that under some
assumptions, the algorithm provides false discovery rate control. The algorithm
is sound and complete when given access to perfect directed information testing
oracles. We also outline a novel tester for the linear Gaussian case. We show
through our extensive experiments that the MMPC-p algorithm scales to larger
problems and has improved statistical power compared to existing state of the
art for large sparse graphs. We also apply our algorithm on a global
development dataset and validate our findings with subject matter experts.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pegueroles_B/0/1/0/all/0/1&quot;&gt;Bernat Guillen Pegueroles&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Vinzamuri_B/0/1/0/all/0/1&quot;&gt;Bhanukiran Vinzamuri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Shanmugam_K/0/1/0/all/0/1&quot;&gt;Karthikeyan Shanmugam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hedden_S/0/1/0/all/0/1&quot;&gt;Steve Hedden&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Moyer_J/0/1/0/all/0/1&quot;&gt;Jonathan D. Moyer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Varshney_K/0/1/0/all/0/1&quot;&gt;Kush R. Varshney&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09910">
<title>Fairness GAN. (arXiv:1805.09910v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.09910</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we introduce the Fairness GAN, an approach for generating a
dataset that is plausibly similar to a given multimedia dataset, but is more
fair with respect to protected attributes in allocative decision making. We
propose a novel auxiliary classifier GAN that strives for demographic parity or
equality of opportunity and show empirical results on several datasets,
including the CelebFaces Attributes (CelebA) dataset, the Quick, Draw!\
dataset, and a dataset of soccer player images and the offenses they were
called for. The proposed formulation is well-suited to absorbing unlabeled
data; we leverage this to augment the soccer dataset with the much larger
CelebA dataset. The methodology tends to improve demographic parity and
equality of opportunity while generating plausible images.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sattigeri_P/0/1/0/all/0/1&quot;&gt;Prasanna Sattigeri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hoffman_S/0/1/0/all/0/1&quot;&gt;Samuel C. Hoffman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chenthamarakshan_V/0/1/0/all/0/1&quot;&gt;Vijil Chenthamarakshan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Varshney_K/0/1/0/all/0/1&quot;&gt;Kush R. Varshney&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09916">
<title>Basket Completion with Multi-task Determinantal Point Processes. (arXiv:1805.09916v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.09916</link>
<description rdf:parseType="Literal">&lt;p&gt;Determinantal point processes (DPPs) have received significant attention in
the recent years as an elegant model for a variety of machine learning tasks,
due to their ability to elegantly model set diversity and item quality or
popularity. Recent work has shown that DPPs can be effective models for product
recommendation and basket completion tasks. We present an enhanced DPP model
that is specialized for the task of basket completion, the multi-task DPP. We
view the basket completion problem as a multi-class classification problem, and
leverage ideas from tensor factorization and multi-class classification to
design the multi-task DPP model. We evaluate our model on several real-world
datasets, and find that the multi-task DPP provides significantly better
predictive quality than a number of state-of-the-art models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Warlop_R/0/1/0/all/0/1&quot;&gt;Romain Warlop&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mary_J/0/1/0/all/0/1&quot;&gt;J&amp;#xe9;r&amp;#xe9;mie Mary&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gartrell_M/0/1/0/all/0/1&quot;&gt;Mike Gartrell&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09917">
<title>Machine-learning prediction of fluid variables from data using reservoir computing. (arXiv:1805.09917v1 [physics.comp-ph])</title>
<link>http://arxiv.org/abs/1805.09917</link>
<description rdf:parseType="Literal">&lt;p&gt;We predict both microscopic and macroscopic variables of a chaotic fluid flow
using reservoir computing. In our procedure of the prediction, we assume no
prior knowledge of physical model describing a fluid flow except that its
behavior is complex but deterministic. We present two ways of prediction of the
complex behavior; the first called partial-prediction requires continued
knowledge of partial time-series data during the prediction as well as past
time-series data, while the second called full-prediction requires only past
time-series data as training data. For the first case, we are able to predict
long-time motion of microscopic fluid variables. For the second case, we show
that the reservoir dynamics constructed from only past data of energy functions
can predict the future behavior of energy functions and reproduce the energy
spectrum. This implies that the obtained reservoir system constructed without
the knowledge of microscopic data is equivalent to the dynamical system
describing macroscopic behavior of energy functions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Nakai_K/0/1/0/all/0/1&quot;&gt;Kengo Nakai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Saiki_Y/0/1/0/all/0/1&quot;&gt;Yoshitaka Saiki&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09948">
<title>How Many Machines Can We Use in Parallel Computing for Kernel Ridge Regression?. (arXiv:1805.09948v1 [math.ST])</title>
<link>http://arxiv.org/abs/1805.09948</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper attempts to solve a basic problem in distributed statistical
inference: how many machines can we use in parallel computing? In kernel ridge
regression, we address this question in two important settings: nonparametric
estimation and hypothesis testing. Specifically, we find a range for the number
of machines under which optimal estimation/testing is achievable. The employed
empirical processes method provides a unified framework, that allows us to
handle various regression problems (such as thin-plate splines and
nonparametric additive regression) under different settings (such as
univariate, multivariate and diverging-dimensional designs). It is worth noting
that the upper bounds of the number of machines are proven to be un-improvable
(up to a logarithmic factor) in two important cases: smoothing spline
regression and Gaussian RKHS regression. Our theoretical findings are backed by
thorough numerical studies.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Liu_M/0/1/0/all/0/1&quot;&gt;Meimei Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Shang_Z/0/1/0/all/0/1&quot;&gt;Zuofeng Shang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Cheng_G/0/1/0/all/0/1&quot;&gt;Guang Cheng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09949">
<title>Topological Data Analysis of Decision Boundaries with Application to Model Selection. (arXiv:1805.09949v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.09949</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose the labeled \v{C}ech complex, the plain labeled Vietoris-Rips
complex, and the locally scaled labeled Vietoris-Rips complex to perform
persistent homology inference of decision boundaries in classification tasks.
We provide theoretical conditions and analysis for recovering the homology of a
decision boundary from samples. Our main objective is quantification of deep
neural network complexity to enable matching of datasets to pre-trained models;
we report results for experiments using MNIST, FashionMNIST, and CIFAR10.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ramamurthy_K/0/1/0/all/0/1&quot;&gt;Karthikeyan Natesan Ramamurthy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Varshney_K/0/1/0/all/0/1&quot;&gt;Kush R. Varshney&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mody_K/0/1/0/all/0/1&quot;&gt;Krishnan Mody&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09950">
<title>Early Stopping for Nonparametric Testing. (arXiv:1805.09950v1 [math.ST])</title>
<link>http://arxiv.org/abs/1805.09950</link>
<description rdf:parseType="Literal">&lt;p&gt;Early stopping of iterative algorithms is an algorithmic regularization
method to avoid over-fitting in estimation and classification. In this paper,
we show that early stopping can also be applied to obtain the minimax optimal
testing in a general non-parametric setup. Specifically, a Wald-type test
statistic is obtained based on an iterated estimate produced by functional
gradient descent algorithms in a reproducing kernel Hilbert space. A notable
contribution is to establish a &quot;sharp&quot; stopping rule: when the number of
iterations achieves an optimal order, testing optimality is achievable;
otherwise, testing optimality becomes impossible. As a by-product, a similar
sharpness result is also derived for minimax optimal estimation under early
stopping studied in [11] and [19]. All obtained results hold for various kernel
classes, including Sobolev smoothness classes and Gaussian kernel classes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Liu_M/0/1/0/all/0/1&quot;&gt;Meimei Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Cheng_G/0/1/0/all/0/1&quot;&gt;Guang Cheng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09969">
<title>Towards More Efficient Stochastic Decentralized Learning: Faster Convergence and Sparse Communication. (arXiv:1805.09969v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.09969</link>
<description rdf:parseType="Literal">&lt;p&gt;Recently, the decentralized optimization problem is attracting growing
attention. Most existing methods are deterministic with high per-iteration cost
and have a convergence rate quadratically depending on the problem condition
number. Besides, the dense communication is necessary to ensure the convergence
even if the dataset is sparse. In this paper, we generalize the decentralized
optimization problem to a monotone operator root finding problem, and propose a
stochastic algorithm named DSBA that (i) converges geometrically with a rate
linearly depending on the problem condition number, and (ii) can be implemented
using sparse communication only. Additionally, DSBA handles learning problems
like AUC-maximization which cannot be tackled efficiently in the decentralized
setting. Experiments on convex minimization and AUC-maximization validate the
efficiency of our method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Shen_Z/0/1/0/all/0/1&quot;&gt;Zebang Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mokhtari_A/0/1/0/all/0/1&quot;&gt;Aryan Mokhtari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhou_T/0/1/0/all/0/1&quot;&gt;Tengfei Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhao_P/0/1/0/all/0/1&quot;&gt;Peilin Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Qian_H/0/1/0/all/0/1&quot;&gt;Hui Qian&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09978">
<title>Distributed Cartesian Power Graph Segmentation for Graphon Estimation. (arXiv:1805.09978v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.09978</link>
<description rdf:parseType="Literal">&lt;p&gt;We study an extention of total variation denoising over images to over
Cartesian power graphs and its applications to estimating non-parametric
network models. The power graph fused lasso (PGFL) segments a matrix by
exploiting a known graphical structure, $G$, over the rows and columns. Our
main results shows that for any connected graph, under subGaussian noise, the
PGFL achieves the same mean-square error rate as 2D total variation denoising
for signals of bounded variation. We study the use of the PGFL for denoising an
observed network $H$, where we learn the graph $G$ as the $K$-nearest
neighborhood graph of an estimated metric over the vertices. We provide
theoretical and empirical results for estimating graphons, a non-parametric
exchangeable network model, and compare to the state of the art graphon
estimation methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wei_S/0/1/0/all/0/1&quot;&gt;Shitong Wei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Madrid_Padilla_O/0/1/0/all/0/1&quot;&gt;Oscar Hernan Madrid-Padilla&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sharpnack_J/0/1/0/all/0/1&quot;&gt;James Sharpnack&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09994">
<title>Safe learning-based optimal motion planning for automated driving. (arXiv:1805.09994v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.09994</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents preliminary work on learning the search heuristic for the
optimal motion planning for automated driving in urban traffic.
&lt;/p&gt;
&lt;p&gt;Previous work considered search-based optimal motion planning framework
(SBOMP) that utilized numerical or model-based heuristics that did not consider
dynamic obstacles. Optimal solution was still guaranteed since dynamic
obstacles can only increase the cost. However, significant variations in the
search efficiency are observed depending weather dynamic obstacles are present
or not.
&lt;/p&gt;
&lt;p&gt;This paper introduces machine learning (ML) based heuristic that takes into
account dynamic obstacles, thus adding to the performance consistency for
achieving real-time implementation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ajanovic_Z/0/1/0/all/0/1&quot;&gt;Zlatan Ajanovic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lacevic_B/0/1/0/all/0/1&quot;&gt;Bakir Lacevic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stettinger_G/0/1/0/all/0/1&quot;&gt;Georg Stettinger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Watzenig_D/0/1/0/all/0/1&quot;&gt;Daniel Watzenig&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Horn_M/0/1/0/all/0/1&quot;&gt;Martin Horn&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.10014">
<title>KONG: Kernels for ordered-neighborhood graphs. (arXiv:1805.10014v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.10014</link>
<description rdf:parseType="Literal">&lt;p&gt;We present novel graph kernels for graphs with node and edge labels that have
ordered neighborhoods, i.e. when neighbor nodes follow an order. Graphs with
ordered neighborhoods are a natural data representation for evolving graphs
where edges are created over time, which induces an order. Combining
convolutional subgraph kernels and string kernels, we design new scalable
algorithms for generation of explicit graph feature maps using sketching
techniques. We obtain precise bounds for the approximation accuracy and
computational complexity of the proposed approaches and demonstrate their
applicability on real datasets. In particular, our experiments demonstrate that
neighborhood ordering results in more informative features. For the special
case of general graphs, i.e. graphs without ordered neighborhoods, the new
graph kernels yield efficient and simple algorithms for the comparison of label
distributions between graphs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Draief_M/0/1/0/all/0/1&quot;&gt;Moez Draief&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kutzkov_K/0/1/0/all/0/1&quot;&gt;Konstantin Kutzkov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Scaman_K/0/1/0/all/0/1&quot;&gt;Kevin Scaman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vojnovic_M/0/1/0/all/0/1&quot;&gt;Milan Vojnovic&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.10050">
<title>Bayesian estimation for large scale multivariate Ornstein-Uhlenbeck model of brain connectivity. (arXiv:1805.10050v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.10050</link>
<description rdf:parseType="Literal">&lt;p&gt;Estimation of reliable whole-brain connectivity is a crucial step towards the
use of connectivity information in quantitative approaches to the study of
neuropsychiatric disorders. When estimating brain connectivity a challenge is
imposed by the paucity of time samples and the large dimensionality of the
measurements. Bayesian estimation methods for network models offer a number of
advantages in this context but are not commonly employed. Here we compare three
different estimation methods for the multivariate Ornstein-Uhlenbeck model,
that has recently gained some popularity for characterizing whole-brain
connectivity. We first show that a Bayesian estimation of model parameters
assuming uniform priors is equivalent to an application of the method of
moments. Then, using synthetic data, we show that the Bayesian estimate scales
poorly with number of nodes in the network as compared to an iterative Lyapunov
optimization. In particular when the network size is in the order of that used
for whole-brain studies (about 100 nodes) the Bayesian method needs about eight
times more time samples than Lyapunov method in order to achieve similar
estimation accuracy. We also show that the higher estimation accuracy of
Lyapunov method is reflected in a much better classification of individuals
based on the estimated connectivity from a real dataset of BOLD fMRI. Finally
we show that the poor accuracy of Bayesian method is due to numerical errors,
when the imaginary part of the connectivity estimate gets large compared to its
real part.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Insabato_A/0/1/0/all/0/1&quot;&gt;Andrea Insabato&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Cunningham_J/0/1/0/all/0/1&quot;&gt;John P. Cunningham&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gilson_M/0/1/0/all/0/1&quot;&gt;Matthieu Gilson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.10054">
<title>EM algorithms for ICA. (arXiv:1805.10054v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.10054</link>
<description rdf:parseType="Literal">&lt;p&gt;Independent component analysis (ICA) is a widely spread data exploration
technique, where observed signals are assumed to be linear mixtures of
independent components. From a machine learning point of view, it amounts to a
matrix factorization problem under statistical independence constraints.
Infomax is one of the first and most used algorithms for inference of the
latent parameters. It maximizes a log-likelihood function which is non-convex
and decomposes as a sum over signal samples. We introduce a new
majorization-minimization framework for the optimization of the loss function.
We show that this approach is equivalent to an Expectation-Maximization (EM)
algorithm using Gaussian scale mixtures. Inspired by the literature around EM
algorithms, we derive an online algorithm for the streaming setting, and an
incremental algorithm for the finite-sum setting. These algorithms do not rely
on any critical hyper-parameter like a step size, nor do they require a
line-search technique. The finite-sum algorithm also enjoys the precious
guarantee of decreasing the loss function at each iteration. Experiments show
that they outperform the state-of-the-art on large scale problems, where one
iteration of a full-batch algorithm is a computational burden.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ablin_P/0/1/0/all/0/1&quot;&gt;Pierre Ablin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gramfort_A/0/1/0/all/0/1&quot;&gt;Alexandre Gramfort&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Cardoso_J/0/1/0/all/0/1&quot;&gt;Jean-Fran&amp;#xe7;ois Cardoso&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bach_F/0/1/0/all/0/1&quot;&gt;Francis Bach&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.10066">
<title>A Sliding-Window Algorithm for Markov Decision Processes with Arbitrarily Changing Rewards and Transitions. (arXiv:1805.10066v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.10066</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider reinforcement learning in changing Markov Decision Processes
where both the state-transition probabilities and the reward functions may vary
over time. For this problem setting, we propose an algorithm using a sliding
window approach and provide performance guarantees for the regret evaluated
against the optimal non-stationary policy. We also characterize the optimal
window size suitable for our algorithm. These results are complemented by a
sample complexity bound on the number of sub-optimal steps taken by the
algorithm. Finally, we present some experimental results to support our
theoretical analysis.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gajane_P/0/1/0/all/0/1&quot;&gt;Pratik Gajane&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ortner_R/0/1/0/all/0/1&quot;&gt;Ronald Ortner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Auer_P/0/1/0/all/0/1&quot;&gt;Peter Auer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.10074">
<title>Statistical Optimality of Stochastic Gradient Descent on Hard Learning Problems through Multiple Passes. (arXiv:1805.10074v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.10074</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider stochastic gradient descent (SGD) for least-squares regression
with potentially several passes over the data. While several passes have been
widely reported to perform practically better in terms of predictive
performance on unseen data, the existing theoretical analysis of SGD suggests
that a single pass is statistically optimal. While this is true for
low-dimensional easy problems, we show that for hard problems, multiple passes
lead to statistically optimal predictions while single pass does not; we also
show that in these hard models, the optimal number of passes over the data
increases with sample size. In order to define the notion of hardness and show
that our predictive performances are optimal, we consider potentially
infinite-dimensional models and notions typically associated to kernel methods,
namely, the decay of eigenvalues of the covariance matrix of the features and
the complexity of the optimal predictor as measured through the covariance
matrix. We illustrate our results on synthetic experiments with non-linear
kernel methods and on a classical benchmark with a linear model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pillaud_Vivien_L/0/1/0/all/0/1&quot;&gt;Loucas Pillaud-Vivien&lt;/a&gt; (SIERRA), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rudi_A/0/1/0/all/0/1&quot;&gt;Alessandro Rudi&lt;/a&gt; (SIERRA), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bach_F/0/1/0/all/0/1&quot;&gt;Francis Bach&lt;/a&gt; (SIERRA)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.10111">
<title>A New Analysis of Variance Reduced Stochastic Proximal Methods for Composite Optimization with Serial and Asynchronous Realizations. (arXiv:1805.10111v1 [math.OC])</title>
<link>http://arxiv.org/abs/1805.10111</link>
<description rdf:parseType="Literal">&lt;p&gt;We provide a comprehensive analysis of stochastic variance reduced gradient
(SVRG) based proximal algorithms, both with and without momentum, in serial and
asynchronous realizations. Specifically, we propose the Prox-SVRG$^{++}$
algorithm, and prove that it has a linear convergence rate with a small epoch
length and we obtain an $O(1/\epsilon)$ complexity in non-strongly convex case.
Then, we propose a momentum accelerated algorithm, called Prox-MSVRG$^{++}$,
and show that it achieves a complexity of $O(1/\sqrt{\epsilon})$. After that,
we develop two asynchronous versions based on the above serial algorithms and
provide a general analysis under nonconvex and non-strongly convex cases
respectively. Our theoretical results indicate that the algorithms can achieve
a potentially significant speedup when implemented with multiple servers. We
conduct extensive experiments based on $4$ real-world datasets on an experiment
platform with $11$ physical machines. The experiments validate our theoretical
findings and demonstrate the effectiveness of our algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Yu_Y/0/1/0/all/0/1&quot;&gt;Yue Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Huang_L/0/1/0/all/0/1&quot;&gt;Longbo Huang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.10118">
<title>Analyzing high-dimensional time-series data using kernel transfer operator eigenfunctions. (arXiv:1805.10118v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.10118</link>
<description rdf:parseType="Literal">&lt;p&gt;Kernel transfer operators, which can be regarded as approximations of
transfer operators such as the Perron-Frobenius or Koopman operator in
reproducing kernel Hilbert spaces, are defined in terms of covariance and
cross-covariance operators and have been shown to be closely related to the
conditional mean embedding framework developed by the machine learning
community. The goal of this paper is to show how the dominant eigenfunctions of
these operators in combination with gradient-based optimization techniques can
be used to detect long-lived coherent patterns in high-dimensional time-series
data. The results will be illustrated using video data and a fluid flow
example.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Klus_S/0/1/0/all/0/1&quot;&gt;Stefan Klus&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Peitz_S/0/1/0/all/0/1&quot;&gt;Sebastian Peitz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Schuster_I/0/1/0/all/0/1&quot;&gt;Ingmar Schuster&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.10122">
<title>Function Estimation via Reconstruction. (arXiv:1805.10122v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.10122</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper introduces an interpolation-based method, called the
reconstruction approach, for function estimation in nonparametric models. Based
on the fact that interpolation usually has negligible errors compared to
statistical estimation, the reconstruction approach uses an interpolator to
parameterize the unknown function with its values at finite knots, and then
estimates these values by minimizing a regularized empirical risk function.
Some popular methods including kernel ridge regression and kernel support
vector machines can be viewed as its special cases. It is shown that, the
reconstruction idea not only provides different angles to look into existing
methods, but also produces new effective experimental design and estimation
methods for nonparametric models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Xiong_S/0/1/0/all/0/1&quot;&gt;Shifeng Xiong&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.10168">
<title>Futuristic Classification with Dynamic Reference Frame Strategy. (arXiv:1805.10168v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.10168</link>
<description rdf:parseType="Literal">&lt;p&gt;Classification is one of the widely used analytical techniques in data
science domain across different business to associate a pattern which
contribute to the occurrence of certain event which is predicted with some
likelihood. This Paper address a lacuna of creating some time window before the
prediction actually happen to enable organizations some space to act on the
prediction. There are some really good state of the art machine learning
techniques to optimally identify the possible churners in either customer base
or employee base, similarly for fault prediction too if the prediction does not
come with some buffer time to act on the fault it is very difficult to provide
a seamless experience to the user. New concept of reference frame creation is
introduced to solve this problem in this paper
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pathak_K/0/1/0/all/0/1&quot;&gt;Kumarjit Pathak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kapila_J/0/1/0/all/0/1&quot;&gt;Jitin Kapila&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Barvey_A/0/1/0/all/0/1&quot;&gt;Aasheesh Barvey&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.10196">
<title>Maximizing acquisition functions for Bayesian optimization. (arXiv:1805.10196v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.10196</link>
<description rdf:parseType="Literal">&lt;p&gt;Bayesian optimization is a sample-efficient approach to global optimization
that relies on theoretically motivated value heuristics (acquisition functions)
to guide the search process. Fully maximizing acquisition functions produces
the Bayes&apos; decision rule, but this ideal is difficult to achieve since these
functions are frequently non-trivial to optimize. This statement is especially
true when evaluating queries in parallel, where acquisition functions are
routinely non-convex, high-dimensional, and intractable. We present two modern
approaches for maximizing acquisition functions that exploit key properties
thereof, namely the differentiability of Monte Carlo integration and the
submodularity of parallel querying.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wilson_J/0/1/0/all/0/1&quot;&gt;James T. Wilson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hutter_F/0/1/0/all/0/1&quot;&gt;Frank Hutter&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Deisenroth_M/0/1/0/all/0/1&quot;&gt;Marc Peter Deisenroth&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.10204">
<title>Adversarial examples from computational constraints. (arXiv:1805.10204v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.10204</link>
<description rdf:parseType="Literal">&lt;p&gt;Why are classifiers in high dimension vulnerable to &quot;adversarial&quot;
perturbations? We show that it is likely not due to information theoretic
limitations, but rather it could be due to computational constraints.
&lt;/p&gt;
&lt;p&gt;First we prove that, for a broad set of classification tasks, the mere
existence of a robust classifier implies that it can be found by a possibly
exponential-time algorithm with relatively few training examples. Then we give
a particular classification task where learning a robust classifier is
computationally intractable. More precisely we construct a binary
classification task in high dimensional space which is (i) information
theoretically easy to learn robustly for large perturbations, (ii) efficiently
learnable (non-robustly) by a simple linear separator, (iii) yet is not
efficiently robustly learnable, even for small perturbations, by any algorithm
in the statistical query (SQ) model. This example gives an exponential
separation between classical learning and robust learning in the statistical
query model. It suggests that adversarial examples may be an unavoidable
byproduct of computational limitations of learning algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bubeck_S/0/1/0/all/0/1&quot;&gt;S&amp;#xe9;bastien Bubeck&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Price_E/0/1/0/all/0/1&quot;&gt;Eric Price&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Razenshteyn_I/0/1/0/all/0/1&quot;&gt;Ilya Razenshteyn&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.10205">
<title>Multimodal Sentiment Analysis To Explore the Structure of Emotions. (arXiv:1805.10205v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.10205</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a novel approach to multimodal sentiment analysis using deep
neural networks combining visual analysis and natural language processing. Our
goal is different than the standard sentiment analysis goal of predicting
whether a sentence expresses positive or negative sentiment; instead, we aim to
infer the latent emotional state of the user. Thus, we focus on predicting the
emotion word tags attached by users to their Tumblr posts, treating these as
&quot;self-reported emotions.&quot; We demonstrate that our multimodal model combining
both text and image features outperforms separate models based solely on either
images or text. Our model&apos;s results are interpretable, automatically yielding
sensible word lists associated with emotions. We explore the structure of
emotions implied by our model and compare it to what has been posited in the
psychology literature, and validate our model on a set of images that have been
used in psychology studies. Finally, our work also provides a useful tool for
the growing academic study of images - both photographs and memes - on social
networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hu_A/0/1/0/all/0/1&quot;&gt;Anthony Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Flaxman_S/0/1/0/all/0/1&quot;&gt;Seth Flaxman&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.10206">
<title>On the Estimation of Entropy in the FastICA Algorithm. (arXiv:1805.10206v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.10206</link>
<description rdf:parseType="Literal">&lt;p&gt;The fastICA algorithm is a popular dimension reduction technique used to
reveal patterns in data. Here we show that the approximations used in fastICA
can result in patterns not being successfully recognised. We demonstrate this
problem using a two-dimensional example where a clear structure is immediately
visible to the naked eye, but where the projection chosen by fastICA fails to
reveal this structure. This implies that care is needed when applying fastICA.
We discuss how the problem arises and how it is intrinsically connected to the
approximations that form the basis of the computational efficiency of fastICA.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Smith_P/0/1/0/all/0/1&quot;&gt;Paul Smith&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Voss_J/0/1/0/all/0/1&quot;&gt;Jochen Voss&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Issoglio_E/0/1/0/all/0/1&quot;&gt;Elena Issoglio&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.10211">
<title>COREclust: a new package for a robust and scalable analysis of complex data. (arXiv:1805.10211v1 [cs.MS])</title>
<link>http://arxiv.org/abs/1805.10211</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we present a new R package COREclust dedicated to the
detection of representative variables in high dimensional spaces with a
potentially limited number of observations. Variable sets detection is based on
an original graph clustering strategy denoted CORE-clustering algorithm that
detects CORE-clusters, i.e. variable sets having a user defined size range and
in which each variable is very similar to at least another variable.
Representative variables are then robustely estimate as the CORE-cluster
centers. This strategy is entirely coded in C++ and wrapped by R using the Rcpp
package. A particular effort has been dedicated to keep its algorithmic cost
reasonable so that it can be used on large datasets. After motivating our work,
we will explain the CORE-clustering algorithm as well as a greedy extension of
this algorithm. We will then present how to use it and results obtained on
synthetic and real data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Champion_C/0/1/0/all/0/1&quot;&gt;Camille Champion&lt;/a&gt; (IMT), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brunet_A/0/1/0/all/0/1&quot;&gt;Anne-Claire Brunet&lt;/a&gt; (IMT), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Loubes_J/0/1/0/all/0/1&quot;&gt;Jean-Michel Loubes&lt;/a&gt; (IMT), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Risser_L/0/1/0/all/0/1&quot;&gt;Laurent Risser&lt;/a&gt; (IMT)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.10251">
<title>How Much Restricted Isometry is Needed In Nonconvex Matrix Recovery?. (arXiv:1805.10251v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.10251</link>
<description rdf:parseType="Literal">&lt;p&gt;When the linear measurements of an instance of low-rank matrix recovery
satisfy a restricted isometry property (RIP)---i.e. they are approximately
norm-preserving---the problem is known to contain no spurious local minima, so
exact recovery is guaranteed. In this paper, we show that moderate RIP is not
enough to eliminate spurious local minima, so existing results can only hold
for near-perfect RIP. In fact, counterexamples are ubiquitous: we prove that
every x is the spurious local minimum of a rank-1 instance of matrix recovery
that satisfies RIP. One specific counterexample has RIP constant $\delta=1/2$,
but causes randomly initialized stochastic gradient descent (SGD) to fail 12%
of the time. SGD is frequently able to avoid and escape spurious local minima,
but this empirical result shows that it can occasionally be defeated by their
existence. Hence, while exact recovery guarantees will likely require a proof
of no spurious local minima, arguments based solely on norm preservation will
only be applicable to a narrow set of nearly-isotropic instances.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1&quot;&gt;Richard Y. Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Josz_C/0/1/0/all/0/1&quot;&gt;C&amp;#xe9;dric Josz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sojoudi_S/0/1/0/all/0/1&quot;&gt;Somayeh Sojoudi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lavaei_J/0/1/0/all/0/1&quot;&gt;Javad Lavaei&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.10262">
<title>Learning Restricted Boltzmann Machines via Influence Maximization. (arXiv:1805.10262v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.10262</link>
<description rdf:parseType="Literal">&lt;p&gt;Graphical models are a rich language for describing high-dimensional
distributions in terms of their dependence structure. While there are provable
algorithms for learning graphical models in a variety of settings, there has
been much less progress when there are latent variables. Here we study
Restricted Boltzmann Machines (or RBMs), which are a popular model with
wide-ranging applications in dimensionality reduction, collaborative filtering,
topic modeling, feature extraction and deep learning.
&lt;/p&gt;
&lt;p&gt;We give a simple greedy algorithm based on influence maximization to learn
ferromagnetic RBMs with bounded degree. More precisely, we learn a description
of the distribution on the observed variables as a Markov Random Field (or
MRF), even though it exhibits complex higher- order interactions. Our analysis
is based on tools from mathematical physics that were developed to show the
concavity of magnetization. Moreover our results extend in a straightforward
manner to ferromagnetic Ising models with latent variables. Conversely, we show
that the distribution on the observed nodes of a general RBM can simulate any
MRF which allows us to show new hardness results for improperly learning RBMs
even with only a constant number of latent variables.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bresler_G/0/1/0/all/0/1&quot;&gt;Guy Bresler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koehler_F/0/1/0/all/0/1&quot;&gt;Frederic Koehler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moitra_A/0/1/0/all/0/1&quot;&gt;Ankur Moitra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mossel_E/0/1/0/all/0/1&quot;&gt;Elchanan Mossel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1602.00522">
<title>A Quasi-Bayesian Perspective to Online Clustering. (arXiv:1602.00522v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1602.00522</link>
<description rdf:parseType="Literal">&lt;p&gt;When faced with high frequency streams of data, clustering raises theoretical
and algorithmic pitfalls. We introduce a new and adaptive online clustering
algorithm relying on a quasi-Bayesian approach, with a dynamic (i.e.,
time-dependent) estimation of the (unknown and changing) number of clusters. We
prove that our approach is supported by minimax regret bounds. We also provide
an RJMCMC-flavored implementation (called PACBO, see
https://cran.r-project.org/web/packages/PACBO/index.html) for which we give a
convergence guarantee. Finally, numerical experiments illustrate the potential
of our procedure.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Li_L/0/1/0/all/0/1&quot;&gt;Le Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Guedj_B/0/1/0/all/0/1&quot;&gt;Benjamin Guedj&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Loustau_S/0/1/0/all/0/1&quot;&gt;S&amp;#xe9;bastien Loustau&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1606.04366">
<title>Recursive nonlinear-system identification using latent variables. (arXiv:1606.04366v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1606.04366</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper we develop a method for learning nonlinear systems with
multiple outputs and inputs. We begin by modelling the errors of a nominal
predictor of the system using a latent variable framework. Then using the
maximum likelihood principle we derive a criterion for learning the model. The
resulting optimization problem is tackled using a majorization-minimization
approach. Finally, we develop a convex majorization technique and show that it
enables a recursive identification method. The method learns parsimonious
predictive models and is tested on both synthetic and real nonlinear systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mattsson_P/0/1/0/all/0/1&quot;&gt;Per Mattsson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zachariah_D/0/1/0/all/0/1&quot;&gt;Dave Zachariah&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Stoica_P/0/1/0/all/0/1&quot;&gt;Petre Stoica&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1708.00707">
<title>ELFI: Engine for Likelihood Free Inference. (arXiv:1708.00707v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1708.00707</link>
<description rdf:parseType="Literal">&lt;p&gt;Engine for Likelihood-Free Inference (ELFI) is a Python software library for
performing likelihood-free inference (LFI). ELFI provides a convenient syntax
for arranging components in LFI, such as priors, simulators, summaries or
distances, to a network called ELFI graph. The components can be implemented in
a wide variety of languages. The stand-alone ELFI graph can be used with any of
the available inference methods without modifications. A central method
implemented in ELFI is Bayesian Optimization for Likelihood-Free Inference
(BOLFI), which has recently been shown to accelerate likelihood-free inference
up to several orders of magnitude by surrogate-modelling the distance. ELFI
also has an inbuilt support for output data storing for reuse and analysis, and
supports parallelization of computation from multiple cores up to a cluster
environment. ELFI is designed to be extensible and provides interfaces for
widening its functionality. This makes the adding of new inference methods to
ELFI straightforward and automatically compatible with the inbuilt features.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lintusaari_J/0/1/0/all/0/1&quot;&gt;Jarno Lintusaari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Vuollekoski_H/0/1/0/all/0/1&quot;&gt;Henri Vuollekoski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kangasraasio_A/0/1/0/all/0/1&quot;&gt;Antti Kangasr&amp;#xe4;&amp;#xe4;si&amp;#xf6;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Skyten_K/0/1/0/all/0/1&quot;&gt;Kusti Skyt&amp;#xe9;n&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Jarvenpaa_M/0/1/0/all/0/1&quot;&gt;Marko J&amp;#xe4;rvenp&amp;#xe4;&amp;#xe4;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Marttinen_P/0/1/0/all/0/1&quot;&gt;Pekka Marttinen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gutmann_M/0/1/0/all/0/1&quot;&gt;Michael Gutmann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Vehtari_A/0/1/0/all/0/1&quot;&gt;Aki Vehtari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Corander_J/0/1/0/all/0/1&quot;&gt;Jukka Corander&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kaski_S/0/1/0/all/0/1&quot;&gt;Samuel Kaski&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.01297">
<title>Implicit Weight Uncertainty in Neural Networks. (arXiv:1711.01297v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1711.01297</link>
<description rdf:parseType="Literal">&lt;p&gt;Modern neural networks tend to be overconfident on unseen, noisy or
incorrectly labelled data and do not produce meaningful uncertainty measures.
Bayesian deep learning aims to address this shortcoming with variational
approximations (such as Bayes by Backprop or Multiplicative Normalising Flows).
However, current approaches have limitations regarding flexibility and
scalability. We introduce Bayes by Hypernet (BbH), a new method of variational
approximation that interprets hypernetworks as implicit distributions. It
naturally uses neural networks to model arbitrarily complex distributions and
scales to modern deep learning architectures. In our experiments, we
demonstrate that our method achieves competitive accuracies and predictive
uncertainties on MNIST and a CIFAR5 task, while being the most robust against
adversarial attacks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pawlowski_N/0/1/0/all/0/1&quot;&gt;Nick Pawlowski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Brock_A/0/1/0/all/0/1&quot;&gt;Andrew Brock&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lee_M/0/1/0/all/0/1&quot;&gt;Matthew C.H. Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rajchl_M/0/1/0/all/0/1&quot;&gt;Martin Rajchl&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Glocker_B/0/1/0/all/0/1&quot;&gt;Ben Glocker&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.01193">
<title>A Riemannian approach to trace norm regularized low-rank tensor completion. (arXiv:1712.01193v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1712.01193</link>
<description rdf:parseType="Literal">&lt;p&gt;One of the popular approaches for low-rank tensor completion is to use the
{\it latent trace norm} regularization. However, most existing works in this
direction learn a sparse combination of tensors. In this work, we fill this gap
by proposing a variant of the latent trace norm that helps in learning a
non-sparse combination of tensors. We develop a dual framework for solving the
proposed low-rank tensor completion problem. In this framework, we first show a
novel characterization of the solution space with an interesting factorization
of the optimal solution. This allows to propose two scalable optimization
formulations. The problems are shown to lie on a Cartesian product of
Riemannian spectrahedron manifolds. We exploit the versatile Riemannian
optimization framework for proposing computationally efficient trust region
algorithms. The experiments illustrate the efficacy of the proposed algorithms
on several real-world datasets across applications.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nimishakavi_M/0/1/0/all/0/1&quot;&gt;Madhav Nimishakavi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jawanpuria_P/0/1/0/all/0/1&quot;&gt;Pratik Jawanpuria&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mishra_B/0/1/0/all/0/1&quot;&gt;Bamdev Mishra&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.03471">
<title>Identifiability of Kronecker-structured Dictionaries for Tensor Data. (arXiv:1712.03471v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1712.03471</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper derives sufficient conditions for local recovery of coordinate
dictionaries comprising a Kronecker-structured dictionary that is used for
representing $K$th-order tensor data. Tensor observations are assumed to be
generated from a Kronecker-structured dictionary multiplied by sparse
coefficient tensors that follow the separable sparsity model. This work
provides sufficient conditions on the underlying coordinate dictionaries,
coefficient and noise distributions, and number of samples that guarantee
recovery of the individual coordinate dictionaries up to a specified error, as
a local minimum of the objective function, with high probability. In
particular, the sample complexity to recover $K$ coordinate dictionaries with
dimensions $m_k \times p_k$ up to estimation error $\varepsilon_k$ is shown to
be $\max_{k \in [K]}\mathcal{O}(m_kp_k^3\varepsilon_k^{-2})$.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Shakeri_Z/0/1/0/all/0/1&quot;&gt;Zahra Shakeri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sarwate_A/0/1/0/all/0/1&quot;&gt;Anand D. Sarwate&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bajwa_W/0/1/0/all/0/1&quot;&gt;Waheed U. Bajwa&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.06203">
<title>Attenuation correction for brain PET imaging using deep neural network based on dixon and ZTE MR images. (arXiv:1712.06203v2 [physics.med-ph] UPDATED)</title>
<link>http://arxiv.org/abs/1712.06203</link>
<description rdf:parseType="Literal">&lt;p&gt;Positron Emission Tomography (PET) is a functional imaging modality widely
used in neuroscience studies. To obtain meaningful quantitative results from
PET images, attenuation correction is necessary during image reconstruction.
For PET/MR hybrid systems, PET attenuation is challenging as Magnetic Resonance
(MR) images do not reflect attenuation coefficients directly. To address this
issue, we present deep neural network methods to derive the continuous
attenuation coefficients for brain PET imaging from MR images. With only Dixon
MR images as the network input, the existing U-net structure was adopted and
analysis using forty patient data sets shows it is superior than other Dixon
based methods. When both Dixon and zero echo time (ZTE) images are available,
we have proposed a modified U-net structure, named GroupU-net, to efficiently
make use of both Dixon and ZTE information through group convolution modules
when the network goes deeper. Quantitative analysis based on fourteen real
patient data sets demonstrates that both network approaches can perform better
than the standard methods, and the proposed network structure can further
reduce the PET quantification error compared to the U-net structure.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Gong_K/0/1/0/all/0/1&quot;&gt;Kuang Gong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Yang_J/0/1/0/all/0/1&quot;&gt;Jaewon Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Kim_K/0/1/0/all/0/1&quot;&gt;Kyungsang Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Fakhri_G/0/1/0/all/0/1&quot;&gt;Georges El Fakhri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Seo_Y/0/1/0/all/0/1&quot;&gt;Youngho Seo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Li_Q/0/1/0/all/0/1&quot;&gt;Quanzheng Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.00857">
<title>Optimal Bayesian Transfer Learning. (arXiv:1801.00857v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1801.00857</link>
<description rdf:parseType="Literal">&lt;p&gt;Transfer learning has recently attracted significant research attention, as
it simultaneously learns from different source domains, which have plenty of
labeled data, and transfers the relevant knowledge to the target domain with
limited labeled data to improve the prediction performance. We propose a
Bayesian transfer learning framework where the source and target domains are
related through the joint prior density of the model parameters. The modeling
of joint prior densities enables better understanding of the &quot;transferability&quot;
between domains. We define a joint Wishart density for the precision matrices
of the Gaussian feature-label distributions in the source and target domains to
act like a bridge that transfers the useful information of the source domain to
help classification in the target domain by improving the target posteriors.
Using several theorems in multivariate statistics, the posteriors and posterior
predictive densities are derived in closed forms with hypergeometric functions
of matrix argument, leading to our novel closed-form and fast Optimal Bayesian
Transfer Learning (OBTL) classifier. Experimental results on both synthetic and
real-world benchmark data confirm the superb performance of the OBTL compared
to the other state-of-the-art transfer learning and domain adaptation methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Karbalayghareh_A/0/1/0/all/0/1&quot;&gt;Alireza Karbalayghareh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Qian_X/0/1/0/all/0/1&quot;&gt;Xiaoning Qian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Dougherty_E/0/1/0/all/0/1&quot;&gt;Edward R. Dougherty&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.02550">
<title>Semi-Amortized Variational Autoencoders. (arXiv:1802.02550v5 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1802.02550</link>
<description rdf:parseType="Literal">&lt;p&gt;Amortized variational inference (AVI) replaces instance-specific local
inference with a global inference network. While AVI has enabled efficient
training of deep generative models such as variational autoencoders (VAE),
recent empirical work suggests that inference networks can produce suboptimal
variational parameters. We propose a hybrid approach, to use AVI to initialize
the variational parameters and run stochastic variational inference (SVI) to
refine them. Crucially, the local SVI procedure is itself differentiable, so
the inference network and generative model can be trained end-to-end with
gradient-based optimization. This semi-amortized approach enables the use of
rich generative models without experiencing the posterior-collapse phenomenon
common in training VAEs for problems like text generation. Experiments show
this approach outperforms strong autoregressive and variational baselines on
standard text and image datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kim_Y/0/1/0/all/0/1&quot;&gt;Yoon Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wiseman_S/0/1/0/all/0/1&quot;&gt;Sam Wiseman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Miller_A/0/1/0/all/0/1&quot;&gt;Andrew C. Miller&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sontag_D/0/1/0/all/0/1&quot;&gt;David Sontag&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rush_A/0/1/0/all/0/1&quot;&gt;Alexander M. Rush&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.03569">
<title>Persistence Fisher Kernel: A Riemannian Manifold Kernel for Persistence Diagrams. (arXiv:1802.03569v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1802.03569</link>
<description rdf:parseType="Literal">&lt;p&gt;Algebraic topology methods have recently played an important role for
statistical analysis with complicated geometric structured data such as shapes,
linked twist maps, and material data. Among them, \textit{persistent homology}
is a well-known tool to extract robust topological features, and outputs as
\textit{persistence diagrams} (PDs). However, PDs are point multi-sets which
can not be used in machine learning algorithms for vector data. To deal with
it, an emerged approach is to use kernel methods, and an appropriate geometry
for PDs is an important factor to measure the similarity of PDs. A popular
geometry for PDs is the \textit{Wasserstein metric}. However, Wasserstein
distance is not \textit{negative definite}. Thus, it is limited to build
positive definite kernels upon the Wasserstein distance \textit{without
approximation}. In this work, we rely upon the alternative \textit{Fisher
information geometry} to propose a positive definite kernel for PDs
\textit{without approximation}, namely the Persistence Fisher (PF) kernel.
Then, we analyze eigensystem of the integral operator induced by the proposed
kernel for kernel machines. Based on that, we derive generalization error
bounds via covering numbers and Rademacher averages for kernel machines with
the PF kernel. Additionally, we show some nice properties such as stability and
infinite divisibility for the proposed kernel. Furthermore, we also propose a
linear time complexity over the number of points in PDs for an approximation of
our proposed kernel with a bounded error. Throughout experiments with many
different tasks on various benchmark datasets, we illustrate that the PF kernel
compares favorably with other baseline kernels for PDs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Le_T/0/1/0/all/0/1&quot;&gt;Tam Le&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yamada_M/0/1/0/all/0/1&quot;&gt;Makoto Yamada&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04956">
<title>D2KE: From Distance to Kernel and Embedding. (arXiv:1802.04956v4 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1802.04956</link>
<description rdf:parseType="Literal">&lt;p&gt;For many machine learning problem settings, particularly with structured
inputs such as sequences or sets of objects, a distance measure between inputs
can be specified more naturally than a feature representation. However, most
standard machine models are designed for inputs with a vector feature
representation. In this work, we consider the estimation of a function
$f:\mathcal{X} \rightarrow \R$ based solely on a dissimilarity measure
$d:\mathcal{X}\times\mathcal{X} \rightarrow \R$ between inputs. In particular,
we propose a general framework to derive a family of \emph{positive definite
kernels} from a given dissimilarity measure, which subsumes the widely-used
\emph{representative-set method} as a special case, and relates to the
well-known \emph{distance substitution kernel} in a limiting case. We show that
functions in the corresponding Reproducing Kernel Hilbert Space (RKHS) are
Lipschitz-continuous w.r.t. the given distance metric. We provide a tractable
algorithm to estimate a function from this RKHS, and show that it enjoys better
generalizability than Nearest-Neighbor estimates. Our approach draws from the
literature of Random Features, but instead of deriving feature maps from an
existing kernel, we construct novel kernels from a random feature map, that we
specify given the distance measure. We conduct classification experiments with
such disparate domains as strings, time series, and sets of vectors, where our
proposed framework compares favorably to existing distance-based learning
methods such as $k$-nearest-neighbors, distance-substitution kernels,
pseudo-Euclidean embedding, and the representative-set method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wu_L/0/1/0/all/0/1&quot;&gt;Lingfei Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yen_I/0/1/0/all/0/1&quot;&gt;Ian En-Hsu Yen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Xu_F/0/1/0/all/0/1&quot;&gt;Fangli Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ravikumar_P/0/1/0/all/0/1&quot;&gt;Pradeep Ravikumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Witbrock_M/0/1/0/all/0/1&quot;&gt;Michael Witbrock&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05451">
<title>Mapping Images to Scene Graphs with Permutation-Invariant Structured Prediction. (arXiv:1802.05451v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1802.05451</link>
<description rdf:parseType="Literal">&lt;p&gt;Machine understanding of complex images is a key goal of artificial
intelligence. One challenge underlying this task is that visual scenes contain
multiple inter-related objects, and that global context plays an important role
in interpreting the scene. A natural modeling framework for capturing such
effects is structured prediction, which optimizes over complex labels, while
modeling within-label interactions. However, it is unclear what principles
should guide the design of a structured prediction model that utilizes the
power of deep learning components. Here we propose a design principle for such
architectures that follows from a natural requirement of permutation
invariance. We prove a necessary and sufficient characterization for
architectures that follow this invariance, and discuss its implication on model
design. Finally, we show that the resulting model achieves new state of the art
results on the Visual Genome scene graph labeling benchmark, outperforming all
recent approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Herzig_R/0/1/0/all/0/1&quot;&gt;Roei Herzig&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Raboh_M/0/1/0/all/0/1&quot;&gt;Moshiko Raboh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chechik_G/0/1/0/all/0/1&quot;&gt;Gal Chechik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Berant_J/0/1/0/all/0/1&quot;&gt;Jonathan Berant&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Globerson_A/0/1/0/all/0/1&quot;&gt;Amir Globerson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.05112">
<title>Uplift Modeling from Separate Labels. (arXiv:1803.05112v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1803.05112</link>
<description rdf:parseType="Literal">&lt;p&gt;Uplift modeling is aimed at estimating the incremental impact of an action on
an individual&apos;s behavior, which is useful in various application domains such
as targeted marketing (advertisement campaigns) and personalized medicine
(medical treatments). Conventional methods of uplift modeling require every
instance to be jointly equipped with two types of labels: the taken action and
its outcome. However, obtaining two labels for each instance at the same time
is difficult or expensive in many real-world problems. In this paper, we
propose a novel method of uplift modeling that is applicable to a more
practical setting where only one type of labels is available for each instance.
We show a generalization error bound for the proposed method and demonstrate
its effectiveness through experiments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yamane_I/0/1/0/all/0/1&quot;&gt;Ikko Yamane&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yger_F/0/1/0/all/0/1&quot;&gt;Florian Yger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Atif_J/0/1/0/all/0/1&quot;&gt;Jamal Atif&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sugiyama_M/0/1/0/all/0/1&quot;&gt;Masashi Sugiyama&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.04438">
<title>Pooling is neither necessary nor sufficient for appropriate deformation stability in CNNs. (arXiv:1804.04438v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1804.04438</link>
<description rdf:parseType="Literal">&lt;p&gt;Many of our core assumptions about how neural networks operate remain
empirically untested. One common assumption is that convolutional neural
networks need to be stable to small translations and deformations to solve
image recognition tasks. For many years, this stability was baked into CNN
architectures by incorporating interleaved pooling layers. Recently, however,
interleaved pooling has largely been abandoned. This raises a number of
questions: Are our intuitions about deformation stability right at all? Is it
important? Is pooling necessary for deformation invariance? If not, how is
deformation invariance achieved in its absence? In this work, we rigorously
test these questions, and find that deformation stability in convolutional
networks is more nuanced than it first appears: (1) Deformation invariance is
not a binary property, but rather that different tasks require different
degrees of deformation stability at different layers. (2) Deformation stability
is not a fixed property of a network and is heavily adjusted over the course of
training, largely through the smoothness of the convolutional filters. (3)
Interleaved pooling layers are neither necessary nor sufficient for achieving
the optimal form of deformation stability for natural image classification. (4)
Pooling confers too much deformation stability for image classification at
initialization, and during training, networks have to learn to counteract this
inductive bias. Together, these findings provide new insights into the role of
interleaved pooling and deformation invariance in CNNs, and demonstrate the
importance of rigorous empirical testing of even our most basic assumptions
about the working of neural networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ruderman_A/0/1/0/all/0/1&quot;&gt;Avraham Ruderman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rabinowitz_N/0/1/0/all/0/1&quot;&gt;Neil C. Rabinowitz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Morcos_A/0/1/0/all/0/1&quot;&gt;Ari S. Morcos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zoran_D/0/1/0/all/0/1&quot;&gt;Daniel Zoran&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.05981">
<title>A Univariate Bound of Area Under ROC. (arXiv:1804.05981v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1804.05981</link>
<description rdf:parseType="Literal">&lt;p&gt;Area under ROC (AUC) is an important metric for binary classification and
bipartite ranking problems. However, it is difficult to directly optimizing AUC
as a learning objective, so most existing algorithms are based on optimizing a
surrogate loss to AUC. One significant drawback of these surrogate losses is
that they require pairwise comparisons among training data, which leads to slow
running time and increasing local storage for online learning. In this work, we
describe a new surrogate loss based on a reformulation of the AUC risk, which
does not require pairwise comparison but rankings of the predictions. We
further show that the ranking operation can be avoided, and the learning
objective obtained based on this surrogate enjoys linear complexity in time and
storage. We perform experiments to demonstrate the effectiveness of the online
and batch algorithms for AUC optimization based on the proposed surrogate loss.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lyu_S/0/1/0/all/0/1&quot;&gt;Siwei Lyu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ying_Y/0/1/0/all/0/1&quot;&gt;Yiming Ying&lt;/a&gt;</dc:creator>
</item></rdf:RDF>