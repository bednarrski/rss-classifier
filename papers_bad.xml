<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Boring papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Bad Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-05-09T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.03337"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.03473"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.07257"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.03359"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.03364"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.03382"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.03435"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.03545"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.03586"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1602.08199"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.07615"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.09780"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.07244"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.03824"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.06439"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.01157"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.02785"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.03294"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.03317"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.03444"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.03463"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.03504"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.03591"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.03620"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.10266"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.00616"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.02627"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1805.03337">
<title>Multi-scale metrics and self-organizing maps: a computational approach to the structure of sensory maps. (arXiv:1805.03337v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1805.03337</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper introduces the concept of a bi-scale metric for use in the
cooperative phase of the self-organizing map (SOM) algorithm. Use of a bi-scale
metric allows segmentation of the map into a number of regions, corresponding
to anticipated cluster structure in the data. Such a situation occurs, for
example, in the somatotopic maps which inspired the SOM algo- rithm, where
clusters of data may correspond to body surface regions whose general structure
is known. When a bi-scale metric is appropriately applied, issues with map
neurons that are not activated by any point in the training data are reduced or
eliminated. The paper also presents results of simulation studies on the
plasticity of bi-scale metric maps when they are retrained af- ter loss of
groups of map neurons or after changes in training data (such as would occur in
a somatotopic map when a body surface region like a finger is lost/removed).
The paper further considers situations where tri-scale met- rics may be useful,
and an alternative approach suggested by neurobiology, where some map regions
adapt more slowly to stimuli because they have a lower learning rate parameter.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wilson_W/0/1/0/all/0/1&quot;&gt;William H. Wilson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.03473">
<title>Learning representations for multivariate time series with missing data using Temporal Kernelized Autoencoders. (arXiv:1805.03473v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1805.03473</link>
<description rdf:parseType="Literal">&lt;p&gt;Learning compressed representations of multivariate time series (MTS)
facilitate the analysis and process of the data in presence of noise, redundant
information, and large amount of variables and time steps. However, classic
dimensionality reduction approaches are not designed to process sequential
data, especially in the presence of missing values. In this work, we propose a
novel autoencoder architecture based on recurrent neural networks to generate
compressed representations of MTS, which may contain missing values and have
variable lengths. Our autoencoder learns fixed-length vectorial
representations, whose pairwise similarities are aligned with a kernel function
that operates in input space and handles missing values. This, allows to
preserve relationships in the low-dimensional vector space even in presence of
missing values. To highlight the main features of the proposed autoencoder, we
first investigate its performance in controlled experiments. Successively, we
show how the learned representations can be exploited both in several benchmark
and real-world classification tasks on medical data. Finally, based on the
proposed architecture, we conceive a framework for one-class classification and
imputation of missing data in time series extracted from ECG signals.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bianchi_F/0/1/0/all/0/1&quot;&gt;Filippo Maria Bianchi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Livi_L/0/1/0/all/0/1&quot;&gt;Lorenzo Livi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mikalsen_K/0/1/0/all/0/1&quot;&gt;Karl &amp;#xd8;yvind Mikalsen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kampffmeyer_M/0/1/0/all/0/1&quot;&gt;Michael Kampffmeyer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jenssen_R/0/1/0/all/0/1&quot;&gt;Robert Jenssen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.07257">
<title>Multi-shot Pedestrian Re-identification via Sequential Decision Making. (arXiv:1712.07257v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1712.07257</link>
<description rdf:parseType="Literal">&lt;p&gt;Multi-shot pedestrian re-identification problem is at the core of
surveillance video analysis. It matches two tracks of pedestrians from
different cameras. In contrary to existing works that aggregate single frames
features by time series model such as recurrent neural network, in this paper,
we propose an interpretable reinforcement learning based approach to this
problem. Particularly, we train an agent to verify a pair of images at each
time. The agent could choose to output the result (same or different) or
request another pair of images to verify (unsure). By this way, our model
implicitly learns the difficulty of image pairs, and postpone the decision when
the model does not accumulate enough evidence. Moreover, by adjusting the
reward for unsure action, we can easily trade off between speed and accuracy.
In three open benchmarks, our method are competitive with the state-of-the-art
methods while only using 3% to 6% images. These promising results demonstrate
that our method is favorable in both efficiency and performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Jianfu Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_N/0/1/0/all/0/1&quot;&gt;Naiyan Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1&quot;&gt;Liqing Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.03359">
<title>Reward Estimation for Variance Reduction in Deep Reinforcement Learning. (arXiv:1805.03359v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.03359</link>
<description rdf:parseType="Literal">&lt;p&gt;In reinforcement learning (RL), stochastic environments can make learning a
policy difficult due to high degrees of variance. As such, variance reduction
methods have been investigated in other works, such as advantage estimation and
control-variates estimation. Here, we propose to learn a separate reward
estimator to train the value function, to help reduce variance caused by a
noisy reward signal. This results in theoretical reductions in variance in the
tabular case, as well as empirical improvements in both the function
approximation and tabular settings in environments where rewards are
stochastic. To do so, we use a modified version of Advantage Actor Critic (A2C)
on variations of Atari games.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Romoff_J/0/1/0/all/0/1&quot;&gt;Joshua Romoff&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Piche_A/0/1/0/all/0/1&quot;&gt;Alexandre Pich&amp;#xe9;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Henderson_P/0/1/0/all/0/1&quot;&gt;Peter Henderson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Francois_Lavet_V/0/1/0/all/0/1&quot;&gt;Vincent Francois-Lavet&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pineau_J/0/1/0/all/0/1&quot;&gt;Joelle Pineau&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.03364">
<title>A Symbolic Approach to Explaining Bayesian Network Classifiers. (arXiv:1805.03364v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1805.03364</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose an approach for explaining Bayesian network classifiers, which is
based on compiling such classifiers into decision functions that have a
tractable and symbolic form. We introduce two types of explanations for why a
classifier may have classified an instance positively or negatively and suggest
algorithms for computing these explanations. The first type of explanation
identifies a minimal set of the currently active features that is responsible
for the current classification, while the second type of explanation identifies
a minimal set of features whose current state (active or not) is sufficient for
the classification. We consider in particular the compilation of Naive and
Latent-Tree Bayesian network classifiers into Ordered Decision Diagrams (ODDs),
providing a context for evaluating our proposal using case studies and
experiments based on classifiers from the literature.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shih_A/0/1/0/all/0/1&quot;&gt;Andy Shih&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Choi_A/0/1/0/all/0/1&quot;&gt;Arthur Choi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Darwiche_A/0/1/0/all/0/1&quot;&gt;Adnan Darwiche&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.03382">
<title>Computer-aided mechanism design: designing revenue-optimal mechanisms via neural networks. (arXiv:1805.03382v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1805.03382</link>
<description rdf:parseType="Literal">&lt;p&gt;Using AI approaches to automatically design mechanisms has been a central
research mission at the interface of AI and economics [Conitzer and Sandholm,
2002]. Previous approaches that a empt to design revenue optimal auctions for
the multi-dimensional settings fall short in at least one of the three aspects:
1) representation --- search in a space that probably does not even contain the
optimal mechanism; 2) exactness --- finding a mechanism that is either not
truthful or far from optimal; 3) domain dependence --- need a different design
for different environment settings. To resolve the three difficulties, in this
paper, we put forward a uni ed neural network based framework that
automatically learns to design revenue optimal mechanisms. Our framework
consists of a mechanism network that takes an input distribution for training
and outputs a mechanism, as well as a buyer network that takes a mechanism as
input and output an action. Such a separation in design mitigates the
difficulty to impose incentive compatibility constraints on the mechanism, by
making it a rational choice of the buyer. As a result, our framework easily
overcomes the previously mentioned difficulty in incorporating IC constraints
and always returns exactly incentive compatible mechanisms. We then applied our
framework to a number of multi-item revenue optimal design settings, for a few
of which the theoretically optimal mechanisms are unknown. We then go on to
theoretically prove that the mechanisms found by our framework are indeed
optimal.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_W/0/1/0/all/0/1&quot;&gt;Weiran Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_P/0/1/0/all/0/1&quot;&gt;Pingzhong Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zuo_S/0/1/0/all/0/1&quot;&gt;Song Zuo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.03435">
<title>Decoding Decoders: Finding Optimal Representation Spaces for Unsupervised Similarity Tasks. (arXiv:1805.03435v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1805.03435</link>
<description rdf:parseType="Literal">&lt;p&gt;Experimental evidence indicates that simple models outperform complex deep
networks on many unsupervised similarity tasks. We provide a simple yet
rigorous explanation for this behaviour by introducing the concept of an
optimal representation space, in which semantically close symbols are mapped to
representations that are close under a similarity measure induced by the
model&apos;s objective function. In addition, we present a straightforward procedure
that, without any retraining or architectural modifications, allows deep
recurrent models to perform equally well (and sometimes better) when compared
to shallow models. To validate our analysis, we conduct a set of consistent
empirical evaluations and introduce several new sentence embedding models in
the process. Even though this work is presented within the context of natural
language processing, the insights are readily applicable to other domains that
rely on distributed representations for transfer tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhelezniak_V/0/1/0/all/0/1&quot;&gt;Vitalii Zhelezniak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Busbridge_D/0/1/0/all/0/1&quot;&gt;Dan Busbridge&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_A/0/1/0/all/0/1&quot;&gt;April Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Smith_S/0/1/0/all/0/1&quot;&gt;Samuel L. Smith&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hammerla_N/0/1/0/all/0/1&quot;&gt;Nils Y. Hammerla&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.03545">
<title>Solving Sudoku with Ant Colony Optimisation. (arXiv:1805.03545v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1805.03545</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper we present a new Ant Colony Optimisation-based algorithm for
Sudoku, which out-performs existing methods on large instances. Our method
includes a novel anti-stagnation operator, which we call Best Value
Evaporation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lloyd_H/0/1/0/all/0/1&quot;&gt;Huw Lloyd&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Amos_M/0/1/0/all/0/1&quot;&gt;Martyn Amos&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.03586">
<title>Policy Optimization with Second-Order Advantage Information. (arXiv:1805.03586v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.03586</link>
<description rdf:parseType="Literal">&lt;p&gt;Policy optimization on high-dimensional continuous control tasks exhibits its
difficulty caused by the large variance of the policy gradient estimators. We
present the action subspace dependent gradient (ASDG) estimator which
incorporates the Rao-Blackwell theorem (RB) and Control Variates (CV) into a
unified framework to reduce the variance. To invoke RB, our proposed algorithm
(POSA) learns the underlying factorization structure among the action space
based on the second-order advantage information. POSA captures the quadratic
information explicitly and efficiently by utilizing the wide &amp;amp; deep
architecture. Empirical studies show that our proposed approach demonstrates
the performance improvements on high-dimensional synthetic settings and OpenAI
Gym&apos;s MuJoCo continuous control tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jiajin Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1&quot;&gt;Baoxiang Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1602.08199">
<title>Category Theoretic Analysis of Photon-based Decision Making. (arXiv:1602.08199v3 [physics.optics] UPDATED)</title>
<link>http://arxiv.org/abs/1602.08199</link>
<description rdf:parseType="Literal">&lt;p&gt;Decision making is a vital function in this age of machine learning and
artificial intelligence, yet its physical realization and theoretical
fundamentals are still not completely understood. In our former study, we
demonstrated that single-photons can be used to make decisions in uncertain,
dynamically changing environments. The two-armed bandit problem was
successfully solved using the dual probabilistic and particle attributes of
single photons. In this study, we present a category theoretic modeling and
analysis of single-photon-based decision making, including a quantitative
analysis that is in agreement with the experimental results. A category
theoretic model reveals the complex interdependencies of subject matter
entities in a simplified manner, even in dynamically changing environments. In
particular, the octahedral and braid structures in triangulated categories
provide a better understanding and quantitative metrics of the underlying
mechanisms of a single-photon decision maker. This study provides both insight
and a foundation for analyzing more complex and uncertain problems, to further
machine learning and artificial intelligence.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Naruse_M/0/1/0/all/0/1&quot;&gt;Makoto Naruse&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Kim_S/0/1/0/all/0/1&quot;&gt;Song-Ju Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Aono_M/0/1/0/all/0/1&quot;&gt;Masashi Aono&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Berthel_M/0/1/0/all/0/1&quot;&gt;Martin Berthel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Drezet_A/0/1/0/all/0/1&quot;&gt;Aur&amp;#xe9;lien Drezet&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Huant_S/0/1/0/all/0/1&quot;&gt;Serge Huant&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Hori_H/0/1/0/all/0/1&quot;&gt;Hirokazu Hori&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.07615">
<title>Neural Networks for Predicting Algorithm Runtime Distributions. (arXiv:1709.07615v3 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1709.07615</link>
<description rdf:parseType="Literal">&lt;p&gt;Many state-of-the-art algorithms for solving hard combinatorial problems in
artificial intelligence (AI) include elements of stochasticity that lead to
high variations in runtime, even for a fixed problem instance. Knowledge about
the resulting runtime distributions (RTDs) of algorithms on given problem
instances can be exploited in various meta-algorithmic procedures, such as
algorithm selection, portfolios, and randomized restarts. Previous work has
shown that machine learning can be used to individually predict mean, median
and variance of RTDs. To establish a new state-of-the-art in predicting RTDs,
we demonstrate that the parameters of an RTD should be learned jointly and that
neural networks can do this well by directly optimizing the likelihood of an
RTD given runtime observations. In an empirical study involving five algorithms
for SAT solving and AI planning, we show that neural networks predict the true
RTDs of unseen instances better than previous methods, and can even do so when
only few runtime observations are available per training instance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Eggensperger_K/0/1/0/all/0/1&quot;&gt;Katharina Eggensperger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lindauer_M/0/1/0/all/0/1&quot;&gt;Marius Lindauer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hutter_F/0/1/0/all/0/1&quot;&gt;Frank Hutter&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.09780">
<title>Bounded Policy Synthesis for POMDPs with Safe-Reachability Objectives. (arXiv:1801.09780v2 [cs.RO] UPDATED)</title>
<link>http://arxiv.org/abs/1801.09780</link>
<description rdf:parseType="Literal">&lt;p&gt;Planning robust executions under uncertainty is a fundamental challenge for
building autonomous robots. Partially Observable Markov Decision Processes
(POMDPs) provide a standard framework for modeling uncertainty in many
applications. In this work, we study POMDPs with safe-reachability objectives,
which require that with a probability above some threshold, a goal state is
eventually reached while keeping the probability of visiting unsafe states
below some threshold. This POMDP formulation is different from the traditional
POMDP models with optimality objectives and we show that in some cases, POMDPs
with safe-reachability objectives can provide a better guarantee of both safety
and reachability than the existing POMDP models through an example. A key
algorithmic problem for POMDPs is policy synthesis, which requires reasoning
over a vast space of beliefs (probability distributions). To address this
challenge, we introduce the notion of a goal-constrained belief space, which
only contains beliefs reachable from the initial belief under desired
executions that can achieve the given safe-reachability objective. Our method
compactly represents this space over a bounded horizon using symbolic
constraints, and employs an incremental Satisfiability Modulo Theories (SMT)
solver to efficiently search for a valid policy over it. We evaluate our method
using a case study involving a partially observable robotic domain with
uncertain obstacles. The results show that our method can synthesize policies
over large belief spaces with a small number of SMT solver calls by focusing on
the goal-constrained belief space.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yue Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chaudhuri_S/0/1/0/all/0/1&quot;&gt;Swarat Chaudhuri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kavraki_L/0/1/0/all/0/1&quot;&gt;Lydia E. Kavraki&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.07244">
<title>The Three Pillars of Machine Programming. (arXiv:1803.07244v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1803.07244</link>
<description rdf:parseType="Literal">&lt;p&gt;In this position paper, we describe our vision of the future of machine
programming through a categorical examination of three pillars of research.
Those pillars are: (i) intention, (ii) invention, and(iii) adaptation.
Intention emphasizes advancements in the human-to-computer and
computer-to-machine-learning interfaces. Invention emphasizes the creation or
refinement of algorithms or core hardware and software building blocks through
machine learning (ML). Adaptation emphasizes advances in the use of ML-based
constructs to autonomously evolve software.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gottschlich_J/0/1/0/all/0/1&quot;&gt;Justin Gottschlich&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Solar_Lezama_A/0/1/0/all/0/1&quot;&gt;Armando Solar-Lezama&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tatbul_N/0/1/0/all/0/1&quot;&gt;Nesime Tatbul&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Carbin_M/0/1/0/all/0/1&quot;&gt;Michael Carbin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rinard_M/0/1/0/all/0/1&quot;&gt;Martin Rinard&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barzilay_R/0/1/0/all/0/1&quot;&gt;Regina Barzilay&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Amarasinghe_S/0/1/0/all/0/1&quot;&gt;Saman Amarasinghe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tenenbaum_J/0/1/0/all/0/1&quot;&gt;Joshua B Tenenbaum&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mattson_T/0/1/0/all/0/1&quot;&gt;Tim Mattson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.03824">
<title>Reference-less Measure of Faithfulness for Grammatical Error Correction. (arXiv:1804.03824v4 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1804.03824</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose USim, a semantic measure for Grammatical Error Correction (GEC)
that measures the semantic faithfulness of the output to the source, thereby
complementing existing reference-less measures (RLMs) for measuring the
output&apos;s grammaticality. USim operates by comparing the semantic symbolic
structure of the source and the correction, without relying on manually-curated
references. Our experiments establish the validity of USim, by showing that (1)
semantic annotation can be consistently applied to ungrammatical text; (2)
valid corrections obtain a high USim similarity score to the source; and (3)
invalid corrections obtain a lower score.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Choshen_L/0/1/0/all/0/1&quot;&gt;Leshem Choshen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abend_O/0/1/0/all/0/1&quot;&gt;Omri Abend&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.06439">
<title>Personalized neural language models for real-world query auto completion. (arXiv:1804.06439v3 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1804.06439</link>
<description rdf:parseType="Literal">&lt;p&gt;Query auto completion (QAC) systems are a standard part of search engines in
industry, helping users formulate their query. Such systems update their
suggestions after the user types each character, predicting the user&apos;s intent
using various signals - one of the most common being popularity. Recently, deep
learning approaches have been proposed for the QAC task, to specifically
address the main limitation of previous popularity-based methods: the inability
to predict unseen queries. In this work we improve previous methods based on
neural language modeling, with the goal of building an end-to-end system. We
particularly focus on using real-world data by integrating user information for
personalized suggestions when possible. We also make use of time information
and study how to increase diversity in the suggestions while studying the
impact on scalability. Our empirical results demonstrate a marked improvement
on two separate datasets over previous best methods in both accuracy and
scalability, making a step towards neural query auto-completion in production
search engines.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fiorini_N/0/1/0/all/0/1&quot;&gt;Nicolas Fiorini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_Z/0/1/0/all/0/1&quot;&gt;Zhiyong Lu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.01157">
<title>Graph Bayesian Optimization: Algorithms, Evaluations and Applications. (arXiv:1805.01157v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1805.01157</link>
<description rdf:parseType="Literal">&lt;p&gt;Network structure optimization is a fundamental task in complex network
analysis. However, almost all the research on Bayesian optimization is aimed at
optimizing the objective functions with vectorial inputs. In this work, we
first present a flexible framework, denoted graph Bayesian optimization, to
handle arbitrary graphs in the Bayesian optimization community. By combining
the proposed framework with graph kernels, it can take full advantage of
implicit graph structural features to supplement explicit features guessed
according to the experience, such as tags of nodes and any attributes of
graphs. The proposed framework can identify which features are more important
during the optimization process. We apply the framework to solve four problems
including two evaluations and two applications to demonstrate its efficacy and
potential applications.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Cui_J/0/1/0/all/0/1&quot;&gt;Jiaxu Cui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yang_B/0/1/0/all/0/1&quot;&gt;Bo Yang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.02785">
<title>Fast Online Exact Solutions for Deterministic MDPs with Sparse Rewards. (arXiv:1805.02785v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.02785</link>
<description rdf:parseType="Literal">&lt;p&gt;Markov Decision Processes (MDPs) are a mathematical framework for modeling
sequential decision making under uncertainty. The classical approaches for
solving MDPs are well known and have been widely studied, some of which rely on
approximation techniques to solve MDPs with large state space and/or action
space. However, most of these classical solution approaches and their
approximation techniques still take much computation time to converge and
usually must be re-computed if the reward function is changed. This paper
introduces a novel alternative approach for exactly and efficiently solving
deterministic, continuous MDPs with sparse reward sources. When the environment
is such that the &quot;distance&quot; between states can be determined in constant time,
e.g. grid world, our algorithm offers $O( |R|^2 \times |A|^2 \times |S|)$,
where $|R|$ is the number of reward sources, $|A|$ is the number of actions,
and $|S|$ is the number of states. Memory complexity for the algorithm is $O(
|S| + |R| \times |A|)$. This new approach opens new avenues for boosting
computational performance for certain classes of MDPs and is of tremendous
value for MDP applications such as robotics and unmanned systems. This paper
describes the algorithm and presents numerical experiment results to
demonstrate its powerful computational performance. We also provide rigorous
mathematical description of the approach.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bertram_J/0/1/0/all/0/1&quot;&gt;Joshua R. Bertram&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1&quot;&gt;Xuxi Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wei_P/0/1/0/all/0/1&quot;&gt;Peng Wei&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.03294">
<title>Improved training of end-to-end attention models for speech recognition. (arXiv:1805.03294v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1805.03294</link>
<description rdf:parseType="Literal">&lt;p&gt;Sequence-to-sequence attention-based models on subword units allow simple
open-vocabulary end-to-end speech recognition. In this work, we show that such
models can achieve competitive results on the Switchboard 300h and LibriSpeech
1000h tasks. In particular, we report the state-of-the-art word error rates
(WER) of 3.54% on the dev-clean and 3.82% on the test-clean evaluation subsets
of LibriSpeech. We introduce a new pretraining scheme by starting with a high
time reduction factor and lowering it during training, which is crucial both
for convergence and final performance. In some experiments, we also use an
auxiliary CTC loss function to help the convergence. In addition, we train long
short-term memory (LSTM) language models on subword units. By shallow fusion,
we report up to 27% relative improvements in WER over the attention baseline
without a language model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zeyer_A/0/1/0/all/0/1&quot;&gt;Albert Zeyer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Irie_K/0/1/0/all/0/1&quot;&gt;Kazuki Irie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schluter_R/0/1/0/all/0/1&quot;&gt;Ralf Schl&amp;#xfc;ter&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ney_H/0/1/0/all/0/1&quot;&gt;Hermann Ney&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.03317">
<title>Subsampling Sequential Monte Carlo for Static Bayesian Models. (arXiv:1805.03317v1 [stat.CO])</title>
<link>http://arxiv.org/abs/1805.03317</link>
<description rdf:parseType="Literal">&lt;p&gt;Our article shows how to carry out Bayesian inference by combining data
subsampling with Sequential Monte Carlo (SMC). This takes advantage of the
attractive properties of SMC for Bayesian computations with the ability of
subsampling to tackle big data problems. SMC sequentially updates a cloud of
particles through a sequence of densities, beginning with a density that is
easy to sample from such as the prior and ending with the posterior density.
Each update of the particle cloud consists of three steps: reweighting,
resampling, and moving. In the move step, each particle is moved using a Markov
kernel and this is typically the most computationally expensive part,
particularly when the dataset is large. It is crucial to have an efficient move
step to ensure particle diversity. Our article makes two important
contributions. First, in order to speed up the SMC computation, we use an
approximately unbiased and efficient annealed likelihood estimator based on
data subsampling. The subsampling approach is more memory efficient than the
corresponding full data SMC, which is a great advantage for parallel
computation. Second, we use a Metropolis within Gibbs kernel with two
conditional updates. First, a Hamiltonian Monte Carlo update makes distant
moves for the model parameters. Second, a block pseudo-marginal proposal is
used for the particles corresponding to the auxiliary variables for the data
subsampling. We demonstrate the usefulness of the methodology using two large
datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gunawan_D/0/1/0/all/0/1&quot;&gt;David Gunawan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kohn_R/0/1/0/all/0/1&quot;&gt;Robert Kohn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Quiroz_M/0/1/0/all/0/1&quot;&gt;Matias Quiroz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Dang_K/0/1/0/all/0/1&quot;&gt;Khue-Dung Dang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tran_M/0/1/0/all/0/1&quot;&gt;Minh-Ngoc Tran&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.03444">
<title>Controlling the privacy loss with the input feature maps of the layers in convolutional neural networks. (arXiv:1805.03444v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.03444</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose the method to sanitize the privacy of the IFM(Input Feature Map)s
that are fed into the layers of CNN(Convolutional Neural Network)s. The method
introduces the degree of the sanitization that makes the application using a
CNN be able to control the privacy loss represented as the ratio of the
probabilistic accuracies for original IFM(Input Feature Map) and sanitized IFM.
For the sanitization of an IFM, the sample-and-hold based approximation scheme
is devised to satisfy an application-specific degree of the sanitization. The
scheme approximates an IFM by replacing all the samples in a window with the
non-zero sample closest to the mean of the sampling window. It also removes the
dependency on CNN configuration by unfolding multi-dimensional IFM tensors into
one-dimensional streams to be approximated.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chun_W/0/1/0/all/0/1&quot;&gt;Woohyung Chun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hong_S/0/1/0/all/0/1&quot;&gt;Sung-Min Hong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huh_J/0/1/0/all/0/1&quot;&gt;Junho Huh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kang_I/0/1/0/all/0/1&quot;&gt;Inyup Kang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.03463">
<title>Dealing with Categorical and Integer-valued Variables in Bayesian Optimization with Gaussian Processes. (arXiv:1805.03463v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.03463</link>
<description rdf:parseType="Literal">&lt;p&gt;Bayesian Optimization (BO) methods are useful for optimizing functions that
are expen- sive to evaluate, lack an analytical expression and whose
evaluations can be contaminated by noise. These methods rely on a probabilistic
model of the objective function, typically a Gaussian process (GP), upon which
an acquisition function is built. The acquisition function guides the
optimization process and measures the expected utility of performing an
evaluation of the objective at a new point. GPs assume continous input
variables. When this is not the case, for example when some of the input
variables take categorical or integer values, one has to introduce extra
approximations. Consider a suggested input location taking values in the real
line. Before doing the evaluation of the objective, a common approach is to use
a one hot encoding approximation for categorical variables, or to round to the
closest integer, in the case of integer-valued variables. We show that this can
lead to problems in the optimization process and describe a more principled
approach to account for input variables that are categorical or integer-valued.
We illustrate in both synthetic and a real experiments the utility of our
approach, which significantly improves the results of standard BO methods using
Gaussian processes on problems with categorical or integer-valued variables.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Garrido_Merchan_E/0/1/0/all/0/1&quot;&gt;Eduardo C. Garrido-Merch&amp;#xe1;n&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hernandez_Lobato_D/0/1/0/all/0/1&quot;&gt;Daniel Hern&amp;#xe1;ndez-Lobato&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.03504">
<title>Diffusion Based Network Embedding. (arXiv:1805.03504v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.03504</link>
<description rdf:parseType="Literal">&lt;p&gt;In network embedding, random walks play a fundamental role in preserving
network structures. However, random walk based embedding methods have two
limitations. First, random walk methods are fragile when the sampling frequency
or the number of node sequences changes. Second, in disequilibrium networks
such as highly biases networks, random walk methods often perform poorly due to
the lack of global network information. In order to solve the limitations, we
propose in this paper a network diffusion based embedding method. To solve the
first limitation, our method employs a diffusion driven process to capture both
depth information and breadth information. The time dimension is also attached
to node sequences that can strengthen information preserving. To solve the
second limitation, our method uses the network inference technique based on
cascades to capture the global network information. To verify the performance,
we conduct experiments on node classification tasks using the learned
representations. Results show that compared with random walk based methods,
diffusion based models are more robust when samplings under each node is rare.
We also conduct experiments on a highly imbalanced network. Results shows that
the proposed model are more robust under the biased network structure.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1&quot;&gt;Yong Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lei_M/0/1/0/all/0/1&quot;&gt;Minglong Lei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_P/0/1/0/all/0/1&quot;&gt;Peng Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Niu_L/0/1/0/all/0/1&quot;&gt;Lingfeng Niu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.03591">
<title>Secure Mobile Edge Computing in IoT via Collaborative Online Learning. (arXiv:1805.03591v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.03591</link>
<description rdf:parseType="Literal">&lt;p&gt;To accommodate heterogeneous tasks in Internet of Things (IoT), a new
communication and computing paradigm termed mobile edge computing emerges that
extends computing services from the cloud to edge, but at the same time exposes
new challenges on security. The present paper studies online security-aware
edge computing under jamming attacks. Leveraging online learning tools, novel
algorithms abbreviated as SAVE-S and SAVE-A are developed to cope with the
stochastic and adversarial forms of jamming, respectively. Without utilizing
extra resources such as spectrum and transmission power to evade jamming
attacks, SAVE-S and SAVE-A can select the most reliable server to offload
computing tasks with minimal privacy and security concerns. It is analytically
established that without any prior information on future jamming and server
security risks, the proposed schemes can achieve ${\cal O}\big(\sqrt{T}\big)$
regret. Information sharing among devices can accelerate the security-aware
computing tasks. Incorporating the information shared by other devices, SAVE-S
and SAVE-A offer impressive improvements on the sublinear regret, which is
guaranteed by what is termed &quot;value of cooperation.&quot; Effectiveness of the
proposed schemes is tested on both synthetic and real datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1&quot;&gt;Bingcong Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1&quot;&gt;Tianyi Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Giannakis_G/0/1/0/all/0/1&quot;&gt;Georgios B. Giannakis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.03620">
<title>On the Limitations of Unsupervised Bilingual Dictionary Induction. (arXiv:1805.03620v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1805.03620</link>
<description rdf:parseType="Literal">&lt;p&gt;Unsupervised machine translation---i.e., not assuming any cross-lingual
supervision signal, whether a dictionary, translations, or comparable
corpora---seems impossible, but nevertheless, Lample et al. (2018) recently
proposed a fully unsupervised machine translation (MT) model. The model relies
heavily on an adversarial, unsupervised alignment of word embedding spaces for
bilingual dictionary induction (Conneau et al., 2018), which we examine here.
Our results identify the limitations of current unsupervised MT: unsupervised
bilingual dictionary induction performs much worse on morphologically rich
languages that are not dependent marking, when monolingual corpora from
different domains or different embedding algorithms are used. We show that a
simple trick, exploiting a weak supervision signal from identical words,
enables more robust induction, and establish a near-perfect correlation between
unsupervised bilingual dictionary induction performance and a previously
unexplored graph similarity metric.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sogaard_A/0/1/0/all/0/1&quot;&gt;Anders S&amp;#xf8;gaard&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ruder_S/0/1/0/all/0/1&quot;&gt;Sebastian Ruder&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vulic_I/0/1/0/all/0/1&quot;&gt;Ivan Vuli&amp;#x107;&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.10266">
<title>Privacy-preserving Prediction. (arXiv:1803.10266v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1803.10266</link>
<description rdf:parseType="Literal">&lt;p&gt;Ensuring differential privacy of models learned from sensitive user data is
an important goal that has been studied extensively in recent years. It is now
known that for some basic learning problems, especially those involving
high-dimensional data, producing an accurate private model requires much more
data than learning without privacy. At the same time, in many applications it
is not necessary to expose the model itself. Instead users may be allowed to
query the prediction model on their inputs only through an appropriate
interface. Here we formulate the problem of ensuring privacy of individual
predictions and investigate the overheads required to achieve it in several
standard models of classification and regression.
&lt;/p&gt;
&lt;p&gt;We first describe a simple baseline approach based on training several models
on disjoint subsets of data and using standard private aggregation techniques
to predict. We show that this approach has nearly optimal sample complexity for
(realizable) PAC learning of any class of Boolean functions. At the same time,
without strong assumptions on the data distribution, the aggregation step
introduces a substantial overhead. We demonstrate that this overhead can be
avoided for the well-studied class of thresholds on a line and for a number of
standard settings of convex regression. The analysis of our algorithm for
learning thresholds relies crucially on strong generalization guarantees that
we establish for all differentially private prediction algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dwork_C/0/1/0/all/0/1&quot;&gt;Cynthia Dwork&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feldman_V/0/1/0/all/0/1&quot;&gt;Vitaly Feldman&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.00616">
<title>$\ell_1$-regression with Heavy-tailed Distributions. (arXiv:1805.00616v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.00616</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we consider the problem of linear regression with heavy-tailed
distributions. Different from previous studies that use the squared loss to
measure the performance, we choose the absolute loss, which is more robust in
the presence of large prediction errors. To address the challenge that both the
input and output could be heavy-tailed, we propose a truncated minimization
problem, and demonstrate that it enjoys an $\widetilde{O}(\sqrt{d/n})$ excess
risk, where $d$ is the dimensionality and $n$ is the number of samples.
Compared with traditional work on $\ell_1$-regression, the main advantage of
our result is that we achieve a high-probability risk bound without exponential
moment conditions on the input and output. Furthermore, if the input is
bounded, we show that the classical ERM is competent for $\ell_1$-regression
even when the output is heavy-tailed.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1&quot;&gt;Lijun Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1&quot;&gt;Zhi-Hua Zhou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.02627">
<title>Computing the Shattering Coefficient of Supervised Learning Algorithms. (arXiv:1805.02627v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.02627</link>
<description rdf:parseType="Literal">&lt;p&gt;The Statistical Learning Theory (SLT) provides the theoretical guarantees for
supervised machine learning based on the Empirical Risk Minimization Principle
(ERMP). Such principle defines an upper bound to ensure the uniform convergence
of the empirical risk Remp(f), i.e., the error measured on a given data sample,
to the expected value of risk R(f) (a.k.a. actual risk), which depends on the
Joint Probability Distribution P(X x Y) mapping input examples x in X to class
labels y in Y. The uniform convergence is only ensured when the Shattering
coefficient N(F,2n) has a polynomial growing behavior. This paper proves the
Shattering coefficient for any Hilbert space H containing the input space X and
discusses its effects in terms of learning guarantees for supervised machine
algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mello_R/0/1/0/all/0/1&quot;&gt;Rodrigo Fernandes de Mello&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ponti_M/0/1/0/all/0/1&quot;&gt;Moacir Antonelli Ponti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ferreira_C/0/1/0/all/0/1&quot;&gt;Carlos Henrique Grossi Ferreira&lt;/a&gt;</dc:creator>
</item></rdf:RDF>