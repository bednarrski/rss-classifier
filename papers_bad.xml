<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Boring papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Bad Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-09-12T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.04397"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.04430"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.04461"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.04106"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.04198"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.04232"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.04306"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.04322"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.04343"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.04344"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.04356"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.04382"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.04585"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1605.06588"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.10241"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07683"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.10568"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.08666"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.04069"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.04091"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.04121"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.04127"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.04184"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.04188"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.04197"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.04206"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.04216"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.04249"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.04262"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.04279"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.04294"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.04379"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.04400"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.04429"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.04440"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.04441"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.04481"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.04487"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.04542"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.04547"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.04559"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.04578"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1809.04587"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1510.01518"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1605.06718"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1705.09700"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1706.07834"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1708.05569"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.03222"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.09599"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.08824"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.07889"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07405"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08010"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08672"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04819"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.11876"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.00020"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.09897"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1809.04397">
<title>Isolated and Ensemble Audio Preprocessing Methods for Detecting Adversarial Examples against Automatic Speech Recognition. (arXiv:1809.04397v1 [cs.SD])</title>
<link>http://arxiv.org/abs/1809.04397</link>
<description rdf:parseType="Literal">&lt;p&gt;An adversarial attack is an exploitative process in which minute alterations
are made to natural inputs, causing the inputs to be misclassified by neural
models. In the field of speech recognition, this has become an issue of
increasing significance. Although adversarial attacks were originally
introduced in computer vision, they have since infiltrated the realm of speech
recognition. In 2017, a genetic attack was shown to be quite potent against the
Speech Commands Model. Limited-vocabulary speech classifiers, such as the
Speech Commands Model, are used in a variety of applications, particularly in
telephony; as such, adversarial examples produced by this attack pose as a
major security threat. This paper explores various methods of detecting these
adversarial examples with combinations of audio preprocessing. One particular
combined defense incorporating compressions, speech coding, filtering, and
audio panning was shown to be quite effective against the attack on the Speech
Commands Model, detecting audio adversarial examples with 93.5% precision and
91.2% recall.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rajaratnam_K/0/1/0/all/0/1&quot;&gt;Krishan Rajaratnam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shah_K/0/1/0/all/0/1&quot;&gt;Kunal Shah&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kalita_J/0/1/0/all/0/1&quot;&gt;Jugal Kalita&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.04430">
<title>Deep learning to achieve clinically applicable segmentation of head and neck anatomy for radiotherapy. (arXiv:1809.04430v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1809.04430</link>
<description rdf:parseType="Literal">&lt;p&gt;Over half a million individuals are diagnosed with head and neck cancer each
year worldwide. Radiotherapy is an important curative treatment for this
disease, but it requires manually intensive delineation of radiosensitive
organs at risk (OARs). This planning process can delay treatment commencement.
While auto-segmentation algorithms offer a potentially time-saving solution,
the challenges in defining, quantifying and achieving expert performance
remain. Adopting a deep learning approach, we demonstrate a 3D U-Net
architecture that achieves performance similar to experts in delineating a wide
range of head and neck OARs. The model was trained on a dataset of 663
deidentified computed tomography (CT) scans acquired in routine clinical
practice and segmented according to consensus OAR definitions. We demonstrate
its generalisability through application to an independent test set of 24 CT
scans available from The Cancer Imaging Archive collected at multiple
international sites previously unseen to the model, each segmented by two
independent experts and consisting of 21 OARs commonly segmented in clinical
practice. With appropriate validation studies and regulatory approvals, this
system could improve the effectiveness of radiotherapy pathways.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nikolov_S/0/1/0/all/0/1&quot;&gt;Stanislav Nikolov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Blackwell_S/0/1/0/all/0/1&quot;&gt;Sam Blackwell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mendes_R/0/1/0/all/0/1&quot;&gt;Ruheena Mendes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fauw_J/0/1/0/all/0/1&quot;&gt;Jeffrey De Fauw&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meyer_C/0/1/0/all/0/1&quot;&gt;Clemens Meyer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hughes_C/0/1/0/all/0/1&quot;&gt;C&amp;#xed;an Hughes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Askham_H/0/1/0/all/0/1&quot;&gt;Harry Askham&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Romera_Paredes_B/0/1/0/all/0/1&quot;&gt;Bernardino Romera-Paredes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Karthikesalingam_A/0/1/0/all/0/1&quot;&gt;Alan Karthikesalingam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chu_C/0/1/0/all/0/1&quot;&gt;Carlton Chu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Carnell_D/0/1/0/all/0/1&quot;&gt;Dawn Carnell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Boon_C/0/1/0/all/0/1&quot;&gt;Cheng Boon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+DSouza_D/0/1/0/all/0/1&quot;&gt;Derek D&amp;#x27;Souza&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moinuddin_S/0/1/0/all/0/1&quot;&gt;Syed Ali Moinuddin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sullivan_K/0/1/0/all/0/1&quot;&gt;Kevin Sullivan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Consortium_D/0/1/0/all/0/1&quot;&gt;DeepMind Radiographer Consortium&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Montgomery_H/0/1/0/all/0/1&quot;&gt;Hugh Montgomery&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rees_G/0/1/0/all/0/1&quot;&gt;Geraint Rees&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sharma_R/0/1/0/all/0/1&quot;&gt;Ricky Sharma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Suleyman_M/0/1/0/all/0/1&quot;&gt;Mustafa Suleyman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Back_T/0/1/0/all/0/1&quot;&gt;Trevor Back&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ledsam_J/0/1/0/all/0/1&quot;&gt;Joseph R. Ledsam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ronneberger_O/0/1/0/all/0/1&quot;&gt;Olaf Ronneberger&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.04461">
<title>DeepProteomics: Protein family classification using Shallow and Deep Networks. (arXiv:1809.04461v1 [q-bio.QM])</title>
<link>http://arxiv.org/abs/1809.04461</link>
<description rdf:parseType="Literal">&lt;p&gt;The knowledge regarding the function of proteins is necessary as it gives a
clear picture of biological processes. Nevertheless, there are many protein
sequences found and added to the databases but lacks functional annotation. The
laboratory experiments take a considerable amount of time for annotation of the
sequences. This arises the need to use computational techniques to classify
proteins based on their functions. In our work, we have collected the data from
Swiss-Prot containing 40433 proteins which is grouped into 30 families. We pass
it to recurrent neural network(RNN), long short term memory(LSTM) and gated
recurrent unit(GRU) model and compare it by applying trigram with deep neural
network and shallow neural network on the same dataset. Through this approach,
we could achieve maximum of around 78% accuracy for the classification of
protein families.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Vazhayil_A/0/1/0/all/0/1&quot;&gt;Anu Vazhayil&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+R_V/0/1/0/all/0/1&quot;&gt;Vinayakumar R&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+KP_S/0/1/0/all/0/1&quot;&gt;Soman KP&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.04106">
<title>ACM RecSys 2018 Late-Breaking Results Proceedings. (arXiv:1809.04106v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1809.04106</link>
<description rdf:parseType="Literal">&lt;p&gt;The ACM RecSys&apos;18 Late-Breaking Results track (previously known as the Poster
track) is part of the main program of the 2018 ACM Conference on Recommender
Systems in Vancouver, Canada. The track attracted 48 submissions this year out
of which 18 papers could be accepted resulting in an acceptance rated of 37.5%.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Trattner_C/0/1/0/all/0/1&quot;&gt;Christoph Trattner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Murdock_V/0/1/0/all/0/1&quot;&gt;Vanessa Murdock&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chang_S/0/1/0/all/0/1&quot;&gt;Steven Chang&lt;/a&gt; (Quora)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.04198">
<title>Optimization with Non-Differentiable Constraints with Applications to Fairness, Recall, Churn, and Other Goals. (arXiv:1809.04198v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1809.04198</link>
<description rdf:parseType="Literal">&lt;p&gt;We show that many machine learning goals, such as improved fairness metrics,
can be expressed as constraints on the model&apos;s predictions, which we call rate
constraints. We study the problem of training non-convex models subject to
these rate constraints (or any non-convex and non-differentiable constraints).
In the non-convex setting, the standard approach of Lagrange multipliers may
fail. Furthermore, if the constraints are non-differentiable, then one cannot
optimize the Lagrangian with gradient-based methods. To solve these issues, we
introduce the proxy-Lagrangian formulation. This new formulation leads to an
algorithm that produces a stochastic classifier by playing a two-player
non-zero-sum game solving for what we call a semi-coarse correlated
equilibrium, which in turn corresponds to an approximately optimal and feasible
solution to the constrained optimization problem. We then give a procedure
which shrinks the randomized solution down to one that is a mixture of at most
$m+1$ deterministic solutions, given $m$ constraints. This culminates in
algorithms that can solve non-convex constrained optimization problems with
possibly non-differentiable and non-convex constraints with theoretical
guarantees. We provide extensive experimental results enforcing a wide range of
policy goals including different fairness metrics, and other goals on accuracy,
coverage, recall, and churn.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cotter_A/0/1/0/all/0/1&quot;&gt;Andrew Cotter&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1&quot;&gt;Heinrich Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1&quot;&gt;Serena Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Narayan_T/0/1/0/all/0/1&quot;&gt;Taman Narayan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gupta_M/0/1/0/all/0/1&quot;&gt;Maya Gupta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+You_S/0/1/0/all/0/1&quot;&gt;Seungil You&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sridharan_K/0/1/0/all/0/1&quot;&gt;Karthik Sridharan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.04232">
<title>Safe Exploration in Markov Decision Processes with Time-Variant Safety using Spatio-Temporal Gaussian Process. (arXiv:1809.04232v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1809.04232</link>
<description rdf:parseType="Literal">&lt;p&gt;In many real-world applications (e.g., planetary exploration, robot
navigation), an autonomous agent must be able to explore a space with
guaranteed safety. Most safe exploration algorithms in the field of
reinforcement learning and robotics have been based on the assumption that the
safety features are a priori known and time-invariant. This paper presents a
learning algorithm called ST-SafeMDP for exploring Markov decision processes
(MDPs) that is based on the assumption that the safety features are a priori
unknown and time-variant. In this setting, the agent explores MDPs while
constraining the probability of entering unsafe states defined by a safety
function being below a threshold. The unknown and time-variant safety values
are modeled using a spatio-temporal Gaussian process. However, there remains an
issue that an agent may have no viable action in a shrinking true safe space.
To address this issue, we formulate a problem maximizing the cumulative number
of safe states in the worst case scenario with respect to future observations.
The effectiveness of this approach was demonstrated in two simulation settings,
including one using real lunar terrain data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wachi_A/0/1/0/all/0/1&quot;&gt;Akifumi Wachi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kajino_H/0/1/0/all/0/1&quot;&gt;Hiroshi Kajino&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Munawar_A/0/1/0/all/0/1&quot;&gt;Asim Munawar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.04306">
<title>Chinese Poetry Generation with a Working Memory Model. (arXiv:1809.04306v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1809.04306</link>
<description rdf:parseType="Literal">&lt;p&gt;As an exquisite and concise literary form, poetry is a gem of human culture.
Automatic poetry generation is an essential step towards computer creativity.
In recent years, several neural models have been designed for this task.
However, among lines of a whole poem, the coherence in meaning and topics still
remains a big challenge. In this paper, inspired by the theoretical concept in
cognitive psychology, we propose a novel Working Memory model for poetry
generation. Different from previous methods, our model explicitly maintains
topics and informative limited history in a neural memory. During the
generation process, our model reads the most relevant parts from memory slots
to generate the current line. After each line is generated, it writes the most
salient parts of the previous line into memory slots. By dynamic manipulation
of the memory, our model keeps a coherent information flow and learns to
express each topic flexibly and naturally. We experiment on three different
genres of Chinese poetry: quatrain, iambic and chinoiserie lyric. Both
automatic and human evaluation results show that our model outperforms current
state-of-the-art methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yi_X/0/1/0/all/0/1&quot;&gt;Xiaoyuan Yi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1&quot;&gt;Maosong Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_R/0/1/0/all/0/1&quot;&gt;Ruoyu Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1&quot;&gt;Zonghan Yang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.04322">
<title>Reinforcement Learning in Topology-based Representation for Human Body Movement with Whole Arm Manipulation. (arXiv:1809.04322v1 [cs.RO])</title>
<link>http://arxiv.org/abs/1809.04322</link>
<description rdf:parseType="Literal">&lt;p&gt;Moving a human body or a large and bulky object can require the strength of
whole arm manipulation (WAM). This type of manipulation places the load on the
robot&apos;s arms and relies on global properties of the interaction to
succeed---rather than local contacts such as grasping or non-prehensile
pushing. In this paper, we learn to generate motions that enable WAM for
holding and transporting of humans in certain rescue or patient care scenarios.
We model the task as a reinforcement learning problem in order to provide a
behavior that can directly respond to external perturbation and human motion.
For this, we represent global properties of the robot-human interaction with
topology-based coordinates that are computed from arm and torso positions.
These coordinates also allow transferring the learned policy to other body
shapes and sizes. For training and evaluation, we simulate a dynamic sea rescue
scenario and show in quantitative experiments that the policy can solve unseen
scenarios with differently-shaped humans, floating humans, or with perception
noise. Our qualitative experiments show the subsequent transporting after
holding is achieved and we demonstrate that the policy can be directly
transferred to a real world setting.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yuan_W/0/1/0/all/0/1&quot;&gt;Weihao Yuan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hang_K/0/1/0/all/0/1&quot;&gt;Kaiyu Hang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_H/0/1/0/all/0/1&quot;&gt;Haoran Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kragic_D/0/1/0/all/0/1&quot;&gt;Danica Kragic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1&quot;&gt;Michael Y. Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stork_J/0/1/0/all/0/1&quot;&gt;Johannes A. Stork&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.04343">
<title>Compact Optimization Algorithms with Re-sampled Inheritance. (arXiv:1809.04343v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1809.04343</link>
<description rdf:parseType="Literal">&lt;p&gt;Compact optimization algorithms are a class of Estimation of Distribution
Algorithms (EDAs) characterized by extremely limited memory requirements (hence
they are called &quot;compact&quot;). As all EDAs, compact algorithms build and update a
probabilistic model of the distribution of solutions within the search space,
as opposed to population-based algorithms that instead make use of an explicit
population of solutions. In addition to that, to keep their memory consumption
low, compact algorithms purposely employ simple probabilistic models that can
be described with a small number of parameters. Despite their simplicity,
compact algorithms have shown good performances on a broad range of benchmark
functions and real-world problems. However, compact algorithms also come with
some drawbacks, i.e. they tend to premature convergence and show poorer
performance on non-separable problems. To overcome these limitations, here we
investigate a possible memetic computing approach obtained by combining compact
algorithms with a non-disruptive restart mechanism taken from the literature,
named Re-Sampled Inheritance (RI). The resulting compact algorithms with RI are
then tested on the CEC 2014 benchmark functions. The numerical results show on
the one hand that the use of RI consistently enhances the performances of
compact algorithms, still keeping a limited usage of memory. On the other hand,
our experiments show that among the tested algorithms, the best performance is
obtained by compact Differential Evolution with RI.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Iacca_G/0/1/0/all/0/1&quot;&gt;Giovanni Iacca&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Caraffini_F/0/1/0/all/0/1&quot;&gt;Fabio Caraffini&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.04344">
<title>The Wisdom of MaSSeS: Majority, Subjectivity, and Semantic Similarity in the Evaluation of VQA. (arXiv:1809.04344v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1809.04344</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce MASSES, a simple evaluation metric for the task of Visual
Question Answering (VQA). In its standard form, the VQA task is operationalized
as follows: Given an image and an open-ended question in natural language,
systems are required to provide a suitable answer. Currently, model performance
is evaluated by means of a somehow simplistic metric: If the predicted answer
is chosen by at least 3 human annotators out of 10, then it is 100% correct.
Though intuitively valuable, this metric has some important limitations. First,
it ignores whether the predicted answer is the one selected by the Majority
(MA) of annotators. Second, it does not account for the quantitative
Subjectivity (S) of the answers in the sample (and dataset). Third, information
about the Semantic Similarity (SES) of the responses is completely neglected.
Based on such limitations, we propose a multi-component metric that accounts
for all these issues. We show that our metric is effective in providing a more
fine-grained evaluation both on the quantitative and qualitative level.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jolly_S/0/1/0/all/0/1&quot;&gt;Shailza Jolly&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pezzelle_S/0/1/0/all/0/1&quot;&gt;Sandro Pezzelle&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Klein_T/0/1/0/all/0/1&quot;&gt;Tassilo Klein&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dengel_A/0/1/0/all/0/1&quot;&gt;Andreas Dengel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nabi_M/0/1/0/all/0/1&quot;&gt;Moin Nabi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.04356">
<title>Deep learning for time series classification: a review. (arXiv:1809.04356v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1809.04356</link>
<description rdf:parseType="Literal">&lt;p&gt;Time Series Classification (TSC) is an important and challenging problem in
data mining. With the increase of time series data availability, hundreds of
TSC algorithms have been proposed. Among these methods, only a few have
considered Deep Neural Networks (DNNs) to perform this task. This is surprising
as deep learning has seen very successful applications in the last years. DNNs
have indeed revolutionized the field of computer vision especially with the
advent of novel deeper architectures such as Residual and Convolutional Neural
Networks. Apart from images, sequential data such as text and audio can also be
processed with DNNs to reach state of the art performance for document
classification and speech recognition. In this article, we study the current
state of the art performance of deep learning algorithms for TSC by presenting
an empirical study of the most recent DNN architectures for TSC. We give an
overview of the most successful deep learning applications in various time
series domains under a unified taxonomy of DNNs for TSC. We also provide an
open source deep learning framework to the TSC community where we implemented
each of the compared approaches and evaluated them on a univariate TSC
benchmark (the UCR archive) and 12 multivariate time series datasets. By
training 8,730 deep learning models on 97 time series datasets, we propose the
most exhaustive study of DNNs for TSC to date.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fawaz_H/0/1/0/all/0/1&quot;&gt;Hassan Ismail Fawaz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Forestier_G/0/1/0/all/0/1&quot;&gt;Germain Forestier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Weber_J/0/1/0/all/0/1&quot;&gt;Jonathan Weber&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Idoumghar_L/0/1/0/all/0/1&quot;&gt;Lhassane Idoumghar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Muller_P/0/1/0/all/0/1&quot;&gt;Pierre-Alain Muller&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.04382">
<title>A Framework for Approval-based Budgeting Methods. (arXiv:1809.04382v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1809.04382</link>
<description rdf:parseType="Literal">&lt;p&gt;We define and study a general framework for approval-based budgeting methods
and compare certain methods within this framework by their axiomatic and
computational properties. Furthermore, we visualize their behavior on certain
Euclidean distributions and analyze them experimentally.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Faliszewski_P/0/1/0/all/0/1&quot;&gt;Piotr Faliszewski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Talmon_N/0/1/0/all/0/1&quot;&gt;Nimrod Talmon&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.04585">
<title>Closed-Book Training to Improve Summarization Encoder Memory. (arXiv:1809.04585v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1809.04585</link>
<description rdf:parseType="Literal">&lt;p&gt;A good neural sequence-to-sequence summarization model should have a strong
encoder that can distill and memorize the important information from long input
texts so that the decoder can generate salient summaries based on the encoder&apos;s
memory. In this paper, we aim to improve the memorization capabilities of the
encoder of a pointer-generator model by adding an additional &apos;closed-book&apos;
decoder without attention and pointer mechanisms. Such a decoder forces the
encoder to be more selective in the information encoded in its memory state
because the decoder can&apos;t rely on the extra information provided by the
attention and possibly copy modules, and hence improves the entire model. On
the CNN/Daily Mail dataset, our 2-decoder model outperforms the baseline
significantly in terms of ROUGE and METEOR metrics, for both cross-entropy and
reinforced setups (and on human evaluation). Moreover, our model also achieves
higher scores in a test-only DUC-2002 generalizability setup. We further
present a memory ability test, two saliency metrics, as well as several
sanity-check ablations (based on fixed-encoder, gradient-flow cut, and model
capacity) to prove that the encoder of our 2-decoder model does in fact learn
stronger memory representations than the baseline encoder.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1&quot;&gt;Yichen Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bansal_M/0/1/0/all/0/1&quot;&gt;Mohit Bansal&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1605.06588">
<title>Optimal Number of Choices in Rating Contexts. (arXiv:1605.06588v7 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1605.06588</link>
<description rdf:parseType="Literal">&lt;p&gt;In many settings people must give numerical scores to entities from a small
discrete set. For instance, rating physical attractiveness from 1--5 on dating
sites, or papers from 1--10 for conference reviewing. We study the problem of
understanding when using a different number of options is optimal. We consider
the case when scores are uniform random and Gaussian. We study when using 2, 3,
4, 5, and 10 options out of a total of 100 is optimal in these models. One may
expect that using more options would always improve performance in this model,
but we show that this is not necessarily the case, and that using fewer
choices---even just two---can surprisingly be optimal in certain situations.
While in theory for this setting it would be optimal to use all 100 options, in
practice this is prohibitive, and it is preferable to utilize a smaller number
of options due to humans&apos; limited computational resources. Our results could
have many potential applications, as settings requiring entities to be ranked
by humans are ubiquitous. There could also be applications to other fields such
as signal or image processing where input values from a large set must be
mapped to output values in a smaller set.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ganzfried_S/0/1/0/all/0/1&quot;&gt;Sam Ganzfried&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yusuf_F/0/1/0/all/0/1&quot;&gt;Farzana Yusuf&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.10241">
<title>The Price of Diversity in Assignment Problems. (arXiv:1711.10241v4 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1711.10241</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce and analyze an extension to the matching problem on a weighted
bipartite graph: Assignment with Type Constraints. The two parts of the graph
are partitioned into subsets called types and blocks; we seek a matching with
the largest sum of weights under the constraint that there is a pre-specified
cap on the number of vertices matched in every type-block pair. Our primary
motivation stems from the public housing program of Singapore, accounting for
over 70% of its residential real estate. To promote ethnic diversity within its
housing projects, Singapore imposes ethnicity quotas: each new housing
development comprises blocks of flats and each ethnicity-based group in the
population must not own more than a certain percentage of flats in a block.
Other domains using similar hard capacity constraints include matching
prospective students to schools or medical residents to hospitals. Limiting
agents&apos; choices for ensuring diversity in this manner naturally entails some
welfare loss. One of our goals is to study the trade-off between diversity and
social welfare in such settings. We first show that, while the classic
assignment program is polynomial-time computable, adding diversity constraints
makes it computationally intractable; however, we identify a
$\tfrac{1}{2}$-approximation algorithm, as well as reasonable assumptions on
the weights that permit poly-time algorithms. Next, we provide two upper bounds
on the price of diversity -- a measure of the loss in welfare incurred by
imposing diversity constraints -- as functions of natural problem parameters.
We conclude the paper with simulations based on publicly available data from
two diversity-constrained allocation problems -- Singapore Public Housing and
Chicago School Choice -- which shed light on how the constrained maximization
as well as lottery-based variants perform in practice.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Benabbou_N/0/1/0/all/0/1&quot;&gt;Nawal Benabbou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chakraborty_M/0/1/0/all/0/1&quot;&gt;Mithun Chakraborty&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xuan_V/0/1/0/all/0/1&quot;&gt;Vinh Ho Xuan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sliwinski_J/0/1/0/all/0/1&quot;&gt;Jakub Sliwinski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zick_Y/0/1/0/all/0/1&quot;&gt;Yair Zick&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07683">
<title>Learning Graph-Level Representations with Recurrent Neural Networks. (arXiv:1805.07683v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.07683</link>
<description rdf:parseType="Literal">&lt;p&gt;Recently a variety of methods have been developed to encode graphs into
low-dimensional vectors that can be easily exploited by machine learning
algorithms. The majority of these methods start by embedding the graph nodes
into a low-dimensional vector space, followed by using some scheme to aggregate
the node embeddings. In this work, we develop a new approach to learn
graph-level representations, which includes a combination of unsupervised and
supervised learning components. We start by learning a set of node
representations in an unsupervised fashion. Graph nodes are mapped into node
sequences sampled from random walk approaches approximated by the
Gumbel-Softmax distribution. Recurrent neural network (RNN) units are modified
to accommodate both the node representations as well as their neighborhood
information. Experiments on standard graph classification benchmarks
demonstrate that our proposed approach achieves superior or comparable
performance relative to the state-of-the-art algorithms in terms of convergence
speed and classification accuracy. We further illustrate the effectiveness of
the different components used by our approach.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jin_Y/0/1/0/all/0/1&quot;&gt;Yu Jin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+JaJa_J/0/1/0/all/0/1&quot;&gt;Joseph F. JaJa&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.10568">
<title>Multi-Hop Knowledge Graph Reasoning with Reward Shaping. (arXiv:1808.10568v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1808.10568</link>
<description rdf:parseType="Literal">&lt;p&gt;Multi-hop reasoning is an effective approach for query answering (QA) over
incomplete knowledge graphs (KGs). The problem can be formulated in a
reinforcement learning (RL) setup, where a policy-based agent sequentially
extends its inference path until it reaches a target. However, in an incomplete
KG environment, the agent receives low-quality rewards corrupted by false
negatives in the training data, which harms generalization at test time.
Furthermore, since no golden action sequence is used for training, the agent
can be misled by spurious search trajectories that incidentally lead to the
correct answer. We propose two modeling advances to address both issues: (1) we
reduce the impact of false negative supervision by adopting a pretrained
one-hop embedding model to estimate the reward of unobserved facts; (2) we
counter the sensitivity to spurious paths of on-policy RL by forcing the agent
to explore a diverse set of paths using randomly generated edge masks. Our
approach significantly improves over existing path-based KGQA models on several
benchmark datasets and is comparable or better than embedding-based models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_X/0/1/0/all/0/1&quot;&gt;Xi Victoria Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Socher_R/0/1/0/all/0/1&quot;&gt;Richard Socher&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiong_C/0/1/0/all/0/1&quot;&gt;Caiming Xiong&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.08666">
<title>APR: Architectural Pattern Recommender. (arXiv:1803.08666v1 [cs.SE] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1803.08666</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper proposes Architectural Pattern Recommender (APR) system which
helps in such architecture selection process. Main contribution of this work is
in replacing the manual effort required to identify and analyse relevant
architectural patterns in context of a particular set of software requirements.
Key input to APR is a set of architecturally significant use cases concerning
the application being developed. Central idea of APR&apos;s design is two folds: a)
transform the unstructured information about software architecture design into
a structured form which is suitable for recognizing textual entailment between
a requirement scenario and a potential architectural pattern. b) leverage the
rich experiential knowledge embedded in discussions on professional developer
support forums such as Stackoverflow to check the sentiment about a design
decision. APR makes use of both the above elements to identify a suitable
architectural pattern and assess its suitability for a given set of
requirements. Efficacy of APR has been evaluated by comparing its
recommendations for &quot;ground truth&quot; scenarios (comprising of applications whose
architecture is well known).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sharma_S/0/1/0/all/0/1&quot;&gt;Shipra Sharma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sodhi_B/0/1/0/all/0/1&quot;&gt;Balwinder Sodhi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.04069">
<title>Estimate the Warfarin Dose by Ensemble of Machine Learning Algorithms. (arXiv:1809.04069v1 [q-bio.QM])</title>
<link>http://arxiv.org/abs/1809.04069</link>
<description rdf:parseType="Literal">&lt;p&gt;Warfarin dosing remains challenging due to narrow therapeutic index and
highly individual variability. Incorrect warfarin dosing is associated with
devastating adverse events. Remarkable efforts have been made to develop the
machine learning based warfarin dosing algorithms incorporating clinical
factors and genetic variants such as polymorphisms in CYP2C9 and VKORC1. The
most widely validated pharmacogenetic algorithm is the IWPC algorithm based on
multivariate linear regression (MLR). However, with only a single algorithm,
the prediction performance may reach an upper limit even with optimal
parameters. Here, we present novel algorithms using stacked generalization
frameworks to estimate the warfarin dose, within which different types of
machine learning algorithms function together through a meta-machine learning
model to maximize the prediction accuracy. Compared to the IWPC-derived MLR
algorithm, Stack 1 and 2 based on stacked generalization frameworks performed
significantly better overall. Subgroup analysis revealed that the mean of the
percentage of patients whose predicted dose of warfarin within 20% of the
actual stable therapeutic dose (mean percentage within 20%) for Stack 1 was
improved by 12.7% (from 42.47% to 47.86%) in Asians and by 13.5% (from 22.08%
to 25.05%) in the low-dose group compared to that for MLR, respectively. These
data suggest that our algorithms would especially benefit patients required low
warfarin maintenance dose, as subtle changes in warfarin dose could lead to
adverse clinical events (thrombosis or bleeding) in patients with low dose. Our
study offers novel pharmacogenetic algorithms for clinical trials and practice.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Ma_Z/0/1/0/all/0/1&quot;&gt;Zhiyuan Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Wang_P/0/1/0/all/0/1&quot;&gt;Ping Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Gao_Z/0/1/0/all/0/1&quot;&gt;Zehui Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Wang_R/0/1/0/all/0/1&quot;&gt;Ruobing Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Khalighi_K/0/1/0/all/0/1&quot;&gt;Koroush Khalighi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.04091">
<title>Smooth Structured Prediction Using Quantum and Classical Gibbs Samplers. (arXiv:1809.04091v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1809.04091</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce a quantum algorithm for solving structured-prediction problems
with a runtime that scales with the square root of the size of the label space,
but scales in $\widetilde O\left(\frac{1}{\epsilon^5}\right)$ with respect to
the precision of the solution. In doing so, we analyze a stochastic gradient
algorithm for convex optimization in the presence of an additive error in the
calculation of the gradients, and show that its convergence rate does not
deteriorate if the additive errors are of the order $\widetilde O(\epsilon)$.
Our algorithm uses quantum Gibbs sampling at temperature $O (\epsilon)$ as a
subroutine. Numerical results using Monte Carlo simulations on an image tagging
task demonstrate the benefit of the approach.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sepehry_B/0/1/0/all/0/1&quot;&gt;Behrooz Sepehry&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Iranmanesh_E/0/1/0/all/0/1&quot;&gt;Ehsan Iranmanesh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Friedlander_M/0/1/0/all/0/1&quot;&gt;Michael P. Friedlander&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ronagh_P/0/1/0/all/0/1&quot;&gt;Pooya Ronagh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.04121">
<title>Cartesian Neural Network Constitutive Models for Data-driven Elasticity Imaging. (arXiv:1809.04121v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1809.04121</link>
<description rdf:parseType="Literal">&lt;p&gt;Elasticity images map biomechanical properties of soft tissues to aid in the
detection and diagnosis of pathological states. In particular, quasi-static
ultrasonic (US) elastography techniques use force-displacement measurements
acquired during an US scan to parameterize the spatio-temporal stress-strain
behavior. Current methods use a model-based inverse approach to estimate the
parameters associated with a chosen constitutive model. However, model-based
methods rely on simplifying assumptions of tissue biomechanical properties,
often limiting elastography to imaging one or two linear-elastic parameters.
&lt;/p&gt;
&lt;p&gt;We previously described a data-driven method for building neural network
constitutive models (NNCMs) that learn stress-strain relationships from
force-displacement data. Using measurements acquired on gelatin phantoms, we
demonstrated the ability of NNCMs to characterize linear-elastic mechanical
properties without an initial model assumption and thus circumvent the
mathematical constraints typically encountered in classic model-based
approaches to the inverse problem. While successful, we were required to use a
priori knowledge of the internal object shape to define the spatial
distribution of regions exhibiting different material properties.
&lt;/p&gt;
&lt;p&gt;Here, we introduce Cartesian neural network constitutive models (CaNNCMs)
that are capable of using data to model both linear-elastic mechanical
properties and their distribution in space. We demonstrate the ability of
CaNNCMs to capture arbitrary material property distributions using
stress-strain data from simulated phantoms. Furthermore, we show that a trained
CaNNCM can be used to reconstruct a Young&apos;s modulus image. CaNNCMs are an
important step toward data-driven modeling and imaging the complex mechanical
properties of soft tissues.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hoerig_C/0/1/0/all/0/1&quot;&gt;Cameron Hoerig&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghaboussi_J/0/1/0/all/0/1&quot;&gt;Jamshid Ghaboussi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Insana_M/0/1/0/all/0/1&quot;&gt;Michael F. Insana&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.04127">
<title>Poisoning Attacks to Graph-Based Recommender Systems. (arXiv:1809.04127v1 [cs.IR])</title>
<link>http://arxiv.org/abs/1809.04127</link>
<description rdf:parseType="Literal">&lt;p&gt;Recommender system is an important component of many web services to help
users locate items that match their interests. Several studies showed that
recommender systems are vulnerable to poisoning attacks, in which an attacker
injects fake data to a given system such that the system makes recommendations
as the attacker desires. However, these poisoning attacks are either agnostic
to recommendation algorithms or optimized to recommender systems that are not
graph-based. Like association-rule-based and matrix-factorization-based
recommender systems, graph-based recommender system is also deployed in
practice, e.g., eBay, Huawei App Store. However, how to design optimized
poisoning attacks for graph-based recommender systems is still an open problem.
In this work, we perform a systematic study on poisoning attacks to graph-based
recommender systems. Due to limited resources and to avoid detection, we assume
the number of fake users that can be injected into the system is bounded. The
key challenge is how to assign rating scores to the fake users such that the
target item is recommended to as many normal users as possible. To address the
challenge, we formulate the poisoning attacks as an optimization problem,
solving which determines the rating scores for the fake users. We also propose
techniques to solve the optimization problem. We evaluate our attacks and
compare them with existing attacks under white-box (recommendation algorithm
and its parameters are known), gray-box (recommendation algorithm is known but
its parameters are unknown), and black-box (recommendation algorithm is
unknown) settings using two real-world datasets. Our results show that our
attack is effective and outperforms existing attacks for graph-based
recommender systems. For instance, when 1% fake users are injected, our attack
can make a target item recommended to 580 times more normal users in certain
scenarios.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fang_M/0/1/0/all/0/1&quot;&gt;Minghong Fang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_G/0/1/0/all/0/1&quot;&gt;Guolei Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gong_N/0/1/0/all/0/1&quot;&gt;Neil Zhenqiang Gong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Jia Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.04184">
<title>Searching for Efficient Multi-Scale Architectures for Dense Image Prediction. (arXiv:1809.04184v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1809.04184</link>
<description rdf:parseType="Literal">&lt;p&gt;The design of neural network architectures is an important component for
achieving state-of-the-art performance with machine learning systems across a
broad array of tasks. Much work has endeavored to design and build
architectures automatically through clever construction of a search space
paired with simple learning algorithms. Recent progress has demonstrated that
such meta-learning methods may exceed scalable human-invented architectures on
image classification tasks. An open question is the degree to which such
methods may generalize to new domains. In this work we explore the construction
of meta-learning techniques for dense image prediction focused on the tasks of
scene parsing, person-part segmentation, and semantic image segmentation.
Constructing viable search spaces in this domain is challenging because of the
multi-scale representation of visual information and the necessity to operate
on high resolution imagery. Based on a survey of techniques in dense image
prediction, we construct a recursive search space and demonstrate that even
with efficient random search, we can identify architectures that outperform
human-invented architectures and achieve state-of-the-art performance on three
dense prediction tasks including 82.7\% on Cityscapes (street scene parsing),
71.3\% on PASCAL-Person-Part (person-part segmentation), and 87.9\% on PASCAL
VOC 2012 (semantic image segmentation). Additionally, the resulting
architecture is more computationally efficient, requiring half the parameters
and half the computational cost as previous state of the art systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1&quot;&gt;Liang-Chieh Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Collins_M/0/1/0/all/0/1&quot;&gt;Maxwell D. Collins&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1&quot;&gt;Yukun Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Papandreou_G/0/1/0/all/0/1&quot;&gt;George Papandreou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zoph_B/0/1/0/all/0/1&quot;&gt;Barret Zoph&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schroff_F/0/1/0/all/0/1&quot;&gt;Florian Schroff&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Adam_H/0/1/0/all/0/1&quot;&gt;Hartwig Adam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shlens_J/0/1/0/all/0/1&quot;&gt;Jonathon Shlens&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.04188">
<title>Layerwise Perturbation-Based Adversarial Training for Hard Drive Health Degree Prediction. (arXiv:1809.04188v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1809.04188</link>
<description rdf:parseType="Literal">&lt;p&gt;With the development of cloud computing and big data, the reliability of data
storage systems becomes increasingly important. Previous researchers have shown
that machine learning algorithms based on SMART attributes are effective
methods to predict hard drive failures. In this paper, we use SMART attributes
to predict hard drive health degrees which are helpful for taking different
fault tolerant actions in advance. Given the highly imbalanced SMART datasets,
it is a nontrivial work to predict the health degree precisely. The proposed
model would encounter overfitting and biased fitting problems if it is trained
by the traditional methods. In order to resolve this problem, we propose two
strategies to better utilize imbalanced data and improve performance. Firstly,
we design a layerwise perturbation-based adversarial training method which can
add perturbations to any layers of a neural network to improve the
generalization of the network. Secondly, we extend the training method to the
semi-supervised settings. Then, it is possible to utilize unlabeled data that
have a potential of failure to further improve the performance of the model.
Our extensive experiments on two real-world hard drive datasets demonstrate the
superiority of the proposed schemes for both supervised and semi-supervised
classification. The model trained by the proposed method can correctly predict
the hard drive health status 5 and 15 days in advance. Finally, we verify the
generality of the proposed training method in other similar anomaly detection
tasks where the dataset is imbalanced. The results argue that the proposed
methods are applicable to other domains.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Jianguo Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Ji Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_L/0/1/0/all/0/1&quot;&gt;Lifang He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Zhao Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1&quot;&gt;Philip S. Yu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.04197">
<title>Change-Point Detection on Hierarchical Circadian Models. (arXiv:1809.04197v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1809.04197</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper addresses the problem of change-point detection on sequences of
high-dimensional and heterogeneous observations, which also possess a periodic
temporal structure. Due to the dimensionality problem, when the time between
change-points is on the order of the dimension of the model parameters, drifts
in the underlying distribution can be misidentified as changes. To overcome
this limitation we assume that the observations lie in a lower dimensional
manifold that admits a latent variable representation. In particular, we
propose a hierarchical model that is computationally feasible, widely
applicable to heterogeneous data and robust to missing instances. Additionally,
to deal with the observations&apos; periodic dependencies, we employ a circadian
model where the data periodicity is captured by non-stationary covariance
functions. We validate the proposed technique on synthetic examples and we
demonstrate its utility in the detection of changes for human behavior
characterization.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Moreno_Munoz_P/0/1/0/all/0/1&quot;&gt;Pablo Moreno-Mu&amp;#xf1;oz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ramirez_D/0/1/0/all/0/1&quot;&gt;David Ram&amp;#xed;rez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Artes_Rodriguez_A/0/1/0/all/0/1&quot;&gt;Antonio Art&amp;#xe9;s-Rodr&amp;#xed;guez&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.04206">
<title>Temporal Pattern Attention for Multivariate Time Series Forecasting. (arXiv:1809.04206v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1809.04206</link>
<description rdf:parseType="Literal">&lt;p&gt;Forecasting multivariate time series data, such as prediction of electricity
consumption, solar power production, and polyphonic piano pieces, has numerous
valuable applications. However, complex and non-linear interdependencies
between time steps and series complicate the task. To obtain accurate
prediction, it is crucial to model long-term dependency in time series data,
which can be achieved to some good extent by recurrent neural network (RNN)
with attention mechanism. Typical attention mechanism reviews the information
at each previous time step and selects the relevant information to help
generate the outputs, but it fails to capture the temporal patterns across
multiple time steps. In this paper, we propose to use a set of filters to
extract time-invariant temporal patterns, which is similar to transforming time
series data into its &quot;frequency domain&quot;. Then we proposed a novel attention
mechanism to select relevant time series, and use its &quot;frequency domain&quot;
information for forecasting. We applied the proposed model on several
real-world tasks and achieved the state-of-the-art performance in all of them
with only one exception. We also show that to some degree the learned filters
play the role of bases in discrete Fourier transform.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shih_S/0/1/0/all/0/1&quot;&gt;Shun-Yao Shih&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_F/0/1/0/all/0/1&quot;&gt;Fan-Keng Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1&quot;&gt;Hung-yi Lee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.04216">
<title>On Markov Chain Gradient Descent. (arXiv:1809.04216v1 [math.OC])</title>
<link>http://arxiv.org/abs/1809.04216</link>
<description rdf:parseType="Literal">&lt;p&gt;Stochastic gradient methods are the workhorse (algorithms) of large-scale
optimization problems in machine learning, signal processing, and other
computational sciences and engineering. This paper studies Markov chain
gradient descent, a variant of stochastic gradient descent where the random
samples are taken on the trajectory of a Markov chain. Existing results of this
method assume convex objectives and a reversible Markov chain and thus have
their limitations. We establish new non-ergodic convergence under wider step
sizes, for nonconvex problems, and for non-reversible finite-state Markov
chains. Nonconvexity makes our method applicable to broader problem classes.
Non-reversible finite-state Markov chains, on the other hand, can mix
substatially faster. To obtain these results, we introduce a new technique that
varies the mixing levels of the Markov chains. The reported numerical results
validate our contributions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Sun_T/0/1/0/all/0/1&quot;&gt;Tao Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Sun_Y/0/1/0/all/0/1&quot;&gt;Yuejiao Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Yin_W/0/1/0/all/0/1&quot;&gt;Wotao Yin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.04249">
<title>A Fast Globally Linearly Convergent Algorithm for the Computation of Wasserstein Barycenters. (arXiv:1809.04249v1 [math.OC])</title>
<link>http://arxiv.org/abs/1809.04249</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we consider the problem of computing a Wasserstein barycenter
for a set of discrete probability distributions with finite supports, which
finds many applications in different areas such as statistics, machine learning
and image processing. When the support points of the barycenter are
pre-specified, this problem can be modeled as a linear programming (LP), while
the problem size can be extremely large. To handle this large-scale LP, in this
paper, we derive its dual problem, which is conceivably more tractable and can
be reformulated as a well-structured convex problem with 3 kinds of block
variables and a coupling linear equality constraint. We then adapt a symmetric
Gauss-Seidel based alternating direction method of multipliers (sGS-ADMM) to
solve the resulting dual problem and analyze its global convergence as well as
its global linear convergence rate. We also show how all the subproblems
involved can be solved exactly and efficiently. This makes our method suitable
for computing a Wasserstein barycenter on a large dataset. In addition, our
sGS-ADMM can be used as a subroutine in an alternating minimization method to
compute a barycenter when its support points are not pre-specified. Numerical
results on synthetic datasets and image datasets demonstrate that our method is
more efficient for solving large-scale problems, comparing with two existing
representative methods and the commercial software Gurobi.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Yang_L/0/1/0/all/0/1&quot;&gt;Lei Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jia Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Sun_D/0/1/0/all/0/1&quot;&gt;Defeng Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Toh_K/0/1/0/all/0/1&quot;&gt;Kim-Chuan Toh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.04262">
<title>Extracting Fairness Policies from Legal Documents. (arXiv:1809.04262v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1809.04262</link>
<description rdf:parseType="Literal">&lt;p&gt;Machine Learning community is recently exploring the implications of bias and
fairness with respect to the AI applications. The definition of fairness for
such applications varies based on their domain of application. The policies
governing the use of such machine learning system in a given context are
defined by the constitutional laws of nations and regulatory policies enforced
by the organizations that are involved in the usage. Fairness related laws and
policies are often spread across the large documents like constitution,
agreements, and organizational regulations. These legal documents have long
complex sentences in order to achieve rigorousness and robustness. Automatic
extraction of fairness policies, or in general, any specific kind of policies
from large legal corpus can be very useful for the study of bias and fairness
in the context of AI applications.
&lt;/p&gt;
&lt;p&gt;We attempted to automatically extract fairness policies from publicly
available law documents using two approaches based on semantic relatedness. The
experiments reveal how classical Wordnet-based similarity and vector-based
similarity differ in addressing this task. We have shown that similarity based
on word vectors beats the classical approach with a large margin, whereas other
vector representations of senses and sentences fail to even match the classical
baseline. Further, we have presented thorough error analysis and reasoning to
explain the results with appropriate examples from the dataset for deeper
insights.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nagpal_R/0/1/0/all/0/1&quot;&gt;Rashmi Nagpal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wadhwa_C/0/1/0/all/0/1&quot;&gt;Chetna Wadhwa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gupta_M/0/1/0/all/0/1&quot;&gt;Mallika Gupta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shaikh_S/0/1/0/all/0/1&quot;&gt;Samiulla Shaikh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mehta_S/0/1/0/all/0/1&quot;&gt;Sameep Mehta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goyal_V/0/1/0/all/0/1&quot;&gt;Vikram Goyal&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.04279">
<title>Discretely Relaxing Continuous Variables for tractable Variational Inference. (arXiv:1809.04279v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1809.04279</link>
<description rdf:parseType="Literal">&lt;p&gt;We explore a new research direction in Bayesian variational inference with
discrete latent variable priors where we exploit Kronecker matrix algebra for
efficient and exact computations of the evidence lower bound (ELBO). The
proposed &quot;DIRECT&quot; approach has several advantages over its predecessors; (i) it
can exactly compute ELBO gradients (i.e. unbiased, zero-variance gradient
estimates), eliminating the need for high-variance stochastic gradient
estimators and enabling the use of quasi-Newton optimization methods; (ii) its
training complexity is independent of the number of training points, permitting
inference on large datasets; and (iii) its posterior samples consist of sparse
and low-precision quantized integers which permit fast inference on hardware
limited devices. In addition, our DIRECT models can exactly compute statistical
moments of the parameterized predictive posterior without relying on Monte
Carlo sampling. Our numerical studies demonstrate accurate inference using
latent variables discretized as extremely low-precision 4-bit quantized
integers. While the ELBO computations considered require over $10^{2352}$
log-likelihood evaluations, we train on datasets with over two-million points
in just seconds.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Evans_T/0/1/0/all/0/1&quot;&gt;Trefor W. Evans&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Nair_P/0/1/0/all/0/1&quot;&gt;Prasanth B. Nair&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.04294">
<title>Cluster Variational Approximations for Structure Learning of Continuous-Time Bayesian Networks from Incomplete Data. (arXiv:1809.04294v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1809.04294</link>
<description rdf:parseType="Literal">&lt;p&gt;Continuous-time Bayesian networks (CTBNs) constitute a general and powerful
framework for modeling continuous-time stochastic processes on networks. This
makes them particularly attractive for learning the directed structures among
interacting entities. However, if the available data is incomplete, one needs
to simulate the prohibitively complex CTBN dynamics. Existing approximation
techniques, such as sampling and low-order variational methods, either scale
unfavorably in system size, or are unsatisfactory in terms of accuracy.
Inspired by recent advances in statistical physics, we present a new
approximation scheme based on cluster-variational methods significantly
improving upon existing variational approximations. We can analytically
marginalize the parameters of the approximate CTBN, as these are of secondary
importance for structure learning. This recovers a scalable scheme for direct
structure learning from incomplete and noisy time-series data. Our approach
outperforms existing methods in terms of scalability.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Linzner_D/0/1/0/all/0/1&quot;&gt;Dominik Linzner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Koeppl_H/0/1/0/all/0/1&quot;&gt;Heinz Koeppl&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.04379">
<title>Bayesian Semi-supervised Learning with Graph Gaussian Processes. (arXiv:1809.04379v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1809.04379</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a data-efficient Gaussian process-based Bayesian approach to the
semi-supervised learning problem on graphs. The proposed model shows extremely
competitive performance when compared to the state-of-the-art graph neural
networks on semi-supervised learning benchmark experiments, and outperforms the
neural networks in active learning experiments where labels are scarce.
Furthermore, the model does not require a validation data set for early
stopping to control over-fitting. Our model can be viewed as an instance of
empirical distribution regression weighted locally by network connectivity. We
further motivate the intuitive construction of the model with a Bayesian linear
model interpretation where the node features are filtered by an operator
related to the graph Laplacian. The method can be easily implemented by
adapting off-the-shelf scalable variational inference algorithms for Gaussian
processes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ng_Y/0/1/0/all/0/1&quot;&gt;Yin Cheng Ng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Silva_R/0/1/0/all/0/1&quot;&gt;Ricardo Silva&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.04400">
<title>Learning Deep Mixtures of Gaussian Process Experts Using Sum-Product Networks. (arXiv:1809.04400v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1809.04400</link>
<description rdf:parseType="Literal">&lt;p&gt;While Gaussian processes (GPs) are the method of choice for regression tasks,
they also come with practical difficulties, as inference cost scales cubic in
time and quadratic in memory. In this paper, we introduce a natural and
expressive way to tackle these problems, by incorporating GPs in sum-product
networks (SPNs), a recently proposed tractable probabilistic model allowing
exact and efficient inference. In particular, by using GPs as leaves of an SPN
we obtain a novel flexible prior over functions, which implicitly represents an
exponentially large mixture of local GPs. Exact and efficient posterior
inference in this model can be done in a natural interplay of the inference
mechanisms in GPs and SPNs. Thereby, each GP is -- similarly as in a mixture of
experts approach -- responsible only for a subset of data points, which
effectively reduces inference cost in a divide and conquer fashion. We show
that integrating GPs into the SPN framework leads to a promising probabilistic
regression model which is: (1) computational and memory efficient, (2) allows
efficient and exact posterior inference, (3) is flexible enough to mix
different kernel functions, and (4) naturally accounts for non-stationarities
in time series. In a variate of experiments, we show that the SPN-GP model can
learn input dependent parameters and hyper-parameters and is on par with or
outperforms the traditional GPs as well as state of the art approximations on
real-world data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Trapp_M/0/1/0/all/0/1&quot;&gt;Martin Trapp&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peharz_R/0/1/0/all/0/1&quot;&gt;Robert Peharz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rasmussen_C/0/1/0/all/0/1&quot;&gt;Carl E. Rasmussen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pernkopf_F/0/1/0/all/0/1&quot;&gt;Franz Pernkopf&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.04429">
<title>Gradient-based Representational Similarity Analysis with Searchlight for Analyzing fMRI Data. (arXiv:1809.04429v1 [q-bio.NC])</title>
<link>http://arxiv.org/abs/1809.04429</link>
<description rdf:parseType="Literal">&lt;p&gt;Representational Similarity Analysis (RSA) aims to explore similarities
between neural activities of different stimuli. Classical RSA techniques employ
the inverse of the covariance matrix to explore a linear model between the
neural activities and task events. However, calculating the inverse of a
large-scale covariance matrix is time-consuming and can reduce the stability
and robustness of the final analysis. Notably, it becomes severe when the
number of samples is too large. For facing this shortcoming, this paper
proposes a novel RSA method called gradient-based RSA (GRSA). Moreover, the
proposed method is not restricted to a linear model. In fact, there is a
growing interest in finding more effective ways of using multi-subject and
whole-brain fMRI data. Searchlight technique can extend RSA from the localized
brain regions to the whole-brain regions with smaller memory footprint in each
process. Based on Searchlight, we propose a new method called Spatiotemporal
Searchlight GRSA (SSL-GRSA) that generalizes our ROI-based GRSA algorithm to
the whole-brain data. Further, our approach can handle some computational
challenges while dealing with large-scale, multi-subject fMRI data.
Experimental studies on multi-subject datasets confirm that both proposed
approaches achieve superior performance to other state-of-the-art RSA
algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Sheng_X/0/1/0/all/0/1&quot;&gt;Xiaoliang Sheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Yousefnezhad_M/0/1/0/all/0/1&quot;&gt;Muhammad Yousefnezhad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Xu_T/0/1/0/all/0/1&quot;&gt;Tonglin Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Yuan_N/0/1/0/all/0/1&quot;&gt;Ning Yuan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Zhang_D/0/1/0/all/0/1&quot;&gt;Daoqiang Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.04440">
<title>Convolutional Neural Networks for Fast Approximation of Graph Edit Distance. (arXiv:1809.04440v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1809.04440</link>
<description rdf:parseType="Literal">&lt;p&gt;Graph Edit Distance (GED) computation is a core operation of many widely-used
graph applications, such as graph classification, graph matching, and graph
similarity search. However, computing the exact GED between two graphs is
NP-complete. Most current approximate algorithms are based on solving a
combinatorial optimization problem, which involves complicated design and high
time complexity. In this paper, we propose a novel end-to-end neural network
based approach to GED approximation, aiming to alleviate the computational
burden while preserving good performance. The proposed approach, named GSimCNN,
turns GED computation into a learning problem. Each graph is considered as a
set of nodes, represented by learnable embedding vectors. The GED computation
is then considered as a two-set matching problem, where a higher matching score
leads to a lower GED. A Convolutional Neural Network (CNN) based approach is
proposed to tackle the set matching problem. We test our algorithm on three
real graph datasets, and our model achieves significant performance enhancement
against state-of-the-art approximate GED computation algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bai_Y/0/1/0/all/0/1&quot;&gt;Yunsheng Bai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ding_H/0/1/0/all/0/1&quot;&gt;Hao Ding&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1&quot;&gt;Yizhou Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1&quot;&gt;Wei Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.04441">
<title>An empirical learning-based validation procedure for simulation workflow. (arXiv:1809.04441v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1809.04441</link>
<description rdf:parseType="Literal">&lt;p&gt;Simulation workflow is a top-level model for the design and control of
simulation process. It connects multiple simulation components with time and
interaction restrictions to form a complete simulation system. Before the
construction and evaluation of the component models, the validation of
upper-layer simulation workflow is of the most importance in a simulation
system. However, the methods especially for validating simulation workflow is
very limit. Many of the existing validation techniques are domain-dependent
with cumbersome questionnaire design and expert scoring. Therefore, this paper
present an empirical learning-based validation procedure to implement a
semi-automated evaluation for simulation workflow. First, representative
features of general simulation workflow and their relations with validation
indices are proposed. The calculation process of workflow credibility based on
Analytic Hierarchy Process (AHP) is then introduced. In order to make full use
of the historical data and implement more efficient validation, four learning
algorithms, including back propagation neural network (BPNN), extreme learning
machine (ELM), evolving new-neuron (eNFN) and fast incremental gaussian mixture
model (FIGMN), are introduced for constructing the empirical relation between
the workflow credibility and its features. A case study on a landing-process
simulation workflow is established to test the feasibility of the proposed
procedure. The experimental results also provide some useful overview of the
state-of-the-art learning algorithms on the credibility evaluation of
simulation models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1&quot;&gt;Zhuqing Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lai_L/0/1/0/all/0/1&quot;&gt;Liyuanjun Lai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1&quot;&gt;Lin Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.04481">
<title>But How Does It Work in Theory? Linear SVM with Random Features. (arXiv:1809.04481v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1809.04481</link>
<description rdf:parseType="Literal">&lt;p&gt;We prove that, under low noise assumptions, the support vector machine with
$N\ll m$ random features (RFSVM) can achieve the learning rate faster than
$O(1/\sqrt{m})$ on a training set with $m$ samples when an optimized feature
map is used. Our work extends the previous fast rate analysis of random
features method from least square loss to 0-1 loss. We also show that the
reweighted feature selection method, which approximates the optimized feature
map, helps improve the performance of RFSVM in experiments on a synthetic data
set.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gilbert_A/0/1/0/all/0/1&quot;&gt;Anna Gilbert&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tewari_A/0/1/0/all/0/1&quot;&gt;Ambuj Tewari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_Y/0/1/0/all/0/1&quot;&gt;Yitong Sun&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.04487">
<title>Discovering Topical Interactions in Text-based Cascades using Hidden Markov Hawkes Processes. (arXiv:1809.04487v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1809.04487</link>
<description rdf:parseType="Literal">&lt;p&gt;Social media conversations unfold based on complex interactions between
users, topics and time. While recent models have been proposed to capture
network strengths between users, users&apos; topical preferences and temporal
patterns between posting and response times, interaction patterns between
topics has not been studied. We propose the Hidden Markov Hawkes Process (HMHP)
that incorporates topical Markov Chains within Hawkes processes to jointly
model topical interactions along with user-user and user-topic patterns. We
propose a Gibbs sampling algorithm for HMHP that jointly infers the network
strengths, diffusion paths, the topics of the posts as well as the topic-topic
interactions. We show using experiments on real and semi-synthetic data that
HMHP is able to generalize better and recover the network strengths, topics and
diffusion paths more accurately than state-of-the-art baselines. More
interestingly, HMHP finds insightful interactions between topics in real tweets
which no existing model is able to do.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bedathur_S/0/1/0/all/0/1&quot;&gt;Srikanta Bedathur&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bhattacharya_I/0/1/0/all/0/1&quot;&gt;Indrajit Bhattacharya&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Choudhari_J/0/1/0/all/0/1&quot;&gt;Jayesh Choudhari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dasgupta_A/0/1/0/all/0/1&quot;&gt;Anirban Dasgupta&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.04542">
<title>The Inductive Bias of Restricted f-GANs. (arXiv:1809.04542v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1809.04542</link>
<description rdf:parseType="Literal">&lt;p&gt;Generative adversarial networks are a novel method for statistical inference
that have achieved much empirical success; however, the factors contributing to
this success remain ill-understood. In this work, we attempt to analyze
generative adversarial learning -- that is, statistical inference as the result
of a game between a generator and a discriminator -- with the view of
understanding how it differs from classical statistical inference solutions
such as maximum likelihood inference and the method of moments.
&lt;/p&gt;
&lt;p&gt;Specifically, we provide a theoretical characterization of the distribution
inferred by a simple form of generative adversarial learning called restricted
f-GANs -- where the discriminator is a function in a given function class, the
distribution induced by the generator is restricted to lie in a pre-specified
distribution class and the objective is similar to a variational form of the
f-divergence. A consequence of our result is that for linear KL-GANs -- that
is, when the discriminator is a linear function over some feature space and f
corresponds to the KL-divergence -- the distribution induced by the optimal
generator is neither the maximum likelihood nor the method of moments solution,
but an interesting combination of both.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1&quot;&gt;Shuang Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chaudhuri_K/0/1/0/all/0/1&quot;&gt;Kamalika Chaudhuri&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.04547">
<title>Using the Tsetlin Machine to Learn Human-Interpretable Rules for High-Accuracy Text Categorization with Medical Applications. (arXiv:1809.04547v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1809.04547</link>
<description rdf:parseType="Literal">&lt;p&gt;Medical applications challenge today&apos;s text categorization techniques by
demanding both high accuracy and ease-of-interpretation. Although deep learning
has provided a leap ahead in accuracy, this leap comes at the sacrifice of
interpretability. To address this accuracy-interpretability challenge, we here
introduce, for the first time, a text categorization approach that leverages
the recently introduced Tsetlin Machine. In all brevity, we represent the terms
of a text as propositional variables. From these, we capture categories using
simple propositional formulae, such as: if &quot;rash&quot; and &quot;reaction&quot; and
&quot;penicillin&quot; then Allergy. The Tsetlin Machine learns these formulae from a
labelled text, utilizing conjunctive clauses to represent the particular facets
of each category. Indeed, even the absence of terms (negated features) can be
used for categorization purposes. Our empirical results are quite conclusive.
The Tsetlin Machine either performs on par with or outperforms all of the
evaluated methods on both the 20 Newsgroups and IMDb datasets, as well as on a
non-public clinical dataset. On average, the Tsetlin Machine delivers the best
recall and precision scores across the datasets. The GPU implementation of the
Tsetlin Machine is further 8 times faster than the GPU implementation of the
neural network. We thus believe that our novel approach can have a significant
impact on a wide range of text analysis applications, forming a promising
starting point for deeper natural language understanding with the Tsetlin
Machine.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Berge_G/0/1/0/all/0/1&quot;&gt;Geir Thore Berge&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Granmo_O/0/1/0/all/0/1&quot;&gt;Ole-Christoffer Granmo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tveit_T/0/1/0/all/0/1&quot;&gt;Tor Oddbj&amp;#xf8;rn Tveit&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goodwin_M/0/1/0/all/0/1&quot;&gt;Morten Goodwin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiao_L/0/1/0/all/0/1&quot;&gt;Lei Jiao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Matheussen_B/0/1/0/all/0/1&quot;&gt;Bernt Viggo Matheussen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.04559">
<title>Benchmarking and Optimization of Gradient Boosted Decision Tree Algorithms. (arXiv:1809.04559v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1809.04559</link>
<description rdf:parseType="Literal">&lt;p&gt;Gradient boosted decision trees (GBDTs) have seen widespread adoption in
academia, industry and competitive data science due to their state-of-the-art
performance in a wide variety of machine learning tasks. In this paper, we
present an extensive empirical comparison of XGBoost, LightGBM and CatBoost,
three popular GBDT algorithms, to aid the data science practitioner in the
choice from the multitude of available implementations. Specifically, we
evaluate their behavior on four large-scale datasets with varying shapes,
sparsities and learning tasks, in order to evaluate the algorithms&apos;
generalization performance, training times (on both CPU and GPU) and their
sensitivity to hyper-parameter tuning. In our analysis, we first make use of a
distributed grid-search to benchmark the algorithms on fixed configurations,
and then employ a state-of-the-art algorithm for Bayesian hyper-parameter
optimization to fine-tune the models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Anghel_A/0/1/0/all/0/1&quot;&gt;Andreea Anghel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Papandreou_N/0/1/0/all/0/1&quot;&gt;Nikolaos Papandreou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Parnell_T/0/1/0/all/0/1&quot;&gt;Thomas Parnell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Palma_A/0/1/0/all/0/1&quot;&gt;Alessandro De Palma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pozidis_H/0/1/0/all/0/1&quot;&gt;Haralampos Pozidis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.04578">
<title>Simplicity Creates Inequity: Implications for Fairness, Stereotypes, and Interpretability. (arXiv:1809.04578v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1809.04578</link>
<description rdf:parseType="Literal">&lt;p&gt;Algorithmic predictions are increasingly used to aid, or in some cases
supplant, human decision-making, and this development has placed new demands on
the outputs of machine learning procedures. To facilitate human interaction, we
desire that they output prediction functions that are in some fashion simple or
interpretable. And because they influence consequential decisions, we also
desire equitable prediction functions, ones whose allocations benefit (or at
the least do not harm) disadvantaged groups.
&lt;/p&gt;
&lt;p&gt;We develop a formal model to explore the relationship between simplicity and
equity. Although the two concepts appear to be motivated by qualitatively
distinct goals, our main result shows a fundamental inconsistency between them.
Specifically, we formalize a general framework for producing simple prediction
functions, and in this framework we show that every simple prediction function
is strictly improvable: there exists a more complex prediction function that is
both strictly more efficient and also strictly more equitable. Put another way,
using a simple prediction function both reduces utility for disadvantaged
groups and reduces overall welfare. Our result is not only about algorithms but
about any process that produces simple models, and as such connects to the
psychology of stereotypes and to an earlier economics literature on statistical
discrimination.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kleinberg_J/0/1/0/all/0/1&quot;&gt;Jon Kleinberg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mullainathan_S/0/1/0/all/0/1&quot;&gt;Sendhil Mullainathan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1809.04587">
<title>Distributed Chernoff Test: Optimal decision systems over networks. (arXiv:1809.04587v1 [stat.ME])</title>
<link>http://arxiv.org/abs/1809.04587</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work, we propose two different sequential and adaptive hypothesis
tests, motivated from classic Chernoff&apos;s test, for both decentralized and
distributed setup of sensor networks. In the former setup, the sensors can
communicate via central entity i.e. fusion center. On the other hand, in the
latter setup, sensors are connected via communication link, and no central
entity is present to facilitate the communication. We compare the performance
of these tests with the optimal consistent sequential test in the sensor
network. In decentralized setup, the proposed test achieves the same asymptotic
optimality of the classic one, minimizing the expected cost required to reach a
decision plus the expected cost of making a wrong decision, when the
observation cost per unit time tends to zero. This test is also asymptotic
optimal in the higher moments of decision time. The proposed test is
parsimonious in terms of communications as the expected number of channel uses
required by each sensor, in the regime of vanishing observation cost per unit
time, to complete the test converges to four.In distributed setup, the proposed
test is evaluated on the same performance measures as the test in decentralized
setup. We also provide sufficient conditions for which the proposed test in
distributed setup also achieves the same asymptotic optimality as the classic
one. Like the proposed test in decentralized setup, under these sufficient
conditions, the proposed test in distributed setup is also asymptotic optimal
in the higher moments of time required to reach a decision in the sensor
network. This test is parsimonious is terms of communications in comparison to
the state of art schemes proposed in the literature for distributed hypothesis
testing.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rangi_A/0/1/0/all/0/1&quot;&gt;Anshuka Rangi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Franceschetti_M/0/1/0/all/0/1&quot;&gt;Massimo Franceschetti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Marano_S/0/1/0/all/0/1&quot;&gt;Stefano Marano&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1510.01518">
<title>DC Decomposition of Nonconvex Polynomials with Algebraic Techniques. (arXiv:1510.01518v2 [math.OC] UPDATED)</title>
<link>http://arxiv.org/abs/1510.01518</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the problem of decomposing a multivariate polynomial as the
difference of two convex polynomials. We introduce algebraic techniques which
reduce this task to linear, second order cone, and semidefinite programming.
This allows us to optimize over subsets of valid difference of convex
decompositions (dcds) and find ones that speed up the convex-concave procedure
(CCP). We prove, however, that optimizing over the entire set of dcds is
NP-hard.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Ahmadi_A/0/1/0/all/0/1&quot;&gt;Amir Ali Ahmadi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Hall_G/0/1/0/all/0/1&quot;&gt;Georgina Hall&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1605.06718">
<title>The De-Biased Whittle Likelihood. (arXiv:1605.06718v3 [stat.ME] UPDATED)</title>
<link>http://arxiv.org/abs/1605.06718</link>
<description rdf:parseType="Literal">&lt;p&gt;The Whittle likelihood is a widely used and computationally efficient
pseudo-likelihood. However, it is known to produce biased parameter estimates
for large classes of models. We propose a method for de-biasing Whittle
estimates for second-order stationary stochastic processes. The de-biased
Whittle likelihood can be computed in the same $\mathcal{O}(n\log n)$
operations as the standard approach. We demonstrate the superior performance of
the method in simulation studies and in application to a large-scale
oceanographic dataset, where in both cases the de-biased approach reduces bias
by up to two orders of magnitude, achieving estimates that are close to exact
maximum likelihood, at a fraction of the computational cost. We prove that the
method yields estimates that are consistent at an optimal convergence rate of
$n^{-1/2}$, under weaker assumptions than standard theory, where we do not
require that the power spectral density is continuous in frequency. We describe
how the method can be easily combined with standard methods of bias reduction,
such as tapering and differencing, to further reduce bias in parameter
estimates.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sykulski_A/0/1/0/all/0/1&quot;&gt;Adam M. Sykulski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Olhede_S/0/1/0/all/0/1&quot;&gt;Sofia C. Olhede&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Guillaumin_A/0/1/0/all/0/1&quot;&gt;Arthur P. Guillaumin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lilly_J/0/1/0/all/0/1&quot;&gt;Jonathan M. Lilly&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Early_J/0/1/0/all/0/1&quot;&gt;Jeffrey J. Early&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1705.09700">
<title>Multi-scale Online Learning and its Applications to Online Auctions. (arXiv:1705.09700v2 [cs.GT] UPDATED)</title>
<link>http://arxiv.org/abs/1705.09700</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider revenue maximization in online auction/pricing problems. A seller
sells an identical item in each period to a new buyer, or a new set of buyers.
For the online posted pricing problem, we show regret bounds that scale with
the best fixed price, rather than the range of the values. We also show regret
bounds that are almost scale free, and match the offline sample complexity,
when comparing to a benchmark that requires a lower bound on the market share.
These results are obtained by generalizing the classical learning from experts
and multi-armed bandit problems to their multi-scale versions. In this version,
the reward of each action is in a different range, and the regret w.r.t. a
given action scales with its own range, rather than the maximum range.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bubeck_S/0/1/0/all/0/1&quot;&gt;S&amp;#xe9;bastien Bubeck&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Devanur_N/0/1/0/all/0/1&quot;&gt;Nikhil R. Devanur&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1&quot;&gt;Zhiyi Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Niazadeh_R/0/1/0/all/0/1&quot;&gt;Rad Niazadeh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1706.07834">
<title>Cover Tree Compressed Sensing for Fast MR Fingerprint Recovery. (arXiv:1706.07834v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1706.07834</link>
<description rdf:parseType="Literal">&lt;p&gt;We adopt data structure in the form of cover trees and iteratively apply
approximate nearest neighbour (ANN) searches for fast compressed sensing
reconstruction of signals living on discrete smooth manifolds. Levering on the
recent stability results for the inexact Iterative Projected Gradient (IPG)
algorithm and by using the cover tree&apos;s ANN searches, we decrease the
projection cost of the IPG algorithm to be logarithmically growing with data
population for low dimensional smooth manifolds. We apply our results to
quantitative MRI compressed sensing and in particular within the Magnetic
Resonance Fingerprinting (MRF) framework. For a similar (or sometimes better)
reconstruction accuracy, we report 2-3 orders of magnitude reduction in
computations compared to the standard iterative method which uses brute-force
searches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Golbabaee_M/0/1/0/all/0/1&quot;&gt;Mohammad Golbabaee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chen_Z/0/1/0/all/0/1&quot;&gt;Zhouye Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wiaux_Y/0/1/0/all/0/1&quot;&gt;Yves Wiaux&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Davies_M/0/1/0/all/0/1&quot;&gt;Mike E. Davies&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1708.05569">
<title>Community detection in networks via nonlinear modularity eigenvectors. (arXiv:1708.05569v2 [cs.SI] UPDATED)</title>
<link>http://arxiv.org/abs/1708.05569</link>
<description rdf:parseType="Literal">&lt;p&gt;Revealing a community structure in a network or dataset is a central problem
arising in many scientific areas. The modularity function $Q$ is an established
measure quantifying the quality of a community, being identified as a set of
nodes having high modularity. In our terminology, a set of nodes with positive
modularity is called a \textit{module} and a set that maximizes $Q$ is thus
called \textit{leading module}. Finding a leading module in a network is an
important task, however the dimension of real-world problems makes the
maximization of $Q$ unfeasible. This poses the need of approximation techniques
which are typically based on a linear relaxation of $Q$, induced by the
spectrum of the modularity matrix $M$. In this work we propose a nonlinear
relaxation which is instead based on the spectrum of a nonlinear modularity
operator $\mathcal M$. We show that extremal eigenvalues of $\mathcal M$
provide an exact relaxation of the modularity measure $Q$, however at the price
of being more challenging to be computed than those of $M$. Thus we extend the
work made on nonlinear Laplacians, by proposing a computational scheme, named
\textit{generalized RatioDCA}, to address such extremal eigenvalues. We show
monotonic ascent and convergence of the method. We finally apply the new method
to several synthetic and real-world data sets, showing both effectiveness of
the model and performance of the method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tudisco_F/0/1/0/all/0/1&quot;&gt;Francesco Tudisco&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mercado_P/0/1/0/all/0/1&quot;&gt;Pedro Mercado&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hein_M/0/1/0/all/0/1&quot;&gt;Matthias Hein&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.03222">
<title>Forecasting Across Time Series Databases using Recurrent Neural Networks on Groups of Similar Series: A Clustering Approach. (arXiv:1710.03222v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1710.03222</link>
<description rdf:parseType="Literal">&lt;p&gt;With the advent of Big Data, nowadays in many applications databases
containing large quantities of similar time series are available. Forecasting
time series in these domains with traditional univariate forecasting procedures
leaves great potentials for producing accurate forecasts untapped. Recurrent
neural networks (RNNs), and in particular Long Short-Term Memory (LSTM)
networks, have proven recently that they are able to outperform
state-of-the-art univariate time series forecasting methods in this context
when trained across all available time series. However, if the time series
database is heterogeneous, accuracy may degenerate, so that on the way towards
fully automatic forecasting methods in this space, a notion of similarity
between the time series needs to be built into the methods. To this end, we
present a prediction model that can be used with different types of RNN models
on subgroups of similar time series, which are identified by time series
clustering techniques. We assess our proposed methodology using LSTM networks,
a widely popular RNN variant. Our method achieves competitive results on
benchmarking datasets under competition evaluation procedures. In particular,
in terms of mean sMAPE accuracy, it consistently outperforms the baseline LSTM
model and outperforms all other methods on the CIF2016 forecasting competition
dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bandara_K/0/1/0/all/0/1&quot;&gt;Kasun Bandara&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bergmeir_C/0/1/0/all/0/1&quot;&gt;Christoph Bergmeir&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Smyl_S/0/1/0/all/0/1&quot;&gt;Slawek Smyl&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.09599">
<title>Watch Your Step: Learning Node Embeddings via Graph Attention. (arXiv:1710.09599v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1710.09599</link>
<description rdf:parseType="Literal">&lt;p&gt;Graph embedding methods represent nodes in a continuous vector space,
preserving information from the graph (e.g. by sampling random walks). There
are many hyper-parameters to these methods (such as random walk length) which
have to be manually tuned for every graph. In this paper, we replace random
walk hyper-parameters with trainable parameters that we automatically learn via
backpropagation. In particular, we learn a novel attention model on the power
series of the transition matrix, which guides the random walk to optimize an
upstream objective. Unlike previous approaches to attention models, the method
that we propose utilizes attention parameters exclusively on the data (e.g. on
the random walk), and not used by the model for inference. We experiment on
link prediction tasks, as we aim to produce embeddings that best-preserve the
graph structure, generalizing to unseen information. We improve
state-of-the-art on a comprehensive suite of real world datasets including
social, collaboration, and biological networks. Adding attention to random
walks can reduce the error by 20% to 45% on datasets we attempted. Further, our
learned attention parameters are different for every graph, and our
automatically-found values agree with the optimal choice of hyper-parameter if
we manually tune existing methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abu_El_Haija_S/0/1/0/all/0/1&quot;&gt;Sami Abu-El-Haija&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Perozzi_B/0/1/0/all/0/1&quot;&gt;Bryan Perozzi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Al_Rfou_R/0/1/0/all/0/1&quot;&gt;Rami Al-Rfou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alemi_A/0/1/0/all/0/1&quot;&gt;Alex Alemi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.08824">
<title>The Nearest Neighbor Information Estimator is Adaptively Near Minimax Rate-Optimal. (arXiv:1711.08824v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1711.08824</link>
<description rdf:parseType="Literal">&lt;p&gt;We analyze the Kozachenko--Leonenko (KL) nearest neighbor estimator for the
differential entropy. We obtain the first uniform upper bound on its
performance over H\&quot;older balls on a torus without assuming any conditions on
how close the density could be from zero. Accompanying a new minimax lower
bound over the H\&quot;older ball, we show that the KL estimator is achieving the
minimax rates up to logarithmic factors without cognizance of the smoothness
parameter $s$ of the H\&quot;older ball for $s\in (0,2]$ and arbitrary dimension
$d$, rendering it the first estimator that provably satisfies this property.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Jiao_J/0/1/0/all/0/1&quot;&gt;Jiantao Jiao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gao_W/0/1/0/all/0/1&quot;&gt;Weihao Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Han_Y/0/1/0/all/0/1&quot;&gt;Yanjun Han&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.07889">
<title>Entropy Rate Estimation for Markov Chains with Large State Space. (arXiv:1802.07889v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1802.07889</link>
<description rdf:parseType="Literal">&lt;p&gt;Estimating the entropy based on data is one of the prototypical problems in
distribution property testing and estimation. For estimating the Shannon
entropy of a distribution on $S$ elements with independent samples,
[Paninski2004] showed that the sample complexity is sublinear in $S$, and
[Valiant--Valiant2011] showed that consistent estimation of Shannon entropy is
possible if and only if the sample size $n$ far exceeds $\frac{S}{\log S}$. In
this paper we consider the problem of estimating the entropy rate of a
stationary reversible Markov chain with $S$ states from a sample path of $n$
observations. We show that:
&lt;/p&gt;
&lt;p&gt;(1) As long as the Markov chain mixes not too slowly, i.e., the relaxation
time is at most $O(\frac{S}{\ln^3 S})$, consistent estimation is achievable
when $n \gg \frac{S^2}{\log S}$.
&lt;/p&gt;
&lt;p&gt;(2) As long as the Markov chain has some slight dependency, i.e., the
relaxation time is at least $1+\Omega(\frac{\ln^2 S}{\sqrt{S}})$, consistent
estimation is impossible when $n \lesssim \frac{S^2}{\log S}$.
&lt;/p&gt;
&lt;p&gt;Under both assumptions, the optimal estimation accuracy is shown to be
$\Theta(\frac{S^2}{n \log S})$. In comparison, the empirical entropy rate
requires at least $\Omega(S^2)$ samples to be consistent, even when the Markov
chain is memoryless. In addition to synthetic experiments, we also apply the
estimators that achieve the optimal sample complexity to estimate the entropy
rate of the English language in the Penn Treebank and the Google One Billion
Words corpora, which provides a natural benchmark for language modeling and
relates it directly to the widely used perplexity measure.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Han_Y/0/1/0/all/0/1&quot;&gt;Yanjun Han&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiao_J/0/1/0/all/0/1&quot;&gt;Jiantao Jiao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_C/0/1/0/all/0/1&quot;&gt;Chuan-Zheng Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Weissman_T/0/1/0/all/0/1&quot;&gt;Tsachy Weissman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1&quot;&gt;Yihong Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_T/0/1/0/all/0/1&quot;&gt;Tiancheng Yu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07405">
<title>Processing of missing data by neural networks. (arXiv:1805.07405v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.07405</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a general, theoretically justified mechanism for processing
missing data by neural networks. Our idea is to replace typical neuron response
in the first hidden layer by its expected value. This approach can be applied
for various types of networks at minimal cost in their modification. Moreover,
in contrast to recent approaches, it does not require complete data for
training. Experimental results performed on different types of architectures
show that our method gives better results than typical imputation strategies
and other methods dedicated for incomplete data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Smieja_M/0/1/0/all/0/1&quot;&gt;Marek Smieja&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Struski_L/0/1/0/all/0/1&quot;&gt;&amp;#x141;ukasz Struski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tabor_J/0/1/0/all/0/1&quot;&gt;Jacek Tabor&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zielinski_B/0/1/0/all/0/1&quot;&gt;Bartosz Zieli&amp;#x144;ski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Spurek_P/0/1/0/all/0/1&quot;&gt;Przemys&amp;#x142;aw Spurek&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08010">
<title>Where Do You Think You&apos;re Going?: Inferring Beliefs about Dynamics from Behavior. (arXiv:1805.08010v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.08010</link>
<description rdf:parseType="Literal">&lt;p&gt;Inferring intent from observed behavior has been studied extensively within
the frameworks of Bayesian inverse planning and inverse reinforcement learning.
These methods infer a goal or reward function that best explains the actions of
the observed agent, typically a human demonstrator. Another agent can use this
inferred intent to predict, imitate, or assist the human user. However, a
central assumption in inverse reinforcement learning is that the demonstrator
is close to optimal. While models of suboptimal behavior exist, they typically
assume that suboptimal actions are the result of some type of random noise or a
known cognitive bias, like temporal inconsistency. In this paper, we take an
alternative approach, and model suboptimal behavior as the result of internal
model misspecification: the reason that user actions might deviate from
near-optimal actions is that the user has an incorrect set of beliefs about the
rules -- the dynamics -- governing how actions affect the environment. Our
insight is that while demonstrated actions may be suboptimal in the real world,
they may actually be near-optimal with respect to the user&apos;s internal model of
the dynamics. By estimating these internal beliefs from observed behavior, we
arrive at a new method for inferring intent. We demonstrate in simulation and
in a user study with 12 participants that this approach enables us to more
accurately model human intent, and can be used in a variety of applications,
including offering assistance in a shared autonomy framework and inferring
human preferences.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Reddy_S/0/1/0/all/0/1&quot;&gt;Siddharth Reddy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dragan_A/0/1/0/all/0/1&quot;&gt;Anca D. Dragan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1&quot;&gt;Sergey Levine&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08672">
<title>Information Constraints on Auto-Encoding Variational Bayes. (arXiv:1805.08672v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.08672</link>
<description rdf:parseType="Literal">&lt;p&gt;Parameterizing the approximate posterior of a generative model with neural
networks has become a common theme in recent machine learning research. While
providing appealing flexibility, this approach makes it difficult to impose or
assess structural constraints such as conditional independence. We propose a
framework for learning representations that relies on Auto-Encoding Variational
Bayes and whose search space is constrained via kernel-based measures of
independence. In particular, our method employs the $d$-variable
Hilbert-Schmidt Independence Criterion (dHSIC) to enforce independence between
the latent representations and arbitrary nuisance factors. We show how to apply
this method to a range of problems, including the problems of learning
invariant representations and the learning of interpretable representations. We
also present a full-fledged application to single-cell RNA sequencing
(scRNA-seq). In this setting the biological signal in mixed in complex ways
with sequencing errors and sampling effects. We show that our method
out-performs the state-of-the-art in this domain.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lopez_R/0/1/0/all/0/1&quot;&gt;Romain Lopez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Regier_J/0/1/0/all/0/1&quot;&gt;Jeffrey Regier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jordan_M/0/1/0/all/0/1&quot;&gt;Michael I. Jordan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yosef_N/0/1/0/all/0/1&quot;&gt;Nir Yosef&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04819">
<title>Integral Privacy for Sampling from Mollifier Densities with Approximation Guarantees. (arXiv:1806.04819v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1806.04819</link>
<description rdf:parseType="Literal">&lt;p&gt;Sampling encompasses old and central problems in statistics and machine
learning. There exists several approaches to cast this problem in a
differential privacy framework but little is still comparatively known about
the approximation guarantees of the unknown density by the private one learned.
In this paper, we first introduce a general condition for a set of densities,
called an $\varepsilon$-mollifier, to grant privacy for sampling in the
$\varepsilon$-differential privacy model, and even in a stronger model where we
remove the famed adjacency condition of inputs. We then show how to exploit the
boosting toolkit to learn a density within an $\varepsilon$-mollifier with
guaranteed approximation of the target density that degrade gracefully with the
privacy budget. Approximation guarantees cover the mode capture problem, a
problem which is receiving a lot of attention in the generative models
literature. To our knowledge, the way we exploit the boosting toolkit has never
been done before in the context of density estimation or sampling: we require
access to a weak learner in the original boosting sense, so we learn a density
out of \textit{classifiers}. Experimental results against a state of the art
implementation of private kernel density estimation display that our technique
consistently obtains improved results, managing in particular to get similar
outputs for a privacy budget $\epsilon$ which is however orders of magnitude
smaller.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Husain_H/0/1/0/all/0/1&quot;&gt;Hisham Husain&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Cranko_Z/0/1/0/all/0/1&quot;&gt;Zac Cranko&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Nock_R/0/1/0/all/0/1&quot;&gt;Richard Nock&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.11876">
<title>Predicting Solution Summaries to Integer Linear Programs under Imperfect Information with Machine Learning. (arXiv:1807.11876v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1807.11876</link>
<description rdf:parseType="Literal">&lt;p&gt;The paper provides a methodological contribution at the intersection of
machine learning and operations research. Namely, we propose a methodology to
quickly predict solution summaries (i.e., solution descriptions at a given
level of detail) to discrete stochastic optimization problems. We approximate
the solutions based on supervised learning and the training dataset consists of
a large number of deterministic problems that have been solved independently
and offline. Uncertainty regarding a missing subset of the inputs is addressed
through sampling and aggregation methods.
&lt;/p&gt;
&lt;p&gt;Our motivating application concerns booking decisions of intermodal
containers on double-stack trains. Under perfect information, this is the
so-called load planning problem and it can be formulated by means of integer
linear programming. However, the formulation cannot be used for the application
at hand because of the restricted computational budget and unknown container
weights. The results show that standard deep learning algorithms allow one to
predict descriptions of solutions with high accuracy in very short time
(milliseconds or less).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Larsen_E/0/1/0/all/0/1&quot;&gt;Eric Larsen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lachapelle_S/0/1/0/all/0/1&quot;&gt;S&amp;#xe9;bastien Lachapelle&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bengio_Y/0/1/0/all/0/1&quot;&gt;Yoshua Bengio&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Frejinger_E/0/1/0/all/0/1&quot;&gt;Emma Frejinger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lacoste_Julien_S/0/1/0/all/0/1&quot;&gt;Simon Lacoste-Julien&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lodi_A/0/1/0/all/0/1&quot;&gt;Andrea Lodi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.00020">
<title>On-line Adaptative Curriculum Learning for GANs. (arXiv:1808.00020v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1808.00020</link>
<description rdf:parseType="Literal">&lt;p&gt;Generative Adversarial Networks (GANs) can successfully approximate a
probability distribution and produce realistic samples. However, open questions
such as sufficient convergence conditions and mode collapse still persist. In
this paper, we build on existing work in the area by proposing a novel
framework for training the generator against an ensemble of discriminator
networks, which can be seen as a one-student/multiple-teachers setting. We
formalize this problem within the full-information adversarial bandit
framework, where we evaluate the capability of an algorithm to select mixtures
of discriminators for providing the generator with feedback during learning. To
this end, we propose a reward function which reflects the progress made by the
generator and dynamically update the mixture weights allocated to each
discriminator. We also draw connections between our algorithm and stochastic
optimization methods and then show that existing approaches using multiple
discriminators in literature can be recovered from our framework. We argue that
less expressive discriminators are smoother and have a general coarse grained
view of the modes map, which enforces the generator to cover a wide portion of
the data distribution support. On the other hand, highly expressive
discriminators ensure samples quality. Finally, experimental results show that
our approach improves samples quality and diversity over existing baselines by
effectively learning a curriculum. These results also support the claim that
weaker discriminators have higher entropy improving modes coverage.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Doan_T/0/1/0/all/0/1&quot;&gt;Thang Doan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Monteiro_J/0/1/0/all/0/1&quot;&gt;Joao Monteiro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Albuquerque_I/0/1/0/all/0/1&quot;&gt;Isabela Albuquerque&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mazoure_B/0/1/0/all/0/1&quot;&gt;Bogdan Mazoure&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Durand_A/0/1/0/all/0/1&quot;&gt;Audrey Durand&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pineau_J/0/1/0/all/0/1&quot;&gt;Joelle Pineau&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hjelm_R/0/1/0/all/0/1&quot;&gt;R Devon Hjelm&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.09897">
<title>Towards security defect prediction with AI. (arXiv:1808.09897v2 [cs.CR] UPDATED)</title>
<link>http://arxiv.org/abs/1808.09897</link>
<description rdf:parseType="Literal">&lt;p&gt;In this study, we investigate the limits of the current state of the art AI
system for detecting buffer overflows and compare it with current static
analysis tools. To do so, we developed a code generator, s-bAbI, capable of
producing an arbitrarily large number of code samples of controlled complexity.
We found that the static analysis engines we examined have good precision, but
poor recall on this dataset, except for a sound static analyzer that has good
precision and recall. We found that the state of the art AI system, a memory
network modeled after Choi et al. [1], can achieve similar performance to the
static analysis engines, but requires an exhaustive amount of training data in
order to do so. Our work points towards future approaches that may solve these
problems; namely, using representations of code that can capture appropriate
scope information and using deep learning methods that are able to perform
arithmetic operations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sestili_C/0/1/0/all/0/1&quot;&gt;Carson D. Sestili&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Snavely_W/0/1/0/all/0/1&quot;&gt;William S. Snavely&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+VanHoudnos_N/0/1/0/all/0/1&quot;&gt;Nathan M. VanHoudnos&lt;/a&gt;</dc:creator>
</item></rdf:RDF>