<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Boring papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Bad Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-06-10T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02855"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02925"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02932"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02967"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.04487"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02873"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02908"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02918"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02985"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.03155"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.03192"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.03240"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.03267"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.05380"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.11157"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05027"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08183"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09477"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.08355"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.02477"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.07193"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02027"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02457"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02510"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02867"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02878"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02887"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02892"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02920"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02922"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02927"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02935"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02954"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02958"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02970"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02977"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02988"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.03000"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.03044"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.03085"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.03121"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.03125"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.03143"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.03145"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.03146"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.03182"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.03185"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.03190"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.03198"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.03218"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.03232"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.03281"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.03285"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.03286"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.03287"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1401.5508"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1506.05855"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1606.00925"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1612.03450"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1703.04691"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.04425"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.07168"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.06309"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.00008"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.03801"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06501"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.06058"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.09159"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.09539"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.03184"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.08598"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.08841"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.09699"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.01852"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.04591"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02402"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02455"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1806.02855">
<title>Scalable Natural Gradient Langevin Dynamics in Practice. (arXiv:1806.02855v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.02855</link>
<description rdf:parseType="Literal">&lt;p&gt;Stochastic Gradient Langevin Dynamics (SGLD) is a sampling scheme for
Bayesian modeling adapted to large datasets and models. SGLD relies on the
injection of Gaussian Noise at each step of a Stochastic Gradient Descent (SGD)
update. In this scheme, every component in the noise vector is independent and
has the same scale, whereas the parameters we seek to estimate exhibit strong
variations in scale and significant correlation structures, leading to poor
convergence and mixing times. We compare different preconditioning approaches
to the normalization of the noise vector and benchmark these approaches on the
following criteria: 1) mixing times of the multivariate parameter vector, 2)
regularizing effect on small dataset where it is easy to overfit, 3) covariate
shift detection and 4) resistance to adversarial examples.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Palacci_H/0/1/0/all/0/1&quot;&gt;Henri Palacci&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hess_H/0/1/0/all/0/1&quot;&gt;Henry Hess&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02925">
<title>A Spectral Approach to Gradient Estimation for Implicit Distributions. (arXiv:1806.02925v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.02925</link>
<description rdf:parseType="Literal">&lt;p&gt;Recently there have been increasing interests in learning and inference with
implicit distributions (i.e., distributions without tractable densities). To
this end, we develop a gradient estimator for implicit distributions based on
Stein&apos;s identity and a spectral decomposition of kernel operators, where the
eigenfunctions are approximated by the Nystr\&quot;om method. Unlike the previous
works that only provide estimates at the sample points, our approach directly
estimates the gradient function, thus allows for a simple and principled
out-of-sample extension. We provide theoretical results on the error bound of
the estimator and discuss the bias-variance tradeoff in practice. The
effectiveness of our method is demonstrated by applications to gradient-free
Hamiltonian Monte Carlo and variational inference with implicit distributions.
Finally, we discuss the intuition behind the estimator by drawing connections
between the Nystr\&quot;om method and kernel PCA, which indicates that the estimator
can automatically adapt to the geometry of the underlying distribution.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Shi_J/0/1/0/all/0/1&quot;&gt;Jiaxin Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sun_S/0/1/0/all/0/1&quot;&gt;Shengyang Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhu_J/0/1/0/all/0/1&quot;&gt;Jun Zhu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02932">
<title>Program Synthesis Through Reinforcement Learning Guided Tree Search. (arXiv:1806.02932v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1806.02932</link>
<description rdf:parseType="Literal">&lt;p&gt;Program Synthesis is the task of generating a program from a provided
specification. Traditionally, this has been treated as a search problem by the
programming languages (PL) community and more recently as a supervised learning
problem by the machine learning community. Here, we propose a third approach,
representing the task of synthesizing a given program as a Markov decision
process solvable via reinforcement learning(RL). From observations about the
states of partial programs, we attempt to find a program that is optimal over a
provided reward metric on pairs of programs and states. We instantiate this
approach on a subset of the RISC-V assembly language operating on floating
point numbers, and as an optimization inspired by search-based techniques from
the PL community, we combine RL with a priority search tree. We evaluate this
instantiation and demonstrate the effectiveness of our combined method compared
to a variety of baselines, including a pure RL ablation and a state of the art
Markov chain Monte Carlo search method on this task.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Simmons_Edler_R/0/1/0/all/0/1&quot;&gt;Riley Simmons-Edler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Miltner_A/0/1/0/all/0/1&quot;&gt;Anders Miltner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Seung_S/0/1/0/all/0/1&quot;&gt;Sebastian Seung&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02967">
<title>Locating the boundaries of Pareto fronts: A Many-Objective Evolutionary Algorithm Based on Corner Solution Search. (arXiv:1806.02967v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1806.02967</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, an evolutionary many-objective optimization algorithm based on
corner solution search (MaOEA-CS) was proposed. MaOEA-CS implicitly contains
two phases: the exploitative search for the most important boundary optimal
solutions - corner solutions, at the first phase, and the use of angle-based
selection [1] with the explorative search for the extension of PF approximation
at the second phase. Due to its high efficiency and robustness to the shapes of
PFs, it has won the CEC&apos;2017 Competition on Evolutionary Many-Objective
Optimization. In addition, MaOEA-CS has also been applied on two real-world
engineering optimization problems with very irregular PFs. The experimental
results show that MaOEA-CS outperforms other six state-of-the-art compared
algorithms, which indicates it has the ability to handle real-world complex
optimization problems with irregular PFs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cai_X/0/1/0/all/0/1&quot;&gt;Xinye Cai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1&quot;&gt;Haoran Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_C/0/1/0/all/0/1&quot;&gt;Chunyang Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Zhenyu Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1&quot;&gt;Qingfu Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.04487">
<title>Better Runtime Guarantees Via Stochastic Domination. (arXiv:1801.04487v2 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1801.04487</link>
<description rdf:parseType="Literal">&lt;p&gt;Apart from few exceptions, the mathematical runtime analysis of evolutionary
algorithms is mostly concerned with expected runtimes. In this work, we argue
that stochastic domination is a notion that should be used more frequently in
this area. Stochastic domination allows to formulate much more informative
performance guarantees, it allows to decouple the algorithm analysis into the
true algorithmic part of detecting a domination statement and the
probability-theoretical part of deriving the desired probabilistic guarantees
from this statement, and it helps finding simpler and more natural proofs.
&lt;/p&gt;
&lt;p&gt;As particular results, we prove a fitness level theorem which shows that the
runtime is dominated by a sum of independent geometric random variables, we
prove the first tail bounds for several classic runtime problems, and we give a
short and natural proof for Witt&apos;s result that the runtime of any $(\mu,p)$
mutation-based algorithm on any function with unique optimum is subdominated by
the runtime of a variant of the \oea on the \onemax function.
&lt;/p&gt;
&lt;p&gt;As side-products, we determine the fastest unbiased (1+1) algorithm for the
\leadingones benchmark problem, both in the general case and when restricted to
static mutation operators, and we prove a Chernoff-type tail bound for sums of
independent coupon collector distributions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Doerr_B/0/1/0/all/0/1&quot;&gt;Benjamin Doerr&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02873">
<title>Medical Concept Embedding with Time-Aware Attention. (arXiv:1806.02873v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1806.02873</link>
<description rdf:parseType="Literal">&lt;p&gt;Embeddings of medical concepts such as medication, procedure and diagnosis
codes in Electronic Medical Records (EMRs) are central to healthcare analytics.
Previous work on medical concept embedding takes medical concepts and EMRs as
words and documents respectively. Nevertheless, such models miss out the
temporal nature of EMR data. On the one hand, two consecutive medical concepts
do not indicate they are temporally close, but the correlations between them
can be revealed by the time gap. On the other hand, the temporal scopes of
medical concepts often vary greatly (e.g., \textit{common cold} and
\textit{diabetes}). In this paper, we propose to incorporate the temporal
information to embed medical codes. Based on the Continuous Bag-of-Words model,
we employ the attention mechanism to learn a &quot;soft&quot; time-aware context window
for each medical concept. Experiments on public and proprietary datasets
through clustering and nearest neighbour search tasks demonstrate the
effectiveness of our model, showing that it outperforms five state-of-the-art
baselines.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cai_X/0/1/0/all/0/1&quot;&gt;Xiangrui Cai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1&quot;&gt;Jinyang Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ngiam_K/0/1/0/all/0/1&quot;&gt;Kee Yuan Ngiam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ooi_B/0/1/0/all/0/1&quot;&gt;Beng Chin Ooi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Ying Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yuan_X/0/1/0/all/0/1&quot;&gt;Xiaojie Yuan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02908">
<title>Is preprocessing of text really worth your time for online comment classification?. (arXiv:1806.02908v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1806.02908</link>
<description rdf:parseType="Literal">&lt;p&gt;A large proportion of online comments present on public domains are
constructive, however a significant proportion are toxic in nature. The
comments contain lot of typos which increases the number of features manifold,
making the ML model difficult to train. Considering the fact that the data
scientists spend approximately 80% of their time in collecting, cleaning and
organizing their data [1], we explored how much effort should we invest in the
preprocessing (transformation) of raw comments before feeding it to the
state-of-the-art classification models. With the help of four models on Jigsaw
toxic comment classification data, we demonstrated that the training of model
without any transformation produce relatively decent model. Applying even basic
transformations, in some cases, lead to worse performance and should be applied
with caution.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mohammad_F/0/1/0/all/0/1&quot;&gt;Fahim Mohammad&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02918">
<title>Color Sails: Discrete-Continuous Palettes for Deep Color Exploration. (arXiv:1806.02918v1 [cs.GR])</title>
<link>http://arxiv.org/abs/1806.02918</link>
<description rdf:parseType="Literal">&lt;p&gt;We present color sails, a discrete-continuous color gamut representation that
extends the color gradient analogy to three dimensions and allows interactive
control of the color blending behavior. Our representation models a wide
variety of color distributions in a compact manner, and lends itself to
applications such as color exploration for graphic design, illustration and
similar fields. We propose a Neural Network that can fit a color sail to any
image. Then, the user can adjust color sail parameters to change the base
colors, their blending behavior and the number of colors, exploring a wide
range of options for the original design. In addition, we propose a Deep
Learning model that learns to automatically segment an image into
color-compatible alpha masks, each equipped with its own color sail. This
allows targeted color exploration by either editing their corresponding color
sails or using standard software packages. Our model is trained on a custom
diverse dataset of art and design. We provide both quantitative evaluations,
and a user study, demonstrating the effectiveness of color sail interaction.
Interactive demos are available at www.colorsails.com.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shugrina_M/0/1/0/all/0/1&quot;&gt;Maria Shugrina&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kar_A/0/1/0/all/0/1&quot;&gt;Amlan Kar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singh_K/0/1/0/all/0/1&quot;&gt;Karan Singh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fidler_S/0/1/0/all/0/1&quot;&gt;Sanja Fidler&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02985">
<title>Continuous-time Value Function Approximation in Reproducing Kernel Hilbert Spaces. (arXiv:1806.02985v1 [math.OC])</title>
<link>http://arxiv.org/abs/1806.02985</link>
<description rdf:parseType="Literal">&lt;p&gt;Motivated by the success of reinforcement learning (RL) for discrete-time
tasks such as AlphaGo and Atari games, there has been a recent surge of
interest in using RL for continuous-time control of physical systems (cf. many
challenging tasks in OpenAI Gym and the DeepMind Control Suite). Since
discretization of time is susceptible to error, it is methodologically more
desirable to handle the system dynamics directly in continuous time. However,
very few techniques exist for continuous-time RL and they lack flexibility in
value function approximation. In this paper, we propose a novel framework for
continuous-time value function approximation based on reproducing kernel
Hilbert spaces. The resulting framework is so flexible that it can accommodate
any kind of kernel-based approach, such as Gaussian processes and the adaptive
projected subgradient method, and it allows us to handle uncertainties and
nonstationarity without prior knowledge about the environment or what basis
functions to employ. We demonstrate the validity of the presented framework
through experiments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Ohnishi_M/0/1/0/all/0/1&quot;&gt;Motoya Ohnishi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Yukawa_M/0/1/0/all/0/1&quot;&gt;Masahiro Yukawa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Johansson_M/0/1/0/all/0/1&quot;&gt;Mikael Johansson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Sugiyama_M/0/1/0/all/0/1&quot;&gt;Masashi Sugiyama&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.03155">
<title>Evaluating CBR Similarity Functions for BAM Switching in Networks with Dynamic Traffic Profile. (arXiv:1806.03155v1 [cs.NI])</title>
<link>http://arxiv.org/abs/1806.03155</link>
<description rdf:parseType="Literal">&lt;p&gt;In an increasingly complex scenario for network management, a solution that
allows configuration in more autonomous way with less intervention of the
network manager is expected. This paper presents an evaluation of similarity
functions that are necessary in the context of using a learning strategy for
finding solutions. The learning approach considered is based on Case-Based
Reasoning (CBR) and is applied to a network scenario where different Bandwidth
Allocation Models (BAMs) behaviors are used and must be eventually switched
looking for the best possible network operation. In this context, it is
required to identify and configure an adequate similarity function that will be
used in the learning process to recover similar solutions previously
considered. This paper introduces the similarity functions, explains the
relevant aspects of the learning process in which the similarity function plays
a role and, finally, presents a proof of concept for a specific similarity
function adopted. Results show that the similarity function was capable to get
similar results from the existing use case database. As such, the use of
similarity functions with CBR technique has proved to be potentially
satisfactory for supporting BAM switching decisions mostly driven by the
dynamics of input traffic profile.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oliveira_E/0/1/0/all/0/1&quot;&gt;Eliseu Oliveira&lt;/a&gt; (UNIFACS), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Freitas_R/0/1/0/all/0/1&quot;&gt;Rafael Freitas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Martins_J/0/1/0/all/0/1&quot;&gt;Joberto Martins&lt;/a&gt; (UNIFACS)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.03192">
<title>Assessing the impact of machine intelligence on human behaviour: an interdisciplinary endeavour. (arXiv:1806.03192v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1806.03192</link>
<description rdf:parseType="Literal">&lt;p&gt;This document contains the outcome of the first Human behaviour and machine
intelligence (HUMAINT) workshop that took place 5-6 March 2018 in Barcelona,
Spain. The workshop was organized in the context of a new research programme at
the Centre for Advanced Studies, Joint Research Centre of the European
Commission, which focuses on studying the potential impact of artificial
intelligence on human behaviour. The workshop gathered an interdisciplinary
group of experts to establish the state of the art research in the field and a
list of future research challenges to be addressed on the topic of human and
machine intelligence, algorithm&apos;s potential impact on human cognitive
capabilities and decision making, and evaluation and regulation needs. The
document is made of short position statements and identification of challenges
provided by each expert, and incorporates the result of the discussions carried
out during the workshop. In the conclusion section, we provide a list of
emerging research topics and strategies to be addressed in the near future.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gomez_E/0/1/0/all/0/1&quot;&gt;Emilia G&amp;#xf3;mez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Castillo_C/0/1/0/all/0/1&quot;&gt;Carlos Castillo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Charisi_V/0/1/0/all/0/1&quot;&gt;Vicky Charisi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dahl_V/0/1/0/all/0/1&quot;&gt;Ver&amp;#xf3;nica Dahl&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deco_G/0/1/0/all/0/1&quot;&gt;Gustavo Deco&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Delipetrev_B/0/1/0/all/0/1&quot;&gt;Blagoj Delipetrev&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dewandre_N/0/1/0/all/0/1&quot;&gt;Nicole Dewandre&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gonzalez_Ballester_M/0/1/0/all/0/1&quot;&gt;Miguel &amp;#xc1;ngel Gonz&amp;#xe1;lez-Ballester&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gouyon_F/0/1/0/all/0/1&quot;&gt;Fabien Gouyon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hernandez_Orallo_J/0/1/0/all/0/1&quot;&gt;Jos&amp;#xe9; Hern&amp;#xe1;ndez-Orallo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Herrera_P/0/1/0/all/0/1&quot;&gt;Perfecto Herrera&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jonsson_A/0/1/0/all/0/1&quot;&gt;Anders Jonsson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koene_A/0/1/0/all/0/1&quot;&gt;Ansgar Koene&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Larson_M/0/1/0/all/0/1&quot;&gt;Martha Larson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mantaras_R/0/1/0/all/0/1&quot;&gt;Ram&amp;#xf3;n L&amp;#xf3;pez de M&amp;#xe1;ntaras&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Martens_B/0/1/0/all/0/1&quot;&gt;Bertin Martens&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Miron_M/0/1/0/all/0/1&quot;&gt;Marius Miron&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moreno_Bote_R/0/1/0/all/0/1&quot;&gt;Rub&amp;#xe9;n Moreno-Bote&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oliver_N/0/1/0/all/0/1&quot;&gt;Nuria Oliver&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gallardo_A/0/1/0/all/0/1&quot;&gt;Antonio Puertas Gallardo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schweitzer_H/0/1/0/all/0/1&quot;&gt;Heike Schweitzer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sebastian_N/0/1/0/all/0/1&quot;&gt;Nuria Sebastian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Serra_X/0/1/0/all/0/1&quot;&gt;Xavier Serra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Serra_J/0/1/0/all/0/1&quot;&gt;Joan Serr&amp;#xe0;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tolan_S/0/1/0/all/0/1&quot;&gt;Song&amp;#xfc;l Tolan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vold_K/0/1/0/all/0/1&quot;&gt;Karina Vold&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.03240">
<title>Measuring Item Similarity in Introductory Programming: Python and Robot Programming Case Studies. (arXiv:1806.03240v1 [cs.CY])</title>
<link>http://arxiv.org/abs/1806.03240</link>
<description rdf:parseType="Literal">&lt;p&gt;A personalized learning system needs a large pool of items for learners to
solve. When working with a large pool of items, it is useful to measure the
similarity of items. We outline a general approach to measuring the similarity
of items and discuss specific measures for items used in introductory
programming. Evaluation of quality of similarity measures is difficult. To this
end, we propose an evaluation approach utilizing three levels of abstraction.
We illustrate our approach to measuring similarity and provide evaluation using
items from three diverse programming environments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pelanek_R/0/1/0/all/0/1&quot;&gt;Radek Pel&amp;#xe1;nek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Effenberger_T/0/1/0/all/0/1&quot;&gt;Tom&amp;#xe1;&amp;#x161; Effenberger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vanek_M/0/1/0/all/0/1&quot;&gt;Mat&amp;#x11b;j Van&amp;#x11b;k&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sassmann_V/0/1/0/all/0/1&quot;&gt;Vojt&amp;#x11b;ch Sassmann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gmiterko_D/0/1/0/all/0/1&quot;&gt;Dominik Gmiterko&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.03267">
<title>Orbital Petri Nets: A Novel Petri Net Approach. (arXiv:1806.03267v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1806.03267</link>
<description rdf:parseType="Literal">&lt;p&gt;Petri Nets is very interesting tool for studying and simulating different
behaviors of information systems. It can be used in different applications
based on the appropriate class of Petri Nets whereas it is classical, colored
or timed Petri Nets. In this paper we introduce a new approach of Petri Nets
called orbital Petri Nets (OPN) for studying the orbital rotating systems
within a specific domain. The study investigated and analyzed OPN with
highlighting the problem of space debris collision problem as a case study. The
mathematical investigation results of two OPN models proved that space debris
collision problem can be prevented based on the new method of firing sequence
in OPN. By this study, new smart algorithms can be implemented and simulated by
orbital Petri Nets for mitigating the space debris collision problem as a next
work.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yorky_M/0/1/0/all/0/1&quot;&gt;Mohamed Yorky&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hassanien_A/0/1/0/all/0/1&quot;&gt;Aboul Ella Hassanien&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.05380">
<title>The Uncertainty Bellman Equation and Exploration. (arXiv:1709.05380v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1709.05380</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the exploration/exploitation problem in reinforcement learning.
For exploitation, it is well known that the Bellman equation connects the value
at any time-step to the expected value at subsequent time-steps. In this paper
we consider a similar \textit{uncertainty} Bellman equation (UBE), which
connects the uncertainty at any time-step to the expected uncertainties at
subsequent time-steps, thereby extending the potential exploratory benefit of a
policy beyond individual time-steps. We prove that the unique fixed point of
the UBE yields an upper bound on the variance of the posterior distribution of
the Q-values induced by any policy. This bound can be much tighter than
traditional count-based bonuses that compound standard deviation rather than
variance. Importantly, and unlike several existing approaches to optimism, this
method scales naturally to large systems with complex generalization.
Substituting our UBE-exploration strategy for $\epsilon$-greedy improves DQN
performance on 51 out of 57 games in the Atari suite.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+ODonoghue_B/0/1/0/all/0/1&quot;&gt;Brendan O&amp;#x27;Donoghue&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Osband_I/0/1/0/all/0/1&quot;&gt;Ian Osband&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Munos_R/0/1/0/all/0/1&quot;&gt;Remi Munos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mnih_V/0/1/0/all/0/1&quot;&gt;Volodymyr Mnih&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.11157">
<title>A Semantic Loss Function for Deep Learning with Symbolic Knowledge. (arXiv:1711.11157v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1711.11157</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper develops a novel methodology for using symbolic knowledge in deep
learning. From first principles, we derive a semantic loss function that
bridges between neural output vectors and logical constraints. This loss
function captures how close the neural network is to satisfying the constraints
on its output. An experimental evaluation shows that it effectively guides the
learner to achieve (near-)state-of-the-art results on semi-supervised
multi-class classification. Moreover, it significantly increases the ability of
the neural network to predict structured objects, such as rankings and paths.
These discrete concepts are tremendously difficult to learn, and benefit from a
tight integration of deep learning and symbolic reasoning methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1&quot;&gt;Jingyi Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1&quot;&gt;Zilu Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Friedman_T/0/1/0/all/0/1&quot;&gt;Tal Friedman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1&quot;&gt;Yitao Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Broeck_G/0/1/0/all/0/1&quot;&gt;Guy Van den Broeck&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05027">
<title>Not to Cry Wolf: Distantly Supervised Multitask Learning in Critical Care. (arXiv:1802.05027v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1802.05027</link>
<description rdf:parseType="Literal">&lt;p&gt;Patients in the intensive care unit (ICU) require constant and close
supervision. To assist clinical staff in this task, hospitals use monitoring
systems that trigger audiovisual alarms if their algorithms indicate that a
patient&apos;s condition may be worsening. However, current monitoring systems are
extremely sensitive to movement artefacts and technical errors. As a result,
they typically trigger hundreds to thousands of false alarms per patient per
day - drowning the important alarms in noise and adding to the exhaustion of
clinical staff. In this setting, data is abundantly available, but obtaining
trustworthy annotations by experts is laborious and expensive. We frame the
problem of false alarm reduction from multivariate time series as a
machine-learning task and address it with a novel multitask network
architecture that utilises distant supervision through multiple related
auxiliary tasks in order to reduce the number of expensive labels required for
training. We show that our approach leads to significant improvements over
several state-of-the-art baselines on real-world ICU data and provide new
insights on the importance of task selection and architectural choices in
distantly supervised multitask learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schwab_P/0/1/0/all/0/1&quot;&gt;Patrick Schwab&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Keller_E/0/1/0/all/0/1&quot;&gt;Emanuela Keller&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Muroi_C/0/1/0/all/0/1&quot;&gt;Carl Muroi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mack_D/0/1/0/all/0/1&quot;&gt;David J. Mack&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Strassle_C/0/1/0/all/0/1&quot;&gt;Christian Str&amp;#xe4;ssle&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Karlen_W/0/1/0/all/0/1&quot;&gt;Walter Karlen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08183">
<title>Projection-Free Online Optimization with Stochastic Gradient: From Convexity to Submodularity. (arXiv:1802.08183v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1802.08183</link>
<description rdf:parseType="Literal">&lt;p&gt;Online optimization has been a successful framework for solving large-scale
problems under computational constraints and partial information. Current
methods for online convex optimization require either a projection or exact
gradient computation at each step, both of which can be prohibitively expensive
for large-scale applications. At the same time, there is a growing trend of
non-convex optimization in machine learning community and a need for online
methods. Continuous DR-submodular functions, which exhibit a natural
diminishing returns condition, have recently been proposed as a broad class of
non-convex functions which may be efficiently optimized. Although online
methods have been introduced, they suffer from similar problems. In this work,
we propose Meta-Frank-Wolfe, the first online projection-free algorithm that
uses stochastic gradient estimates. The algorithm relies on a careful sampling
of gradients in each round and achieves the optimal $O( \sqrt{T})$ adversarial
regret bounds for convex and continuous submodular optimization. We also
propose One-Shot Frank-Wolfe, a simpler algorithm which requires only a single
stochastic gradient estimate in each round and achieves an $O(T^{2/3})$
stochastic regret bound for convex and continuous submodular optimization. We
apply our methods to develop a novel &quot;lifting&quot; framework for the online
discrete submodular maximization and also see that they outperform current
state-of-the-art techniques on various experiments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chen_L/0/1/0/all/0/1&quot;&gt;Lin Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Harshaw_C/0/1/0/all/0/1&quot;&gt;Christopher Harshaw&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hassani_H/0/1/0/all/0/1&quot;&gt;Hamed Hassani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Karbasi_A/0/1/0/all/0/1&quot;&gt;Amin Karbasi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09477">
<title>Addressing Function Approximation Error in Actor-Critic Methods. (arXiv:1802.09477v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1802.09477</link>
<description rdf:parseType="Literal">&lt;p&gt;In value-based reinforcement learning methods such as deep Q-learning,
function approximation errors are known to lead to overestimated value
estimates and suboptimal policies. We show that this problem persists in an
actor-critic setting and propose novel mechanisms to minimize its effects on
both the actor and the critic. Our algorithm builds on Double Q-learning, by
taking the minimum value between a pair of critics to limit overestimation. We
draw the connection between target networks and overestimation bias, and
suggest delaying policy updates to reduce per-update error and further improve
performance. We evaluate our method on the suite of OpenAI gym tasks,
outperforming the state of the art in every environment tested.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fujimoto_S/0/1/0/all/0/1&quot;&gt;Scott Fujimoto&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hoof_H/0/1/0/all/0/1&quot;&gt;Herke van Hoof&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meger_D/0/1/0/all/0/1&quot;&gt;David Meger&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.08355">
<title>Structured Output Learning with Abstention: Application to Accurate Opinion Prediction. (arXiv:1803.08355v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1803.08355</link>
<description rdf:parseType="Literal">&lt;p&gt;Motivated by Supervised Opinion Analysis, we propose a novel framework
devoted to Structured Output Learning with Abstention (SOLA). The structure
prediction model is able to abstain from predicting some labels in the
structured output at a cost chosen by the user in a flexible way. For that
purpose, we decompose the problem into the learning of a pair of predictors,
one devoted to structured abstention and the other, to structured output
prediction. To compare fully labeled training data with predictions potentially
containing abstentions, we define a wide class of asymmetric abstention-aware
losses. Learning is achieved by surrogate regression in an appropriate feature
space while prediction with abstention is performed by solving a new pre-image
problem. Thus, SOLA extends recent ideas about Structured Output Prediction via
surrogate problems and calibration theory and enjoys statistical guarantees on
the resulting excess risk. Instantiated on a hierarchical abstention-aware
loss, SOLA is shown to be relevant for fine-grained opinion mining and gives
state-of-the-art results on this task. Moreover, the abstention-aware
representations can be used to competitively predict user-review ratings based
on a sentence-level opinion predictor.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garcia_A/0/1/0/all/0/1&quot;&gt;Alexandre Garcia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Essid_S/0/1/0/all/0/1&quot;&gt;Slim Essid&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Clavel_C/0/1/0/all/0/1&quot;&gt;Chlo&amp;#xe9; Clavel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+dAlche_Buc_F/0/1/0/all/0/1&quot;&gt;Florence d&amp;#x27;Alch&amp;#xe9;-Buc&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.02477">
<title>Programmatically Interpretable Reinforcement Learning. (arXiv:1804.02477v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1804.02477</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a reinforcement learning framework, called Programmatically
Interpretable Reinforcement Learning (PIRL), that is designed to generate
interpretable and verifiable agent policies. Unlike the popular Deep
Reinforcement Learning (DRL) paradigm, which represents policies by neural
networks, PIRL represents policies using a high-level, domain-specific
programming language. Such programmatic policies have the benefits of being
more easily interpreted than neural networks, and being amenable to
verification by symbolic methods. We propose a new method, called Neurally
Directed Program Search (NDPS), for solving the challenging nonsmooth
optimization problem of finding a programmatic policy with maximal reward. NDPS
works by first learning a neural policy network using DRL, and then performing
a local search over programmatic policies that seeks to minimize a distance
from this neural &quot;oracle&quot;. We evaluate NDPS on the task of learning to drive a
simulated car in the TORCS car-racing environment. We demonstrate that NDPS is
able to discover human-readable policies that pass some significant performance
bars. We also show that PIRL policies can have smoother trajectories, and can
be more easily transferred to environments not encountered during training,
than corresponding policies discovered by DRL.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Verma_A/0/1/0/all/0/1&quot;&gt;Abhinav Verma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Murali_V/0/1/0/all/0/1&quot;&gt;Vijayaraghavan Murali&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singh_R/0/1/0/all/0/1&quot;&gt;Rishabh Singh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kohli_P/0/1/0/all/0/1&quot;&gt;Pushmeet Kohli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chaudhuri_S/0/1/0/all/0/1&quot;&gt;Swarat Chaudhuri&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.07193">
<title>Lipschitz Continuity in Model-based Reinforcement Learning. (arXiv:1804.07193v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1804.07193</link>
<description rdf:parseType="Literal">&lt;p&gt;We examine the impact of learning Lipschitz continuous models in the context
of model-based reinforcement learning. We provide a novel bound on multi-step
prediction error of Lipschitz models where we quantify the error using the
Wasserstein metric. We go on to prove an error bound for the value-function
estimate arising from Lipschitz models and show that the estimated value
function is itself Lipschitz. We conclude with empirical results that show the
benefits of controlling the Lipschitz constant of neural-network models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Asadi_K/0/1/0/all/0/1&quot;&gt;Kavosh Asadi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Misra_D/0/1/0/all/0/1&quot;&gt;Dipendra Misra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Littman_M/0/1/0/all/0/1&quot;&gt;Michael L. Littman&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02027">
<title>Discrete-Continuous Mixtures in Probabilistic Programming: Generalized Semantics and Inference Algorithms. (arXiv:1806.02027v3 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1806.02027</link>
<description rdf:parseType="Literal">&lt;p&gt;Despite the recent successes of probabilistic programming languages (PPLs) in
AI applications, PPLs offer only limited support for random variables whose
distributions combine discrete and continuous elements. We develop the notion
of measure-theoretic Bayesian networks (MTBNs) and use it to provide more
general semantics for PPLs with arbitrarily many random variables defined over
arbitrary measure spaces. We develop two new general sampling algorithms that
are provably correct under the MTBN framework: the lexicographic likelihood
weighting (LLW) for general MTBNs and the lexicographic particle filter (LPF),
a specialized algorithm for state-space models. We further integrate MTBNs into
a widely used PPL system, BLOG, and verify the effectiveness of the new
inference algorithms through representative examples.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1&quot;&gt;Yi Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Srivastava_S/0/1/0/all/0/1&quot;&gt;Siddharth Srivastava&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hay_N/0/1/0/all/0/1&quot;&gt;Nicholas Hay&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Du_S/0/1/0/all/0/1&quot;&gt;Simon Du&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Russell_S/0/1/0/all/0/1&quot;&gt;Stuart Russell&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02457">
<title>Reference Model of Multi-Entity Bayesian Networks for Predictive Situation Awareness. (arXiv:1806.02457v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1806.02457</link>
<description rdf:parseType="Literal">&lt;p&gt;During the past quarter-century, situation awareness (SAW) has become a
critical research theme, because of its importance. Since the concept of SAW
was first introduced during World War I, various versions of SAW have been
researched and introduced. Predictive Situation Awareness (PSAW) focuses on the
ability to predict aspects of a temporally evolving situation over time. PSAW
requires a formal representation and a reasoning method using such a
representation. A Multi-Entity Bayesian Network (MEBN) is a knowledge
representation formalism combining Bayesian Networks (BN) with First-Order
Logic (FOL). MEBN can be used to represent uncertain situations (supported by
BN) as well as complex situations (supported by FOL). Also, efficient reasoning
algorithms for MEBN have been developed. MEBN can be a formal representation to
support PSAW and has been used for several PSAW systems. Although several MEBN
applications for PSAW exist, very little work can be found in the literature
that attempts to generalize a MEBN model to support PSAW. In this research, we
define a reference model for MEBN in PSAW, called a PSAW-MEBN reference model.
The PSAW-MEBN reference model enables us to easily develop a MEBN model for
PSAW by supporting the design of a MEBN model for PSAW. In this research, we
introduce two example use cases using the PSAW-MEBN reference model to develop
MEBN models to support PSAW: a Smart Manufacturing System and a Maritime Domain
Awareness System.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Park_C/0/1/0/all/0/1&quot;&gt;Cheol Young Park&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Laskey_K/0/1/0/all/0/1&quot;&gt;Kathryn Blackmond Laskey&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02510">
<title>Removing Algorithmic Discrimination (With Minimal Individual Error). (arXiv:1806.02510v1 [cs.AI] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1806.02510</link>
<description rdf:parseType="Literal">&lt;p&gt;We address the problem of correcting group discriminations within a score
function, while minimizing the individual error. Each group is described by a
probability density function on the set of profiles. We first solve the problem
analytically in the case of two populations, with a uniform bonus-malus on the
zones where each population is a majority. We then address the general case of
n populations, where the entanglement of populations does not allow a similar
analytical solution. We show that an approximate solution with an arbitrarily
high level of precision can be computed with linear programming. Finally, we
address the inverse problem where the error should not go beyond a certain
value and we seek to minimize the discrimination.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mhamdi_E/0/1/0/all/0/1&quot;&gt;El Mahdi El Mhamdi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guerraoui_R/0/1/0/all/0/1&quot;&gt;Rachid Guerraoui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hoang_L/0/1/0/all/0/1&quot;&gt;L&amp;#xea; Nguy&amp;#xea;n Hoang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Maurer_A/0/1/0/all/0/1&quot;&gt;Alexandre Maurer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02867">
<title>Direct Optimization through $\arg \max$ for Discrete Variational Auto-Encoder. (arXiv:1806.02867v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.02867</link>
<description rdf:parseType="Literal">&lt;p&gt;Reparameterization of variational auto-encoders with continuous latent spaces
is an effective method for reducing the variance of their gradient estimates.
However, using the same approach when latent variables are discrete is
problematic, due to the resulting non-differentiable objective. In this work,
we present a direct optimization method that propagates gradients through a
non-differentiable $\arg \max$ prediction operation. We apply this method to
discrete variational auto-encoders, by modeling a discrete random variable by
the $\arg \max$ function of the Gumbel-Max perturbation model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lorberbom_G/0/1/0/all/0/1&quot;&gt;Guy Lorberbom&lt;/a&gt; (Technion), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gane_A/0/1/0/all/0/1&quot;&gt;Andreea Gane&lt;/a&gt; (MIT), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jaakkola_T/0/1/0/all/0/1&quot;&gt;Tommi Jaakkola&lt;/a&gt; (MIT), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hazan_T/0/1/0/all/0/1&quot;&gt;Tamir Hazan&lt;/a&gt; (Technion)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02878">
<title>Learning Tasks for Multitask Learning: Heterogenous Patient Populations in the ICU. (arXiv:1806.02878v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.02878</link>
<description rdf:parseType="Literal">&lt;p&gt;Machine learning approaches have been effective in predicting adverse
outcomes in different clinical settings. These models are often developed and
evaluated on datasets with heterogeneous patient populations. However, good
predictive performance on the aggregate population does not imply good
performance for specific groups.
&lt;/p&gt;
&lt;p&gt;In this work, we present a two-step framework to 1) learn relevant patient
subgroups, and 2) predict an outcome for separate patient populations in a
multi-task framework, where each population is a separate task. We demonstrate
how to discover relevant groups in an unsupervised way with a
sequence-to-sequence autoencoder. We show that using these groups in a
multi-task framework leads to better predictive performance of in-hospital
mortality both across groups and overall. We also highlight the need for more
granular evaluation of performance when dealing with heterogeneous populations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Suresh_H/0/1/0/all/0/1&quot;&gt;Harini Suresh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gong_J/0/1/0/all/0/1&quot;&gt;Jen J. Gong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guttag_J/0/1/0/all/0/1&quot;&gt;John Guttag&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02887">
<title>Residual Unfairness in Fair Machine Learning from Prejudiced Data. (arXiv:1806.02887v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.02887</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent work in fairness in machine learning has proposed adjusting for
fairness by equalizing accuracy metrics across groups and has also studied how
datasets affected by historical prejudices may lead to unfair decision
policies. We connect these lines of work and study the residual unfairness that
arises when a fairness-adjusted predictor is not actually fair on the target
population due to systematic censoring of training data by existing biased
policies. This scenario is particularly common in the same applications where
fairness is a concern. We characterize theoretically the impact of such
censoring on standard fairness metrics for binary classifiers and provide
criteria for when residual unfairness may or may not appear. We prove that,
under certain conditions, fairness-adjusted classifiers will in fact induce
residual unfairness that perpetuates the same injustices, against the same
groups, that biased the data to begin with, thus showing that even
state-of-the-art fair machine learning can have a &quot;bias in, bias out&quot; property.
When certain benchmark data is available, we show how sample reweighting can
estimate and adjust fairness metrics while accounting for censoring. We use
this to study the case of Stop, Question, and Frisk (SQF) and demonstrate that
attempting to adjust for fairness perpetuates the same injustices that the
policy is infamous for.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kallus_N/0/1/0/all/0/1&quot;&gt;Nathan Kallus&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhou_A/0/1/0/all/0/1&quot;&gt;Angela Zhou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02892">
<title>Training Faster by Separating Modes of Variation in Batch-normalized Models. (arXiv:1806.02892v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1806.02892</link>
<description rdf:parseType="Literal">&lt;p&gt;Batch Normalization (BN) is essential to effectively train state-of-the-art
deep Convolutional Neural Networks (CNN). It normalizes inputs to the layers
during training using the statistics of each mini-batch. In this work, we study
BN from the viewpoint of Fisher kernels. We show that assuming samples within a
mini-batch are from the same probability density function, then BN is identical
to the Fisher vector of a Gaussian distribution. That means BN can be explained
in terms of kernels that naturally emerge from the probability density function
of the underlying data distribution. However, given the rectifying
non-linearities employed in CNN architectures, distribution of inputs to the
layers show heavy tail and asymmetric characteristics. Therefore, we propose
approximating underlying data distribution not with one, but a mixture of
Gaussian densities. Deriving Fisher vector for a Gaussian Mixture Model (GMM),
reveals that BN can be improved by independently normalizing with respect to
the statistics of disentangled sub-populations. We refer to our proposed soft
piecewise version of BN as Mixture Normalization (MN). Through extensive set of
experiments on CIFAR-10 and CIFAR-100, we show that MN not only effectively
accelerates training image classification and Generative Adversarial networks,
but also reaches higher quality models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kalayeh_M/0/1/0/all/0/1&quot;&gt;Mahdi M. Kalayeh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shah_M/0/1/0/all/0/1&quot;&gt;Mubarak Shah&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02920">
<title>GAIN: Missing Data Imputation using Generative Adversarial Nets. (arXiv:1806.02920v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.02920</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a novel method for imputing missing data by adapting the
well-known Generative Adversarial Nets (GAN) framework. Accordingly, we call
our method Generative Adversarial Imputation Nets (GAIN). The generator (G)
observes some components of a real data vector, imputes the missing components
conditioned on what is actually observed, and outputs a completed vector. The
discriminator (D) then takes a completed vector and attempts to determine which
components were actually observed and which were imputed. To ensure that D
forces G to learn the desired distribution, we provide D with some additional
information in the form of a hint vector. The hint reveals to D partial
information about the missingness of the original sample, which is used by D to
focus its attention on the imputation quality of particular components. This
hint ensures that G does in fact learn to generate according to the true data
distribution. We tested our method on various datasets and found that GAIN
significantly outperforms state-of-the-art imputation methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yoon_J/0/1/0/all/0/1&quot;&gt;Jinsung Yoon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jordon_J/0/1/0/all/0/1&quot;&gt;James Jordon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schaar_M/0/1/0/all/0/1&quot;&gt;Mihaela van der Schaar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02922">
<title>Feature selection in functional data classification with recursive maxima hunting. (arXiv:1806.02922v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.02922</link>
<description rdf:parseType="Literal">&lt;p&gt;Dimensionality reduction is one of the key issues in the design of effective
machine learning methods for automatic induction. In this work, we introduce
recursive maxima hunting (RMH) for variable selection in classification
problems with functional data. In this context, variable selection techniques
are especially attractive because they reduce the dimensionality, facilitate
the interpretation and can improve the accuracy of the predictive models. The
method, which is a recursive extension of maxima hunting (MH), performs
variable selection by identifying the maxima of a relevance function, which
measures the strength of the correlation of the predictor functional variable
with the class label. At each stage, the information associated with the
selected variable is removed by subtracting the conditional expectation of the
process. The results of an extensive empirical evaluation are used to
illustrate that, in the problems investigated, RMH has comparable or higher
predictive accuracy than the standard dimensionality reduction techniques, such
as PCA and PLS, and state-of-the-art feature selection methods for functional
data, such as maxima hunting.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Torrecilla_J/0/1/0/all/0/1&quot;&gt;Jos&amp;#xe9; L. Torrecilla&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Suarez_A/0/1/0/all/0/1&quot;&gt;Alberto Su&amp;#xe1;rez&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02927">
<title>Lightweight Stochastic Optimization for Minimizing Finite Sums with Infinite Data. (arXiv:1806.02927v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.02927</link>
<description rdf:parseType="Literal">&lt;p&gt;Variance reduction has been commonly used in stochastic optimization. It
relies crucially on the assumption that the data set is finite. However, when
the data are imputed with random noise as in data augmentation, the perturbed
data set be- comes essentially infinite. Recently, the stochastic MISO (S-MISO)
algorithm is introduced to address this expected risk minimization problem.
Though it converges faster than SGD, a significant amount of memory is
required. In this pa- per, we propose two SGD-like algorithms for expected risk
minimization with random perturbation, namely, stochastic sample average
gradient (SSAG) and stochastic SAGA (S-SAGA). The memory cost of SSAG does not
depend on the sample size, while that of S-SAGA is the same as those of
variance reduction methods on un- perturbed data. Theoretical analysis and
experimental results on logistic regression and AUC maximization show that SSAG
has faster convergence rate than SGD with comparable space requirement, while
S-SAGA outperforms S-MISO in terms of both iteration complexity and storage.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_S/0/1/0/all/0/1&quot;&gt;Shuai Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kwok_J/0/1/0/all/0/1&quot;&gt;James T. Kwok&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02935">
<title>Causal effects based on distributional distances. (arXiv:1806.02935v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.02935</link>
<description rdf:parseType="Literal">&lt;p&gt;We develop a novel framework for estimating causal effects based on the
discrepancy between unobserved counterfactual distributions. In our setting a
causal effect is defined in terms of the $L_1$ distance between different
counterfactual outcome distributions, rather than a mean difference in outcome
values. Directly comparing counterfactual outcome distributions can provide
more nuanced and valuable information about causality than a simple comparison
of means. We consider single- and multi-source randomized studies, as well as
observational studies, and analyze error bounds and asymptotic properties of
the proposed estimators. We further propose methods to construct confidence
intervals for the unknown mean distribution distance. Finally, we illustrate
the new methods and verify their effectiveness in empirical studies.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kim_K/0/1/0/all/0/1&quot;&gt;Kwangho Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kim_J/0/1/0/all/0/1&quot;&gt;Jisu Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kennedy_E/0/1/0/all/0/1&quot;&gt;Edward H. Kennedy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02954">
<title>Using Social Network Information in Bayesian Truth Discovery. (arXiv:1806.02954v1 [cs.SI])</title>
<link>http://arxiv.org/abs/1806.02954</link>
<description rdf:parseType="Literal">&lt;p&gt;We investigate the problem of truth discovery based on opinions from multiple
agents who may be unreliable or biased. We consider the case where agents&apos;
reliabilities or biases are correlated if they belong to the same community,
which defines a group of agents with similar opinions regarding a particular
event. An agent can belong to different communities for different events, and
these communities are unknown \emph{a priori}. We incorporate knowledge of the
agents&apos; social network in our truth discovery framework and develop Laplace
variational inference methods to estimate agents&apos; reliabilities, communities,
and the event states. We also develop a stochastic variational inference method
to scale our model to large social networks. Simulations and experiments on
real data suggest that when observations are sparse, our proposed methods
perform better than several other inference methods, including majority voting,
the popular Bayesian Classifier Combination (BCC) method, and the Community BCC
method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1&quot;&gt;Jielong Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Junshan Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tay_W/0/1/0/all/0/1&quot;&gt;Wee Peng Tay&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02958">
<title>The Case for Full-Matrix Adaptive Regularization. (arXiv:1806.02958v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.02958</link>
<description rdf:parseType="Literal">&lt;p&gt;Adaptive regularization methods come in diagonal and full-matrix variants.
However, only the former have enjoyed widespread adoption in training
large-scale deep models. This is due to the computational overhead of
manipulating a full matrix in high dimension. In this paper, we show how to
make full-matrix adaptive regularization practical and useful. We present GGT,
a truly scalable full-matrix adaptive optimizer. At the heart of our algorithm
is an efficient method for computing the inverse square root of a low-rank
matrix. We show that GGT converges to first-order local minima, providing the
first rigorous theoretical analysis of adaptive regularization in non-convex
optimization. In preliminary experiments, GGT trains faster across a variety of
synthetic tasks and standard deep learning benchmarks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Agarwal_N/0/1/0/all/0/1&quot;&gt;Naman Agarwal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bullins_B/0/1/0/all/0/1&quot;&gt;Brian Bullins&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1&quot;&gt;Xinyi Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hazan_E/0/1/0/all/0/1&quot;&gt;Elad Hazan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singh_K/0/1/0/all/0/1&quot;&gt;Karan Singh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1&quot;&gt;Cyril Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yi Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02970">
<title>PAC Ranking from Pairwise and Listwise Queries: Lower Bounds and Upper Bounds. (arXiv:1806.02970v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.02970</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper explores the adaptively (active) PAC (probably approximately
correct) top-$k$ ranking and total ranking from $l$-wise ($l\geq 2$)
comparisons under the popular multinomial logit (MNL) model. By adaptively
choosing sets to query and observing the noisy output about the most favored
item of each query, we want to design ranking algorithms that recover the
top-$k$ or total ranking using as few queries as possible. For the PAC top-$k$
ranking problem, we prove a lower bound on the sample complexity (aka number of
queries), and propose an algorithm that is sample complexity optimal up to a
$O(\log(k+l)/\log{k})$ factor. When $l=2$ (i.e., pairwise) or $l=O(poly(k))$,
the algorithm matches the lower bound. For the PAC total ranking problem, we
prove a lower bound, and propose an algorithm that matches the lower bound.
When $l=2$, this model reduces to the popular Plackett-Luce (PL) model, and our
results still outperform the state-of-the-art theoretically and numerically. We
also run comparisons of our algorithms with the state-of-the-art on synthesized
data as well as real-world data, and demonstrate the improvement on sample
complexity numerically.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ren_W/0/1/0/all/0/1&quot;&gt;Wenbo Ren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Jia Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shroff_N/0/1/0/all/0/1&quot;&gt;Ness B. Shroff&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02977">
<title>Monge beats Bayes: Hardness Results for Adversarial Training. (arXiv:1806.02977v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.02977</link>
<description rdf:parseType="Literal">&lt;p&gt;The last few years have seen extensive empirical study of the robustness of
neural networks, with a concerning conclusion: several state-of-the-art
approaches are highly sensitive to adversarial perturbations of their inputs.
There has been an accompanying surge of interest in learning including defense
mechanisms against specific adversaries, known as adversarial training. Despite
some impressive advances, little remains known on how to best frame a
resource-bounded adversary so that it can be severely detrimental to learning,
a non-trivial problem which entails at a minimum the choice of loss and
classifiers.
&lt;/p&gt;
&lt;p&gt;We suggest here a formal answer to this question, and pin down a simple
sufficient property for any given class of adversaries to be detrimental to
learning. This property involves a central measure of &quot;harmfulness&quot; which
generalizes the well-known class of integral probability metrics, and thus the
maximum mean discrepancy. A key feature of our result is that it holds for all
proper losses, and for a popular subset of these, the optimisation of this
central measure appears to be \textit{independent of the loss}.
&lt;/p&gt;
&lt;p&gt;We then deliver a sufficient condition for this sufficient property to hold
for Lipschitz classifiers, which relies on framing it into optimal transport
theory. We finally deliver a negative boosting result which shows how weakly
contractive adversaries for a RKHS can be combined to build a maximally
detrimental adversary, show that some implemented existing adversaries involve
proxies of our optimal transport adversaries and finally provide a toy
experiment assessing such adversaries in a simple context, displaying that
additional robustness on testing can be granted through adversarial training.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cranko_Z/0/1/0/all/0/1&quot;&gt;Zac Cranko&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Menon_A/0/1/0/all/0/1&quot;&gt;Aditya Krishna Menon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nock_R/0/1/0/all/0/1&quot;&gt;Richard Nock&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ong_C/0/1/0/all/0/1&quot;&gt;Cheng-Soon Ong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_Z/0/1/0/all/0/1&quot;&gt;Zhan Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Walder_C/0/1/0/all/0/1&quot;&gt;Christian Walder&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02988">
<title>Towards Binary-Valued Gates for Robust LSTM Training. (arXiv:1806.02988v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.02988</link>
<description rdf:parseType="Literal">&lt;p&gt;Long Short-Term Memory (LSTM) is one of the most widely used recurrent
structures in sequence modeling. It aims to use gates to control information
flow (e.g., whether to skip some information or not) in the recurrent
computations, although its practical implementation based on soft gates only
partially achieves this goal. In this paper, we propose a new way for LSTM
training, which pushes the output values of the gates towards 0 or 1. By doing
so, we can better control the information flow: the gates are mostly open or
closed, instead of in a middle state, which makes the results more
interpretable. Empirical studies show that (1) Although it seems that we
restrict the model capacity, there is no performance drop: we achieve better or
comparable performances due to its better generalization ability; (2) The
outputs of gates are not sensitive to their inputs: we can easily compress the
LSTM unit in multiple ways, e.g., low-rank approximation and low-precision
approximation. The compressed models are even better than the baseline models
without compression.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Zhuohan Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_D/0/1/0/all/0/1&quot;&gt;Di He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tian_F/0/1/0/all/0/1&quot;&gt;Fei Tian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1&quot;&gt;Wei Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qin_T/0/1/0/all/0/1&quot;&gt;Tao Qin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1&quot;&gt;Liwei Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1&quot;&gt;Tie-Yan Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.03000">
<title>Noise-adding Methods of Saliency Map as Series of Higher Order Partial Derivative. (arXiv:1806.03000v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.03000</link>
<description rdf:parseType="Literal">&lt;p&gt;SmoothGrad and VarGrad are techniques that enhance the empirical quality of
standard saliency maps by adding noise to input. However, there were few works
that provide a rigorous theoretical interpretation of those methods. We
analytically formalize the result of these noise-adding methods. As a result,
we observe two interesting results from the existing noise-adding methods.
First, SmoothGrad does not make the gradient of the score function smooth.
Second, VarGrad is independent of the gradient of the score function. We
believe that our findings provide a clue to reveal the relationship between
local explanation methods of deep neural networks and higher-order partial
derivatives of the score function.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Seo_J/0/1/0/all/0/1&quot;&gt;Junghoon Seo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Choe_J/0/1/0/all/0/1&quot;&gt;Jeongyeol Choe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koo_J/0/1/0/all/0/1&quot;&gt;Jamyoung Koo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jeon_S/0/1/0/all/0/1&quot;&gt;Seunghyeon Jeon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_B/0/1/0/all/0/1&quot;&gt;Beomsu Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jeon_T/0/1/0/all/0/1&quot;&gt;Taegyun Jeon&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.03044">
<title>Investigating the Impact of CNN Depth on Neonatal Seizure Detection Performance. (arXiv:1806.03044v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.03044</link>
<description rdf:parseType="Literal">&lt;p&gt;This study presents a novel, deep, fully convolutional architecture which is
optimized for the task of EEG-based neonatal seizure detection. Architectures
of different depths were designed and tested; varying network depth impacts
convolutional receptive fields and the corresponding learned feature
complexity. Two deep convolutional networks are compared with a shallow
SVM-based neonatal seizure detector, which relies on the extraction of
hand-crafted features. On a large clinical dataset, of over 800 hours of
multichannel unedited EEG, containing 1389 seizure events, the deep 11-layer
architecture significantly outperforms the shallower architectures, improving
the AUC90 from 82.6% to 86.8%. Combining the end-to-end deep architecture with
the feature-based shallow SVM further improves the AUC90 to 87.6%. The fusion
of classifiers of different depths gives greatly improved performance and
reduced variability, making the combined classifier more clinically reliable.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+OShea_A/0/1/0/all/0/1&quot;&gt;Alison O&amp;#x27;Shea&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lightbody_G/0/1/0/all/0/1&quot;&gt;Gordon Lightbody&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Boylan_G/0/1/0/all/0/1&quot;&gt;Geraldine Boylan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Temko_A/0/1/0/all/0/1&quot;&gt;Andriy Temko&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.03085">
<title>A Stein variational Newton method. (arXiv:1806.03085v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.03085</link>
<description rdf:parseType="Literal">&lt;p&gt;Stein variational gradient descent (SVGD) was recently proposed as a general
purpose nonparametric variational inference algorithm [Liu &amp;amp; Wang, NIPS 2016]:
it minimizes the Kullback-Leibler divergence between the target distribution
and its approximation by implementing a form of functional gradient descent on
a reproducing kernel Hilbert space. In this paper, we accelerate and generalize
the SVGD algorithm by including second-order information, thereby approximating
a Newton-like iteration in function space. We also show how second-order
information can lead to more effective choices of kernel. We observe
significant computational gains over the original SVGD algorithm in multiple
test cases.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Detommaso_G/0/1/0/all/0/1&quot;&gt;Gianluca Detommaso&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Cui_T/0/1/0/all/0/1&quot;&gt;Tiangang Cui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Marzouk_Y/0/1/0/all/0/1&quot;&gt;Youssef Marzouk&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Scheichl_R/0/1/0/all/0/1&quot;&gt;Robert Scheichl&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Spantini_A/0/1/0/all/0/1&quot;&gt;Alessio Spantini&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.03121">
<title>Machine Learning CICY Threefolds. (arXiv:1806.03121v1 [hep-th])</title>
<link>http://arxiv.org/abs/1806.03121</link>
<description rdf:parseType="Literal">&lt;p&gt;The latest techniques from Neural Networks and Support Vector Machines (SVM)
are used to investigate geometric properties of Complete Intersection
Calabi-Yau (CICY) threefolds, a class of manifolds that facilitate string model
building. An advanced neural network classifier and SVM are employed to (1)
learn Hodge numbers and report a remarkable improvement over previous efforts,
(2) query for favourability, and (3) predict discrete symmetries, a highly
imbalanced problem to which the Synthetic Minority Oversampling Technique
(SMOTE) is applied to boost performance. In each case study, we employ a
genetic algorithm to optimise the hyperparameters of the neural network. We
demonstrate that our approach provides quick diagnostic tools capable of
shortlisting quasi-realistic string models based on compactification over
smooth CICYs and further supports the paradigm that classes of problems in
algebraic geometry can be machine learned.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/hep-th/1/au:+Bull_K/0/1/0/all/0/1&quot;&gt;Kieran Bull&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/hep-th/1/au:+He_Y/0/1/0/all/0/1&quot;&gt;Yang-Hui He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/hep-th/1/au:+Jejjala_V/0/1/0/all/0/1&quot;&gt;Vishnu Jejjala&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/hep-th/1/au:+Mishra_C/0/1/0/all/0/1&quot;&gt;Challenger Mishra&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.03125">
<title>Text Classification based on Word Subspace with Term-Frequency. (arXiv:1806.03125v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.03125</link>
<description rdf:parseType="Literal">&lt;p&gt;Text classification has become indispensable due to the rapid increase of
text in digital form. Over the past three decades, efforts have been made to
approach this task using various learning algorithms and statistical models
based on bag-of-words (BOW) features. Despite its simple implementation, BOW
features lack semantic meaning representation. To solve this problem, neural
networks started to be employed to learn word vectors, such as the word2vec.
Word2vec embeds word semantic structure into vectors, where the angle between
vectors indicates the meaningful similarity between words. To measure the
similarity between texts, we propose the novel concept of word subspace, which
can represent the intrinsic variability of features in a set of word vectors.
Through this concept, it is possible to model text from word vectors while
holding semantic information. To incorporate the word frequency directly in the
subspace model, we further extend the word subspace to the term-frequency (TF)
weighted word subspace. Based on these new concepts, text classification can be
performed under the mutual subspace method (MSM) framework. The validity of our
modeling is shown through experiments on the Reuters text database, comparing
the results to various state-of-art algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Shimomoto_E/0/1/0/all/0/1&quot;&gt;Erica K. Shimomoto&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Souza_L/0/1/0/all/0/1&quot;&gt;Lincon S. Souza&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gatto_B/0/1/0/all/0/1&quot;&gt;Bernardo B. Gatto&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Fukui_K/0/1/0/all/0/1&quot;&gt;Kazuhiro Fukui&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.03143">
<title>Black Box FDR. (arXiv:1806.03143v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.03143</link>
<description rdf:parseType="Literal">&lt;p&gt;Analyzing large-scale, multi-experiment studies requires scientists to test
each experimental outcome for statistical significance and then assess the
results as a whole. We present Black Box FDR (BB-FDR), an empirical-Bayes
method for analyzing multi-experiment studies when many covariates are gathered
per experiment. BB-FDR learns a series of black box predictive models to boost
power and control the false discovery rate (FDR) at two stages of study
analysis. In Stage 1, it uses a deep neural network prior to report which
experiments yielded significant outcomes. In Stage 2, a separate black box
model of each covariate is used to select features that have significant
predictive power across all experiments. In benchmarks, BB-FDR outperforms
competing state-of-the-art methods in both stages of analysis. We apply BB-FDR
to two real studies on cancer drug efficacy. For both studies, BB-FDR increases
the proportion of significant outcomes discovered and selects variables that
reveal key genomic drivers of drug sensitivity and resistance in cancer.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tansey_W/0/1/0/all/0/1&quot;&gt;Wesley Tansey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yixin Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Blei_D/0/1/0/all/0/1&quot;&gt;David M. Blei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rabadan_R/0/1/0/all/0/1&quot;&gt;Raul Rabadan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.03145">
<title>Fidelity-based Probabilistic Q-learning for Control of Quantum Systems. (arXiv:1806.03145v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.03145</link>
<description rdf:parseType="Literal">&lt;p&gt;The balance between exploration and exploitation is a key problem for
reinforcement learning methods, especially for Q-learning. In this paper, a
fidelity-based probabilistic Q-learning (FPQL) approach is presented to
naturally solve this problem and applied for learning control of quantum
systems. In this approach, fidelity is adopted to help direct the learning
process and the probability of each action to be selected at a certain state is
updated iteratively along with the learning process, which leads to a natural
exploration strategy instead of a pointed one with configured parameters. A
probabilistic Q-learning (PQL) algorithm is first presented to demonstrate the
basic idea of probabilistic action selection. Then the FPQL algorithm is
presented for learning control of quantum systems. Two examples (a spin- 1/2
system and a lamda-type atomic system) are demonstrated to test the performance
of the FPQL algorithm. The results show that FPQL algorithms attain a better
balance between exploration and exploitation, and can also avoid local optimal
policies and accelerate the learning process.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1&quot;&gt;Chunlin Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dong_D/0/1/0/all/0/1&quot;&gt;Daoyi Dong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1&quot;&gt;Han-Xiong Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chu_J/0/1/0/all/0/1&quot;&gt;Jian Chu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tarn_T/0/1/0/all/0/1&quot;&gt;Tzyh-Jong Tarn&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.03146">
<title>Neural Message Passing with Edge Updates for Predicting Properties of Molecules and Materials. (arXiv:1806.03146v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.03146</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural message passing on molecular graphs is one of the most promising
methods for predicting formation energy and other properties of molecules and
materials. In this work we extend the neural message passing model with an edge
update network which allows the information exchanged between atoms to depend
on the hidden state of the receiving atom. We benchmark the proposed model on
three publicly available datasets (QM9, The Materials Project and OQMD) and
show that the proposed model yields superior prediction of formation energies
and other properties on all three datasets in comparison with the best
published results. Furthermore we investigate different methods for
constructing the graph used to represent crystalline structures and we find
that using a graph based on K-nearest neighbors achieves better prediction
accuracy than using maximum distance cutoff or the Voronoi tessellation graph.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Jorgensen_P/0/1/0/all/0/1&quot;&gt;Peter Bj&amp;#xf8;rn J&amp;#xf8;rgensen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Jacobsen_K/0/1/0/all/0/1&quot;&gt;Karsten Wedel Jacobsen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Schmidt_M/0/1/0/all/0/1&quot;&gt;Mikkel N. Schmidt&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.03182">
<title>Deep learning based inverse method for layout design. (arXiv:1806.03182v1 [eess.SP])</title>
<link>http://arxiv.org/abs/1806.03182</link>
<description rdf:parseType="Literal">&lt;p&gt;Layout design with complex constraints is a challenging problem to solve due
to the non-uniqueness of the solution and the difficulties in incorporating the
constraints into the conventional optimization-based methods. In this paper, we
propose a design method based on the recently developed machine learning
technique, Variational Autoencoder (VAE). We utilize the learning capability of
the VAE to learn the constraints and the generative capability of the VAE to
generate design candidates that automatically satisfy all the constraints. As
such, no constraints need to be imposed during the design stage. In addition,
we show that the VAE network is also capable of learning the underlying physics
of the design problem, leading to an efficient design tool that does not need
any physical simulation once the network is constructed. We demonstrated the
performance of the method on two cases: inverse design of surface diffusion
induced morphology change and mask design for optical microlithography.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yujie Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Ye_W/0/1/0/all/0/1&quot;&gt;Wenjing Ye&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.03185">
<title>Wave-U-Net: A Multi-Scale Neural Network for End-to-End Audio Source Separation. (arXiv:1806.03185v1 [cs.SD])</title>
<link>http://arxiv.org/abs/1806.03185</link>
<description rdf:parseType="Literal">&lt;p&gt;Models for audio source separation usually operate on the magnitude spectrum,
which ignores phase information and makes separation performance dependant on
hyper-parameters for the spectral front-end. Therefore, we investigate
end-to-end source separation in the time-domain, which allows modelling phase
information and avoids fixed spectral transformations. Due to high sampling
rates for audio, employing a long temporal input context on the sample level is
difficult, but required for high quality separation results because of
long-range temporal correlations. In this context, we propose the Wave-U-Net,
an adaptation of the U-Net to the one-dimensional time domain, which repeatedly
resamples feature maps to compute and combine features at different time
scales. We introduce further architectural improvements, including an output
layer that enforces source additivity, an upsampling technique and a
context-aware prediction framework to reduce output artifacts. Experiments for
singing voice separation indicate that our architecture yields a performance
comparable to a state-of-the-art spectrogram-based U-Net architecture, given
the same data. Finally, we reveal a problem with outliers in the currently used
SDR evaluation metrics and suggest reporting rank-based statistics to alleviate
this problem.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stoller_D/0/1/0/all/0/1&quot;&gt;Daniel Stoller&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ewert_S/0/1/0/all/0/1&quot;&gt;Sebastian Ewert&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dixon_S/0/1/0/all/0/1&quot;&gt;Simon Dixon&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.03190">
<title>The Well Tempered Lasso. (arXiv:1806.03190v1 [cs.DS])</title>
<link>http://arxiv.org/abs/1806.03190</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the complexity of the entire regularization path for least squares
regression with 1-norm penalty, known as the Lasso. Every regression parameter
in the Lasso changes linearly as a function of the regularization value. The
number of changes is regarded as the Lasso&apos;s complexity. Experimental results
using exact path following exhibit polynomial complexity of the Lasso in the
problem size. Alas, the path complexity of the Lasso on artificially designed
regression problems is exponential.
&lt;/p&gt;
&lt;p&gt;We use smoothed analysis as a mechanism for bridging the gap between worst
case settings and the de facto low complexity. Our analysis assumes that the
observed data has a tiny amount of intrinsic noise. We then prove that the
Lasso&apos;s complexity is polynomial in the problem size. While building upon the
seminal work of Spielman and Teng on smoothed complexity, our analysis is
morally different as it is divorced from specific path following algorithms. We
verify the validity of our analysis in experiments with both worst case
settings and real datasets. The empirical results we obtain closely match our
analysis.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yuanzhi Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singer_Y/0/1/0/all/0/1&quot;&gt;Yoram Singer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.03198">
<title>A neural network catalyzer for multi-dimensional similarity search. (arXiv:1806.03198v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.03198</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper aims at learning a function mapping input vectors to an output
space in a way that improves high-dimensional similarity search. As a proxy
objective, we design and train a neural network that favors uniformity in the
spherical output space, while preserving the neighborhood structure after the
mapping. For this purpose, we propose a new regularizer derived from the
Kozachenko-Leonenko differential entropy estimator and combine it with a
locality-aware triplet loss. Our method operates as a catalyzer for traditional
indexing methods such as locality sensitive hashing or iterative quantization,
boosting the overall recall. Additionally, the network output distribution
makes it possible to leverage structured quantizers with efficient algebraic
encoding, in particular spherical lattice quantizers such as the Gosset lattice
E8. Our experiments show that this approach is competitive with
state-of-the-art methods such as optimized product quantization.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sablayrolles_A/0/1/0/all/0/1&quot;&gt;Alexandre Sablayrolles&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Douze_M/0/1/0/all/0/1&quot;&gt;Matthijs Douze&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Schmid_C/0/1/0/all/0/1&quot;&gt;Cordelia Schmid&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Jegou_H/0/1/0/all/0/1&quot;&gt;Herv&amp;#xe9; J&amp;#xe9;gou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.03218">
<title>Data-driven model for the identification of the rock type at a drilling bit. (arXiv:1806.03218v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.03218</link>
<description rdf:parseType="Literal">&lt;p&gt;In order to bridge the gap of more than 15m between the drilling bit and
high-fidelity rock type sensors during the directional drilling, we present a
novel approach for identifying rock type at the drilling bit. The approach is
based on application of machine learning techniques for Measurements While
Drilling (MWD) data. We demonstrate capabilities of the developed approach for
distinguishing between the rock types corresponding to (1) a target oil bearing
interval of a reservoir and (2) a non-productive shale layer and compare it to
more traditional physics-driven approaches. The dataset includes MWD data and
lithology mapping along multiple wellbores obtained by processing of Logging
While Drilling (LWD) measurements from a massive drilling effort on one of the
major newly developed oilfield in the North of Western Siberia. We compare
various machine-learning algorithms, examine extra features coming from
physical modeling of drilling mechanics, and show that the classification error
can be reduced from 13.5% to 9%.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Klyuchnikov_N/0/1/0/all/0/1&quot;&gt;Nikita Klyuchnikov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zaytsev_A/0/1/0/all/0/1&quot;&gt;Alexey Zaytsev&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gruzdev_A/0/1/0/all/0/1&quot;&gt;Arseniy Gruzdev&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ovchinnikov_G/0/1/0/all/0/1&quot;&gt;Georgiy Ovchinnikov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Antipova_K/0/1/0/all/0/1&quot;&gt;Ksenia Antipova&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ismailova_L/0/1/0/all/0/1&quot;&gt;Leyla Ismailova&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Muravleva_E/0/1/0/all/0/1&quot;&gt;Ekaterina Muravleva&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Burnaev_E/0/1/0/all/0/1&quot;&gt;Evgeny Burnaev&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Semenikhin_A/0/1/0/all/0/1&quot;&gt;Artyom Semenikhin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cherepanov_A/0/1/0/all/0/1&quot;&gt;Alexey Cherepanov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koryabkin_V/0/1/0/all/0/1&quot;&gt;Vitaliy Koryabkin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Simon_I/0/1/0/all/0/1&quot;&gt;Igor Simon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tsurgan_A/0/1/0/all/0/1&quot;&gt;Alexey Tsurgan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Krasnov_F/0/1/0/all/0/1&quot;&gt;Fedor Krasnov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koroteev_D/0/1/0/all/0/1&quot;&gt;Dmitry Koroteev&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.03232">
<title>Randomized Optimal Transport on a Graph: Framework and New Distance Measures. (arXiv:1806.03232v1 [cs.SI])</title>
<link>http://arxiv.org/abs/1806.03232</link>
<description rdf:parseType="Literal">&lt;p&gt;The recently developed bag-of-paths framework consists in setting a
Gibbs-Boltzmann distribution on all feasible paths of a graph. This probability
distribution favors short paths over long ones, with a free parameter (the
temperature $T &amp;gt; 0$) controlling the entropic level of the distribution. This
formalism enables the computation of new distances or dissimilarities,
interpolating between the shortest-path and the resistance distance, which have
been shown to perform well in clustering and classification tasks. In this
work, the bag-of-paths formalism is extended by adding two independent equality
constraints fixing starting and ending nodes distributions of paths. When the
temperature is low, this formalism is shown to be equivalent to a relaxation of
the optimal transport problem on a network where paths carry a flow between two
discrete distributions on nodes. The randomization is achieved by considering
free energy minimization instead of traditional cost minimization. Algorithms
computing the optimal free energy solution are developed for two types of
paths: hitting (or absorbing) paths and non-hitting, regular paths, and require
the inversion of an $n \times n$ matrix with $n$ being the number of nodes.
Interestingly, for regular paths, the resulting optimal policy interpolates
between the deterministic optimal transport policy ($T \rightarrow 0^{+}$) and
the solution to the corresponding electrical circuit ($T \rightarrow \infty$).
Two distance measures between nodes and a dissimilarity between groups of
nodes, both integrating weights on nodes, are derived from this framework.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guex_G/0/1/0/all/0/1&quot;&gt;Guillaume Guex&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kivimaki_I/0/1/0/all/0/1&quot;&gt;Ilkka Kivim&amp;#xe4;ki&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saerens_M/0/1/0/all/0/1&quot;&gt;Marco Saerens&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.03281">
<title>Blind Justice: Fairness with Encrypted Sensitive Attributes. (arXiv:1806.03281v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.03281</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent work has explored how to train machine learning models which do not
discriminate against any subgroup of the population as determined by sensitive
attributes such as gender or race. To avoid disparate treatment, sensitive
attributes should not be considered. On the other hand, in order to avoid
disparate impact, sensitive attributes must be examined, e.g., in order to
learn a fair model, or to check if a given model is fair. We introduce methods
from secure multi-party computation which allow us to avoid both. By encrypting
sensitive attributes, we show how an outcome-based fair model may be learned,
checked, or have its outputs verified and held to account, without users
revealing their sensitive attributes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kilbertus_N/0/1/0/all/0/1&quot;&gt;Niki Kilbertus&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gascon_A/0/1/0/all/0/1&quot;&gt;Adri&amp;#xe0; Gasc&amp;#xf3;n&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kusner_M/0/1/0/all/0/1&quot;&gt;Matt J. Kusner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Veale_M/0/1/0/all/0/1&quot;&gt;Michael Veale&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gummadi_K/0/1/0/all/0/1&quot;&gt;Krishna P. Gummadi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Weller_A/0/1/0/all/0/1&quot;&gt;Adrian Weller&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.03285">
<title>Pricing Engine: Estimating Causal Impacts in Real World Business Settings. (arXiv:1806.03285v1 [econ.EM])</title>
<link>http://arxiv.org/abs/1806.03285</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce the Pricing Engine package to enable the use of Double ML
estimation techniques in general panel data settings. Customization allows the
user to specify first-stage models, first-stage featurization, second stage
treatment selection and second stage causal-modeling. We also introduce a
DynamicDML class that allows the user to generate dynamic treatment-aware
forecasts at a range of leads and to understand how the forecasts will vary as
a function of causally estimated treatment parameters. The Pricing Engine is
built on Python 3.5 and can be run on an Azure ML Workbench environment with
the addition of only a few Python packages. This note provides high-level
discussion of the Double ML method, describes the packages intended use and
includes an example Jupyter notebook demonstrating application to some publicly
available data. Installation of the package and additional technical
documentation is available at https://github.com/bquistorff/pricingengine.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/econ/1/au:+Goldman_M/0/1/0/all/0/1&quot;&gt;Matt Goldman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/econ/1/au:+Quistorff_B/0/1/0/all/0/1&quot;&gt;Brian Quistorff&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.03286">
<title>Nonparametric Regression with Comparisons: Escaping the Curse of Dimensionality with Ordinal Information. (arXiv:1806.03286v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.03286</link>
<description rdf:parseType="Literal">&lt;p&gt;In supervised learning, we leverage a labeled dataset to design methods for
function estimation. In many practical situations, we are able to obtain
alternative feedback, possibly at a low cost. A broad goal is to understand the
usefulness of, and to design algorithms to exploit, this alternative feedback.
We focus on a semi-supervised setting where we obtain additional ordinal (or
comparison) information for potentially unlabeled samples. We consider ordinal
feedback of varying qualities where we have either a perfect ordering of the
samples, a noisy ordering of the samples or noisy pairwise comparisons between
the samples. We provide a precise quantification of the usefulness of these
types of ordinal feedback in non-parametric regression, showing that in many
cases it is possible to accurately estimate an underlying function with a very
small labeled set, effectively escaping the curse of dimensionality. We develop
an algorithm called Ranking-Regression (RR) and analyze its accuracy as a
function of size of the labeled and unlabeled datasets and various noise
parameters. We also present lower bounds, that establish fundamental limits for
the task and show that RR is optimal in a variety of settings. Finally, we
present experiments that show the efficacy of RR and investigate its robustness
to various sources of noise and model-misspecification.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Xu_Y/0/1/0/all/0/1&quot;&gt;Yichong Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Muthakana_H/0/1/0/all/0/1&quot;&gt;Hariank Muthakana&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Balakrishnan_S/0/1/0/all/0/1&quot;&gt;Sivaraman Balakrishnan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Singh_A/0/1/0/all/0/1&quot;&gt;Aarti Singh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Dubrawski_A/0/1/0/all/0/1&quot;&gt;Artur Dubrawski&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.03287">
<title>Slalom: Fast, Verifiable and Private Execution of Neural Networks in Trusted Hardware. (arXiv:1806.03287v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.03287</link>
<description rdf:parseType="Literal">&lt;p&gt;As Machine Learning (ML) gets applied to security-critical or sensitive
domains, there is a growing need for integrity and privacy guarantees for ML
computations running in untrusted environments. A pragmatic solution comes from
Trusted Execution Environments, which use hardware and software protections to
isolate sensitive computations from the untrusted software stack. However,
these isolation guarantees come at a price in performance, compared to
untrusted alternatives. This paper initiates the study of high performance
execution of Deep Neural Networks (DNNs) in trusted environments by efficiently
partitioning computations between trusted and untrusted devices. Building upon
a simple secure outsourcing scheme for matrix multiplication, we propose
Slalom, a framework that outsources execution of all linear layers in a DNN
from any trusted environment (e.g., SGX, TrustZone or Sanctum) to a faster
co-located device. We evaluate Slalom by executing DNNs in an Intel SGX
enclave, which selectively outsources work to an untrusted GPU. For two
canonical DNNs, VGG16 and MobileNet, we obtain 20x and 6x increases in
throughput for verifiable inference, and 10x and 3.5x for verifiable and
private inference.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tramer_F/0/1/0/all/0/1&quot;&gt;Florian Tramer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Boneh_D/0/1/0/all/0/1&quot;&gt;Dan Boneh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1401.5508">
<title>Hilbert Space Methods for Reduced-Rank Gaussian Process Regression. (arXiv:1401.5508v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1401.5508</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper proposes a novel scheme for reduced-rank Gaussian process
regression. The method is based on an approximate series expansion of the
covariance function in terms of an eigenfunction expansion of the Laplace
operator in a compact subset of $\mathbb{R}^d$. On this approximate eigenbasis
the eigenvalues of the covariance function can be expressed as simple functions
of the spectral density of the Gaussian process, which allows the GP inference
to be solved under a computational cost scaling as $\mathcal{O}(nm^2)$
(initial) and $\mathcal{O}(m^3)$ (hyperparameter learning) with $m$ basis
functions and $n$ data points. The approach also allows for rigorous error
analysis with Hilbert space theory, and we show that the approximation becomes
exact when the size of the compact subset and the number of eigenfunctions go
to infinity. The expansion generalizes to Hilbert spaces with an inner product
which is defined as an integral over a specified input density. The method is
compared to previously proposed methods theoretically and through empirical
tests with simulated and real data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Solin_A/0/1/0/all/0/1&quot;&gt;Arno Solin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sarkka_S/0/1/0/all/0/1&quot;&gt;Simo S&amp;#xe4;rkk&amp;#xe4;&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1506.05855">
<title>Information-based inference for singular models and finite sample sizes: A frequentist information criterion. (arXiv:1506.05855v5 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1506.05855</link>
<description rdf:parseType="Literal">&lt;p&gt;In the information-based paradigm of inference, model selection is performed
by selecting the candidate model with the best estimated predictive
performance. The success of this approach depends on the accuracy of the
estimate of the predictive complexity. In the large-sample-size limit of a
regular model, the predictive performance is well estimated by the Akaike
Information Criterion (AIC). However, this approximation can either
significantly under or over-estimating the complexity in a wide range of
important applications where models are either non-regular or
finite-sample-size corrections are significant. We introduce an improved
approximation for the complexity that is used to define a new information
criterion: the Frequentist Information Criterion (QIC). QIC extends the
applicability of information-based inference to the finite-sample-size regime
of regular models and to singular models. We demonstrate the power and the
comparative advantage of QIC in a number of example analyses.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+LaMont_C/0/1/0/all/0/1&quot;&gt;Colin H. LaMont&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wiggins_P/0/1/0/all/0/1&quot;&gt;Paul A. Wiggins&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1606.00925">
<title>Convolutional Imputation of Matrix Networks. (arXiv:1606.00925v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1606.00925</link>
<description rdf:parseType="Literal">&lt;p&gt;A matrix network is a family of matrices, with relatedness modeled by a
weighted graph. We consider the task of completing a partially observed matrix
network. We assume a novel sampling scheme where a fraction of matrices might
be completely unobserved. How can we recover the entire matrix network from
incomplete observations? This mathematical problem arises in many applications
including medical imaging and social networks.
&lt;/p&gt;
&lt;p&gt;To recover the matrix network, we propose a structural assumption that the
matrices have a graph Fourier transform which is low-rank. We formulate a
convex optimization problem and prove an exact recovery guarantee for the
optimization problem. Furthermore, we numerically characterize the exact
recovery regime for varying rank and sampling rate and discover a new phase
transition phenomenon. Then we give an iterative imputation algorithm to
efficiently solve the optimization problem and complete large scale matrix
networks. We demonstrate the algorithm with a variety of applications such as
MRI and Facebook user network.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_Q/0/1/0/all/0/1&quot;&gt;Qingyun Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Donoho_M/0/1/0/all/0/1&quot;&gt;Mengyuan Yan David Donoho&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Boyd_S/0/1/0/all/0/1&quot;&gt;Stephen Boyd&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1612.03450">
<title>Noisy subspace clustering via matching pursuits. (arXiv:1612.03450v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1612.03450</link>
<description rdf:parseType="Literal">&lt;p&gt;Sparsity-based subspace clustering algorithms have attracted significant
attention thanks to their excellent performance in practical applications. A
prominent example is the sparse subspace clustering (SSC) algorithm by
Elhamifar and Vidal, which performs spectral clustering based on an adjacency
matrix obtained by sparsely representing each data point in terms of all the
other data points via the Lasso. When the number of data points is large or the
dimension of the ambient space is high, the computational complexity of SSC
quickly becomes prohibitive. Dyer et al. observed that SSC-OMP obtained by
replacing the Lasso by the greedy orthogonal matching pursuit (OMP) algorithm
results in significantly lower computational complexity, while often yielding
comparable performance. The central goal of this paper is an analytical
performance characterization of SSC-OMP for noisy data. Moreover, we introduce
and analyze the SSC-MP algorithm, which employs matching pursuit (MP) in lieu
of OMP. Both SSC-OMP and SSC-MP are proven to succeed even when the subspaces
intersect and when the data points are contaminated by severe noise. The
clustering conditions we obtain for SSC-OMP and SSC-MP are similar to those for
SSC and for the thresholding-based subspace clustering (TSC) algorithm due to
Heckel and B\&quot;olcskei. Analytical results in combination with numerical results
indicate that both SSC-OMP and SSC-MP with a data-dependent stopping criterion
automatically detect the dimensions of the subspaces underlying the data.
Moreover, experiments on synthetic and on real data show that SSC-MP compares
very favorably to SSC, SSC-OMP, TSC, and the nearest subspace neighbor
algorithm, both in terms of clustering performance and running time. In
addition, we find that, in contrast to SSC-OMP, the performance of SSC-MP is
very robust with respect to the choice of parameters in the stopping criteria.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tschannen_M/0/1/0/all/0/1&quot;&gt;Michael Tschannen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bolcskei_H/0/1/0/all/0/1&quot;&gt;Helmut B&amp;#xf6;lcskei&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1703.04691">
<title>Conditional Time Series Forecasting with Convolutional Neural Networks. (arXiv:1703.04691v4 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1703.04691</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a method for conditional time series forecasting based on an
adaptation of the recent deep convolutional WaveNet architecture. The proposed
network contains stacks of dilated convolutions that allow it to access a broad
range of history when forecasting, a ReLU activation function and conditioning
is performed by applying multiple convolutional filters in parallel to separate
time series which allows for the fast processing of data and the exploitation
of the correlation structure between the multivariate time series. We test and
analyze the performance of the convolutional network both unconditionally as
well as conditionally for financial time series forecasting using the S&amp;amp;P500,
the volatility index, the CBOE interest rate and several exchange rates and
extensively compare it to the performance of the well-known autoregressive
model and a long-short term memory network. We show that a convolutional
network is well-suited for regression-type problems and is able to effectively
learn dependencies in and between the series without the need for long
historical time series, is a time-efficient and easy to implement alternative
to recurrent-type networks and tends to outperform linear and recurrent models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Borovykh_A/0/1/0/all/0/1&quot;&gt;Anastasia Borovykh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bohte_S/0/1/0/all/0/1&quot;&gt;Sander Bohte&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Oosterlee_C/0/1/0/all/0/1&quot;&gt;Cornelis W. Oosterlee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.04425">
<title>Message Passing Stein Variational Gradient Descent. (arXiv:1711.04425v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1711.04425</link>
<description rdf:parseType="Literal">&lt;p&gt;Stein variational gradient descent (SVGD) is a recently proposed
particle-based Bayesian inference method, which has attracted a lot of interest
due to its remarkable approximation ability and particle efficiency compared to
traditional variational inference and Markov Chain Monte Carlo methods.
However, we observed that particles of SVGD tend to collapse to modes of the
target distribution, and this particle degeneracy phenomenon becomes more
severe with higher dimensions. Our theoretical analysis finds out that there
exists a negative correlation between the dimensionality and the repulsive
force of SVGD which should be blamed for this phenomenon. We propose Message
Passing SVGD (MP-SVGD) to solve this problem. By leveraging the conditional
independence structure of probabilistic graphical models (PGMs), MP-SVGD
converts the original high-dimensional global inference problem into a set of
local ones over the Markov blanket with lower dimensions. Experimental results
show its advantages of preventing vanishing repulsive force in high-dimensional
space over SVGD, and its particle efficiency and approximation flexibility over
other inference methods on graphical models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhuo_J/0/1/0/all/0/1&quot;&gt;Jingwei Zhuo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Liu_C/0/1/0/all/0/1&quot;&gt;Chang Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Shi_J/0/1/0/all/0/1&quot;&gt;Jiaxin Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhu_J/0/1/0/all/0/1&quot;&gt;Jun Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chen_N/0/1/0/all/0/1&quot;&gt;Ning Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhang_B/0/1/0/all/0/1&quot;&gt;Bo Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.07168">
<title>Stein Variational Message Passing for Continuous Graphical Models. (arXiv:1711.07168v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1711.07168</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a novel distributed inference algorithm for continuous graphical
models, by extending Stein variational gradient descent (SVGD) to leverage the
Markov dependency structure of the distribution of interest. Our approach
combines SVGD with a set of structured local kernel functions defined on the
Markov blanket of each node, which alleviates the curse of high dimensionality
and simultaneously yields a distributed algorithm for decentralized inference
tasks. We justify our method with theoretical analysis and show that the use of
local kernels can be viewed as a new type of localized approximation that
matches the target distribution on the conditional distributions of each node
over its Markov blanket. Our empirical results show that our method outperforms
a variety of baselines including standard MCMC and particle message passing
methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wang_D/0/1/0/all/0/1&quot;&gt;Dilin Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zeng_Z/0/1/0/all/0/1&quot;&gt;Zhe Zeng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Liu_Q/0/1/0/all/0/1&quot;&gt;Qiang Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.06309">
<title>Composite Functional Gradient Learning of Generative Adversarial Models. (arXiv:1801.06309v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1801.06309</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper first presents a theory for generative adversarial methods that
does not rely on the traditional minimax formulation. It shows that with a
strong discriminator, a good generator can be learned so that the KL divergence
between the distributions of real data and generated data improves after each
functional gradient step until it converges to zero. Based on the theory, we
propose a new stable generative adversarial method. A theoretical insight into
the original GAN from this new viewpoint is also provided. The experiments on
image generation show the effectiveness of our new method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Johnson_R/0/1/0/all/0/1&quot;&gt;Rie Johnson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhang_T/0/1/0/all/0/1&quot;&gt;Tong Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.00008">
<title>On the Topic of Jets: Disentangling Quarks and Gluons at Colliders. (arXiv:1802.00008v2 [hep-ph] UPDATED)</title>
<link>http://arxiv.org/abs/1802.00008</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce jet topics: a framework to identify underlying classes of jets
from collider data. Because of a close mathematical relationship between
distributions of observables in jets and emergent themes in sets of documents,
we can apply recent techniques in &quot;topic modeling&quot; to extract jet topics from
data with minimal or no input from simulation or theory. As a proof of concept
with parton shower samples, we apply jet topics to determine separate quark and
gluon jet distributions for constituent multiplicity. We also determine
separate quark and gluon rapidity spectra from a mixed Z-plus-jet sample. While
jet topics are defined directly from hadron-level multi-differential cross
sections, one can also predict jet topics from first-principles theoretical
calculations, with potential implications for how to define quark and gluon
jets beyond leading-logarithmic accuracy. These investigations suggest that jet
topics will be useful for extracting underlying jet distributions and fractions
in a wide range of contexts at the Large Hadron Collider.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/hep-ph/1/au:+Metodiev_E/0/1/0/all/0/1&quot;&gt;Eric M. Metodiev&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/hep-ph/1/au:+Thaler_J/0/1/0/all/0/1&quot;&gt;Jesse Thaler&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.03801">
<title>SGD and Hogwild! Convergence Without the Bounded Gradients Assumption. (arXiv:1802.03801v2 [math.OC] UPDATED)</title>
<link>http://arxiv.org/abs/1802.03801</link>
<description rdf:parseType="Literal">&lt;p&gt;Stochastic gradient descent (SGD) is the optimization algorithm of choice in
many machine learning applications such as regularized empirical risk
minimization and training deep neural networks. The classical convergence
analysis of SGD is carried out under the assumption that the norm of the
stochastic gradient is uniformly bounded. While this might hold for some loss
functions, it is always violated for cases where the objective function is
strongly convex. In (Bottou et al.,2016), a new analysis of convergence of SGD
is performed under the assumption that stochastic gradients are bounded with
respect to the true gradient norm. Here we show that for stochastic problems
arising in machine learning such bound always holds; and we also propose an
alternative convergence analysis of SGD with diminishing learning rate regime,
which results in more relaxed conditions than those in (Bottou et al.,2016). We
then move on the asynchronous parallel setting, and prove convergence of
Hogwild! algorithm in the same regime, obtaining the first convergence results
for this method in the case of diminished learning rate.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Nguyen_L/0/1/0/all/0/1&quot;&gt;Lam M. Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Nguyen_P/0/1/0/all/0/1&quot;&gt;Phuong Ha Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Dijk_M/0/1/0/all/0/1&quot;&gt;Marten van Dijk&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Richtarik_P/0/1/0/all/0/1&quot;&gt;Peter Richt&amp;#xe1;rik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Scheinberg_K/0/1/0/all/0/1&quot;&gt;Katya Scheinberg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Takac_M/0/1/0/all/0/1&quot;&gt;Martin Tak&amp;#xe1;&amp;#x10d;&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06501">
<title>Recommendations with Negative Feedback via Pairwise Deep Reinforcement Learning. (arXiv:1802.06501v2 [cs.IR] UPDATED)</title>
<link>http://arxiv.org/abs/1802.06501</link>
<description rdf:parseType="Literal">&lt;p&gt;Recommender systems play a crucial role in mitigating the problem of
information overload by suggesting users&apos; personalized items or services. The
vast majority of traditional recommender systems consider the recommendation
procedure as a static process and make recommendations following a fixed
strategy. In this paper, we propose a novel recommender system with the
capability of continuously improving its strategies during the interactions
with users. We model the sequential interactions between users and a
recommender system as a Markov Decision Process (MDP) and leverage
Reinforcement Learning (RL) to automatically learn the optimal strategies via
recommending trial-and-error items and receiving reinforcements of these items
from users&apos; feedback. Users&apos; feedback can be positive and negative and both
types of feedback have great potentials to boost recommendations. However, the
number of negative feedback is much larger than that of positive one; thus
incorporating them simultaneously is challenging since positive feedback could
be buried by negative one. In this paper, we develop a novel approach to
incorporate them into the proposed deep recommender system (DEERS) framework.
The experimental results based on real-world e-commerce data demonstrate the
effectiveness of the proposed framework. Further experiments have been
conducted to understand the importance of both positive and negative feedback
in recommendations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1&quot;&gt;Xiangyu Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1&quot;&gt;Liang Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ding_Z/0/1/0/all/0/1&quot;&gt;Zhuoye Ding&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xia_L/0/1/0/all/0/1&quot;&gt;Long Xia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1&quot;&gt;Jiliang Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yin_D/0/1/0/all/0/1&quot;&gt;Dawei Yin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.06058">
<title>Constant-Time Predictive Distributions for Gaussian Processes. (arXiv:1803.06058v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1803.06058</link>
<description rdf:parseType="Literal">&lt;p&gt;One of the most compelling features of Gaussian process (GP) regression is
its ability to provide well-calibrated posterior distributions. Recent advances
in inducing point methods have sped up GP marginal likelihood and posterior
mean computations, leaving posterior covariance estimation and sampling as the
remaining computational bottlenecks. In this paper we address these
shortcomings by using the Lanczos algorithm to rapidly approximate the
predictive covariance matrix. Our approach, which we refer to as LOVE (LanczOs
Variance Estimates), substantially improves time and space complexity. In our
experiments, LOVE computes covariances up to 2,000 times faster and draws
samples 18,000 times faster than existing methods, all without sacrificing
accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pleiss_G/0/1/0/all/0/1&quot;&gt;Geoff Pleiss&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gardner_J/0/1/0/all/0/1&quot;&gt;Jacob R. Gardner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Weinberger_K/0/1/0/all/0/1&quot;&gt;Kilian Q. Weinberger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wilson_A/0/1/0/all/0/1&quot;&gt;Andrew Gordon Wilson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.09159">
<title>Efficient Discovery of Heterogeneous Treatment Effects in Randomized Experiments via Anomalous Pattern Detection. (arXiv:1803.09159v2 [stat.ME] UPDATED)</title>
<link>http://arxiv.org/abs/1803.09159</link>
<description rdf:parseType="Literal">&lt;p&gt;In the recent literature on estimating heterogeneous treatment effects, each
proposed method makes its own set of restrictive assumptions about the
intervention&apos;s effects and which subpopulations to explicitly estimate.
Moreover, the majority of the literature provides no mechanism to identify
which subpopulations are the most affected--beyond manual inspection--and
provides little guarantee on the correctness of the identified subpopulations.
Therefore, we propose Treatment Effect Subset Scan (TESS), a new method for
discovering which subpopulation in a randomized experiment is most
significantly affected by a treatment. We frame this challenge as a pattern
detection problem where we efficiently maximize a nonparametric scan statistic
over subpopulations. Furthermore, we identify the subpopulation which
experiences the largest distributional change as a result of the intervention,
while making minimal assumptions about the intervention&apos;s effects or the
underlying data generating process. In addition to the algorithm, we
demonstrate that the asymptotic Type I and II error can be controlled, and
provide sufficient conditions for detection consistency--i.e., exact
identification of the affected subpopulation. Finally, we validate the efficacy
of the method by discovering heterogeneous treatment effects in simulations and
in real-world data from a well-known program evaluation study.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+McFowland_E/0/1/0/all/0/1&quot;&gt;Edward McFowland III&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Somanchi_S/0/1/0/all/0/1&quot;&gt;Sriram Somanchi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Neill_D/0/1/0/all/0/1&quot;&gt;Daniel B. Neill&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.09539">
<title>On Matching Pursuit and Coordinate Descent. (arXiv:1803.09539v4 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1803.09539</link>
<description rdf:parseType="Literal">&lt;p&gt;Two popular examples of first-order optimization methods over linear spaces
are coordinate descent and matching pursuit algorithms, with their randomized
variants. While the former targets the optimization by moving along
coordinates, the latter considers a generalized notion of directions.
Exploiting the connection between the two algorithms, we present a unified
analysis of both, providing affine invariant sublinear $O(1/t)$ rates on smooth
objectives and linear convergence on strongly convex objectives. As a byproduct
of our affine invariant analysis of matching pursuit, our rates for steepest
coordinate descent are the tightest known. Furthermore, we show the first
accelerated convergence rate $O(1/t^2)$ for matching pursuit and steepest
coordinate descent on convex objectives.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Locatello_F/0/1/0/all/0/1&quot;&gt;Francesco Locatello&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Raj_A/0/1/0/all/0/1&quot;&gt;Anant Raj&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Karimireddy_S/0/1/0/all/0/1&quot;&gt;Sai Praneeth Karimireddy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ratsch_G/0/1/0/all/0/1&quot;&gt;Gunnar R&amp;#xe4;tsch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Scholkopf_B/0/1/0/all/0/1&quot;&gt;Bernhard Sch&amp;#xf6;lkopf&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Stich_S/0/1/0/all/0/1&quot;&gt;Sebastian U. Stich&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Jaggi_M/0/1/0/all/0/1&quot;&gt;Martin Jaggi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.03184">
<title>Adversarial Time-to-Event Modeling. (arXiv:1804.03184v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1804.03184</link>
<description rdf:parseType="Literal">&lt;p&gt;Modern health data science applications leverage abundant molecular and
electronic health data, providing opportunities for machine learning to build
statistical models to support clinical practice. Time-to-event analysis, also
called survival analysis, stands as one of the most representative examples of
such statistical models. We present a deep-network-based approach that
leverages adversarial learning to address a key challenge in modern
time-to-event modeling: nonparametric estimation of event-time distributions.
We also introduce a principled cost function to exploit information from
censored events (events that occur subsequent to the observation window).
Unlike most time-to-event models, we focus on the estimation of time-to-event
distributions, rather than time ordering. We validate our model on both
benchmark and real datasets, demonstrating that the proposed formulation yields
significant performance gains relative to a parametric alternative, which we
also propose.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chapfuwa_P/0/1/0/all/0/1&quot;&gt;Paidamoyo Chapfuwa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tao_C/0/1/0/all/0/1&quot;&gt;Chenyang Tao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Li_C/0/1/0/all/0/1&quot;&gt;Chunyuan Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Page_C/0/1/0/all/0/1&quot;&gt;Courtney Page&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Goldstein_B/0/1/0/all/0/1&quot;&gt;Benjamin Goldstein&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Carin_L/0/1/0/all/0/1&quot;&gt;Lawrence Carin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Henao_R/0/1/0/all/0/1&quot;&gt;Ricardo Henao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.08598">
<title>Black-box Adversarial Attacks with Limited Queries and Information. (arXiv:1804.08598v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1804.08598</link>
<description rdf:parseType="Literal">&lt;p&gt;Current neural network-based classifiers are susceptible to adversarial
examples even in the black-box setting, where the attacker only has query
access to the model. In practice, the threat model for real-world systems is
often more restrictive than the typical black-box model where the adversary can
observe the full output of the network on arbitrarily many chosen inputs. We
define three realistic threat models that more accurately characterize many
real-world classifiers: the query-limited setting, the partial-information
setting, and the label-only setting. We develop new attacks that fool
classifiers under these more restrictive threat models, where previous methods
would be impractical or ineffective. We demonstrate that our methods are
effective against an ImageNet classifier under our proposed threat models. We
also demonstrate a targeted black-box attack against a commercial classifier,
overcoming the challenges of limited query access, partial information, and
other practical issues to break the Google Cloud Vision API.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ilyas_A/0/1/0/all/0/1&quot;&gt;Andrew Ilyas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Engstrom_L/0/1/0/all/0/1&quot;&gt;Logan Engstrom&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Athalye_A/0/1/0/all/0/1&quot;&gt;Anish Athalye&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1&quot;&gt;Jessy Lin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.08841">
<title>Between hard and soft thresholding: optimal iterative thresholding algorithms. (arXiv:1804.08841v3 [stat.ME] UPDATED)</title>
<link>http://arxiv.org/abs/1804.08841</link>
<description rdf:parseType="Literal">&lt;p&gt;Iterative thresholding algorithms seek to optimize a differentiable objective
function over a sparsity or rank constraint by alternating between gradient
steps that reduce the objective, and thresholding steps that enforce the
constraint. This work examines the choice of the thresholding operator, and
asks whether it is possible to achieve stronger guarantees than what is
possible with hard thresholding. We develop the notion of relative concavity of
a thresholding operator, a quantity that characterizes the convergence
performance of any thresholding operator on the target optimization problem.
Surprisingly, we find that commonly used thresholding operators, such as hard
thresholding and soft thresholding, are suboptimal in terms of convergence
guarantees. Instead, a general class of thresholding operators, lying between
hard thresholding and soft thresholding, is shown to be optimal with the
strongest possible convergence guarantee among all thresholding operators.
Examples of this general class includes $\ell_q$ thresholding with appropriate
choices of $q$, and a newly defined {\em reciprocal thresholding} operator. We
also investigate the implications of the improved optimization guarantee in the
statistical setting of sparse linear regression, and show that this new class
of thresholding operators attain the optimal rate for computationally efficient
estimators, matching the Lasso.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Liu_H/0/1/0/all/0/1&quot;&gt;Haoyang Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Barber_R/0/1/0/all/0/1&quot;&gt;Rina Foygel Barber&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.09699">
<title>Towards Fast Computation of Certified Robustness for ReLU Networks. (arXiv:1804.09699v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1804.09699</link>
<description rdf:parseType="Literal">&lt;p&gt;Verifying the robustness property of a general Rectified Linear Unit (ReLU)
network is an NP-complete problem [Katz, Barrett, Dill, Julian and Kochenderfer
CAV17]. Although finding the exact minimum adversarial distortion is hard,
giving a certified lower bound of the minimum distortion is possible. Current
available methods of computing such a bound are either time-consuming or
delivering low quality bounds that are too loose to be useful. In this paper,
we exploit the special structure of ReLU networks and provide two
computationally efficient algorithms Fast-Lin and Fast-Lip that are able to
certify non-trivial lower bounds of minimum distortions, by bounding the ReLU
units with appropriate linear functions Fast-Lin, or by bounding the local
Lipschitz constant Fast-Lip. Experiments show that (1) our proposed methods
deliver bounds close to (the gap is 2-3X) exact minimum distortion found by
Reluplex in small MNIST networks while our algorithms are more than 10,000
times faster; (2) our methods deliver similar quality of bounds (the gap is
within 35% and usually around 10%; sometimes our bounds are even better) for
larger networks compared to the methods based on solving linear programming
problems but our algorithms are 33-14,000 times faster; (3) our method is
capable of solving large MNIST and CIFAR networks up to 7 layers with more than
10,000 neurons within tens of seconds on a single CPU core.
&lt;/p&gt;
&lt;p&gt;In addition, we show that, in fact, there is no polynomial time algorithm
that can approximately find the minimum $\ell_1$ adversarial distortion of a
ReLU network with a $0.99\ln n$ approximation ratio unless
$\mathsf{NP}$=$\mathsf{P}$, where $n$ is the number of neurons in the network.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Weng_T/0/1/0/all/0/1&quot;&gt;Tsui-Wei Weng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhang_H/0/1/0/all/0/1&quot;&gt;Huan Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chen_H/0/1/0/all/0/1&quot;&gt;Hongge Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Song_Z/0/1/0/all/0/1&quot;&gt;Zhao Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hsieh_C/0/1/0/all/0/1&quot;&gt;Cho-Jui Hsieh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Boning_D/0/1/0/all/0/1&quot;&gt;Duane Boning&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Dhillon_I/0/1/0/all/0/1&quot;&gt;Inderjit S. Dhillon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Daniel_L/0/1/0/all/0/1&quot;&gt;Luca Daniel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.01852">
<title>Selective Inference for $L_2$-Boosting. (arXiv:1805.01852v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1805.01852</link>
<description rdf:parseType="Literal">&lt;p&gt;We review several recently proposed post-selection inference frameworks and
assess their transferability to the component-wise functional gradient descent
algorithm (CFGD) under normality assumption for model errors, also known as
$L_2$-Boosting. The CFGD is one of the most versatile toolboxes to analyze data
as it scales well to high-dimensional data sets, allows for a very flexible
definition of additive regression models and incorporates inbuilt variable
selection. Due to the iterative nature, which can repeatedly select the same
component to update, a statistical inference framework for component-wise
boosting algorithms requires adaptations of existing approaches; we propose
tests and confidence intervals for linear, grouped and penalized additive model
components selected by $L_2$-Boosting. We apply our framework to the prostate
cancer data set and investigate the properties of our concepts in simulation
studies.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rugamer_D/0/1/0/all/0/1&quot;&gt;David R&amp;#xfc;gamer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Greven_S/0/1/0/all/0/1&quot;&gt;Sonja Greven&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.04591">
<title>Robust and Scalable Models of Microbiome Dynamics. (arXiv:1805.04591v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1805.04591</link>
<description rdf:parseType="Literal">&lt;p&gt;Microbes are everywhere, including in and on our bodies, and have been shown
to play key roles in a variety of prevalent human diseases. Consequently, there
has been intense interest in the design of bacteriotherapies or &quot;bugs as
drugs,&quot; which are communities of bacteria administered to patients for specific
therapeutic applications. Central to the design of such therapeutics is an
understanding of the causal microbial interaction network and the population
dynamics of the organisms. In this work we present a Bayesian nonparametric
model and associated efficient inference algorithm that addresses the key
conceptual and practical challenges of learning microbial dynamics from time
series microbe abundance data. These challenges include high-dimensional (300+
strains of bacteria in the gut) but temporally sparse and non-uniformly sampled
data; high measurement noise; and, nonlinear and physically non-negative
dynamics. Our contributions include a new type of dynamical systems model for
microbial dynamics based on what we term interaction modules, or learned
clusters of latent variables with redundant interaction structure (reducing the
expected number of interaction coefficients from $O(n^2)$ to $O((\log n)^2)$);
a fully Bayesian formulation of the stochastic dynamical systems model that
propagates measurement and latent state uncertainty throughout the model; and
introduction of a temporally varying auxiliary variable technique to enable
efficient inference by relaxing the hard non-negativity constraint on states.
We apply our method to simulated and real data, and demonstrate the utility of
our technique for system identification from limited data and gaining new
biological insights into bacteriotherapy design.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gibson_T/0/1/0/all/0/1&quot;&gt;Travis E. Gibson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gerber_G/0/1/0/all/0/1&quot;&gt;Georg K. Gerber&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02402">
<title>Localized Structured Prediction. (arXiv:1806.02402v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1806.02402</link>
<description rdf:parseType="Literal">&lt;p&gt;Key to structured prediction is exploiting the problem structure to simplify
the learning process. A major challenge arises when data exhibit a local
structure (e.g., are made by &quot;parts&quot;) that can be leveraged to better
approximate the relation between (parts of) the input and (parts of) the
output. Recent literature on signal processing, and in particular computer
vision, has shown that capturing these aspects is indeed essential to achieve
state-of-the-art performance. While such algorithms are typically derived on a
case-by-case basis, in this work we propose the first theoretical framework to
deal with part-based data from a general perspective. We derive a novel
approach to deal with these problems and study its generalization properties
within the setting of statistical learning theory. Our analysis is novel in
that it explicitly quantifies the benefits of leveraging the part-based
structure of the problem with respect to the learning rates of the proposed
estimator.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ciliberto_C/0/1/0/all/0/1&quot;&gt;Carlo Ciliberto&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bach_F/0/1/0/all/0/1&quot;&gt;Francis Bach&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rudi_A/0/1/0/all/0/1&quot;&gt;Alessandro Rudi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02455">
<title>MEBN-RM: A Mapping between Multi-Entity Bayesian Network and Relational Model. (arXiv:1806.02455v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1806.02455</link>
<description rdf:parseType="Literal">&lt;p&gt;Multi-Entity Bayesian Network (MEBN) is a knowledge representation formalism
combining Bayesian Networks (BN) with First-Order Logic (FOL). MEBN has
sufficient expressive power for general-purpose knowledge representation and
reasoning. Developing a MEBN model to support a given application is a
challenge, requiring definition of entities, relationships, random variables,
conditional dependence relationships, and probability distributions. When
available, data can be invaluable both to improve performance and to streamline
development. By far the most common format for available data is the relational
database (RDB). Relational databases describe and organize data according to
the Relational Model (RM). Developing a MEBN model from data stored in an RDB
therefore requires mapping between the two formalisms. This paper presents
MEBN-RM, a set of mapping rules between key elements of MEBN and RM. We
identify links between the two languages (RM and MEBN) and define four levels
of mapping from elements of RM to elements of MEBN. These definitions are
implemented in the MEBN-RM algorithm, which converts a relational schema in RM
to a partial MEBN model. Through this research, the software has been released
as a MEBN-RM open-source software tool. The method is illustrated through two
example use cases using MEBN-RM to develop MEBN models: a Critical
Infrastructure Defense System and a Smart Manufacturing System.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Park_C/0/1/0/all/0/1&quot;&gt;Cheol Young Park&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Laskey_K/0/1/0/all/0/1&quot;&gt;Kathryn Blackmond Laskey&lt;/a&gt;</dc:creator>
</item></rdf:RDF>