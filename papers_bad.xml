<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Boring papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Bad Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-05-29T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11201"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11232"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11371"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11535"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1307.2559"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.01423"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.10328"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.01756"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11088"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11122"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11166"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11170"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11324"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11375"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11447"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11452"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11548"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11555"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11592"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11593"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1705.10899"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.06451"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10123"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11155"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11182"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11183"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11191"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11204"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11221"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11243"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11259"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11264"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11284"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11328"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11394"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11405"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11450"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11454"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11494"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11534"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11542"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11571"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11572"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11576"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11596"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11597"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1610.06447"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1612.05846"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1705.07019"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1705.07819"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1708.01384"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.06970"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.04725"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.05610"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.00287"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.01737"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.02922"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.08591"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.02086"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.03836"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.09597"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.06619"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08045"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10014"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10988"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1805.11201">
<title>A parallel implementation of the covariance matrix adaptation evolution strategy. (arXiv:1805.11201v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1805.11201</link>
<description rdf:parseType="Literal">&lt;p&gt;In many practical optimization problems, the derivatives of the functions to
be optimized are unavailable or unreliable. Such optimization problems are
solved using derivative-free optimization techniques. One of the
state-of-the-art techniques for derivative-free optimization is the covariance
matrix adaptation evolution strategy (CMA-ES) algorithm. However, the
complexity of CMA-ES algorithm makes it undesirable for tasks where fast
optimization is needed. To reduce the execution time of CMA-ES, a parallel
implementation is proposed, and its performance is analyzed using the benchmark
problems in PythOPT optimization environment.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khan_N/0/1/0/all/0/1&quot;&gt;Najeeb Khan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11232">
<title>Currency exchange prediction using machine learning, genetic algorithms and technical analysis. (arXiv:1805.11232v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.11232</link>
<description rdf:parseType="Literal">&lt;p&gt;Technical analysis is used to discover investment opportunities. To test this
hypothesis we propose an hybrid system using machine learning techniques
together with genetic algorithms. Using technical analysis there are more ways
to represent a currency exchange time series than the ones it is possible to
test computationally, i.e., it is unfeasible to search the whole input feature
space thus a genetic algorithm is an alternative. In this work, an architecture
for automatic feature selection is proposed to optimize the cross validated
performance estimation of a Naive Bayes model using a genetic algorithm. The
proposed architecture improves the return on investment of the unoptimized
system from 0,43% to 10,29% in the validation set. The features selected and
the model decision boundary are visualized using the algorithm t-Distributed
Stochastic Neighbor embedding.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abreu_G/0/1/0/all/0/1&quot;&gt;Gon&amp;#xe7;alo Abreu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Neves_R/0/1/0/all/0/1&quot;&gt;Rui Neves&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Horta_N/0/1/0/all/0/1&quot;&gt;Nuno Horta&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11371">
<title>How to Blend a Robot within a Group of Zebrafish: Achieving Social Acceptance through Real-time Calibration of a Multi-level Behavioural Model. (arXiv:1805.11371v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1805.11371</link>
<description rdf:parseType="Literal">&lt;p&gt;We have previously shown how to socially integrate a fish robot into a group
of zebrafish thanks to biomimetic behavioural models. The models have to be
calibrated on experimental data to present correct behavioural features. This
calibration is essential to enhance the social integration of the robot into
the group. When calibrated, the behavioural model of fish behaviour is
implemented to drive a robot with closed-loop control of social interactions
into a group of zebrafish. This approach can be useful to form mixed-groups,
and study animal individual and collective behaviour by using biomimetic
autonomous robots capable of responding to the animals in long-standing
experiments. Here, we show a methodology for continuous real-time calibration
and refinement of multi-level behavioural model. The real-time calibration, by
an evolutionary algorithm, is based on simulation of the model to correspond to
the observed fish behaviour in real-time. The calibrated model is updated on
the robot and tested during the experiments. This method allows to cope with
changes of dynamics in fish behaviour. Moreover, each fish presents individual
behavioural differences. Thus, each trial is done with naive fish groups that
display behavioural variability. This real-time calibration methodology can
optimise the robot behaviours during the experiments. Our implementation of
this methodology runs on three different computers that perform individual
tracking, data-analysis, multi-objective evolutionary algorithms, simulation of
the fish robot and adaptation of the robot behavioural models, all in
real-time.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cazenille_L/0/1/0/all/0/1&quot;&gt;Leo Cazenille&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chemtob_Y/0/1/0/all/0/1&quot;&gt;Yohann Chemtob&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bonnet_F/0/1/0/all/0/1&quot;&gt;Frank Bonnet&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gribovskiy_A/0/1/0/all/0/1&quot;&gt;Alexey Gribovskiy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mondada_F/0/1/0/all/0/1&quot;&gt;Francesco Mondada&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bredeche_N/0/1/0/all/0/1&quot;&gt;Nicolas Bredeche&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Halloy_J/0/1/0/all/0/1&quot;&gt;Jose Halloy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11535">
<title>CoupleNet: Paying Attention to Couples with Coupled Attention for Relationship Recommendation. (arXiv:1805.11535v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1805.11535</link>
<description rdf:parseType="Literal">&lt;p&gt;Dating and romantic relationships not only play a huge role in our personal
lives but also collectively influence and shape society. Today, many romantic
partnerships originate from the Internet, signifying the importance of
technology and the web in modern dating. In this paper, we present a text-based
computational approach for estimating the relationship compatibility of two
users on social media. Unlike many previous works that propose reciprocal
recommender systems for online dating websites, we devise a distant supervision
heuristic to obtain real world couples from social platforms such as Twitter.
Our approach, the CoupleNet is an end-to-end deep learning based estimator that
analyzes the social profiles of two users and subsequently performs a
similarity match between the users. Intuitively, our approach performs both
user profiling and match-making within a unified end-to-end framework.
CoupleNet utilizes hierarchical recurrent neural models for learning
representations of user profiles and subsequently coupled attention mechanisms
to fuse information aggregated from two users. To the best of our knowledge,
our approach is the first data-driven deep learning approach for our novel
relationship recommendation problem. We benchmark our CoupleNet against several
machine learning and deep learning baselines. Experimental results show that
our approach outperforms all approaches significantly in terms of precision.
Qualitative analysis shows that our model is capable of also producing
explainable results to users.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tay_Y/0/1/0/all/0/1&quot;&gt;Yi Tay&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luu_A/0/1/0/all/0/1&quot;&gt;Anh Tuan Luu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hui_S/0/1/0/all/0/1&quot;&gt;Siu Cheung Hui&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1307.2559">
<title>General Drift Analysis with Tail Bounds. (arXiv:1307.2559v4 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1307.2559</link>
<description rdf:parseType="Literal">&lt;p&gt;Drift analysis is one of the state-of-the-art techniques for the runtime
analysis of randomized search heuristics (RSHs) such as evolutionary algorithms
(EAs), simulated annealing etc. The vast majority of existing drift theorems
yield bounds on the expected value of the hitting time for a target state,
e.g., the set of optimal solutions, without making additional statements on the
distribution of this time. We address this lack by providing a general drift
theorem that includes bounds on the upper and lower tail of the hitting time
distribution. The new tail bounds are applied to prove very precise
sharp-concentration results on the running time of a simple EA on standard
benchmark problems, including the class of general linear functions.
Surprisingly, the probability of deviating by an $r$-factor in lower order
terms of the expected time decreases exponentially with $r$ on all these
problems. The usefulness of the theorem outside the theory of RSHs is
demonstrated by deriving tail bounds on the number of cycles in random
permutations. All these results handle a position-dependent (variable) drift
that was not covered by previous drift theorems with tail bounds. Moreover, our
theorem can be specialized into virtually all existing drift theorems with
drift towards the target from the literature. Finally, user-friendly
specializations of the general drift theorem are given.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lehre_P/0/1/0/all/0/1&quot;&gt;Per Kristian Lehre&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Witt_C/0/1/0/all/0/1&quot;&gt;Carsten Witt&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.01423">
<title>Overcoming catastrophic forgetting with hard attention to the task. (arXiv:1801.01423v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1801.01423</link>
<description rdf:parseType="Literal">&lt;p&gt;Catastrophic forgetting occurs when a neural network loses the information
learned in a previous task after training on subsequent tasks. This problem
remains a hurdle for artificial intelligence systems with sequential learning
capabilities. In this paper, we propose a task-based hard attention mechanism
that preserves previous tasks&apos; information without affecting the current task&apos;s
learning. A hard attention mask is learned concurrently to every task, through
stochastic gradient descent, and previous masks are exploited to condition such
learning. We show that the proposed mechanism is effective for reducing
catastrophic forgetting, cutting current rates by 45 to 80%. We also show that
it is robust to different hyperparameter choices, and that it offers a number
of monitoring capabilities. The approach features the possibility to control
both the stability and compactness of the learned knowledge, which we believe
makes it also attractive for online learning or network compression
applications.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Serra_J/0/1/0/all/0/1&quot;&gt;Joan Serr&amp;#xe0;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Suris_D/0/1/0/all/0/1&quot;&gt;D&amp;#xed;dac Sur&amp;#xed;s&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Miron_M/0/1/0/all/0/1&quot;&gt;Marius Miron&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Karatzoglou_A/0/1/0/all/0/1&quot;&gt;Alexandros Karatzoglou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.10328">
<title>Neural Inverse Rendering for General Reflectance Photometric Stereo. (arXiv:1802.10328v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1802.10328</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a novel convolutional neural network architecture for photometric
stereo (Woodham, 1980), a problem of recovering 3D object surface normals from
multiple images observed under varying illuminations. Despite its long history
in computer vision, the problem still shows fundamental challenges for surfaces
with unknown general reflectance properties (BRDFs). Leveraging deep neural
networks to learn complicated reflectance models is promising, but studies in
this direction are very limited due to difficulties in acquiring accurate
ground truth for training and also in designing networks invariant to
permutation of input images. In order to address these challenges, we propose a
physics based unsupervised learning framework where surface normals and BRDFs
are predicted by the network and fed into the rendering equation to synthesize
observed images. The network weights are optimized during testing by minimizing
reconstruction loss between observed and synthesized images. Thus, our learning
process does not require ground truth normals or even pre-training on external
images. Our method is shown to achieve the state-of-the-art performance on a
challenging real-world scene benchmark.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Taniai_T/0/1/0/all/0/1&quot;&gt;Tatsunori Taniai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Maehara_T/0/1/0/all/0/1&quot;&gt;Takanori Maehara&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.01756">
<title>The Kanerva Machine: A Generative Distributed Memory. (arXiv:1804.01756v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1804.01756</link>
<description rdf:parseType="Literal">&lt;p&gt;We present an end-to-end trained memory system that quickly adapts to new
data and generates samples like them. Inspired by Kanerva&apos;s sparse distributed
memory, it has a robust distributed reading and writing mechanism. The memory
is analytically tractable, which enables optimal on-line compression via a
Bayesian update-rule. We formulate it as a hierarchical conditional generative
model, where memory provides a rich data-dependent prior distribution.
Consequently, the top-down memory and bottom-up perception are combined to
produce the code representing an observation. Empirically, we demonstrate that
the adaptive memory significantly improves generative models trained on both
the Omniglot and CIFAR datasets. Compared with the Differentiable Neural
Computer (DNC) and its variants, our memory model has greater capacity and is
significantly easier to train.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wu_Y/0/1/0/all/0/1&quot;&gt;Yan Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wayne_G/0/1/0/all/0/1&quot;&gt;Greg Wayne&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Graves_A/0/1/0/all/0/1&quot;&gt;Alex Graves&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lillicrap_T/0/1/0/all/0/1&quot;&gt;Timothy Lillicrap&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11088">
<title>Deep Reinforcement Learning in Ice Hockey for Context-Aware Player Evaluation. (arXiv:1805.11088v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.11088</link>
<description rdf:parseType="Literal">&lt;p&gt;A variety of machine learning models have been proposed to assess the
performance of players in professional sports. However, they have only a
limited ability to model how player performance depends on the game context.
This paper proposes a new approach to capturing game context: we apply Deep
Reinforcement Learning (DRL) to learn an action-value Q function from 3M
play-by-play events in the National Hockey League (NHL). The neural network
representation integrates both continuous context signals and game history,
using a possession-based LSTM. The learned Q-function is used to value players&apos;
actions under different game contexts. To assess a player&apos;s overall
performance, we introduce a novel Game Impact Metric (GIM) that aggregates the
values of the player&apos;s actions. Empirical Evaluation shows GIM is consistent
throughout a play season, and correlates highly with standard success measures
and future salary.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1&quot;&gt;Guiliang Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schulte_O/0/1/0/all/0/1&quot;&gt;Oliver Schulte&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11122">
<title>Differentiable Particle Filters: End-to-End Learning with Algorithmic Priors. (arXiv:1805.11122v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.11122</link>
<description rdf:parseType="Literal">&lt;p&gt;We present differentiable particle filters (DPFs): a differentiable
implementation of the particle filter algorithm with learnable motion and
measurement models. Since DPFs are end-to-end differentiable, we can
efficiently train their models by optimizing end-to-end state estimation
performance, rather than proxy objectives such as model accuracy. DPFs encode
the structure of recursive state estimation with prediction and measurement
update that operate on a probability distribution over states. This structure
represents an algorithmic prior that improves learning performance in state
estimation problems while enabling explainability of the learned model. Our
experiments on simulated and real data show substantial benefits from end-to-
end learning with algorithmic priors, e.g. reducing error rates by ~80%. Our
experiments also show that, unlike long short-term memory networks, DPFs learn
localization in a policy-agnostic way and thus greatly improve generalization.
Source code is available at
https://github.com/tu-rbo/differentiable-particle-filters.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jonschkowski_R/0/1/0/all/0/1&quot;&gt;Rico Jonschkowski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rastogi_D/0/1/0/all/0/1&quot;&gt;Divyam Rastogi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brock_O/0/1/0/all/0/1&quot;&gt;Oliver Brock&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11166">
<title>A visual approach for age and gender identification on Twitter. (arXiv:1805.11166v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1805.11166</link>
<description rdf:parseType="Literal">&lt;p&gt;The goal of Author Profiling (AP) is to identify demographic aspects (e.g.,
age, gender) from a given set of authors by analyzing their written texts.
Recently, the AP task has gained interest in many problems related to computer
forensics, psychology, marketing, but specially in those related with social
media exploitation. As known, social media data is shared through a wide range
of modalities (e.g., text, images and audio), representing valuable information
to be exploited for extracting valuable insights from users. Nevertheless, most
of the current work in AP using social media data has been devoted to analyze
textual information only, and there are very few works that have started
exploring the gender identification using visual information. Contrastingly,
this paper focuses in exploiting the visual modality to perform both age and
gender identification in social media, specifically in Twitter. Our goal is to
evaluate the pertinence of using visual information in solving the AP task.
Accordingly, we have extended the Twitter corpus from PAN 2014, incorporating
posted images from all the users, making a distinction between tweeted and
retweeted images. Performed experiments provide interesting evidence on the
usefulness of visual information in comparison with traditional textual
representations for the AP task.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alvarez_Carmona_M/0/1/0/all/0/1&quot;&gt;Miguel A. Alvarez-Carmona&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pellegrin_L/0/1/0/all/0/1&quot;&gt;Luis Pellegrin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Montes_y_Gomez_M/0/1/0/all/0/1&quot;&gt;Manuel Montes-y-G&amp;#xf3;mez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sanchez_Vega_F/0/1/0/all/0/1&quot;&gt;Fernando S&amp;#xe1;nchez-Vega&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Escalante_H/0/1/0/all/0/1&quot;&gt;Hugo Jair Escalante&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lopez_Monroy_A/0/1/0/all/0/1&quot;&gt;A. Pastor L&amp;#xf3;pez-Monroy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Villasenor_Pineda_L/0/1/0/all/0/1&quot;&gt;Luis Villase&amp;#xf1;or-Pineda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Villatoro_Tello_E/0/1/0/all/0/1&quot;&gt;Esa&amp;#xfa; Villatoro-Tello&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11170">
<title>Strongly polynomial efficient approximation scheme for segmentation. (arXiv:1805.11170v1 [cs.DS])</title>
<link>http://arxiv.org/abs/1805.11170</link>
<description rdf:parseType="Literal">&lt;p&gt;Partitioning a sequence of length $n$ into $k$ coherent segments is one of
the classic optimization problems. As long as the optimization criterion is
additive, the problem can be solved exactly in $O(n^2k)$ time using a classic
dynamic program. Due to the quadratic term, computing the exact segmentation
may be too expensive for long sequences, which has led to development of
approximate solutions. We consider an existing estimation scheme that computes
$(1 + \epsilon)$ approximation in polylogarithmic time. We augment this
algorithm, making it strongly polynomial. We do this by first solving a
slightly different segmentation problem, where the quality of the segmentation
is the maximum penalty of an individual segment. By using this solution to
initialize the estimation scheme, we are able to obtain a strongly polynomial
algorithm. In addition, we consider a cumulative version of the problem, where
we are asked to discover the optimal segmentation for each prefix of the input
sequence. We propose a strongly polynomial algorithm that yields $(1 +
\epsilon)$ approximation in $O(nk^2 / \epsilon)$ time. Finally, we consider a
cumulative version of the maximum segmentation, and show that this can be
solved in $O(nk \log k)$ time.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tatti_N/0/1/0/all/0/1&quot;&gt;Nikolaj Tatti&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11324">
<title>Bayesian Inference with Anchored Ensembles of Neural Networks, and Application to Reinforcement Learning. (arXiv:1805.11324v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.11324</link>
<description rdf:parseType="Literal">&lt;p&gt;The use of ensembles of neural networks (NNs) for the quantification of
predictive uncertainty is widespread. However, the current justification is
intuitive rather than analytical. This work proposes one minor modification to
the normal ensembling methodology, which we prove allows the ensemble to
perform Bayesian inference, hence converging to the corresponding Gaussian
Process as both the total number of NNs, and the size of each, tend to
infinity.
&lt;/p&gt;
&lt;p&gt;This working paper provides early-stage results in a reinforcement learning
setting, analysing the practicality of the technique for an ensemble of small,
finite number. Using the uncertainty estimates they produce to govern the
exploration-exploitation process results in steadier, more stable learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pearce_T/0/1/0/all/0/1&quot;&gt;Tim Pearce&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Anastassacos_N/0/1/0/all/0/1&quot;&gt;Nicolas Anastassacos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zaki_M/0/1/0/all/0/1&quot;&gt;Mohamed Zaki&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Neely_A/0/1/0/all/0/1&quot;&gt;Andy Neely&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11375">
<title>Automating Personnel Rostering by Learning Constraints Using Tensors. (arXiv:1805.11375v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1805.11375</link>
<description rdf:parseType="Literal">&lt;p&gt;Many problems in operations research require that constraints be specified in
the model. Determining the right constraints is a hard and laborsome task. We
propose an approach to automate this process using artificial intelligence and
machine learning principles. So far there has been only little work on learning
constraints within the operations research community. We focus on personnel
rostering and scheduling problems in which there are often past schedules
available and show that it is possible to automatically learn constraints from
such examples. To realize this, we adapted some techniques from the constraint
programming community and we have extended them in order to cope with
multidimensional examples. The method uses a tensor representation of the
example, which helps in capturing the dimensionality as well as the structure
of the example, and applies tensor operations to find the constraints that are
satisfied by the example. To evaluate the proposed algorithm, we used
constraints from the Nurse Rostering Competition and generated solutions that
satisfy these constraints; these solutions were then used as examples to learn
constraints. Experiments demonstrate that the proposed algorithm is capable of
producing human readable constraints that capture the underlying
characteristics of the examples.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kumar_M/0/1/0/all/0/1&quot;&gt;Mohit Kumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Teso_S/0/1/0/all/0/1&quot;&gt;Stefano Teso&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Raedt_L/0/1/0/all/0/1&quot;&gt;Luc De Raedt&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11447">
<title>Virtuously Safe Reinforcement Learning. (arXiv:1805.11447v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.11447</link>
<description rdf:parseType="Literal">&lt;p&gt;We show that when a third party, the adversary, steps into the two-party
setting (agent and operator) of safely interruptible reinforcement learning, a
trade-off has to be made between the probability of following the optimal
policy in the limit, and the probability of escaping a dangerous situation
created by the adversary. So far, the work on safely interruptible agents has
assumed a perfect perception of the agent about its environment (no adversary),
and therefore implicitly set the second probability to zero, by explicitly
seeking a value of one for the first probability. We show that (1) agents can
be made both interruptible and adversary-resilient, and (2) the
interruptibility can be made safe in the sense that the agent itself will not
seek to avoid it. We also solve the problem that arises when the agent does not
go completely greedy, i.e. issues with safe exploration in the limit.
Resilience to perturbed perception, safe exploration in the limit, and safe
interruptibility are the three pillars of what we call \emph{virtuously safe
reinforcement learning}.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aslund_H/0/1/0/all/0/1&quot;&gt;Henrik Aslund&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mhamdi_E/0/1/0/all/0/1&quot;&gt;El Mahdi El Mhamdi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guerraoui_R/0/1/0/all/0/1&quot;&gt;Rachid Guerraoui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Maurer_A/0/1/0/all/0/1&quot;&gt;Alexandre Maurer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11452">
<title>An Analytic Solution to the Inverse Ising Problem in the Tree-reweighted Approximation. (arXiv:1805.11452v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.11452</link>
<description rdf:parseType="Literal">&lt;p&gt;Many iterative and non-iterative methods have been developed for inverse
problems associated with Ising models. Aiming to derive an accurate
non-iterative method for the inverse problems, we employ the tree-reweighted
approximation. Using the tree-reweighted approximation, we can optimize the
rigorous lower bound of the objective function. By solving the moment-matching
and self-consistency conditions analytically, we can derive the interaction
matrix as a function of the given data statistics. With this solution, we can
obtain the optimal interaction matrix without iterative computation. To
evaluate the accuracy of the proposed inverse formula, we compared our results
to those obtained by existing inverse formulae derived with other
approximations. In an experiment to reconstruct the interaction matrix, we
found that the proposed formula returns the best estimates in
strongly-attractive regions for various graph structures. We also performed an
experiment using real-world biological data. When applied to finding the
connectivity of neurons from spike train data, the proposed formula gave the
closest result to that obtained by a gradient ascent algorithm, which typically
requires thousands of iterations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sano_T/0/1/0/all/0/1&quot;&gt;Takashi Sano&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11548">
<title>The Actor Search Tree Critic (ASTC) for Off-Policy POMDP Learning in Medical Decision Making. (arXiv:1805.11548v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1805.11548</link>
<description rdf:parseType="Literal">&lt;p&gt;Off-policy reinforcement learning enables near-optimal policy from suboptimal
experience, thereby provisions opportunity for artificial intelligence
applications in healthcare. Previous works have mainly framed patient-clinician
interactions as Markov decision processes, while true physiological states are
not necessarily fully observable from clinical data. We capture this situation
with partially observable Markov decision process, in which an agent optimises
its actions in a belief represented as a distribution of patient states
inferred from individual history trajectories. A Gaussian mixture model is
fitted for the observed data. Moreover, we take into account the fact that
nuance in pharmaceutical dosage could presumably result in significantly
different effect by modelling a continuous policy through a Gaussian
approximator directly in the policy space, i.e. the actor. To address the
challenge of infinite number of possible belief states which renders exact
value iteration intractable, we evaluate and plan for only every encountered
belief, through heuristic search tree by tightly maintaining lower and upper
bounds of the true value of belief. We further resort to function
approximations to update value bounds estimation, i.e. the critic, so that the
tree search can be improved through more compact bounds at the fringe nodes
that will be back-propagated to the root. Both actor and critic parameters are
learned via gradient-based approaches. Our proposed policy trained from real
intensive care unit data is capable of dictating dosing on vasopressors and
intravenous fluids for sepsis patients that lead to the best patient outcomes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1&quot;&gt;Luchen Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Komorowski_M/0/1/0/all/0/1&quot;&gt;Matthieu Komorowski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Faisal_A/0/1/0/all/0/1&quot;&gt;Aldo A. Faisal&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11555">
<title>Optimisation and Illumination of a Real-world Workforce Scheduling and Routing Application via Map-Elites. (arXiv:1805.11555v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1805.11555</link>
<description rdf:parseType="Literal">&lt;p&gt;Workforce Scheduling and Routing Problems (WSRP) are very common in many
practical domains, and usually, have a number of objectives. Illumination
algorithms such as Map-Elites (ME) have recently gained traction in application
to {\em design} problems, in providing multiple diverse solutions as well as
illuminating the solution space in terms of user-defined characteristics, but
typically require significant computational effort to produce the solution
archive. We investigate whether ME can provide an effective approach to solving
WSRP, a {\em repetitive} problem in which solutions have to be produced quickly
and often. The goals of the paper are two-fold. The first is to evaluate
whether ME can provide solutions of competitive quality to an Evolutionary
Algorithm (EA) in terms of a single objective function, and the second to
examine its ability to provide a repertoire of solutions that maximise user
choice. We find that very small computational budgets favour the EA in terms of
quality, but ME outperforms the EA at larger budgets, provides a more diverse
array of solutions, and lends insight to the end-user.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Urquhart_N/0/1/0/all/0/1&quot;&gt;Neil Urquhart&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hart_E/0/1/0/all/0/1&quot;&gt;Emma Hart&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11592">
<title>Playing hard exploration games by watching YouTube. (arXiv:1805.11592v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.11592</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep reinforcement learning methods traditionally struggle with tasks where
environment rewards are particularly sparse. One successful method of guiding
exploration in these domains is to imitate trajectories provided by a human
demonstrator. However, these demonstrations are typically collected under
artificial conditions, i.e. with access to the agent&apos;s exact environment setup
and the demonstrator&apos;s action and reward trajectories. Here we propose a
two-stage method that overcomes these limitations by relying on noisy,
unaligned footage without access to such data. First, we learn to map unaligned
videos from multiple sources to a common representation using self-supervised
objectives constructed over both time and modality (i.e. vision and sound).
Second, we embed a single YouTube video in this representation to construct a
reward function that encourages an agent to imitate human gameplay. This method
of one-shot imitation allows our agent to convincingly exceed human-level
performance on the infamously hard exploration games Montezuma&apos;s Revenge,
Pitfall! and Private Eye for the first time, even if the agent is not presented
with any environment rewards.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aytar_Y/0/1/0/all/0/1&quot;&gt;Yusuf Aytar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pfaff_T/0/1/0/all/0/1&quot;&gt;Tobias Pfaff&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Budden_D/0/1/0/all/0/1&quot;&gt;David Budden&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Paine_T/0/1/0/all/0/1&quot;&gt;Tom Le Paine&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Ziyu Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Freitas_N/0/1/0/all/0/1&quot;&gt;Nando de Freitas&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11593">
<title>Observe and Look Further: Achieving Consistent Performance on Atari. (arXiv:1805.11593v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.11593</link>
<description rdf:parseType="Literal">&lt;p&gt;Despite significant advances in the field of deep Reinforcement Learning
(RL), today&apos;s algorithms still fail to learn human-level policies consistently
over a set of diverse tasks such as Atari 2600 games. We identify three key
challenges that any algorithm needs to master in order to perform well on all
games: processing diverse reward distributions, reasoning over long time
horizons, and exploring efficiently. In this paper, we propose an algorithm
that addresses each of these challenges and is able to learn human-level
policies on nearly all Atari games. A new transformed Bellman operator allows
our algorithm to process rewards of varying densities and scales; an auxiliary
temporal consistency loss allows us to train stably using a discount factor of
$\gamma = 0.999$ (instead of $\gamma = 0.99$) extending the effective planning
horizon by an order of magnitude; and we ease the exploration problem by using
human demonstrations that guide the agent towards rewarding states. When tested
on a set of 42 Atari games, our algorithm exceeds the performance of an average
human on 40 games using a common set of hyper parameters. Furthermore, it is
the first deep RL algorithm to solve the first level of Montezuma&apos;s Revenge.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pohlen_T/0/1/0/all/0/1&quot;&gt;Tobias Pohlen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Piot_B/0/1/0/all/0/1&quot;&gt;Bilal Piot&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hester_T/0/1/0/all/0/1&quot;&gt;Todd Hester&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Azar_M/0/1/0/all/0/1&quot;&gt;Mohammad Gheshlaghi Azar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Horgan_D/0/1/0/all/0/1&quot;&gt;Dan Horgan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Budden_D/0/1/0/all/0/1&quot;&gt;David Budden&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barth_Maron_G/0/1/0/all/0/1&quot;&gt;Gabriel Barth-Maron&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hasselt_H/0/1/0/all/0/1&quot;&gt;Hado van Hasselt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Quan_J/0/1/0/all/0/1&quot;&gt;John Quan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vecerik_M/0/1/0/all/0/1&quot;&gt;Mel Ve&amp;#x10d;er&amp;#xed;k&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hessel_M/0/1/0/all/0/1&quot;&gt;Matteo Hessel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Munos_R/0/1/0/all/0/1&quot;&gt;R&amp;#xe9;mi Munos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pietquin_O/0/1/0/all/0/1&quot;&gt;Olivier Pietquin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1705.10899">
<title>Propositional Knowledge Representation and Reasoning in Restricted Boltzmann Machines. (arXiv:1705.10899v3 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1705.10899</link>
<description rdf:parseType="Literal">&lt;p&gt;While knowledge representation and reasoning are considered the keys for
human-level artificial intelligence, connectionist networks have been shown
successful in a broad range of applications due to their capacity for robust
learning and flexible inference under uncertainty. The idea of representing
symbolic knowledge in connectionist networks has been well-received and
attracted much attention from research community as this can establish a
foundation for integration of scalable learning and sound reasoning. In
previous work, there exist a number of approaches that map logical inference
rules with feed-forward propagation of artificial neural networks (ANN).
However, the discriminative structure of an ANN requires the separation of
input/output variables which makes it difficult for general reasoning where any
variables should be inferable. Other approaches address this issue by employing
generative models such as symmetric connectionist networks, however, they are
difficult and convoluted. In this paper we propose a novel method to represent
propositional formulas in restricted Boltzmann machines which is less complex,
especially in the cases of logical implications and Horn clauses. An
integration system is then developed and evaluated in real datasets which shows
promising results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tran_S/0/1/0/all/0/1&quot;&gt;Son N. Tran&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.06451">
<title>Multi-Reward Reinforced Summarization with Saliency and Entailment. (arXiv:1804.06451v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1804.06451</link>
<description rdf:parseType="Literal">&lt;p&gt;Abstractive text summarization is the task of compressing and rewriting a
long document into a short summary while maintaining saliency, directed logical
entailment, and non-redundancy. In this work, we address these three important
aspects of a good summary via a reinforcement learning approach with two novel
reward functions: ROUGESal and Entail, on top of a coverage-based baseline. The
ROUGESal reward modifies the ROUGE metric by up-weighting the salient
phrases/words detected via a keyphrase classifier. The Entail reward gives high
(length-normalized) scores to logically-entailed summaries using an entailment
classifier. Further, we show superior performance improvement when these
rewards are combined with traditional metric (ROUGE) based rewards, via our
novel and effective multi-reward approach of optimizing multiple rewards
simultaneously in alternate mini-batches. Our method achieves the new
state-of-the-art results (including human evaluation) on the CNN/Daily Mail
dataset as well as strong improvements in a test-only transfer setup on
DUC-2002.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pasunuru_R/0/1/0/all/0/1&quot;&gt;Ramakanth Pasunuru&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bansal_M/0/1/0/all/0/1&quot;&gt;Mohit Bansal&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.10123">
<title>TADAM: Task dependent adaptive metric for improved few-shot learning. (arXiv:1805.10123v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.10123</link>
<description rdf:parseType="Literal">&lt;p&gt;Few-shot learning has become essential for producing models that generalize
from few examples. In this work, we identify that metric scaling and metric
task conditioning are important to improve the performance of few-shot
algorithms. Our analysis reveals that simple metric scaling completely changes
the nature of few-shot algorithm parameter updates. Metric scaling provides
improvements up to 14% in accuracy for certain metrics on the mini-Imagenet
5-way 5-shot classification task. We further propose a simple and effective way
of conditioning a learner on the task sample set, resulting in learning a
task-dependent metric space. Moreover, we propose and empirically test a
practical end-to-end optimization procedure based on auxiliary task co-training
to learn a task-dependent metric space. The resulting few-shot learning model
based on the task-dependent scaled metric achieves state of the art on
mini-Imagenet. We confirm these results on another few-shot dataset that we
introduce in this paper based on CIFAR100.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oreshkin_B/0/1/0/all/0/1&quot;&gt;Boris N. Oreshkin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rodriguez_P/0/1/0/all/0/1&quot;&gt;Pau Rodriguez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lacoste_A/0/1/0/all/0/1&quot;&gt;Alexandre Lacoste&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11155">
<title>Unsupervised Learning of Artistic Styles with Archetypal Style Analysis. (arXiv:1805.11155v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.11155</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we introduce an unsupervised learning approach to
automatically discover, summarize, and manipulate artistic styles from large
collections of paintings. Our method is based on archetypal analysis, which is
an unsupervised learning technique akin to sparse coding with a geometric
interpretation. When applied to deep image representations from a collection of
artworks, it learns a dictionary of archetypal styles, which can be easily
visualized. After training the model, the style of a new image, which is
characterized by local statistics of deep visual features, is approximated by a
sparse convex combination of archetypes. This enables us to interpret which
archetypal styles are present in the input image, and in which proportion.
Finally, our approach allows us to manipulate the coefficients of the latent
archetypal decomposition, and achieve various special effects such as style
enhancement, transfer, and interpolation between multiple archetypes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wynen_D/0/1/0/all/0/1&quot;&gt;Daan Wynen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Schmid_C/0/1/0/all/0/1&quot;&gt;Cordelia Schmid&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mairal_J/0/1/0/all/0/1&quot;&gt;Julien Mairal&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11182">
<title>GESF: A Universal Discriminative Mapping Mechanism for Graph Representation Learning. (arXiv:1805.11182v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.11182</link>
<description rdf:parseType="Literal">&lt;p&gt;Graph embedding is a central problem in social network analysis and many
other applications, aiming to learn the vector representation for each node.
While most existing approaches need to specify the neighborhood and the
dependence form to the neighborhood, which may significantly degrades the
flexibility of representation, we propose a novel graph node embedding method
(namely GESF) via the set function technique. Our method can 1) learn an
arbitrary form of representation function from neighborhood, 2) automatically
decide the significance of neighbors at different distances, and 3) be applied
to heterogeneous graph embedding, which may contain multiple types of nodes.
Theoretical guarantee for the representation capability of our method has been
proved for general homogeneous and heterogeneous graphs and evaluation results
on benchmark data sets show that the proposed GESF outperforms the
state-of-the-art approaches on producing node vectors for classification tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gui_S/0/1/0/all/0/1&quot;&gt;Shupeng Gui&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xiangliang Zhang&lt;/a&gt; (2), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qiu_S/0/1/0/all/0/1&quot;&gt;Shuang Qiu&lt;/a&gt; (3), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_M/0/1/0/all/0/1&quot;&gt;Mingrui Wu&lt;/a&gt; (4), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1&quot;&gt;Jieping Ye&lt;/a&gt; (3), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Ji Liu&lt;/a&gt; (1) ((1) University of Rochester, (2) KAUST, Saudi Arabia, (3) University of Michigan, (4) Alibaba Group)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11183">
<title>Semi-Implicit Variational Inference. (arXiv:1805.11183v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.11183</link>
<description rdf:parseType="Literal">&lt;p&gt;Semi-implicit variational inference (SIVI) is introduced to expand the
commonly used analytic variational distribution family, by mixing the
variational parameter with a flexible distribution. This mixing distribution
can assume any density function, explicit or not, as long as independent random
samples can be generated via reparameterization. Not only does SIVI expand the
variational family to incorporate highly flexible variational distributions,
including implicit ones that have no analytic density functions, but also
sandwiches the evidence lower bound (ELBO) between a lower bound and an upper
bound, and further derives an asymptotically exact surrogate ELBO that is
amenable to optimization via stochastic gradient ascent. With a substantially
expanded variational family and a novel optimization algorithm, SIVI is shown
to closely match the accuracy of MCMC in inferring the posterior in a variety
of Bayesian inference tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yin_M/0/1/0/all/0/1&quot;&gt;Mingzhang Yin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhou_M/0/1/0/all/0/1&quot;&gt;Mingyuan Zhou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11191">
<title>Learning From Less Data: Diversified Subset Selection and Active Learning in Image Classification Tasks. (arXiv:1805.11191v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1805.11191</link>
<description rdf:parseType="Literal">&lt;p&gt;Supervised machine learning based state-of-the-art computer vision techniques
are in general data hungry and pose the challenges of not having adequate
computing resources and of high costs involved in human labeling efforts.
Training data subset selection and active learning techniques have been
proposed as possible solutions to these challenges respectively. A special
class of subset selection functions naturally model notions of diversity,
coverage and representation and they can be used to eliminate redundancy and
thus lend themselves well for training data subset selection. They can also
help improve the efficiency of active learning in further reducing human
labeling efforts by selecting a subset of the examples obtained using the
conventional uncertainty sampling based techniques. In this work we empirically
demonstrate the effectiveness of two diversity models, namely the
Facility-Location and Disparity-Min models for training-data subset selection
and reducing labeling effort. We do this for a variety of computer vision tasks
including Gender Recognition, Scene Recognition and Object Recognition. Our
results show that subset selection done in the right way can add 2-3% in
accuracy on existing baselines, particularly in the case of less training data.
This allows the training of complex machine learning models (like Convolutional
Neural Networks) with much less training data while incurring minimal
performance loss.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kaushal_V/0/1/0/all/0/1&quot;&gt;Vishal Kaushal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sahoo_A/0/1/0/all/0/1&quot;&gt;Anurag Sahoo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Doctor_K/0/1/0/all/0/1&quot;&gt;Khoshrav Doctor&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Raju_N/0/1/0/all/0/1&quot;&gt;Narasimha Raju&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shetty_S/0/1/0/all/0/1&quot;&gt;Suyash Shetty&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singh_P/0/1/0/all/0/1&quot;&gt;Pankaj Singh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Iyer_R/0/1/0/all/0/1&quot;&gt;Rishabh Iyer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ramakrishnan_G/0/1/0/all/0/1&quot;&gt;Ganesh Ramakrishnan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11204">
<title>Statistical Recurrent Models on Manifold valued Data. (arXiv:1805.11204v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.11204</link>
<description rdf:parseType="Literal">&lt;p&gt;In a number of disciplines, the data (e.g., graphs, manifolds) to be analyzed
are non-Euclidean in nature. Geometric deep learning corresponds to techniques
that generalize deep neural network models to such non-Euclidean spaces.
Several recent papers have shown how convolutional neural networks (CNNs) can
be extended to learn with graph-based data. In this work, we study the setting
where the data (or measurements) are ordered, longitudinal or temporal in
nature and live on a Riemannian manifold -- this setting is common in a variety
of problems in statistical machine learning, vision and medical imaging. We
show how statistical recurrent network models can be defined in such spaces. We
give an efficient algorithm and conduct a rigorous analysis of its statistical
properties. We perform extensive numerical experiments showing competitive
performance with state of the art methods but with far fewer parameters. We
also show applications to a statistical analysis task in brain imaging, a
regime where deep neural network models have only been utilized in limited
ways.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chakraborty_R/0/1/0/all/0/1&quot;&gt;Rudrasis Chakraborty&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1&quot;&gt;Chun-Hao Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhen_X/0/1/0/all/0/1&quot;&gt;Xingjian Zhen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Banerjee_M/0/1/0/all/0/1&quot;&gt;Monami Banerjee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Archer_D/0/1/0/all/0/1&quot;&gt;Derek Archer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vaillancourt_D/0/1/0/all/0/1&quot;&gt;David Vaillancourt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singh_V/0/1/0/all/0/1&quot;&gt;Vikas Singh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vemuri_B/0/1/0/all/0/1&quot;&gt;Baba C. Vemuri&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11221">
<title>MBA: Mini-Batch AUC Optimization. (arXiv:1805.11221v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.11221</link>
<description rdf:parseType="Literal">&lt;p&gt;Area under the receiver operating characteristics curve (AUC) is an important
metric for a wide range of signal processing and machine learning problems, and
scalable methods for optimizing AUC have recently been proposed. However,
handling very large datasets remains an open challenge for this problem. This
paper proposes a novel approach to AUC maximization, based on sampling
mini-batches of positive/negative instance pairs and computing U-statistics to
approximate a global risk minimization problem. The resulting algorithm is
simple, fast, and learning-rate free. We show that the number of samples
required for good performance is independent of the number of pairs available,
which is a quadratic function of the positive and negative instances. Extensive
experiments show the practical utility of the proposed method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gultekin_S/0/1/0/all/0/1&quot;&gt;San Gultekin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sana_A/0/1/0/all/0/1&quot;&gt;Avishek Sana&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ratnaparkhi_A/0/1/0/all/0/1&quot;&gt;Adwait Ratnaparkhi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Paisley_J/0/1/0/all/0/1&quot;&gt;John Paisley&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11243">
<title>On Robust Trimming of Bayesian Network Classifiers. (arXiv:1805.11243v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.11243</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper considers the problem of removing costly features from a Bayesian
network classifier. We want the classifier to be robust to these changes, and
maintain its classification behavior. To this end, we propose a closeness
metric between Bayesian classifiers, called the expected classification
agreement (ECA). Our corresponding trimming algorithm finds an optimal subset
of features and a new classification threshold that maximize the expected
agreement, subject to a budgetary constraint. It utilizes new theoretical
insights to perform branch-and-bound search in the space of feature sets, while
computing bounds on the ECA. Our experiments investigate both the runtime cost
of trimming and its effect on the robustness and accuracy of the final
classifier.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Choi_Y/0/1/0/all/0/1&quot;&gt;YooJung Choi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Broeck_G/0/1/0/all/0/1&quot;&gt;Guy Van den Broeck&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11259">
<title>Statistical mechanical analysis of sparse linear regression as a variable selection problem. (arXiv:1805.11259v1 [cond-mat.dis-nn])</title>
<link>http://arxiv.org/abs/1805.11259</link>
<description rdf:parseType="Literal">&lt;p&gt;An algorithmic limit of compressed sensing or related variable-selection
problems is analytically evaluated when a design matrix is given by an
overcomplete random matrix. The replica method from statistical mechanics is
employed to derive the result. The analysis is conducted through evaluation of
the entropy, an exponential rate of the number of combinations of variables
giving a specific value of fit error to given data which is assumed to be
generated from a linear process using the design matrix. This yields the
typical achievable limit of the fit error when solving a representative
$\ell_0$ problem and includes the presence of unfavourable phase transitions
preventing local search algorithms from reaching the minimum-error
configuration. The associated phase diagrams are presented. A noteworthy
outcome of the phase diagrams is, however, that there exists a wide parameter
region where any phase transition is absent from the high temperature to the
lowest temperature at which the minimum-error configuration or the ground state
is reached. This implies that certain local search algorithms can find the
ground state with moderate computational costs in that region. The theoretical
evaluation of the entropy is confirmed by extensive numerical methods using the
exchange Monte Carlo and the multi-histogram methods. Another numerical test
based on a metaheuristic optimisation algorithm called simulated annealing is
conducted, which well supports the theoretical predictions on the local search
algorithms and we can find the ground state with high probability in polynomial
time with respect to system size.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Obuchi_T/0/1/0/all/0/1&quot;&gt;Tomoyuki Obuchi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Nakanishi_Ohno_Y/0/1/0/all/0/1&quot;&gt;Yoshinori Nakanishi-Ohno&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Okada_M/0/1/0/all/0/1&quot;&gt;Masato Okada&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Kabashima_Y/0/1/0/all/0/1&quot;&gt;Yoshiyuki Kabashima&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11264">
<title>Disentangling by Partitioning: A Representation Learning Framework for Multimodal Sensory Data. (arXiv:1805.11264v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.11264</link>
<description rdf:parseType="Literal">&lt;p&gt;Multimodal sensory data resembles the form of information perceived by humans
for learning, and are easy to obtain in large quantities. Compared to unimodal
data, synchronization of concepts between modalities in such data provides
supervision for disentangling the underlying explanatory factors of each
modality. Previous work leveraging multimodal data has mainly focused on
retaining only the modality-invariant factors while discarding the rest. In
this paper, we present a partitioned variational autoencoder (PVAE) and several
training objectives to learn disentangled representations, which encode not
only the shared factors, but also modality-dependent ones, into separate latent
variables. Specifically, PVAE integrates a variational inference framework and
a multimodal generative model that partitions the explanatory factors and
conditions only on the relevant subset of them for generation. We evaluate our
model on two parallel speech/image datasets, and demonstrate its ability to
learn disentangled representations by qualitatively exploring within-modality
and cross-modality conditional generation with semantics and styles specified
by examples. For quantitative analysis, we evaluate the classification accuracy
of automatically discovered semantic units. Our PVAE can achieve over 99%
accuracy on both modalities.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hsu_W/0/1/0/all/0/1&quot;&gt;Wei-Ning Hsu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Glass_J/0/1/0/all/0/1&quot;&gt;James Glass&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11284">
<title>Wasserstein Variational Inference. (arXiv:1805.11284v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.11284</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper introduces Wasserstein variational inference, a new form of
approximate Bayesian inference based on optimal transport theory. Wasserstein
variational inference uses a new family of divergences that includes both
f-divergences and the Wasserstein distance as special cases. The gradients of
the Wasserstein variational loss are obtained by backpropagating through the
Sinkhorn iterations. This technique results in a very stable likelihood-free
training method that can be used with implicit distributions and probabilistic
programs. Using the Wasserstein variational inference framework, we introduce
several new forms of autoencoders and test their robustness and performance
against existing variational autoencoding techniques.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ambrogioni_L/0/1/0/all/0/1&quot;&gt;Luca Ambrogioni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Guclu_U/0/1/0/all/0/1&quot;&gt;Umut G&amp;#xfc;&amp;#xe7;l&amp;#xfc;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gucluturk_Y/0/1/0/all/0/1&quot;&gt;Ya&amp;#x11f;mur G&amp;#xfc;&amp;#xe7;l&amp;#xfc;t&amp;#xfc;rk&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hinne_M/0/1/0/all/0/1&quot;&gt;Max Hinne&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gerven_M/0/1/0/all/0/1&quot;&gt;Marcel A. J. van Gerven&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Maris_E/0/1/0/all/0/1&quot;&gt;Eric Maris&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11328">
<title>Hamiltonian Variational Auto-Encoder. (arXiv:1805.11328v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.11328</link>
<description rdf:parseType="Literal">&lt;p&gt;Variational Auto-Encoders (VAEs) have become very popular techniques to
perform inference and learning in latent variable models as they allow us to
leverage the rich representational power of neural networks to obtain flexible
approximations of the posterior of latent variables as well as tight evidence
lower bounds (ELBOs). Combined with stochastic variational inference, this
provides a methodology scaling to large datasets. However, for this methodology
to be practically efficient, it is necessary to obtain low-variance unbiased
estimators of the ELBO and its gradients with respect to the parameters of
interest. While the use of Markov chain Monte Carlo (MCMC) techniques such as
Hamiltonian Monte Carlo (HMC) has been previously suggested to achieve this
[23, 26], the proposed methods require specifying reverse kernels which have a
large impact on performance. Additionally, the resulting unbiased estimator of
the ELBO for most MCMC kernels is typically not amenable to the
reparameterization trick. We show here how to optimally select reverse kernels
in this setting and, by building upon Hamiltonian Importance Sampling (HIS)
[17], we obtain a scheme that provides low-variance unbiased estimators of the
ELBO and its gradients using the reparameterization trick. This allows us to
develop a Hamiltonian Variational Auto-Encoder (HVAE). This method can be
reinterpreted as a target-informed normalizing flow [20] which, within our
context, only requires a few evaluations of the gradient of the sampled
likelihood and trivial Jacobian calculations at each iteration.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Caterini_A/0/1/0/all/0/1&quot;&gt;Anthony L. Caterini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Doucet_A/0/1/0/all/0/1&quot;&gt;Arnaud Doucet&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sejdinovic_D/0/1/0/all/0/1&quot;&gt;Dino Sejdinovic&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11394">
<title>A novel channel pruning method for deep neural network compression. (arXiv:1805.11394v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1805.11394</link>
<description rdf:parseType="Literal">&lt;p&gt;In recent years, deep neural networks have achieved great success in the
field of computer vision. However, it is still a big challenge to deploy these
deep models on resource-constrained embedded devices such as mobile robots,
smart phones and so on. Therefore, network compression for such platforms is a
reasonable solution to reduce memory consumption and computation complexity. In
this paper, a novel channel pruning method based on genetic algorithm is
proposed to compress very deep Convolution Neural Networks (CNNs). Firstly, a
pre-trained CNN model is pruned layer by layer according to the sensitivity of
each layer. After that, the pruned model is fine-tuned based on knowledge
distillation framework. These two improvements significantly decrease the model
redundancy with less accuracy drop. Channel selection is a combinatorial
optimization problem that has exponential solution space. In order to
accelerate the selection process, the proposed method formulates it as a search
problem, which can be solved efficiently by genetic algorithm. Meanwhile, a
two-step approximation fitness function is designed to further improve the
efficiency of genetic process. The proposed method has been verified on three
benchmark datasets with two popular CNN models: VGGNet and ResNet. On the
CIFAR-100 and ImageNet datasets, our approach outperforms several
state-of-the-art methods. On the CIFAR-10 and SVHN datasets, the pruned VGGNet
achieves better performance than the original model with 8 times parameters
compression and 3 times FLOPs reduction.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1&quot;&gt;Yiming Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_S/0/1/0/all/0/1&quot;&gt;Siyang Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jianquan Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;Xingang Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gu_Q/0/1/0/all/0/1&quot;&gt;Qingyi Gu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11405">
<title>Representational Power of ReLU Networks and Polynomial Kernels: Beyond Worst-Case Analysis. (arXiv:1805.11405v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.11405</link>
<description rdf:parseType="Literal">&lt;p&gt;There has been a large amount of interest, both in the past and particularly
recently, into the power of different families of universal approximators, e.g.
ReLU networks, polynomials, rational functions. However, current research has
focused almost exclusively on understanding this problem in a worst-case
setting, e.g. bounding the error of the best infinity-norm approximation in a
box. In this setting a high-degree polynomial is required to even approximate a
single ReLU.
&lt;/p&gt;
&lt;p&gt;However, in real applications with high dimensional data we expect it is only
important to approximate the desired function well on certain relevant parts of
its domain. With this motivation, we analyze the ability of neural networks and
polynomial kernels of bounded degree to achieve good statistical performance on
a simple, natural inference problem with sparse latent structure. We give
almost-tight bounds on the performance of both neural networks and low degree
polynomials for this problem. Our bounds for polynomials involve new techniques
which may be of independent interest and show major qualitative differences
with what is known in the worst-case setting.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koehler_F/0/1/0/all/0/1&quot;&gt;Frederic Koehler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Risteski_A/0/1/0/all/0/1&quot;&gt;Andrej Risteski&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11450">
<title>Model-based Pricing for Machine Learning in a Data Marketplace. (arXiv:1805.11450v1 [cs.DB])</title>
<link>http://arxiv.org/abs/1805.11450</link>
<description rdf:parseType="Literal">&lt;p&gt;Data analytics using machine learning (ML) has become ubiquitous in science,
business intelligence, journalism and many other domains. While a lot of work
focuses on reducing the training cost, inference runtime and storage cost of ML
models, little work studies how to reduce the cost of data acquisition, which
potentially leads to a loss of sellers&apos; revenue and buyers&apos; affordability and
efficiency.
&lt;/p&gt;
&lt;p&gt;In this paper, we propose a model-based pricing (MBP) framework, which
instead of pricing the data, directly prices ML model instances. We first
formally describe the desired properties of the MBP framework, with a focus on
avoiding arbitrage. Next, we show a concrete realization of the MBP framework
via a noise injection approach, which provably satisfies the desired formal
properties. Based on the proposed framework, we then provide algorithmic
solutions on how the seller can assign prices to models under different market
scenarios (such as to maximize revenue). Finally, we conduct extensive
experiments, which validate that the MBP framework can provide high revenue to
the seller, high affordability to the buyer, and also operate on low runtime
cost.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1&quot;&gt;Lingjiao Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koutris_P/0/1/0/all/0/1&quot;&gt;Paraschos Koutris&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kumar_A/0/1/0/all/0/1&quot;&gt;Arun Kumar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11454">
<title>Distributed Stochastic Gradient Tracking Methods. (arXiv:1805.11454v1 [math.OC])</title>
<link>http://arxiv.org/abs/1805.11454</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we study the problem of distributed multi-agent optimization
over a network, where each agent possesses a local cost function that is smooth
and strongly convex. The global objective is to find a common solution that
minimizes the average of all cost functions. Assuming agents only have access
to unbiased estimates of the gradients of their local cost functions, we
consider a distributed stochastic gradient tracking method (DSGT) and a
gossip-like stochastic gradient tracking method (GSGT). We show that, in
expectation, the iterates generated by each agent are attracted to a
neighborhood of the optimal solution, where they accumulate exponentially fast
(under a constant stepsize choice). Under DSGT, the limiting (expected) error
bounds on the distance of the iterates from the optimal solution decrease with
the network size $n$, which is a comparable performance to a centralized
stochastic gradient algorithm. Moreover, we show that when the network is
well-connected, GSGT incurs lower communication cost than DSGT while
maintaining a similar computational cost. Numerical example further
demonstrates the effectiveness of the proposed methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Pu_S/0/1/0/all/0/1&quot;&gt;Shi Pu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Nedic_A/0/1/0/all/0/1&quot;&gt;Angelia Nedi&amp;#x107;&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11494">
<title>Efficient Bayesian Inference for a Gaussian Process Density Model. (arXiv:1805.11494v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.11494</link>
<description rdf:parseType="Literal">&lt;p&gt;We reconsider a nonparametric density model based on Gaussian processes. By
augmenting the model with latent P\&apos;olya--Gamma random variables and a latent
marked Poisson process we obtain a new likelihood which is conjugate to the
model&apos;s Gaussian process prior. The augmented posterior allows for efficient
inference by Gibbs sampling and an approximate variational mean field approach.
For the latter we utilise sparse GP approximations to tackle the infinite
dimensionality of the problem. The performance of both algorithms and
comparisons with other density estimators are demonstrated on artificial and
real datasets with up to several thousand data points.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Donner_C/0/1/0/all/0/1&quot;&gt;Christian Donner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Opper_M/0/1/0/all/0/1&quot;&gt;Manfred Opper&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11534">
<title>aipred: A Flexible R Package Implementing Methods for Predicting Air Pollution. (arXiv:1805.11534v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.11534</link>
<description rdf:parseType="Literal">&lt;p&gt;Fine particulate matter (PM$_{2.5}$) is one of the criteria air pollutants
regulated by the Environmental Protection Agency in the United States. There is
strong evidence that ambient exposure to (PM$_{2.5}$) increases risk of
mortality and hospitalization. Large scale epidemiological studies on the
health effects of PM$_{2.5}$ provide the necessary evidence base for lowering
the safety standards and inform regulatory policy. However, ambient monitors of
PM$_{2.5}$ (as well as monitors for other pollutants) are sparsely located
across the U.S., and therefore studies based only on the levels of PM$_{2.5}$
measured from the monitors would inevitably exclude large amounts of the
population. One approach to resolving this issue has been developing models to
predict local PM$_{2.5}$, NO$_2$, and ozone based on satellite, meteorological,
and land use data. This process typically relies developing a prediction model
that relies on large amounts of input data and is highly computationally
intensive to predict levels of air pollution in unmonitored areas. We have
developed a flexible R package that allows for environmental health researchers
to design and train spatio-temporal models capable of predicting multiple
pollutants, including PM$_{2.5}$. We utilize H2O, an open source big data
platform, to achieve both performance and scalability when used in conjunction
with cloud or cluster computing systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sabath_M/0/1/0/all/0/1&quot;&gt;M. Benjamin Sabath&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Di_Q/0/1/0/all/0/1&quot;&gt;Qian Di&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Braun_D/0/1/0/all/0/1&quot;&gt;Danielle Braun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Dominici_F/0/1/0/all/0/1&quot;&gt;Francesca Dominici&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Choirat_C/0/1/0/all/0/1&quot;&gt;Christine Choirat&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11542">
<title>Forward Amortized Inference for Likelihood-Free Variational Marginalization. (arXiv:1805.11542v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.11542</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we introduce a new form of amortized variational inference by
using the forward KL divergence in a joint-contrastive variational loss. The
resulting forward amortized variational inference is a likelihood-free method
as its gradient can be sampled without bias and without requiring any
evaluation of either the model joint distribution or its derivatives. We prove
that our new variational loss is optimized by the exact posterior marginals in
the fully factorized mean-field approximation, a property that is not shared
with the more conventional reverse KL inference. Furthermore, we show that
forward amortized inference can be easily marginalized over large families of
latent variables in order to obtain a marginalized variational posterior. We
consider two examples of variational marginalization. In our first example we
train a Bayesian forecaster for predicting a simplified chaotic model of
atmospheric convection. In the second example we train an amortized variational
approximation of a Bayesian optimal classifier by marginalizing over the model
space. The result is a powerful meta-classification network that can solve
arbitrary classification problems without further training.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ambrogioni_L/0/1/0/all/0/1&quot;&gt;Luca Ambrogioni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Guclu_U/0/1/0/all/0/1&quot;&gt;Umut G&amp;#xfc;&amp;#xe7;l&amp;#xfc;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Berezutskaya_J/0/1/0/all/0/1&quot;&gt;Julia Berezutskaya&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Borne_E/0/1/0/all/0/1&quot;&gt;Eva W. P. van den Borne&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gucluturk_Y/0/1/0/all/0/1&quot;&gt;Ya&amp;#x11f;mur G&amp;#xfc;&amp;#xe7;l&amp;#xfc;t&amp;#xfc;rk&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hinne_M/0/1/0/all/0/1&quot;&gt;Max Hinne&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Maris_E/0/1/0/all/0/1&quot;&gt;Eric Maris&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gerven_M/0/1/0/all/0/1&quot;&gt;Marcel A. J. van Gerven&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11571">
<title>Human-in-the-Loop Interpretability Prior. (arXiv:1805.11571v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.11571</link>
<description rdf:parseType="Literal">&lt;p&gt;We often desire our models to be interpretable as well as accurate. Prior
work on optimizing models for interpretability has relied on easy-to-quantify
proxies for interpretability, such as sparsity or the number of operations
required. In this work, we optimize for interpretability by directly including
humans in the optimization loop. We develop an algorithm that minimizes the
number of user studies to find models that are both predictive and
interpretable and demonstrate our approach on several data sets. Our human
subjects results show trends towards different proxy notions of
interpretability on different datasets, which suggests that different proxies
are preferred on different tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lage_I/0/1/0/all/0/1&quot;&gt;Isaac Lage&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ross_A/0/1/0/all/0/1&quot;&gt;Andrew Slavin Ross&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kim_B/0/1/0/all/0/1&quot;&gt;Been Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gershman_S/0/1/0/all/0/1&quot;&gt;Samuel J. Gershman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Doshi_Velez_F/0/1/0/all/0/1&quot;&gt;Finale Doshi-Velez&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11572">
<title>Adversarial Regularizers in Inverse Problems. (arXiv:1805.11572v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1805.11572</link>
<description rdf:parseType="Literal">&lt;p&gt;Inverse Problems in medical imaging and computer vision are traditionally
solved using purely model-based methods. Among those variational regularization
models are one of the most popular approaches. We propose a new framework for
applying data-driven approaches to inverse problems, using a neural network as
a regularization functional. The network learns to discriminate between the
distribution of ground truth images and the distribution of unregularized
reconstructions. Once trained, the network is applied to the inverse problem by
solving the corresponding variational problem. Unlike other data-based
approaches for inverse problems, the algorithm can be applied even if only
unsupervised training data is available. Experiments demonstrate the potential
of the framework for denoising on the BSDS dataset and for computer tomography
reconstruction on the LIDC dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lunz_S/0/1/0/all/0/1&quot;&gt;Sebastian Lunz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oktem_O/0/1/0/all/0/1&quot;&gt;Ozan &amp;#xd6;ktem&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schonlieb_C/0/1/0/all/0/1&quot;&gt;Carola-Bibiane Sch&amp;#xf6;nlieb&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11576">
<title>Focal onset seizure prediction using convolutional networks. (arXiv:1805.11576v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.11576</link>
<description rdf:parseType="Literal">&lt;p&gt;Objective: This work investigates the hypothesis that focal seizures can be
predicted using scalp electroencephalogram (EEG) data. Our first aim is to
learn features that distinguish between the interictal and preictal regions.
The second aim is to define a prediction horizon in which the prediction is as
accurate and as early as possible, clearly two competing objectives. Methods:
Convolutional filters on the wavelet transformation of the EEG signal are used
to define and learn quantitative signatures for each period: interictal,
preictal, and ictal. The optimal seizure prediction horizon is also learned
from the data as opposed to making an a priori assumption. Results:
Computational solutions to the optimization problem indicate a ten-minute
seizure prediction horizon. This result is verified by measuring
Kullback-Leibler divergence on the distributions of the automatically extracted
features. Conclusion: The results on the EEG database of 204 recordings
demonstrate that (i) the preictal phase transition occurs approximately ten
minutes before seizure onset, and (ii) the prediction results on the test set
are promising, with a sensitivity of 87.8% and a low false prediction rate of
0.142 FP/h. Our results significantly outperform a random predictor and other
seizure prediction algorithms. Significance: We demonstrate that a robust set
of features can be learned from scalp EEG that characterize the preictal state
of focal seizures.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khan_H/0/1/0/all/0/1&quot;&gt;Haidar Khan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Marcuse_L/0/1/0/all/0/1&quot;&gt;Lara Marcuse&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fields_M/0/1/0/all/0/1&quot;&gt;Madeline Fields&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Swann_K/0/1/0/all/0/1&quot;&gt;Kalina Swann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yener_B/0/1/0/all/0/1&quot;&gt;B&amp;#xfc;lent Yener&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11596">
<title>Classification Stability for Sparse-Modeled Signals. (arXiv:1805.11596v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.11596</link>
<description rdf:parseType="Literal">&lt;p&gt;Despite their impressive performance, deep convolutional neural networks
(CNNs) have been shown to be sensitive to small adversarial perturbations.
These nuisances, which one can barely notice, are powerful enough to fool
sophisticated and well performing classifiers, leading to ridiculous
misclassification results. In this paper we analyze the stability of
state-of-the-art classification machines to adversarial perturbations, where we
assume that the signals belong to the (possibly multi-layer) sparse
representation model. We start with convolutional sparsity and then proceed to
its multi-layered version, which is tightly connected to CNNs. Our analysis
links between the stability of the classification to noise and the underlying
structure of the signal, quantified by the sparsity of its representation under
a fixed dictionary. Our claims can be translated to a practical regularization
term that provides a new interpretation to the robustness of Parseval Networks.
Also, the proposed theory justifies the increased stability of the recently
emerging layered basis pursuit architectures, when compared to the classic
forward-pass.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Romano_Y/0/1/0/all/0/1&quot;&gt;Yaniv Romano&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Elad_M/0/1/0/all/0/1&quot;&gt;Michael Elad&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11597">
<title>Deep Neural Networks for Swept Volume Prediction Between Configurations. (arXiv:1805.11597v1 [cs.RO])</title>
<link>http://arxiv.org/abs/1805.11597</link>
<description rdf:parseType="Literal">&lt;p&gt;Swept Volume (SV), the volume displaced by an object when it is moving along
a trajectory, is considered a useful metric for motion planning. First, SV has
been used to identify collisions along a trajectory, because it directly
measures the amount of space required for an object to move. Second, in
sampling-based motion planning, SV is an ideal distance metric, because it
correlates to the likelihood of success of the expensive local planning step
between two sampled configurations. However, in both of these applications,
traditional SV algorithms are too computationally expensive for efficient
motion planning. In this work, we train Deep Neural Networks (DNNs) to learn
the size of SV for specific robot geometries. Results for two robots, a 6
degree of freedom (DOF) rigid body and a 7 DOF fixed-based manipulator,
indicate that the network estimations are very close to the true size of SV and
is more than 1500 times faster than a state of the art SV estimation algorithm.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chiang_H/0/1/0/all/0/1&quot;&gt;Hao-Tien Lewis Chiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Faust_A/0/1/0/all/0/1&quot;&gt;Aleksandra Faust&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tapia_L/0/1/0/all/0/1&quot;&gt;Lydia Tapia&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1610.06447">
<title>Regularized Optimal Transport and the Rot Mover&apos;s Distance. (arXiv:1610.06447v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1610.06447</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents a unified framework for smooth convex regularization of
discrete optimal transport problems. In this context, the regularized optimal
transport turns out to be equivalent to a matrix nearness problem with respect
to Bregman divergences. Our framework thus naturally generalizes a previously
proposed regularization based on the Boltzmann-Shannon entropy related to the
Kullback-Leibler divergence, and solved with the Sinkhorn-Knopp algorithm. We
call the regularized optimal transport distance the rot mover&apos;s distance in
reference to the classical earth mover&apos;s distance. We develop two generic
schemes that we respectively call the alternate scaling algorithm and the
non-negative alternate scaling algorithm, to compute efficiently the
regularized optimal plans depending on whether the domain of the regularizer
lies within the non-negative orthant or not. These schemes are based on
Dykstra&apos;s algorithm with alternate Bregman projections, and further exploit the
Newton-Raphson method when applied to separable divergences. We enhance the
separable case with a sparse extension to deal with high data dimensions. We
also instantiate our proposed framework and discuss the inherent specificities
for well-known regularizers and statistical divergences in the machine learning
and information geometry communities. Finally, we demonstrate the merits of our
methods with experiments using synthetic data to illustrate the effect of
different regularizers and penalties on the solutions, as well as real-world
data for a pattern recognition application to audio scene classification.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Dessein_A/0/1/0/all/0/1&quot;&gt;Arnaud Dessein&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Papadakis_N/0/1/0/all/0/1&quot;&gt;Nicolas Papadakis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rouas_J/0/1/0/all/0/1&quot;&gt;Jean-Luc Rouas&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1612.05846">
<title>Joint Spatial-Angular Sparse Coding for dMRI with Separable Dictionaries. (arXiv:1612.05846v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1612.05846</link>
<description rdf:parseType="Literal">&lt;p&gt;Diffusion MRI (dMRI) provides the ability to reconstruct neuronal fibers in
the brain, $\textit{in vivo}$, by measuring water diffusion along angular
gradient directions in q-space. High angular resolution diffusion imaging
(HARDI) can produce better estimates of fiber orientation than the popularly
used diffusion tensor imaging, but the high number of samples needed to
estimate diffusivity requires longer patient scan times. To accelerate dMRI,
compressed sensing (CS) has been utilized by exploiting a sparse dictionary
representation of the data, discovered through sparse coding. The sparser the
representation, the fewer samples are needed to reconstruct a high resolution
signal with limited information loss, and so an important area of research has
focused on finding the sparsest possible representation of dMRI. Current
reconstruction methods however, rely on an angular representation $\textit{per
voxel}$ with added spatial regularization, and so, for non-zero signals, one is
required to have at least one non-zero coefficient per voxel. This means that
the global level of sparsity must be greater than the number of voxels. In
contrast, we propose a joint spatial-angular representation of dMRI that will
allow us to achieve levels of global sparsity that are below the number of
voxels. A major challenge, however, is the computational complexity of solving
a global sparse coding problem over large-scale dMRI. In this work, we present
novel adaptations of popular sparse coding algorithms that become better suited
for solving large-scale problems by exploiting spatial-angular separability.
Our experiments show that our method achieves significantly sparser
representations of HARDI than is possible by the state of the art.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Schwab_E/0/1/0/all/0/1&quot;&gt;Evan Schwab&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Vidal_R/0/1/0/all/0/1&quot;&gt;Ren&amp;#xe9; Vidal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Charon_N/0/1/0/all/0/1&quot;&gt;Nicolas Charon&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1705.07019">
<title>Model-Robust Counterfactual Prediction Method. (arXiv:1705.07019v5 [math.ST] UPDATED)</title>
<link>http://arxiv.org/abs/1705.07019</link>
<description rdf:parseType="Literal">&lt;p&gt;We develop a novel method for counterfactual analysis based on observational
data using prediction intervals for units under different exposures. Unlike
methods that target heterogeneous or conditional average treatment effects of
an exposure, the proposed approach aims to take into account the irreducible
dispersions of counterfactual outcomes so as to quantify the relative impact of
different exposures. The prediction intervals are constructed in a
distribution-free and model-robust manner based on the conformal prediction
approach. The computational obstacles to this approach are circumvented by
leveraging properties of a tuning-free method that learns sparse additive
predictor models for counterfactual outcomes. The method is illustrated using
both real and synthetic data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Zachariah_D/0/1/0/all/0/1&quot;&gt;Dave Zachariah&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Stoica_P/0/1/0/all/0/1&quot;&gt;Petre Stoica&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1705.07819">
<title>Regularizing deep networks using efficient layerwise adversarial training. (arXiv:1705.07819v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1705.07819</link>
<description rdf:parseType="Literal">&lt;p&gt;Adversarial training has been shown to regularize deep neural networks in
addition to increasing their robustness to adversarial examples. However, its
impact on very deep state of the art networks has not been fully investigated.
In this paper, we present an efficient approach to perform adversarial training
by perturbing intermediate layer activations and study the use of such
perturbations as a regularizer during training. We use these perturbations to
train very deep models such as ResNets and show improvement in performance both
on adversarial and original test data. Our experiments highlight the benefits
of perturbing intermediate layer activations compared to perturbing only the
inputs. The results on CIFAR-10 and CIFAR-100 datasets show the merits of the
proposed adversarial training approach. Additional results on WideResNets show
that our approach provides significant improvement in classification accuracy
for a given base model, outperforming dropout and other base models of larger
size.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sankaranarayanan_S/0/1/0/all/0/1&quot;&gt;Swami Sankaranarayanan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jain_A/0/1/0/all/0/1&quot;&gt;Arpit Jain&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chellappa_R/0/1/0/all/0/1&quot;&gt;Rama Chellappa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lim_S/0/1/0/all/0/1&quot;&gt;Ser Nam Lim&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1708.01384">
<title>Variance-Reduced Stochastic Learning by Networked Agents under Random Reshuffling. (arXiv:1708.01384v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1708.01384</link>
<description rdf:parseType="Literal">&lt;p&gt;A new amortized variance-reduced gradient (AVRG) algorithm was developed in
\cite{ying2017convergence}, which has constant storage requirement in
comparison to SAGA and balanced gradient computations in comparison to SVRG.
One key advantage of the AVRG strategy is its amenability to decentralized
implementations. In this work, we show how AVRG can be extended to the network
case where multiple learning agents are assumed to be connected by a graph
topology. In this scenario, each agent observes data that is spatially
distributed and all agents are only allowed to communicate with direct
neighbors. Moreover, the amount of data observed by the individual agents may
differ drastically. For such situations, the balanced gradient computation
property of AVRG becomes a real advantage in reducing idle time caused by
unbalanced local data storage requirements, which is characteristic of other
reduced-variance gradient algorithms. The resulting diffusion-AVRG algorithm is
shown to have linear convergence to the exact solution, and is much more memory
efficient than other alternative algorithms. In addition, we propose a
mini-batch strategy to balance the communication and computation efficiency for
diffusion-AVRG. When a proper batch size is employed, it is observed in
simulations that diffusion-AVRG is more computationally efficient than exact
diffusion or EXTRA while maintaining almost the same communication efficiency.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yuan_K/0/1/0/all/0/1&quot;&gt;Kun Yuan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ying_B/0/1/0/all/0/1&quot;&gt;Bicheng Ying&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Jiageng Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sayed_A/0/1/0/all/0/1&quot;&gt;Ali H. Sayed&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.06970">
<title>An Expectation Conditional Maximization approach for Gaussian graphical models. (arXiv:1709.06970v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1709.06970</link>
<description rdf:parseType="Literal">&lt;p&gt;Bayesian graphical models are a useful tool for understanding dependence
relationships among many variables, particularly in situations with external
prior information. In high-dimensional settings, the space of possible graphs
becomes enormous, rendering even state-of-the-art Bayesian stochastic search
computationally infeasible. We propose a deterministic alternative to estimate
Gaussian and Gaussian copula graphical models using an Expectation Conditional
Maximization (ECM) algorithm, extending the EM approach from Bayesian variable
selection to graphical model estimation. We show that the ECM approach enables
fast posterior exploration under a sequence of mixture priors, and can
incorporate multiple sources of information.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Zehang Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+McCormick_T/0/1/0/all/0/1&quot;&gt;Tyler H. McCormick&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.04725">
<title>Hyperparameter Importance Across Datasets. (arXiv:1710.04725v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1710.04725</link>
<description rdf:parseType="Literal">&lt;p&gt;With the advent of automated machine learning, automated hyperparameter
optimization methods are by now routinely used in data mining. However, this
progress is not yet matched by equal progress on automatic analyses that yield
information beyond performance-optimizing hyperparameter settings. In this
work, we aim to answer the following two questions: Given an algorithm, what
are generally its most important hyperparameters, and what are typically good
values for these? We present methodology and a framework to answer these
questions based on meta-learning across many datasets. We apply this
methodology using the experimental meta-data available on OpenML to determine
the most important hyperparameters of support vector machines, random forests
and Adaboost, and to infer priors for all their hyperparameters. The results,
obtained fully automatically, provide a quantitative basis to focus efforts in
both manual algorithm design and in automated hyperparameter optimization. The
conducted experiments confirm that the hyperparameters selected by the proposed
method are indeed the most important ones and that the obtained priors also
lead to statistically significant improvements in hyperparameter optimization.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rijn_J/0/1/0/all/0/1&quot;&gt;J. N. van Rijn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hutter_F/0/1/0/all/0/1&quot;&gt;F. Hutter&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.05610">
<title>On consistent vertex nomination schemes. (arXiv:1711.05610v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1711.05610</link>
<description rdf:parseType="Literal">&lt;p&gt;Given a vertex of interest in a network $G_1$, the vertex nomination problem
seeks to find the corresponding vertex of interest (if it exists) in a second
network $G_2$. A vertex nomination scheme produces a rank list of the vertices
in $G_2$, where the vertices are ranked by how likely they are judged to be the
corresponding vertex of interest in $G_2$. The vertex nomination problem and
related information retrieval tasks have attracted much attention in the
machine learning literature, with numerous applications in social and
biological networks. However, the current framework has often been confined to
a comparatively small class of network models, and the concept of statistically
consistent vertex nomination schemes has been only shallowly explored. In this
paper, we extend the vertex nomination problem to a very general statistical
model of graphs. Further, drawing inspiration from the long-established
classification framework in the pattern recognition literature, we provide
definitions for the key notions of Bayes optimality and consistency in our
extended vertex nomination framework, including a derivation of the Bayes
optimal vertex nomination scheme. In addition, we prove that no universally
consistent vertex nomination schemes exist. Illustrative examples are provided
throughout.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lyzinski_V/0/1/0/all/0/1&quot;&gt;Vince Lyzinski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Levin_K/0/1/0/all/0/1&quot;&gt;Keith Levin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Priebe_C/0/1/0/all/0/1&quot;&gt;Carey E. Priebe&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.00287">
<title>Faithful Inversion of Generative Models for Effective Amortized Inference. (arXiv:1712.00287v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1712.00287</link>
<description rdf:parseType="Literal">&lt;p&gt;Inference amortization methods share information across multiple
posterior-inference problems, allowing each to be carried out more efficiently.
Generally, they require the inversion of the dependency structure in the
generative model, as the modeller must learn a mapping from observations to
distributions approximating the posterior. Previous approaches have involved
inverting the dependency structure in a heuristic way that fails to capture
these dependencies correctly, thereby limiting the achievable accuracy of the
resulting approximations. We introduce an algorithm for faithfully, and
minimally, inverting the graphical model structure of any generative model.
Such inverses have two crucial properties: (a) they do not encode any
independence assertions that are absent from the model and; (b) they are local
maxima for the number of true independencies encoded. We prove the correctness
of our approach and empirically show that the resulting minimally faithful
inverses lead to better inference amortization than existing heuristic
approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Webb_S/0/1/0/all/0/1&quot;&gt;Stefan Webb&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Golinski_A/0/1/0/all/0/1&quot;&gt;Adam Golinski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zinkov_R/0/1/0/all/0/1&quot;&gt;Robert Zinkov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Siddharth_N/0/1/0/all/0/1&quot;&gt;N. Siddharth&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rainforth_T/0/1/0/all/0/1&quot;&gt;Tom Rainforth&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Teh_Y/0/1/0/all/0/1&quot;&gt;Yee Whye Teh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wood_F/0/1/0/all/0/1&quot;&gt;Frank Wood&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.01737">
<title>Bayesian Coreset Construction via Greedy Iterative Geodesic Ascent. (arXiv:1802.01737v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1802.01737</link>
<description rdf:parseType="Literal">&lt;p&gt;Coherent uncertainty quantification is a key strength of Bayesian methods.
But modern algorithms for approximate Bayesian posterior inference often
sacrifice accurate posterior uncertainty estimation in the pursuit of
scalability. This work shows that previous Bayesian coreset construction
algorithms---which build a small, weighted subset of the data that approximates
the full dataset---are no exception. We demonstrate that these algorithms scale
the coreset log-likelihood suboptimally, resulting in underestimated posterior
uncertainty. To address this shortcoming, we develop greedy iterative geodesic
ascent (GIGA), a novel algorithm for Bayesian coreset construction that scales
the coreset log-likelihood optimally. GIGA provides geometric decay in
posterior approximation error as a function of coreset size, and maintains the
fast running time of its predecessors. The paper concludes with validation of
GIGA on both synthetic and real datasets, demonstrating that it reduces
posterior approximation error by orders of magnitude compared with previous
coreset constructions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Campbell_T/0/1/0/all/0/1&quot;&gt;Trevor Campbell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Broderick_T/0/1/0/all/0/1&quot;&gt;Tamara Broderick&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.02922">
<title>Fast Convergence for Stochastic and Distributed Gradient Descent in the Interpolation Limit. (arXiv:1803.02922v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1803.02922</link>
<description rdf:parseType="Literal">&lt;p&gt;Modern supervised learning techniques, particularly those using deep nets,
involve fitting high dimensional labelled data sets with functions containing
very large numbers of parameters. Much of this work is empirical. Interesting
phenomena have been observed that require theoretical explanations; however the
non-convexity of the loss functions complicates the analysis. Recently it has
been proposed that the success of these techniques rests partly in the
effectiveness of the simple stochastic gradient descent algorithm in the so
called interpolation limit in which all labels are fit perfectly. This analysis
is made possible since the SGD algorithm reduces to a stochastic linear system
near the interpolating minimum of the loss function. Here we exploit this
insight by presenting and analyzing a new distributed algorithm for gradient
descent, also in the interpolating limit. The distributed SGD algorithm
presented in the paper corresponds to gradient descent applied to a simple
penalized distributed loss function, $L({\bf w}_1,...,{\bf w}_n) = \Sigma_i
l_i({\bf w}_i) + \mu \sum_{&amp;lt;i,j&amp;gt;}|{\bf w}_i-{\bf w}_j|^2$. Here each node holds
only one sample, and its own parameter vector. The notation $&amp;lt;i,j&amp;gt;$ denotes
edges of a connected graph defining the links between nodes. It is shown that
this distributed algorithm converges linearly (ie the error reduces
exponentially with iteration number), with a rate
$1-\frac{\eta}{n}\lambda_{min}(H)&amp;lt;R&amp;lt;1$ where $\lambda_{min}(H)$ is the smallest
nonzero eigenvalue of the sample covariance or the Hessian H. In contrast with
previous usage of similar penalty functions to enforce consensus between nodes,
in the interpolating limit it is not required to take the penalty parameter to
infinity for consensus to occur. The analysis further reinforces the utility of
the interpolation limit in the theoretical treatment of modern machine learning
algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mitra_P/0/1/0/all/0/1&quot;&gt;Partha P Mitra&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.08591">
<title>End-to-End Learning for the Deep Multivariate Probit Model. (arXiv:1803.08591v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1803.08591</link>
<description rdf:parseType="Literal">&lt;p&gt;The multivariate probit model (MVP) is a popular classic model for studying
binary responses of multiple entities. Nevertheless, the computational
challenge of learning the MVP model, given that its likelihood involves
integrating over a multidimensional constrained space of latent variables,
significantly limits its application in practice. We propose a flexible deep
generalization of the classic MVP, the Deep Multivariate Probit Model (DMVP),
which is an end-to-end learning scheme that uses an efficient parallel sampling
process of the multivariate probit model to exploit GPU-boosted deep neural
networks. We present both theoretical and empirical analysis of the convergence
behavior of DMVP&apos;s sampling process with respect to the resolution of the
correlation structure. We provide convergence guarantees for DMVP and our
empirical analysis demonstrates the advantages of DMVP&apos;s sampling compared with
standard MCMC-based methods. We also show that when applied to multi-entity
modelling problems, which are natural DMVP applications, DMVP trains faster
than classical MVP, by at least an order of magnitude, captures rich
correlations among entities, and further improves the joint likelihood of
entities compared with several competitive models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1&quot;&gt;Di Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xue_Y/0/1/0/all/0/1&quot;&gt;Yexiang Xue&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gomes_C/0/1/0/all/0/1&quot;&gt;Carla P. Gomes&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.02086">
<title>Structured Disentangled Representations. (arXiv:1804.02086v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1804.02086</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep latent-variable models learn representations of high-dimensional data in
an unsupervised manner. A number of recent efforts have focused on learning
representations that disentangle statistically independent axes of variation by
introducing modifications to the standard objective function. These approaches
generally assume a simple diagonal Gaussian prior and as a result are not able
to reliably disentangle discrete factors of variation. We propose a two-level
hierarchical objective to control relative degree of statistical independence
between blocks of variables and individual variables within blocks. We derive
this objective as a generalization of the evidence lower bound, which allows us
to explicitly represent the trade-offs between mutual information between data
and representation, KL divergence between representation and prior, and
coverage of the support of the empirical data distribution. Experiments on a
variety of datasets demonstrate that our objective can not only disentangle
discrete variables, but that doing so also improves disentanglement of other
variables and, importantly, generalization even to unseen combinations of
factors.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Esmaeili_B/0/1/0/all/0/1&quot;&gt;Babak Esmaeili&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wu_H/0/1/0/all/0/1&quot;&gt;Hao Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Jain_S/0/1/0/all/0/1&quot;&gt;Sarthak Jain&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bozkurt_A/0/1/0/all/0/1&quot;&gt;Alican Bozkurt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Siddharth_N/0/1/0/all/0/1&quot;&gt;N. Siddharth&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Paige_B/0/1/0/all/0/1&quot;&gt;Brooks Paige&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Brooks_D/0/1/0/all/0/1&quot;&gt;Dana H. Brooks&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Dy_J/0/1/0/all/0/1&quot;&gt;Jennifer Dy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Meent_J/0/1/0/all/0/1&quot;&gt;Jan-Willem van de Meent&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.03836">
<title>E-commerce Anomaly Detection: A Bayesian Semi-Supervised Tensor Decomposition Approach using Natural Gradients. (arXiv:1804.03836v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1804.03836</link>
<description rdf:parseType="Literal">&lt;p&gt;Anomaly Detection has several important applications. In this paper, our
focus is on detecting anomalies in seller-reviewer data using tensor
decomposition. While tensor-decomposition is mostly unsupervised, we formulate
Bayesian semi-supervised tensor decomposition to take advantage of sparse
labeled data. In addition, we use Polya-Gamma data augmentation for the
semi-supervised Bayesian tensor decomposition. Finally, we show that the
P\&apos;olya-Gamma formulation simplifies calculation of the Fisher information
matrix for partial natural gradient learning. Our experimental results show
that our semi-supervised approach outperforms state of the art unsupervised
baselines. And that the partial natural gradient learning outperforms
stochastic gradient learning and Online-EM with sufficient statistics.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yelundur_A/0/1/0/all/0/1&quot;&gt;Anil R. Yelundur&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sengamedu_S/0/1/0/all/0/1&quot;&gt;Srinivasan H. Sengamedu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mishra_B/0/1/0/all/0/1&quot;&gt;Bamdev Mishra&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.09597">
<title>On The Complexity of Sparse Label Propagation. (arXiv:1804.09597v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1804.09597</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper investigates the computational complexity of sparse label
propagation which has been proposed recently for processing network structured
data. Sparse label propagation amounts to a convex optimization problem and
might be considered as an extension of basis pursuit from sparse vectors to
network structured datasets. Using a standard first-order oracle model, we
characterize the number of iterations for sparse label propagation to achieve a
prescribed accuracy. In particular, we derive an upper bound on the number of
iterations required to achieve a certain accuracy and show that this upper
bound is sharp for datasets having a chain structure (e.g., time series).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Jung_A/0/1/0/all/0/1&quot;&gt;Alexander Jung&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.06619">
<title>Taxi demand forecasting: A HEDGE based tessellation strategy for improved accuracy. (arXiv:1805.06619v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.06619</link>
<description rdf:parseType="Literal">&lt;p&gt;A key problem in location-based modeling and forecasting lies in identifying
suitable spatial and temporal resolutions. In particular, judicious spatial
partitioning can play a significant role in enhancing the performance of
location-based forecasting models. In this work, we investigate two widely used
tessellation strategies for partitioning city space, in the context of
real-time taxi demand forecasting. Our study compares (i) Geohash tessellation,
and (ii) Voronoi tessellation, using two distinct taxi demand datasets, over
multiple time scales. For the purpose of comparison, we employ classical
time-series tools to model the spatio-temporal demand. Our study finds that the
performance of each tessellation strategy is highly dependent on the city
geography, spatial distribution of the data, and the time of the day, and that
neither strategy is found to perform optimally across the forecast horizon. We
propose a hybrid tessellation algorithm that picks the best tessellation
strategy at each instant, based on their performance in the recent past. Our
hybrid algorithm is a non-stationary variant of the well-known HEDGE algorithm
for choosing the best advice from multiple experts. We show that the hybrid
tessellation strategy performs consistently better than either of the two
strategies across the data sets considered, at multiple time scales, and with
different performance metrics. We achieve an average accuracy of above 80% per
km^2 for both data sets considered at 60 minute aggregation levels.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Davis_N/0/1/0/all/0/1&quot;&gt;Neema Davis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Raina_G/0/1/0/all/0/1&quot;&gt;Gaurav Raina&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jagannathan_K/0/1/0/all/0/1&quot;&gt;Krishna Jagannathan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08045">
<title>A universal framework for learning based on the elliptical mixture model (EMM). (arXiv:1805.08045v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.08045</link>
<description rdf:parseType="Literal">&lt;p&gt;An increasing prominence of unbalanced and noisy data highlights the
importance of elliptical mixture models (EMMs), which exhibit enhanced
robustness, flexibility and stability over the widely applied Gaussian mixture
model (GMM). However, existing studies of the EMM are typically of \textit{ad
hoc} nature, without a universal analysis framework or existence and uniqueness
considerations. To this end, we propose a general framework for estimating the
EMM, which makes use of the Riemannian manifold optimisation to convert the
original constrained optimisation paradigms into an un-constrained one. We
first revisit the statistics of elliptical distributions, to give a rationale
for the use of Riemannian metrics as well as the reformulation of the problem
in the Riemannian space. We then derive the EMM learning framework, based on
Riemannian gradient descent, which ensures the same optimum as the original
problem but accelerates the convergence speed. We also unify the treatment of
the existing elliptical distributions to build a universal EMM, providing a
simple and intuitive way to deal with the non-convex nature of this
optimisation problem. Numerical results demonstrate the ability of the proposed
framework to accommodate EMMs with different properties of individual
functions, and also verify the robustness and flexibility of the proposed
framework over the standard GMM.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1&quot;&gt;Shengxi Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1&quot;&gt;Zeyang Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mandic_D/0/1/0/all/0/1&quot;&gt;Danilo P. Mandic&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.10014">
<title>KONG: Kernels for ordered-neighborhood graphs. (arXiv:1805.10014v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.10014</link>
<description rdf:parseType="Literal">&lt;p&gt;We present novel graph kernels for graphs with node and edge labels that have
ordered neighborhoods, i.e. when neighbor nodes follow an order. Graphs with
ordered neighborhoods are a natural data representation for evolving graphs
where edges are created over time, which induces an order. Combining
convolutional subgraph kernels and string kernels, we design new scalable
algorithms for generation of explicit graph feature maps using sketching
techniques. We obtain precise bounds for the approximation accuracy and
computational complexity of the proposed approaches and demonstrate their
applicability on real datasets. In particular, our experiments demonstrate that
neighborhood ordering results in more informative features. For the special
case of general graphs, i.e. graphs without ordered neighborhoods, the new
graph kernels yield efficient and simple algorithms for the comparison of label
distributions between graphs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Draief_M/0/1/0/all/0/1&quot;&gt;Moez Draief&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kutzkov_K/0/1/0/all/0/1&quot;&gt;Konstantin Kutzkov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Scaman_K/0/1/0/all/0/1&quot;&gt;Kevin Scaman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vojnovic_M/0/1/0/all/0/1&quot;&gt;Milan Vojnovic&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.10988">
<title>Deeply learning molecular structure-property relationships using graph attention neural network. (arXiv:1805.10988v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.10988</link>
<description rdf:parseType="Literal">&lt;p&gt;Molecular structure-property relationships are the key to molecular
engineering for materials and drug discovery. The rise of deep learning offers
a new viable solution to elucidate the structure-property relationships
directly from chemical data. Here we show that graph attention networks can
greatly improve performance of the deep learning for chemistry. The attention
mechanism enables to distinguish atoms in different environments and thus to
extract important structural features determining target properties. We
demonstrated that our model can detect appropriate features for molecular
polarity, solubility, and energy. Interestingly, it identified two distinct
parts of molecules as essential structural features for high photovoltaic
efficiency, each of which coincided with the area of donor and acceptor
orbitals in charge-transfer excitations, respectively. As a result, it could
accurately predict molecular properties. Moreover, the resultant latent space
was well-organized such that molecules with similar properties were closely
located, which is critical for successful molecular engineering.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ryu_S/0/1/0/all/0/1&quot;&gt;Seongok Ryu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lim_J/0/1/0/all/0/1&quot;&gt;Jaechang Lim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_W/0/1/0/all/0/1&quot;&gt;Woo Youn Kim&lt;/a&gt;</dc:creator>
</item></rdf:RDF>