<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Boring papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Bad Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-03-08T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.02943"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.03015"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.02855"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.02865"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.02998"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.03021"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.03067"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.03114"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.03146"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.03241"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.03719"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04520"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.02544"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.02879"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.02922"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.02933"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.03104"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.03166"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.03191"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.03234"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1602.06701"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1602.08207"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1703.06856"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1706.03779"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1706.08344"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.09513"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.07871"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.08664"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.10110"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.03848"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.01814"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.02726"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1803.02943">
<title>Multi-objective evolution for 3D RTS Micro. (arXiv:1803.02943v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1803.02943</link>
<description rdf:parseType="Literal">&lt;p&gt;We attack the problem of controlling teams of autonomous units during
skirmishes in real-time strategy games. Earlier work had shown promise in
evolving control algorithm parameters that lead to high performance team
behaviors similar to those favored by good human players in real-time strategy
games like Starcraft. This algorithm specifically encoded parameterized kiting
and fleeing behaviors and the genetic algorithm evolved these parameter values.
In this paper we investigate using influence maps and potential fields alone to
compactly represent and control real-time team behavior for entities that can
maneuver in three dimensions. A two-objective fitness function that maximizes
damage done and minimizes damage taken guides our multi-objective evolutionary
algorithm. Preliminary results indicate that evolving friend and enemy unit
potential field parameters for distance, weapon characteristics, and entity
health suffice to produce complex, high performing, three-dimensional, team
tactics.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Louis_S/0/1/0/all/0/1&quot;&gt;Sushil J. Louis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1&quot;&gt;Siming Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.03015">
<title>An FPGA-based Massively Parallel Neuromorphic Cortex Simulator. (arXiv:1803.03015v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1803.03015</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents a massively parallel and scalable neuromorphic cortex
simulator designed for simulating large and structurally connected spiking
neural networks, such as complex models of various areas of the cortex. The
main novelty of this work is the abstraction of a neuromorphic architecture
into clusters represented by minicolumns and hypercolumns, analogously to the
fundamental structural units observed in neurobiology. Without this approach,
simulating large-scale fully connected networks needs prohibitively large
memory to store look-up tables for point-to-point connections. Instead, we use
a novel architecture, based on the structural connectivity in the neocortex,
such that all the required parameters and connections can be stored in on-chip
memory. The cortex simulator can be easily reconfigured for simulating
different neural networks without any change in hardware structure by
programming the memory. A hierarchical communication scheme allows one neuron
to have a fan-out of up to 200k neurons. As a proof-of-concept, an
implementation on one Altera Stratix V FPGA was able to simulate 20 million to
2.6 billion leaky-integrate-and-fire (LIF) neurons in real time. We verified
the system by emulating a simplified auditory cortex (with 100 million
neurons). This cortex simulator achieved a low power dissipation of 1.62 {\mu}W
per neuron. With the advent of commercially available FPGA boards, our system
offers an accessible and scalable tool for the design, real-time simulation,
and analysis of large-scale spiking neural networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1&quot;&gt;Runchun Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Thakur_C/0/1/0/all/0/1&quot;&gt;Chetan Singh Thakur&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schaik_A/0/1/0/all/0/1&quot;&gt;Andre van Schaik&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.02855">
<title>Satisficing in Time-Sensitive Bandit Learning. (arXiv:1803.02855v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1803.02855</link>
<description rdf:parseType="Literal">&lt;p&gt;Much of the recent literature on bandit learning focuses on algorithms that
aim to converge on an optimal action. One shortcoming is that this orientation
does not account for time sensitivity, which can play a crucial role when
learning an optimal action requires much more information than near-optimal
ones. Indeed, popular approaches such as upper-confidence-bound methods and
Thompson sampling can fare poorly in such situations. We consider instead
learning a satisficing action, which is near-optimal while requiring less
information, and propose satisficing Thompson sampling, an algorithm that
serves this purpose. We establish a general bound on expected discounted regret
and study the application of satisficing Thompson sampling to linear and
infinite-armed bandits, demonstrating arbitrarily large benefits over Thompson
sampling. We also discuss the relation between the notion of satisficing and
the theory of rate distortion, which offers guidance on the selection of
satisficing actions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Russo_D/0/1/0/all/0/1&quot;&gt;Daniel Russo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roy_B/0/1/0/all/0/1&quot;&gt;Benjamin Van Roy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.02865">
<title>WNGrad: Learn the Learning Rate in Gradient Descent. (arXiv:1803.02865v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1803.02865</link>
<description rdf:parseType="Literal">&lt;p&gt;Adjusting the learning rate schedule in stochastic gradient methods is an
important unresolved problem which requires tuning in practice. If certain
parameters of the loss function such as smoothness or strong convexity
constants are known, theoretical learning rate schedules can be applied.
However, in practice, such parameters are not known, and the loss function of
interest is not convex in any case. The recently proposed batch normalization
reparametrization is widely adopted in most neural network architectures today
because, among other advantages, it is robust to the choice of Lipschitz
constant of the gradient in loss function, allowing one to set a large learning
rate without worry. Inspired by batch normalization, we propose a general
nonlinear update rule for the learning rate in batch and stochastic gradient
descent so that the learning rate can be initialized at a high value, and is
subsequently decreased according to gradient observations along the way. The
proposed method is shown to achieve robustness to the relationship between the
learning rate and the Lipschitz constant, and near-optimal convergence rates in
both the batch and stochastic settings ($O(1/T)$ for smooth loss in the batch
setting, and $O(1/\sqrt{T})$ for convex loss in the stochastic setting). We
also show through numerical evidence that such robustness of the proposed
method extends to highly nonconvex and possibly non-smooth loss function in
deep learning problems.Our analysis establishes some first theoretical
understanding into the observed robustness for batch normalization and weight
normalization.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wu_X/0/1/0/all/0/1&quot;&gt;Xiaoxia Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ward_R/0/1/0/all/0/1&quot;&gt;Rachel Ward&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bottou_L/0/1/0/all/0/1&quot;&gt;L&amp;#xe9;on Bottou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.02998">
<title>DeepCAS: A Deep Reinforcement Learning Algorithm for Control-Aware Scheduling. (arXiv:1803.02998v1 [cs.SY])</title>
<link>http://arxiv.org/abs/1803.02998</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider networked control systems consisting of multiple independent
closed-loop control subsystems, operating over a shared communication network.
Such systems are ubiquitous in cyber-physical systems, Internet of Things, and
large-scale industrial systems. In many large-scale settings, the size of the
communication network is smaller than the size of the system. In consequence,
scheduling issues arise. The main contribution of this paper is to develop a
deep reinforcement learning-based \emph{control-aware} scheduling
(\textsc{DeepCAS}) algorithm to tackle these issues. We use the following
(optimal) design strategy: First, we synthesize an optimal controller for each
subsystem; next, we design learning algorithm that adapts to the chosen
subsystem (plant) and controller. As a consequence of this adaptation, our
algorithm finds a schedule that minimizes the \emph{control loss}. We present
empirical results to show that \textsc{DeepCAS} finds schedules with better
performance than periodic ones. Finally, we illustrate that our algorithm can
be used for \emph{scheduling and resource allocation in more general networked
control settings than the above-mentioned one}.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Demirel_B/0/1/0/all/0/1&quot;&gt;Burak Demirel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ramaswamy_A/0/1/0/all/0/1&quot;&gt;Arunselvan Ramaswamy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Quevedo_D/0/1/0/all/0/1&quot;&gt;Daniel E. Quevedo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Karl_H/0/1/0/all/0/1&quot;&gt;Holger Karl&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.03021">
<title>SA-IGA: A Multiagent Reinforcement Learning Method Towards Socially Optimal Outcomes. (arXiv:1803.03021v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1803.03021</link>
<description rdf:parseType="Literal">&lt;p&gt;In multiagent environments, the capability of learning is important for an
agent to behave appropriately in face of unknown opponents and dynamic
environment. From the system designer&apos;s perspective, it is desirable if the
agents can learn to coordinate towards socially optimal outcomes, while also
avoiding being exploited by selfish opponents. To this end, we propose a novel
gradient ascent based algorithm (SA-IGA) which augments the basic
gradient-ascent algorithm by incorporating social awareness into the policy
update process. We theoretically analyze the learning dynamics of SA-IGA using
dynamical system theory and SA-IGA is shown to have linear dynamics for a wide
range of games including symmetric games. The learning dynamics of two
representative games (the prisoner&apos;s dilemma game and the coordination game)
are analyzed in details. Based on the idea of SA-IGA, we further propose a
practical multiagent learning algorithm, called SA-PGA, based on Q-learning
update rule. Simulation results show that SA-PGA agent can achieve higher
social welfare than previous social-optimality oriented Conditional Joint
Action Learner (CJAL) and also is robust against individually rational
opponents by reaching Nash equilibrium solutions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1&quot;&gt;Chengwei Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xiaohong Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hao_J/0/1/0/all/0/1&quot;&gt;Jianye Hao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1&quot;&gt;Siqi Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tuyls_K/0/1/0/all/0/1&quot;&gt;Karl Tuyls&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xue_W/0/1/0/all/0/1&quot;&gt;Wanli Xue&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.03067">
<title>Compositional Attention Networks for Machine Reasoning. (arXiv:1803.03067v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1803.03067</link>
<description rdf:parseType="Literal">&lt;p&gt;We present the MAC network, a novel fully differentiable neural network
architecture, designed to facilitate explicit and expressive reasoning. Drawing
inspiration from first principles of computer organization, MAC moves away from
monolithic black-box neural architectures towards a design that encourages both
transparency and versatility. The model approaches problems by decomposing them
into a series of attention-based reasoning steps, each performed by a novel
recurrent Memory, Attention, and Composition (MAC) cell that maintains a
separation between control and memory. By stringing the cells together and
imposing structural constraints that regulate their interaction, MAC
effectively learns to perform iterative reasoning processes that are directly
inferred from the data in an end-to-end approach. We demonstrate the model&apos;s
strength, robustness and interpretability on the challenging CLEVR dataset for
visual reasoning, achieving a new state-of-the-art 98.9% accuracy, halving the
error rate of the previous best model. More importantly, we show that the model
is computationally-efficient and data-efficient, in particular requiring 5x
less data than existing models to achieve strong results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hudson_D/0/1/0/all/0/1&quot;&gt;Drew A. Hudson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Manning_C/0/1/0/all/0/1&quot;&gt;Christopher D. Manning&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.03114">
<title>Concise Fuzzy Representation of Big Graphs: a Dimensionality Reduction Approach. (arXiv:1803.03114v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1803.03114</link>
<description rdf:parseType="Literal">&lt;p&gt;The enormous amount of data to be represented using large graphs exceeds in
some cases the resources of a conventional computer. Edges in particular can
take up a considerable amount of memory as compared to the number of nodes.
However, rigorous edge storage might not always be essential to be able to draw
the needed conclusions. A similar problem takes records with many variables and
attempts to extract the most discernible features. It is said that the
&quot;dimension&quot; of this data is reduced. Following an approach with the same
objective in mind, we can map a graph representation to a k-dimensional space
and answer queries of neighboring nodes by measuring Euclidean distances. The
accuracy of our answers would decrease but would be compensated for by fuzzy
logic which gives an idea about the likelihood of error. This method allows for
reasonable representation in memory while maintaining a fair amount of useful
information. Promising preliminary results are obtained and reported by testing
the proposed approach on a number of Facebook graphs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abu_Khzam_F/0/1/0/all/0/1&quot;&gt;Faisal N. Abu-Khzam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mouawi_R/0/1/0/all/0/1&quot;&gt;Rana H. Mouawi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.03146">
<title>SentRNA: Improving computational RNA design by incorporating a prior of human design strategies. (arXiv:1803.03146v1 [q-bio.QM])</title>
<link>http://arxiv.org/abs/1803.03146</link>
<description rdf:parseType="Literal">&lt;p&gt;Designing RNA sequences that fold into specific structures and perform
desired biological functions is an emerging field in bioengineering with broad
applications from intracellular chemical catalysis to cancer therapy via
selective gene silencing. Effective RNA design requires first solving the
inverse folding problem: given a target structure, propose a sequence that
folds into that structure. Although significant progress has been made in
developing computational algorithms for this purpose, current approaches are
ineffective at designing sequences for complex targets, limiting their utility
in real-world applications. However, an alternative that has shown
significantly higher performance are human players of the online RNA design
game EteRNA. Through many rounds of gameplay, these players have developed a
collective library of &quot;human&quot; rules and strategies for RNA design that have
proven to be more effective than current computational approaches, especially
for complex targets. Here, we present an RNA design agent, SentRNA, which
consists of a fully-connected neural network trained using the $eternasolves$
dataset, a set of $1.8 x 10^4$ player-submitted sequences across 724 unique
targets. The agent first predicts an initial sequence for a target using the
trained network, and then refines that solution if necessary using a short
adaptive walk utilizing a canon of standard design moves. Through this
approach, we observe SentRNA can learn and apply human-like design strategies
to solve several complex targets previously unsolvable by any computational
approach. We thus demonstrate that incorporating a prior of human design
strategies into a computational agent can significantly boost its performance,
and suggests a new paradigm for machine-based RNA design.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Shi_J/0/1/0/all/0/1&quot;&gt;Jade Shi&lt;/a&gt; (EteRNA players), &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Das_R/0/1/0/all/0/1&quot;&gt;Rhiju Das&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Pande_V/0/1/0/all/0/1&quot;&gt;Vijay S. Pande&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.03241">
<title>Efficient Algorithms for Outlier-Robust Regression. (arXiv:1803.03241v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1803.03241</link>
<description rdf:parseType="Literal">&lt;p&gt;We give the first polynomial-time algorithm for performing linear or
polynomial regression resilient to adversarial corruptions in both examples and
labels.
&lt;/p&gt;
&lt;p&gt;Given a sufficiently large (polynomial-size) training set drawn i.i.d. from
distribution D and subsequently corrupted on some fraction of points, our
algorithm outputs a linear function whose squared error is close to the squared
error of the best-fitting linear function with respect to D, assuming that the
marginal distribution of D over the input space is \emph{certifiably
hypercontractive}. This natural property is satisfied by many well-studied
distributions such as Gaussian, strongly log-concave distributions and, uniform
distribution on the hypercube among others. We also give a simple statistical
lower bound showing that some distributional assumption is necessary to succeed
in this setting.
&lt;/p&gt;
&lt;p&gt;These results are the first of their kind and were not known to be even
information-theoretically possible prior to our work.
&lt;/p&gt;
&lt;p&gt;Our approach is based on the sum-of-squares (SoS) method and is inspired by
the recent applications of the method for parameter recovery problems in
unsupervised learning. Our algorithm can be seen as a natural convex relaxation
of the following conceptually simple non-convex optimization problem: find a
linear function and a large subset of the input corrupted sample such that the
least squares loss of the function over the subset is minimized over all
possible large subsets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Klivans_A/0/1/0/all/0/1&quot;&gt;Adam Klivans&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kothari_P/0/1/0/all/0/1&quot;&gt;Pravesh K. Kothari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meka_R/0/1/0/all/0/1&quot;&gt;Raghu Meka&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.03719">
<title>A novel model-based heuristic for energy optimal motion planning for automated driving. (arXiv:1712.03719v2 [math.OC] UPDATED)</title>
<link>http://arxiv.org/abs/1712.03719</link>
<description rdf:parseType="Literal">&lt;p&gt;Predictive motion planning is the key to achieve energy-efficient driving,
which is one of the main benefits of automated driving. Researchers have been
studying the planning of velocity trajectories, a simpler form of motion
planning, for over a decade now and many different methods are available.
Dynamic programming has shown to be the most common choice due to its numerical
background and ability to include nonlinear constraints and models. Although
planning of an optimal trajectory is done in a systematic way, dynamic
programming does not use any knowledge about the considered problem to guide
the exploration and therefore explores all possible trajectories.
&lt;/p&gt;
&lt;p&gt;A* is a search algorithm which enables using knowledge about the problem to
guide the exploration to the most promising solutions first. Knowledge has to
be represented in a form of a heuristic function, which gives an optimistic
estimate of cost for transitioning to the final state, which is not a
straightforward task. This paper presents a novel heuristics incorporating air
drag and auxiliary power as well as operational costs of the vehicle, besides
kinetic and potential energy and rolling resistance known in the literature.
Furthermore, optimal cruising velocity, which depends on vehicle aerodynamic
properties and auxiliary power, is derived. Results are compared for different
variants of heuristic functions and dynamic programming as well.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Ajanovic_Z/0/1/0/all/0/1&quot;&gt;Zlatan Ajanovic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Stolz_M/0/1/0/all/0/1&quot;&gt;Michael Stolz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Horn_M/0/1/0/all/0/1&quot;&gt;Martin Horn&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04520">
<title>Learning Robust and Adaptive Real-World Continuous Control Using Simulation and Transfer Learning. (arXiv:1802.04520v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1802.04520</link>
<description rdf:parseType="Literal">&lt;p&gt;We use model-free reinforcement learning, extensive simulation, and transfer
learning to develop a continuous control algorithm that has good zero-shot
performance in a real physical environment. We train a simulated agent to act
optimally across a set of similar environments, each with dynamics drawn from a
prior distribution. We propose that the agent is able to adjust its actions
almost immediately, based on small set of observations. This robust and
adaptive behavior is enabled by using a policy gradient algorithm with an Long
Short Term Memory (LSTM) function approximation. Finally, we train an agent to
navigate a two-dimensional environment with uncertain dynamics and noisy
observations. We demonstrate that this agent has good zero-shot performance in
a real physical environment. Our preliminary results indicate that the agent is
able to infer the environmental dynamics after only a few timesteps, and adjust
its actions accordingly.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ferguson_M/0/1/0/all/0/1&quot;&gt;M Ferguson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Law_K/0/1/0/all/0/1&quot;&gt;K. H. Law&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.02544">
<title>Visual Explanations From Deep 3D Convolutional Neural Networks for Alzheimer&apos;s Disease Classification. (arXiv:1803.02544v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1803.02544</link>
<description rdf:parseType="Literal">&lt;p&gt;We develop three efficient approaches for generating visual explanations from
3D convolutional neural networks (3D-CNNs) for Alzheimer&apos;s disease
classification. One approach conducts sensitivity analysis on hierarchical 3D
image segmentation, and the other two visualize network activations on a
spatial map. Visual checks and a quantitative localization benchmark indicate
that all approaches identify important brain parts for Alzheimer&apos;s disease
diagnosis. Comparative analysis show that the sensitivity analysis based
approach has difficulty handling loosely distributed cerebral cortex, and
approaches based on visualization of activations are constrained by the
resolution of the convolutional layer. The complementarity of these methods
improves the understanding of 3D-CNNs in Alzheimer&apos;s disease classification
from different perspectives.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1&quot;&gt;Chengliang Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rangarajan_A/0/1/0/all/0/1&quot;&gt;Anand Rangarajan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ranka_S/0/1/0/all/0/1&quot;&gt;Sanjay Ranka&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.02879">
<title>Deep Models of Interactions Across Sets. (arXiv:1803.02879v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1803.02879</link>
<description rdf:parseType="Literal">&lt;p&gt;We use deep learning to model interactions across two or more sets of
objects, such as user-movie ratings or protein-drug bindings. The canonical
representation of such interactions is a matrix (or tensor) with an
exchangeability property: the encoding&apos;s meaning is not changed by permuting
rows or columns. We argue that models should hence be Permutation Equivariant
(PE): constrained to make the same predictions across such permutations. We
present a parameter-sharing scheme and prove that it could not be made any more
expressive without violating PE. This scheme yields three benefits. First, we
demonstrate performance competitive with the state of the art on multiple
matrix completion benchmarks. Second, our models require a number of parameters
independent of the numbers of objects, and thus scale well to large datasets.
Third, models can be queried about new objects that were not available at
training time, but for which interactions have since been observed. We observed
surprisingly good generalization performance on this matrix extrapolation task,
both within domains (e.g., new users and new movies drawn from the same
distribution used for training) and even across domains (e.g., predicting music
ratings after training on movie ratings).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hartford_J/0/1/0/all/0/1&quot;&gt;Jason Hartford&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Graham_D/0/1/0/all/0/1&quot;&gt;Devon R Graham&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Leyton_Brown_K/0/1/0/all/0/1&quot;&gt;Kevin Leyton-Brown&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ravanbakhsh_S/0/1/0/all/0/1&quot;&gt;Siamak Ravanbakhsh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.02922">
<title>Fast Convergence for Stochastic and Distributed Gradient Descent in the Interpolation Limit. (arXiv:1803.02922v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1803.02922</link>
<description rdf:parseType="Literal">&lt;p&gt;Modern supervised learning techniques, particularly those using so called
deep nets, involve fitting high dimensional labelled data sets with functions
containing very large numbers of parameters. Much of this work is empirical,
and interesting phenomena have been observed that require theoretical
explanations, however the non-convexity of the loss functions complicates the
analysis. Recently it has been proposed that some of the success of these
techniques resides in the effectiveness of the simple stochastic gradient
descent algorithm in the so called interpolation limit in which all labels are
fit perfectly. This analysis is made possible since the SGD algorithm reduces
to a stochastic linear system near the interpolating minimum of the loss
function. Here we exploit this insight by analyzing a distributed algorithm for
gradient descent, also in the interpolating limit. The algorithm corresponds to
gradient descent applied to a simple penalized distributed loss function,
$L({\bf w}_1,...,{\bf w}_n) = \Sigma_i l_i({\bf w}_i) + \mu \sum_{&amp;lt;i,j&amp;gt;}|{\bf
w}_i-{\bf w}_j|^2$. Here each node is allowed its own parameter vector and
$&amp;lt;i,j&amp;gt;$ denotes edges of a connected graph defining the communication links
between nodes. It is shown that this distributed algorithm converges linearly
(ie the error reduces exponentially with iteration number), with a rate
$1-\frac{\eta}{n}\lambda_{min}(H)&amp;lt;R&amp;lt;1$ where $\lambda_{min}(H)$ is the smallest
nonzero eigenvalue of the sample covariance or the Hessian H. In contrast with
previous usage of similar penalty functions to enforce consensus between nodes,
in the interpolating limit it is not required to take the penalty parameter to
infinity for consensus to occur. The analysis further reinforces the utility of
this limit in the theoretical treatment of modern machine learning algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mitra_P/0/1/0/all/0/1&quot;&gt;Partha P Mitra&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.02933">
<title>Distributed Computation of Wasserstein Barycenters over Networks. (arXiv:1803.02933v1 [math.OC])</title>
<link>http://arxiv.org/abs/1803.02933</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a new class-optimal algorithm for the distributed computation of
Wasserstein Barycenters over networks. Assuming that each node in a graph has a
probability distribution, we prove that every node is able to reach the
barycenter of all distributions held in the network by using local interactions
compliant with the topology of the graph. We show the minimum number of
communication rounds required for the proposed method to achieve arbitrary
relative precision both in the optimality of the solution and the consensus
among all agents for undirected fixed networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Uribe_C/0/1/0/all/0/1&quot;&gt;C&amp;#xe9;sar A. Uribe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Dvinskikh_D/0/1/0/all/0/1&quot;&gt;Darina Dvinskikh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Dvurechensky_P/0/1/0/all/0/1&quot;&gt;Pavel Dvurechensky&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Gasnikov_A/0/1/0/all/0/1&quot;&gt;Alexander Gasnikov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Nedic_A/0/1/0/all/0/1&quot;&gt;Angelia Nedi&amp;#x107;&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.03104">
<title>Applicability and interpretation of the deterministic weighted cepstral distance. (arXiv:1803.03104v1 [cs.SY])</title>
<link>http://arxiv.org/abs/1803.03104</link>
<description rdf:parseType="Literal">&lt;p&gt;Quantifying similarity between data objects is an important part of modern
data science. Deciding what similarity measure to use is very application
dependent. In this paper, we combine insights from systems theory and machine
learning, and investigate the weighted cepstral distance, which was previously
defined for signals coming from ARMA models. We provide an extension of this
distance to invertible deterministic linear time invariant single input single
output models, and assess its applicability. We show that it can always be
interpreted in terms of the poles and zeros of the underlying model, and that,
in the case of stable, minimum-phase, or unstable, maximum-phase models, a
geometrical interpretation in terms of subspace angles can be given. We then
devise a method to assess stability and phase-type of the generating models,
using only input/output signal information. In this way, we prove a connection
between the extended weighted cepstral distance and a weighted cepstral model
norm. In this way, we provide a purely data-driven way to assess different
underlying dynamics of input/output signal pairs, without the need for any
system identification step. This can be useful in machine learning tasks such
as time series clustering. An iPython tutorial is published complementary to
this paper, containing implementations of the various methods and algorithms
presented here, as well as some numerical illustrations of the equivalences
proven here.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lauwers_O/0/1/0/all/0/1&quot;&gt;Oliver Lauwers&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moor_B/0/1/0/all/0/1&quot;&gt;Bart De Moor&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.03166">
<title>Aggregation using input-output trade-off. (arXiv:1803.03166v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1803.03166</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we introduce a new learning strategy based on a seminal idea
of Mojirsheibani (1999, 2000, 2002a, 2002b), who proposed a smart method for
combining several classifiers, relying on a consensus notion. In many
aggregation methods, the prediction for a new observation x is computed by
building a linear or convex combination over a collection of basic estimators
r1(x),. .. , rm(x) previously calibrated using a training data set.
Mojirsheibani proposes to compute the prediction associated to a new
observation by combining selected outputs of the training examples. The output
of a training example is selected if some kind of consensus is observed: the
predictions computed for the training example with the different machines have
to be &quot;similar&quot; to the prediction for the new observation. This approach has
been recently extended to the context of regression in Biau et al. (2016). In
the original scheme, the agreement condition is actually required to hold for
all individual estimators, which appears inadequate if there is one bad initial
estimator. In practice, a few disagreements are allowed ; for establishing the
theoretical results, the proportion of estimators satisfying the condition is
required to tend to 1. In this paper, we propose an alternative procedure,
mixing the previous consensus ideas on the predictions with the Euclidean
distance computed between entries. This may be seen as an alternative approach
allowing to reduce the effect of a possibly bad estimator in the initial list,
using a constraint on the inputs. We prove the consistency of our strategy in
classification and in regression. We also provide some numerical experiments on
simulated and real data to illustrate the benefits of this new aggregation
method. On the whole, our practical study shows that our method may perform
much better than the original combination technique, and, in particular,
exhibit far less variance. We also show on simulated examples that this
procedure mixing inputs and outputs is still robust to high dimensional inputs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Fischer_A/0/1/0/all/0/1&quot;&gt;Aur&amp;#xe9;lie Fischer&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mougeot_M/0/1/0/all/0/1&quot;&gt;Mathilde Mougeot&lt;/a&gt; (1) ((1) LPSM UMR 8001)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.03191">
<title>A Bayesian and Machine Learning approach to estimating Influence Model parameters for IM-RO. (arXiv:1803.03191v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1803.03191</link>
<description rdf:parseType="Literal">&lt;p&gt;The rise of Online Social Networks (OSNs) has caused an insurmountable amount
of interest from advertisers and researchers seeking to monopolize on its
features. Researchers aim to develop strategies for determining how information
is propagated among users within an OSN that is captured by diffusion or
influence models. We consider the influence models for the IM-RO problem, a
novel formulation to the Influence Maximization (IM) problem based on
implementing Stochastic Dynamic Programming (SDP). In contrast to existing
approaches involving influence spread and the theory of submodular functions,
the SDP method focuses on optimizing clicks and ultimately revenue to
advertisers in OSNs. Existing approaches to influence maximization have been
actively researched over the past decade, with applications to multiple fields,
however, our approach is a more practical variant to the original IM problem.
In this paper, we provide an analysis on the influence models of the IM-RO
problem by conducting experiments on synthetic and real-world datasets. We
propose a Bayesian and Machine Learning approach for estimating the parameters
of the influence models for the (Influence Maximization- Revenue Optimization)
IM-RO problem. We present a Bayesian hierarchical model and implement the
well-known Naive Bayes classifier (NBC), Decision Trees classifier (DTC) and
Random Forest classifier (RFC) on three real-world datasets. Compared to
previous approaches to estimating influence model parameters, our strategy has
the great advantage of being directly implementable in standard software
packages such as WinBUGS/OpenBUGS/JAGS and Apache Spark. We demonstrate the
efficiency and usability of our methods in terms of spreading information and
generating revenue for advertisers in the context of OSNs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lawrence_T/0/1/0/all/0/1&quot;&gt;Trisha Lawrence&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.03234">
<title>Improving Optimization in Models With Continuous Symmetry Breaking. (arXiv:1803.03234v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1803.03234</link>
<description rdf:parseType="Literal">&lt;p&gt;Many loss functions in representation learning are invariant under a
continuous symmetry transformation. As an example, consider word embeddings
(Mikolov et al., 2013), where the loss remains unchanged if we simultaneously
rotate all word and context embedding vectors. We show that representation
learning models with a continuous symmetry and a quadratic Markovian time
series prior possess so-called Goldstone modes. These are low cost deviations
from the optimum which slow down convergence of gradient descent. We use tools
from gauge theory in physics to design an optimization algorithm that solves
the slow convergence problem. Our algorithm leads to a fast decay of Goldstone
modes, to orders of magnitude faster convergence, and to more interpretable
representations, as we show for dynamic extensions of matrix factorization and
word embedding models. We present an example application, translating modern
words into historic language using a shared representation space.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bamler_R/0/1/0/all/0/1&quot;&gt;Robert Bamler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mandt_S/0/1/0/all/0/1&quot;&gt;Stephan Mandt&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1602.06701">
<title>Inference Networks for Sequential Monte Carlo in Graphical Models. (arXiv:1602.06701v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1602.06701</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce a new approach for amortizing inference in directed graphical
models by learning heuristic approximations to stochastic inverses, designed
specifically for use as proposal distributions in sequential Monte Carlo
methods. We describe a procedure for constructing and learning a structured
neural network which represents an inverse factorization of the graphical
model, resulting in a conditional density estimator that takes as input
particular values of the observed random variables, and returns an
approximation to the distribution of the latent variables. This recognition
model can be learned offline, independent from any particular dataset, prior to
performing inference. The output of these networks can be used as
automatically-learned high-quality proposal distributions to accelerate
sequential Monte Carlo across a diverse range of problem settings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Paige_B/0/1/0/all/0/1&quot;&gt;Brooks Paige&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wood_F/0/1/0/all/0/1&quot;&gt;Frank Wood&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1602.08207">
<title>Learning and Free Energies for Vector Approximate Message Passing. (arXiv:1602.08207v4 [cs.IT] UPDATED)</title>
<link>http://arxiv.org/abs/1602.08207</link>
<description rdf:parseType="Literal">&lt;p&gt;Vector approximate message passing (VAMP) is a computationally simple
approach to the recovery of a signal $\mathbf{x}$ from noisy linear
measurements $\mathbf{y}=\mathbf{Ax}+\mathbf{w}$. Like the AMP proposed by
Donoho, Maleki, and Montanari in 2009, VAMP is characterized by a rigorous
state evolution (SE) that holds under certain large random matrices and that
matches the replica prediction of optimality. But while AMP&apos;s SE holds only for
large i.i.d. sub-Gaussian $\mathbf{A}$, VAMP&apos;s SE holds under the much larger
class: right-rotationally invariant $\mathbf{A}$. To run VAMP, however, one
must specify the statistical parameters of the signal and noise. This work
combines VAMP with Expectation-Maximization to yield an algorithm, EM-VAMP,
that can jointly recover $\mathbf{x}$ while learning those statistical
parameters. The fixed points of the proposed EM-VAMP algorithm are shown to be
stationary points of a certain constrained free-energy, providing a variational
interpretation of the algorithm. Numerical simulations show that EM-VAMP is
robust to highly ill-conditioned $\mathbf{A}$ with performance nearly matching
oracle-parameter VAMP.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fletcher_A/0/1/0/all/0/1&quot;&gt;Alyson K. Fletcher&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schniter_P/0/1/0/all/0/1&quot;&gt;Philip Schniter&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1703.06856">
<title>Counterfactual Fairness. (arXiv:1703.06856v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1703.06856</link>
<description rdf:parseType="Literal">&lt;p&gt;Machine learning can impact people with legal or ethical consequences when it
is used to automate decisions in areas such as insurance, lending, hiring, and
predictive policing. In many of these scenarios, previous decisions have been
made that are unfairly biased against certain subpopulations, for example those
of a particular race, gender, or sexual orientation. Since this past data may
be biased, machine learning predictors must account for this to avoid
perpetuating or creating discriminatory practices. In this paper, we develop a
framework for modeling fairness using tools from causal inference. Our
definition of counterfactual fairness captures the intuition that a decision is
fair towards an individual if it is the same in (a) the actual world and (b) a
counterfactual world where the individual belonged to a different demographic
group. We demonstrate our framework on a real-world problem of fair prediction
of success in law school.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kusner_M/0/1/0/all/0/1&quot;&gt;Matt J. Kusner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Loftus_J/0/1/0/all/0/1&quot;&gt;Joshua R. Loftus&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Russell_C/0/1/0/all/0/1&quot;&gt;Chris Russell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Silva_R/0/1/0/all/0/1&quot;&gt;Ricardo Silva&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1706.03779">
<title>General Latent Feature Models for Heterogeneous Datasets. (arXiv:1706.03779v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1706.03779</link>
<description rdf:parseType="Literal">&lt;p&gt;Latent feature modeling allows capturing the latent structure responsible for
generating the observed properties of a set of objects. It is often used to
make predictions either for new values of interest or missing information in
the original data, as well as to perform data exploratory analysis. However,
although there is an extensive literature on latent feature models for
homogeneous datasets, where all the attributes that describe each object are of
the same (continuous or discrete) nature, there is a lack of work on latent
feature modeling for heterogeneous databases. In this paper, we introduce a
general Bayesian nonparametric latent feature model suitable for heterogeneous
datasets, where the attributes describing each object can be either discrete,
continuous or mixed variables. The proposed model presents several important
properties. First, it accounts for heterogeneous data while keeping the
properties of conjugate models, which allow us to infer the model in linear
time with respect to the number of objects and attributes. Second, its Bayesian
nonparametric nature allows us to automatically infer the model complexity from
the data, i.e., the number of features necessary to capture the latent
structure in the data. Third, the latent features in the model are
binary-valued variables, easing the interpretability of the obtained latent
features in data exploratory analysis. We show the flexibility of the proposed
model by solving both prediction and data analysis tasks on several real-world
datasets. Moreover, a software package of the GLFM is publicly available for
other researcher to use and improve it.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Valera_I/0/1/0/all/0/1&quot;&gt;Isabel Valera&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pradier_M/0/1/0/all/0/1&quot;&gt;Melanie F. Pradier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lomeli_M/0/1/0/all/0/1&quot;&gt;Maria Lomeli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ghahramani_Z/0/1/0/all/0/1&quot;&gt;Zoubin Ghahramani&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1706.08344">
<title>High-dimensional classification by sparse logistic regression. (arXiv:1706.08344v2 [math.ST] UPDATED)</title>
<link>http://arxiv.org/abs/1706.08344</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider high-dimensional binary classification by sparse logistic
regression. We propose a model/feature selection procedure based on penalized
maximum likelihood with a complexity penalty on the model size and derive the
non-asymptotic bounds for the resulting misclassification excess risk. The
bounds can be reduced under the additional low-noise condition. The proposed
complexity penalty is remarkably related to the VC-dimension of a set of sparse
linear classifiers. Implementation of any complexity penalty-based criterion,
however, requires a combinatorial search over all possible models. To find a
model selection procedure computationally feasible for high-dimensional data,
we extend the Slope estimator for logistic regression and show that under an
additional weighted restricted eigenvalue condition it is rate-optimal in the
minimax sense.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Abramovich_F/0/1/0/all/0/1&quot;&gt;Felix Abramovich&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Grinshtein_V/0/1/0/all/0/1&quot;&gt;Vadim Grinshtein&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.09513">
<title>Maximum Principle Based Algorithms for Deep Learning. (arXiv:1710.09513v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1710.09513</link>
<description rdf:parseType="Literal">&lt;p&gt;The continuous dynamical system approach to deep learning is explored in
order to devise alternative frameworks for training algorithms. Training is
recast as a control problem and this allows us to formulate necessary
optimality conditions in continuous time using the Pontryagin&apos;s maximum
principle (PMP). A modification of the method of successive approximations is
then used to solve the PMP, giving rise to an alternative training algorithm
for deep learning. This approach has the advantage that rigorous error
estimates and convergence results can be established. We also show that it may
avoid some pitfalls of gradient-based methods, such as slow convergence on flat
landscapes near saddle points. Furthermore, we demonstrate that it obtains
favorable initial convergence rate per-iteration, provided Hamiltonian
maximization can be efficiently carried out - a step which is still in need of
improvement. Overall, the approach opens up new avenues to attack problems
associated with deep learning, such as trapping in slow manifolds and
inapplicability of gradient-based methods for discrete trainable variables.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1&quot;&gt;Qianxiao Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1&quot;&gt;Long Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tai_C/0/1/0/all/0/1&quot;&gt;Cheng Tai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+E_W/0/1/0/all/0/1&quot;&gt;Weinan E&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.07871">
<title>Autoencoder Node Saliency: Selecting Relevant Latent Representations. (arXiv:1711.07871v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1711.07871</link>
<description rdf:parseType="Literal">&lt;p&gt;The autoencoder is an artificial neural network model that learns hidden
representations of unlabeled data. With a linear transfer function it is
similar to the principal component analysis (PCA). While both methods use
weight vectors for linear transformations, the autoencoder does not come with
any indication similar to the eigenvalues in PCA that are paired with the
eigenvectors. We propose a novel supervised node saliency (SNS) method that
ranks the hidden nodes by comparing class distributions of latent
representations against a fixed reference distribution. The latent
representations of a hidden node can be described using a one-dimensional
histogram. We apply normalized entropy difference (NED) to measure the
&quot;interestingness&quot; of the histograms, and conclude a property for NED values to
identify a good classifying node. By applying our methods to real data sets, we
demonstrate the ability of SNS to explain what the trained autoencoders have
learned.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fan_Y/0/1/0/all/0/1&quot;&gt;Ya Ju Fan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.08664">
<title>Mixtures of Matrix Variate Bilinear Factor Analyzers. (arXiv:1712.08664v2 [stat.ME] UPDATED)</title>
<link>http://arxiv.org/abs/1712.08664</link>
<description rdf:parseType="Literal">&lt;p&gt;Over the years data has become increasingly higher dimensional, which has
prompted an increased need for dimension reduction techniques. This is perhaps
especially true for clustering (unsupervised classification) as well as
semi-supervised and supervised classification. Although dimension reduction in
the area of clustering for multivariate data has been quite thoroughly
discussed in the literature, there is relatively little work in the area of
three way, or matrix variate, data. Herein, we develop a mixture of matrix
variate bilinear factor analyzers (MMVBFA) model for use in clustering
high-dimensional matrix variate data. This work can be considered both the
first matrix variate bilinear factor analyzers model as well as the first
MMVBFA model. Parameter estimation is discussed, and the MMVBFA model is
illustrated using simulated and real data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gallaugher_M/0/1/0/all/0/1&quot;&gt;Michael P.B. Gallaugher&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+McNicholas_P/0/1/0/all/0/1&quot;&gt;Paul D. McNicholas&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.10110">
<title>Beyond Keywords and Relevance: A Personalized Ad Retrieval Framework in E-Commerce Sponsored Search. (arXiv:1712.10110v3 [cs.IR] UPDATED)</title>
<link>http://arxiv.org/abs/1712.10110</link>
<description rdf:parseType="Literal">&lt;p&gt;On most sponsored search platforms, advertisers bid on some keywords for
their advertisements (ads). Given a search request, ad retrieval module
rewrites the query into bidding keywords, and uses these keywords as keys to
select Top N ads through inverted indexes. In this way, an ad will not be
retrieved even if queries are related when the advertiser does not bid on
corresponding keywords. Moreover, most ad retrieval approaches regard rewriting
and ad-selecting as two separated tasks, and focus on boosting relevance
between search queries and ads. Recently, in e-commerce sponsored search more
and more personalized information has been introduced, such as user profiles,
long-time and real-time clicks. Personalized information makes ad retrieval
able to employ more elements (e.g. real-time clicks) as search signals and
retrieval keys, however it makes ad retrieval more difficult to measure ads
retrieved through different signals. To address these problems, we propose a
novel ad retrieval framework beyond keywords and relevance in e-commerce
sponsored search. Firstly, we employ historical ad click data to initialize a
hierarchical network representing signals, keys and ads, in which personalized
information is introduced. Then we train a model on top of the hierarchical
network by learning the weights of edges. Finally we select the best edges
according to the model, boosting RPM/CTR. Experimental results on our
e-commerce platform demonstrate that our ad retrieval framework achieves good
performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yan_S/0/1/0/all/0/1&quot;&gt;Su Yan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_W/0/1/0/all/0/1&quot;&gt;Wei Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_T/0/1/0/all/0/1&quot;&gt;Tianshu Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiao_D/0/1/0/all/0/1&quot;&gt;Daorui Xiao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_X/0/1/0/all/0/1&quot;&gt;Xu Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_B/0/1/0/all/0/1&quot;&gt;Bo Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_K/0/1/0/all/0/1&quot;&gt;Kaipeng Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.03848">
<title>Region Detection in Markov Random Fields: Gaussian Case. (arXiv:1802.03848v5 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1802.03848</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work we consider the problem of model selection in Gaussian Markov
fields in the sample deficient scenario. The benchmark information-theoretic
results in the case of d-regular graphs require the number of samples to be at
least proportional to the logarithm of the number of vertices to allow
consistent graph recovery. When the number of samples is less than this amount,
reliable detection of all edges is impossible. In many applications, it is more
important to learn the distribution of the edge (coupling) parameters over the
network than the specific locations of the edges. Assuming that the entire
graph can be partitioned into a number of spatial regions with similar edge
parameters and reasonably regular boundaries, we develop new
information-theoretic sample complexity bounds and show that even bounded
number of samples can be enough to consistently recover these regions. We also
introduce and analyze an efficient region growing algorithm capable of
recovering the regions with high accuracy. We show that it is consistent and
demonstrate its performance benefits in synthetic simulations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Soloveychik_I/0/1/0/all/0/1&quot;&gt;Ilya Soloveychik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tarokh_V/0/1/0/all/0/1&quot;&gt;Vahid Tarokh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.01814">
<title>Norm matters: efficient and accurate normalization schemes in deep networks. (arXiv:1803.01814v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1803.01814</link>
<description rdf:parseType="Literal">&lt;p&gt;Over the past few years batch-normalization has been commonly used in deep
networks, allowing faster training and high performance for a wide variety of
applications. However, the reasons behind its merits remained unanswered, with
several shortcomings that hindered its use for certain tasks. In this work we
present a novel view on the purpose and function of normalization methods and
weight-decay, as tools to decouple weights&apos; norm from the underlying optimized
objective. We also improve the use of weight-normalization and show the
connection between practices such as normalization, weight decay and
learning-rate adjustments. Finally, we suggest several alternatives to the
widely used $L^2$ batch-norm, using normalization in $L^1$ and $L^\infty$
spaces that can substantially improve numerical stability in low-precision
implementations as well as provide computational and memory benefits. We
demonstrate that such methods enable the first batch-norm alternative to work
for half-precision implementations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hoffer_E/0/1/0/all/0/1&quot;&gt;Elad Hoffer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Banner_R/0/1/0/all/0/1&quot;&gt;Ron Banner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Golan_I/0/1/0/all/0/1&quot;&gt;Itay Golan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Soudry_D/0/1/0/all/0/1&quot;&gt;Daniel Soudry&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.02726">
<title>Stochastic Block Models with Multiple Continuous Attributes. (arXiv:1803.02726v1 [cs.SI] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1803.02726</link>
<description rdf:parseType="Literal">&lt;p&gt;The stochastic block model (SBM) is a probabilistic model for community
structure in networks. Typically, only the adjacency matrix is used to perform
SBM parameter inference. In this paper, we consider circumstances in which
nodes have an associated vector of continuous attributes that are also used to
learn the node-to-community assignments and corresponding SBM parameters. While
this assumption is not realistic for every application, our model assumes that
the attributes associated with the nodes in a network&apos;s community can be
described by a common multivariate Gaussian model. In this augmented,
attributed SBM, the objective is to simultaneously learn the SBM connectivity
probabilities with the multivariate Gaussian parameters describing each
community. While there are recent examples in the literature that combine
connectivity and attribute information to inform community detection, our model
is the first augmented stochastic block model to handle multiple continuous
attributes. This provides the flexibility in biological data to, for example,
augment connectivity information with continuous measurements from multiple
experimental modalities. Because the lack of labeled network data often makes
community detection results difficult to validate, we highlight the usefulness
of our model for two network prediction tasks: link prediction and
collaborative filtering. As a result of fitting this attributed stochastic
block model, one can predict the attribute vector or connectivity patterns for
a new node in the event of the complementary source of information
(connectivity or attributes, respectively). We also highlight two biological
examples where the attributed stochastic block model provides satisfactory
performance in the link prediction and collaborative filtering tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stanley_N/0/1/0/all/0/1&quot;&gt;Natalie Stanley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bonacci_T/0/1/0/all/0/1&quot;&gt;Thomas Bonacci&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kwitt_R/0/1/0/all/0/1&quot;&gt;Roland Kwitt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Niethammer_M/0/1/0/all/0/1&quot;&gt;Marc Niethammer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mucha_P/0/1/0/all/0/1&quot;&gt;Peter J. Mucha&lt;/a&gt;</dc:creator>
</item></rdf:RDF>