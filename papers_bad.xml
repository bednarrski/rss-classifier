<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Boring papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Bad Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-05-22T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08249"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08289"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08303"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08311"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08545"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08594"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08680"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08709"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08751"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.10067"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.01221"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08256"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08263"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08313"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08322"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08456"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08468"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08588"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08645"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08698"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08743"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08768"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1706.00359"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.00455"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.10314"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.06957"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04240"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.01987"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07830"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08195"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08239"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08244"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08254"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08268"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08273"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08306"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08308"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08309"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08321"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08327"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08331"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08336"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08342"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08349"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08395"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08498"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08527"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08531"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08539"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08562"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08565"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08571"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08593"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08610"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08622"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08638"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08647"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08651"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08665"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08672"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08727"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08728"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1604.04706"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1605.09499"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1607.00696"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.05289"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.07616"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.05241"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.04126"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.05134"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.06302"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.08289"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04034"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05451"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06104"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06847"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08012"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08249"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.10988"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.00915"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.03463"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07777"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1805.08249">
<title>Classifier-agnostic saliency map extraction. (arXiv:1805.08249v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.08249</link>
<description rdf:parseType="Literal">&lt;p&gt;We argue for the importance of decoupling saliency map extraction from any
specific classifier. We propose a practical algorithm to train a
classifier-agnostic saliency mapping by simultaneously training a classifier
and a saliency mapping. The proposed algorithm is motivated as finding the
mapping that is not strongly coupled with any specific classifier. We
qualitatively and quantitatively evaluate the proposed approach and verify that
it extracts higher quality saliency maps compared to the existing approaches
that are dependent on a fixed classifier. The proposed approach performs well
even on images containing objects from classes unseen during training.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zolna_K/0/1/0/all/0/1&quot;&gt;Konrad Zolna&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Geras_K/0/1/0/all/0/1&quot;&gt;Krzysztof J. Geras&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cho_K/0/1/0/all/0/1&quot;&gt;Kyunghyun Cho&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08289">
<title>Measuring and regularizing networks in function space. (arXiv:1805.08289v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1805.08289</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural network optimization is often conceptualized as optimizing parameters,
but it is ultimately a matter of optimizing a function defined by inputs and
outputs. However, little work has empirically evaluated network optimization in
the space of possible functions and much analysis relies on Lipschitz bounds.
Here, we measure the behavior of several networks in an $L^2$ Hilbert space.
Lipschitz bounds appear reasonable in late optimization but not the beginning.
We also observe that the function continues to change even after test error
saturates. In light of this we propose a learning rule, Hilbert-constrained
gradient descent (HCGD), that regularizes the distance a network can travel
through $L^2$-space in any one update. HCGD should increase generalization if
it is important that single updates minimally change the output function.
Experiments show that HCGD reduces exploration in function space and often, but
not always, improves generalization. We connect this idea to the natural
gradient, which can also be derived from penalizing changes in the outputs. We
conclude that decreased movement in function space is an important
consideration in training neural networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Benjamin_A/0/1/0/all/0/1&quot;&gt;Ari S. Benjamin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rolnick_D/0/1/0/all/0/1&quot;&gt;David Rolnick&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kording_K/0/1/0/all/0/1&quot;&gt;Konrad Kording&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08303">
<title>Compression of Deep Convolutional Neural Networks under Joint Sparsity Constraints. (arXiv:1805.08303v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1805.08303</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the optimization of deep convolutional neural networks (CNNs)
such that they provide good performance while having reduced complexity if
deployed on either conventional systems utilizing spatial-domain convolution or
lower complexity systems designed for Winograd convolution. Furthermore, we
explore the universal quantization and compression of these networks. In
particular, the proposed framework produces one compressed model whose
convolutional filters are sparse not only in the spatial domain but also in the
Winograd domain. Hence, one compressed model can be deployed universally on any
platform, without need for re-training on the deployed platform, and the
sparsity of its convolutional filters can be exploited for further complexity
reduction in either domain. To get a better compression ratio, the sparse model
is compressed in the spatial domain which has a less number of parameters. From
our experiments, we obtain $24.2\times$, $47.7\times$ and $35.4\times$
compressed models for ResNet-18, AlexNet and CT-SRCNN, while their
computational complexity is also reduced by $4.5\times$, $5.1\times$ and
$23.5\times$, respectively.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Choi_Y/0/1/0/all/0/1&quot;&gt;Yoojin Choi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+El_Khamy_M/0/1/0/all/0/1&quot;&gt;Mostafa El-Khamy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1&quot;&gt;Jungwon Lee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08311">
<title>AgileNet: Lightweight Dictionary-based Few-shot Learning. (arXiv:1805.08311v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.08311</link>
<description rdf:parseType="Literal">&lt;p&gt;The success of deep learning models is heavily tied to the use of massive
amount of labeled data and excessively long training time. With the emergence
of intelligent edge applications that use these models, the critical challenge
is to obtain the same inference capability on a resource-constrained device
while providing adaptability to cope with the dynamic changes in the data. We
propose AgileNet, a novel lightweight dictionary-based few-shot learning
methodology which provides reduced complexity deep neural network for efficient
execution at the edge while enabling low-cost updates to capture the dynamics
of the new data. Evaluations of state-of-the-art few-shot learning benchmarks
demonstrate the superior accuracy of AgileNet compared to prior arts.
Additionally, AgileNet is the first few-shot learning approach that prevents
model updates by eliminating the knowledge obtained from the primary training.
This property is ensured through the dictionaries learned by our novel
end-to-end structured decomposition, which also reduces the memory footprint
and computation complexity to match the edge device constraints.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghasemzadeh_M/0/1/0/all/0/1&quot;&gt;Mohammad Ghasemzadeh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_F/0/1/0/all/0/1&quot;&gt;Fang Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rouhani_B/0/1/0/all/0/1&quot;&gt;Bita Darvish Rouhani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koushanfar_F/0/1/0/all/0/1&quot;&gt;Farinaz Koushanfar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1&quot;&gt;Ke Huang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08545">
<title>A Recurrent Convolutional Neural Network Approach for Sensorless Force Estimation in Robotic Surgery. (arXiv:1805.08545v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1805.08545</link>
<description rdf:parseType="Literal">&lt;p&gt;Providing force feedback as relevant information in current Robot-Assisted
Minimally Invasive Surgery systems constitutes a technological challenge due to
the constraints imposed by the surgical environment. In this context,
Sensorless Force Estimation techniques represent a potential solution, enabling
to sense the interaction forces between the surgical instruments and
soft-tissues. Specifically, if visual feedback is available for observing
soft-tissues&apos; deformation, this feedback can be used to estimate the forces
applied to these tissues. To this end, a force estimation model, based on
Convolutional Neural Networks and Long-Short Term Memory networks, is proposed
in this work. This model is designed to process both, the spatiotemporal
information present in video sequences and the temporal structure of tool data
(the surgical tool-tip trajectory and its grasping status). A series of
analyses are carried out to reveal the advantages of the proposal and the
challenges that remain for real applications. This research work focuses on two
surgical task scenarios, referred to as pushing and pulling tissue. For these
two scenarios, different input data modalities and their effect on the force
estimation quality are investigated. These input data modalities are tool data,
video sequences and a combination of both. The results suggest that the force
estimation quality is better when both, the tool data and video sequences, are
processed by the neural network model. Moreover, this study reveals the need
for a loss function, designed to promote the modeling of smooth and sharp
details found in force signals. Finally, the results show that the modeling of
forces due to pulling tasks is more challenging than for the simplest pushing
actions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Marban_A/0/1/0/all/0/1&quot;&gt;Arturo Marban&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Srinivasan_V/0/1/0/all/0/1&quot;&gt;Vignesh Srinivasan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Samek_W/0/1/0/all/0/1&quot;&gt;Wojciech Samek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fernandez_J/0/1/0/all/0/1&quot;&gt;Josep Fern&amp;#xe1;ndez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Casals_A/0/1/0/all/0/1&quot;&gt;Alicia Casals&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08594">
<title>Neural Generative Models for Global Optimization with Gradients. (arXiv:1805.08594v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1805.08594</link>
<description rdf:parseType="Literal">&lt;p&gt;The aim of global optimization is to find the global optimum of arbitrary
classes of functions, possibly highly multimodal ones. In this paper we focus
on the subproblem of global optimization for differentiable functions and we
propose an Evolutionary Search-inspired solution where we model point search
distributions via Generative Neural Networks. This approach enables us to model
diverse and complex search distributions based on which we can efficiently
explore complicated objective landscapes. In our experiments we show the
practical superiority of our algorithm versus classical Evolutionary Search and
gradient-based solutions on a benchmark set of multimodal functions, and
demonstrate how it can be used to accelerate Bayesian Optimization with
Gaussian Processes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Faury_L/0/1/0/all/0/1&quot;&gt;Louis Faury&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vasile_F/0/1/0/all/0/1&quot;&gt;Flavian Vasile&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Calauzenes_C/0/1/0/all/0/1&quot;&gt;Cl&amp;#xe9;ment Calauz&amp;#xe8;nes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fercoq_O/0/1/0/all/0/1&quot;&gt;Oliver Fercoq&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08680">
<title>A Parameter Estimation of Fractional Order Gray Model Based on Adaptive Dynamic Cat Swarm Algorithm. (arXiv:1805.08680v1 [math.OC])</title>
<link>http://arxiv.org/abs/1805.08680</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we utilize ADCSO (Adaptive Dynamic Cat Swarm Optimization) to
estimate the parameters of Fractional Order Grey Model. The parameters of
Fractional Order Grey Model affect the prediction accuracy of the model. In
order to solve the problem that general swarm intelligence algorithms easily
fall into the local optimum and optimize the accuracy of the model, ADCSO is
utilized to reduce the error of the model. Experimental results for the data of
container throughput of Wuhan Port and marine capture productions of Zhejiang
Province show that the different parameter values affect the prediction
results. The parameters estimated by ADCSO make the prediction error of the
model smaller and the convergence speed higher, and it is not easy to fall into
the local convergence compared with PSO (Particle Swarm Optimization) and LSM
(Least Square Method). The feasibility and advantage of ADCSO for the parameter
estimation of Fractional Order Grey Model are verified.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Lin_B/0/1/0/all/0/1&quot;&gt;Binyan Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Gao_F/0/1/0/all/0/1&quot;&gt;Fei Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Wang_M/0/1/0/all/0/1&quot;&gt;Meng Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Xiong_Y/0/1/0/all/0/1&quot;&gt;Yuyao Xiong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Li_A/0/1/0/all/0/1&quot;&gt;Ansheng Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08709">
<title>A Simple Cache Model for Image Recognition. (arXiv:1805.08709v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1805.08709</link>
<description rdf:parseType="Literal">&lt;p&gt;Training large-scale image recognition models is computationally expensive.
This raises the question of whether there might be simple ways to improve the
test performance of an already trained model without having to re-train or even
fine-tune it with new data. Here, we show that, surprisingly, this is indeed
possible. The key observation we make is that the layers of a deep network
close to the output layer contain independent, easily extractable
class-relevant information that is not contained in the output layer itself. We
propose to extract this extra class-relevant information using a simple
key-value cache memory to improve the classification performance of the model
at test time. Our cache memory is directly inspired by a similar cache model
previously proposed for language modeling (Grave et al., 2017). This cache
component does not require any training or fine-tuning; it can be applied to
any pre-trained model and, by properly setting only two hyper-parameters, leads
to significant improvements in its classification performance. Improvements are
observed across several architectures and datasets. In the cache component,
using features extracted from layers close to the output (but not from the
output layer itself) as keys leads to the largest improvements. Concatenating
features from multiple layers to form keys can further improve performance over
using single-layer features as keys. The cache component also has a
regularizing effect, a simple consequence of which is that it substantially
increases the robustness of models against adversarial attacks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Orhan_A/0/1/0/all/0/1&quot;&gt;A. Emin Orhan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08751">
<title>Fake News Detection with Deep Diffusive Network Model. (arXiv:1805.08751v1 [cs.SI])</title>
<link>http://arxiv.org/abs/1805.08751</link>
<description rdf:parseType="Literal">&lt;p&gt;In recent years, due to the booming development of online social networks,
fake news for various commercial and political purposes has been appearing in
large numbers and widespread in the online world. With deceptive words, online
social network users can get infected by these online fake news easily, which
has brought about tremendous effects on the offline society already. An
important goal in improving the trustworthiness of information in online social
networks is to identify the fake news timely. This paper aims at investigating
the principles, methodologies and algorithms for detecting fake news articles,
creators and subjects from online social networks and evaluating the
corresponding performance. This paper addresses the challenges introduced by
the unknown characteristics of fake news and diverse connections among news
articles, creators and subjects. Based on a detailed data analysis, this paper
introduces a novel automatic fake news credibility inference model, namely
FakeDetector. Based on a set of explicit and latent features extracted from the
textual information, FakeDetector builds a deep diffusive network model to
learn the representations of news articles, creators and subjects
simultaneously. Extensive experiments have been done on a real-world fake news
dataset to compare FakeDetector with several state-of-the-art models, and the
experimental results have demonstrated the effectiveness of the proposed model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Jiawei Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cui_L/0/1/0/all/0/1&quot;&gt;Limeng Cui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1&quot;&gt;Yanjie Fu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gouza_F/0/1/0/all/0/1&quot;&gt;Fisher B. Gouza&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.10067">
<title>WSNet: Compact and Efficient Networks Through Weight Sampling. (arXiv:1711.10067v3 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1711.10067</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a new approach and a novel architecture, termed WSNet, for
learning compact and efficient deep neural networks. Existing approaches
conventionally learn full model parameters independently and then compress them
via ad hoc processing such as model pruning or filter factorization.
Alternatively, WSNet proposes learning model parameters by sampling from a
compact set of learnable parameters, which naturally enforces {parameter
sharing} throughout the learning process. We demonstrate that such a novel
weight sampling approach (and induced WSNet) promotes both weights and
computation sharing favorably. By employing this method, we can more
efficiently learn much smaller networks with competitive performance compared
to baseline networks with equal numbers of convolution filters. Specifically,
we consider learning compact and efficient 1D convolutional neural networks for
audio classification. Extensive experiments on multiple audio classification
datasets verify the effectiveness of WSNet. Combined with weight quantization,
the resulted models are up to 180 times smaller and theoretically up to 16
times faster than the well-established baselines, without noticeable
performance drop.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jin_X/0/1/0/all/0/1&quot;&gt;Xiaojie Jin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1&quot;&gt;Yingzhen Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_N/0/1/0/all/0/1&quot;&gt;Ning Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1&quot;&gt;Jianchao Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jojic_N/0/1/0/all/0/1&quot;&gt;Nebojsa Jojic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1&quot;&gt;Jiashi Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yan_S/0/1/0/all/0/1&quot;&gt;Shuicheng Yan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.01221">
<title>Design and Analysis of Diversity-Based Parent Selection Schemes for Speeding Up Evolutionary Multi-objective Optimisation. (arXiv:1805.01221v2 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1805.01221</link>
<description rdf:parseType="Literal">&lt;p&gt;Parent selection in evolutionary algorithms for multi-objective optimisation
is usually performed by dominance mechanisms or indicator functions that prefer
non-dominated points. We propose to refine the parent selection on evolutionary
multi-objective optimisation with diversity-based metrics. The aim is to focus
on individuals with a high diversity contribution located in poorly explored
areas of the search space, so the chances of creating new non-dominated
individuals are better than in highly populated areas. We show by means of
rigorous runtime analysis that the use of diversity-based parent selection
mechanisms in the Simple Evolutionary Multi-objective Optimiser (SEMO) and
Global SEMO for the well known bi-objective functions ${\rm O{\small
NE}M{\small IN}M{\small AX}}$ and ${\rm LOTZ}$ can significantly improve their
performance. Our theoretical results are accompanied by experimental studies
that show a correspondence between theory and empirical results and motivate
further theoretical investigations in terms of stagnation. We show that
stagnation might occur when favouring individuals with a high diversity
contribution in the parent selection step and provide a discussion on which
scheme to use for more complex problems based on our theoretical and
experimental results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Osuna_E/0/1/0/all/0/1&quot;&gt;Edgar Covantes Osuna&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_W/0/1/0/all/0/1&quot;&gt;Wanru Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Neumann_F/0/1/0/all/0/1&quot;&gt;Frank Neumann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sudholt_D/0/1/0/all/0/1&quot;&gt;Dirk Sudholt&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08256">
<title>Evolving Real-Time Heuristics Search Algorithms with Building Blocks. (arXiv:1805.08256v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1805.08256</link>
<description rdf:parseType="Literal">&lt;p&gt;The research area of real-time heuristics search has produced quite many
algorithms. In the landscape of real-time heuristics search research, it is not
rare to find that an algorithm X that appears to perform better than algorithm
Y on a group of problems, performed worse than Y for another group of problems.
If these published algorithms are combined to generate a more powerful space of
algorithms, then that novel space of algorithms may solve a distribution of
problems more efficiently. Based on this intuition, a recent work Bulitko 2016
has defined the task of finding a combination of heuristics search algorithms
as a survival task. In this evolutionary approach, a space of algorithms is
defined over a set of building blocks published algorithms and a simulated
evolution is used to recombine these building blocks to find out the best
algorithm from that space of algorithms.
&lt;/p&gt;
&lt;p&gt;In this paper, we extend the set of building blocks by adding one published
algorithm, namely lookahead based A-star shaped local search space generation
method from LSSLRTA-star, plus an unpublished novel strategy to generate local
search space with Greedy Best First Search. Then we perform experiments in the
new space of algorithms, which show that the best algorithms selected by the
evolutionary process have the following property: the deeper is the lookahead
depth of an algorithm, the lower is its suboptimality and scrubbing complexity.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chowdhury_M/0/1/0/all/0/1&quot;&gt;Md Solimul Chowdhury&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Silva_V/0/1/0/all/0/1&quot;&gt;Victor Silva&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08263">
<title>Planning to Give Information in Partially Observed Domains with a Learned Weighted Entropy Model. (arXiv:1805.08263v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1805.08263</link>
<description rdf:parseType="Literal">&lt;p&gt;In many real-world robotic applications, an autonomous agent must act within
and explore a partially observed environment that is unobserved by its human
teammate. We consider such a setting in which the agent can, while acting,
transmit declarative information to the human that helps them understand
aspects of this unseen environment. Importantly, we should expect the human to
have preferences about what information they are given and when they are given
it. In this work, we adopt an information-theoretic view of the human&apos;s
preferences: the human scores a piece of information as a function of the
induced reduction in weighted entropy of their belief about the environment
state. We formulate this setting as a POMDP and give a practical algorithm for
solving it approximately. Then, we give an algorithm that allows the agent to
sample-efficiently learn the human&apos;s preferences online. Finally, we describe
an extension in which the human&apos;s preferences are time-varying. We validate our
approach experimentally in two planning domains: a 2D robot mining task and a
more realistic 3D robot fetching task.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chitnis_R/0/1/0/all/0/1&quot;&gt;Rohan Chitnis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kaelbling_L/0/1/0/all/0/1&quot;&gt;Leslie Pack Kaelbling&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lozano_Perez_T/0/1/0/all/0/1&quot;&gt;Tom&amp;#xe1;s Lozano-P&amp;#xe9;rez&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08313">
<title>Learning Safe Policies with Expert Guidance. (arXiv:1805.08313v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.08313</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a framework for ensuring safe behavior of a reinforcement learning
agent when the reward function may be difficult to specify. In order to do
this, we rely on the existence of demonstrations from expert policies, and we
provide a theoretical framework for the agent to optimize in the space of
rewards consistent with its existing knowledge. We propose two methods to solve
the resulting optimization: an exact ellipsoid-based method and a method in the
spirit of the &quot;follow-the-perturbed-leader&quot; algorithm. Our experiments
demonstrate the behavior of our algorithm in both discrete and continuous
problems. The trained agent safely avoids states with potential negative
effects while imitating the behavior of the expert in the other states.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1&quot;&gt;Jessie Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1&quot;&gt;Fa Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Precup_D/0/1/0/all/0/1&quot;&gt;Doina Precup&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cai_Y/0/1/0/all/0/1&quot;&gt;Yang Cai&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08322">
<title>Teaching Multiple Concepts to Forgetful Learners. (arXiv:1805.08322v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1805.08322</link>
<description rdf:parseType="Literal">&lt;p&gt;How can we help a forgetful learner learn multiple concepts within a limited
time frame? For long-term learning, it is crucial to devise teaching strategies
that leverage the underlying forgetting mechanisms of the learners. In this
paper, we cast the problem of adaptively teaching a forgetful learner as a
novel discrete optimization problem, where we seek to optimize a natural
objective function that characterizes the learner&apos;s expected performance
throughout the teaching session. We then propose a simple greedy teaching
strategy and derive strong performance guarantees based on two intuitive
data-dependent parameters, which characterize the degree of diminishing returns
of teaching each concept. We show that, given some assumptions of the learner&apos;s
memory model, one can efficiently compute the performance bounds. Furthermore,
we identify parameter settings of our memory models where greedy is guaranteed
to achieve high performance. We have deployed our approach in two concrete
applications, namely (1) an educational app for online vocabulary teaching and
(2) an app for teaching novices how to recognize bird species. We demonstrate
the effectiveness of our algorithm using simulations along with user studies.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hunziker_A/0/1/0/all/0/1&quot;&gt;Anette Hunziker&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yuxin Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aodha_O/0/1/0/all/0/1&quot;&gt;Oisin Mac Aodha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rodriguez_M/0/1/0/all/0/1&quot;&gt;Manuel Gomez Rodriguez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Krause_A/0/1/0/all/0/1&quot;&gt;Andreas Krause&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Perona_P/0/1/0/all/0/1&quot;&gt;Pietro Perona&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yue_Y/0/1/0/all/0/1&quot;&gt;Yisong Yue&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singla_A/0/1/0/all/0/1&quot;&gt;Adish Singla&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08456">
<title>QBF as an Alternative to Courcelle&apos;s Theorem. (arXiv:1805.08456v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1805.08456</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose reductions to quantified Boolean formulas (QBF) as a new approach
to showing fixed-parameter linear algorithms for problems parameterized by
treewidth. We demonstrate the feasibility of this approach by giving new
algorithms for several well-known problems from artificial intelligence that
are in general complete for the second level of the polynomial hierarchy. By
reduction from QBF we show that all resulting algorithms are essentially
optimal in their dependence on the treewidth. Most of the problems that we
consider were already known to be fixed-parameter linear by using Courcelle&apos;s
Theorem or dynamic programming, but we argue that our approach has clear
advantages over these techniques: on the one hand, in contrast to Courcelle&apos;s
Theorem, we get concrete and tight guarantees for the runtime dependence on the
treewidth. On the other hand, we avoid tedious dynamic programming and, after
showing some normalization results for CNF-formulas, our upper bounds often
boil down to a few lines.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lampis_M/0/1/0/all/0/1&quot;&gt;Michael Lampis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mengel_S/0/1/0/all/0/1&quot;&gt;Stefan Mengel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mitsou_V/0/1/0/all/0/1&quot;&gt;Valia Mitsou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08468">
<title>Rank Minimization on Tensor Ring: A New Paradigm in Scalable Tensor Decomposition and Completion. (arXiv:1805.08468v1 [cs.NA])</title>
<link>http://arxiv.org/abs/1805.08468</link>
<description rdf:parseType="Literal">&lt;p&gt;In low-rank tensor completion tasks, due to the underlying multiple
large-scale singular value decomposition (SVD) operations and rank selection
problem of the traditional methods, they suffer from high computational cost
and high sensitivity of model complexity. In this paper, taking advantages of
high compressibility of the recently proposed tensor ring (TR) decomposition,
we propose a new model for tensor completion problem. This is achieved through
introducing convex surrogates of tensor low-rank assumption on latent tensor
ring factors, which makes it possible for the Schatten norm regularization
based models to be solved at much smaller scale. We propose two algorithms
which apply different structured Schatten norms on tensor ring factors
respectively. By the alternating direction method of multipliers (ADMM) scheme,
the tensor ring factors and the predicted tensor can be optimized
simultaneously. The experiments on synthetic data and real-world data show the
high performance and efficiency of the proposed approach.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yuan_L/0/1/0/all/0/1&quot;&gt;Longhao Yuan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1&quot;&gt;Chao Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mandic_D/0/1/0/all/0/1&quot;&gt;Danilo Mandic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cao_J/0/1/0/all/0/1&quot;&gt;Jianting Cao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_Q/0/1/0/all/0/1&quot;&gt;Qibin Zhao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08588">
<title>An Optimal Rewiring Strategy for Reinforcement Social Learning in Cooperative Multiagent Systems. (arXiv:1805.08588v1 [cs.MA])</title>
<link>http://arxiv.org/abs/1805.08588</link>
<description rdf:parseType="Literal">&lt;p&gt;Multiagent coordination in cooperative multiagent systems (MASs) has been
widely studied in both fixed-agent repeated interaction setting and the static
social learning framework. However, two aspects of dynamics in real-world
multiagent scenarios are currently missing in existing works. First, the
network topologies can be dynamic where agents may change their connections
through rewiring during the course of interactions. Second, the game matrix
between each pair of agents may not be static and usually not known as a prior.
Both the network dynamic and game uncertainty increase the coordination
difficulty among agents. In this paper, we consider a multiagent dynamic social
learning environment in which each agent can choose to rewire potential
partners and interact with randomly chosen neighbors in each round. We propose
an optimal rewiring strategy for agents to select most beneficial peers to
interact with for the purpose of maximizing the accumulated payoff in repeated
interactions. We empirically demonstrate the effectiveness and robustness of
our approach through comparing with benchmark strategies. The performance of
three representative learning strategies under our social learning framework
with our optimal rewiring is investigated as well.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_H/0/1/0/all/0/1&quot;&gt;Hongyao Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1&quot;&gt;Li Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zan Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Baarslag_T/0/1/0/all/0/1&quot;&gt;Tim Baarslag&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hao_J/0/1/0/all/0/1&quot;&gt;Jianye Hao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08645">
<title>Multi-robot Symmetric Rendezvous Search on the Line with an Unknown Initial Distance. (arXiv:1805.08645v1 [cs.DC])</title>
<link>http://arxiv.org/abs/1805.08645</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we study the symmetric rendezvous search problem on the line
with n &amp;gt; 2 robots that are unaware of their locations and the initial distances
between them. In the symmetric version of this problem, the robots execute the
same strategy. The multi-robot symmetric rendezvous algorithm, MSR presented in
this paper is an extension our symmetric rendezvous algorithm, SR presented in
[23]. We study both the synchronous and asynchronous cases of the problem. The
asynchronous version of MSR algorithm is called MASR algorithm. We consider
that robots start executing MASR at different times. We perform the theoretical
analysis of MSR and MASR, and show that their competitive ratios are
$O(n^{0.67})$ and $O(n^{1.5})$, respectively. Finally, we confirm our
theoretical results through simulations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ozsoyeller_D/0/1/0/all/0/1&quot;&gt;Deniz Ozsoyeller&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08698">
<title>Imitation Refinement. (arXiv:1805.08698v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1805.08698</link>
<description rdf:parseType="Literal">&lt;p&gt;Many real-world tasks involve identifying patterns from data satisfying
background and prior knowledge, for which the ground truth is not available,
but ideal data can be obtained, for example, using theoretical simulations. We
propose a novel approach, imitation refinement, which refines imperfect
patterns by imitating ideal patterns. The imperfect patterns are obtained for
example using an unsupervised learner. Imitation refinement imitates ideal data
by incorporating prior knowledge captured by a classifier trained on the ideal
data: an imitation refiner applies small modifications to imperfect patterns so
that the classifier can identify them. In a sense, imitation refinement fits
the data to the classifier, which complements the classical supervised learning
task. We show that our imitation refinement approach outperforms existing
methods in identifying crystal patterns from X-ray diffraction data in
materials discovery. We also show the generality of our approach by
illustrating its applicability to a computer vision task.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bai_J/0/1/0/all/0/1&quot;&gt;Junwen Bai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_R/0/1/0/all/0/1&quot;&gt;Runzhe Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xue_Y/0/1/0/all/0/1&quot;&gt;Yexiang Xue&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gregoire_J/0/1/0/all/0/1&quot;&gt;John Gregoire&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gomes_C/0/1/0/all/0/1&quot;&gt;Carla Gomes&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08743">
<title>CascadeCNN: Pushing the performance limits of quantisation. (arXiv:1805.08743v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1805.08743</link>
<description rdf:parseType="Literal">&lt;p&gt;This work presents CascadeCNN, an automated toolflow that pushes the
quantisation limits of any given CNN model, to perform high-throughput
inference by exploiting the computation time-accuracy trade-off. Without the
need for retraining, a two-stage architecture tailored for any given FPGA
device is generated, consisting of a low- and a high-precision unit. A
confidence evaluation unit is employed between them to identify misclassified
cases at run time and forward them to the high-precision unit or terminate
computation. Experiments demonstrate that CascadeCNN achieves a performance
boost of up to 55% for VGG-16 and 48% for AlexNet over the baseline design for
the same resource budget and accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kouris_A/0/1/0/all/0/1&quot;&gt;Alexandros Kouris&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Venieris_S/0/1/0/all/0/1&quot;&gt;Stylianos I. Venieris&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bouganis_C/0/1/0/all/0/1&quot;&gt;Christos-Savvas Bouganis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08768">
<title>Sparse Binary Compression: Towards Distributed Deep Learning with minimal Communication. (arXiv:1805.08768v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.08768</link>
<description rdf:parseType="Literal">&lt;p&gt;Currently, progressively larger deep neural networks are trained on ever
growing data corpora. As this trend is only going to increase in the future,
distributed training schemes are becoming increasingly relevant. A major issue
in distributed training is the limited communication bandwidth between
contributing nodes or prohibitive communication cost in general. These
challenges become even more pressing, as the number of computation nodes
increases. To counteract this development we propose sparse binary compression
(SBC), a compression framework that allows for a drastic reduction of
communication cost for distributed training. SBC combines existing techniques
of communication delay and gradient sparsification with a novel binarization
method and optimal weight update encoding to push compression gains to new
limits. By doing so, our method also allows us to smoothly trade-off gradient
sparsity and temporal sparsity to adapt to the requirements of the learning
task. Our experiments show, that SBC can reduce the upstream communication on a
variety of convolutional and recurrent neural network architectures by more
than four orders of magnitude without significantly harming the convergence
speed in terms of forward-backward passes. For instance, we can train ResNet50
on ImageNet in the same number of iterations to the baseline accuracy, using
$\times 3531$ less bits or train it to a $1\%$ lower accuracy using $\times
37208$ less bits. In the latter case, the total upstream communication required
is cut from 125 terabytes to 3.35 gigabytes for every participating client.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sattler_F/0/1/0/all/0/1&quot;&gt;Felix Sattler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wiedemann_S/0/1/0/all/0/1&quot;&gt;Simon Wiedemann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Muller_K/0/1/0/all/0/1&quot;&gt;Klaus-Robert M&amp;#xfc;ller&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Samek_W/0/1/0/all/0/1&quot;&gt;Wojciech Samek&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1706.00359">
<title>Discovering Discrete Latent Topics with Neural Variational Inference. (arXiv:1706.00359v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1706.00359</link>
<description rdf:parseType="Literal">&lt;p&gt;Topic models have been widely explored as probabilistic generative models of
documents. Traditional inference methods have sought closed-form derivations
for updating the models, however as the expressiveness of these models grows,
so does the difficulty of performing fast and accurate inference over their
parameters. This paper presents alternative neural approaches to topic
modelling by providing parameterisable distributions over topics which permit
training by backpropagation in the framework of neural variational inference.
In addition, with the help of a stick-breaking construction, we propose a
recurrent network that is able to discover a notionally unbounded number of
topics, analogous to Bayesian non-parametric topic models. Experimental results
on the MXM Song Lyrics, 20NewsGroups and Reuters News datasets demonstrate the
effectiveness and efficiency of these neural topic models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Miao_Y/0/1/0/all/0/1&quot;&gt;Yishu Miao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grefenstette_E/0/1/0/all/0/1&quot;&gt;Edward Grefenstette&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Blunsom_P/0/1/0/all/0/1&quot;&gt;Phil Blunsom&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.00455">
<title>A Unified View of Piecewise Linear Neural Network Verification. (arXiv:1711.00455v3 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1711.00455</link>
<description rdf:parseType="Literal">&lt;p&gt;The success of Deep Learning and its potential use in many safety-critical
applications has motivated research on formal verification of Neural Network
(NN) models. Despite the reputation of learned NN models to behave as black
boxes and the theoretical hardness of proving their properties, researchers
have been successful in verifying some classes of models by exploiting their
piecewise linear structure and taking insights from formal methods such as
Satisifiability Modulo Theory. These methods are however still far from scaling
to realistic neural networks. To facilitate progress on this crucial area, we
make two key contributions. First, we present a unified framework that
encompasses previous methods. This analysis results in the identification of
new methods that combine the strengths of multiple existing approaches,
accomplishing a speedup of two orders of magnitude compared to the previous
state of the art. Second, we propose a new data set of benchmarks which
includes a collection of previously released testcases. We use the benchmark to
provide the first experimental comparison of existing algorithms and identify
the factors impacting the hardness of verification problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bunel_R/0/1/0/all/0/1&quot;&gt;Rudy Bunel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Turkaslan_I/0/1/0/all/0/1&quot;&gt;Ilker Turkaslan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Torr_P/0/1/0/all/0/1&quot;&gt;Philip H.S. Torr&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kohli_P/0/1/0/all/0/1&quot;&gt;Pushmeet Kohli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kumar_M/0/1/0/all/0/1&quot;&gt;M. Pawan Kumar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.10314">
<title>Crossmodal Attentive Skill Learner. (arXiv:1711.10314v3 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1711.10314</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents the Crossmodal Attentive Skill Learner (CASL), integrated
with the recently-introduced Asynchronous Advantage Option-Critic (A2OC)
architecture [Harb et al., 2017] to enable hierarchical reinforcement learning
across multiple sensory inputs. We provide concrete examples where the approach
not only improves performance in a single task, but accelerates transfer to new
tasks. We demonstrate the attention mechanism anticipates and identifies useful
latent features, while filtering irrelevant sensor modalities during execution.
We modify the Arcade Learning Environment [Bellemare et al., 2013] to support
audio queries, and conduct evaluations of crossmodal learning in the Atari 2600
game Amidar. Finally, building on the recent work of Babaeizadeh et al. [2017],
we open-source a fast hybrid CPU-GPU implementation of CASL.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Omidshafiei_S/0/1/0/all/0/1&quot;&gt;Shayegan Omidshafiei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1&quot;&gt;Dong-Ki Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pazis_J/0/1/0/all/0/1&quot;&gt;Jason Pazis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+How_J/0/1/0/all/0/1&quot;&gt;Jonathan P. How&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.06957">
<title>MURA: Large Dataset for Abnormality Detection in Musculoskeletal Radiographs. (arXiv:1712.06957v4 [physics.med-ph] UPDATED)</title>
<link>http://arxiv.org/abs/1712.06957</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce MURA, a large dataset of musculoskeletal radiographs containing
40,561 images from 14,863 studies, where each study is manually labeled by
radiologists as either normal or abnormal. To evaluate models robustly and to
get an estimate of radiologist performance, we collect additional labels from
six board-certified Stanford radiologists on the test set, consisting of 207
musculoskeletal studies. On this test set, the majority vote of a group of
three radiologists serves as gold standard. We train a 169-layer DenseNet
baseline model to detect and localize abnormalities. Our model achieves an
AUROC of 0.929, with an operating point of 0.815 sensitivity and 0.887
specificity. We compare our model and radiologists on the Cohen&apos;s kappa
statistic, which expresses the agreement of our model and of each radiologist
with the gold standard. Model performance is comparable to the best radiologist
performance in detecting abnormalities on finger and wrist studies. However,
model performance is lower than best radiologist performance in detecting
abnormalities on elbow, forearm, hand, humerus, and shoulder studies. We
believe that the task is a good challenge for future research. To encourage
advances, we have made our dataset freely available at
https://stanfordmlgroup.github.io/competitions/mura .
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Rajpurkar_P/0/1/0/all/0/1&quot;&gt;Pranav Rajpurkar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Irvin_J/0/1/0/all/0/1&quot;&gt;Jeremy Irvin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Bagul_A/0/1/0/all/0/1&quot;&gt;Aarti Bagul&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Ding_D/0/1/0/all/0/1&quot;&gt;Daisy Ding&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Duan_T/0/1/0/all/0/1&quot;&gt;Tony Duan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Mehta_H/0/1/0/all/0/1&quot;&gt;Hershel Mehta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Yang_B/0/1/0/all/0/1&quot;&gt;Brandon Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Zhu_K/0/1/0/all/0/1&quot;&gt;Kaylie Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Laird_D/0/1/0/all/0/1&quot;&gt;Dillon Laird&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Ball_R/0/1/0/all/0/1&quot;&gt;Robyn L. Ball&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Langlotz_C/0/1/0/all/0/1&quot;&gt;Curtis Langlotz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Shpanskaya_K/0/1/0/all/0/1&quot;&gt;Katie Shpanskaya&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Lungren_M/0/1/0/all/0/1&quot;&gt;Matthew P. Lungren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Ng_A/0/1/0/all/0/1&quot;&gt;Andrew Y. Ng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04240">
<title>Reinforcement Learning for Solving the Vehicle Routing Problem. (arXiv:1802.04240v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1802.04240</link>
<description rdf:parseType="Literal">&lt;p&gt;We present an end-to-end framework for solving the Vehicle Routing Problem
(VRP) using reinforcement learning. In this approach, we train a single model
that finds near-optimal solutions for problem instances sampled from a given
distribution, only by observing the reward signals and following feasibility
rules. Our model represents a parameterized stochastic policy, and by applying
a policy gradient algorithm to optimize its parameters, the trained model
produces the solution as a sequence of consecutive actions in real time,
without the need to re-train for every new problem instance. On capacitated
VRP, our approach outperforms classical heuristics and Google&apos;s OR-Tools on
medium-sized instances in solution quality with comparable computation time
(after training). We demonstrate how our approach can handle problems with
split delivery and explore the effect of such deliveries on the solution
quality. Our proposed framework can be applied to other variants of the VRP
such as the stochastic VRP, and has the potential to be applied more generally
to combinatorial optimization problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nazari_M/0/1/0/all/0/1&quot;&gt;Mohammadreza Nazari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oroojlooy_A/0/1/0/all/0/1&quot;&gt;Afshin Oroojlooy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Snyder_L/0/1/0/all/0/1&quot;&gt;Lawrence V. Snyder&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Takac_M/0/1/0/all/0/1&quot;&gt;Martin Tak&amp;#xe1;&amp;#x10d;&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.01987">
<title>Designing the Game to Play: Optimizing Payoff Structure in Security Games. (arXiv:1805.01987v2 [cs.GT] UPDATED)</title>
<link>http://arxiv.org/abs/1805.01987</link>
<description rdf:parseType="Literal">&lt;p&gt;Effective game-theoretic modeling of defender-attacker behavior is becoming
increasingly important. In many domains, the defender functions not only as a
player but also the designer of the game&apos;s payoff structure. We study
Stackelberg Security Games where the defender, in addition to allocating
defensive resources to protect targets from the attacker, can strategically
manipulate the attacker&apos;s payoff under budget constraints in weighted L^p-norm
form regarding the amount of change. Focusing on problems with weighted
L^1-norm form constraint, we present (i) a mixed integer linear program-based
algorithm with approximation guarantee; (ii) a branch-and-bound based algorithm
with improved efficiency achieved by effective pruning; (iii) a polynomial time
approximation scheme for a special but practical class of problems. In
addition, we show that problems under budget constraints in L^0-norm form and
weighted L^\infty-norm form can be solved in polynomial time. We provide an
extensive experimental evaluation of our proposed algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_Z/0/1/0/all/0/1&quot;&gt;Zheyuan Ryan Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_Z/0/1/0/all/0/1&quot;&gt;Ziye Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tran_Thanh_L/0/1/0/all/0/1&quot;&gt;Long Tran-Thanh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singh_R/0/1/0/all/0/1&quot;&gt;Rohit Singh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fang_F/0/1/0/all/0/1&quot;&gt;Fei Fang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07830">
<title>Learning to Teach in Cooperative Multiagent Reinforcement Learning. (arXiv:1805.07830v2 [cs.MA] UPDATED)</title>
<link>http://arxiv.org/abs/1805.07830</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a framework and algorithm for peer-to-peer teaching in cooperative
multiagent reinforcement learning. Our algorithm, Learning to Coordinate and
Teach Reinforcement (LeCTR), trains advising policies by using students&apos;
learning progress as a teaching reward. Agents using LeCTR learn to assume the
role of a teacher or student at the appropriate moments, exchanging action
advice to accelerate the entire learning process. Our algorithm supports
teaching heterogeneous teammates, advising under communication constraints, and
learns both what and when to advise. LeCTR is demonstrated to outperform the
final performance and rate of learning of prior teaching methods on multiple
benchmark domains. To our knowledge, this is the first approach for learning to
teach in a multiagent setting.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Omidshafiei_S/0/1/0/all/0/1&quot;&gt;Shayegan Omidshafiei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1&quot;&gt;Dong-Ki Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1&quot;&gt;Miao Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tesauro_G/0/1/0/all/0/1&quot;&gt;Gerald Tesauro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Riemer_M/0/1/0/all/0/1&quot;&gt;Matthew Riemer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Amato_C/0/1/0/all/0/1&quot;&gt;Christopher Amato&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Campbell_M/0/1/0/all/0/1&quot;&gt;Murray Campbell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+How_J/0/1/0/all/0/1&quot;&gt;Jonathan P. How&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08195">
<title>Depth-Limited Solving for Imperfect-Information Games. (arXiv:1805.08195v1 [cs.GT] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1805.08195</link>
<description rdf:parseType="Literal">&lt;p&gt;A fundamental challenge in imperfect-information games is that states do not
have well-defined values. As a result, depth-limited search algorithms used in
single-agent settings and perfect-information games do not apply. This paper
introduces a principled way to conduct depth-limited solving in
imperfect-information games by allowing the opponent to choose among a number
of strategies for the remainder of the game at the depth limit. Each one of
these strategies results in a different set of values for leaf nodes. This
forces an agent to be robust to the different strategies an opponent may
employ. We demonstrate the effectiveness of this approach by building a
master-level heads-up no-limit Texas hold&apos;em poker AI that defeats two prior
top agents using only a 4-core CPU and 16 GB of memory. Developing such a
powerful agent would have previously required a supercomputer.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brown_N/0/1/0/all/0/1&quot;&gt;Noam Brown&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sandholm_T/0/1/0/all/0/1&quot;&gt;Tuomas Sandholm&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Amos_B/0/1/0/all/0/1&quot;&gt;Brandon Amos&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08239">
<title>The Roles of Supervised Machine Learning in Systems Neuroscience. (arXiv:1805.08239v1 [q-bio.NC])</title>
<link>http://arxiv.org/abs/1805.08239</link>
<description rdf:parseType="Literal">&lt;p&gt;Over the last several years, the use of machine learning (ML) in neuroscience
has been increasing exponentially. Here, we review ML&apos;s contributions, both
realized and potential, across several areas of systems neuroscience. We
describe four primary roles of ML within neuroscience: 1) creating solutions to
engineering problems, 2) identifying predictive variables, 3) setting
benchmarks for simple models of the brain, and 4) serving itself as a model for
the brain. The breadth and ease of its applicability suggests that machine
learning should be in the toolbox of most systems neuroscientists.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Glaser_J/0/1/0/all/0/1&quot;&gt;Joshua I. Glaser&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Benjamin_A/0/1/0/all/0/1&quot;&gt;Ari S. Benjamin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Farhoodi_R/0/1/0/all/0/1&quot;&gt;Roozbeh Farhoodi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Kording_K/0/1/0/all/0/1&quot;&gt;Konrad P. Kording&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08244">
<title>Stochastic modified equations for the asynchronous stochastic gradient descent. (arXiv:1805.08244v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.08244</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a stochastic modified equations (SME) for modeling the
asynchronous stochastic gradient descent (ASGD) algorithms. The resulting SME
of Langevin type extracts more information about the ASGD dynamics and
elucidates the relationship between different types of stochastic gradient
algorithms. We show the convergence of ASGD to the SME in the continuous time
limit, as well as the SME&apos;s precise prediction to the trajectories of ASGD with
various forcing terms. As an application of the SME, we propose an optimal
mini-batching strategy for ASGD via solving the optimal control problem of the
associated SME.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+An_J/0/1/0/all/0/1&quot;&gt;Jing An&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lu_J/0/1/0/all/0/1&quot;&gt;Jianfeng Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ying_L/0/1/0/all/0/1&quot;&gt;Lexing Ying&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08254">
<title>Sample Compression for Real-Valued Learners. (arXiv:1805.08254v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.08254</link>
<description rdf:parseType="Literal">&lt;p&gt;We give an algorithmically efficient version of the learner-to-compression
scheme conversion in Moran and Yehudayoff (2016). In extending this technique
to real-valued hypotheses, we also obtain an efficient regression-to-bounded
sample compression converter. To our knowledge, this is the first general
compressed regression result (regardless of efficiency or boundedness)
guaranteeing uniform approximate reconstruction. Along the way, we develop a
generic procedure for constructing weak real-valued learners out of abstract
regressors; this may be of independent interest. In particular, this result
sheds new light on an open question of H. Simon (1997). We show applications to
two regression problems: learning Lipschitz and bounded-variation functions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hanneke_S/0/1/0/all/0/1&quot;&gt;Steve Hanneke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kontorovich_A/0/1/0/all/0/1&quot;&gt;Aryeh Kontorovich&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sadigurschi_M/0/1/0/all/0/1&quot;&gt;Menachem Sadigurschi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08268">
<title>Effective Dimension of Exp-concave Optimization. (arXiv:1805.08268v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.08268</link>
<description rdf:parseType="Literal">&lt;p&gt;We investigate the role of the effective (a.k.a. statistical) dimension in
determining both the statistical and the computational costs associated with
exp-concave stochastic minimization. We derive sample complexity bounds that
scale with $\frac{d_{\lambda}}{\epsilon}$, where $d_{\lambda}$ is the effective
dimension associated with the regularization parameter $\lambda$. These are the
first fast rates in this setting that do not exhibit any explicit dependence
either on the intrinsic dimension or the $\ell_{2}$-norm of the optimal
classifier.
&lt;/p&gt;
&lt;p&gt;We also propose fast preconditioned methods that solve the ERM problem in
time
$\tO\left(\nnz(X)+\min_{\lambda&apos;\ge\lambda}\frac{\lambda&apos;}{\lambda}\,d_{\lambda&apos;}^{2}d\right)$,
where $\nnz(X)$ is the number of nonzero entries in the data. Our analysis
emphasizes interesting connections between leverage scores, algorithmic
stability and regularization. In particular, our algorithm involves a novel
technique for choosing a regularization parameter $\lambda&apos;$ that minimizes the
complexity bound $\frac{\lambda&apos;}{\lambda}\,d_{\lambda&apos;}^{2}d$, while avoiding
the entire (approximate) computation of the effective dimension for each
candidate $\lambda&apos;$. All of our result extend to the kernel setting.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Agarwal_N/0/1/0/all/0/1&quot;&gt;Naman Agarwal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gonen_A/0/1/0/all/0/1&quot;&gt;Alon Gonen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08273">
<title>Multiple Causal Inference with Latent Confounding. (arXiv:1805.08273v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.08273</link>
<description rdf:parseType="Literal">&lt;p&gt;Causal inference from observational data requires assumptions. These
assumptions range from measuring confounders to identifying instruments.
Traditionally, these assumptions have focused on estimation in a single causal
problem. In this work, we develop techniques for causal estimation in causal
problems with multiple treatments. We develop two assumptions based on shared
confounding between treatments and independence of treatments given the
confounder. Together these assumptions lead to a confounder estimator
regularized by mutual information. For this estimator, we develop a tractable
lower bound. To fit the outcome model, we use the residual information in the
treatments given the confounder. We validate on simulations and an example from
clinical medicine.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ranganath_R/0/1/0/all/0/1&quot;&gt;Rajesh Ranganath&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Perotte_A/0/1/0/all/0/1&quot;&gt;Adler Perotte&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08306">
<title>Deep Energy Estimator Networks. (arXiv:1805.08306v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.08306</link>
<description rdf:parseType="Literal">&lt;p&gt;Density estimation is a fundamental problem in statistical learning. This
problem is especially challenging for complex high-dimensional data due to the
curse of dimensionality. A promising solution to this problem is given here in
an inference-free hierarchical framework that is built on score matching. We
revisit the Bayesian interpretation of the score function and the Parzen score
matching, and construct a multilayer perceptron with a scalable objective for
learning the energy (i.e. the unnormalized log-density), which is then
optimized with stochastic gradient descent. In addition, the resulting deep
energy estimator network (DEEN) is designed as products of experts. We present
the utility of DEEN in learning the energy, the score function, and in
single-step denoising experiments for synthetic and high-dimensional data. We
also diagnose stability problems in the direct estimation of the score function
that had been observed for denoising autoencoders.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Saremi_S/0/1/0/all/0/1&quot;&gt;Saeed Saremi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mehrjou_A/0/1/0/all/0/1&quot;&gt;Arash Mehrjou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Scholkopf_B/0/1/0/all/0/1&quot;&gt;Bernhard Sch&amp;#xf6;lkopf&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hyvarinen_A/0/1/0/all/0/1&quot;&gt;Aapo Hyv&amp;#xe4;rinen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08308">
<title>geomstats: a Python Package for Riemannian Geometry in Machine Learning. (arXiv:1805.08308v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.08308</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce geomstats, a python package that performs computations on
manifolds such as hyperspheres, hyperbolic spaces, spaces of symmetric positive
definite matrices and Lie groups of transformations. We provide efficient and
extensively unit-tested implementations of these manifolds, together with
useful Riemannian metrics and associated Exponential and Logarithm maps. The
corresponding geodesic distances provide a range of intuitive choices of
Machine Learning loss functions. We also give the corresponding Riemannian
gradients. The operations implemented in geomstats are available with different
computing backends such as numpy, tensorflow and keras. We have enabled GPU
implementation and integrated geomstats manifold computations into keras deep
learning framework. This paper also presents a review of manifolds in machine
learning and an overview of the geomstats package with examples demonstrating
its use for efficient and user-friendly Riemannian geometry.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Miolane_N/0/1/0/all/0/1&quot;&gt;Nina Miolane&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mathe_J/0/1/0/all/0/1&quot;&gt;Johan Mathe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Donnat_C/0/1/0/all/0/1&quot;&gt;Claire Donnat&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jorda_M/0/1/0/all/0/1&quot;&gt;Mikael Jorda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pennec_X/0/1/0/all/0/1&quot;&gt;Xavier Pennec&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08309">
<title>AxTrain: Hardware-Oriented Neural Network Training for Approximate Inference. (arXiv:1805.08309v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.08309</link>
<description rdf:parseType="Literal">&lt;p&gt;The intrinsic error tolerance of neural network (NN) makes approximate
computing a promising technique to improve the energy efficiency of NN
inference. Conventional approximate computing focuses on balancing the
efficiency-accuracy trade-off for existing pre-trained networks, which can lead
to suboptimal solutions. In this paper, we propose AxTrain, a hardware-oriented
training framework to facilitate approximate computing for NN inference.
Specifically, AxTrain leverages the synergy between two orthogonal
methods---one actively searches for a network parameters distribution with high
error tolerance, and the other passively learns resilient weights by
numerically incorporating the noise distributions of the approximate hardware
in the forward pass during the training phase. Experimental results from
various datasets with near-threshold computing and approximation multiplication
strategies demonstrate AxTrain&apos;s ability to obtain resilient neural network
parameters and system energy efficiency improvement.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1&quot;&gt;Xin He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ke_L/0/1/0/all/0/1&quot;&gt;Liu Ke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_W/0/1/0/all/0/1&quot;&gt;Wenyan Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yan_G/0/1/0/all/0/1&quot;&gt;Guihai Yan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xuan Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08321">
<title>Adaptive Monte-Carlo Optimization. (arXiv:1805.08321v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.08321</link>
<description rdf:parseType="Literal">&lt;p&gt;The celebrated Monte Carlo method estimates a quantity that is expensive to
compute by random sampling. We propose adaptive Monte Carlo optimization: a
general framework for discrete optimization of an expensive-to-compute function
by adaptive random sampling. Applications of this framework have already
appeared in machine learning but are tied to their specific contexts and
developed in isolation. We take a unified view and show that the framework has
broad applicability by applying it on several common machine learning problems:
$k$-nearest neighbors, hierarchical clustering and maximum mutual information
feature selection. On real data we show that this framework allows us to
develop algorithms that confer a gain of a magnitude or two over exact
computation. We also characterize the performance gain theoretically under
regularity assumptions on the data that we verify in real world data. The code
is available at https://github.com/govinda-kamath/combinatorial_MAB.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bagaria_V/0/1/0/all/0/1&quot;&gt;Vivek Bagaria&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kamath_G/0/1/0/all/0/1&quot;&gt;Govinda M. Kamath&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tse_D/0/1/0/all/0/1&quot;&gt;David N. Tse&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08327">
<title>Robust Gradient Descent via Moment Encoding with LDPC Codes. (arXiv:1805.08327v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.08327</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper considers the problem of implementing large-scale gradient descent
algorithms in a distributed computing setting in the presence of {\em
straggling} processors. To mitigate the effect of the stragglers, it has been
previously proposed to encode the data with an erasure-correcting code and
decode at the master server at the end of the computation. We, instead, propose
to encode the second-moment of the data with a low density parity-check (LDPC)
code. The iterative decoding algorithms for LDPC codes have very low
computational overhead and the number of decoding iterations can be made to
automatically adjust with the number of stragglers in the system. We show that
for a random model for stragglers, the proposed moment encoding based gradient
descent method can be viewed as the stochastic gradient descent method. This
allows us to obtain convergence guarantees for the proposed solution.
Furthermore, the proposed moment encoding based method is shown to outperform
the existing schemes in a real distributed computing setup.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Maity_R/0/1/0/all/0/1&quot;&gt;Raj Kumar Maity&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rawat_A/0/1/0/all/0/1&quot;&gt;Ankit Singh Rawat&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mazumdar_A/0/1/0/all/0/1&quot;&gt;Arya Mazumdar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08331">
<title>Large Scale computation of Means and Clusters for Persistence Diagrams using Optimal Transport. (arXiv:1805.08331v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.08331</link>
<description rdf:parseType="Literal">&lt;p&gt;Persistence diagrams (PDs) are now routinely used to summarize the underlying
topology of sophisticated data encountered in challenging learning problems.
Despite several appealing properties, integrating PDs in learning pipelines can
be challenging because their natural geometry is not Hilbertian. In particular,
algorithms to average a family of PDs have only been considered recently and
are known to be computationally prohibitive. We propose in this article a
tractable framework to carry out fundamental tasks on PDs, namely evaluating
distances, computing barycenters and carrying out clustering. This framework
builds upon a formulation of PD metrics as optimal transport (OT) problems, for
which recent computational advances, in particular entropic regularization and
its convolutional formulation on regular grids, can all be leveraged to provide
efficient and (GPU) scalable computations. We demonstrate the efficiency of our
approach by carrying out clustering on PDs at scales never seen before in the
literature.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lacombe_T/0/1/0/all/0/1&quot;&gt;Th&amp;#xe9;o Lacombe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Cuturi_M/0/1/0/all/0/1&quot;&gt;Marco Cuturi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Oudot_S/0/1/0/all/0/1&quot;&gt;Steve Oudot&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08336">
<title>Maximum Causal Tsallis Entropy Imitation Learning. (arXiv:1805.08336v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.08336</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we propose a novel maximum causal Tsallis entropy (MCTE)
framework for imitation learning which can efficiently learn a sparse
multi-modal policy distribution from demonstrations. We provide the full
mathematical analysis of the proposed framework. First, the optimal solution of
an MCTE problem is shown to be a sparsemax distribution, whose supporting set
can be adjusted. The proposed method has advantages over a softmax distribution
in that it can exclude unnecessary actions by assigning zero probability.
Second, we prove that an MCTE problem is equivalent to robust Bayes estimation
in the sense of the Brier score. Third, we propose a maximum causal Tsallis
entropy imitation learning (MCTEIL) algorithm with a sparse mixture density
network (sparse MDN) by modeling mixture weights using a sparsemax
distribution. In particular, we show that the causal Tsallis entropy of an MDN
encourages exploration and efficient mixture utilization while Boltzmann Gibbs
entropy is less effective. We validate the proposed method in two simulation
studies and MCTEIL outperforms existing imitation learning methods in terms of
average returns and learning multi-modal policies.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_K/0/1/0/all/0/1&quot;&gt;Kyungjae Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Choi_S/0/1/0/all/0/1&quot;&gt;Sungjoon Choi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oh_S/0/1/0/all/0/1&quot;&gt;Songhwai Oh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08342">
<title>Nearest neighbor density functional estimation based on inverse Laplace transform. (arXiv:1805.08342v1 [math.ST])</title>
<link>http://arxiv.org/abs/1805.08342</link>
<description rdf:parseType="Literal">&lt;p&gt;A general approach to $L_2$-consistent estimation of various density
functionals using $k$-nearest neighbor distances is proposed, along with the
analysis of convergence rates in mean squared error. The construction of the
estimator is based on inverse Laplace transforms related to the target density
functional, which arises naturally from the convergence of a normalized volume
of $k$-nearest neighbor ball to a Gamma distribution in the sample limit. Some
instantiations of the proposed estimator rediscover existing $k$-nearest
neighbor based estimators of Shannon and Renyi entropies and Kullback--Leibler
and Renyi divergences, and discover new consistent estimators for many other
functionals, such as Jensen--Shannon divergence and generalized entropies and
divergences. A unified finite-sample analysis of the proposed estimator is
presented that builds on a recent result by Gao, Oh, and Viswanath (2017) on
the finite sample behavior of the Kozachenko--Leoneko estimator of entropy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Ganguly_S/0/1/0/all/0/1&quot;&gt;Shouvik Ganguly&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Ryu_J/0/1/0/all/0/1&quot;&gt;Jongha Ryu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Kim_Y/0/1/0/all/0/1&quot;&gt;Young-Han Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Noh_Y/0/1/0/all/0/1&quot;&gt;Yung-Kyun Noh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Lee_D/0/1/0/all/0/1&quot;&gt;Daniel D. Lee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08349">
<title>A Solvable High-Dimensional Model of GAN. (arXiv:1805.08349v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.08349</link>
<description rdf:parseType="Literal">&lt;p&gt;Despite the remarkable successes of generative adversarial networks (GANs) in
many applications, theoretical understandings of their performance is still
limited. In this paper, we present a simple shallow GAN model fed by
high-dimensional input data. The dynamics of the training process of the
proposed model can be exactly analyzed in the high-dimensional limit. In
particular, by using the tool of scaling limits of stochastic processes, we
show that the macroscopic quantities measuring the quality of the training
process converge to a deterministic process that is characterized as the unique
solution of a finite-dimensional ordinary differential equation (ODE). The
proposed model is simple, but its training process already exhibits several
different phases that can mimic the behaviors of more realistic GAN models used
in practice. Specifically, depending on the choice of the learning rates, the
training process can reach either a successful, a failed, or an oscillating
phase. By studying the steady-state solutions of the limiting ODEs, we obtain a
phase diagram that precisely characterizes the conditions under which each
phase takes place. Although this work focuses on a simple GAN model, the
analysis methods developed here might prove useful in the theoretical
understanding of other variants of GANs with more advanced training algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1&quot;&gt;Chuang Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1&quot;&gt;Hong Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1&quot;&gt;Yue M. Lu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08395">
<title>Learning to Optimize via Wasserstein Deep Inverse Optimal Control. (arXiv:1805.08395v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.08395</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the inverse optimal control problem in social sciences: we aim at
learning a user&apos;s true cost function from the observed temporal behavior. In
contrast to traditional phenomenological works that aim to learn a generative
model to fit the behavioral data, we propose a novel variational principle and
treat user as a reinforcement learning algorithm, which acts by optimizing his
cost function. We first propose a unified KL framework that generalizes
existing maximum entropy inverse optimal control methods. We further propose a
two-step Wasserstein inverse optimal control framework. In the first step, we
compute the optimal measure with a novel mass transport equation. In the second
step, we formulate the learning problem as a generative adversarial network. In
two real world experiments - recommender systems and social networks, we show
that our framework obtains significant performance gains over both existing
inverse optimal control methods and point process based generative models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yichen Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_L/0/1/0/all/0/1&quot;&gt;Le Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zha_H/0/1/0/all/0/1&quot;&gt;Hongyuan Zha&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08498">
<title>Implicit Reparameterization Gradients. (arXiv:1805.08498v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.08498</link>
<description rdf:parseType="Literal">&lt;p&gt;By providing a simple and efficient way of computing low-variance gradients
of continuous random variables, the reparameterization trick has become the
technique of choice for training a variety of latent variable models. However,
it is not applicable to a number of important continuous distributions. We
introduce an alternative approach to computing reparameterization gradients
based on implicit differentiation and demonstrate its broader applicability by
applying it to Gamma, Beta, Dirichlet, and von Mises distributions, which
cannot be used with the classic reparameterization trick. Our experiments show
that the proposed approach is faster and more accurate than the existing
gradient estimators for these distributions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Figurnov_M/0/1/0/all/0/1&quot;&gt;Michael Figurnov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mohamed_S/0/1/0/all/0/1&quot;&gt;Shakir Mohamed&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mnih_A/0/1/0/all/0/1&quot;&gt;Andriy Mnih&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08527">
<title>Safe Element Screening for Submodular Function Minimization. (arXiv:1805.08527v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.08527</link>
<description rdf:parseType="Literal">&lt;p&gt;Submodular functions are discrete analogs of convex functions, which have
applications in various fields, including machine learning, computer vision and
signal processing. However, in large-scale applications, solving Submodular
Function Minimization (SFM) problems remains challenging. In this paper, we
make the first attempt to extend the emerging technique named screening in
large-scale sparse learning to SFM for accelerating its optimization process.
Specifically, we propose a novel safe element screening method---based on a
careful studying of the relationships between SFM and the corresponding convex
proximal problems, as well as the accurate estimation of the optimum of the
proximal problem---to quickly identify the elements that are guaranteed to be
included (we refer to them as active) or excluded (inactive) in the final
optimal solution of SFM during the optimization process. By removing the
inactive elements and fixing the active ones, the problem size can be
dramatically reduced, leading to great savings in the computational cost
without sacrificing accuracy. To the best of our knowledge, the proposed method
is the first screening method in the fields of SFM and even combinatorial
optimization, and thus points out a new direction for accelerating SFM
algorithms. Experiment results on both synthetic and real datasets demonstrate
the significant speedups gained by our screening method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhang_W/0/1/0/all/0/1&quot;&gt;Weizhong Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hong_B/0/1/0/all/0/1&quot;&gt;Bin Hong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ma_L/0/1/0/all/0/1&quot;&gt;Lin Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Liu_W/0/1/0/all/0/1&quot;&gt;Wei Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhang_T/0/1/0/all/0/1&quot;&gt;Tong Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08531">
<title>Gossip of Statistical Observations using Orthogonal Polynomials. (arXiv:1805.08531v1 [cs.MA])</title>
<link>http://arxiv.org/abs/1805.08531</link>
<description rdf:parseType="Literal">&lt;p&gt;Consider a network of agents connected by communication links, where each
agent holds a real value. The gossip problem consists in estimating the average
of the values diffused in the network in a distributed manner. Current
techniques for gossiping are designed to deal with worst-case scenarios, which
is irrelevant in applications to distributed statistical learning and denoising
in sensor networks. We design second-order gossip methods tailor-made for the
case where the real values are i.i.d. samples from the same distribution. In
some regular network structures, we are able to prove optimality of our
methods, and simulations suggest that they are efficient in a wide range of
random networks. Our approach of gossip stems from a new acceleration framework
using the family of orthogonal polynomials with respect to the spectral measure
of the network graph.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Berthier_R/0/1/0/all/0/1&quot;&gt;Rapha&amp;#xeb;l Berthier&lt;/a&gt; (SIERRA), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bach_F/0/1/0/all/0/1&quot;&gt;Francis Bach&lt;/a&gt; (SIERRA), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gaillard_P/0/1/0/all/0/1&quot;&gt;Pierre Gaillard&lt;/a&gt; (SIERRA)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08539">
<title>Fully Understanding the Hashing Trick. (arXiv:1805.08539v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.08539</link>
<description rdf:parseType="Literal">&lt;p&gt;Feature hashing, also known as {\em the hashing trick}, introduced by
Weinberger et al. (2009), is one of the key techniques used in scaling-up
machine learning algorithms. Loosely speaking, feature hashing uses a random
sparse projection matrix $A : \mathbb{R}^n \to \mathbb{R}^m$ (where $m \ll n$)
in order to reduce the dimension of the data from $n$ to $m$ while
approximately preserving the Euclidean norm. Every column of $A$ contains
exactly one non-zero entry, equals to either $-1$ or $1$.
&lt;/p&gt;
&lt;p&gt;Weinberger et al. showed tail bounds on $\|Ax\|_2^2$. Specifically they
showed that for every $\varepsilon, \delta$, if $\|x\|_{\infty} / \|x\|_2$ is
sufficiently small, and $m$ is sufficiently large, then $$\Pr[ \; |
\;\|Ax\|_2^2 - \|x\|_2^2\; | &amp;lt; \varepsilon \|x\|_2^2 \;] \ge 1 - \delta \;.$$
These bounds were later extended by Dasgupta \etal (2010) and most recently
refined by Dahlgaard et al. (2017), however, the true nature of the performance
of this key technique, and specifically the correct tradeoff between the
pivotal parameters $\|x\|_{\infty} / \|x\|_2, m, \varepsilon, \delta$ remained
an open question.
&lt;/p&gt;
&lt;p&gt;We settle this question by giving tight asymptotic bounds on the exact
tradeoff between the central parameters, thus providing a complete
understanding of the performance of feature hashing. We complement the
asymptotic bound with empirical data, which shows that the constants &quot;hiding&quot;
in the asymptotic notation are, in fact, very close to $1$, thus further
illustrating the tightness of the presented bounds in practice.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Freksen_C/0/1/0/all/0/1&quot;&gt;Casper Benjamin Freksen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kamma_L/0/1/0/all/0/1&quot;&gt;Lior Kamma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Larsen_K/0/1/0/all/0/1&quot;&gt;Kasper Green Larsen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08562">
<title>Best of many worlds: Robust model selection for online supervised learning. (arXiv:1805.08562v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.08562</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce algorithms for online, full-information prediction that are
competitive with contextual tree experts of unknown complexity, in both
probabilistic and adversarial settings. We show that by incorporating a
probabilistic framework of structural risk minimization into existing adaptive
algorithms, we can robustly learn not only the presence of stochastic structure
when it exists (leading to constant as opposed to $\mathcal{O}(\sqrt{T})$
regret), but also the correct model order. We thus obtain regret bounds that
are competitive with the regret of an optimal algorithm that possesses strong
side information about both the complexity of the optimal contextual tree
expert and whether the process generating the data is stochastic or
adversarial. These are the first constructive guarantees on simultaneous
adaptivity to the model and the presence of stochasticity.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Muthukumar_V/0/1/0/all/0/1&quot;&gt;Vidya Muthukumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ray_M/0/1/0/all/0/1&quot;&gt;Mitas Ray&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sahai_A/0/1/0/all/0/1&quot;&gt;Anant Sahai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bartlett_P/0/1/0/all/0/1&quot;&gt;Peter L. Bartlett&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08565">
<title>Global Navigation Using Predictable and Slow Feature Analysis in Multiroom Environments, Path Planning and Other Control Tasks. (arXiv:1805.08565v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.08565</link>
<description rdf:parseType="Literal">&lt;p&gt;Extended Predictable Feature Analysis (PFAx) [Richthofer and Wiskott, 2017]
is an extension of PFA [Richthofer and Wiskott, 2015] that allows generating a
goal-directed control signal of an agent whose dynamics has previously been
learned during a training phase in an unsupervised manner. PFAx hardly requires
assumptions or prior knowledge of the agent&apos;s sensor or control mechanics, or
of the environment. It selects features from a high-dimensional input by
intrinsic predictability and organizes them into a reasonably low-dimensional
model.
&lt;/p&gt;
&lt;p&gt;While PFA obtains a well predictable model, PFAx yields a model ideally
suited for manipulations with predictable outcome. This allows for
goal-directed manipulation of an agent and thus for local navigation, i.e. for
reaching states where intermediate actions can be chosen by a permanent descent
of distance to the goal. The approach is limited when it comes to global
navigation, e.g. involving obstacles or multiple rooms.
&lt;/p&gt;
&lt;p&gt;In this article, we extend theoretical results from [Sprekeler and Wiskott,
2008], enabling PFAx to perform stable global navigation. So far, the most
widely exploited characteristic of Slow Feature Analysis (SFA) was that
slowness yields invariances. We focus on another fundamental characteristics of
slow signals: They tend to yield monotonicity and one significant property of
monotonicity is that local optimization is sufficient to find a global optimum.
&lt;/p&gt;
&lt;p&gt;We present an SFA-based algorithm that structures an environment such that
navigation tasks hierarchically decompose into subgoals. Each of these can be
efficiently achieved by PFAx, yielding an overall global solution of the task.
The algorithm needs to explore and process an environment only once and can
then perform all sorts of navigation tasks efficiently. We support this
algorithm by mathematical theory and apply it to different problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Richthofer_S/0/1/0/all/0/1&quot;&gt;Stefan Richthofer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wiskott_L/0/1/0/all/0/1&quot;&gt;Laurenz Wiskott&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08571">
<title>On Coresets for Logistic Regression. (arXiv:1805.08571v1 [cs.DS])</title>
<link>http://arxiv.org/abs/1805.08571</link>
<description rdf:parseType="Literal">&lt;p&gt;Coresets are one of the central methods to facilitate the analysis of large
data sets. We continue a recent line of research applying the theory of
coresets to logistic regression. First, we show a negative result, namely, that
no strongly sublinear sized coresets exist for logistic regression. To deal
with intractable worst-case instances we introduce a complexity measure
$\mu(X)$, which quantifies the hardness of compressing a data set for logistic
regression. $\mu(X)$ has an intuitive statistical interpretation that may be of
independent interest. For data sets with bounded $\mu(X)$-complexity, we show
that a novel sensitivity sampling scheme produces the first provably sublinear
$(1\pm\varepsilon)$-coreset. We illustrate the performance of our method by
comparing to uniform sampling as well as to state of the art methods in the
area. The experiments are conducted on real world benchmark data for logistic
regression.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Munteanu_A/0/1/0/all/0/1&quot;&gt;Alexander Munteanu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schwiegelshohn_C/0/1/0/all/0/1&quot;&gt;Chris Schwiegelshohn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sohler_C/0/1/0/all/0/1&quot;&gt;Christian Sohler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Woodruff_D/0/1/0/all/0/1&quot;&gt;David P. Woodruff&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08593">
<title>Confounding-Robust Policy Improvement. (arXiv:1805.08593v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.08593</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the problem of learning personalized decision policies from
observational data while accounting for possible unobserved confounding in the
data-generating process. Unlike previous approaches which assume
unconfoundedness, i.e., no unobserved confounders affected treatment assignment
as well as outcome, we calibrate policy learning for realistic violations of
this unverifiable assumption with uncertainty sets motivated by sensitivity
analysis in causal inference. Our framework for confounding-robust policy
improvement optimizes the minimax regret of a candidate policy against a
baseline or reference &quot;status quo&quot; policy, over a uncertainty set around
nominal propensity weights. We prove that if the uncertainty set is
well-specified, robust policy learning can do no worse than the baseline, and
only improve if the data supports it. We characterize the adversarial
subproblem and use efficient algorithmic solutions to optimize over
parametrized spaces of decision policies such as logistic treatment assignment.
We assess our methods on synthetic data and a large clinical trial,
demonstrating that confounded selection can hinder policy learning and lead to
unwarranted harm, while our robust approach guarantees safety and focuses on
well-evidenced improvement.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kallus_N/0/1/0/all/0/1&quot;&gt;Nathan Kallus&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_A/0/1/0/all/0/1&quot;&gt;Angela Zhou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08610">
<title>Optimization, fast and slow: optimally switching between local and Bayesian optimization. (arXiv:1805.08610v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.08610</link>
<description rdf:parseType="Literal">&lt;p&gt;We develop the first Bayesian Optimization algorithm, BLOSSOM, which selects
between multiple alternative acquisition functions and traditional local
optimization at each step. This is combined with a novel stopping condition
based on expected regret. This pairing allows us to obtain the best
characteristics of both local and Bayesian optimization, making efficient use
of function evaluations while yielding superior convergence to the global
minimum on a selection of optimization problems, and also halting optimization
once a principled and intuitive stopping condition has been fulfilled.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+McLeod_M/0/1/0/all/0/1&quot;&gt;Mark McLeod&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Osborne_M/0/1/0/all/0/1&quot;&gt;Michael A. Osborne&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Roberts_S/0/1/0/all/0/1&quot;&gt;Stephen J. Roberts&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08622">
<title>Transitions, Losses, and Re-parameterizations: Elements of Prediction Games. (arXiv:1805.08622v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.08622</link>
<description rdf:parseType="Literal">&lt;p&gt;This thesis presents some geometric insights into three different types of
two player prediction games -- namely general learning task, prediction with
expert advice, and online convex optimization. These games differ in the nature
of the opponent (stochastic, adversarial, or intermediate), the order of the
players&apos; move, and the utility function. The insights shed some light on the
understanding of the intrinsic barriers of the prediction problems and the
design of computationally efficient learning algorithms with strong theoretical
guarantees (such as generalizability, statistical consistency, and constant
regret etc.).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kamalaruban_P/0/1/0/all/0/1&quot;&gt;Parameswaran Kamalaruban&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08638">
<title>Cost-aware Cascading Bandits. (arXiv:1805.08638v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.08638</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we propose a cost-aware cascading bandits model, a new variant
of multi-armed ban- dits with cascading feedback, by considering the random
cost of pulling arms. In each step, the learning agent chooses an ordered list
of items and examines them sequentially, until certain stopping condition is
satisfied. Our objective is then to max- imize the expected net reward in each
step, i.e., the reward obtained in each step minus the total cost in- curred in
examining the items, by deciding the or- dered list of items, as well as when
to stop examina- tion. We study both the offline and online settings, depending
on whether the state and cost statistics of the items are known beforehand. For
the of- fline setting, we show that the Unit Cost Ranking with Threshold 1
(UCR-T1) policy is optimal. For the online setting, we propose a Cost-aware
Cas- cading Upper Confidence Bound (CC-UCB) algo- rithm, and show that the
cumulative regret scales in O(log T ). We also provide a lower bound for all
{\alpha}-consistent policies, which scales in {\Omega}(log T ) and matches our
upper bound. The performance of the CC-UCB algorithm is evaluated with both
synthetic and real-world data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_R/0/1/0/all/0/1&quot;&gt;Ruida Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gan_C/0/1/0/all/0/1&quot;&gt;Chao Gan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yan_J/0/1/0/all/0/1&quot;&gt;Jing Yan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_C/0/1/0/all/0/1&quot;&gt;Cong Shen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08647">
<title>Multi-Statistic Approximate Bayesian Computation with Multi-Armed Bandits. (arXiv:1805.08647v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.08647</link>
<description rdf:parseType="Literal">&lt;p&gt;Approximate Bayesian computation is an established and popular method for
likelihood-free inference with applications in many disciplines. The
effectiveness of the method depends critically on the availability of well
performing summary statistics. Summary statistic selection relies heavily on
domain knowledge and carefully engineered features, and can be a laborious time
consuming process. Since the method is sensitive to data dimensionality, the
process of selecting summary statistics must balance the need to include
informative statistics and the dimensionality of the feature vector. This paper
proposes to treat the problem of dynamically selecting an appropriate summary
statistic from a given pool of candidate summary statistics as a multi-armed
bandit problem. This allows approximate Bayesian computation rejection sampling
to dynamically focus on a distribution over well performing summary statistics
as opposed to a fixed set of statistics. The proposed method is unique in that
it does not require any pre-processing and is scalable to a large number of
candidate statistics. This enables efficient use of a large library of possible
time series summary statistics without prior feature engineering. The proposed
approach is compared to state-of-the-art methods for summary statistics
selection using a challenging test problem from the systems biology literature.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Singh_P/0/1/0/all/0/1&quot;&gt;Prashant Singh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hellander_A/0/1/0/all/0/1&quot;&gt;Andreas Hellander&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08651">
<title>Nonlinear ICA Using Auxiliary Variables and Generalized Contrastive Learning. (arXiv:1805.08651v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.08651</link>
<description rdf:parseType="Literal">&lt;p&gt;Nonlinear ICA is a fundamental problem for unsupervised representation
learning, emphasizing the capacity to recover the underlying latent variables
generating the data (i.e., identifiability). Recently, the very first
identifiability proofs for nonlinear ICA have been proposed, leveraging the
temporal structure of the independent components. Here, we propose a general
framework for nonlinear ICA, which, as a special case, can make use of temporal
structure. It is based on augmenting the data by an auxiliary variable, such as
the time index, the history of the time series, or any other available
information. We propose to learn nonlinear ICA by discriminating between true
augmented data, or data in which the auxiliary variable has been randomized.
This enables the framework to be implemented algorithmically through logistic
regression, possibly in a neural network. We provide a comprehensive proof of
the identifiability of the model as well as the consistency of our estimation
method. The approach not only provides a general theoretical framework
combining and generalizing previously proposed nonlinear ICA models and
algorithms, but also brings practical advantages.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hyvarinen_A/0/1/0/all/0/1&quot;&gt;Aapo Hyvarinen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sasaki_H/0/1/0/all/0/1&quot;&gt;Hiroaki Sasaki&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Turner_R/0/1/0/all/0/1&quot;&gt;Richard E. Turner&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08665">
<title>Structured Bayesian Gaussian process latent variable model. (arXiv:1805.08665v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.08665</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce a Bayesian Gaussian process latent variable model that
explicitly captures spatial correlations in data using a parameterized spatial
kernel and leveraging structure-exploiting algebra on the model covariance
matrices for computational tractability. Inference is made tractable through a
collapsed variational bound with similar computational complexity to that of
the traditional Bayesian GP-LVM. Inference over partially-observed test cases
is achieved by optimizing a &quot;partially-collapsed&quot; bound. Modeling
high-dimensional time series systems is enabled through use of a dynamical GP
latent variable prior. Examples imputing missing data on images and
super-resolution imputation of missing video frames demonstrate the model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Atkinson_S/0/1/0/all/0/1&quot;&gt;Steven Atkinson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zabaras_N/0/1/0/all/0/1&quot;&gt;Nicholas Zabaras&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08672">
<title>Information Constraints on Auto-Encoding Variational Bayes. (arXiv:1805.08672v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.08672</link>
<description rdf:parseType="Literal">&lt;p&gt;Parameterizing the approximate posterior of a generative model with neural
networks has become a common theme in recent machine learning research. While
providing appealing flexibility, this approach makes it difficult to impose or
assess structural constraints such as conditional independence. We propose a
framework for learning representations that relies on Auto-Encoding Variational
Bayes and whose search space is constrained via kernel-based measures of
independence. In particular, our method employs the $d$-variable
Hilbert-Schmidt Independence Criterion (dHSIC) to enforce independence between
the latent representations and arbitrary nuisance factors. We show how to apply
this method to a range of problems, including the problems of learning
invariant representations and the learning of interpretable representations. We
also present a full-fledged application to single-cell RNA sequencing
(scRNA-seq). In this setting the biological signal in mixed in complex ways
with sequencing errors and sampling effects. We show that our method
out-performs the state-of-the-art in this domain.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lopez_R/0/1/0/all/0/1&quot;&gt;Romain Lopez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Regier_J/0/1/0/all/0/1&quot;&gt;Jeffrey Regier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yosef_N/0/1/0/all/0/1&quot;&gt;Nir Yosef&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jordan_M/0/1/0/all/0/1&quot;&gt;Michael I. Jordan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08727">
<title>Algorithms and Theory for Multiple-Source Adaptation. (arXiv:1805.08727v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.08727</link>
<description rdf:parseType="Literal">&lt;p&gt;This work includes a number of novel contributions for the multiple-source
adaptation problem. We present new normalized solutions with strong theoretical
guarantees for the cross-entropy loss and other similar losses. We also provide
new guarantees that hold in the case where the conditional probabilities for
the source domains are distinct. Moreover, we give new algorithms for
determining the distribution-weighted combination solution for the
cross-entropy loss and other losses. We report the results of a series of
experiments with real-world datasets. We find that our algorithm outperforms
competing approaches by producing a single robust model that performs well on
any target mixture distribution. Altogether, our theory, algorithms, and
empirical results provide a full solution for the multiple-source adaptation
problem with very practical benefits.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hoffman_J/0/1/0/all/0/1&quot;&gt;Judy Hoffman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mohri_M/0/1/0/all/0/1&quot;&gt;Mehryar Mohri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_N/0/1/0/all/0/1&quot;&gt;Ningshan Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08728">
<title>Efficient Stochastic Gradient Descent for Distributionally Robust Learning. (arXiv:1805.08728v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.08728</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider a new stochastic gradient descent algorithm for efficiently
solving general min-max optimization problems that arise naturally in
distributionally robust learning. By focusing on the entire dataset, current
approaches do not scale well. We address this issue by initially focusing on a
subset of the data and progressively increasing this support to statistically
cover the entire dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ghosh_S/0/1/0/all/0/1&quot;&gt;Soumyadip Ghosh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Squillante_M/0/1/0/all/0/1&quot;&gt;Mark Squillante&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wollega_E/0/1/0/all/0/1&quot;&gt;Ebisa Wollega&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1604.04706">
<title>DS-MLR: Exploiting Double Separability for Scaling up Distributed Multinomial Logistic Regression. (arXiv:1604.04706v6 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1604.04706</link>
<description rdf:parseType="Literal">&lt;p&gt;Scaling multinomial logistic regression to datasets with very large number of
data points and classes is challenging. This is primarily because one needs to
compute the log-partition function on every data point. This makes distributing
the computation hard. In this paper, we present a distributed stochastic
gradient descent based optimization method (DS-MLR) for scaling up multinomial
logistic regression problems to massive scale datasets without hitting any
storage constraints on the data and model parameters. Our algorithm exploits
double-separability, an attractive property that allows us to achieve both data
as well as model parallelism simultaneously. In addition, we introduce a
non-blocking and asynchronous variant of our algorithm that avoids
bulk-synchronization. We demonstrate the versatility of DS-MLR to various
scenarios in data and model parallelism, through an extensive empirical study
using several real-world datasets. In particular, we demonstrate the
scalability of DS-MLR by solving an extreme multi-class classification problem
on the Reddit dataset (228 GB data, 358 GB parameters) where, to the best of
our knowledge, no other existing methods apply.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Raman_P/0/1/0/all/0/1&quot;&gt;Parameswaran Raman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Srinivasan_S/0/1/0/all/0/1&quot;&gt;Sriram Srinivasan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Matsushima_S/0/1/0/all/0/1&quot;&gt;Shin Matsushima&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xinhua Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yun_H/0/1/0/all/0/1&quot;&gt;Hyokun Yun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vishwanathan_S/0/1/0/all/0/1&quot;&gt;S.V.N. Vishwanathan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1605.09499">
<title>Extreme Stochastic Variational Inference: Distributed and Asynchronous. (arXiv:1605.09499v8 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1605.09499</link>
<description rdf:parseType="Literal">&lt;p&gt;Stochastic variational inference (SVI), the state-of-the-art algorithm for
scaling variational inference to large-datasets, is inherently serial.
Moreover, it requires the parameters to fit in the memory of a single
processor; this is problematic when the number of parameters is in billions. In
this paper, we propose extreme stochastic variational inference (ESVI), an
asynchronous and lock-free algorithm to perform variational inference for
mixture models on massive real world datasets. ESVI overcomes the limitations
of SVI by requiring that each processor only access a subset of the data and a
subset of the parameters, thus providing data and model parallelism
simultaneously. We demonstrate the effectiveness of ESVI by running Latent
Dirichlet Allocation (LDA) on UMBC-3B, a dataset that has a vocabulary of 3
million and a token size of 3 billion. In our experiments, we found that ESVI
not only outperforms VI and SVI in wallclock-time, but also achieves a better
quality solution. In addition, we propose a strategy to speed up computation
and save memory when fitting large number of topics.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Jiong Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Raman_P/0/1/0/all/0/1&quot;&gt;Parameswaran Raman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ji_S/0/1/0/all/0/1&quot;&gt;Shihao Ji&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yu_H/0/1/0/all/0/1&quot;&gt;Hsiang-Fu Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Vishwanathan_S/0/1/0/all/0/1&quot;&gt;S.V.N. Vishwanathan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Dhillon_I/0/1/0/all/0/1&quot;&gt;Inderjit S. Dhillon&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1607.00696">
<title>Variational limits of k-NN graph based functionals on data clouds. (arXiv:1607.00696v3 [math.ST] UPDATED)</title>
<link>http://arxiv.org/abs/1607.00696</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper studies the large sample asymptotics of data analysis procedures
based on the optimization of functionals defined on $k$-NN graphs on point
clouds. The paper is framed in the context of minimization of balanced cut
functionals, but our techniques, ideas and results can be adapted to other
functionals of relevance. We rigorously show that provided the number of
neighbors in the graph $k:=k_n$ scales with the number of points in the cloud
as $n \gg k_n \gg \log(n)$, then with probability one, the solution to the
graph cut optimization problem converges towards the solution of an analogue
variational problem at the continuum level.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Trillos_N/0/1/0/all/0/1&quot;&gt;Nicolas Garcia Trillos&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.05289">
<title>Optimal approximation of piecewise smooth functions using deep ReLU neural networks. (arXiv:1709.05289v4 [math.FA] UPDATED)</title>
<link>http://arxiv.org/abs/1709.05289</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the necessary and sufficient complexity of ReLU neural networks---in
terms of depth and number of weights---which is required for approximating
classifier functions in $L^2$. As a model class, we consider the set
$\mathcal{E}^\beta (\mathbb R^d)$ of possibly discontinuous piecewise $C^\beta$
functions $f : [-1/2, 1/2]^d \to \mathbb R$, where the different smooth regions
of $f$ are separated by $C^\beta$ hypersurfaces. For dimension $d \geq 2$,
regularity $\beta &amp;gt; 0$, and accuracy $\varepsilon &amp;gt; 0$, we construct artificial
neural networks with ReLU activation function that approximate functions from
$\mathcal{E}^\beta(\mathbb R^d)$ up to $L^2$ error of $\varepsilon$. The
constructed networks have a fixed number of layers, depending only on $d$ and
$\beta$, and they have $O(\varepsilon^{-2(d-1)/\beta})$ many nonzero weights,
which we prove to be optimal. In addition to the optimality in terms of the
number of weights, we show that in order to achieve the optimal approximation
rate, one needs ReLU networks of a certain depth. Precisely, for piecewise
$C^\beta(\mathbb R^d)$ functions, this minimal depth is given---up to a
multiplicative constant---by $\beta/d$. Up to a log factor, our constructed
networks match this bound. This partly explains the benefits of depth for ReLU
networks by showing that deep networks are necessary to achieve efficient
approximation of (piecewise) smooth functions. Finally, we analyze
approximation in high-dimensional spaces where the function $f$ to be
approximated can be factorized into a smooth dimension reducing feature map
$\tau$ and classifier function $g$---defined on a low-dimensional feature
space---as $f = g \circ \tau$. We show that in this case the approximation rate
depends only on the dimension of the feature space and not the input dimension.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Petersen_P/0/1/0/all/0/1&quot;&gt;Philipp Petersen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Voigtlaender_F/0/1/0/all/0/1&quot;&gt;Felix Voigtlaender&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.07616">
<title>General Bayesian Updating and the Loss-Likelihood Bootstrap. (arXiv:1709.07616v2 [stat.ME] UPDATED)</title>
<link>http://arxiv.org/abs/1709.07616</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper we revisit the weighted likelihood bootstrap, a method that
generates samples from an approximate Bayesian posterior of a parametric model.
We show that the same method can be derived, without approximation, under a
Bayesian nonparametric model with the parameter of interest defined as
minimising an expected negative log-likelihood under an unknown sampling
distribution. This interpretation enables us to extend the weighted likelihood
bootstrap to posterior sampling for parameters minimizing an expected loss. We
call this method the loss-likelihood bootstrap. We make a connection between
this and general Bayesian updating, which is a way of updating prior belief
distributions without needing to construct a global probability model, yet
requires the calibration of two forms of loss function. The loss-likelihood
bootstrap is used to calibrate the general Bayesian posterior by matching
asymptotic Fisher information. We demonstrate the methodology on a number of
examples.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lyddon_S/0/1/0/all/0/1&quot;&gt;Simon Lyddon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Holmes_C/0/1/0/all/0/1&quot;&gt;Chris Holmes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Walker_S/0/1/0/all/0/1&quot;&gt;Stephen Walker&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.05241">
<title>Robust Decentralized Learning Using ADMM with Unreliable Agents. (arXiv:1710.05241v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1710.05241</link>
<description rdf:parseType="Literal">&lt;p&gt;Many machine learning problems can be formulated as consensus optimization
problems which can be solved efficiently via a cooperative multi-agent system.
However, the agents in the system can be unreliable due to a variety of
reasons: noise, faults and attacks. Providing erroneous updates leads the
optimization process in a wrong direction, and degrades the performance of
distributed machine learning algorithms. This paper considers the problem of
decentralized learning using ADMM in the presence of unreliable agents. First,
we rigorously analyze the effect of erroneous updates (in ADMM learning
iterations) on the convergence behavior of multi-agent system. We show that the
algorithm linearly converges to a neighborhood of the optimal solution under
certain conditions and characterize the neighborhood size analytically. Next,
we provide guidelines for network design to achieve a faster convergence. We
also provide conditions on the erroneous updates for exact convergence to the
optimal solution. Finally, to mitigate the influence of unreliable agents, we
propose \textsf{ROAD}, a robust variant of ADMM, and show its resilience to
unreliable agents with an exact convergence to the optimum.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1&quot;&gt;Qunwei Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kailkhura_B/0/1/0/all/0/1&quot;&gt;Bhavya Kailkhura&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goldhahn_R/0/1/0/all/0/1&quot;&gt;Ryan Goldhahn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ray_P/0/1/0/all/0/1&quot;&gt;Priyadip Ray&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Varshney_P/0/1/0/all/0/1&quot;&gt;Pramod K. Varshney&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.04126">
<title>Adversarial Training for Disease Prediction from Electronic Health Records with Missing Data. (arXiv:1711.04126v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1711.04126</link>
<description rdf:parseType="Literal">&lt;p&gt;Electronic health records (EHRs) have contributed to the computerization of
patient records and can thus be used not only for efficient and systematic
medical services, but also for research on biomedical data science. However,
there are many missing values in EHRs when provided in matrix form, which is an
important issue in many biomedical EHR applications. In this paper, we propose
a two-stage framework that includes missing data imputation and disease
prediction to address the missing data problem in EHRs. We compared the disease
prediction performance of generative adversarial networks (GANs) and
conventional learning algorithms in combination with missing data prediction
methods. As a result, we obtained a level of accuracy of 0.9777, sensitivity of
0.9521, specificity of 0.9925, area under the receiver operating characteristic
curve (AUC-ROC) of 0.9889, and F-score of 0.9688 with a stacked autoencoder as
the missing data prediction method and an auxiliary classifier GAN (AC-GAN) as
the disease prediction method. The comparison results show that a combination
of a stacked autoencoder and an AC-GAN significantly outperforms other existing
approaches. Our results suggest that the proposed framework is more robust for
disease prediction from EHRs with missing data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hwang_U/0/1/0/all/0/1&quot;&gt;Uiwon Hwang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Choi_S/0/1/0/all/0/1&quot;&gt;Sungwoon Choi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_H/0/1/0/all/0/1&quot;&gt;Han-Byoel Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yoon_S/0/1/0/all/0/1&quot;&gt;Sungroh Yoon&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.05134">
<title>Learning Compact Recurrent Neural Networks with Block-Term Tensor Decomposition. (arXiv:1712.05134v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1712.05134</link>
<description rdf:parseType="Literal">&lt;p&gt;Recurrent Neural Networks (RNNs) are powerful sequence modeling tools.
However, when dealing with high dimensional inputs, the training of RNNs
becomes computational expensive due to the large number of model parameters.
This hinders RNNs from solving many important computer vision tasks, such as
Action Recognition in Videos and Image Captioning. To overcome this problem, we
propose a compact and flexible structure, namely Block-Term tensor
decomposition, which greatly reduces the parameters of RNNs and improves their
training efficiency. Compared with alternative low-rank approximations, such as
tensor-train RNN (TT-RNN), our method, Block-Term RNN (BT-RNN), is not only
more concise (when using the same rank), but also able to attain a better
approximation to the original RNNs with much fewer parameters. On three
challenging tasks, including Action Recognition in Videos, Image Captioning and
Image Generation, BT-RNN outperforms TT-RNN and the standard RNN in terms of
both prediction accuracy and convergence rate. Specifically, BT-LSTM utilizes
17,388 times fewer parameters than the standard LSTM to achieve an accuracy
improvement over 15.6\% in the Action Recognition task on the UCF11 dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1&quot;&gt;Jinmian Ye&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1&quot;&gt;Linnan Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1&quot;&gt;Guangxi Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1&quot;&gt;Di Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhe_S/0/1/0/all/0/1&quot;&gt;Shandian Zhe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chu_X/0/1/0/all/0/1&quot;&gt;Xinqi Chu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1&quot;&gt;Zenglin Xu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.06302">
<title>Visual Explanation by Interpretation: Improving Visual Feedback Capabilities of Deep Neural Networks. (arXiv:1712.06302v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1712.06302</link>
<description rdf:parseType="Literal">&lt;p&gt;Learning-based representations have become the de facto means to address
computer vision tasks. Despite their massive adoption, the amount of work
aiming at understanding the internal representations learned by these models is
rather limited. Existing methods for model interpretation either require
exhaustive manual inspection of visualizations, or link internal network
activations with external &quot;possibly useful&quot; annotated concepts. In this paper,
we propose an intermediate scheme in which, given a pretrained model, we
automatically identify internal features relevant for the set of classes
considered by the model, without requiring additional annotations. We interpret
the model through average visualizations of these features. Then, at test time,
we explain the network prediction by accompanying the predicted class label
with supporting heatmap visualizations derived from the identified relevant
features. In addition, we propose a method to address the artifacts introduced
by strided operations in deconvnet-based visualizations. Moreover, we introduce
an8Flower, a dataset specifically designed for the qualitative and quantitative
evaluation of methods for model explanation. Our evaluation on the MNIST,
ILSVRC12, Fashion144k and an8Flower datasets shows that the proposed method is
able to identify relevant internal features for the classes of interest while
improving the quality of the produced visualizations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oramas_J/0/1/0/all/0/1&quot;&gt;Jose Oramas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1&quot;&gt;Kaili Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tuytelaars_T/0/1/0/all/0/1&quot;&gt;Tinne Tuytelaars&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.08289">
<title>Learning and Transferring IDs Representation in E-commerce. (arXiv:1712.08289v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1712.08289</link>
<description rdf:parseType="Literal">&lt;p&gt;Many machine intelligence techniques are developed in E-commerce and one of
the most essential components is the representation of IDs, including user ID,
item ID, product ID, store ID, brand ID, category ID etc. The classical
encoding based methods (like one-hot encoding) are inefficient in that it
suffers sparsity problems due to its high dimension, and it cannot reflect the
relationships among IDs, either homogeneous or heterogeneous ones. In this
paper, we propose an embedding based framework to learn and transfer the
representation of IDs. As the implicit feedbacks of users, a tremendous amount
of item ID sequences can be easily collected from the interactive sessions. By
jointly using these informative sequences and the structural connections among
IDs, all types of IDs can be embedded into one low-dimensional semantic space.
Subsequently, the learned representations are utilized and transferred in four
scenarios: (i) measuring the similarity between items, (ii) transferring from
seen items to unseen items, (iii) transferring across different domains, (iv)
transferring across different tasks. We deploy and evaluate the proposed
approach in Hema App and the results validate its effectiveness.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_K/0/1/0/all/0/1&quot;&gt;Kui Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yuechuan Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shuai_Z/0/1/0/all/0/1&quot;&gt;Zhaoqian Shuai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1&quot;&gt;Cheng Yang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04034">
<title>Lipschitz-Margin Training: Scalable Certification of Perturbation Invariance for Deep Neural Networks. (arXiv:1802.04034v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1802.04034</link>
<description rdf:parseType="Literal">&lt;p&gt;High sensitivity of neural networks against malicious perturbations on inputs
causes security concerns. To take a steady step towards robust classifiers, we
aim to create neural network models provably defended from perturbations. Prior
certification work requires strong assumptions on network structures and
massive computational costs, and thus, their applications are limited. Based on
the relationship between the Lipschitz constants and prediction margins, we
present a computationally efficient calculation technique that lower-bounds the
size of adversarial perturbations that can deceive networks, and that is widely
applicable to various complicated networks. Moreover, we propose an efficient
training procedure, which robustifies networks and significantly improves the
provably guarded areas around data points. In experimental evaluations, our
method showed its ability to provide a non-trivial guarantee and improve
robustness for even large networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tsuzuku_Y/0/1/0/all/0/1&quot;&gt;Yusuke Tsuzuku&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sato_I/0/1/0/all/0/1&quot;&gt;Issei Sato&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sugiyama_M/0/1/0/all/0/1&quot;&gt;Masashi Sugiyama&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05451">
<title>Mapping Images to Scene Graphs with Permutation-Invariant Structured Prediction. (arXiv:1802.05451v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1802.05451</link>
<description rdf:parseType="Literal">&lt;p&gt;Machine understanding of complex images is a key goal of artificial
intelligence. One challenge underlying this task is that visual scenes contain
multiple inter-related objects, and that global context plays an important role
in interpreting the scene. A natural modeling framework for capturing such
effects is structured prediction, which optimizes over complex labels, while
modeling within-label interactions. However, it is unclear what principles
should guide the design of a structured prediction model that utilizes the
power of deep learning components. Here we propose a design principle for such
architectures that follows from a natural requirement of permutation
invariance. We prove a necessary and sufficient characterization for
architectures that follow this invariance, and discuss its implication on model
design. Finally, we show that the resulting model achieves new state of the art
results on the Visual Genome scene graph labeling benchmark, outperforming all
recent approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Herzig_R/0/1/0/all/0/1&quot;&gt;Roei Herzig&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Raboh_M/0/1/0/all/0/1&quot;&gt;Moshiko Raboh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chechik_G/0/1/0/all/0/1&quot;&gt;Gal Chechik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Berant_J/0/1/0/all/0/1&quot;&gt;Jonathan Berant&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Globerson_A/0/1/0/all/0/1&quot;&gt;Amir Globerson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06104">
<title>Information-theoretic Limits for Community Detection in Network Models. (arXiv:1802.06104v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1802.06104</link>
<description rdf:parseType="Literal">&lt;p&gt;We analyze the information-theoretic limits for the recovery of node labels
in several network models. This includes the Stochastic Block Model, the
Exponential Random Graph Model, the Latent Space Model, the Directed
Preferential Attachment Model, and the Directed Small-world Model. For the
Stochastic Block Model, the non-recoverability condition depends on the
probabilities of having edges inside a community, and between different
communities. For the Latent Space Model, the non-recoverability condition
depends on the dimension of the latent space, and how far and spread are the
communities in the latent space. For the Directed Preferential Attachment Model
and the Directed Small-world Model, the non-recoverability condition depends on
the ratio between homophily and neighborhood size. We also consider dynamic
versions of the Stochastic Block Model and the Latent Space Model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ke_C/0/1/0/all/0/1&quot;&gt;Chuyang Ke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Honorio_J/0/1/0/all/0/1&quot;&gt;Jean Honorio&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06847">
<title>Distribution Matching in Variational Inference. (arXiv:1802.06847v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1802.06847</link>
<description rdf:parseType="Literal">&lt;p&gt;We show that Variational Autoencoders consistently fail to learn marginal
distributions in latent and visible space. We ask whether this is a consequence
of matching conditional distributions, or a limitation of explicit model and
posterior distributions. We explore alternatives provided by marginal
distribution matching and implicit distributions through the use of Generative
Adversarial Networks in variational inference. We perform a large-scale
evaluation of several VAE-GAN hybrids and explore the implications of class
probability estimation for learning distributions. We conclude that at present
VAE-GAN hybrids have limited applicability: they are harder to scale, evaluate,
and use for inference compared to VAEs; and they do not improve over the
generation quality of GANs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rosca_M/0/1/0/all/0/1&quot;&gt;Mihaela Rosca&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lakshminarayanan_B/0/1/0/all/0/1&quot;&gt;Balaji Lakshminarayanan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mohamed_S/0/1/0/all/0/1&quot;&gt;Shakir Mohamed&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08012">
<title>A Network Approach to Learning Supervised Topic Model with Word Embedding. (arXiv:1802.08012v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1802.08012</link>
<description rdf:parseType="Literal">&lt;p&gt;Topic models are frequently used in machine learning owing to their high
interpretability and modular structure. However, extending a topic model to
include a supervisory signal, to incorporate pre-trained word embedding vectors
and to include a nonlinear output function is not an easy task because one has
to resort to a highly intricate approximate inference procedure. The present
paper shows that topic modeling can be viewed as implementing a neighborhood
aggregation algorithm where messages are passed through a network defined over
words. From the network view of topic models, nodes correspond to words in a
document and edges correspond to either a relationship describing co-occurring
words in a document or a relationship describing the same word in the corpus.
The network view allows us to extend the model to include supervisory signals,
incorporate pre-trained word embedding vectors and include a nonlinear output
function in a simple manner. Moreover, we describe a simple way to train the
model that is well suited to a semi-supervised setting where we only have
supervisory signals for some portion of the corpus and the goal is to improve
prediction performance in the held-out data. In experiments, we show that our
approach outperforms the state-of-the-art supervised Latent Dirichlet
Allocation implementation in terms of both held-out document classification
tasks and topic coherence.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hisano_R/0/1/0/all/0/1&quot;&gt;Ryohei Hisano&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08249">
<title>On the Convergence and Robustness of Training GANs with Regularized Optimal Transport. (arXiv:1802.08249v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1802.08249</link>
<description rdf:parseType="Literal">&lt;p&gt;Generative Adversarial Networks (GANs) are one of the most practical methods
for learning data distributions. A popular GAN formulation is based on the use
of Wasserstein distance as a metric between probability distributions.
Unfortunately, minimizing the Wasserstein distance between the data
distribution and the generative model distribution is a computationally
challenging problem as its objective is non-convex, non-smooth, and even hard
to compute. In this work, we show that obtaining gradient information of the
smoothed Wasserstein GAN formulation, which is based on regularized Optimal
Transport (OT), is computationally effortless and hence one can apply first
order optimization methods to minimize this objective. Consequently, we
establish theoretical convergence guarantee to stationarity for a proposed
class of GAN optimization algorithms. Unlike the original non-smooth
formulation, our algorithm only requires solving the discriminator to
approximate optimality. We apply our method to learning MNIST digits as well as
CIFAR-10images. Our experiments show that our method is computationally
efficient and generates images comparable to the state of the art algorithms
given the same architecture and computational power.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sanjabi_M/0/1/0/all/0/1&quot;&gt;Maziar Sanjabi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ba_J/0/1/0/all/0/1&quot;&gt;Jimmy Ba&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Razaviyayn_M/0/1/0/all/0/1&quot;&gt;Meisam Razaviyayn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1&quot;&gt;Jason D. Lee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.10988">
<title>SHADE: Information Based Regularization for Deep Learning. (arXiv:1804.10988v4 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1804.10988</link>
<description rdf:parseType="Literal">&lt;p&gt;Regularization is a big issue for training deep neural networks. In this
paper, we propose a new information-theory-based regularization scheme named
SHADE for SHAnnon DEcay. The originality of the approach is to define a prior
based on conditional entropy, which explicitly decouples the learning of
invariant representations in the regularizer and the learning of correlations
between inputs and labels in the data fitting term. Our second contribution is
to derive a stochastic version of the regularizer compatible with deep
learning, resulting in a tractable training scheme. We empirically validate the
efficiency of our approach to improve classification performances compared to
common regularization schemes on several standard architectures.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Blot_M/0/1/0/all/0/1&quot;&gt;Michael Blot&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Robert_T/0/1/0/all/0/1&quot;&gt;Thomas Robert&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Thome_N/0/1/0/all/0/1&quot;&gt;Nicolas Thome&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Cord_M/0/1/0/all/0/1&quot;&gt;Matthieu Cord&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.00915">
<title>Neural Networks as Interacting Particle Systems: Asymptotic Convexity of the Loss Landscape and Universal Scaling of the Approximation Error. (arXiv:1805.00915v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1805.00915</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural networks, a central tool in machine learning, have demonstrated
remarkable, high fidelity performance on image recognition and classification
tasks. These successes evince an ability to accurately represent high
dimensional functions, potentially of great use in computational and applied
mathematics. That said, there are few rigorous results about the representation
error and trainability of neural networks. Here we characterize both the error
and the scaling of the error with the size of the network by reinterpreting the
standard optimization algorithm used in machine learning applications,
stochastic gradient descent, as the evolution of a particle system with
interactions governed by a potential related to the objective or &quot;loss&quot;
function used to train the network. We show that, when the number $n$ of
parameters is large, the empirical distribution of the particles descends on a
convex landscape towards a minimizer at a rate independent of $n$. We establish
a Law of Large Numbers and a Central Limit Theorem for the empirical
distribution, which together show that the approximation error of the network
universally scales as $O(n^{-1})$. Remarkably, these properties do not depend
on the dimensionality of the domain of the function that we seek to represent.
Our analysis also quantifies the scale and nature of the noise introduced by
stochastic gradient descent and provides guidelines for the step size and batch
size to use when training a neural network. We illustrate our findings on
examples in which we train neural network to learn the energy function of the
continuous 3-spin model on the sphere. The approximation error scales as our
analysis predicts in as high a dimension as $d=25$.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rotskoff_G/0/1/0/all/0/1&quot;&gt;Grant M. Rotskoff&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Vanden_Eijnden_E/0/1/0/all/0/1&quot;&gt;Eric Vanden-Eijnden&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.03463">
<title>Dealing with Categorical and Integer-valued Variables in Bayesian Optimization with Gaussian Processes. (arXiv:1805.03463v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1805.03463</link>
<description rdf:parseType="Literal">&lt;p&gt;Bayesian Optimization (BO) methods are useful for optimizing functions that
are expen- sive to evaluate, lack an analytical expression and whose
evaluations can be contaminated by noise. These methods rely on a probabilistic
model of the objective function, typically a Gaussian process (GP), upon which
an acquisition function is built. The acquisition function guides the
optimization process and measures the expected utility of performing an
evaluation of the objective at a new point. GPs assume continous input
variables. When this is not the case, for example when some of the input
variables take categorical or integer values, one has to introduce extra
approximations. Consider a suggested input location taking values in the real
line. Before doing the evaluation of the objective, a common approach is to use
a one hot encoding approximation for categorical variables, or to round to the
closest integer, in the case of integer-valued variables. We show that this can
lead to problems in the optimization process and describe a more principled
approach to account for input variables that are categorical or integer-valued.
We illustrate in both synthetic and a real experiments the utility of our
approach, which significantly improves the results of standard BO methods using
Gaussian processes on problems with categorical or integer-valued variables.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Garrido_Merchan_E/0/1/0/all/0/1&quot;&gt;Eduardo C. Garrido-Merch&amp;#xe1;n&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hernandez_Lobato_D/0/1/0/all/0/1&quot;&gt;Daniel Hern&amp;#xe1;ndez-Lobato&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07777">
<title>DLBI: Deep learning guided Bayesian inference for structure reconstruction of super-resolution fluorescence microscopy. (arXiv:1805.07777v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1805.07777</link>
<description rdf:parseType="Literal">&lt;p&gt;Super-resolution fluorescence microscopy, with a resolution beyond the
diffraction limit of light, has become an indispensable tool to directly
visualize biological structures in living cells at a nanometer-scale
resolution. Despite advances in high-density super-resolution fluorescent
techniques, existing methods still have bottlenecks, including extremely long
execution time, artificial thinning and thickening of structures, and lack of
ability to capture latent structures. Here we propose a novel deep learning
guided Bayesian inference approach, DLBI, for the time-series analysis of
high-density fluorescent images. Our method combines the strength of deep
learning and statistical inference, where deep learning captures the underlying
distribution of the fluorophores that are consistent with the observed
time-series fluorescent images by exploring local features and correlation
along time-axis, and statistical inference further refines the ultrastructure
extracted by deep learning and endues physical meaning to the final image.
Comprehensive experimental results on both real and simulated datasets
demonstrate that our method provides more accurate and realistic local patch
and large-field reconstruction than the state-of-the-art method, the 3B
analysis, while our method is more than two orders of magnitude faster. The
main program is available at https://github.com/lykaust15/DLBI
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yu Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_F/0/1/0/all/0/1&quot;&gt;Fan Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1&quot;&gt;Fa Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_P/0/1/0/all/0/1&quot;&gt;Pingyong Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1&quot;&gt;Mingshu Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fan_M/0/1/0/all/0/1&quot;&gt;Ming Fan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1&quot;&gt;Lihua Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_X/0/1/0/all/0/1&quot;&gt;Xin Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Han_R/0/1/0/all/0/1&quot;&gt;Renmin Han&lt;/a&gt;</dc:creator>
</item></rdf:RDF>