<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Boring papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Bad Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-05-23T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08878"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08889"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08932"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09244"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08680"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08874"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08882"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08913"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08915"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08930"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08948"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08966"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08975"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09044"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09045"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09137"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09145"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09169"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09197"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09218"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09235"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09238"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09267"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.00503"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.05060"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.11223"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05844"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.07779"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07733"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08808"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08836"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08838"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08845"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08890"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08920"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08952"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08956"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08957"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08970"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08974"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09023"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09076"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09091"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09108"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09114"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09213"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09217"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09247"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09253"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09266"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09281"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09293"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09294"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09302"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1503.05509"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1608.08063"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1611.02401"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1702.08134"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.06181"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.02766"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08855"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.10551"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.01314"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.01682"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.04087"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.04899"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.05857"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08058"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08102"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08268"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08321"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08527"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1605.02536"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1805.08878">
<title>ARiA: Utilizing Richard&apos;s Curve for Controlling the Non-monotonicity of the Activation Function in Deep Neural Nets. (arXiv:1805.08878v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1805.08878</link>
<description rdf:parseType="Literal">&lt;p&gt;This work introduces a novel activation unit that can be efficiently employed
in deep neural nets (DNNs) and performs significantly better than the
traditional Rectified Linear Units (ReLU). The function developed is a two
parameter version of the specialized Richard&apos;s Curve and we call it Adaptive
Richard&apos;s Curve weighted Activation (ARiA). This function is non-monotonous,
analogous to the newly introduced Swish, however allows a precise control over
its non-monotonous convexity by varying the hyper-parameters. We first
demonstrate the mathematical significance of the two parameter ARiA followed by
its application to benchmark problems such as MNIST, CIFAR-10 and CIFAR-100,
where we compare the performance with ReLU and Swish units. Our results
illustrate a significantly superior performance on all these datasets, making
ARiA a potential replacement for ReLU and other activations in DNNs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Patwardhan_N/0/1/0/all/0/1&quot;&gt;Narendra Patwardhan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ingalhalikar_M/0/1/0/all/0/1&quot;&gt;Madhura Ingalhalikar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Walambe_R/0/1/0/all/0/1&quot;&gt;Rahee Walambe&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08889">
<title>Spiking Linear Dynamical Systems on Neuromorphic Hardware for Low-Power Brain-Machine Interfaces. (arXiv:1805.08889v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1805.08889</link>
<description rdf:parseType="Literal">&lt;p&gt;Neuromorphic architectures achieve low-power operation by using many simple
spiking neurons in lieu of traditional hardware. Here, we develop methods for
precise linear computations in spiking neural networks and use these methods to
map the evolution of a linear dynamical system (LDS) onto an existing
neuromorphic chip: IBM&apos;s TrueNorth. We analytically characterize, and
numerically validate, the discrepancy between the spiking LDS state sequence
and that of its non-spiking counterpart. These analytical results shed light on
the multiway tradeoff between time, space, energy, and accuracy in neuromorphic
computation. To demonstrate the utility of our work, we implemented a
neuromorphic Kalman filter (KF) and used it for offline decoding of human vocal
pitch from neural data. The neuromorphic KF could be used for low-power
filtering in domains beyond neuroscience, such as navigation or robotics.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Clark_D/0/1/0/all/0/1&quot;&gt;David G. Clark&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Livezey_J/0/1/0/all/0/1&quot;&gt;Jesse A. Livezey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chang_E/0/1/0/all/0/1&quot;&gt;Edward F. Chang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bouchard_K/0/1/0/all/0/1&quot;&gt;Kristofer E. Bouchard&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08932">
<title>Large-Scale Neuromorphic Spiking Array Processors: A quest to mimic the brain. (arXiv:1805.08932v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1805.08932</link>
<description rdf:parseType="Literal">&lt;p&gt;Neuromorphic engineering (NE) encompasses a diverse range of approaches to
information processing that are inspired by neurobiological systems, and this
feature distinguishes neuromorphic systems from conventional computing systems.
The brain has evolved over billions of years to solve difficult engineering
problems by using efficient, parallel, low-power computation. The goal of NE is
to design systems capable of brain-like computation. Numerous large-scale
neuromorphic projects have emerged recently. This interdisciplinary field was
listed among the top 10 technology breakthroughs of 2014 by the MIT Technology
Review and among the top 10 emerging technologies of 2015 by the World Economic
Forum. NE has two-way goals: one, a scientific goal to understand the
computational properties of biological neural systems by using models
implemented in integrated circuits (ICs); second, an engineering goal to
exploit the known properties of biological systems to design and implement
efficient devices for engineering applications. Building hardware neural
emulators can be extremely useful for simulating large-scale neural models to
explain how intelligent behavior arises in the brain. The principle advantages
of neuromorphic emulators are that they are highly energy efficient, parallel
and distributed, and require a small silicon area. Thus, compared to
conventional CPUs, these neuromorphic emulators are beneficial in many
engineering applications such as for the porting of deep learning algorithms
for various recognitions tasks. In this review article, we describe some of the
most significant neuromorphic spiking emulators, compare the different
architectures and approaches used by them, illustrate their advantages and
drawbacks, and highlight the capabilities that each can deliver to neural
modelers.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Thakur_C/0/1/0/all/0/1&quot;&gt;Chetan Singh Thakur&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Molin_J/0/1/0/all/0/1&quot;&gt;Jamal Molin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cauwenberghs_G/0/1/0/all/0/1&quot;&gt;Gert Cauwenberghs&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Indiveri_G/0/1/0/all/0/1&quot;&gt;Giacomo Indiveri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kumar_K/0/1/0/all/0/1&quot;&gt;Kundan Kumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qiao_N/0/1/0/all/0/1&quot;&gt;Ning Qiao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schemmel_J/0/1/0/all/0/1&quot;&gt;Johannes Schemmel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_R/0/1/0/all/0/1&quot;&gt;Runchun Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chicca_E/0/1/0/all/0/1&quot;&gt;Elisabetta Chicca&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hasler_J/0/1/0/all/0/1&quot;&gt;Jennifer Olson Hasler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Seo_J/0/1/0/all/0/1&quot;&gt;Jae-sun Seo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_S/0/1/0/all/0/1&quot;&gt;Shimeng Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cao_Y/0/1/0/all/0/1&quot;&gt;Yu Cao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schaik_A/0/1/0/all/0/1&quot;&gt;Andr&amp;#xe9; van Schaik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Etienne_Cummings_R/0/1/0/all/0/1&quot;&gt;Ralph Etienne-Cummings&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09244">
<title>Concentric ESN: Assessing the Effect of Modularity in Cycle Reservoirs. (arXiv:1805.09244v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1805.09244</link>
<description rdf:parseType="Literal">&lt;p&gt;The paper introduces concentric Echo State Network, an approach to design
reservoir topologies that tries to bridge the gap between deterministically
constructed simple cycle models and deep reservoir computing approaches. We
show how to modularize the reservoir into simple unidirectional and concentric
cycles with pairwise bidirectional jump connections between adjacent loops. We
provide a preliminary experimental assessment showing how concentric reservoirs
yield to superior predictive accuracy and memory capacity with respect to
single cycle reservoirs and deep reservoir models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bacciu_D/0/1/0/all/0/1&quot;&gt;Davide Bacciu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bongiorno_A/0/1/0/all/0/1&quot;&gt;Andrea Bongiorno&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08680">
<title>A Parameter Estimation of Fractional Order Grey Model Based on Adaptive Dynamic Cat Swarm Algorithm. (arXiv:1805.08680v2 [math.OC] UPDATED)</title>
<link>http://arxiv.org/abs/1805.08680</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we utilize ADCSO (Adaptive Dynamic Cat Swarm Optimization) to
estimate the parameters of Fractional Order Grey Model. The parameters of
Fractional Order Grey Model affect the prediction accuracy of the model. In
order to solve the problem that general swarm intelligence algorithms easily
fall into the local optimum and optimize the accuracy of the model, ADCSO is
utilized to reduce the error of the model. Experimental results for the data of
container throughput of Wuhan Port and marine capture productions of Zhejiang
Province show that the different parameter values affect the prediction
results. The parameters estimated by ADCSO make the prediction error of the
model smaller and the convergence speed higher, and it is not easy to fall into
the local convergence compared with PSO (Particle Swarm Optimization) and LSM
(Least Square Method). The feasibility and advantage of ADCSO for the parameter
estimation of Fractional Order Grey Model are verified.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Lin_B/0/1/0/all/0/1&quot;&gt;Binyan Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Gao_F/0/1/0/all/0/1&quot;&gt;Fei Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Wang_M/0/1/0/all/0/1&quot;&gt;Meng Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Xiong_Y/0/1/0/all/0/1&quot;&gt;Yuyao Xiong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Li_A/0/1/0/all/0/1&quot;&gt;Ansheng Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08874">
<title>Unsupervised Domain Adaptation using Regularized Hyper-graph Matching. (arXiv:1805.08874v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1805.08874</link>
<description rdf:parseType="Literal">&lt;p&gt;Domain adaptation (DA) addresses the real-world image classification problem
of discrepancy between training (source) and testing (target) data
distributions. We propose an unsupervised DA method that considers the presence
of only unlabelled data in the target domain. Our approach centers on finding
matches between samples of the source and target domains. The matches are
obtained by treating the source and target domains as hyper-graphs and carrying
out a class-regularized hyper-graph matching using first-, second- and
third-order similarities between the graphs. We have also developed a
computationally efficient algorithm by initially selecting a subset of the
samples to construct a graph and then developing a customized optimization
routine for graph-matching based on Conditional Gradient and Alternating
Direction Multiplier Method. This allows the proposed method to be used widely.
We also performed a set of experiments on standard object recognition datasets
to validate the effectiveness of our framework over state-of-the-art
approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Das_D/0/1/0/all/0/1&quot;&gt;Debasmit Das&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_C/0/1/0/all/0/1&quot;&gt;C.S. George Lee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08882">
<title>Multi-task Maximum Entropy Inverse Reinforcement Learning. (arXiv:1805.08882v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.08882</link>
<description rdf:parseType="Literal">&lt;p&gt;Multi-task Inverse Reinforcement Learning (IRL) is the problem of inferring
multiple reward functions from expert demonstrations. Prior work, built on
Bayesian IRL, is unable to scale to complex environments due to computational
constraints. This paper contributes the first formulation of multi-task IRL in
the more computationally efficient Maximum Causal Entropy (MCE) IRL framework.
Experiments show our approach can perform one-shot imitation learning in a
gridworld environment that single-task IRL algorithms require hundreds of
demonstrations to solve. Furthermore, we outline how our formulation can be
applied to state-of-the-art MCE IRL algorithms such as Guided Cost Learning.
This extension, based on meta-learning, could enable multi-task IRL to be
performed for the first time in high-dimensional, continuous state MDPs with
unknown dynamics as commonly arise in robotics.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gleave_A/0/1/0/all/0/1&quot;&gt;Adam Gleave&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Habryka_O/0/1/0/all/0/1&quot;&gt;Oliver Habryka&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08913">
<title>Amortized Inference Regularization. (arXiv:1805.08913v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.08913</link>
<description rdf:parseType="Literal">&lt;p&gt;The variational autoencoder (VAE) is a popular model for density estimation
and representation learning. Canonically, the variational principle suggests to
prefer an expressive inference model so that the variational approximation is
accurate. However, it is often overlooked that an overly-expressive inference
model can be detrimental to the test set performance of both the amortized
posterior approximator and, more importantly, the generative density estimator.
In this paper, we leverage the fact that VAEs rely on amortized inference and
propose techniques for amortized inference regularization (AIR) that control
the smoothness of the inference model. We demonstrate that, by applying AIR, it
is possible to improve VAE generalization on both inference and generative
performance. Our paper challenges the belief that amortized inference is simply
a mechanism for approximating maximum likelihood training and illustrates that
regularization of the amortization family provides a new direction for
understanding and improving generalization in VAEs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Shu_R/0/1/0/all/0/1&quot;&gt;Rui Shu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bui_H/0/1/0/all/0/1&quot;&gt;Hung H. Bui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhao_S/0/1/0/all/0/1&quot;&gt;Shengjia Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kochenderfer_M/0/1/0/all/0/1&quot;&gt;Mykel J. Kochenderfer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ermon_S/0/1/0/all/0/1&quot;&gt;Stefano Ermon&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08915">
<title>A Psychopathological Approach to Safety Engineering in AI and AGI. (arXiv:1805.08915v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1805.08915</link>
<description rdf:parseType="Literal">&lt;p&gt;The complexity of dynamics in AI techniques is already approaching that of
complex adaptive systems, thus curtailing the feasibility of formal
controllability and reachability analysis in the context of AI safety. It
follows that the envisioned instances of Artificial General Intelligence (AGI)
will also suffer from challenges of complexity. To tackle such issues, we
propose the modeling of deleterious behaviors in AI and AGI as psychological
disorders, thereby enabling the employment of psychopathological approaches to
analysis and control of misbehaviors. Accordingly, we present a discussion on
the feasibility of the psychopathological approaches to AI safety, and propose
general directions for research on modeling, diagnosis, and treatment of
psychological disorders in AGI.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Behzadan_V/0/1/0/all/0/1&quot;&gt;Vahid Behzadan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Munir_A/0/1/0/all/0/1&quot;&gt;Arslan Munir&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yampolskiy_R/0/1/0/all/0/1&quot;&gt;Roman V. Yampolskiy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08930">
<title>Analysis of Thompson Sampling for Graphical Bandits Without the Graphs. (arXiv:1805.08930v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.08930</link>
<description rdf:parseType="Literal">&lt;p&gt;We study multi-armed bandit problems with graph feedback, in which the
decision maker is allowed to observe the neighboring actions of the chosen
action, in a setting where the graph may vary over time and is never fully
revealed to the decision maker. We show that when the feedback graphs are
undirected, the original Thompson Sampling achieves the optimal (within
logarithmic factors) regret $\tilde{O}\left(\sqrt{\beta_0(G)T}\right)$ over
time horizon $T$, where $\beta_0(G)$ is the average independence number of the
latent graphs. To the best of our knowledge, this is the first result showing
that the original Thompson Sampling is optimal for graphical bandits in the
undirected setting. A slightly weaker regret bound of Thompson Sampling in the
directed setting is also presented. To fill this gap, we propose a variant of
Thompson Sampling, that attains the optimal regret in the directed setting
within a logarithmic factor. Both algorithms can be implemented efficiently and
do not require the knowledge of the feedback graphs at any time.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Liu_F/0/1/0/all/0/1&quot;&gt;Fang Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zheng_Z/0/1/0/all/0/1&quot;&gt;Zizhan Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Shroff_N/0/1/0/all/0/1&quot;&gt;Ness Shroff&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08948">
<title>Scalable Coordinated Exploration in Concurrent Reinforcement Learning. (arXiv:1805.08948v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.08948</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider a team of reinforcement learning agents that concurrently operate
in a common environment, and we develop an approach to efficient coordinated
exploration that is suitable for problems of practical scale. Our approach
builds on seed sampling (Dimakopoulou and Van Roy, 2018) and randomized value
function learning (Osband et al., 2016). We demonstrate that, for simple
tabular contexts, the approach is competitive with previously proposed tabular
model learning methods (Dimakopoulou and Van Roy, 2018). With a
higher-dimensional problem and a neural network value function representation,
the approach learns quickly with far fewer agents than alternative exploration
schemes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dimakopoulou_M/0/1/0/all/0/1&quot;&gt;Maria Dimakopoulou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Osband_I/0/1/0/all/0/1&quot;&gt;Ian Osband&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roy_B/0/1/0/all/0/1&quot;&gt;Benjamin Van Roy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08966">
<title>Discovering Blind Spots in Reinforcement Learning. (arXiv:1805.08966v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.08966</link>
<description rdf:parseType="Literal">&lt;p&gt;Agents trained in simulation may make errors in the real world due to
mismatches between training and execution environments. These mistakes can be
dangerous and difficult to discover because the agent cannot predict them a
priori. We propose using oracle feedback to learn a predictive model of these
blind spots to reduce costly errors in real-world applications. We focus on
blind spots in reinforcement learning (RL) that occur due to incomplete state
representation: The agent does not have the appropriate features to represent
the true state of the world and thus cannot distinguish among numerous states.
We formalize the problem of discovering blind spots in RL as a noisy supervised
learning problem with class imbalance. We learn models to predict blind spots
in unseen regions of the state space by combining techniques for label
aggregation, calibration, and supervised learning. The models take into
consideration noise emerging from different forms of oracle feedback, including
demonstrations and corrections. We evaluate our approach on two domains and
show that it achieves higher predictive performance than baseline methods, and
that the learned model can be used to selectively query an oracle at execution
time to prevent errors. We also empirically analyze the biases of various
feedback types and how they influence the discovery of blind spots.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ramakrishnan_R/0/1/0/all/0/1&quot;&gt;Ramya Ramakrishnan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kamar_E/0/1/0/all/0/1&quot;&gt;Ece Kamar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dey_D/0/1/0/all/0/1&quot;&gt;Debadeepta Dey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shah_J/0/1/0/all/0/1&quot;&gt;Julie Shah&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Horvitz_E/0/1/0/all/0/1&quot;&gt;Eric Horvitz&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08975">
<title>Particle Filter Networks: End-to-End Probabilistic Localization From Visual Observations. (arXiv:1805.08975v1 [cs.RO])</title>
<link>http://arxiv.org/abs/1805.08975</link>
<description rdf:parseType="Literal">&lt;p&gt;Particle filters sequentially approximate posterior distributions by sampling
representative points and updating them independently. The idea is applied in
various domains, e.g. reasoning with uncertainty in robotics. A remaining
challenge is constructing probabilistic models of the system, which can be
especially hard for complex sensors, e.g. a camera. We introduce the Particle
Filter Networks (PF-nets) that encode both a learned probabilistic system model
and the particle filter algorithm in a single neural network architecture. The
unified representation allows learning models end-to-end, circumventing the
difficulties of conventional model-based methods. We applied PF-nets to a
challenging visual localization task that requires matching visual features
from camera images with the geometry encoded in a 2-D floor map. In preliminary
experiments end-to-end PF-nets consistently outperformed alternative learning
architectures, as well as conventional model-based methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Karkus_P/0/1/0/all/0/1&quot;&gt;Peter Karkus&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hsu_D/0/1/0/all/0/1&quot;&gt;David Hsu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_W/0/1/0/all/0/1&quot;&gt;Wee Sun Lee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09044">
<title>Representation Balancing MDPs for Off-Policy Policy Evaluation. (arXiv:1805.09044v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.09044</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the problem of off-policy policy evaluation (OPPE) in RL. In
contrast to prior work, we consider how to estimate both the individual policy
value and average policy value accurately. We draw inspiration from recent work
in causal reasoning, and propose a new finite sample generalization error bound
for value estimates from MDP models. Using this upper bound as an objective, we
develop a learning algorithm of an MDP model with a balanced representation,
and show that our approach can yield substantially lower MSE in a common
synthetic domain and on a challenging real-world sepsis management problem.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yao Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gottesman_O/0/1/0/all/0/1&quot;&gt;Omer Gottesman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Raghu_A/0/1/0/all/0/1&quot;&gt;Aniruddh Raghu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Komorowski_M/0/1/0/all/0/1&quot;&gt;Matthieu Komorowski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Faisal_A/0/1/0/all/0/1&quot;&gt;Aldo Faisal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Doshi_Velez_F/0/1/0/all/0/1&quot;&gt;Finale Doshi-Velez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brunskill_E/0/1/0/all/0/1&quot;&gt;Emma Brunskill&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09045">
<title>When Simple Exploration is Sample Efficient: Identifying Sufficient Conditions for Random Exploration to Yield PAC RL Algorithms. (arXiv:1805.09045v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.09045</link>
<description rdf:parseType="Literal">&lt;p&gt;Efficient exploration is one of the key challenges for reinforcement learning
(RL) algorithms. Most traditional sample efficiency bounds require strategic
exploration. Recently many deep RL algorithm with simple heuristic exploration
strategies that have few formal guarantees, achieve surprising success in many
domains. These results pose an important question about understanding these
exploration strategies such as $e$-greedy, as well as understanding what
characterize the difficulty of exploration in MDPs. In this work we propose
problem specific sample complexity bounds of $Q$ learning with random walk
exploration that rely on several structural properties. We also link our
theoretical results to some empirical benchmark domains, to illustrate if our
bound gives polynomial sample complexity or not in these domains and how that
is related with the empirical performance in these domains.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yao Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brunskill_E/0/1/0/all/0/1&quot;&gt;Emma Brunskill&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09137">
<title>Image Captioning. (arXiv:1805.09137v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1805.09137</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper discusses and demonstrates the outcomes from our experimentation
on Image Captioning. Image captioning is a much more involved task than image
recognition or classification, because of the additional challenge of
recognizing the interdependence between the objects/concepts in the image and
the creation of a succinct sentential narration. Experiments on several labeled
datasets show the accuracy of the model and the fluency of the language it
learns solely from image descriptions. As a toy application, we apply image
captioning to create video captions, and we advance a few hypotheses on the
challenges we encountered.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mullachery_V/0/1/0/all/0/1&quot;&gt;Vikram Mullachery&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Motwani_V/0/1/0/all/0/1&quot;&gt;Vishal Motwani&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09145">
<title>RDF2Vec-based Classification of Ontology Alignment Changes. (arXiv:1805.09145v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1805.09145</link>
<description rdf:parseType="Literal">&lt;p&gt;When ontologies cover overlapping topics, the overlap can be represented
using ontology alignments. These alignments need to be continuously adapted to
changing ontologies. Especially for large ontologies this is a costly task
often consisting of manual work. Finding changes that do not lead to an
adaption of the alignment can potentially make this process significantly
easier. This work presents an approach to finding these changes based on RDF
embeddings and common classification techniques. To examine the feasibility of
this approach, an evaluation on a real-world dataset is presented. In this
evaluation, the best classifiers reached a precision of 0.8.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jurisch_M/0/1/0/all/0/1&quot;&gt;Matthias Jurisch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Igler_B/0/1/0/all/0/1&quot;&gt;Bodo Igler&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09169">
<title>A distinct approach to diagnose Dengue Fever with the help of Soft Set Theory. (arXiv:1805.09169v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1805.09169</link>
<description rdf:parseType="Literal">&lt;p&gt;Mathematics has played a substantial role to revolutionize the medical
science. Intelligent systems based on mathematical theories have proved to be
efficient in diagnosing various diseases. In this paper, we used an expert
system based on soft set theory and fuzzy set theory named as a soft expert
system to diagnose tropical disease dengue. The objective to use soft expert
system is to predict the risk level of a patient having dengue fever by using
input variables like age, TLC, SGOT, platelets count and blood pressure. The
proposed method explicitly demonstrates the exact percentage of the risk level
of dengue fever automatically circumventing for all possible (medical)
imprecisions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bukhari_S/0/1/0/all/0/1&quot;&gt;Syeda fariha Bukhari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Amvad_M/0/1/0/all/0/1&quot;&gt;Maaz Amvad&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09197">
<title>ASR-based Features for Emotion Recognition: A Transfer Learning Approach. (arXiv:1805.09197v1 [eess.AS])</title>
<link>http://arxiv.org/abs/1805.09197</link>
<description rdf:parseType="Literal">&lt;p&gt;During the last decade, the applications of signal processing have
drastically improved with deep learning. However areas of affecting computing
such as emotional speech synthesis or emotion recognition from spoken language
remains challenging. In this paper, we investigate the use of a neural
Automatic Speech Recognition (ASR) as a feature extractor for emotion
recognition. We show that these features outperform the eGeMAPS feature set to
predict the valence and arousal emotional dimensions, which means that the
audio-to-text mapping learning by the ASR system contain information related to
the emotional dimensions in spontaneous speech. We also examine the
relationship between first layers (closer to speech) and last layers (closer to
text) of the ASR and valence/arousal.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Tits_N/0/1/0/all/0/1&quot;&gt;No&amp;#xe9; Tits&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Haddad_K/0/1/0/all/0/1&quot;&gt;Kevin El Haddad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Dutoit_T/0/1/0/all/0/1&quot;&gt;Thierry Dutoit&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09218">
<title>Monte Carlo Tree Search for Asymmetric Trees. (arXiv:1805.09218v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.09218</link>
<description rdf:parseType="Literal">&lt;p&gt;We present an extension of Monte Carlo Tree Search (MCTS) that strongly
increases its efficiency for trees with asymmetry and/or loops. Asymmetric
termination of search trees introduces a type of uncertainty for which the
standard upper confidence bound (UCB) formula does not account. Our first
algorithm (MCTS-T), which assumes a non-stochastic environment, backs-up tree
structure uncertainty and leverages it for exploration in a modified UCB
formula. Results show vastly improved efficiency in a well-known asymmetric
domain in which MCTS performs arbitrarily bad. Next, we connect the ideas about
asymmetric termination to the presence of loops in the tree, where the same
state appears multiple times in a single trace. An extension to our algorithm
(MCTS-T+), which in addition to non-stochasticity assumes full state
observability, further increases search efficiency for domains with loops as
well. Benchmark testing on a set of OpenAI Gym and Atari 2600 games indicates
that our algorithms always perform better than or at least equivalent to
standard MCTS, and could be first-choice tree search algorithms for
non-stochastic, fully-observable environments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Moerland_T/0/1/0/all/0/1&quot;&gt;Thomas M. Moerland&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Broekens_J/0/1/0/all/0/1&quot;&gt;Joost Broekens&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Plaat_A/0/1/0/all/0/1&quot;&gt;Aske Plaat&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Jonker_C/0/1/0/all/0/1&quot;&gt;Catholijn M. Jonker&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09235">
<title>Cramer-Wold AutoEncoder. (arXiv:1805.09235v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.09235</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a new generative model, Cramer-Wold Autoencoder (CWAE). Following
WAE, we directly encourage normality of the latent space. Our paper uses also
the recent idea from Sliced WAE (SWAE) model, which uses one-dimensional
projections as a method of verifying closeness of two distributions.
&lt;/p&gt;
&lt;p&gt;The crucial new ingredient is the introduction of a new (Cramer-Wold) metric
in the space of densities, which replaces the Wasserstein metric used in SWAE.
We show that the Cramer-Wold metric between Gaussian mixtures is given by a
simple analytic formula, which results in the removal of sampling necessary to
estimate the cost function in WAE and SWAE models.
&lt;/p&gt;
&lt;p&gt;As a consequence, while drastically simplifying the optimization procedure,
CWAE produces samples of a matching perceptual quality to other SOTA models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tabor_J/0/1/0/all/0/1&quot;&gt;Jacek Tabor&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Knop_S/0/1/0/all/0/1&quot;&gt;Szymon Knop&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Spurek_P/0/1/0/all/0/1&quot;&gt;Przemys&amp;#x142;aw Spurek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Podolak_I/0/1/0/all/0/1&quot;&gt;Igor Podolak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mazur_M/0/1/0/all/0/1&quot;&gt;Marcin Mazur&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jastrzebski_S/0/1/0/all/0/1&quot;&gt;Stanis&amp;#x142;aw Jastrz&amp;#x119;bski&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09238">
<title>Highway State Gating for Recurrent Highway Networks: improving information flow through time. (arXiv:1805.09238v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.09238</link>
<description rdf:parseType="Literal">&lt;p&gt;Recurrent Neural Networks (RNNs) play a major role in the field of sequential
learning, and have outperformed traditional algorithms on many benchmarks.
Training deep RNNs still remains a challenge, and most of the state-of-the-art
models are structured with a transition depth of 2-4 layers. Recurrent Highway
Networks (RHNs) were introduced in order to tackle this issue. These have
achieved state-of-the-art performance on a few benchmarks using a depth of 10
layers. However, the performance of this architecture suffers from a
bottleneck, and ceases to improve when an attempt is made to add more layers.
In this work, we analyze the causes for this, and postulate that the main
source is the way that the information flows through time. We introduce a novel
and simple variation for the RHN cell, called Highway State Gating (HSG), which
allows adding more layers, while continuing to improve performance. By using a
gating mechanism for the state, we allow the net to &quot;choose&quot; whether to pass
information directly through time, or to gate it. This mechanism also allows
the gradient to back-propagate directly through time and, therefore, results in
a slightly faster convergence. We use the Penn Treebank (PTB) dataset as a
platform for empirical proof of concept. Empirical results show that the
improvement due to Highway State Gating is for all depths, and as the depth
increases, the improvement also increases.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Shoham_R/0/1/0/all/0/1&quot;&gt;Ron Shoham&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Permuter_H/0/1/0/all/0/1&quot;&gt;Haim Permuter&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09267">
<title>Reinforcement Learning for Heterogeneous Teams with PALO Bounds. (arXiv:1805.09267v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.09267</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce reinforcement learning for heterogeneous teams in which rewards
for an agent are additively factored into local costs, stimuli unique to each
agent, and global rewards, those shared by all agents in the domain. Motivating
domains include coordination of varied robotic platforms, which incur different
costs for the same action, but share an overall goal. We present two templates
for learning in this setting with factored rewards: a generalization of
Perkins&apos; Monte Carlo exploring starts for POMDPs to canonical MPOMDPs, with a
single policy mapping joint observations of all agents to joint actions
(MCES-MP); and another with each agent individually mapping joint observations
to their own action (MCES-FMP). We use probably approximately local optimal
(PALO) bounds to analyze sample complexity, instantiating these templates to
PALO learning. We promote sample efficiency by including a policy space pruning
technique, and evaluate the approaches on three domains of heterogeneous agents
demonstrating that MCES-FMP yields improved policies in less samples compared
to MCES-MP and a previous benchmark.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ceren_R/0/1/0/all/0/1&quot;&gt;Roi Ceren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Doshi_P/0/1/0/all/0/1&quot;&gt;Prashant Doshi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_K/0/1/0/all/0/1&quot;&gt;Keyang He&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.00503">
<title>Mean Actor Critic. (arXiv:1709.00503v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1709.00503</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a new algorithm, Mean Actor-Critic (MAC), for discrete-action
continuous-state reinforcement learning. MAC is a policy gradient algorithm
that uses the agent&apos;s explicit representation of all action values to estimate
the gradient of the policy, rather than using only the actions that were
actually executed. We prove that this approach reduces variance in the policy
gradient estimate relative to traditional actor-critic methods. We show
empirical results on two control domains and on six Atari games, where MAC is
competitive with state-of-the-art policy search algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Allen_C/0/1/0/all/0/1&quot;&gt;Cameron Allen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Asadi_K/0/1/0/all/0/1&quot;&gt;Kavosh Asadi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Roderick_M/0/1/0/all/0/1&quot;&gt;Melrose Roderick&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mohamed_A/0/1/0/all/0/1&quot;&gt;Abdel-rahman Mohamed&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Konidaris_G/0/1/0/all/0/1&quot;&gt;George Konidaris&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Littman_M/0/1/0/all/0/1&quot;&gt;Michael Littman&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.05060">
<title>Functional Decision Theory: A New Theory of Instrumental Rationality. (arXiv:1710.05060v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1710.05060</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper describes and motivates a new decision theory known as functional
decision theory (FDT), as distinct from causal decision theory and evidential
decision theory. Functional decision theorists hold that the normative
principle for action is to treat one&apos;s decision as the output of a fixed
mathematical function that answers the question, &quot;Which output of this very
function would yield the best outcome?&quot; Adhering to this principle delivers a
number of benefits, including the ability to maximize wealth in an array of
traditional decision-theoretic and game-theoretic problems where CDT and EDT
perform poorly. Using one simple and coherent decision rule, functional
decision theorists (for example) achieve more utility than CDT on Newcomb&apos;s
problem, more utility than EDT on the smoking lesion problem, and more utility
than both in Parfit&apos;s hitchhiker problem. In this paper, we define FDT, explore
its prescriptions in a number of different decision problems, compare it to CDT
and EDT, and give philosophical justifications for FDT as a normative theory of
decision-making.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yudkowsky_E/0/1/0/all/0/1&quot;&gt;Eliezer Yudkowsky&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Soares_N/0/1/0/all/0/1&quot;&gt;Nate Soares&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.11223">
<title>Fast and Scalable Learning of Sparse Changes in High-Dimensional Gaussian Graphical Model Structure. (arXiv:1710.11223v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1710.11223</link>
<description rdf:parseType="Literal">&lt;p&gt;We focus on the problem of estimating the change in the dependency structures
of two $p$-dimensional Gaussian Graphical models (GGMs). Previous studies for
sparse change estimation in GGMs involve expensive and difficult non-smooth
optimization. We propose a novel method, DIFFEE for estimating DIFFerential
networks via an Elementary Estimator under a high-dimensional situation. DIFFEE
is solved through a faster and closed form solution that enables it to work in
large-scale settings. We conduct a rigorous statistical analysis showing that
surprisingly DIFFEE achieves the same asymptotic convergence rates as the
state-of-the-art estimators that are much more difficult to compute. Our
experimental results on multiple synthetic datasets and one real-world data
about brain connectivity show strong performance improvements over baselines,
as well as significant computational benefits.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1&quot;&gt;Beilun Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sekhon_A/0/1/0/all/0/1&quot;&gt;Arshdeep Sekhon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qi_Y/0/1/0/all/0/1&quot;&gt;Yanjun Qi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05844">
<title>A Unified View of Causal and Non-causal Feature Selection. (arXiv:1802.05844v3 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1802.05844</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we aim to develop a unified view of causal and non-causal
feature selection methods based on the Bayesian network framework and
information theory. We first show that causal and non-causal feature selection
methods share the same objective. That is to find the Markov blanket of a class
attribute, the theoretically optimal feature set for classification. We then
demonstrate that it is the different assumptions made by causal and non-causal
feature selection methods that lead to the different levels of approximation of
the feature sets found by the methods with respect to the optimal feature set.
With this view, we are able to analyze the sample and error bounds of casual
and non-causal methods. Extensive experiments conducted in the paper have shown
the correctness of the theoretical analysis.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_K/0/1/0/all/0/1&quot;&gt;Kui Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1&quot;&gt;Lin Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jiuyong Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.07779">
<title>PEORL: Integrating Symbolic Planning and Hierarchical Reinforcement Learning for Robust Decision-Making. (arXiv:1804.07779v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1804.07779</link>
<description rdf:parseType="Literal">&lt;p&gt;Reinforcement learning and symbolic planning have both been used to build
intelligent autonomous agents. Reinforcement learning relies on learning from
interactions with real world, which often requires an unfeasibly large amount
of experience. Symbolic planning relies on manually crafted symbolic knowledge,
which may not be robust to domain uncertainties and changes. In this paper we
present a unified framework {\em PEORL} that integrates symbolic planning with
hierarchical reinforcement learning (HRL) to cope with decision-making in a
dynamic environment with uncertainties.
&lt;/p&gt;
&lt;p&gt;Symbolic plans are used to guide the agent&apos;s task execution and learning, and
the learned experience is fed back to symbolic knowledge to improve planning.
This method leads to rapid policy search and robust symbolic plans in complex
domains. The framework is tested on benchmark domains of HRL.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_F/0/1/0/all/0/1&quot;&gt;Fangkai Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lyu_D/0/1/0/all/0/1&quot;&gt;Daoming Lyu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1&quot;&gt;Bo Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gustafson_S/0/1/0/all/0/1&quot;&gt;Steven Gustafson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07733">
<title>Learning Attentional Communication for Multi-Agent Cooperation. (arXiv:1805.07733v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1805.07733</link>
<description rdf:parseType="Literal">&lt;p&gt;Communication could potentially be an effective way for multi-agent
cooperation. However, information sharing among all agents or in predefined
communication architectures that existing methods adopt can be problematic.
When there is a large number of agents, agents hardly differentiate valuable
information that helps cooperative decision making from globally shared
information. Therefore, communication barely helps, and could even impair the
learning of multi-agent cooperation. Predefined communication architectures, on
the other hand, restrict communication among agents and thus restrain potential
cooperation. To tackle these difficulties, in this paper, we propose an
attentional communication model that learns when communication is needed and
how to integrates shared information for cooperative decision making. Our model
leads to efficient and effective communication for large-scale multi-agent
cooperation. Empirically, we show the strength of our model in various
cooperative scenarios, where agents are able to develop more coordinated and
sophisticated strategies than existing methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1&quot;&gt;Jiechuan Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_Z/0/1/0/all/0/1&quot;&gt;Zongqing Lu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08808">
<title>Deformable Part Networks. (arXiv:1805.08808v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.08808</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper we propose novel Deformable Part Networks (DPNs) to learn {\em
pose-invariant} representations for 2D object recognition. In contrast to the
state-of-the-art pose-aware networks such as CapsNet \cite{sabour2017dynamic}
and STN \cite{jaderberg2015spatial}, DPNs can be naturally {\em interpreted} as
an efficient solver for a challenging detection problem, namely Localized
Deformable Part Models (LDPMs) where localization is introduced to DPMs as
another latent variable for searching for the best poses of objects over all
pixels and (predefined) scales. In particular we construct DPNs as sequences of
such LDPM units to model the semantic and spatial relations among the
deformable parts as hierarchical composition and spatial parsing trees.
Empirically our 17-layer DPN can outperform both CapsNets and STNs
significantly on affNIST \cite{sabour2017dynamic}, for instance, by 19.19\% and
12.75\%, respectively, with better generalization and better tolerance to
affine transformations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhang_Z/0/1/0/all/0/1&quot;&gt;Ziming Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lin_R/0/1/0/all/0/1&quot;&gt;Rongmei Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sullivan_A/0/1/0/all/0/1&quot;&gt;Alan Sullivan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08836">
<title>Nonparametric Density Estimation under Adversarial Losses. (arXiv:1805.08836v1 [math.ST])</title>
<link>http://arxiv.org/abs/1805.08836</link>
<description rdf:parseType="Literal">&lt;p&gt;We study minimax convergence rates of nonparametric density estimation under
a large class of loss functions called &quot;adversarial losses&quot;, which, besides
classical $\mathcal{L}^p$ losses, includes maximum mean discrepancy (MMD),
Wasserstein distance, and total variation distance. These losses are closely
related to the losses encoded by discriminator networks in generative
adversarial networks (GANs). In a general framework, we study how the choice of
loss and the assumed smoothness of the underlying density together determine
the minimax rate. We also discuss implications for training GANs based on deep
ReLU networks, and more general connections to learning implicit generative
models in a minimax statistical sense.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Singh_S/0/1/0/all/0/1&quot;&gt;Shashank Singh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Uppal_A/0/1/0/all/0/1&quot;&gt;Ananya Uppal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Li_B/0/1/0/all/0/1&quot;&gt;Boyue Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Li_C/0/1/0/all/0/1&quot;&gt;Chun-Liang Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Zaheer_M/0/1/0/all/0/1&quot;&gt;Manzil Zaheer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Poczos_B/0/1/0/all/0/1&quot;&gt;Barnab&amp;#xe1;s P&amp;#xf3;czos&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08838">
<title>Clustering - What Both Theoreticians and Practitioners are Doing Wrong. (arXiv:1805.08838v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.08838</link>
<description rdf:parseType="Literal">&lt;p&gt;Unsupervised learning is widely recognized as one of the most important
challenges facing machine learning nowa- days. However, in spite of hundreds of
papers on the topic being published every year, current theoretical
understanding and practical implementations of such tasks, in particular of
clustering, is very rudimentary. This note focuses on clustering. I claim that
the most signif- icant challenge for clustering is model selection. In contrast
with other common computational tasks, for clustering, dif- ferent algorithms
often yield drastically different outcomes. Therefore, the choice of a
clustering algorithm, and their pa- rameters (like the number of clusters) may
play a crucial role in the usefulness of an output clustering solution.
However, currently there exists no methodical guidance for clustering
tool-selection for a given clustering task. Practitioners pick the algorithms
they use without awareness to the implications of their choices and the vast
majority of theory of clustering papers focus on providing savings to the
resources needed to solve optimization problems that arise from picking some
concrete clustering objective. Saving that pale in com- parison to the costs of
mismatch between those objectives and the intended use of clustering results. I
argue the severity of this problem and describe some recent proposals aiming to
address this crucial lacuna.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ben_David_S/0/1/0/all/0/1&quot;&gt;Shai Ben-David&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08845">
<title>Counterfactual Mean Embedding: A Kernel Method for Nonparametric Causal Inference. (arXiv:1805.08845v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.08845</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper introduces a novel Hilbert space representation of a
counterfactual distribution---called counterfactual mean embedding (CME)---with
applications in nonparametric causal inference. Counterfactual prediction has
become an ubiquitous tool in machine learning applications, such as online
advertisement, recommendation systems, and medical diagnosis, whose performance
relies on certain interventions. To infer the outcomes of such interventions,
we propose to embed the associated counterfactual distribution into a
reproducing kernel Hilbert space (RKHS) endowed with a positive definite
kernel. Under appropriate assumptions, the CME allows us to perform causal
inference over the entire landscape of the counterfactual distribution. The CME
can be estimated consistently from observational data without requiring any
parametric assumption about the underlying distributions. We also derive a rate
of convergence which depends on the smoothness of the conditional mean and the
Radon-Nikodym derivative of the underlying marginal distributions. Our
framework can deal with not only real-valued outcome, but potentially also more
complex and structured outcomes such as images, sequences, and graphs. Lastly,
our experimental results on off-policy evaluation tasks demonstrate the
advantages of the proposed estimator.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Muandet_K/0/1/0/all/0/1&quot;&gt;Krikamol Muandet&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kanagawa_M/0/1/0/all/0/1&quot;&gt;Motonobu Kanagawa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Saengkyongam_S/0/1/0/all/0/1&quot;&gt;Sorawit Saengkyongam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Marukatat_S/0/1/0/all/0/1&quot;&gt;Sanparith Marukatat&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08890">
<title>Step Size Matters in Deep Learning. (arXiv:1805.08890v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.08890</link>
<description rdf:parseType="Literal">&lt;p&gt;Training a neural network with the gradient descent algorithm gives rise to a
discrete-time nonlinear dynamical system. Consequently, behaviors that are
typically observed in these systems emerge during training, such as convergence
to an orbit but not to a fixed point or dependence of convergence on the
initialization. Step size of the algorithm plays a critical role in these
behaviors: it determines the subset of the local optima that the algorithm can
converge to, and it specifies the magnitude of the oscillations if the
algorithm converges to an orbit. To elucidate the effects of the step size on
training of neural networks, we study the gradient descent algorithm as a
discrete-time dynamical system, and by analyzing the Lyapunov stability of
different solutions, we show the relationship between the step size of the
algorithm and the solutions that can be obtained with this algorithm. The
results provide an explanation for several phenomena observed in practice,
including the deterioration in the training error with increased depth, the
hardness of estimating linear mappings with large singular values, and the
distinct performance of deep residual networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nar_K/0/1/0/all/0/1&quot;&gt;Kamil Nar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sastry_S/0/1/0/all/0/1&quot;&gt;S. Shankar Sastry&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08920">
<title>Approximate Newton-based statistical inference using only stochastic gradients. (arXiv:1805.08920v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.08920</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a novel inference framework for convex empirical risk
minimization, using approximate stochastic Newton steps. The proposed algorithm
is based on the notion of finite differences and allows the approximation of a
Hessian-vector product from first-order information. In theory, our method
efficiently computes the statistical error covariance in $M$-estimation, both
for unregularized convex learning problems and high-dimensional LASSO
regression, without using exact second order information, or resampling the
entire data set. In practice, we demonstrate the effectiveness of our framework
on large-scale machine learning problems, that go even beyond convexity: as a
highlight, our work can be used to detect certain adversarial attacks on neural
networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1&quot;&gt;Tianyang Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kyrillidis_A/0/1/0/all/0/1&quot;&gt;Anastasios Kyrillidis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_L/0/1/0/all/0/1&quot;&gt;Liu Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Caramanis_C/0/1/0/all/0/1&quot;&gt;Constantine Caramanis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08952">
<title>Dictionary Learning by Dynamical Neural Networks. (arXiv:1805.08952v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.08952</link>
<description rdf:parseType="Literal">&lt;p&gt;A dynamical neural network consists of a set of interconnected neurons that
interact over time continuously. It can exhibit computational properties in the
sense that the dynamical system&apos;s evolution and/or limit points in the
associated state space can correspond to numerical solutions to certain
mathematical optimization or learning problems. Such a computational system is
particularly attractive in that it can be mapped to a massively parallel
computer architecture for power and throughput efficiency, especially if each
neuron can rely solely on local information (i.e., local memory). Deriving
gradients from the dynamical network&apos;s various states while conforming to this
last constraint, however, is challenging. We show that by combining ideas of
top-down feedback and contrastive learning, a dynamical network for solving the
l1-minimizing dictionary learning problem can be constructed, and the true
gradients for learning are provably computable by individual neurons. Using
spiking neurons to construct our dynamical network, we present a learning
process, its rigorous mathematical analysis, and numerical results on several
dictionary learning problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_T/0/1/0/all/0/1&quot;&gt;Tsung-Han Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_P/0/1/0/all/0/1&quot;&gt;Ping Tak Peter Tang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08956">
<title>Hypergraph Spectral Clustering in the Weighted Stochastic Block Model. (arXiv:1805.08956v1 [math.ST])</title>
<link>http://arxiv.org/abs/1805.08956</link>
<description rdf:parseType="Literal">&lt;p&gt;Spectral clustering is a celebrated algorithm that partitions objects based
on pairwise similarity information. While this approach has been successfully
applied to a variety of domains, it comes with limitations. The reason is that
there are many other applications in which only \emph{multi}-way similarity
measures are available. This motivates us to explore the multi-way measurement
setting. In this work, we develop two algorithms intended for such setting:
Hypergraph Spectral Clustering (HSC) and Hypergraph Spectral Clustering with
Local Refinement (HSCLR). Our main contribution lies in performance analysis of
the poly-time algorithms under a random hypergraph model, which we name the
weighted stochastic block model, in which objects and multi-way measures are
modeled as nodes and weights of hyperedges, respectively. Denoting by $n$ the
number of nodes, our analysis reveals the following: (1) HSC outputs a
partition which is better than a random guess if the sum of edge weights (to be
explained later) is $\Omega(n)$; (2) HSC outputs a partition which coincides
with the hidden partition except for a vanishing fraction of nodes if the sum
of edge weights is $\omega(n)$; and (3) HSCLR exactly recovers the hidden
partition if the sum of edge weights is on the order of $n \log n$. Our results
improve upon the state of the arts recently established under the model and
they firstly settle the order-wise optimal results for the binary edge weight
case. Moreover, we show that our results lead to efficient sketching algorithms
for subspace clustering, a computer vision application. Lastly, we show that
HSCLR achieves the information-theoretic limits for a special yet practically
relevant model, thereby showing no computational barrier for the case.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Ahn_K/0/1/0/all/0/1&quot;&gt;Kwangjun Ahn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Lee_K/0/1/0/all/0/1&quot;&gt;Kangwook Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Suh_C/0/1/0/all/0/1&quot;&gt;Changho Suh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08957">
<title>Semi-Supervised Learning with GANs: Revisiting Manifold Regularization. (arXiv:1805.08957v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.08957</link>
<description rdf:parseType="Literal">&lt;p&gt;GANS are powerful generative models that are able to model the manifold of
natural images. We leverage this property to perform manifold regularization by
approximating the Laplacian norm using a Monte Carlo approximation that is
easily computed with the GAN. When incorporated into the feature-matching GAN
of Improved GAN, we achieve state-of-the-art results for GAN-based
semi-supervised learning on the CIFAR-10 dataset, with a method that is
significantly easier to implement than competing methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lecouat_B/0/1/0/all/0/1&quot;&gt;Bruno Lecouat&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Foo_C/0/1/0/all/0/1&quot;&gt;Chuan-Sheng Foo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zenati_H/0/1/0/all/0/1&quot;&gt;Houssam Zenati&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chandrasekhar_V/0/1/0/all/0/1&quot;&gt;Vijay R. Chandrasekhar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08970">
<title>Toward a Thinking Microscope: Deep Learning in Optical Microscopy and Image Reconstruction. (arXiv:1805.08970v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.08970</link>
<description rdf:parseType="Literal">&lt;p&gt;We discuss recently emerging applications of the state-of-art deep learning
methods on optical microscopy and microscopic image reconstruction, which
enable new transformations among different modes and modalities of microscopic
imaging, driven entirely by image data. We believe that deep learning will
fundamentally change both the hardware and image reconstruction methods used in
optical microscopy in a holistic manner.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rivenson_Y/0/1/0/all/0/1&quot;&gt;Yair Rivenson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ozcan_A/0/1/0/all/0/1&quot;&gt;Aydogan Ozcan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08974">
<title>Do Better ImageNet Models Transfer Better?. (arXiv:1805.08974v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1805.08974</link>
<description rdf:parseType="Literal">&lt;p&gt;Transfer learning has become a cornerstone of computer vision with the advent
of ImageNet features, yet little work has been done to evaluate the performance
of ImageNet architectures across different datasets. An implicit hypothesis in
modern computer vision research is that models that perform better on ImageNet
necessarily perform better on other vision tasks. However, this hypothesis has
never been systematically tested. Here, we compare the performance of 13
classification models on 12 image classification tasks in three settings: as
fixed feature extractors, fine-tuned, and trained from random initialization.
We find that, when networks are used as fixed feature extractors, ImageNet
accuracy is only weakly predictive of accuracy on other tasks ($r^2=0.24$). In
this setting, ResNets consistently outperform networks that achieve higher
accuracy on ImageNet. When networks are fine-tuned, we observe a substantially
stronger correlation ($r^2 = 0.86$). We achieve state-of-the-art performance on
eight image classification tasks simply by fine-tuning state-of-the-art
ImageNet architectures, outperforming previous results based on specialized
methods for transfer learning. Finally, we observe that, on three small
fine-grained image classification datasets, networks trained from random
initialization perform similarly to ImageNet-pretrained networks. Together, our
results show that ImageNet architectures generalize well across datasets, with
small improvements in ImageNet accuracy producing improvements across other
tasks, but ImageNet features are less general than previously suggested.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kornblith_S/0/1/0/all/0/1&quot;&gt;Simon Kornblith&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shlens_J/0/1/0/all/0/1&quot;&gt;Jonathon Shlens&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Le_Q/0/1/0/all/0/1&quot;&gt;Quoc V. Le&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09023">
<title>Addressing the Item Cold-start Problem by Attribute-driven Active Learning. (arXiv:1805.09023v1 [cs.IR])</title>
<link>http://arxiv.org/abs/1805.09023</link>
<description rdf:parseType="Literal">&lt;p&gt;In recommender systems, cold-start issues are situations where no previous
events, e.g. ratings, are known for certain users or items. In this paper, we
focus on the item cold-start problem. Both content information (e.g. item
attributes) and initial user ratings are valuable for seizing users&apos;
preferences on a new item. However, previous methods for the item cold-start
problem either 1) incorporate content information into collaborative filtering
to perform hybrid recommendation, or 2) actively select users to rate the new
item without considering content information and then do collaborative
filtering. In this paper, we propose a novel recommendation scheme for the item
cold-start problem by leverage both active learning and items&apos; attribute
information. Specifically, we design useful user selection criteria based on
items&apos; attributes and users&apos; rating history, and combine the criteria in an
optimization framework for selecting users. By exploiting the feedback ratings,
users&apos; previous ratings and items&apos; attributes, we then generate accurate rating
predictions for the other unselected users. Experimental results on two
real-world datasets show the superiority of our proposed method over
traditional methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1&quot;&gt;Yu Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1&quot;&gt;Jinhao Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_S/0/1/0/all/0/1&quot;&gt;Shibi He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1&quot;&gt;Beidou Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guan_Z/0/1/0/all/0/1&quot;&gt;Ziyu Guan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1&quot;&gt;Haifeng Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cai_D/0/1/0/all/0/1&quot;&gt;Deng Cai&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09076">
<title>Constrained Graph Variational Autoencoders for Molecule Design. (arXiv:1805.09076v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.09076</link>
<description rdf:parseType="Literal">&lt;p&gt;Graphs are ubiquitous data structures for representing interactions between
entities. With an emphasis on the use of graphs to represent chemical
molecules, we explore the task of learning to generate graphs that conform to a
distribution observed in training data. We propose a variational autoencoder
model in which both encoder and decoder are graph-structured. Our decoder
assumes a sequential ordering of graph extension steps and we discuss and
analyze design choices that mitigate the potential downsides of this
linearization. Experiments compare our approach with a wide range of baselines
on the molecule generation task and show that our method is more successful at
matching the statistics of the original dataset on semantically important
metrics. Furthermore, we show that by using appropriate shaping of the latent
space, our model allows us to design molecules that are (locally) optimal in
desired properties.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1&quot;&gt;Qi Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Allamanis_M/0/1/0/all/0/1&quot;&gt;Miltiadis Allamanis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brockschmidt_M/0/1/0/all/0/1&quot;&gt;Marc Brockschmidt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gaunt_A/0/1/0/all/0/1&quot;&gt;Alexander L. Gaunt&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09091">
<title>Neural networks for post-processing ensemble weather forecasts. (arXiv:1805.09091v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.09091</link>
<description rdf:parseType="Literal">&lt;p&gt;Ensemble weather predictions require statistical post-processing of
systematic errors to obtain reliable and accurate probabilistic forecasts.
Traditionally, this is accomplished with distributional regression models in
which the parameters of a predictive distribution are estimated from a training
period. We propose a flexible alternative based on neural networks that can
incorporate nonlinear relationships between arbitrary predictor variables and
forecast distribution parameters that are automatically learned in a
data-driven way rather than requiring pre-specified link functions. In a case
study of 2-meter temperature forecasts at surface stations in Germany, the
neural network approach significantly outperforms benchmark post-processing
methods while being computationally more affordable. Key components to this
improvement are the use of auxiliary predictor variables and station-specific
information with the help of embeddings. Furthermore, the trained neural
network can be used to gain insight into the importance of meteorological
variables thereby challenging the notion of neural networks as uninterpretable
black boxes. Our approach can easily be extended to other statistical
post-processing and forecasting problems. We anticipate that recent advances in
deep learning combined with the ever-increasing amounts of model and
observation data will transform the post-processing of numerical weather
forecasts in the coming decade.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rasp_S/0/1/0/all/0/1&quot;&gt;Stephan Rasp&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lerch_S/0/1/0/all/0/1&quot;&gt;Sebastian Lerch&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09108">
<title>Deep Learning Estimation of Absorbed Dose for Nuclear Medicine Diagnostics. (arXiv:1805.09108v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.09108</link>
<description rdf:parseType="Literal">&lt;p&gt;The distribution of energy dose from Lu$^{177}$ radiotherapy can be estimated
by convolving an image of a time-integrated activity distribution with a dose
voxel kernel (DVK) consisting of different types of tissues. This fast and
inacurate approximation is inappropriate for personalized dosimetry as it
neglects tissue heterogenity. The latter can be calculated using different
imaging techniques such as CT and SPECT combined with a time consuming
Monte-Carlo simulation. The aim of this study is, for the first time, an
estimation of DVKs from CT-derived density kernels (DK) via deep learning in
Convolutional Neural Networks (CNNs). The proposed CNN achieved, on the test
set, a mean intersection over union of intersection over union (IoU) $= 0.86$
after $308$ epochs and a corresponding mean squared error (MSE) $= 1.24 \cdot
10^{-4}$. This generalization ability shows that the trained CNN can indeed
learn the complex transfer function from DK to DVK. Future work will evaluate
DVKs estimated by CNNs with full MC simulations of a whole body CT to predict
patient specific voxel dose maps.
&lt;/p&gt;
&lt;p&gt;Keywords: Deep Learning, Nuclear Medicine, Diagnostics, Machine Learning,
Statistics
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Melodia_L/0/1/0/all/0/1&quot;&gt;Luciano Melodia&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09114">
<title>Optimal Transport for structured data. (arXiv:1805.09114v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.09114</link>
<description rdf:parseType="Literal">&lt;p&gt;Optimal transport has recently gained a lot of interest in the machine
learning community thanks to its ability to compare probability distributions
while respecting the underlying space&apos;s geometry. Wasserstein distance deals
with feature information through its metric or cost function, but fails in
exploiting the structural information, i.e the specific relations existing
among the components of the distribution. Recently adapted to a machine
learning context, the Gromov-Wasserstein distance defines a metric well suited
for comparing distributions that live in different metric spaces by exploiting
their inner structural information. In this paper we propose a new optimal
transport distance, called the Fused Gromov-Wasserstein distance, capable of
leveraging both structural and feature information by combining both views and
prove its metric properties over very general manifolds. We also define the
barycenter of structured objects as their Fr\&apos;echet mean, leveraging both
feature and structural information. We illustrate the versatility of the method
for problems where structured objects are involved, computing barycenters in
graph and time series contexts. We also use this new distance for graph
classification where we obtain comparable or superior results than
state-of-the-art graph kernel methods and end-to-end graph CNN approach.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Vayer_T/0/1/0/all/0/1&quot;&gt;Titouan Vayer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chapel_L/0/1/0/all/0/1&quot;&gt;Laetitia Chapel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Flamary_R/0/1/0/all/0/1&quot;&gt;R&amp;#xe9;mi Flamary&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tavenard_R/0/1/0/all/0/1&quot;&gt;Romain Tavenard&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Courty_N/0/1/0/all/0/1&quot;&gt;Nicolas Courty&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09213">
<title>Learning latent variable structured prediction models with Gaussian perturbations. (arXiv:1805.09213v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.09213</link>
<description rdf:parseType="Literal">&lt;p&gt;The standard margin-based structured prediction commonly uses a maximum loss
over all possible structured outputs. The large-margin formulation including
latent variables not only results in a non-convex formulation but also
increases the search space by a factor of the size of the latent space. Recent
work has proposed the use of the maximum loss over random structured outputs
sampled independently from some proposal distribution, with theoretical
guarantees. We extend this work by including latent variables. We study a new
family of loss functions under Gaussian perturbations and analyze the effect of
the latent space on the generalization bounds. We show that the non-convexity
of learning with latent variables originates naturally, as it relates to a
tight upper bound of the Gibbs decoder distortion with respect to the latent
space. Finally, we provide a formulation using random samples that produces a
tighter upper bound of the Gibbs decoder distortion up to a statistical
accuracy, which enables a faster evaluation of the objective function. We
illustrate the method with synthetic experiments and a computer vision
application.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bello_K/0/1/0/all/0/1&quot;&gt;Kevin Bello&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Honorio_J/0/1/0/all/0/1&quot;&gt;Jean Honorio&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09217">
<title>Tight Bounds for Collaborative PAC Learning via Multiplicative Weights. (arXiv:1805.09217v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.09217</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the collaborative PAC learning problem recently proposed in Blum et
al.~\cite{BHPQ17}, in which we have $k$ players and they want to learn a target
function collaboratively, such that the learned function approximates the
target function well on all players&apos; distributions simultaneously. The quality
of the collaborative learning algorithm is measured by the ratio between the
sample complexity of the algorithm and that of the learning algorithm for a
single distribution (called the overhead). We obtain a collaborative learning
algorithm with overhead $O(\ln k)$, improving the one with overhead $O(\ln^2
k)$ in \cite{BHPQ17}. We also show that an $\Omega(\ln k)$ overhead is
inevitable when $k$ is polynomial bounded by the VC dimension of the hypothesis
class. Finally, our experimental study has demonstrated the superiority of our
algorithm compared with the one in Blum et al. on real-world datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1&quot;&gt;Jiecao Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1&quot;&gt;Qin Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1&quot;&gt;Yuan Zhou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09247">
<title>Cleaning up the neighborhood: A full classification for adversarial partial monitoring. (arXiv:1805.09247v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.09247</link>
<description rdf:parseType="Literal">&lt;p&gt;Partial monitoring is a generalization of the well-known multi-armed bandit
framework where the loss is not directly observed by the learner. We complete
the classification of finite adversarial partial monitoring to include all
games, solving an open problem posed by Bartok et al. [2014]. Along the way we
simplify and improve existing algorithms and correct errors in previous
analyses. Our second contribution is a new algorithm for the class of games
studied by Bartok [2013] where we prove upper and lower regret bounds that shed
more light on the dependence of the regret on the game structure.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lattimore_T/0/1/0/all/0/1&quot;&gt;Tor Lattimore&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Szepesvari_C/0/1/0/all/0/1&quot;&gt;Csaba Szepesvari&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09253">
<title>Federated Learning for Ultra-Reliable Low-Latency V2V Communications. (arXiv:1805.09253v1 [cs.NI])</title>
<link>http://arxiv.org/abs/1805.09253</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, a novel joint transmit power and resource allocation approach
for enabling ultra-reliable low-latency communication (URLLC) in vehicular
networks is proposed. The objective is to minimize the network-wide power
consumption of vehicular users (VUEs) while ensuring high reliability in terms
of probabilistic queuing delays. In particular, a reliability measure is
defined to characterize extreme events (i.e., when vehicles&apos; queue lengths
exceed a predefined threshold with non-negligible probability) using extreme
value theory (EVT). Leveraging principles from federated learning (FL), the
distribution of these extreme events corresponding to the tail distribution of
queues is estimated by VUEs in a decentralized manner. Finally, Lyapunov
optimization is used to find the joint transmit power and resource allocation
policies for each VUE in a distributed manner. The proposed solution is
validated via extensive simulations using a Manhattan mobility model. It is
shown that FL enables the proposed distributed method to estimate the tail
distribution of queues with an accuracy that is very close to a centralized
solution with up to 79\% reductions in the amount of data that need to be
exchanged. Furthermore, the proposed method yields up to 60\% reductions of
VUEs with large queue lengths, without an additional power consumption,
compared to an average queue-based baseline. Compared to systems with fixed
power consumption and focusing on queue stability while minimizing average
power consumption, the reduction in extreme events of the proposed method is
about two orders of magnitude.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Samarakoon_S/0/1/0/all/0/1&quot;&gt;Sumudu Samarakoon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bennis_M/0/1/0/all/0/1&quot;&gt;Mehdi Bennis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saad_W/0/1/0/all/0/1&quot;&gt;Walid Saad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Debbah_M/0/1/0/all/0/1&quot;&gt;Merouane Debbah&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09266">
<title>Collective Online Learning via Decentralized Gaussian Processes in Massive Multi-Agent Systems. (arXiv:1805.09266v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.09266</link>
<description rdf:parseType="Literal">&lt;p&gt;Distributed machine learning (ML) is a modern computation paradigm that
divides its workload into independent tasks that can be simultaneously achieved
by multiple machines (i.e., agents) for better scalability. However, a typical
distributed system is usually implemented with a central server that collects
data statistics from multiple independent machines operating on different
subsets of data to build a global analytic model. This centralized
communication architecture however exposes a single choke point for operational
failure and places severe bottlenecks on the server&apos;s communication and
computation capacities as it has to process a growing volume of communication
from a crowd of learning agents. To mitigate these bottlenecks, this paper
introduces a novel Collective Online Learning Gaussian Process framework for
massive distributed systems that allows each agent to build its local model,
which can be exchanged and combined efficiently with others via peer-to-peer
communication to converge on a global model of higher quality. Finally, our
empirical results consistently demonstrate the efficiency of our framework on
both synthetic and real-world datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hoang_T/0/1/0/all/0/1&quot;&gt;Trong Nghia Hoang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hoang_Q/0/1/0/all/0/1&quot;&gt;Quang Minh Hoang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Low_K/0/1/0/all/0/1&quot;&gt;Kian Hsiang Low&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+How_J/0/1/0/all/0/1&quot;&gt;Jonathan How&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09281">
<title>Variational Inference for Data-Efficient Model Learning in POMDPs. (arXiv:1805.09281v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.09281</link>
<description rdf:parseType="Literal">&lt;p&gt;Partially observable Markov decision processes (POMDPs) are a powerful
abstraction for tasks that require decision making under uncertainty, and
capture a wide range of real world tasks. Today, effective planning approaches
exist that generate effective strategies given black-box models of a POMDP
task. Yet, an open question is how to acquire accurate models for complex
domains. In this paper we propose DELIP, an approach to model learning for
POMDPs that utilizes amortized structured variational inference. We empirically
show that our model leads to effective control strategies when coupled with
state-of-the-art planners. Intuitively, model-based approaches should be
particularly beneficial in environments with changing reward structures, or
where rewards are initially unknown. Our experiments confirm that DELIP is
particularly effective in this setting.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tschiatschek_S/0/1/0/all/0/1&quot;&gt;Sebastian Tschiatschek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Arulkumaran_K/0/1/0/all/0/1&quot;&gt;Kai Arulkumaran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Stuhmer_J/0/1/0/all/0/1&quot;&gt;Jan St&amp;#xfc;hmer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hofmann_K/0/1/0/all/0/1&quot;&gt;Katja Hofmann&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09293">
<title>Interior Point Methods with Adversarial Networks. (arXiv:1805.09293v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.09293</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a new methodology, called IPMAN, that combines interior point
methods and generative adversarial networks to solve constrained optimization
problems with feasible sets that are non-convex or not explicitly defined. Our
methodology produces {\epsilon}-optimal solutions and demonstrates that, when
there are multiple global optima, it learns a distribution over the optimal
set. We apply our approach to synthetic examples to demonstrate its
effectiveness and to a problem in radiation therapy treatment optimization with
a non-convex feasible set.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mahmood_R/0/1/0/all/0/1&quot;&gt;Rafid Mahmood&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Babier_A/0/1/0/all/0/1&quot;&gt;Aaron Babier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Diamant_A/0/1/0/all/0/1&quot;&gt;Adam Diamant&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chan_T/0/1/0/all/0/1&quot;&gt;Timothy C. Y. Chan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09294">
<title>Likelihood-free inference with emulator networks. (arXiv:1805.09294v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.09294</link>
<description rdf:parseType="Literal">&lt;p&gt;Approximate Bayesian Computation (ABC) provides methods for Bayesian
inference in simulation-based stochastic models which do not permit tractable
likelihoods. We present a new ABC method which uses probabilistic neural
emulator networks to learn synthetic likelihoods on simulated data -- both
local emulators which approximate the likelihood for specific observed data, as
well as global ones which are applicable to a range of data. Simulations are
chosen adaptively using an acquisition function which takes into account
uncertainty about either the posterior distribution of interest, or the
parameters of the emulator. Our approach does not rely on user-defined
rejection thresholds or distance functions. We illustrate inference with
emulator networks on synthetic examples and on a biophysical neuron model, and
show that emulators allow accurate and efficient inference even on
high-dimensional problems which are challenging for conventional ABC
approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lueckmann_J/0/1/0/all/0/1&quot;&gt;Jan-Matthis Lueckmann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bassetto_G/0/1/0/all/0/1&quot;&gt;Giacomo Bassetto&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Karaletsos_T/0/1/0/all/0/1&quot;&gt;Theofanis Karaletsos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Macke_J/0/1/0/all/0/1&quot;&gt;Jakob H. Macke&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09302">
<title>Input and Weight Space Smoothing for Semi-supervised Learning. (arXiv:1805.09302v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.09302</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose regularizing the empirical loss for semi-supervised learning by
acting on both the input (data) space, and the weight (parameter) space. We
show that the two are not equivalent, and in fact are complementary, one
affecting the minimality of the resulting representation, the other
insensitivity to nuisance variability. We propose a method to perform such
smoothing, which combines known input-space smoothing with a novel weight-space
smoothing, based on a min-max (adversarial) optimization. The resulting
Adversarial Block Coordinate Descent (ABCD) algorithm performs gradient ascent
with a small learning rate for a random subset of the weights, and standard
gradient descent on the remaining weights in the same mini-batch. It achieves
comparable performance to the state-of-the-art without resorting to heavy data
augmentation, using a relatively simple architecture.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cicek_S/0/1/0/all/0/1&quot;&gt;Safa Cicek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Soatto_S/0/1/0/all/0/1&quot;&gt;Stefano Soatto&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1503.05509">
<title>Differentiating the multipoint Expected Improvement for optimal batch design. (arXiv:1503.05509v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1503.05509</link>
<description rdf:parseType="Literal">&lt;p&gt;This work deals with parallel optimization of expensive objective functions
which are modeled as sample realizations of Gaussian processes. The study is
formalized as a Bayesian optimization problem, or continuous multi-armed bandit
problem, where a batch of q &amp;gt; 0 arms is pulled in parallel at each iteration.
Several algorithms have been developed for choosing batches by trading off
exploitation and exploration. As of today, the maximum Expected Improvement
(EI) and Upper Confidence Bound (UCB) selection rules appear as the most
prominent approaches for batch selection. Here, we build upon recent work on
the multipoint Expected Improvement criterion, for which an analytic expansion
relying on Tallis&apos; formula was recently established. The computational burden
of this selection rule being still an issue in application, we derive a
closed-form expression for the gradient of the multipoint Expected Improvement,
which aims at facilitating its maximization using gradient-based ascent
algorithms. Substantial computational savings are shown in application. In
addition, our algorithms are tested numerically and compared to
state-of-the-art UCB-based batch-sequential algorithms. Combining starting
designs relying on UCB with gradient-based EI local optimization finally
appears as a sound option for batch design in distributed Gaussian Process
optimization.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Marmin_S/0/1/0/all/0/1&quot;&gt;S&amp;#xe9;bastien Marmin&lt;/a&gt; (I2M, IRSN, IMSV), &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chevalier_C/0/1/0/all/0/1&quot;&gt;Cl&amp;#xe9;ment Chevalier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ginsbourger_D/0/1/0/all/0/1&quot;&gt;David Ginsbourger&lt;/a&gt; (IMSV)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1608.08063">
<title>Wasserstein Discriminant Analysis. (arXiv:1608.08063v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1608.08063</link>
<description rdf:parseType="Literal">&lt;p&gt;Wasserstein Discriminant Analysis (WDA) is a new supervised method that can
improve classification of high-dimensional data by computing a suitable linear
map onto a lower dimensional subspace. Following the blueprint of classical
Linear Discriminant Analysis (LDA), WDA selects the projection matrix that
maximizes the ratio of two quantities: the dispersion of projected points
coming from different classes, divided by the dispersion of projected points
coming from the same class. To quantify dispersion, WDA uses regularized
Wasserstein distances, rather than cross-variance measures which have been
usually considered, notably in LDA. Thanks to the the underlying principles of
optimal transport, WDA is able to capture both global (at distribution scale)
and local (at samples scale) interactions between classes. Regularized
Wasserstein distances can be computed using the Sinkhorn matrix scaling
algorithm; We show that the optimization of WDA can be tackled using automatic
differentiation of Sinkhorn iterations. Numerical experiments show promising
results both in terms of prediction and visualization on toy examples and real
life datasets such as MNIST and on deep features obtained from a subset of the
Caltech dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Flamary_R/0/1/0/all/0/1&quot;&gt;R&amp;#xe9;mi Flamary&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Cuturi_M/0/1/0/all/0/1&quot;&gt;Marco Cuturi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Courty_N/0/1/0/all/0/1&quot;&gt;Nicolas Courty&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rakotomamonjy_A/0/1/0/all/0/1&quot;&gt;Alain Rakotomamonjy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1611.02401">
<title>Divide and Conquer Networks. (arXiv:1611.02401v6 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1611.02401</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the learning of algorithmic tasks by mere observation of
input-output pairs. Rather than studying this as a black-box discrete
regression problem with no assumption whatsoever on the input-output mapping,
we concentrate on tasks that are amenable to the principle of divide and
conquer, and study what are its implications in terms of learning. This
principle creates a powerful inductive bias that we leverage with neural
architectures that are defined recursively and dynamically, by learning two
scale-invariant atomic operations: how to split a given input into smaller
sets, and how to merge two partially solved tasks into a larger partial
solution. Our model can be trained in weakly supervised environments, namely by
just observing input-output pairs, and in even weaker environments, using a
non-differentiable reward signal. Moreover, thanks to the dynamic aspect of our
architecture, we can incorporate the computational complexity as a
regularization term that can be optimized by backpropagation. We demonstrate
the flexibility and efficiency of the Divide-and-Conquer Network on several
combinatorial and geometric tasks: convex hull, clustering, knapsack and
euclidean TSP. Thanks to the dynamic programming nature of our model, we show
significant improvements in terms of generalization error and computational
complexity.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nowak_A/0/1/0/all/0/1&quot;&gt;Alex Nowak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Folque_D/0/1/0/all/0/1&quot;&gt;David Folqu&amp;#xe9;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bruna_J/0/1/0/all/0/1&quot;&gt;Joan Bruna&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1702.08134">
<title>Dropping Convexity for More Efficient and Scalable Online Multiview Learning. (arXiv:1702.08134v7 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1702.08134</link>
<description rdf:parseType="Literal">&lt;p&gt;Multiview representation learning is very popular for latent factor analysis.
It naturally arises in many data analysis, machine learning, and information
retrieval applications to model dependent structures among multiple data
sources. For computational convenience, existing approaches usually formulate
the multiview representation learning as convex optimization problems, where
global optima can be obtained by certain algorithms in polynomial time.
However, many pieces of evidence have corroborated that heuristic nonconvex
approaches also have good empirical computational performance and convergence
to the global optima, although there is a lack of theoretical justification.
Such a gap between theory and practice motivates us to study a nonconvex
formulation for multiview representation learning, which can be efficiently
solved by a simple stochastic gradient descent (SGD) algorithm. We first
illustrate the geometry of the nonconvex formulation; Then, we establish
asymptotic global rates of convergence to the global optima by diffusion
approximations. Numerical experiments are provided to support our theory.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1&quot;&gt;Zhehui Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1&quot;&gt;Lin F. Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1&quot;&gt;Chris J. Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_T/0/1/0/all/0/1&quot;&gt;Tuo Zhao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.06181">
<title>On Nesting Monte Carlo Estimators. (arXiv:1709.06181v4 [stat.CO] UPDATED)</title>
<link>http://arxiv.org/abs/1709.06181</link>
<description rdf:parseType="Literal">&lt;p&gt;Many problems in machine learning and statistics involve nested expectations
and thus do not permit conventional Monte Carlo (MC) estimation. For such
problems, one must nest estimators, such that terms in an outer estimator
themselves involve calculation of a separate, nested, estimation. We
investigate the statistical implications of nesting MC estimators, including
cases of multiple levels of nesting, and establish the conditions under which
they converge. We derive corresponding rates of convergence and provide
empirical evidence that these rates are observed in practice. We further
establish a number of pitfalls that can arise from naive nesting of MC
estimators, provide guidelines about how these can be avoided, and lay out
novel methods for reformulating certain classes of nested expectation problems
into single expectations, leading to improved convergence rates. We demonstrate
the applicability of our work by using our results to develop a new estimator
for discrete Bayesian experimental design problems and derive error bounds for
a class of variational objectives.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rainforth_T/0/1/0/all/0/1&quot;&gt;Tom Rainforth&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Cornish_R/0/1/0/all/0/1&quot;&gt;Robert Cornish&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yang_H/0/1/0/all/0/1&quot;&gt;Hongseok Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Warrington_A/0/1/0/all/0/1&quot;&gt;Andrew Warrington&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wood_F/0/1/0/all/0/1&quot;&gt;Frank Wood&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.02766">
<title>Bayesian Alignments of Warped Multi-Output Gaussian Processes. (arXiv:1710.02766v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1710.02766</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a novel Bayesian approach to modelling nonlinear alignments of
time series based on latent shared information. We apply the method to the
real-world problem of finding common structure in the sensor data of wind
turbines introduced by the underlying latent and turbulent wind field. The
proposed model allows for both arbitrary alignments of the inputs and
non-parametric output warpings to transform the observations. This gives rise
to multiple deep Gaussian process models connected via latent generating
processes. We present an efficient variational approximation based on nested
variational compression and show how the model can be used to extract shared
information between dependent time series, recovering an interpretable
functional decomposition of the learning problem. We show results for an
artificial data set and real-world data of two wind turbines.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kaiser_M/0/1/0/all/0/1&quot;&gt;Markus Kaiser&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Otte_C/0/1/0/all/0/1&quot;&gt;Clemens Otte&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Runkler_T/0/1/0/all/0/1&quot;&gt;Thomas Runkler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ek_C/0/1/0/all/0/1&quot;&gt;Carl Henrik Ek&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08855">
<title>Minimax Distribution Estimation in Wasserstein Distance. (arXiv:1802.08855v2 [math.ST] UPDATED)</title>
<link>http://arxiv.org/abs/1802.08855</link>
<description rdf:parseType="Literal">&lt;p&gt;The Wasserstein metric is an important measure of distance between
probability distributions, with applications in machine learning, statistics,
probability theory, and data analysis. This paper provides upper and lower
bounds on statistical minimax rates for the problem of estimating a probability
distribution under Wasserstein loss, using only metric properties, such as
covering and packing numbers, of the sample space, and weak moment assumptions
on the probability distributions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Singh_S/0/1/0/all/0/1&quot;&gt;Shashank Singh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Poczos_B/0/1/0/all/0/1&quot;&gt;Barnab&amp;#xe1;s P&amp;#xf3;czos&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.10551">
<title>A Variational Inequality Perspective on Generative Adversarial Networks. (arXiv:1802.10551v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1802.10551</link>
<description rdf:parseType="Literal">&lt;p&gt;Generative adversarial networks (GANs) form a generative modeling approach
known for producing appealing samples, but they are notably difficult to train.
One common way to tackle this issue has been to propose new formulations of the
GAN objective. Yet, surprisingly few studies have looked at optimization
methods designed for this adversarial training. In this work, we survey the
&quot;variational inequality&quot; framework which contains most formulations of GANs
introduced so far. Tapping into the mathematical programming literature, we
counter some common misconceptions about the difficulties of saddle point
optimization and propose to extend standard methods designed for variational
inequalities to the training of GANs. Amongst others, we apply a stochastic
version of the extragradient method (SEM) to this task, and propose a novel
cheaper variant (OneSEM).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gidel_G/0/1/0/all/0/1&quot;&gt;Gauthier Gidel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Berard_H/0/1/0/all/0/1&quot;&gt;Hugo Berard&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vincent_P/0/1/0/all/0/1&quot;&gt;Pascal Vincent&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lacoste_Julien_S/0/1/0/all/0/1&quot;&gt;Simon Lacoste-Julien&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.01314">
<title>Training deep learning based denoisers without ground truth data. (arXiv:1803.01314v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1803.01314</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent deep learning based denoisers often outperform state-of-the-art
conventional denoisers such as BM3D. They are typically trained to minimize the
mean squared error (MSE) between the output of a deep neural network and the
ground truth image. In deep learning based denoisers, it is important to use
high quality noiseless ground truth for high performance, but it is often
challenging or even infeasible to obtain such a clean image in application
areas such as hyperspectral remote sensing and medical imaging. We propose a
Stein&apos;s Unbiased Risk Estimator (SURE) based method for training deep neural
network denoisers only with noisy images. We demonstrated that our SURE based
method without ground truth was able to train deep neural network denoisers to
yield performance close to deep learning denoisers trained with ground truth
and to outperform state-of-the-art BM3D. Further improvements were achieved by
including noisy test images for training denoiser networks using our proposed
SURE based method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Soltanayev_S/0/1/0/all/0/1&quot;&gt;Shakarim Soltanayev&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chun_S/0/1/0/all/0/1&quot;&gt;Se Young Chun&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.01682">
<title>Beyond Greedy Ranking: Slate Optimization via List-CVAE. (arXiv:1803.01682v4 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1803.01682</link>
<description rdf:parseType="Literal">&lt;p&gt;The conventional approach to solving the recommendation problem is through
greedy ranking by prediction scores for individual document candidates. However
these methods fail to optimize the slate as a whole, and often struggle at
capturing biases caused by the page layout and interdependencies between
documents. The slate recommendation problem aims to find the optimal, ordered
subset of documents, a.k.a. slate, given the page layout to serve users
recommendations. Solving this problem is hard due to combinatorial explosion of
document candidates and their display positions on the page. In this paper, we
introduce List Conditional Variational Auto-Encoders (List-CVAE) to learn the
joint distribution of documents on the slate conditional on user responses, and
directly generate slates. Experiments on simulated and real-world data show
that List-CVAE outperforms greedy ranking methods consistently on various
scales of documents corpora.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Jiang_R/0/1/0/all/0/1&quot;&gt;Ray Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gowal_S/0/1/0/all/0/1&quot;&gt;Sven Gowal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mann_T/0/1/0/all/0/1&quot;&gt;Timothy A. Mann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rezende_D/0/1/0/all/0/1&quot;&gt;Danilo J. Rezende&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.04087">
<title>Learning Binary Bayesian Networks in Polynomial Time and Sample Complexity. (arXiv:1803.04087v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1803.04087</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the problem of structure learning for binary Bayesian networks.
Our approach is to recover the true parents and children for each node first
and then combine the results to recover the skeleton. We do not assume any
specific conditional probability distribution for the nodes. Rather, we show
that if the expectations of products of node pairs satisfy certain conditions
then we can do exact recovery of parents and children of a node by performing
l_1-regularized linear regression with sufficient number of samples. The sample
complexity of our proposed approach depends logarithmically on number of nodes
in the Bayesian network. Furthermore, our method runs in polynomial time.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barik_A/0/1/0/all/0/1&quot;&gt;Adarsh Barik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Honorio_J/0/1/0/all/0/1&quot;&gt;Jean Honorio&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.04899">
<title>Optimal Transport for Multi-source Domain Adaptation under Target Shift. (arXiv:1803.04899v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1803.04899</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we propose to tackle the problem of reducing discrepancies
between multiple domains referred to as multi-source domain adaptation and
consider it under the target shift assumption: in all domains we aim to solve a
classification problem with the same output classes, but with labels&apos;
proportions differing across them. This problem, generally ignored in the vast
majority papers on domain adaptation papers, is nevertheless critical in
real-world applications, and we theoretically show its impact on the adaptation
success. To address this issue, we design a method based on optimal transport,
a theory that has been successfully used to tackle adaptation problems in
machine learning. Our method performs multi-source adaptation and target shift
correction simultaneously by learning the class probabilities of the unlabeled
target sample and the coupling allowing to align two (or more) probability
distributions. Experiments on both synthetic and real-world data related to
satellite image segmentation task show the superiority of the proposed method
over the state-of-the-art.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Redko_I/0/1/0/all/0/1&quot;&gt;Ievgen Redko&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Courty_N/0/1/0/all/0/1&quot;&gt;Nicolas Courty&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Flamary_R/0/1/0/all/0/1&quot;&gt;R&amp;#xe9;mi Flamary&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tuia_D/0/1/0/all/0/1&quot;&gt;Devis Tuia&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.05857">
<title>On the glassy nature of the hard phase in inference problems. (arXiv:1805.05857v2 [cond-mat.dis-nn] UPDATED)</title>
<link>http://arxiv.org/abs/1805.05857</link>
<description rdf:parseType="Literal">&lt;p&gt;An algorithmically hard phase was described in a range of inference problems:
even if the signal can be reconstructed with a small error from an information
theoretic point of view, known algorithms fail unless the noise-to-signal ratio
is sufficiently small. This hard phase is typically understood as a metastable
branch of the dynamical evolution of message passing algorithms. In this work
we study the metastable branch for a prototypical inference problem, the
low-rank matrix factorization, that presents a hard phase. We show that for
noise-to-signal ratios that are below the information theoretic threshold, the
posterior measure is composed of an exponential number of metastable glassy
states and we compute their entropy, called the complexity. We show that this
glassiness extends even slightly below the algorithmic threshold below which
the well-known approximate message passing (AMP) algorithm is able to closely
reconstruct the signal. Counter-intuitively, we find that the performance of
the AMP algorithm is not improved by taking into account the glassy nature of
the hard phase.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Antenucci_F/0/1/0/all/0/1&quot;&gt;Fabrizio Antenucci&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Franz_S/0/1/0/all/0/1&quot;&gt;Silvio Franz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Urbani_P/0/1/0/all/0/1&quot;&gt;Pierfrancesco Urbani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Zdeborova_L/0/1/0/all/0/1&quot;&gt;Lenka Zdeborov&amp;#xe1;&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08058">
<title>Super learning in the SAS system. (arXiv:1805.08058v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1805.08058</link>
<description rdf:parseType="Literal">&lt;p&gt;Background and objective: Stacking is an ensemble machine learning method
that averages predictions from multiple other algorithms, such as generalized
linear models and regression trees. A recent iteration of stacking, called
super learning, has been developed as a general approach to black box
supervised learning and has seen frequent usage, in part due to the
availability of an R package. I develop super learning in the SAS software
system using a new macro, and demonstrate its performance relative to the R
package.
&lt;/p&gt;
&lt;p&gt;Methods: I follow closely previous work using the R SuperLearner package and
assess the performance of super learning in a number of domains. I compare the
R package with the new SAS macro in a small set of simulations assessing curve
fitting in a prediction model, a set of 14 publicly available datasets to
assess cross-validated, expected loss, and data from a randomized trial of job
seekers&apos; training to assess the utility of super learning in causal inference
using inverse probability weighting.
&lt;/p&gt;
&lt;p&gt;Results: Across the simulated data and the publicly available data, the macro
performed similarly to the R package, even with a different set of potential
algorithms available natively in R and SAS. The example with inverse
probability weighting demonstrated the ability of the SAS macro to include
algorithms developed in R.
&lt;/p&gt;
&lt;p&gt;Conclusions: The super learner macro performs as well as the R package at a
number of tasks. Further, by extending the macro to include the use of R
packages, the macro can leverage both the robust, enterprise oriented
procedures in SAS and the nimble, cutting edge packages in R. In the spirit of
ensemble learning, this macro extends the potential library of algorithms
beyond a single software system and provides a simple avenue into machine
learning in SAS.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Keil_A/0/1/0/all/0/1&quot;&gt;Alexander P. Keil&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08102">
<title>Non-Oscillatory Pattern Learning for Non-Stationary Signals. (arXiv:1805.08102v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1805.08102</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper proposes a novel non-oscillatory pattern (NOP) learning scheme for
several oscillatory data analysis problems including signal decomposition,
super-resolution, and signal sub-sampling. To the best of our knowledge, the
proposed NOP is the first algorithm for these problems with fully
non-stationary oscillatory data with close and crossover frequencies, and
general oscillatory patterns. NOP is capable of handling complicated situations
while existing algorithms fail; even in simple cases, e.g., stationary cases
with trigonometric patterns, numerical examples show that NOP admits
competitive or better performance in terms of accuracy and robustness than
several state-of-the-art algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Xu_J/0/1/0/all/0/1&quot;&gt;Jieren Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yitong Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Dunson_D/0/1/0/all/0/1&quot;&gt;David Dunson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Daubechies_I/0/1/0/all/0/1&quot;&gt;Ingrid Daubechies&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yang_H/0/1/0/all/0/1&quot;&gt;Haizhao Yang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08268">
<title>Effective Dimension of Exp-concave Optimization. (arXiv:1805.08268v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.08268</link>
<description rdf:parseType="Literal">&lt;p&gt;We investigate the role of the effective (a.k.a. statistical) dimension in
determining both the statistical and the computational costs associated with
exp-concave stochastic minimization. We derive sample complexity bounds that
scale with $\frac{d_{\lambda}}{\epsilon}$, where $d_{\lambda}$ is the effective
dimension associated with the regularization parameter $\lambda$. These are the
first fast rates in this setting that do not exhibit any explicit dependence
either on the intrinsic dimension or the $\ell_{2}$-norm of the optimal
classifier.
&lt;/p&gt;
&lt;p&gt;We also propose fast preconditioned methods that solve the ERM problem in
time $\tilde{O}
\left(nnz(X)+\min_{\lambda&apos;\ge\lambda}\frac{\lambda&apos;}{\lambda}~d_{\lambda&apos;}^{2}d
\right)$, where $nnz(X)$ is the number of nonzero entries in the data. Our
analysis emphasizes interesting connections between leverage scores,
algorithmic stability and regularization. In particular, our algorithm involves
a novel technique for choosing a regularization parameter $\lambda&apos;$ that
minimizes the complexity bound $\frac{\lambda&apos;}{\lambda}\,d_{\lambda&apos;}^{2}d$,
while avoiding the entire (approximate) computation of the effective dimension
for each candidate $\lambda&apos;$. All of our result extend to the kernel setting.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Agarwal_N/0/1/0/all/0/1&quot;&gt;Naman Agarwal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gonen_A/0/1/0/all/0/1&quot;&gt;Alon Gonen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08321">
<title>Adaptive Monte-Carlo Optimization. (arXiv:1805.08321v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.08321</link>
<description rdf:parseType="Literal">&lt;p&gt;The celebrated Monte Carlo method estimates a quantity that is expensive to
compute by random sampling. We propose adaptive Monte Carlo optimization: a
general framework for discrete optimization of an expensive-to-compute function
by adaptive random sampling. Applications of this framework have already
appeared in machine learning but are tied to their specific contexts and
developed in isolation. We take a unified view and show that the framework has
broad applicability by applying it on several common machine learning problems:
$k$-nearest neighbors, hierarchical clustering and maximum mutual information
feature selection. On real data we show that this framework allows us to
develop algorithms that confer a gain of a magnitude or two over exact
computation. We also characterize the performance gain theoretically under
regularity assumptions on the data that we verify in real world data. The code
is available at https://github.com/govinda-kamath/combinatorial_MAB.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bagaria_V/0/1/0/all/0/1&quot;&gt;Vivek Bagaria&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kamath_G/0/1/0/all/0/1&quot;&gt;Govinda M. Kamath&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tse_D/0/1/0/all/0/1&quot;&gt;David N. Tse&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08527">
<title>Safe Element Screening for Submodular Function Minimization. (arXiv:1805.08527v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1805.08527</link>
<description rdf:parseType="Literal">&lt;p&gt;Submodular functions are discrete analogs of convex functions, which have
applications in various fields, including machine learning, computer vision and
signal processing. However, in large-scale applications, solving Submodular
Function Minimization (SFM) problems remains challenging. In this paper, we
make the first attempt to extend the emerging technique named screening in
large-scale sparse learning to SFM for accelerating its optimization process.
Specifically, we propose a novel safe element screening method---based on a
careful studying of the relationships between SFM and the corresponding convex
proximal problems, as well as the accurate estimation of the optimum of the
proximal problem---to quickly identify the elements that are guaranteed to be
included (we refer to them as active) or excluded (inactive) in the final
optimal solution of SFM during the optimization process. By removing the
inactive elements and fixing the active ones, the problem size can be
dramatically reduced, leading to great savings in the computational cost
without sacrificing accuracy. To the best of our knowledge, the proposed method
is the first screening method in the fields of SFM and even combinatorial
optimization, and thus points out a new direction for accelerating SFM
algorithms. Experiment results on both synthetic and real datasets demonstrate
the significant speedups gained by our screening method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhang_W/0/1/0/all/0/1&quot;&gt;Weizhong Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hong_B/0/1/0/all/0/1&quot;&gt;Bin Hong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ma_L/0/1/0/all/0/1&quot;&gt;Lin Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Liu_W/0/1/0/all/0/1&quot;&gt;Wei Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhang_T/0/1/0/all/0/1&quot;&gt;Tong Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1605.02536">
<title>Random Fourier Features for Operator-Valued Kernels. (arXiv:1605.02536v3 [cs.LG] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1605.02536</link>
<description rdf:parseType="Literal">&lt;p&gt;Devoted to multi-task learning and structured output learning,
operator-valued kernels provide a flexible tool to build vector-valued
functions in the context of Reproducing Kernel Hilbert Spaces. To scale up
these methods, we extend the celebrated Random Fourier Feature methodology to
get an approximation of operator-valued kernels. We propose a general principle
for Operator-valued Random Fourier Feature construction relying on a
generalization of Bochner&apos;s theorem for translation-invariant operator-valued
Mercer kernels. We prove the uniform convergence of the kernel approximation
for bounded and unbounded operator random Fourier features using appropriate
Bernstein matrix concentration inequality. An experimental proof-of-concept
shows the quality of the approximation and the efficiency of the corresponding
linear models on example datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brault_R/0/1/0/all/0/1&quot;&gt;Romain Brault&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+dAlche_Buc_F/0/1/0/all/0/1&quot;&gt;Florence d&amp;#x27;Alch&amp;#xe9;-Buc&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Heinonen_M/0/1/0/all/0/1&quot;&gt;Markus Heinonen&lt;/a&gt;</dc:creator>
</item></rdf:RDF>