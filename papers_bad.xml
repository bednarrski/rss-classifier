<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Boring papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Bad Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-06-28T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.10950"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.10230"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.10698"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.10758"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.10805"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.10928"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.11078"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1603.03491"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1612.02526"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.02309"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.01267"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.10561"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.10692"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.10701"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.10714"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.10728"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.10736"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.10745"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.10773"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.10861"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.10873"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.10897"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.11006"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.11015"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.11027"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.11096"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1605.01656"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1610.00768"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1701.08142"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1703.07047"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1705.07967"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.05501"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.11053"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.04755"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04712"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04826"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.08130"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10074"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.01240"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.01830"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.03836"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.07506"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.10206"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10827"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1806.10950">
<title>A Decomposition-Based Many-Objective Evolutionary Algorithm with Local Iterative Update. (arXiv:1806.10950v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1806.10950</link>
<description rdf:parseType="Literal">&lt;p&gt;Existing studies have shown that the conventional multi-objective
evolutionary algorithms (MOEAs) based on decomposition may lose the population
diversity when solving some many-objective optimization problems. In this
paper, a simple decomposition-based MOEA with local iterative update (LIU) is
proposed. The LIU strategy has two features that are expected to drive the
population to approximate the Pareto Front with good distribution. One is that
only the worst solution in the current neighborhood is swapped out by the newly
generated offspring, preventing the population from being occupied by copies of
a few individuals. The other is that its iterative process helps to assign
better solutions to subproblems, which is beneficial to make full use of the
similarity of solutions to neighboring subproblems and explore local areas in
the search space. In addition, the time complexity of the proposed algorithm is
the same as that of MOEA/D, and lower than that of other known MOEAs, since it
considers only individuals within the current neighborhood at each update. The
algorithm is compared with several of the best MOEAs on problems chosen from
two famous test suites DTLZ and WFG. Experimental results demonstrate that only
a handful of running instances of the algorithm on DTLZ4 lose their population
diversity. What&apos;s more, the algorithm wins in most of the test instances in
terms of both running time and solution quality, indicating that it is very
effective in solving MaOPs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yingyu Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zeng_B/0/1/0/all/0/1&quot;&gt;Bing Zeng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.10230">
<title>Guided evolutionary strategies: escaping the curse of dimensionality in random search. (arXiv:1806.10230v2 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1806.10230</link>
<description rdf:parseType="Literal">&lt;p&gt;Many applications in machine learning require optimizing a function whose
true gradient is unknown, but where surrogate gradient information (directions
that may be correlated with, but not necessarily identical to, the true
gradient) is available instead. This arises when an approximate gradient is
easier to compute than the full gradient (e.g. in meta-learning or unrolled
optimization), or when a true gradient is intractable and is replaced with a
surrogate (e.g. in certain reinforcement learning applications, or when using
synthetic gradients). We propose Guided Evolutionary Strategies, a method for
optimally using surrogate gradient directions along with random search. We
define a search distribution for evolutionary strategies that is elongated
along a guiding subspace spanned by the surrogate gradients. This allows us to
estimate a descent direction which can then be passed to a first-order
optimizer. We analytically and numerically characterize the tradeoffs that
result from tuning how strongly the search distribution is stretched along the
guiding subspace, and we use this to derive a setting of the hyperparameters
that works well across problems. Finally, we apply our method to example
problems including truncated unrolled optimization and a synthetic gradient
problem, demonstrating improvement over both standard evolutionary strategies
and first-order methods that directly follow the surrogate gradient. We provide
a demo of Guided ES at
https://github.com/brain-research/guided-evolutionary-strategies
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Maheswaranathan_N/0/1/0/all/0/1&quot;&gt;Niru Maheswaranathan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Metz_L/0/1/0/all/0/1&quot;&gt;Luke Metz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tucker_G/0/1/0/all/0/1&quot;&gt;George Tucker&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sohl_Dickstein_J/0/1/0/all/0/1&quot;&gt;Jascha Sohl-Dickstein&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.10698">
<title>A comparative study of artificial intelligence and human doctors for the purpose of triage and diagnosis. (arXiv:1806.10698v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1806.10698</link>
<description rdf:parseType="Literal">&lt;p&gt;Online symptom checkers have significant potential to improve patient care,
however their reliability and accuracy remain variable. We hypothesised that an
artificial intelligence (AI) powered triage and diagnostic system would compare
favourably with human doctors with respect to triage and diagnostic accuracy.
We performed a prospective validation study of the accuracy and safety of an AI
powered triage and diagnostic system. Identical cases were evaluated by both an
AI system and human doctors. Differential diagnoses and triage outcomes were
evaluated by an independent judge, who was blinded from knowing the source (AI
system or human doctor) of the outcomes. Independently of these cases,
vignettes from publicly available resources were also assessed to provide a
benchmark to previous studies and the diagnostic component of the MRCGP exam.
Overall we found that the Babylon AI powered Triage and Diagnostic System was
able to identify the condition modelled by a clinical vignette with accuracy
comparable to human doctors (in terms of precision and recall). In addition, we
found that the triage advice recommended by the AI System was, on average,
safer than that of human doctors, when compared to the ranges of acceptable
triage provided by independent expert judges, with only a minimal reduction in
appropriateness.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Razzaki_S/0/1/0/all/0/1&quot;&gt;Salman Razzaki&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Baker_A/0/1/0/all/0/1&quot;&gt;Adam Baker&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Perov_Y/0/1/0/all/0/1&quot;&gt;Yura Perov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Middleton_K/0/1/0/all/0/1&quot;&gt;Katherine Middleton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Baxter_J/0/1/0/all/0/1&quot;&gt;Janie Baxter&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mullarkey_D/0/1/0/all/0/1&quot;&gt;Daniel Mullarkey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sangar_D/0/1/0/all/0/1&quot;&gt;Davinder Sangar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Taliercio_M/0/1/0/all/0/1&quot;&gt;Michael Taliercio&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Butt_M/0/1/0/all/0/1&quot;&gt;Mobasher Butt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Majeed_A/0/1/0/all/0/1&quot;&gt;Azeem Majeed&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+DoRosario_A/0/1/0/all/0/1&quot;&gt;Arnold DoRosario&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mahoney_M/0/1/0/all/0/1&quot;&gt;Megan Mahoney&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Johri_S/0/1/0/all/0/1&quot;&gt;Saurabh Johri&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.10758">
<title>Evaluating Feature Importance Estimates. (arXiv:1806.10758v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.10758</link>
<description rdf:parseType="Literal">&lt;p&gt;Estimating the influence of a given feature to a model prediction is
challenging. We introduce ROAR, RemOve And Retrain, a benchmark to evaluate the
accuracy of interpretability methods that estimate input feature importance in
deep neural networks. We remove a fraction of input features deemed to be most
important according to each estimator and measure the change to the model
accuracy upon retraining. The most accurate estimator will identify inputs as
important whose removal causes the most damage to model performance relative to
all other estimators. This evaluation produces thought-provoking results -- we
find that several estimators are less accurate than a random assignment of
feature importance. However, averaging a set of squared noisy estimators (a
variant of a technique proposed by Smilkov et al. (2017)), leads to significant
gains in accuracy for each method considered and far outperforms such a random
guess.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hooker_S/0/1/0/all/0/1&quot;&gt;Sara Hooker&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Erhan_D/0/1/0/all/0/1&quot;&gt;Dumitru Erhan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kindermans_P/0/1/0/all/0/1&quot;&gt;Pieter-Jan Kindermans&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_B/0/1/0/all/0/1&quot;&gt;Been Kim&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.10805">
<title>Beyond One-hot Encoding: lower dimensional target embedding. (arXiv:1806.10805v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1806.10805</link>
<description rdf:parseType="Literal">&lt;p&gt;Target encoding plays a central role when learning Convolutional Neural
Networks. In this realm, One-hot encoding is the most prevalent strategy due to
its simplicity. However, this so widespread encoding schema assumes a flat
label space, thus ignoring rich relationships existing among labels that can be
exploited during training. In large-scale datasets, data does not span the full
label space, but instead lies in a low-dimensional output manifold. Following
this observation, we embed the targets into a low-dimensional space,
drastically improving convergence speed while preserving accuracy. Our
contribution is two fold: (i) We show that random projections of the label
space are a valid tool to find such lower dimensional embeddings, boosting
dramatically convergence rates at zero computational cost; and (ii) we propose
a normalized eigenrepresentation of the class manifold that encodes the targets
with minimal information loss, improving the accuracy of random projections
encoding while enjoying the same convergence rates. Experiments on CIFAR-100,
CUB200-2011, Imagenet, and MIT Places demonstrate that the proposed approach
drastically improves convergence speed while reaching very competitive accuracy
rates.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rodriguez_P/0/1/0/all/0/1&quot;&gt;Pau Rodr&amp;#xed;guez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bautista_M/0/1/0/all/0/1&quot;&gt;Miguel A. Bautista&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gonzalez_J/0/1/0/all/0/1&quot;&gt;Jordi Gonz&amp;#xe0;lez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Escalera_S/0/1/0/all/0/1&quot;&gt;Sergio Escalera&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.10928">
<title>Record Linkage to Match Customer Names: A Probabilistic Approach. (arXiv:1806.10928v1 [cs.DB])</title>
<link>http://arxiv.org/abs/1806.10928</link>
<description rdf:parseType="Literal">&lt;p&gt;Consider the following problem: given a database of records indexed by names
(e.g., name of companies, restaurants, businesses, or universities) and a new
name, determine whether the new name is in the database, and if so, which
record it refers to. This problem is an instance of record linkage problem and
is a challenging problem because people do not consistently use the official
name, but use abbreviations, synonyms, different order of terms, different
spelling of terms, short form of terms, and the name can contain typos or
spacing issues. We provide a probabilistic model using relational logistic
regression to find the probability of each record in the database being the
desired record for a given query and find the best record(s) with respect to
the probabilities. Building on term-matching and translational approaches for
search, our model addresses many of the aforementioned challenges and provides
good results when existing baselines fail. Using the probabilities outputted by
the model, we can automate the search process for a portion of queries whose
desired documents get a probability higher than a trust threshold. We evaluate
our model on a large real-world dataset from a telecommunications company and
compare it to several state-of-the-art baselines. The obtained results show
that our model is a promising probabilistic model for record linkage for names.
We also test if the knowledge learned by our model on one domain can be
effectively transferred to a new domain. For this purpose, we test our model on
an unseen test set from the business names of the secondString dataset.
Promising results show that our model can be effectively applied to unseen
datasets. Finally, we study the sensitivity of our model to the statistics of
datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fatemi_B/0/1/0/all/0/1&quot;&gt;Bahare Fatemi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kazemi_S/0/1/0/all/0/1&quot;&gt;Seyed Mehran Kazemi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Poole_D/0/1/0/all/0/1&quot;&gt;David Poole&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.11078">
<title>A probabilistic constrained clustering for transfer learning and image category discovery. (arXiv:1806.11078v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1806.11078</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural network-based clustering has recently gained popularity, and in
particular a constrained clustering formulation has been proposed to perform
transfer learning and image category discovery using deep learning. The core
idea is to formulate a clustering objective with pairwise constraints that can
be used to train a deep clustering network; therefore the cluster assignments
and their underlying feature representations are jointly optimized end-to-end.
In this work, we provide a novel clustering formulation to address scalability
issues of previous work in terms of optimizing deeper networks and larger
amounts of categories. The proposed objective directly minimizes the negative
log-likelihood of cluster assignment with respect to the pairwise constraints,
has no hyper-parameters, and demonstrates improved scalability and performance
on both supervised learning and unsupervised transfer learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hsu_Y/0/1/0/all/0/1&quot;&gt;Yen-Chang Hsu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lv_Z/0/1/0/all/0/1&quot;&gt;Zhaoyang Lv&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schlosser_J/0/1/0/all/0/1&quot;&gt;Joel Schlosser&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Odom_P/0/1/0/all/0/1&quot;&gt;Phillip Odom&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kira_Z/0/1/0/all/0/1&quot;&gt;Zsolt Kira&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1603.03491">
<title>Bayesian Opponent Exploitation in Imperfect-Information Games. (arXiv:1603.03491v6 [cs.GT] UPDATED)</title>
<link>http://arxiv.org/abs/1603.03491</link>
<description rdf:parseType="Literal">&lt;p&gt;Two fundamental problems in computational game theory are computing a Nash
equilibrium and learning to exploit opponents given observations of their play
(opponent exploitation). The latter is perhaps even more important than the
former: Nash equilibrium does not have a compelling theoretical justification
in game classes other than two-player zero-sum, and for all games one can
potentially do better by exploiting perceived weaknesses of the opponent than
by following a static equilibrium strategy throughout the match. The natural
setting for opponent exploitation is the Bayesian setting where we have a prior
model that is integrated with observations to create a posterior opponent model
that we respond to. The most natural, and a well-studied prior distribution is
the Dirichlet distribution. An exact polynomial-time algorithm is known for
best-responding to the posterior distribution for an opponent assuming a
Dirichlet prior with multinomial sampling in normal-form games; however, for
imperfect-information games the best known algorithm is based on approximating
an infinite integral without theoretical guarantees. We present the first exact
algorithm for a natural class of imperfect-information games. We demonstrate
that our algorithm runs quickly in practice and outperforms the best prior
approaches. We also present an algorithm for the uniform prior setting.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ganzfried_S/0/1/0/all/0/1&quot;&gt;Sam Ganzfried&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_Q/0/1/0/all/0/1&quot;&gt;Qingyun Sun&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1612.02526">
<title>Prediction with a Short Memory. (arXiv:1612.02526v5 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1612.02526</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the problem of predicting the next observation given a sequence
of past observations, and consider the extent to which accurate prediction
requires complex algorithms that explicitly leverage long-range dependencies.
Perhaps surprisingly, our positive results show that for a broad class of
sequences, there is an algorithm that predicts well on average, and bases its
predictions only on the most recent few observation together with a set of
simple summary statistics of the past observations. Specifically, we show that
for any distribution over observations, if the mutual information between past
observations and future observations is upper bounded by $I$, then a simple
Markov model over the most recent $I/\epsilon$ observations obtains expected KL
error $\epsilon$---and hence $\ell_1$ error $\sqrt{\epsilon}$---with respect to
the optimal predictor that has access to the entire past and knows the data
generating distribution. For a Hidden Markov Model with $n$ hidden states, $I$
is bounded by $\log n$, a quantity that does not depend on the mixing time, and
we show that the trivial prediction algorithm based on the empirical
frequencies of length $O(\log n/\epsilon)$ windows of observations achieves
this error, provided the length of the sequence is $d^{\Omega(\log
n/\epsilon)}$, where $d$ is the size of the observation alphabet.
&lt;/p&gt;
&lt;p&gt;We also establish that this result cannot be improved upon, even for the
class of HMMs, in the following two senses: First, for HMMs with $n$ hidden
states, a window length of $\log n/\epsilon$ is information-theoretically
necessary to achieve expected $\ell_1$ error $\sqrt{\epsilon}$. Second, the
$d^{\Theta(\log n/\epsilon)}$ samples required to estimate the Markov model for
an observation alphabet of size $d$ is necessary for any computationally
tractable learning algorithm, assuming the hardness of strongly refuting a
certain class of CSPs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sharan_V/0/1/0/all/0/1&quot;&gt;Vatsal Sharan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kakade_S/0/1/0/all/0/1&quot;&gt;Sham Kakade&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_P/0/1/0/all/0/1&quot;&gt;Percy Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Valiant_G/0/1/0/all/0/1&quot;&gt;Gregory Valiant&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.02309">
<title>Learning Overcomplete HMMs. (arXiv:1711.02309v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1711.02309</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the problem of learning overcomplete HMMs---those that have many
hidden states but a small output alphabet. Despite having significant practical
importance, such HMMs are poorly understood with no known positive or negative
results for efficient learning. In this paper, we present several new
results---both positive and negative---which help define the boundaries between
the tractable and intractable settings. Specifically, we show positive results
for a large subclass of HMMs whose transition matrices are sparse,
well-conditioned, and have small probability mass on short cycles. On the other
hand, we show that learning is impossible given only a polynomial number of
samples for HMMs with a small output alphabet and whose transition matrices are
random regular graphs with large degree. We also discuss these results in the
context of learning HMMs which can capture long-term dependencies.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sharan_V/0/1/0/all/0/1&quot;&gt;Vatsal Sharan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kakade_S/0/1/0/all/0/1&quot;&gt;Sham Kakade&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_P/0/1/0/all/0/1&quot;&gt;Percy Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Valiant_G/0/1/0/all/0/1&quot;&gt;Gregory Valiant&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.01267">
<title>Internal Model from Observations for Reward Shaping. (arXiv:1806.01267v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1806.01267</link>
<description rdf:parseType="Literal">&lt;p&gt;Reinforcement learning methods require careful design involving a reward
function to obtain the desired action policy for a given task. In the absence
of hand-crafted reward functions, prior work on the topic has proposed several
methods for reward estimation by using expert state trajectories and action
pairs. However, there are cases where complete or good action information
cannot be obtained from expert demonstrations. We propose a novel reinforcement
learning method in which the agent learns an internal model of observation on
the basis of expert-demonstrated state trajectories to estimate rewards without
completely learning the dynamics of the external environment from state-action
pairs. The internal model is obtained in the form of a predictive model for the
given expert state distribution. During reinforcement learning, the agent
predicts the reward as a function of the difference between the actual state
and the state predicted by the internal model. We conducted multiple
experiments in environments of varying complexity, including the Super Mario
Bros and Flappy Bird games. We show our method successfully trains good
policies directly from expert game-play videos.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kimura_D/0/1/0/all/0/1&quot;&gt;Daiki Kimura&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chaudhury_S/0/1/0/all/0/1&quot;&gt;Subhajit Chaudhury&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tachibana_R/0/1/0/all/0/1&quot;&gt;Ryuki Tachibana&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dasgupta_S/0/1/0/all/0/1&quot;&gt;Sakyasingha Dasgupta&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.10561">
<title>Knowledge Compilation in Multi-Agent Epistemic Logics. (arXiv:1806.10561v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1806.10561</link>
<description rdf:parseType="Literal">&lt;p&gt;Epistemic logics are a primary formalism for multi-agent systems but major
reasoning tasks in such epistemic logics are intractable, which impedes
applications of multi-agent epistemic logics in automatic planning. Knowledge
compilation provides a promising way of resolving the intractability by
identifying expressive fragments of epistemic logics that are tractable for
important reasoning tasks such as satisfiability and forgetting. The property
of logical separability allows to decompose a formula into some of its
subformulas and thus modular algorithms for various reasoning tasks can be
developed. In this paper, by employing logical separability, we propose an
approach to knowledge compilation for the logic Kn by defining a normal form
SDNF. Among several novel results, we show that every epistemic formula can be
equivalently compiled into a formula in SDNF, major reasoning tasks in SDNF are
tractable, and formulas in SDNF enjoy the logical separability. Our results
shed some lights on modular approaches to knowledge compilation. Furthermore,
we apply our results in the multi-agent epistemic planning. Finally, we extend
the above result to the logic K45n that is Kn extended by introspection axioms
4 and 5.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fang_L/0/1/0/all/0/1&quot;&gt;Liangda Fang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1&quot;&gt;Kewen Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zhe Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wen_X/0/1/0/all/0/1&quot;&gt;Ximing Wen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.10692">
<title>ActiveRemediation: The Search for Lead Pipes in Flint, Michigan. (arXiv:1806.10692v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.10692</link>
<description rdf:parseType="Literal">&lt;p&gt;We detail our ongoing work in Flint, Michigan to detect pipes made of lead
and other hazardous metals. After elevated levels of lead were detected in
residents&apos; drinking water, followed by an increase in blood lead levels in area
children, the state and federal governments directed over $125 million to
replace water service lines, the pipes connecting each home to the water
system. In the absence of accurate records, and with the high cost of
determining buried pipe materials, we put forth a number of predictive and
procedural tools to aid in the search and removal of lead infrastructure.
Alongside these statistical and machine learning approaches, we describe our
interactions with government officials in recommending homes for both
inspection and replacement, with a focus on the statistical model that adapts
to incoming information. Finally, in light of discussions about increased
spending on infrastructure development by the federal government, we explore
how our approach generalizes beyond Flint to other municipalities nationwide.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abernethy_J/0/1/0/all/0/1&quot;&gt;Jacob Abernethy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chojnacki_A/0/1/0/all/0/1&quot;&gt;Alex Chojnacki&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Farahi_A/0/1/0/all/0/1&quot;&gt;Arya Farahi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schwartz_E/0/1/0/all/0/1&quot;&gt;Eric Schwartz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Webb_J/0/1/0/all/0/1&quot;&gt;Jared Webb&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.10701">
<title>Empirical Risk Minimization and Stochastic Gradient Descent for Relational Data. (arXiv:1806.10701v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.10701</link>
<description rdf:parseType="Literal">&lt;p&gt;Empirical risk minimization is the principal tool for prediction problems,
but its extension to relational data remains unsolved. We solve this problem
using recent advances in graph sampling theory. We (i) define an empirical risk
for relational data and (ii) obtain stochastic gradients for this risk that are
automatically unbiased. The key ingredient is to consider the method by which
data is sampled from a graph as an explicit component of model design.
Theoretical results establish that the choice of sampling scheme is critical.
By integrating fast implementations of graph sampling schemes with standard
automatic differentiation tools, we are able to solve the risk minimization in
a plug-and-play fashion even on large datasets. We demonstrate empirically that
relational ERM models achieve state-of-the-art results on semi-supervised node
classification tasks. The experiments also confirm the importance of the choice
of sampling scheme.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Veitch_V/0/1/0/all/0/1&quot;&gt;Victor Veitch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Austern_M/0/1/0/all/0/1&quot;&gt;Morgane Austern&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhou_W/0/1/0/all/0/1&quot;&gt;Wenda Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Blei_D/0/1/0/all/0/1&quot;&gt;David M. Blei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Orbanz_P/0/1/0/all/0/1&quot;&gt;Peter Orbanz&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.10714">
<title>TopoReg: A Topological Regularizer for Classifiers. (arXiv:1806.10714v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.10714</link>
<description rdf:parseType="Literal">&lt;p&gt;Regularization plays a crucial role in supervised learning. A successfully
regularized model strikes a balance between a perfect description of the
training data and the ability to generalize to unseen data. Most existing
methods enforce a global regularization in a structure agnostic manner. In this
paper, we initiate a new direction and propose to enforce the structural
simplicity of the classification boundary by regularizing over its topological
complexity. In particular, our measurement of topological complexity
incorporates the importance of topological features (e.g., connected
components, handles, and so on) in a meaningful manner, and provides a direct
control over spurious topological structures. We incorporate the new
measurement as a topological loss in training classifiers. We also propose an
efficient algorithm to compute the gradient. Our method provides a novel way to
topologically simplify the global structure of the model, without having to
sacrifice too much of the flexibility of the model. We demonstrate the
effectiveness of our new topological regularizer on a range of synthetic and
real-world datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1&quot;&gt;Chao Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ni_X/0/1/0/all/0/1&quot;&gt;Xiuyan Ni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bai_Q/0/1/0/all/0/1&quot;&gt;Qinxun Bai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yusu Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.10728">
<title>Hierarchical (Deep) Echo State Networks with Uncertainty Quantification for Spatio-Temporal Forecasting. (arXiv:1806.10728v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.10728</link>
<description rdf:parseType="Literal">&lt;p&gt;Long-lead forecasting for spatio-temporal problems can often entail complex
nonlinear dynamics that are difficult to specify it a priori. Current
statistical methodologies for modeling these processes are often
overparameterized and thus, struggle from a computational perspective. One
potential parsimonious solution to this problem is a method from the dynamical
systems and engineering literature referred to as an echo state network (ESN).
ESN models use so-called reservoir computing to efficiently estimate a
dynamical neural network forecast, model referred to as a recurrent neural
network (RNN). Moreover, so-called deep models have recently been shown to be
successful at predicting high-dimensional complex nonlinear processes. These
same traits can be used to characterize many spatio-temporal processes. Here we
introduce a deep ensemble ESN (D-EESN) model. Through the use of an ensemble
framework, this model is able to generate forecasts that are accompanied by
uncertainty estimates. After introducing the D-EESN, we then develop a
hierarchical Bayesian implementation. We use a general hierarchical Bayesian
framework that accommodates non-Gaussian data types and multiple levels of
uncertainties. The proposed methodology is first applied to a data set
simulated from a novel non-Gaussian multiscale Lorenz-96 dynamical system
simulation model and then to a long-lead United States (U.S.) soil moisture
forecasting application.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+McDermott_P/0/1/0/all/0/1&quot;&gt;Patrick L. McDermott&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wikle_C/0/1/0/all/0/1&quot;&gt;Christopher K. Wikle&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.10736">
<title>Risk-averse estimation, an axiomatic approach to inference, and Wallace-Freeman without MML. (arXiv:1806.10736v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.10736</link>
<description rdf:parseType="Literal">&lt;p&gt;We define a new class of Bayesian point estimators, which we refer to as
risk-averse estimators. We then use this definition to formulate several axioms
that we claim to be natural requirements for good inference procedures, and
show that for two classes of estimation problems the axioms uniquely
characterise an estimator. Namely, for estimation problems with a discrete
hypothesis space, we show that the axioms lead to the MAP estimate, whereas for
well-behaved, purely continuous estimation problems the axioms lead to the
Wallace-Freeman estimate.
&lt;/p&gt;
&lt;p&gt;Interestingly, this combined use of MAP and Wallace-Freeman estimation
reflects the common practice in the Minimum Message Length (MML) community, but
there these two estimators are used as approximations for the
information-theoretic Strict MML estimator, whereas we derive them exactly, not
as approximations, and do so with no use of encoding or information theory.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Brand_M/0/1/0/all/0/1&quot;&gt;Michael Brand&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.10745">
<title>Contextual bandits with surrogate losses: Margin bounds and efficient algorithms. (arXiv:1806.10745v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.10745</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce a new family of margin-based regret guarantees for adversarial
contextual bandit learning. Our results are based on multiclass surrogate
losses. Using the ramp loss, we derive a universal margin-based regret bound in
terms of the sequential metric entropy for a benchmark class of real-valued
regression functions. The new margin bound serves as a complete contextual
bandit analogue of the classical margin bound from statistical learning. The
result applies to large nonparametric classes, improving on the best known
results for Lipschitz contextual bandits (Cesa-Bianchi et al., 2017) and, as a
special case, generalizes the dimension-independent Banditron regret bound
(Kakade et al., 2008) to arbitrary linear classes with smooth norms.
&lt;/p&gt;
&lt;p&gt;On the algorithmic side, we use the hinge loss to derive an efficient
algorithm with a $\sqrt{dT}$-type mistake bound against benchmark policies
induced by $d$-dimensional regression functions. This provides the first hinge
loss-based solution to the open problem of Abernethy and Rakhlin (2009). With
an additional i.i.d. assumption we give a simple oracle-efficient algorithm
whose regret matches our generic metric entropy-based bound for sufficiently
complex nonparametric classes.
&lt;/p&gt;
&lt;p&gt;Under realizability assumptions our results also yield classical regret
bounds.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Foster_D/0/1/0/all/0/1&quot;&gt;Dylan J. Foster&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Krishnamurthy_A/0/1/0/all/0/1&quot;&gt;Akshay Krishnamurthy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.10773">
<title>Successive Convex Approximation Algorithms for Sparse Signal Estimation with Nonconvex Regularizations. (arXiv:1806.10773v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.10773</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we propose a successive convex approximation framework for
sparse optimization where the nonsmooth regularization function in the
objective function is nonconvex and it can be written as the difference of two
convex functions. The proposed framework is based on a nontrivial combination
of the majorization-minimization framework and the successive convex
approximation framework proposed in literature for a convex regularization
function. The proposed framework has several attractive features, namely, i)
flexibility, as different choices of the approximate function lead to different
type of algorithms; ii) fast convergence, as the problem structure can be
better exploited by a proper choice of the approximate function and the
stepsize is calculated by the line search; iii) low complexity, as the
approximate function is convex and the line search scheme is carried out over a
differentiable function; iv) guaranteed convergence to a stationary point. We
demonstrate these features by two example applications in subspace learning,
namely, the network anomaly detection problem and the sparse subspace
clustering problem. Customizing the proposed framework by adopting the
best-response type approximation, we obtain soft-thresholding with exact line
search algorithms for which all elements of the unknown parameter are updated
in parallel according to closed-form expressions. The attractive features of
the proposed algorithms are illustrated numerically.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1&quot;&gt;Yang Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pesavento_M/0/1/0/all/0/1&quot;&gt;Marius Pesavento&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chatzinotas_S/0/1/0/all/0/1&quot;&gt;Symeon Chatzinotas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ottersten_B/0/1/0/all/0/1&quot;&gt;Bj&amp;#xf6;rn Ottersten&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.10861">
<title>Feature Selection for Unsupervised Domain Adaptation using Optimal Transport. (arXiv:1806.10861v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.10861</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we propose a new feature selection method for unsupervised
domain adaptation based on the emerging optimal transportation theory. We build
upon a recent theoretical analysis of optimal transport in domain adaptation
and show that it can directly suggest a feature selection procedure leveraging
the shift between the domains. Based on this, we propose a novel algorithm that
aims to sort features by their similarity across the source and target domains,
where the order is obtained by analyzing the coupling matrix representing the
solution of the proposed optimal transportation problem. We evaluate our method
on a well-known benchmark data set and illustrate its capability of selecting
correlated features leading to better classification performances. Furthermore,
we show that the proposed algorithm can be used as a pre-processing step for
existing domain adaptation techniques ensuring an important speed-up in terms
of the computational time while maintaining comparable results. Finally, we
validate our algorithm on clinical imaging databases for computer-aided
diagnosis task with promising results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gautheron_L/0/1/0/all/0/1&quot;&gt;L&amp;#xe9;o Gautheron&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Redko_I/0/1/0/all/0/1&quot;&gt;Ievgen Redko&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lartizien_C/0/1/0/all/0/1&quot;&gt;Carole Lartizien&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.10873">
<title>Spatiotemporal Prediction of Ambulance Demand using Gaussian Process Regression. (arXiv:1806.10873v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.10873</link>
<description rdf:parseType="Literal">&lt;p&gt;Accurately predicting when and where ambulance call-outs occur can reduce
response times and ensure the patient receives urgent care sooner. Here we
present a novel method for ambulance demand prediction using Gaussian process
regression (GPR) in time and geographic space. The method exhibits superior
accuracy to MEDIC, a method which has been used in industry. The use of GPR has
additional benefits such as the quantification of uncertainty with each
prediction, the choice of kernel functions to encode prior knowledge and the
ability to capture spatial correlation. Measures to increase the utility of GPR
in the current context, with large training sets and a Poisson-distributed
output, are outlined.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Nabarro_S/0/1/0/all/0/1&quot;&gt;Seth Nabarro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Fletcher_T/0/1/0/all/0/1&quot;&gt;Tristan Fletcher&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Shawe_Taylor_J/0/1/0/all/0/1&quot;&gt;John Shawe-Taylor&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.10897">
<title>Deep learning in business analytics and operations research: Models, applications and managerial implications. (arXiv:1806.10897v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.10897</link>
<description rdf:parseType="Literal">&lt;p&gt;Business analytics refers to methods and practices that create value through
data for individuals, firms, and organizations. This field is currently
experiencing a radical shift due to the advent of deep learning: deep neural
networks promise improvements in prediction performance as compared to models
from traditional machine learning. However, our research into the existing body
of literature reveals a scarcity of research works utilizing deep learning in
our discipline. Accordingly, the objectives of this work are as follows: (1) we
motivate why researchers and practitioners from business analytics should
utilize deep neural networks and review potential use cases, necessary
requirements, and benefits. (2) We investigate the added value to operations
research in different case studies with real data from entrepreneurial
undertakings. All such cases demonstrate a higher prediction performance in
comparison to traditional machine learning and thus direct value gains. (3) We
provide guidelines and implications for researchers, managers and practitioners
in operations research who want to advance their capabilities for business
analytics with regard to deep learning. (4) We finally discuss directions for
future research in the field of business analytics.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kraus_M/0/1/0/all/0/1&quot;&gt;Mathias Kraus&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feuerriegel_S/0/1/0/all/0/1&quot;&gt;Stefan Feuerriegel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oztekin_A/0/1/0/all/0/1&quot;&gt;Asil Oztekin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.11006">
<title>Learning Implicit Generative Models with the Method of Learned Moments. (arXiv:1806.11006v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.11006</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a method of moments (MoM) algorithm for training large-scale
implicit generative models. Moment estimation in this setting encounters two
problems: it is often difficult to define the millions of moments needed to
learn the model parameters, and it is hard to determine which properties are
useful when specifying moments. To address the first issue, we introduce a
moment network, and define the moments as the network&apos;s hidden units and the
gradient of the network&apos;s output with the respect to its parameters. To tackle
the second problem, we use asymptotic theory to highlight desiderata for
moments -- namely they should minimize the asymptotic variance of estimated
model parameters -- and introduce an objective to learn better moments. The
sequence of objectives created by this Method of Learned Moments (MoLM) can
train high-quality neural image samplers. On CIFAR-10, we demonstrate that
MoLM-trained generators achieve significantly higher Inception Scores and lower
Frechet Inception Distances than those trained with gradient
penalty-regularized and spectrally-normalized adversarial objectives. These
generators also achieve nearly perfect Multi-Scale Structural Similarity Scores
on CelebA, and can create high-quality samples of 128x128 images.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ravuri_S/0/1/0/all/0/1&quot;&gt;Suman Ravuri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mohamed_S/0/1/0/all/0/1&quot;&gt;Shakir Mohamed&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rosca_M/0/1/0/all/0/1&quot;&gt;Mihaela Rosca&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vinyals_O/0/1/0/all/0/1&quot;&gt;Oriol Vinyals&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.11015">
<title>Bayesian optimization of the PC algorithm for learning Gaussian Bayesian networks. (arXiv:1806.11015v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.11015</link>
<description rdf:parseType="Literal">&lt;p&gt;The PC algorithm is a popular method for learning the structure of Gaussian
Bayesian networks. It carries out statistical tests to determine absent edges
in the network. It is hence governed by two parameters: (i) The type of test,
and (ii) its significance level. These parameters are usually set to values
recommended by an expert. Nevertheless, such an approach can suffer from human
bias, leading to suboptimal reconstruction results. In this paper we consider a
more principled approach for choosing these parameters in an automatic way. For
this we optimize a reconstruction score evaluated on a set of different
Gaussian Bayesian networks. This objective is expensive to evaluate and lacks a
closed-form expression, which means that Bayesian optimization (BO) is a
natural choice. BO methods use a model to guide the search and are hence able
to exploit smoothness properties of the objective surface. We show that the
parameters found by a BO method outperform those found by a random search
strategy and the expert recommendation. Importantly, we have found that an
often overlooked statistical test provides the best over-all reconstruction
results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cordoba_I/0/1/0/all/0/1&quot;&gt;Irene C&amp;#xf3;rdoba&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garrido_Merchan_E/0/1/0/all/0/1&quot;&gt;Eduardo C. Garrido-Merch&amp;#xe1;n&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hernandez_Lobato_D/0/1/0/all/0/1&quot;&gt;Daniel Hern&amp;#xe1;ndez-Lobato&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bielza_C/0/1/0/all/0/1&quot;&gt;Concha Bielza&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Larranaga_P/0/1/0/all/0/1&quot;&gt;Pedro Larra&amp;#xf1;aga&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.11027">
<title>A Simple Stochastic Variance Reduced Algorithm with Fast Convergence Rates. (arXiv:1806.11027v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.11027</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent years have witnessed exciting progress in the study of stochastic
variance reduced gradient methods (e.g., SVRG, SAGA), their accelerated
variants (e.g, Katyusha) and their extensions in many different settings (e.g.,
online, sparse, asynchronous, distributed). Among them, accelerated methods
enjoy improved convergence rates but have complex coupling structures, which
makes them hard to be extended to more settings (e.g., sparse and asynchronous)
due to the existence of perturbation. In this paper, we introduce a simple
stochastic variance reduced algorithm (MiG), which enjoys the best-known
convergence rates for both strongly convex and non-strongly convex problems.
Moreover, we also present its efficient sparse and asynchronous variants, and
theoretically analyze its convergence rates in these settings. Finally,
extensive experiments for various machine learning problems such as logistic
regression are given to illustrate the practical improvement in both serial and
asynchronous settings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_K/0/1/0/all/0/1&quot;&gt;Kaiwen Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shang_F/0/1/0/all/0/1&quot;&gt;Fanhua Shang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_J/0/1/0/all/0/1&quot;&gt;James Cheng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.11096">
<title>Recovering Trees with Convex Clustering. (arXiv:1806.11096v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.11096</link>
<description rdf:parseType="Literal">&lt;p&gt;Convex clustering refers, for given $\left\{x_1, \dots, x_n\right\} \subset
\Real^p$, to the minimization of \begin{eqnarray*} u(\gamma) &amp;amp; = &amp;amp;
\underset{u_1, \dots, u_n }{\arg\min}\;\sum_{i=1}^{n}{\lVert x_i - u_i
\rVert^2} + \gamma \sum_{i,j=1}^{n}{w_{ij} \lVert u_i - u_j\rVert},\\
\end{eqnarray*} where $w_{ij} \geq 0$ is an affinity that quantifies the
similarity between $x_i$ and $x_j$. We prove that if the affinities $w_{ij}$
reflect a tree structure in the $\left\{x_1, \dots, x_n\right\}$, then the
convex clustering solution path reconstructs the tree exactly. The main
technical ingredient implies the following combinatorial byproduct: for every
set $\left\{x_1, \dots, x_n \right\} \subset \Real^p$ of $n \geq 2$ distinct
points, there exist at least $n/6$ points with the property that for any of
these points $x$ there is a unit vector $v \in \Real^p$ such that, when viewed
from $x$, `most&apos; points lie in the direction $v$ \begin{eqnarray*}
\frac{1}{n-1}\sum_{i=1 \atop x_i \neq x}^{n}{ \left\langle \frac{x_i -
x}{\lVert x_i - x \rVert}, v \right\rangle} &amp;amp; \geq &amp;amp; \frac{1}{4}.
\end{eqnarray*}
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chi_E/0/1/0/all/0/1&quot;&gt;Eric C. Chi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Steinerberger_S/0/1/0/all/0/1&quot;&gt;Stefan Steinerberger&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1605.01656">
<title>A Tight Bound of Hard Thresholding. (arXiv:1605.01656v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1605.01656</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper is concerned with the hard thresholding operator which sets all
but the $k$ largest absolute elements of a vector to zero. We establish a {\em
tight} bound to quantitatively characterize the deviation of the thresholded
solution from a given signal. Our theoretical result is universal in the sense
that it holds for all choices of parameters, and the underlying analysis
depends only on fundamental arguments in mathematical optimization. We discuss
the implications for two domains:
&lt;/p&gt;
&lt;p&gt;Compressed Sensing. On account of the crucial estimate, we bridge the
connection between the restricted isometry property (RIP) and the sparsity
parameter for a vast volume of hard thresholding based algorithms, which
renders an improvement on the RIP condition especially when the true sparsity
is unknown. This suggests that in essence, many more kinds of sensing matrices
or fewer measurements are admissible for the data acquisition procedure.
&lt;/p&gt;
&lt;p&gt;Machine Learning. In terms of large-scale machine learning, a significant yet
challenging problem is learning accurate sparse models in an efficient manner.
In stark contrast to prior work that attempted the $\ell_1$-relaxation for
promoting sparsity, we present a novel stochastic algorithm which performs hard
thresholding in each iteration, hence ensuring such parsimonious solutions.
Equipped with the developed bound, we prove the {\em global linear convergence}
for a number of prevalent statistical models under mild assumptions, even
though the problem turns out to be non-convex.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Shen_J/0/1/0/all/0/1&quot;&gt;Jie Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Li_P/0/1/0/all/0/1&quot;&gt;Ping Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1610.00768">
<title>Technical Report on the CleverHans v2.1.0 Adversarial Examples Library. (arXiv:1610.00768v6 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1610.00768</link>
<description rdf:parseType="Literal">&lt;p&gt;CleverHans is a software library that provides standardized reference
implementations of adversarial example construction techniques and adversarial
training. The library may be used to develop more robust machine learning
models and to provide standardized benchmarks of models&apos; performance in the
adversarial setting. Benchmarks constructed without a standardized
implementation of adversarial example construction are not comparable to each
other, because a good result may indicate a robust model or it may merely
indicate a weak implementation of the adversarial example construction
procedure.
&lt;/p&gt;
&lt;p&gt;This technical report is structured as follows. Section 1 provides an
overview of adversarial examples in machine learning and of the CleverHans
software. Section 2 presents the core functionalities of the library: namely
the attacks based on adversarial examples and defenses to improve the
robustness of machine learning models to these attacks. Section 3 describes how
to report benchmark results using the library. Section 4 describes the
versioning system.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Papernot_N/0/1/0/all/0/1&quot;&gt;Nicolas Papernot&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Faghri_F/0/1/0/all/0/1&quot;&gt;Fartash Faghri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Carlini_N/0/1/0/all/0/1&quot;&gt;Nicholas Carlini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goodfellow_I/0/1/0/all/0/1&quot;&gt;Ian Goodfellow&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feinman_R/0/1/0/all/0/1&quot;&gt;Reuben Feinman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kurakin_A/0/1/0/all/0/1&quot;&gt;Alexey Kurakin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_C/0/1/0/all/0/1&quot;&gt;Cihang Xie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sharma_Y/0/1/0/all/0/1&quot;&gt;Yash Sharma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brown_T/0/1/0/all/0/1&quot;&gt;Tom Brown&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roy_A/0/1/0/all/0/1&quot;&gt;Aurko Roy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Matyasko_A/0/1/0/all/0/1&quot;&gt;Alexander Matyasko&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Behzadan_V/0/1/0/all/0/1&quot;&gt;Vahid Behzadan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hambardzumyan_K/0/1/0/all/0/1&quot;&gt;Karen Hambardzumyan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1&quot;&gt;Zhishuai Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Juang_Y/0/1/0/all/0/1&quot;&gt;Yi-Lin Juang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Zhi Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sheatsley_R/0/1/0/all/0/1&quot;&gt;Ryan Sheatsley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garg_A/0/1/0/all/0/1&quot;&gt;Abhibhav Garg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Uesato_J/0/1/0/all/0/1&quot;&gt;Jonathan Uesato&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gierke_W/0/1/0/all/0/1&quot;&gt;Willi Gierke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1&quot;&gt;Yinpeng Dong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Berthelot_D/0/1/0/all/0/1&quot;&gt;David Berthelot&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hendricks_P/0/1/0/all/0/1&quot;&gt;Paul Hendricks&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rauber_J/0/1/0/all/0/1&quot;&gt;Jonas Rauber&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Long_R/0/1/0/all/0/1&quot;&gt;Rujun Long&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+McDaniel_P/0/1/0/all/0/1&quot;&gt;Patrick McDaniel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1701.08142">
<title>Modelling Preference Data with the Wallenius Distribution. (arXiv:1701.08142v5 [stat.ME] UPDATED)</title>
<link>http://arxiv.org/abs/1701.08142</link>
<description rdf:parseType="Literal">&lt;p&gt;The Wallenius distribution is a generalisation of the Hypergeometric
distribution where weights are assigned to balls of different colours. This
naturally defines a model for ranking categories which can be used for
classification purposes. Since, in general, the resulting likelihood is not
analytically available, we adopt an approximate Bayesian computational (ABC)
approach for estimating the importance of the categories. We illustrate the
performance of the estimation procedure on simulated datasets. Finally, we use
the new model for analysing two datasets about movies ratings and Italian
academic statisticians&apos; journal preferences. The latter is a novel dataset
collected by the authors.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Grazian_C/0/1/0/all/0/1&quot;&gt;Clara Grazian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Leisen_F/0/1/0/all/0/1&quot;&gt;Fabrizio Leisen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Liseo_B/0/1/0/all/0/1&quot;&gt;Brunero Liseo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1703.07047">
<title>High-Resolution Breast Cancer Screening with Multi-View Deep Convolutional Neural Networks. (arXiv:1703.07047v3 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1703.07047</link>
<description rdf:parseType="Literal">&lt;p&gt;Advances in deep learning for natural images have prompted a surge of
interest in applying similar techniques to medical images. The majority of the
initial attempts focused on replacing the input of a deep convolutional neural
network with a medical image, which does not take into consideration the
fundamental differences between these two types of images. Specifically, fine
details are necessary for detection in medical images, unlike in natural images
where coarse structures matter most. This difference makes it inadequate to use
the existing network architectures developed for natural images, because they
work on heavily downscaled images to reduce the memory requirements. This hides
details necessary to make accurate predictions. Additionally, a single exam in
medical imaging often comes with a set of views which must be fused in order to
reach a correct conclusion. In our work, we propose to use a multi-view deep
convolutional neural network that handles a set of high-resolution medical
images. We evaluate it on large-scale mammography-based breast cancer screening
(BI-RADS prediction) using 886,000 images. We focus on investigating the impact
of the training set size and image size on the prediction accuracy. Our results
highlight that performance increases with the size of training set, and that
the best performance can only be achieved using the original resolution. In the
reader study, performed on a random subset of the test set, we confirmed the
efficacy of our model, which achieved performance comparable to a committee of
radiologists when presented with the same data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Geras_K/0/1/0/all/0/1&quot;&gt;Krzysztof J. Geras&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wolfson_S/0/1/0/all/0/1&quot;&gt;Stacey Wolfson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1&quot;&gt;Yiqiu Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_N/0/1/0/all/0/1&quot;&gt;Nan Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1&quot;&gt;S. Gene Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_E/0/1/0/all/0/1&quot;&gt;Eric Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Heacock_L/0/1/0/all/0/1&quot;&gt;Laura Heacock&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Parikh_U/0/1/0/all/0/1&quot;&gt;Ujas Parikh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moy_L/0/1/0/all/0/1&quot;&gt;Linda Moy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cho_K/0/1/0/all/0/1&quot;&gt;Kyunghyun Cho&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1705.07967">
<title>Consistencies and inconsistencies between model selection and link prediction in networks. (arXiv:1705.07967v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1705.07967</link>
<description rdf:parseType="Literal">&lt;p&gt;A principled approach to understand network structures is to formulate
generative models. Given a collection of models, however, an outstanding key
task is to determine which one provides a more accurate description of the
network at hand, discounting statistical fluctuations. This problem can be
approached using two principled criteria that at first may seem equivalent:
selecting the most plausible model in terms of its posterior probability; or
selecting the model with the highest predictive performance in terms of
identifying missing links. Here we show that while these two approaches yield
consistent results in most of cases, there are also notable instances where
they do not, that is, where the most plausible model is not the most
predictive. We show that in the latter case the improvement of predictive
performance can in fact lead to overfitting both in artificial and empirical
settings. Furthermore, we show that, in general, the predictive performance is
higher when we average over collections of models that are individually less
plausible, than when we consider only the single most plausible model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Valles_Catala_T/0/1/0/all/0/1&quot;&gt;Toni Vall&amp;#xe8;s-Catal&amp;#xe0;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Peixoto_T/0/1/0/all/0/1&quot;&gt;Tiago P. Peixoto&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Guimera_R/0/1/0/all/0/1&quot;&gt;Roger Guimer&amp;#xe0;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sales_Pardo_M/0/1/0/all/0/1&quot;&gt;Marta Sales-Pardo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.05501">
<title>Constrained Bayesian Optimization for Automatic Chemical Design. (arXiv:1709.05501v5 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1709.05501</link>
<description rdf:parseType="Literal">&lt;p&gt;Automatic Chemical Design provides a framework for generating novel molecules
with optimized molecular properties. The current model suffers from the
pathology that it tends to produce invalid molecular structures. By
reformulating the search procedure as a constrained Bayesian optimization
problem, we showcase improvements in both the validity and quality of the
generated molecules. We demonstrate that the model consistently produces novel
molecules ranking above the 90th percentile of the distribution over training
set scores across a range of objective functions. Importantly, our method
suffers no degradation in the complexity or the diversity of the generated
molecules.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Griffiths_R/0/1/0/all/0/1&quot;&gt;Ryan-Rhys Griffiths&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hernandez_Lobato_J/0/1/0/all/0/1&quot;&gt;Jos&amp;#xe9; Miguel Hern&amp;#xe1;ndez-Lobato&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.11053">
<title>A Multi-Horizon Quantile Recurrent Forecaster. (arXiv:1711.11053v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1711.11053</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a framework for general probabilistic multi-step time series
regression. Specifically, we exploit the expressiveness and temporal nature of
Sequence-to-Sequence Neural Networks (e.g. recurrent and convolutional
structures), the nonparametric nature of Quantile Regression and the efficiency
of Direct Multi-Horizon Forecasting. A new training scheme,
*forking-sequences*, is designed for sequential nets to boost stability and
performance. We show that the approach accommodates both temporal and static
covariates, learning across multiple related series, shifting seasonality,
future planned event spikes and cold-starts in real life large-scale
forecasting. The performance of the framework is demonstrated in an application
to predict the future demand of items sold on Amazon.com, and in a public
probabilistic forecasting competition to predict electricity price and load.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wen_R/0/1/0/all/0/1&quot;&gt;Ruofeng Wen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Torkkola_K/0/1/0/all/0/1&quot;&gt;Kari Torkkola&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Narayanaswamy_B/0/1/0/all/0/1&quot;&gt;Balakrishnan Narayanaswamy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Madeka_D/0/1/0/all/0/1&quot;&gt;Dhruv Madeka&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.04755">
<title>Exponential convergence of testing error for stochastic gradient methods. (arXiv:1712.04755v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1712.04755</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider binary classification problems with positive definite kernels and
square loss, and study the convergence rates of stochastic gradient methods. We
show that while the excess testing loss (squared loss) converges slowly to zero
as the number of observations (and thus iterations) goes to infinity, the
testing error (classification error) converges exponentially fast if low-noise
conditions are assumed.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pillaud_Vivien_L/0/1/0/all/0/1&quot;&gt;Loucas Pillaud-Vivien&lt;/a&gt; (SIERRA), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rudi_A/0/1/0/all/0/1&quot;&gt;Alessandro Rudi&lt;/a&gt; (SIERRA), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bach_F/0/1/0/all/0/1&quot;&gt;Francis Bach&lt;/a&gt; (SIERRA)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04712">
<title>Attention-based Deep Multiple Instance Learning. (arXiv:1802.04712v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1802.04712</link>
<description rdf:parseType="Literal">&lt;p&gt;Multiple instance learning (MIL) is a variation of supervised learning where
a single class label is assigned to a bag of instances. In this paper, we state
the MIL problem as learning the Bernoulli distribution of the bag label where
the bag label probability is fully parameterized by neural networks.
Furthermore, we propose a neural network-based permutation-invariant
aggregation operator that corresponds to the attention mechanism. Notably, an
application of the proposed attention-based operator provides insight into the
contribution of each instance to the bag label. We show empirically that our
approach achieves comparable performance to the best MIL methods on benchmark
MIL datasets and it outperforms other methods on a MNIST-based MIL dataset and
two real-life histopathology datasets without sacrificing interpretability.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ilse_M/0/1/0/all/0/1&quot;&gt;Maximilian Ilse&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tomczak_J/0/1/0/all/0/1&quot;&gt;Jakub M. Tomczak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Welling_M/0/1/0/all/0/1&quot;&gt;Max Welling&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04826">
<title>Leveraging the Exact Likelihood of Deep Latent Variable Models. (arXiv:1802.04826v4 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1802.04826</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep latent variable models (DLVMs) combine the approximation abilities of
deep neural networks and the statistical foundations of generative models.
Variational methods are commonly used for inference; however, the exact
likelihood of these models has been largely overlooked. The purpose of this
work is to study the general properties of this quantity and to show how they
can be leveraged in practice. We focus on important inferential problems that
rely on the likelihood: estimation and missing data imputation. First, we
investigate maximum likelihood estimation for DLVMs: in particular, we show
that most unconstrained models used for continuous data have an unbounded
likelihood function. This problematic behaviour is demonstrated to be a source
of mode collapse. We also show how to ensure the existence of maximum
likelihood estimates, and draw useful connections with nonparametric mixture
models. Finally, we describe an algorithm for missing data imputation using the
exact conditional likelihood of a deep latent variable model. On several data
sets, our algorithm consistently and significantly outperforms the usual
imputation scheme used for DLVMs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mattei_P/0/1/0/all/0/1&quot;&gt;Pierre-Alexandre Mattei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Frellsen_J/0/1/0/all/0/1&quot;&gt;Jes Frellsen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.08130">
<title>Sparse Travel Time Estimation from Streaming Data. (arXiv:1804.08130v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1804.08130</link>
<description rdf:parseType="Literal">&lt;p&gt;We address two shortcomings in online travel time estimation methods for
congested urban traffic. The first shortcoming is related to the determination
of the number of mixture modes, which can change dynamically, within day and
from day to day. The second shortcoming is the wide-spread use of Gaussian
probability densities as mixture components. Gaussian densities fail to capture
the positive skew in travel time distributions and, consequently, large numbers
of mixture components are needed for reasonable fitting accuracy when applied
as mixture components. They also assign positive probabilities to negative
travel times. To address these issues, this paper develops a mixture
distribution with asymmetric components supported on the positive numbers. We
use sparse estimation techniques to ensure parsimonious models. Specifically,
we derive a novel generalization of Gamma mixture densities using
Mittag-Leffler functions, which provides enhanced fitting flexibility and
improved parsimony. In order to accommodate within-day variability and allow
for online implementation of the proposed methodology (i.e., fast computations
on streaming travel time data), we introduce a recursive algorithm which
efficiently updates the fitted distribution whenever new data become available.
Experimental results using real-world travel time data illustrate the efficacy
of the proposed methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Jabari_S/0/1/0/all/0/1&quot;&gt;Saif Eddin Jabari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Freris_N/0/1/0/all/0/1&quot;&gt;Nikolaos M. Freris&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Dilip_D/0/1/0/all/0/1&quot;&gt;Deepthi Mary Dilip&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.10074">
<title>Statistical Optimality of Stochastic Gradient Descent on Hard Learning Problems through Multiple Passes. (arXiv:1805.10074v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.10074</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider stochastic gradient descent (SGD) for least-squares regression
with potentially several passes over the data. While several passes have been
widely reported to perform practically better in terms of predictive
performance on unseen data, the existing theoretical analysis of SGD suggests
that a single pass is statistically optimal. While this is true for
low-dimensional easy problems, we show that for hard problems, multiple passes
lead to statistically optimal predictions while single pass does not; we also
show that in these hard models, the optimal number of passes over the data
increases with sample size. In order to define the notion of hardness and show
that our predictive performances are optimal, we consider potentially
infinite-dimensional models and notions typically associated to kernel methods,
namely, the decay of eigenvalues of the covariance matrix of the features and
the complexity of the optimal predictor as measured through the covariance
matrix. We illustrate our results on synthetic experiments with non-linear
kernel methods and on a classical benchmark with a linear model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pillaud_Vivien_L/0/1/0/all/0/1&quot;&gt;Loucas Pillaud-Vivien&lt;/a&gt; (SIERRA, PSL), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rudi_A/0/1/0/all/0/1&quot;&gt;Alessandro Rudi&lt;/a&gt; (SIERRA, PSL), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bach_F/0/1/0/all/0/1&quot;&gt;Francis Bach&lt;/a&gt; (SIERRA, PSL)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.01240">
<title>Diffeomorphic Learning. (arXiv:1806.01240v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1806.01240</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce in this paper a learning paradigm in which the training data is
transformed by a diffeomorphic transformation before prediction. The learning
algorithm minimizes a cost function evaluating the prediction error on the
training set penalized by the distance between the diffeomorphism and the
identity. The approach borrows ideas from shape analysis, in the way
diffeomorphisms are estimated for shape and image alignment, and brings them in
a previously unexplored setting, estimating, in particular diffeomorphisms in
much larger dimensions. After introducing the concept and describing a learning
algorithm, we present diverse applications, mostly with synthetic examples,
demonstrating the potential of the approach, as well as some of its current
room for improvement.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Younes_L/0/1/0/all/0/1&quot;&gt;Laurent Younes&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.01830">
<title>Relational Deep Reinforcement Learning. (arXiv:1806.01830v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1806.01830</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce an approach for deep reinforcement learning (RL) that improves
upon the efficiency, generalization capacity, and interpretability of
conventional approaches through structured perception and relational reasoning.
It uses self-attention to iteratively reason about the relations between
entities in a scene and to guide a model-free policy. Our results show that in
a novel navigation and planning task called Box-World, our agent finds
interpretable solutions that improve upon baselines in terms of sample
complexity, ability to generalize to more complex scenes than experienced
during training, and overall performance. In the StarCraft II Learning
Environment, our agent achieves state-of-the-art performance on six mini-games
-- surpassing human grandmaster performance on four. By considering
architectural inductive biases, our work opens new directions for overcoming
important, but stubborn, challenges in deep RL.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zambaldi_V/0/1/0/all/0/1&quot;&gt;Vinicius Zambaldi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Raposo_D/0/1/0/all/0/1&quot;&gt;David Raposo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Santoro_A/0/1/0/all/0/1&quot;&gt;Adam Santoro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bapst_V/0/1/0/all/0/1&quot;&gt;Victor Bapst&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yujia Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Babuschkin_I/0/1/0/all/0/1&quot;&gt;Igor Babuschkin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tuyls_K/0/1/0/all/0/1&quot;&gt;Karl Tuyls&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Reichert_D/0/1/0/all/0/1&quot;&gt;David Reichert&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lillicrap_T/0/1/0/all/0/1&quot;&gt;Timothy Lillicrap&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lockhart_E/0/1/0/all/0/1&quot;&gt;Edward Lockhart&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shanahan_M/0/1/0/all/0/1&quot;&gt;Murray Shanahan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Langston_V/0/1/0/all/0/1&quot;&gt;Victoria Langston&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pascanu_R/0/1/0/all/0/1&quot;&gt;Razvan Pascanu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Botvinick_M/0/1/0/all/0/1&quot;&gt;Matthew Botvinick&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vinyals_O/0/1/0/all/0/1&quot;&gt;Oriol Vinyals&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Battaglia_P/0/1/0/all/0/1&quot;&gt;Peter Battaglia&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.03836">
<title>Bayesian Model-Agnostic Meta-Learning. (arXiv:1806.03836v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1806.03836</link>
<description rdf:parseType="Literal">&lt;p&gt;Learning to infer Bayesian posterior from a few-shot dataset is an important
step towards robust meta-learning due to the model uncertainty inherent in the
problem. In this paper, we propose a novel Bayesian model-agnostic
meta-learning method. The proposed method combines scalable gradient-based
meta-learning with nonparametric variational inference in a principled
probabilistic framework. During fast adaptation, the method is capable of
learning complex uncertainty structure beyond a point estimate or a simple
Gaussian approximation. In addition, a robust Bayesian meta-update mechanism
with a new meta-loss prevents overfitting during meta-update. Remaining an
efficient gradient-based meta-learner, the method is also model-agnostic and
simple to implement. Experiment results show the accuracy and robustness of the
proposed method in various tasks: sinusoidal regression, image classification,
active learning, and reinforcement learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_T/0/1/0/all/0/1&quot;&gt;Taesup Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yoon_J/0/1/0/all/0/1&quot;&gt;Jaesik Yoon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dia_O/0/1/0/all/0/1&quot;&gt;Ousmane Dia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1&quot;&gt;Sungwoong Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bengio_Y/0/1/0/all/0/1&quot;&gt;Yoshua Bengio&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ahn_S/0/1/0/all/0/1&quot;&gt;Sungjin Ahn&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.07506">
<title>A Simple Fusion of Deep and Shallow Learning for Acoustic Scene Classification. (arXiv:1806.07506v2 [cs.SD] UPDATED)</title>
<link>http://arxiv.org/abs/1806.07506</link>
<description rdf:parseType="Literal">&lt;p&gt;In the past, Acoustic Scene Classification systems have been based on hand
crafting audio features that are input to a classifier. Nowadays, the common
trend is to adopt data driven techniques, e.g., deep learning, where audio
representations are learned from data. In this paper, we propose a system that
consists of a simple fusion of two methods of the aforementioned types: a deep
learning approach where log-scaled mel-spectrograms are input to a
convolutional neural network, and a feature engineering approach, where a
collection of hand-crafted features is input to a gradient boosting machine. We
first show that both methods provide complementary information to some extent.
Then, we use a simple late fusion strategy to combine both methods. We report
classification accuracy of each method individually and the combined system on
the TUT Acoustic Scenes 2017 dataset. The proposed fused system outperforms
each of the individual methods and attains a classification accuracy of 72.8%
on the evaluation set, improving the baseline system by 11.8%.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fonseca_E/0/1/0/all/0/1&quot;&gt;Eduardo Fonseca&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gong_R/0/1/0/all/0/1&quot;&gt;Rong Gong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Serra_X/0/1/0/all/0/1&quot;&gt;Xavier Serra&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.10206">
<title>Deep Feature Factorization For Concept Discovery. (arXiv:1806.10206v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1806.10206</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose Deep Feature Factorization (DFF), a method capable of localizing
similar semantic concepts within an image or a set of images. We use DFF to
gain insight into a deep convolutional neural network&apos;s learned features, where
we detect hierarchical cluster structures in feature space. This is visualized
as heat maps, which highlight semantically matching regions across a set of
images, revealing what the network `perceives&apos; as similar. DFF can also be used
to perform co-segmentation and co-localization, and we report state-of-the-art
results on these tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Collins_E/0/1/0/all/0/1&quot;&gt;Edo Collins&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Achanta_R/0/1/0/all/0/1&quot;&gt;Radhakrishna Achanta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Susstrunk_S/0/1/0/all/0/1&quot;&gt;Sabine S&amp;#xfc;sstrunk&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.10827">
<title>Learning Temporal Structures of Random Patterns. (arXiv:1805.10827v1 [q-bio.NC] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1805.10827</link>
<description rdf:parseType="Literal">&lt;p&gt;A cornerstone of human statistical learning is the ability to extract
temporal regularities / patterns from random sequences. Here we present a
method of computing pattern time statistics with generating functions for
first-order Markov trials and independent Bernoulli trials. We show that the
pattern time statistics cover a wide range of measurements commonly used in
existing studies of both human and machine learning of stochastic processes,
including probability of alternation, temporal correlation between pattern
events, and related variance / risk measures. Moreover, we show that recurrent
processing and event segmentation by pattern overlap may provide a coherent
explanation for the sensitivity of the human brain to the rich statistics and
the latent structures in the learning environment.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Sun_Y/0/1/0/all/0/1&quot;&gt;Yanlong Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Wang_H/0/1/0/all/0/1&quot;&gt;Hongbin Wang&lt;/a&gt;</dc:creator>
</item></rdf:RDF>