<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Boring papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Bad Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-04-04T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.01144"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.01314"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.02328"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.04170"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.01110"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.01193"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.01405"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.01486"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.01508"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.01523"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1610.09372"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1703.04529"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1705.07177"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.00804"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.00056"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.01116"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.01118"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.01119"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.01188"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.01189"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.01221"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.01238"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.01330"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.01466"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.01491"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1708.03845"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.10781"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.08054"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.01587"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08334"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.10515"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.11136"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1804.01144">
<title>Self-Organization and Artificial Life: A Review. (arXiv:1804.01144v1 [nlin.AO])</title>
<link>http://arxiv.org/abs/1804.01144</link>
<description rdf:parseType="Literal">&lt;p&gt;Self-organization has been an important concept within a number of
disciplines, which Artificial Life (ALife) also has heavily utilized since its
inception. The term and its implications, however, are often confusing or
misinterpreted. In this work, we provide a mini-review of self-organization and
its relationship with ALife, aiming at initiating discussions on this important
topic with the interested audience. We first articulate some fundamental
aspects of self-organization, outline its usage, and review its applications to
ALife within its soft, hard, and wet domains. We also provide perspectives for
further research.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/nlin/1/au:+Gershenson_C/0/1/0/all/0/1&quot;&gt;Carlos Gershenson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/nlin/1/au:+Trianni_V/0/1/0/all/0/1&quot;&gt;Vito Trianni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/nlin/1/au:+Werfel_J/0/1/0/all/0/1&quot;&gt;Justin Werfel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/nlin/1/au:+Sayama_H/0/1/0/all/0/1&quot;&gt;Hiroki Sayama&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.01314">
<title>When Hypermutations and Ageing Enable Artificial Immune Systems to Outperform Evolutionary Algorithms. (arXiv:1804.01314v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1804.01314</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a time complexity analysis of the Opt-IA artificial immune system
(AIS). We first highlight the power and limitations of its distinguishing
operators (i.e., hypermutations with mutation potential and ageing) by
analysing them in isolation. Recent work has shown that ageing combined with
local mutations can help escape local optima on a dynamic optimisation
benchmark function. We generalise this result by rigorously proving that,
compared to evolutionary algorithms (EAs), ageing leads to impressive speed-ups
on the standard Cliff benchmark function both when using local and global
mutations. Unless the stop at first constructive mutation (FCM) mechanism is
applied, we show that hypermutations require exponential expected runtime to
optimise any function with a polynomial number of optima. If instead FCM is
used, the expected runtime is at most a linear factor larger than the upper
bound achieved for any random local search algorithm using the artificial
fitness levels method. Nevertheless, we prove that algorithms using
hypermutations can be considerably faster than EAs at escaping local optima. An
analysis of the complete Opt-IA reveals that it is efficient on the previously
considered functions and highlights problems where the use of the full
algorithm is crucial. We complete the picture by presenting a class of
functions for which Opt-IA fails with overwhelming probability while standard
EAs are efficient.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Corus_D/0/1/0/all/0/1&quot;&gt;Dogan Corus&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oliveto_P/0/1/0/all/0/1&quot;&gt;Pietro S. Oliveto&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yazdani_D/0/1/0/all/0/1&quot;&gt;Donya Yazdani&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.02328">
<title>Generative Adversarial Perturbations. (arXiv:1712.02328v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1712.02328</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we propose novel generative models for creating adversarial
examples, slightly perturbed images resembling natural images but maliciously
crafted to fool pre-trained models. We present trainable deep neural networks
for transforming images to adversarial perturbations. Our proposed models can
produce image-agnostic and image-dependent perturbations for both targeted and
non-targeted attacks. We also demonstrate that similar architectures can
achieve impressive results in fooling classification and semantic segmentation
models, obviating the need for hand-crafting attack methods for each task.
Using extensive experiments on challenging high-resolution datasets such as
ImageNet and Cityscapes, we show that our perturbations achieve high fooling
rates with small perturbation norms. Moreover, our attacks are considerably
faster than current iterative methods at inference time.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Poursaeed_O/0/1/0/all/0/1&quot;&gt;Omid Poursaeed&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Katsman_I/0/1/0/all/0/1&quot;&gt;Isay Katsman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_B/0/1/0/all/0/1&quot;&gt;Bicheng Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Belongie_S/0/1/0/all/0/1&quot;&gt;Serge Belongie&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.04170">
<title>Interpretable Policies for Reinforcement Learning by Genetic Programming. (arXiv:1712.04170v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1712.04170</link>
<description rdf:parseType="Literal">&lt;p&gt;The search for interpretable reinforcement learning policies is of high
academic and industrial interest. Especially for industrial systems, domain
experts are more likely to deploy autonomously learned controllers if they are
understandable and convenient to evaluate. Basic algebraic equations are
supposed to meet these requirements, as long as they are restricted to an
adequate complexity. Here we introduce the genetic programming for
reinforcement learning (GPRL) approach based on model-based batch reinforcement
learning and genetic programming, which autonomously learns policy equations
from pre-existing default state-action trajectory samples. GPRL is compared to
a straight-forward method which utilizes genetic programming for symbolic
regression, yielding policies imitating an existing well-performing, but
non-interpretable policy. Experiments on three reinforcement learning
benchmarks, i.e., mountain car, cart-pole balancing, and industrial benchmark,
demonstrate the superiority of our GPRL approach compared to the symbolic
regression method. GPRL is capable of producing well-performing interpretable
reinforcement learning policies from pre-existing default trajectory data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hein_D/0/1/0/all/0/1&quot;&gt;Daniel Hein&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Udluft_S/0/1/0/all/0/1&quot;&gt;Steffen Udluft&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Runkler_T/0/1/0/all/0/1&quot;&gt;Thomas A. Runkler&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.01110">
<title>Unsupervised Geometry-Aware Representation for 3D Human Pose Estimation. (arXiv:1804.01110v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1804.01110</link>
<description rdf:parseType="Literal">&lt;p&gt;Modern 3D human pose estimation techniques rely on deep networks, which
require large amounts of training data. While weakly-supervised methods require
less supervision, by utilizing 2D poses or multi-view imagery without
annotations, they still need a sufficiently large set of samples with 3D
annotations for learning to succeed.
&lt;/p&gt;
&lt;p&gt;In this paper, we propose to overcome this problem by learning a
geometry-aware body representation from multi-view images without annotations.
To this end, we use an encoder-decoder that predicts an image from one
viewpoint given an image from another viewpoint. Because this representation
encodes 3D geometry, using it in a semi-supervised setting makes it easier to
learn a mapping from it to 3D human pose. As evidenced by our experiments, our
approach significantly outperforms fully-supervised methods given the same
amount of labeled data, and improves over other semi-supervised methods while
using as little as 1% of the labeled data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rhodin_H/0/1/0/all/0/1&quot;&gt;Helge Rhodin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Salzmann_M/0/1/0/all/0/1&quot;&gt;Mathieu Salzmann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fua_P/0/1/0/all/0/1&quot;&gt;Pascal Fua&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.01193">
<title>The Logical Essentials of Bayesian Reasoning. (arXiv:1804.01193v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1804.01193</link>
<description rdf:parseType="Literal">&lt;p&gt;This chapter offers an accessible introduction to the channel-based approach
to Bayesian probability theory. This framework rests on algebraic and logical
foundations, inspired by the methodologies of programming language semantics.
It offers a uniform, structured and expressive language for describing Bayesian
phenomena in terms of familiar programming concepts, like channel, predicate
transformation and state transformation. The introduction also covers inference
in Bayesian networks, which will be modelled by a suitable calculus of string
diagrams.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jacobs_B/0/1/0/all/0/1&quot;&gt;Bart Jacobs&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zanasi_F/0/1/0/all/0/1&quot;&gt;Fabio Zanasi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.01405">
<title>R2RML Mappings in OBDA Systems: Enabling Comparison among OBDA Tools. (arXiv:1804.01405v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1804.01405</link>
<description rdf:parseType="Literal">&lt;p&gt;In today&apos;s large enterprises there is a significant increasing trend in the
amount of data that has to be stored and processed. To complicate this scenario
the complexity of organizing and managing a large collection of data,
structured according to a single, unified schema, makes so that there is almost
never a single place where to look to satisfy an information need.
&lt;/p&gt;
&lt;p&gt;The Ontology-Based Data Access (OBDA) paradigm aims at mitigating this
phenomenon by providing to the users of the system a unified and shared
conceptual view of the domain of interest (ontology), while still enabling the
data to be stored in different data sources, which are managed by a relational
database. In an OBDA system the link between the data stored at the sources and
the ontology is provided through a declarative specification given in terms of
a set of mappings.
&lt;/p&gt;
&lt;p&gt;In this work we focus on comparing two of the available systems for OBDA,
namely, Mastro and Ontop, by adopting OBDA specifications based on W3C
recommendations. We first show how support for R2RML mappings has been
integrated in Mastro, which was the last feature missing in order to enable the
system to use specifications based solely on W3C recommendations relevant to
OBDA. We then proceed in performing a comparison between these systems over two
OBDA specifications, the NPD Benchmark and the ACI specification.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Namici_M/0/1/0/all/0/1&quot;&gt;Manuel Namici&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.01486">
<title>Clinical Concept Embeddings Learned from Massive Sources of Medical Data. (arXiv:1804.01486v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1804.01486</link>
<description rdf:parseType="Literal">&lt;p&gt;Word embeddings have emerged as a popular approach to unsupervised learning
of word relationships in machine learning and natural language processing. In
this article, we benchmark two of the most popular algorithms, GloVe and
word2vec, to assess their suitability for capturing medical relationships in
large sources of biomedical data. Leaning on recent theoretical insights, we
provide a unified view of these algorithms and demonstrate how different
sources of data can be combined to construct the largest ever set of embeddings
for 108,477 medical concepts using an insurance claims database of 60 million
members, 20 million clinical notes, and 1.7 million full text biomedical
journal articles. We evaluate our approach, called cui2vec, on a set of
clinically relevant benchmarks and in many instances demonstrate state of the
art performance relative to previous results. Finally, we provide a
downloadable set of pre-trained embeddings for other researchers to use, as
well as an online tool for interactive exploration of the cui2vec embeddings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Beam_A/0/1/0/all/0/1&quot;&gt;Andrew L. Beam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kompa_B/0/1/0/all/0/1&quot;&gt;Benjamin Kompa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fried_I/0/1/0/all/0/1&quot;&gt;Inbar Fried&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Palmer_N/0/1/0/all/0/1&quot;&gt;Nathan P. Palmer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_X/0/1/0/all/0/1&quot;&gt;Xu Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cai_T/0/1/0/all/0/1&quot;&gt;Tianxi Cai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kohane_I/0/1/0/all/0/1&quot;&gt;Isaac S. Kohane&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.01508">
<title>The Tsetlin Machine - A Game Theoretic Bandit Driven Approach to Optimal Pattern Recognition with Propositional Logic. (arXiv:1804.01508v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1804.01508</link>
<description rdf:parseType="Literal">&lt;p&gt;Although simple individually, artificial neurons provide state-of-the-art
performance when interconnected in deep networks. Unknown to many, there exists
an arguably even simpler and more versatile learning mechanism, namely, the
Tsetlin Automaton. Merely by means of a single integer as memory, it learns the
optimal action in stochastic environments. In this paper, we introduce the
Tsetlin Machine, which solves complex pattern recognition problems with
easy-to-interpret propositional formulas, composed by a collective of Tsetlin
Automata. To eliminate the longstanding problem of vanishing signal-to-noise
ratio, the Tsetlin Machine orchestrates the automata using a novel game. Our
theoretical analysis establishes that the Nash equilibria of the game are
aligned with the propositional formulas that provide optimal pattern
recognition accuracy. This translates to learning without local optima, only
global ones. We argue that the Tsetlin Machine finds the propositional formula
that provides optimal accuracy, with probability arbitrarily close to unity. In
four distinct benchmarks, the Tsetlin Machine outperforms both Neural Networks,
SVMs, Random Forests, the Naive Bayes Classifier and Logistic Regression. It
further turns out that the accuracy advantage of the Tsetlin Machine increases
with lack of data. The Tsetlin Machine has a significant computational
performance advantage since both inputs, patterns, and outputs are expressed as
bits, while recognition of patterns relies on bit manipulation. The combination
of accuracy, interpretability, and computational simplicity makes the Tsetlin
Machine a promising tool for a wide range of domains, including safety-critical
medicine. Being the first of its kind, we believe the Tsetlin Machine will
kick-start completely new paths of research, with a potentially significant
impact on the AI field and the applications of AI.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Granmo_O/0/1/0/all/0/1&quot;&gt;Ole-Christoffer Granmo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.01523">
<title>Stochastic Adversarial Video Prediction. (arXiv:1804.01523v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1804.01523</link>
<description rdf:parseType="Literal">&lt;p&gt;Being able to predict what may happen in the future requires an in-depth
understanding of the physical and causal rules that govern the world. A model
that is able to do so has a number of appealing applications, from robotic
planning to representation learning. However, learning to predict raw future
observations, such as frames in a video, is exceedingly challenging -- the
ambiguous nature of the problem can cause a naively designed model to average
together possible futures into a single, blurry prediction. Recently, this has
been addressed by two distinct approaches: (a) latent variational variable
models that explicitly model underlying stochasticity and (b)
adversarially-trained models that aim to produce naturalistic images. However,
a standard latent variable model can struggle to produce realistic results, and
a standard adversarially-trained model underutilizes latent variables and fails
to produce diverse predictions. We show that these distinct methods are in fact
complementary. Combining the two produces predictions that look more realistic
to human raters and better cover the range of possible futures. Our method
outperforms prior and concurrent work in these aspects.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_A/0/1/0/all/0/1&quot;&gt;Alex X. Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1&quot;&gt;Richard Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ebert_F/0/1/0/all/0/1&quot;&gt;Frederik Ebert&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1&quot;&gt;Pieter Abbeel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Finn_C/0/1/0/all/0/1&quot;&gt;Chelsea Finn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1&quot;&gt;Sergey Levine&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1610.09372">
<title>A Projective Simulation Scheme for a Partially-Observable Multi-Agent Game. (arXiv:1610.09372v3 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1610.09372</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce a kind of partial observability to the projective simulation
(PS) learning method via Dirac notation. It is done by adding a projection
operator and an observability parameter to the original formulation of the
efficiency in PS model. Our examples are from invasion toy problem regarding a
multi-agent setting.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kheiri_R/0/1/0/all/0/1&quot;&gt;Rasoul Kheiri&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1703.04529">
<title>Task-based End-to-end Model Learning in Stochastic Optimization. (arXiv:1703.04529v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1703.04529</link>
<description rdf:parseType="Literal">&lt;p&gt;With the increasing popularity of machine learning techniques, it has become
common to see prediction algorithms operating within some larger process.
However, the criteria by which we train these algorithms often differ from the
ultimate criteria on which we evaluate them. This paper proposes an end-to-end
approach for learning probabilistic machine learning models in a manner that
directly captures the ultimate task-based objective for which they will be
used, within the context of stochastic programming. We present three
experimental evaluations of the proposed approach: a classical inventory stock
problem, a real-world electrical grid scheduling task, and a real-world energy
storage arbitrage task. We show that the proposed approach can outperform both
traditional modeling and purely black-box policy optimization approaches in
these applications.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Donti_P/0/1/0/all/0/1&quot;&gt;Priya L. Donti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Amos_B/0/1/0/all/0/1&quot;&gt;Brandon Amos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kolter_J/0/1/0/all/0/1&quot;&gt;J. Zico Kolter&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1705.07177">
<title>Model-Based Planning with Discrete and Continuous Actions. (arXiv:1705.07177v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1705.07177</link>
<description rdf:parseType="Literal">&lt;p&gt;Action planning using learned and differentiable forward models of the world
is a general approach which has a number of desirable properties, including
improved sample complexity over model-free RL methods, reuse of learned models
across different tasks, and the ability to perform efficient gradient-based
optimization in continuous action spaces. However, this approach does not apply
straightforwardly when the action space is discrete. In this work, we show that
it is in fact possible to effectively perform planning via backprop in discrete
action spaces, using a simple paramaterization of the actions vectors on the
simplex combined with input noise when training the forward model. Our
experiments show that this approach can match or outperform model-free RL and
discrete planning methods on gridworld navigation tasks in terms of performance
and/or planning time while using limited environment interactions, and can
additionally be used to perform model-based control in a challenging new task
where the action space combines discrete and continuous actions. We furthermore
propose a policy distillation approach which yields a fast policy network which
can be used at inference time, removing the need for an iterative planning
procedure.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Henaff_M/0/1/0/all/0/1&quot;&gt;Mikael Henaff&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Whitney_W/0/1/0/all/0/1&quot;&gt;William F. Whitney&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+LeCun_Y/0/1/0/all/0/1&quot;&gt;Yann LeCun&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.00804">
<title>Framework for evaluation of sound event detection in web videos. (arXiv:1711.00804v2 [cs.SD] UPDATED)</title>
<link>http://arxiv.org/abs/1711.00804</link>
<description rdf:parseType="Literal">&lt;p&gt;The largest source of sound events is web videos. Most videos lack sound
event labels at segment level, however, a significant number of them do respond
to text queries, from a match found using metadata by search engines. In this
paper we explore the extent to which a search query can be used as the true
label for detection of sound events in videos. We present a framework for
large-scale sound event recognition on web videos. The framework crawls videos
using search queries corresponding to 78 sound event labels drawn from three
datasets. The datasets are used to train three classifiers, and we obtain a
prediction on 3.7 million web video segments. We evaluated performance using
the search query as true label and compare it with human labeling. Both types
of ground truth exhibited close performance, to within 10%, and similar
performance trend with increasing number of evaluated segments. Hence, our
experiments show potential for using search query as a preliminary true label
for sound event recognition in web videos.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Badlani_R/0/1/0/all/0/1&quot;&gt;Rohan Badlani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shah_A/0/1/0/all/0/1&quot;&gt;Ankit Shah&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Elizalde_B/0/1/0/all/0/1&quot;&gt;Benjamin Elizalde&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kumar_A/0/1/0/all/0/1&quot;&gt;Anurag Kumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Raj_B/0/1/0/all/0/1&quot;&gt;Bhiksha Raj&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.00056">
<title>f-Divergence constrained policy improvement. (arXiv:1801.00056v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1801.00056</link>
<description rdf:parseType="Literal">&lt;p&gt;To ensure stability of learning, state-of-the-art generalized policy
iteration algorithms augment the policy improvement step with a trust region
constraint bounding the information loss. The size of the trust region is
commonly determined by the Kullback-Leibler (KL) divergence, which not only
captures the notion of distance well but also yields closed-form solutions. In
this paper, we consider a more general class of f-divergences and derive the
corresponding policy update rules. The generic solution is expressed through
the derivative of the convex conjugate function to f and includes the KL
solution as a special case. Within the class of f-divergences, we further focus
on a one-parameter family of $\alpha$-divergences to study effects of the
choice of divergence on policy improvement. Previously known as well as new
policy updates emerge for different values of $\alpha$. We show that every type
of policy update comes with a compatible policy evaluation resulting from the
chosen f-divergence. Interestingly, the mean-squared Bellman error minimization
is closely related to policy evaluation with the Pearson $\chi^2$-divergence
penalty, while the KL divergence results in the soft-max policy update and a
log-sum-exp critic. We carry out asymptotic analysis of the solutions for
different values of $\alpha$ and demonstrate the effects of using different
divergence functions on a multi-armed bandit problem and on common standard
reinforcement learning problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Belousov_B/0/1/0/all/0/1&quot;&gt;Boris Belousov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peters_J/0/1/0/all/0/1&quot;&gt;Jan Peters&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.01116">
<title>Renewal Monte Carlo: Renewal theory based reinforcement learning. (arXiv:1804.01116v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1804.01116</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we present an online reinforcement learning algorithm, called
Renewal Monte Carlo (RMC), for infinite horizon Markov decision processes with
a designated start state. RMC is a Monte Carlo algorithm and retains the
advantages of Monte Carlo methods including low bias, simplicity, and ease of
implementation while, at the same time, circumvents their key drawbacks of high
variance and delayed (end of episode) updates. The key ideas behind RMC are as
follows. First, under any reasonable policy, the reward process is ergodic. So,
by renewal theory, the performance of a policy is equal to the ratio of
expected discounted reward to the expected discounted time over a regenerative
cycle. Second, by carefully examining the expression for performance gradient,
we propose a stochastic approximation algorithm that only requires estimates of
the expected discounted reward and discounted time over a regenerative cycle
and their gradients. We propose two unbiased estimators for evaluating
performance gradients---a likelihood ratio based estimator and a simultaneous
perturbation based estimator---and show that for both estimators, RMC converges
to a locally optimal policy. We generalize the RMC algorithm to post-decision
state models and also present a variant that converges faster to an
approximately optimal policy. We conclude by presenting numerical experiments
on a randomly generated MDP, event-triggered communication, and inventory
management.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Subramanian_J/0/1/0/all/0/1&quot;&gt;Jayakumar Subramanian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mahajan_A/0/1/0/all/0/1&quot;&gt;Aditya Mahajan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.01118">
<title>Synthesizing Programs for Images using Reinforced Adversarial Learning. (arXiv:1804.01118v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1804.01118</link>
<description rdf:parseType="Literal">&lt;p&gt;Advances in deep generative networks have led to impressive results in recent
years. Nevertheless, such models can often waste their capacity on the minutiae
of datasets, presumably due to weak inductive biases in their decoders. This is
where graphics engines may come in handy since they abstract away low-level
details and represent images as high-level programs. Current methods that
combine deep learning and renderers are limited by hand-crafted likelihood or
distance functions, a need for large amounts of supervision, or difficulties in
scaling their inference algorithms to richer datasets. To mitigate these
issues, we present SPIRAL, an adversarially trained agent that generates a
program which is executed by a graphics engine to interpret and sample images.
The goal of this agent is to fool a discriminator network that distinguishes
between real and rendered data, trained with a distributed reinforcement
learning setup without any supervision. A surprising finding is that using the
discriminator&apos;s output as a reward signal is the key to allow the agent to make
meaningful progress at matching the desired output rendering. To the best of
our knowledge, this is the first demonstration of an end-to-end, unsupervised
and adversarial inverse graphics agent on challenging real world (MNIST,
Omniglot, CelebA) and synthetic 3D datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ganin_Y/0/1/0/all/0/1&quot;&gt;Yaroslav Ganin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kulkarni_T/0/1/0/all/0/1&quot;&gt;Tejas Kulkarni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Babuschkin_I/0/1/0/all/0/1&quot;&gt;Igor Babuschkin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Eslami_S/0/1/0/all/0/1&quot;&gt;S.M. Ali Eslami&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vinyals_O/0/1/0/all/0/1&quot;&gt;Oriol Vinyals&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.01119">
<title>Feature selection in weakly coherent matrices. (arXiv:1804.01119v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1804.01119</link>
<description rdf:parseType="Literal">&lt;p&gt;A problem of paramount importance in both pure (Restricted Invertibility
problem) and applied mathematics (Feature extraction) is the one of selecting a
submatrix of a given matrix, such that this submatrix has its smallest singular
value above a specified level. Such problems can be addressed using
perturbation analysis. In this paper, we propose a perturbation bound for the
smallest singular value of a given matrix after appending a column, under the
assumption that its initial coherence is not large, and we use this bound to
derive a fast algorithm for feature extraction.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chretien_S/0/1/0/all/0/1&quot;&gt;Stephane Chretien&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ho_Z/0/1/0/all/0/1&quot;&gt;Zhen-Wai Olivier Ho&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.01188">
<title>Hospital Readmission Prediction - Applying Hierarchical Sparsity Norms for Interpretable Models. (arXiv:1804.01188v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1804.01188</link>
<description rdf:parseType="Literal">&lt;p&gt;Hospital readmissions have become one of the key measures of healthcare
quality. Preventable readmissions have been identified as one of the primary
targets for reducing costs and improving healthcare delivery. However, most
data driven studies for understanding readmissions have produced black box
classification and predictive models with moderate performance, which precludes
them from being used effectively within the decision support systems in the
hospitals. In this paper we present an application of structured
sparsity-inducing norms for predicting readmission risk for patients based on
their disease history and demographics. Most existing studies have focused on
hospital utilization, test results, etc., to assign a readmission label to each
episode of hospitalization. However, we focus on assigning a readmission risk
label to a patient based on their disease history. Our emphasis is on
interpreting the models to improve the understanding of the readmission
problem. To achieve this, we exploit the domain induced hierarchical structure
available for the disease codes which are the features for the classification
algorithm. We use a tree based sparsity-inducing regularization strategy that
explicitly uses the domain hierarchy. The resulting model not only outperforms
standard regularization procedures but is also highly sparse and interpretable.
We analyze the model and identify several significant factors that have an
effect on readmission risk. Some of these factors conform to existing beliefs,
e.g., impact of surgical complications and infections during hospital stay.
Other factors, such as the impact of mental disorder and substance abuse on
readmission, provide empirical evidence for several pre-existing but unverified
hypotheses. The analysis also reveals previously undiscovered connections such
as the influence of socioeconomic factors like lack of housing and
malnutrition.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1&quot;&gt;Jialiang Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hewner_S/0/1/0/all/0/1&quot;&gt;Sharon Hewner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chandola_V/0/1/0/all/0/1&quot;&gt;Varun Chandola&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.01189">
<title>Real-Time Prediction of the Duration of Distribution System Outages. (arXiv:1804.01189v1 [cs.SY])</title>
<link>http://arxiv.org/abs/1804.01189</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper addresses the problem of predicting duration of unplanned power
outages, using historical outage records to train a series of neural network
predictors. The initial duration prediction is made based on environmental
factors, and it is updated based on incoming field reports using natural
language processing to automatically analyze the text. Experiments using 15
years of outage records show good initial results and improved performance
leveraging text. Case studies show that the language processing identifies
phrases that point to outage causes and repair steps.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jaech_A/0/1/0/all/0/1&quot;&gt;Aaron Jaech&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1&quot;&gt;Baosen Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ostendorf_M/0/1/0/all/0/1&quot;&gt;Mari Ostendorf&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kirschen_D/0/1/0/all/0/1&quot;&gt;Daniel S. Kirschen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.01221">
<title>Tight Query Complexity Lower Bounds for PCA via Finite Sample Deformed Wigner Law. (arXiv:1804.01221v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1804.01221</link>
<description rdf:parseType="Literal">&lt;p&gt;We prove a \emph{query complexity} lower bound for approximating the top $r$
dimensional eigenspace of a matrix. We consider an oracle model where, given a
symmetric matrix $\mathbf{M} \in \mathbb{R}^{d \times d}$, an algorithm
$\mathsf{Alg}$ is allowed to make $\mathsf{T}$ exact queries of the form
$\mathsf{w}^{(i)} = \mathbf{M} \mathsf{v}^{(i)}$ for $i$ in
$\{1,...,\mathsf{T}\}$, where $\mathsf{v}^{(i)}$ is drawn from a distribution
which depends arbitrarily on the past queries and measurements
$\{\mathsf{v}^{(j)},\mathsf{w}^{(i)}\}_{1 \le j \le i-1}$. We show that for
every $\mathtt{gap} \in (0,1/2]$, there exists a distribution over matrices
$\mathbf{M}$ for which 1) $\mathrm{gap}_r(\mathbf{M}) = \Omega(\mathtt{gap})$
(where $\mathrm{gap}_r(\mathbf{M})$ is the normalized gap between the $r$ and
$r+1$-st largest-magnitude eigenvector of $\mathbf{M}$), and 2) any algorithm
$\mathsf{Alg}$ which takes fewer than $\mathrm{const} \times \frac{r \log
d}{\sqrt{\mathtt{gap}}}$ queries fails (with overwhelming probability) to
identity a matrix $\widehat{\mathsf{V}} \in \mathbb{R}^{d \times r}$ with
orthonormal columns for which $\langle \widehat{\mathsf{V}}, \mathbf{M}
\widehat{\mathsf{V}}\rangle \ge (1 - \mathrm{const} \times
\mathtt{gap})\sum_{i=1}^r \lambda_i(\mathbf{M})$. Our bound requires only that
$d$ is a small polynomial in $1/\mathtt{gap}$ and $r$, and matches the upper
bounds of Musco and Musco &apos;15. Moreover, it establishes a strict separation
between convex optimization and \emph{randomized}, &quot;strict-saddle&quot; non-convex
optimization of which PCA is a canonical example: in the former, first-order
methods can have dimension-free iteration complexity, whereas in PCA, the
iteration complexity of gradient-based methods must necessarily grow with the
dimension.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Simchowitz_M/0/1/0/all/0/1&quot;&gt;Max Simchowitz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alaoui_A/0/1/0/all/0/1&quot;&gt;Ahmed El Alaoui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Recht_B/0/1/0/all/0/1&quot;&gt;Benjamin Recht&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.01238">
<title>Information Maximizing Exploration with a Latent Dynamics Model. (arXiv:1804.01238v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1804.01238</link>
<description rdf:parseType="Literal">&lt;p&gt;All reinforcement learning algorithms must handle the trade-off between
exploration and exploitation. Many state-of-the-art deep reinforcement learning
methods use noise in the action selection, such as Gaussian noise in policy
gradient methods or $\epsilon$-greedy in Q-learning. While these methods are
appealing due to their simplicity, they do not explore the state space in a
methodical manner. We present an approach that uses a model to derive reward
bonuses as a means of intrinsic motivation to improve model-free reinforcement
learning. A key insight of our approach is that this dynamics model can be
learned in the latent feature space of a value function, representing the
dynamics of the agent and the environment. This method is both theoretically
grounded and computationally advantageous, permitting the efficient use of
Bayesian information-theoretic methods in high-dimensional state spaces. We
evaluate our method on several continuous control tasks, focusing on improving
exploration.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barron_T/0/1/0/all/0/1&quot;&gt;Trevor Barron&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Obst_O/0/1/0/all/0/1&quot;&gt;Oliver Obst&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Amor_H/0/1/0/all/0/1&quot;&gt;Heni Ben Amor&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.01330">
<title>An Imprecise Probabilistic Estimator for the Transition Rate Matrix of a Continuous-Time Markov Chain. (arXiv:1804.01330v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1804.01330</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the problem of estimating the transition rate matrix of a
continuous-time Markov chain from a finite-duration realisation of this
process. We approach this problem in an imprecise probabilistic framework,
using a set of prior distributions on the unknown transition rate matrix. The
resulting estimator is a set of transition rate matrices that, for reasons of
conjugacy, is easy to find. To determine the hyperparameters for our set of
priors, we reconsider the problem in discrete time, where we can use the
well-known Imprecise Dirichlet Model. In particular, we show how the limit of
the resulting discrete-time estimators is a continuous-time estimator. It
corresponds to a specific choice of hyperparameters and has an exceptionally
simple closed-form expression.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Krak_T/0/1/0/all/0/1&quot;&gt;Thomas Krak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Erreygers_A/0/1/0/all/0/1&quot;&gt;Alexander Erreygers&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bock_J/0/1/0/all/0/1&quot;&gt;Jasper De Bock&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.01466">
<title>Gaussian Process Subset Scanning for Anomalous Pattern Detection in Non-iid Data. (arXiv:1804.01466v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1804.01466</link>
<description rdf:parseType="Literal">&lt;p&gt;Identifying anomalous patterns in real-world data is essential for
understanding where, when, and how systems deviate from their expected
dynamics. Yet methods that separately consider the anomalousness of each
individual data point have low detection power for subtle, emerging
irregularities. Additionally, recent detection techniques based on subset
scanning make strong independence assumptions and suffer degraded performance
in correlated data. We introduce methods for identifying anomalous patterns in
non-iid data by combining Gaussian processes with novel log-likelihood ratio
statistic and subset scanning techniques. Our approaches are powerful,
interpretable, and can integrate information across multiple data streams. We
illustrate their performance on numeric simulations and three open source
spatiotemporal datasets of opioid overdose deaths, 311 calls, and storm
reports.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Herlands_W/0/1/0/all/0/1&quot;&gt;William Herlands&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+McFowland_E/0/1/0/all/0/1&quot;&gt;Edward McFowland III&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wilson_A/0/1/0/all/0/1&quot;&gt;Andrew Gordon Wilson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Neill_D/0/1/0/all/0/1&quot;&gt;Daniel B. Neill&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.01491">
<title>Online Multi-Label Classification: A Label Compression Method. (arXiv:1804.01491v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1804.01491</link>
<description rdf:parseType="Literal">&lt;p&gt;Many modern applications deal with multi-label data, such as functional
categorizations of genes, image labeling and text categorization.
Classification of such data with a large number of labels and latent
dependencies among them is a challenging task, and it becomes even more
challenging when the data is received online and in chunks. Many of the current
multi-label classification methods require a lot of time and memory, which make
them infeasible for practical real-world applications. In this paper, we
propose a fast linear label space dimension reduction method that transforms
the labels into a reduced encoded space and trains models on the obtained
pseudo labels. Additionally, it provides an analytical method to update the
decoding matrix which maps the labels into the original space and is used
during the test phase. Experimental results show the effectiveness of this
approach in terms of running times and the prediction performance over
different measures.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ahmadi_Z/0/1/0/all/0/1&quot;&gt;Zahra Ahmadi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kramer_S/0/1/0/all/0/1&quot;&gt;Stefan Kramer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1708.03845">
<title>Quantifying multivariate redundancy with maximum entropy decompositions of mutual information. (arXiv:1708.03845v2 [physics.data-an] UPDATED)</title>
<link>http://arxiv.org/abs/1708.03845</link>
<description rdf:parseType="Literal">&lt;p&gt;Williams and Beer (2010) proposed a nonnegative mutual information
decomposition, based on the construction of redundancy lattices, which allows
separating the information that a set of variables contains about a target
variable into nonnegative components interpretable as the unique information of
some variables not provided by others as well as redundant and synergistic
components. However, the definition of multivariate measures of redundancy that
comply with nonnegativity and conform to certain axioms that capture
conceptually desirable properties of redundancy has proven to be elusive. We
here present a procedure to determine nonnegative multivariate redundancy
measures, within the maximum entropy framework. In particular, we generalize
existing bivariate maximum entropy measures of redundancy and unique
information, defining measures of the redundant information that a group of
variables has about a target, and of the unique redundant information that a
group of variables has about a target that is not redundant with information
from another group. The two key ingredients for this approach are: First, the
identification of a type of constraints on entropy maximization that allows
isolating components of redundancy and unique redundancy by mirroring them to
synergy components. Second, the construction of rooted tree-based
decompositions of the mutual information, which conform to the axioms of the
redundancy lattice by the local implementation at each tree node of binary
unfoldings of the information using hierarchically related maximum entropy
constraints. Altogether, the proposed measures quantify the different
multivariate redundancy contributions of a nonnegative mutual information
decomposition consistent with the redundancy lattice.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Chicharro_D/0/1/0/all/0/1&quot;&gt;Daniel Chicharro&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.10781">
<title>Stochastic variance reduced multiplicative update for nonnegative matrix factorization. (arXiv:1710.10781v2 [cs.NA] UPDATED)</title>
<link>http://arxiv.org/abs/1710.10781</link>
<description rdf:parseType="Literal">&lt;p&gt;Nonnegative matrix factorization (NMF), a dimensionality reduction and factor
analysis method, is a special case in which factor matrices have low-rank
nonnegative constraints. Considering the stochastic learning in NMF, we
specifically address the multiplicative update (MU) rule, which is the most
popular, but which has slow convergence property. This present paper introduces
on the stochastic MU rule a variance-reduced technique of stochastic gradient.
Numerical comparisons suggest that our proposed algorithms robustly outperform
state-of-the-art algorithms across different synthetic and real-world datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kasai_H/0/1/0/all/0/1&quot;&gt;Hiroyuki Kasai&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.08054">
<title>Generative Adversarial Positive-Unlabelled Learning. (arXiv:1711.08054v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1711.08054</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work, we consider the task of classifying binary positive-unlabeled
(PU) data. The existing discriminative learning based PU models attempt to seek
an optimal reweighting strategy for U data, so that a decent decision boundary
can be found. However, given limited P data, the conventional PU models tend to
suffer from overfitting when adapted to very flexible deep neural networks. In
contrast, we are the first to innovate a totally new paradigm to attack the
binary PU task, from perspective of generative learning by leveraging the
powerful generative adversarial networks (GAN). Our generative
positive-unlabeled (GenPU) framework incorporates an array of discriminators
and generators that are endowed with different roles in simultaneously
producing positive and negative realistic samples. We provide theoretical
analysis to justify that, at equilibrium, GenPU is capable of recovering both
positive and negative data distributions. Moreover, we show GenPU is
generalizable and closely related to the semi-supervised classification. Given
rather limited P data, experiments on both synthetic and real-world dataset
demonstrate the effectiveness of our proposed framework. With infinite
realistic and diverse sample streams generated from GenPU, a very flexible
classifier can then be trained using deep neural networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hou_M/0/1/0/all/0/1&quot;&gt;Ming Hou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chaib_draa_B/0/1/0/all/0/1&quot;&gt;Brahim Chaib-draa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1&quot;&gt;Chao Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_Q/0/1/0/all/0/1&quot;&gt;Qibin Zhao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.01587">
<title>SpectralNet: Spectral Clustering using Deep Neural Networks. (arXiv:1801.01587v6 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1801.01587</link>
<description rdf:parseType="Literal">&lt;p&gt;Spectral clustering is a leading and popular technique in unsupervised data
analysis. Two of its major limitations are scalability and generalization of
the spectral embedding (i.e., out-of-sample-extension). In this paper we
introduce a deep learning approach to spectral clustering that overcomes the
above shortcomings. Our network, which we call SpectralNet, learns a map that
embeds input data points into the eigenspace of their associated graph
Laplacian matrix and subsequently clusters them. We train SpectralNet using a
procedure that involves constrained stochastic optimization. Stochastic
optimization allows it to scale to large datasets, while the constraints, which
are implemented using a special-purpose output layer, allow us to keep the
network output orthogonal. Moreover, the map learned by SpectralNet naturally
generalizes the spectral embedding to unseen data points. To further improve
the quality of the clustering, we replace the standard pairwise Gaussian
affinities with affinities leaned from unlabeled data using a Siamese network.
Additional improvement can be achieved by applying the network to code
representations produced, e.g., by standard autoencoders. Our end-to-end
learning procedure is fully unsupervised. In addition, we apply VC dimension
theory to derive a lower bound on the size of SpectralNet. State-of-the-art
clustering results are reported on the Reuters dataset. Our implementation is
publicly available at https://github.com/kstant0725/SpectralNet .
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Shaham_U/0/1/0/all/0/1&quot;&gt;Uri Shaham&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Stanton_K/0/1/0/all/0/1&quot;&gt;Kelly Stanton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Li_H/0/1/0/all/0/1&quot;&gt;Henry Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Nadler_B/0/1/0/all/0/1&quot;&gt;Boaz Nadler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Basri_R/0/1/0/all/0/1&quot;&gt;Ronen Basri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kluger_Y/0/1/0/all/0/1&quot;&gt;Yuval Kluger&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08334">
<title>Learning Without Mixing: Towards A Sharp Analysis of Linear System Identification. (arXiv:1802.08334v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1802.08334</link>
<description rdf:parseType="Literal">&lt;p&gt;We prove that the ordinary least-squares (OLS) estimator attains nearly
minimax optimal performance for the identification of linear dynamical systems
from a single observed trajectory. Our upper bound relies on a generalization
of Mendelson&apos;s small-ball method to dependent data, eschewing the use of
standard mixing-time arguments. Our lower bounds reveal that these upper bounds
match up to logarithmic factors. In particular, we capture the correct
signal-to-noise behavior of the problem, showing that more unstable linear
systems are easier to estimate. This behavior is qualitatively different from
arguments which rely on mixing-time calculations that suggest that unstable
systems are more difficult to estimate. We generalize our technique to provide
bounds for a more general class of linear response time-series.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Simchowitz_M/0/1/0/all/0/1&quot;&gt;Max Simchowitz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mania_H/0/1/0/all/0/1&quot;&gt;Horia Mania&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tu_S/0/1/0/all/0/1&quot;&gt;Stephen Tu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jordan_M/0/1/0/all/0/1&quot;&gt;Michael I. Jordan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Recht_B/0/1/0/all/0/1&quot;&gt;Benjamin Recht&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.10515">
<title>Stochastic Dynamic Programming Heuristics for Influence Maximization-Revenue Optimization. (arXiv:1802.10515v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1802.10515</link>
<description rdf:parseType="Literal">&lt;p&gt;The well-known Influence Maximization (IM) problem has been actively studied
by researchers over the past decade, with emphasis on marketing and social
networks. Existing research have obtained solutions to the IM problem by
obtaining the influence spread and utilizing the property of submodularity.
This paper is based on a novel approach to the IM problem geared towards
optimizing clicks and consequently revenue within anOnline Social Network
(OSN). Our approach diverts from existing approaches by adopting a novel,
decision-making perspective through implementing Stochastic Dynamic Programming
(SDP). Thus, we define a new problem Influence Maximization-Revenue
Optimization (IM-RO) and propose SDP as a method in which this problem can be
solved. The SDP method has lucrative gains for an advertiser in terms of
optimizing clicks and generating revenue however, one drawback to the method is
its associated &quot;curse of dimensionality&quot; particularly for problems involving a
large state space. Thus, we introduce the Lawrence Degree Heuristic (LDH),
Adaptive Hill-Climbing (AHC) and Multistage Particle Swarm Optimization (MPSO)
heuristics as methods which are orders of magnitude faster than the SDP method
whilst achieving near-optimal results. Through a comparative analysis on
various synthetic and real-world networks we present the AHC and LDH as
heuristics well suited to to the IM-RO problem in terms of their accuracy,
running times and scalability under ideal model parameters. In this paper we
present a compelling survey on the SDP method as a practical and lucrative
method for spreading information and optimizing revenue within the context of
OSNs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lawrence_T/0/1/0/all/0/1&quot;&gt;Trisha Lawrence&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.11136">
<title>Conformal Prediction in Learning Under Privileged Information Paradigm with Applications in Drug Discovery. (arXiv:1803.11136v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1803.11136</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper explores conformal prediction in the learning under privileged
information (LUPI) paradigm. We use the SVM+ realization of LUPI in an
inductive conformal predictor, and apply it to the MNIST benchmark dataset and
three datasets in drug discovery. The results show that using privileged
information produces valid models and improves efficiency compared to standard
SVM, however the improvement varies between the tested datasets and is not
substantial in the drug discovery applications. More importantly, using SVM+ in
a conformal prediction framework enables valid prediction intervals at
specified significance levels.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gauraha_N/0/1/0/all/0/1&quot;&gt;Niharika Gauraha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Carlsson_L/0/1/0/all/0/1&quot;&gt;Lars Carlsson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Spjuth_O/0/1/0/all/0/1&quot;&gt;Ola Spjuth&lt;/a&gt;</dc:creator>
</item></rdf:RDF>