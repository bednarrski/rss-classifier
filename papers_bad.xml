<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Boring papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Bad Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-07-16T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.05222"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.05636"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.05948"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.05464"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.05517"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.05527"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.05579"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.05609"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.05720"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.05853"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1704.02906"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.05077"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.03058"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.04134"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.06500"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08882"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09476"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11088"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.04458"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.05328"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.05343"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.05351"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.05411"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.05459"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.05515"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.05561"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.05666"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.05800"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.05827"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.05832"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.05836"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.05926"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.05935"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.05981"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1601.03764"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1605.01559"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1610.06447"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1702.00748"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1706.03922"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.03800"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06455"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09902"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.04204"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.08472"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.06576"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.01600"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.01771"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04594"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.04222"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.05077"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1807.05222">
<title>Towards Modeling the Interaction of Spatial-Associative Neural Network Representations for Multisensory Perception. (arXiv:1807.05222v1 [q-bio.NC])</title>
<link>http://arxiv.org/abs/1807.05222</link>
<description rdf:parseType="Literal">&lt;p&gt;Our daily perceptual experience is driven by different neural mechanisms that
yield multisensory interaction as the interplay between exogenous stimuli and
endogenous expectations. While the interaction of multisensory cues according
to their spatiotemporal properties and the formation of multisensory
feature-based representations have been widely studied, the interaction of
spatial-associative neural representations has received considerably less
attention. In this paper, we propose a neural network architecture that models
the interaction of spatial-associative representations to perform causal
inference of audiovisual stimuli. We investigate the spatial alignment of
exogenous audiovisual stimuli modulated by associative congruence. In the
spatial layer, topographically arranged networks account for the interaction of
audiovisual input in terms of population codes. In the associative layer,
congruent audiovisual representations are obtained via the experience-driven
development of feature-based associations. Levels of congruency are obtained as
a by-product of the neurodynamics of self-organizing networks, where the amount
of neural activation triggered by the input can be expressed via a nonlinear
distance function. Our novel proposal is that activity-driven levels of
congruency can be used as top-down modulatory projections to spatially
distributed representations of sensory input, e.g. semantically related
audiovisual pairs will yield a higher level of integration than unrelated
pairs. Furthermore, levels of neural response in unimodal layers may be seen as
sensory reliability for the dynamic weighting of crossmodal cues. We describe a
series of planned experiments to validate our model in the tasks of
multisensory interaction on the basis of semantic congruence and unimodal cue
reliability.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Parisi_G/0/1/0/all/0/1&quot;&gt;German I. Parisi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Tong_J/0/1/0/all/0/1&quot;&gt;Jonathan Tong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Barros_P/0/1/0/all/0/1&quot;&gt;Pablo Barros&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Roder_B/0/1/0/all/0/1&quot;&gt;Brigitte R&amp;#xf6;der&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Wermter_S/0/1/0/all/0/1&quot;&gt;Stefan Wermter&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.05636">
<title>Cross Pixel Optical Flow Similarity for Self-Supervised Learning. (arXiv:1807.05636v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1807.05636</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a novel method for learning convolutional neural image
representations without manual supervision. We use motion cues in the form of
optical flow, to supervise representations of static images. The obvious
approach of training a network to predict flow from a single image can be
needlessly difficult due to intrinsic ambiguities in this prediction task. We
instead propose a much simpler learning goal: embed pixels such that the
similarity between their embeddings matches that between their optical flow
vectors. At test time, the learned deep network can be used without access to
video or flow information and transferred to tasks such as image
classification, detection, and segmentation. Our method, which significantly
simplifies previous attempts at using motion for self-supervision, achieves
state-of-the-art results in self-supervision using motion cues, competitive
results for self-supervision in general, and is overall state of the art in
self-supervised pretraining for semantic image segmentation, as demonstrated on
standard benchmarks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mahendran_A/0/1/0/all/0/1&quot;&gt;Aravindh Mahendran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Thewlis_J/0/1/0/all/0/1&quot;&gt;James Thewlis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vedaldi_A/0/1/0/all/0/1&quot;&gt;Andrea Vedaldi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.05948">
<title>Evolving Differentiable Gene Regulatory Networks. (arXiv:1807.05948v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1807.05948</link>
<description rdf:parseType="Literal">&lt;p&gt;Over the past twenty years, artificial Gene Regulatory Networks (GRNs) have
shown their capacity to solve real-world problems in various domains such as
agent control, signal processing and artificial life experiments. They have
also benefited from new evolutionary approaches and improvements to dynamic
which have increased their optimization efficiency. In this paper, we present
an additional step toward their usability in machine learning applications. We
detail an GPU-based implementation of differentiable GRNs, allowing for local
optimization of GRN architectures with stochastic gradient descent (SGD). Using
a standard machine learning dataset, we evaluate the ways in which evolution
and SGD can be combined to further GRN optimization. We compare these
approaches with neural network models trained by SGD and with support vector
machines.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wilson_D/0/1/0/all/0/1&quot;&gt;Dennis G Wilson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Harrington_K/0/1/0/all/0/1&quot;&gt;Kyle Harrington&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cussat_Blanc_S/0/1/0/all/0/1&quot;&gt;Sylvain Cussat-Blanc&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luga_H/0/1/0/all/0/1&quot;&gt;Herv&amp;#xe9; Luga&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.05464">
<title>Tractable Querying and Learning in Hybrid Domains via Sum-Product Networks. (arXiv:1807.05464v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.05464</link>
<description rdf:parseType="Literal">&lt;p&gt;Probabilistic representations, such as Bayesian and Markov networks, are
fundamental to much of statistical machine learning. Thus, learning
probabilistic representations directly from data is a deep challenge, the main
computational bottleneck being inference that is intractable. Tractable
learning is a powerful new paradigm that attempts to learn distributions that
support efficient probabilistic querying. By leveraging local structure,
representations such as sum-product networks (SPNs) can capture high tree-width
models with many hidden layers, essentially a deep architecture, while still
admitting a range of probabilistic queries to be computable in time polynomial
in the network size. The leaf nodes in SPNs, from which more intricate mixtures
are formed, are tractable univariate distributions, and so the literature has
focused on Bernoulli and Gaussian random variables. This is clearly a
restriction for handling mixed discrete-continuous data, especially if the
continuous features are generated from non-parametric and non-Gaussian
distribution families. In this work, we present a framework that systematically
integrates SPN structure learning with weighted model integration, a recently
introduced computational abstraction for performing inference in hybrid
domains, by means of piecewise polynomial approximations of density functions
of arbitrary shape. Our framework is instantiated by exploiting the notion of
propositional abstractions, thus minimally interfering with the SPN structure
learning module, and supports a powerful query interface for conditioning on
interval constraints. Our empirical results show that our approach is
effective, and allows a study of the trade off between the granularity of the
learned model and its predictive power.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bueff_A/0/1/0/all/0/1&quot;&gt;Andreas Bueff&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Speichert_S/0/1/0/all/0/1&quot;&gt;Stefanie Speichert&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Belle_V/0/1/0/all/0/1&quot;&gt;Vaishak Belle&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.05517">
<title>Boosting Combinatorial Problem Modeling with Machine Learning. (arXiv:1807.05517v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1807.05517</link>
<description rdf:parseType="Literal">&lt;p&gt;In the past few years, the area of Machine Learning (ML) has witnessed
tremendous advancements, becoming a pervasive technology in a wide range of
applications. One area that can significantly benefit from the use of ML is
Combinatorial Optimization. The three pillars of constraint satisfaction and
optimization problem solving, i.e., modeling, search, and optimization, can
exploit ML techniques to boost their accuracy, efficiency and effectiveness. In
this survey we focus on the modeling component, whose effectiveness is crucial
for solving the problem. The modeling activity has been traditionally shaped by
optimization and domain experts, interacting to provide realistic results.
Machine Learning techniques can tremendously ease the process, and exploit the
available data to either create models or refine expert-designed ones. In this
survey we cover approaches that have been recently proposed to enhance the
modeling process by learning either single constraints, objective functions, or
the whole model. We highlight common themes to multiple approaches and draw
connections with related fields of research.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lombardi_M/0/1/0/all/0/1&quot;&gt;Michele Lombardi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Milano_M/0/1/0/all/0/1&quot;&gt;Michela Milano&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.05527">
<title>Learning Probabilistic Logic Programs in Continuous Domains. (arXiv:1807.05527v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.05527</link>
<description rdf:parseType="Literal">&lt;p&gt;The field of statistical relational learning aims at unifying logic and
probability to reason and learn from data. Perhaps the most successful paradigm
in the field is probabilistic logic programming: the enabling of stochastic
primitives in logic programming, which is now increasingly seen to provide a
declarative background to complex machine learning applications. While many
systems offer inference capabilities, the more significant challenge is that of
learning meaningful and interpretable symbolic representations from data. In
that regard, inductive logic programming and related techniques have paved much
of the way for the last few decades.
&lt;/p&gt;
&lt;p&gt;Unfortunately, a major limitation of this exciting landscape is that much of
the work is limited to finite-domain discrete probability distributions.
Recently, a handful of systems have been extended to represent and perform
inference with continuous distributions. The problem, of course, is that
classical solutions for inference are either restricted to well-known
parametric families (e.g., Gaussians) or resort to sampling strategies that
provide correct answers only in the limit. When it comes to learning, moreover,
inducing representations remains entirely open, other than &quot;data-fitting&quot;
solutions that force-fit points to aforementioned parametric families.
&lt;/p&gt;
&lt;p&gt;In this paper, we take the first steps towards inducing probabilistic logic
programs for continuous and mixed discrete-continuous data, without being
pigeon-holed to a fixed set of distribution families. Our key insight is to
leverage techniques from piecewise polynomial function approximation theory,
yielding a principled way to learn and compositionally construct density
functions. We test the framework and discuss the learned representations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Speichert_S/0/1/0/all/0/1&quot;&gt;Stefanie Speichert&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Belle_V/0/1/0/all/0/1&quot;&gt;Vaishak Belle&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.05579">
<title>Ontology-Based Query Expansion with Latently Related Named Entities for Semantic Text Search. (arXiv:1807.05579v1 [cs.IR])</title>
<link>http://arxiv.org/abs/1807.05579</link>
<description rdf:parseType="Literal">&lt;p&gt;Traditional information retrieval systems represent documents and queries by
keyword sets. However, the content of a document or a query is mainly defined
by both keywords and named entities occurring in it. Named entities have
ontological features, namely, their aliases, classes, and identifiers, which
are hidden from their textual appearance. Besides, the meaning of a query may
imply latent named entities that are related to the apparent ones in the query.
We propose an ontology-based generalized vector space model to semantic text
search. It exploits ontological features of named entities and their latently
related ones to reveal the semantics of documents and queries. We also propose
a framework to combine different ontologies to take their complementary
advantages for semantic annotation and searching. Experiments on a benchmark
dataset show better search quality of our model to other ones.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ngo_V/0/1/0/all/0/1&quot;&gt;Vuong M. Ngo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cao_T/0/1/0/all/0/1&quot;&gt;Tru H. Cao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.05609">
<title>A Mathematical Account of Soft Evidence, and of Jeffrey&apos;s `destructive&apos; versus Pearl&apos;s `constructive&apos; updating. (arXiv:1807.05609v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1807.05609</link>
<description rdf:parseType="Literal">&lt;p&gt;Evidence in probabilistic reasoning may be `hard&apos; or `soft&apos;, that is, it may
be of yes/no form, or it may involve a strength of belief, in the unit interval
[0,1]. Reasoning with soft, $[0,1]$-valued evidence is important in many
situations but may lead to different, confusing interpretations. This paper
intends to bring more mathematical clarity to the field by shifting the
existing focus from specification of soft evidence to accomodation of soft
evidence. There are two main approaches, known as Jeffrey&apos;s rule and Pearl&apos;s
method, which give different outcomes on soft evidence. This paper describes
these two approaches as different ways of updating with soft evidence,
highlighting their differences, similarities and applications. This account is
based on a novel channel-based approach to Bayesian probability. Proper
understanding of these two update mechanisms is highly relevant for inference,
decision tools and probabilistic programming languages.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jacobs_B/0/1/0/all/0/1&quot;&gt;Bart Jacobs&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.05720">
<title>Governing autonomous vehicles: emerging responses for safety, liability, privacy, cybersecurity, and industry risks. (arXiv:1807.05720v1 [cs.CY])</title>
<link>http://arxiv.org/abs/1807.05720</link>
<description rdf:parseType="Literal">&lt;p&gt;The benefits of autonomous vehicles (AVs) are widely acknowledged, but there
are concerns about the extent of these benefits and AV risks and unintended
consequences. In this article, we first examine AVs and different categories of
the technological risks associated with them. We then explore strategies that
can be adopted to address these risks, and explore emerging responses by
governments for addressing AV risks. Our analyses reveal that, thus far,
governments have in most instances avoided stringent measures in order to
promote AV developments and the majority of responses are non-binding and focus
on creating councils or working groups to better explore AV implications. The
US has been active in introducing legislations to address issues related to
privacy and cybersecurity. The UK and Germany, in particular, have enacted laws
to address liability issues, other countries mostly acknowledge these issues,
but have yet to implement specific strategies. To address privacy and
cybersecurity risks strategies ranging from introduction or amendment of non-AV
specific legislation to creating working groups have been adopted. Much less
attention has been paid to issues such as environmental and employment risks,
although a few governments have begun programmes to retrain workers who might
be negatively affected.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Taeihagh_A/0/1/0/all/0/1&quot;&gt;Araz Taeihagh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lim_H/0/1/0/all/0/1&quot;&gt;Hazel Si Min Lim&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.05853">
<title>A Distributed Collaborative Filtering Algorithm Using Multiple Data Sources. (arXiv:1807.05853v1 [cs.IR])</title>
<link>http://arxiv.org/abs/1807.05853</link>
<description rdf:parseType="Literal">&lt;p&gt;Collaborative Filtering (CF) is one of the most commonly used recommendation
methods. CF consists in predicting whether, or how much, a user will like (or
dislike) an item by leveraging the knowledge of the user&apos;s preferences as well
as that of other users. In practice, users interact and express their opinion
on only a small subset of items, which makes the corresponding user-item rating
matrix very sparse. Such data sparsity yields two main problems for recommender
systems: (1) the lack of data to effectively model users&apos; preferences, and (2)
the lack of data to effectively model item characteristics. However, there are
often many other data sources that are available to a recommender system
provider, which can describe user interests and item characteristics (e.g.,
users&apos; social network, tags associated to items, etc.). These valuable data
sources may supply useful information to enhance a recommendation system in
modeling users&apos; preferences and item characteristics more accurately and thus,
hopefully, to make recommenders more precise. For various reasons, these data
sources may be managed by clusters of different data centers, thus requiring
the development of distributed solutions. In this paper, we propose a new
distributed collaborative filtering algorithm, which exploits and combines
multiple and diverse data sources to improve recommendation quality. Our
experimental evaluation using real datasets shows the effectiveness of our
algorithm compared to state-of-the-art recommendation algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bouadjenek_M/0/1/0/all/0/1&quot;&gt;Mohamed Reda Bouadjenek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pacitti_E/0/1/0/all/0/1&quot;&gt;Esther Pacitti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Servajean_M/0/1/0/all/0/1&quot;&gt;Maximilien Servajean&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Masseglia_F/0/1/0/all/0/1&quot;&gt;Florent Masseglia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abbadi_A/0/1/0/all/0/1&quot;&gt;Amr El Abbadi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1704.02906">
<title>Multi-Agent Diverse Generative Adversarial Networks. (arXiv:1704.02906v3 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1704.02906</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose MAD-GAN, an intuitive generalization to the Generative Adversarial
Networks (GANs) and its conditional variants to address the well known problem
of mode collapse. First, MAD-GAN is a multi-agent GAN architecture
incorporating multiple generators and one discriminator. Second, to enforce
that different generators capture diverse high probability modes, the
discriminator of MAD-GAN is designed such that along with finding the real and
fake samples, it is also required to identify the generator that generated the
given fake sample. Intuitively, to succeed in this task, the discriminator must
learn to push different generators towards different identifiable modes. We
perform extensive experiments on synthetic and real datasets and compare
MAD-GAN with different variants of GAN. We show high quality diverse sample
generations for challenging tasks such as image-to-image translation and face
generation. In addition, we also show that MAD-GAN is able to disentangle
different modalities when trained using highly challenging diverse-class
dataset (e.g. dataset with images of forests, icebergs, and bedrooms). In the
end, we show its efficacy on the unsupervised feature representation task. In
Appendix, we introduce a similarity based competing objective (MAD-GAN-Sim)
which encourages different generators to generate diverse samples based on a
user defined similarity metric. We show its performance on the image-to-image
translation, and also show its effectiveness on the unsupervised feature
representation task.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghosh_A/0/1/0/all/0/1&quot;&gt;Arnab Ghosh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kulharia_V/0/1/0/all/0/1&quot;&gt;Viveka Kulharia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Namboodiri_V/0/1/0/all/0/1&quot;&gt;Vinay Namboodiri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Torr_P/0/1/0/all/0/1&quot;&gt;Philip H. S. Torr&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dokania_P/0/1/0/all/0/1&quot;&gt;Puneet K. Dokania&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.05077">
<title>Transforming Cooling Optimization for Green Data Center via Deep Reinforcement Learning. (arXiv:1709.05077v3 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1709.05077</link>
<description rdf:parseType="Literal">&lt;p&gt;Cooling system plays a critical role in a modern data center (DC). Developing
an optimal control policy for DC cooling system is a challenging task. The
prevailing approaches often rely on approximating system models that are built
upon the knowledge of mechanical cooling, electrical and thermal management,
which is difficult to design and may lead to sub-optimal or unstable
performances. In this paper, we propose utilizing the large amount of
monitoring data in DC to optimize the control policy. To do so, we cast the
cooling control policy design into an energy cost minimization problem with
temperature constraints, and tap it into the emerging deep reinforcement
learning (DRL) framework. Specifically, we propose an end-to-end cooling
control algorithm (CCA) that is based on the actor-critic framework and an
off-policy off-line version of the deep deterministic policy gradient (DDPG)
algorithm. In the proposed CCA, an evaluation network is trained to predict an
energy cost counter penalized by the cooling status of the DC room, and a
policy network is trained to predict optimized control settings when gave the
current load and weather information. The proposed algorithm is evaluated on
the EnergyPlus simulation platform and on a real data trace collected from the
National Super Computing Centre (NSCC) of Singapore. Our results show that the
proposed CCA can achieve about 11% cooling cost saving on the simulation
platform compared with a manually configured baseline control algorithm. In the
trace-based study, we propose a de-underestimation validation mechanism as we
cannot directly test the algorithm on a real DC. Even though with DUE the
results are conservative, we can still achieve about 15% cooling energy saving
on the NSCC data trace if we set the inlet temperature threshold at 26.6 degree
Celsius.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yuanlong Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wen_Y/0/1/0/all/0/1&quot;&gt;Yonggang Wen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guan_K/0/1/0/all/0/1&quot;&gt;Kyle Guan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1&quot;&gt;Dacheng Tao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.03058">
<title>Abstract: Probabilistic Prognostic Estimates of Survival in Metastatic Cancer Patients. (arXiv:1801.03058v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1801.03058</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a deep learning model - Probabilistic Prognostic Estimates of
Survival in Metastatic Cancer Patients (PPES-Met) for estimating short-term
life expectancy (3 months) of the patients by analyzing free-text clinical
notes in the electronic medical record, while maintaining the temporal visit
sequence. In a single framework, we integrated semantic data mapping and neural
embedding technique to produce a text processing method that extracts relevant
information from heterogeneous types of clinical notes in an unsupervised
manner, and we designed a recurrent neural network to model the temporal
dependency of the patient visits. The model was trained on a large dataset
(10,293 patients) and validated on a separated dataset (1818 patients). Our
method achieved an area under the ROC curve (AUC) of 0.89. To provide
explain-ability, we developed an interactive graphical tool that may improve
physician understanding of the basis for the model&apos;s predictions. The high
accuracy and explain-ability of the PPES-Met model may enable our model to be
used as a decision support tool to personalize metastatic cancer treatment and
provide valuable assistance to the physicians.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Banerjee_I/0/1/0/all/0/1&quot;&gt;Imon Banerjee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gensheimer_M/0/1/0/all/0/1&quot;&gt;Michael Francis Gensheimer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wood_D/0/1/0/all/0/1&quot;&gt;Douglas J. Wood&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Henry_S/0/1/0/all/0/1&quot;&gt;Solomon Henry&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chang_D/0/1/0/all/0/1&quot;&gt;Daniel Chang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rubin_D/0/1/0/all/0/1&quot;&gt;Daniel L. Rubin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.04134">
<title>Deep Episodic Memory: Encoding, Recalling, and Predicting Episodic Experiences for Robot Action Execution. (arXiv:1801.04134v3 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1801.04134</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a novel deep neural network architecture for representing robot
experiences in an episodic-like memory which facilitates encoding, recalling,
and predicting action experiences. Our proposed unsupervised deep episodic
memory model 1) encodes observed actions in a latent vector space and, based on
this latent encoding, 2) infers most similar episodes previously experienced,
3) reconstructs original episodes, and 4) predicts future frames in an
end-to-end fashion. Results show that conceptually similar actions are mapped
into the same region of the latent vector space. Based on these results, we
introduce an action matching and retrieval mechanism, benchmark its performance
on two large-scale action datasets, 20BN-something-something and ActivityNet
and evaluate its generalization capability in a real-world scenario on a
humanoid robot.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rothfuss_J/0/1/0/all/0/1&quot;&gt;Jonas Rothfuss&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ferreira_F/0/1/0/all/0/1&quot;&gt;Fabio Ferreira&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aksoy_E/0/1/0/all/0/1&quot;&gt;Eren Erdal Aksoy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1&quot;&gt;You Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Asfour_T/0/1/0/all/0/1&quot;&gt;Tamim Asfour&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.06500">
<title>Argumentation theory for mathematical argument. (arXiv:1803.06500v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1803.06500</link>
<description rdf:parseType="Literal">&lt;p&gt;To adequately model mathematical arguments the analyst must be able to
represent the mathematical objects under discussion and the relationships
between them, as well as inferences drawn about these objects and relationships
as the discourse unfolds. We introduce a framework with these properties, which
has been used to analyse mathematical dialogues and expository texts. The
framework can recover salient elements of discourse at, and within, the
sentence level, as well as the way mathematical content connects to form larger
argumentative structures. We show how the framework might be used to support
computational reasoning, and argue that it provides a more natural way to
examine the process of proving theorems than do Lamport&apos;s structured proofs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Corneli_J/0/1/0/all/0/1&quot;&gt;Joseph Corneli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Martin_U/0/1/0/all/0/1&quot;&gt;Ursula Martin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Murray_Rust_D/0/1/0/all/0/1&quot;&gt;Dave Murray-Rust&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nesin_G/0/1/0/all/0/1&quot;&gt;Gabriela Rino Nesin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pease_A/0/1/0/all/0/1&quot;&gt;Alison Pease&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08882">
<title>Multi-task Maximum Entropy Inverse Reinforcement Learning. (arXiv:1805.08882v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.08882</link>
<description rdf:parseType="Literal">&lt;p&gt;Multi-task Inverse Reinforcement Learning (IRL) is the problem of inferring
multiple reward functions from expert demonstrations. Prior work, built on
Bayesian IRL, is unable to scale to complex environments due to computational
constraints. This paper contributes a formulation of multi-task IRL in the more
computationally efficient Maximum Causal Entropy (MCE) IRL framework.
Experiments show our approach can perform one-shot imitation learning in a
gridworld environment that single-task IRL algorithms need hundreds of
demonstrations to solve. We outline preliminary work using meta-learning to
extend our method to the function approximator setting of modern MCE IRL
algorithms. Evaluating on multi-task variants of common simulated robotics
benchmarks, we discover serious limitations of these IRL algorithms, and
conclude with suggestions for further work.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gleave_A/0/1/0/all/0/1&quot;&gt;Adam Gleave&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Habryka_O/0/1/0/all/0/1&quot;&gt;Oliver Habryka&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09476">
<title>Hierarchical Clustering with Structural Constraints. (arXiv:1805.09476v2 [cs.DS] UPDATED)</title>
<link>http://arxiv.org/abs/1805.09476</link>
<description rdf:parseType="Literal">&lt;p&gt;Hierarchical clustering is a popular unsupervised data analysis method. For
many real-world applications, we would like to exploit prior information about
the data that imposes constraints on the clustering hierarchy, and is not
captured by the set of features available to the algorithm. This gives rise to
the problem of &quot;hierarchical clustering with structural constraints&quot;.
Structural constraints pose major challenges for bottom-up approaches like
average/single linkage and even though they can be naturally incorporated into
top-down divisive algorithms, no formal guarantees exist on the quality of
their output. In this paper, we provide provable approximation guarantees for
two simple top-down algorithms, using a recently introduced optimization
viewpoint of hierarchical clustering with pairwise similarity information
[Dasgupta, 2016]. We show how to find good solutions even in the presence of
conflicting prior information, by formulating a constraint-based regularization
of the objective. We further explore a variation of this objective for
dissimilarity information [Cohen-Addad et al., 2018] and improve upon current
techniques. Finally, we demonstrate our approach on a real dataset for the
taxonomy application.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chatziafratis_V/0/1/0/all/0/1&quot;&gt;Vaggos Chatziafratis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Niazadeh_R/0/1/0/all/0/1&quot;&gt;Rad Niazadeh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Charikar_M/0/1/0/all/0/1&quot;&gt;Moses Charikar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11088">
<title>Deep Reinforcement Learning in Ice Hockey for Context-Aware Player Evaluation. (arXiv:1805.11088v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.11088</link>
<description rdf:parseType="Literal">&lt;p&gt;A variety of machine learning models have been proposed to assess the
performance of players in professional sports. However, they have only a
limited ability to model how player performance depends on the game context.
This paper proposes a new approach to capturing game context: we apply Deep
Reinforcement Learning (DRL) to learn an action-value Q function from 3M
play-by-play events in the National Hockey League (NHL). The neural network
representation integrates both continuous context signals and game history,
using a possession-based LSTM. The learned Q-function is used to value players&apos;
actions under different game contexts. To assess a player&apos;s overall
performance, we introduce a novel Game Impact Metric (GIM) that aggregates the
values of the player&apos;s actions. Empirical Evaluation shows GIM is consistent
throughout a play season, and correlates highly with standard success measures
and future salary.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_G/0/1/0/all/0/1&quot;&gt;Guiliang Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schulte_O/0/1/0/all/0/1&quot;&gt;Oliver Schulte&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.04458">
<title>Monte Carlo Methods for the Game Kingdomino. (arXiv:1807.04458v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1807.04458</link>
<description rdf:parseType="Literal">&lt;p&gt;Kingdomino is introduced as an interesting game for studying game playing:
the game is multiplayer (4 independent players per game); it has a limited game
depth (13 moves per player); and it has limited but not insignificant
interaction among players.
&lt;/p&gt;
&lt;p&gt;Several strategies based on locally greedy players, Monte Carlo Evaluation
(MCE), and Monte Carlo Tree Search (MCTS) are presented with variants. We
examine a variation of UCT called progressive win bias and a playout policy
(Player-greedy) focused on selecting good moves for the player. A thorough
evaluation is done showing how the strategies perform and how to choose
parameters given specific time constraints. The evaluation shows that
surprisingly MCE is stronger than MCTS for a game like Kingdomino.
&lt;/p&gt;
&lt;p&gt;All experiments use a cloud-native design, with a game server in a Docker
container, and agents communicating using a REST-style JSON protocol. This
enables a multi-language approach to separating the game state, the strategy
implementations, and the coordination layer.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gedda_M/0/1/0/all/0/1&quot;&gt;Magnus Gedda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lagerkvist_M/0/1/0/all/0/1&quot;&gt;Mikael Z. Lagerkvist&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Butler_M/0/1/0/all/0/1&quot;&gt;Martin Butler&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.05328">
<title>On the Acceleration of L-BFGS with Second-Order Information and Stochastic Batches. (arXiv:1807.05328v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.05328</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper proposes a framework of L-BFGS based on the (approximate)
second-order information with stochastic batches, as a novel approach to the
finite-sum minimization problems. Different from the classical L-BFGS where
stochastic batches lead to instability, we use a smooth estimate for the
evaluations of the gradient differences while achieving acceleration by
well-scaling the initial Hessians. We provide theoretical analyses for both
convex and nonconvex cases. In addition, we demonstrate that within the popular
applications of least-square and cross-entropy losses, the algorithm admits a
simple implementation in the distributed environment. Numerical experiments
support the efficiency of our algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Jie Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rong_Y/0/1/0/all/0/1&quot;&gt;Yu Rong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Takac_M/0/1/0/all/0/1&quot;&gt;Martin Takac&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1&quot;&gt;Junzhou Huang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.05343">
<title>Generalization in quasi-periodic environments. (arXiv:1807.05343v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.05343</link>
<description rdf:parseType="Literal">&lt;p&gt;By and large the behavior of stochastic gradient is regarded as a challenging
problem, and it is often presented in the framework of statistical machine
learning. This paper offers a novel view on the analysis of on-line models of
learning that arises when dealing with a generalized version of stochastic
gradient that is based on dissipative dynamics. In order to face the complex
evolution of these models, a systematic treatment is proposed which is based on
energy balance equations that are derived by means of the Caldirola-Kanai (CK)
Hamiltonian. According to these equations, learning can be regarded as an
ordering process which corresponds with the decrement of the loss function.
Finally, the main results established in this paper is that in the case of
quasi-periodic environments, where the pattern novelty is progressively limited
as time goes by, the system dynamics yields an asymptotically consistent
solution in the weight space, that is the solution maps similar patterns to the
same decision.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bellettini_G/0/1/0/all/0/1&quot;&gt;Giovanni Bellettini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Betti_A/0/1/0/all/0/1&quot;&gt;Alessandro Betti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gori_M/0/1/0/all/0/1&quot;&gt;Marco Gori&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.05351">
<title>ML-Schema: Exposing the Semantics of Machine Learning with Schemas and Ontologies. (arXiv:1807.05351v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.05351</link>
<description rdf:parseType="Literal">&lt;p&gt;The ML-Schema, proposed by the W3C Machine Learning Schema Community Group,
is a top-level ontology that provides a set of classes, properties, and
restrictions for representing and interchanging information on machine learning
algorithms, datasets, and experiments. It can be easily extended and
specialized and it is also mapped to other more domain-specific ontologies
developed in the area of machine learning and data mining. In this paper we
overview existing state-of-the-art machine learning interchange formats and
present the first release of ML-Schema, a canonical format resulted of more
than seven years of experience among different research institutions. We argue
that exposing semantics of machine learning algorithms, models, and experiments
through a canonical format may pave the way to better interpretability and to
realistically achieve the full interoperability of experiments regardless of
platform or adopted workflow solution.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Publio_G/0/1/0/all/0/1&quot;&gt;Gustavo Correa Publio&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Esteves_D/0/1/0/all/0/1&quot;&gt;Diego Esteves&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lawrynowicz_A/0/1/0/all/0/1&quot;&gt;Agnieszka &amp;#x141;awrynowicz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Panov_P/0/1/0/all/0/1&quot;&gt;Pan&amp;#x10d;e Panov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Soldatova_L/0/1/0/all/0/1&quot;&gt;Larisa Soldatova&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Soru_T/0/1/0/all/0/1&quot;&gt;Tommaso Soru&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vanschoren_J/0/1/0/all/0/1&quot;&gt;Joaquin Vanschoren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zafar_H/0/1/0/all/0/1&quot;&gt;Hamid Zafar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.05411">
<title>Sparse Relaxed Regularized Regression: SR3. (arXiv:1807.05411v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1807.05411</link>
<description rdf:parseType="Literal">&lt;p&gt;Regularized regression problems are ubiquitous in statistical modeling,
signal processing, and machine learning. Sparse regression in particular has
been instrumental in scientific model discovery, including compressed sensing
applications, variable selection, and high-dimensional analysis. We propose a
new and highly effective approach for regularized regression, called SR3.
&lt;/p&gt;
&lt;p&gt;The key idea is to solve a relaxation of the regularized problem, which has
three advantages over the state-of-the-art: (1) solutions of the relaxed
problem are superior with respect to errors, false positives, and conditioning,
(2) relaxation allows extremely fast algorithms for both convex and nonconvex
formulations, and (3) the methods apply to composite regularizers such as total
variation (TV) and its nonconvex variants. We demonstrate the improved
performance of SR3 across a range of regularized regression problems with
synthetic and real data, including compressed sensing, LASSO, matrix completion
and TV regularization. To promote reproducible research, we include a companion
Matlab package that implements these popular applications.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zheng_P/0/1/0/all/0/1&quot;&gt;Peng Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Askham_T/0/1/0/all/0/1&quot;&gt;Travis Askham&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Brunton_S/0/1/0/all/0/1&quot;&gt;Stephen L. Brunton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kutz_J/0/1/0/all/0/1&quot;&gt;J. Nathan Kutz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Aravkin_A/0/1/0/all/0/1&quot;&gt;Aleksandr Y. Aravkin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.05459">
<title>Multi-time-horizon Solar Forecasting Using Recurrent Neural Network. (arXiv:1807.05459v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.05459</link>
<description rdf:parseType="Literal">&lt;p&gt;The non-stationarity characteristic of the solar power renders traditional
point forecasting methods to be less useful due to large prediction errors.
This results in increased uncertainties in the grid operation, thereby
negatively affecting the reliability and increased cost of operation. This
research paper proposes a unified architecture for multi-time-horizon
predictions for short and long-term solar forecasting using Recurrent Neural
Networks (RNN). The paper describes an end-to-end pipeline to implement the
architecture along with the methods to test and validate the performance of the
prediction model. The results demonstrate that the proposed method based on the
unified architecture is effective for multi-horizon solar forecasting and
achieves a lower root-mean-squared prediction error compared to the previous
best-performing methods which use one model for each time-horizon. The proposed
method enables multi-horizon forecasts with real-time inputs, which have a high
potential for practical applications in the evolving smart grid.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mishra_S/0/1/0/all/0/1&quot;&gt;Sakshi Mishra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Palanisamy_P/0/1/0/all/0/1&quot;&gt;Praveen Palanisamy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.05515">
<title>Magnitude Bounded Matrix Factorisation for Recommender Systems. (arXiv:1807.05515v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.05515</link>
<description rdf:parseType="Literal">&lt;p&gt;Low rank matrix factorisation is often used in recommender systems as a way
of extracting latent features. When dealing with large and sparse datasets,
traditional recommendation algorithms face the problem of acquiring large,
unrestrained, fluctuating values over predictions especially for users/items
with very few corresponding observations. Although the problem has been
somewhat solved by imposing bounding constraints over its objectives, and/or
over all entries to be within a fixed range, in terms of gaining better
recommendations, these approaches have two major shortcomings that we aim to
mitigate in this work: one is they can only deal with one pair of fixed bounds
for all entries, and the other one is they are very time-consuming when applied
on large scale recommender systems. In this paper, we propose a novel algorithm
named Magnitude Bounded Matrix Factorisation (MBMF), which allows different
bounds for individual users/items and performs very fast on large scale
datasets. The key idea of our algorithm is to construct a model by constraining
the magnitudes of each individual user/item feature vector. We achieve this by
converting from the Cartesian to Spherical coordinate system with radii set as
the corresponding magnitudes, which allows the above constrained optimisation
problem to become an unconstrained one. The Stochastic Gradient Descent (SGD)
method is then applied to solve the unconstrained task efficiently. Experiments
on synthetic and real datasets demonstrate that in most cases the proposed MBMF
is superior over all existing algorithms in terms of accuracy and time
complexity.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_S/0/1/0/all/0/1&quot;&gt;Shuai Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_K/0/1/0/all/0/1&quot;&gt;Kan Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_R/0/1/0/all/0/1&quot;&gt;Richard Yi Da Xu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.05561">
<title>Spatio-Temporal Structured Sparse Regression with Hierarchical Gaussian Process Priors. (arXiv:1807.05561v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1807.05561</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper introduces a new sparse spatio-temporal structured Gaussian
process regression framework for online and offline Bayesian inference. This is
the first framework that gives a time-evolving representation of the
interdependencies between the components of the sparse signal of interest. A
hierarchical Gaussian process describes such structure and the
interdependencies are represented via the covariance matrices of the prior
distributions. The inference is based on the expectation propagation method and
the theoretical derivation of the posterior distribution is provided in the
paper. The inference framework is thoroughly evaluated over synthetic, real
video and electroencephalography (EEG) data where the spatio-temporal evolving
patterns need to be reconstructed with high accuracy. It is shown that it
achieves 15% improvement of the F-measure compared with the alternating
direction method of multipliers, spatio-temporal sparse Bayesian learning
method and one-level Gaussian process model. Additionally, the required memory
for the proposed algorithm is less than in the one-level Gaussian process
model. This structured sparse regression framework is of broad applicability to
source localisation and object detection problems with sparse signals.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kuzin_D/0/1/0/all/0/1&quot;&gt;Danil Kuzin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Isupova_O/0/1/0/all/0/1&quot;&gt;Olga Isupova&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mihaylova_L/0/1/0/all/0/1&quot;&gt;Lyudmila Mihaylova&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.05666">
<title>Scene Learning: Deep Convolutional Networks For Wind Power Prediction by Embedding Turbines into Grid Space. (arXiv:1807.05666v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.05666</link>
<description rdf:parseType="Literal">&lt;p&gt;Wind power prediction is of vital importance in wind power utilization. There
have been a lot of researches based on the time series of the wind power or
speed, but In fact, these time series cannot express the temporal and spatial
changes of wind, which fundamentally hinders the advance of wind power
prediction. In this paper, a new kind of feature that can describe the process
of temporal and spatial variation is proposed, namely, Spatio-Temporal
Features. We first map the data collected at each moment from the wind turbine
to the plane to form the state map, namely, the scene, according to the
relative positions. The scene time series over a period of time is a
multi-channel image, i.e. the Spatio-Temporal Features. Based on the
Spatio-Temporal Features, the deep convolutional network is applied to predict
the wind power, achieving a far better accuracy than the existing methods.
Compared with the starge-of-the-art method, the mean-square error (MSE) in our
method is reduced by 49.83%, and the average time cost for training models can
be shortened by a factor of more than 150.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_R/0/1/0/all/0/1&quot;&gt;Ruiguo Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1&quot;&gt;Zhiqiang Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xuewei Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_M/0/1/0/all/0/1&quot;&gt;Mei Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jianrong Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1&quot;&gt;Bin Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.05800">
<title>Anomaly Machine Component Detection by Deep Generative Model with Unregularized Score. (arXiv:1807.05800v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.05800</link>
<description rdf:parseType="Literal">&lt;p&gt;One of the most common needs in manufacturing plants is rejecting products
not coincident with the standards as anomalies. Accurate and automatic anomaly
detection improves product reliability and reduces inspection cost.
Probabilistic models have been employed to detect test samples with lower
likelihoods as anomalies in unsupervised manner. Recently, a probabilistic
model called deep generative model (DGM) has been proposed for end-to-end
modeling of natural images and already achieved a certain success. However,
anomaly detection of machine components with complicated structures is still
challenging because they produce a wide variety of normal image patches with
low likelihoods. For overcoming this difficulty, we propose unregularized score
for the DGM. As its name implies, the unregularized score is the anomaly score
of the DGM without the regularization terms. The unregularized score is robust
to the inherent complexity of a sample and has a smaller risk of rejecting a
sample appearing less frequently but being coincident with the standards.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Matsubara_T/0/1/0/all/0/1&quot;&gt;Takashi Matsubara&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tachibana_R/0/1/0/all/0/1&quot;&gt;Ryosuke Tachibana&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Uehara_K/0/1/0/all/0/1&quot;&gt;Kuniaki Uehara&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.05827">
<title>Remember and Forget for Experience Replay. (arXiv:1807.05827v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.05827</link>
<description rdf:parseType="Literal">&lt;p&gt;Experience replay (ER) is crucial for attaining high data-efficiency in
off-policy deep reinforcement learning (RL). ER entails the recall of
experiences obtained in past iterations to compute gradient estimates for the
current policy. However, the accuracy of such updates may deteriorate when the
policy diverges from past behaviors. Remedies that aim to abate policy changes,
such as target networks and hyper-parameter tuning, do not prevent the policy
from becoming disconnected from past experiences, possibly undermining the
effectiveness of ER. We introduce an algorithm that relies on systematic
Remembering and Forgetting for ER (ReF-ER). In ReF-ER the RL agents forget
experiences that would be too unlikely with the current policy and constrain
policy changes within a trust region of past behaviors in the replay memory. We
show that ReF-ER improves the reliability and performance of off-policy RL,
both in the deterministic and in the stochastic policy gradients settings.
Finally, we complement ReF-ER with a novel off-policy actor-critic algorithm
(RACER) for continuous-action control problems. RACER employs a computationally
efficient closed-form approximation of on-policy action values and is shown to
be highly competitive with state-of-the-art algorithms on benchmark problems,
while being robust to large hyper-parameter variations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Novati_G/0/1/0/all/0/1&quot;&gt;Guido Novati&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koumoutsakos_P/0/1/0/all/0/1&quot;&gt;Petros Koumoutsakos&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.05832">
<title>Manifold Adversarial Learning. (arXiv:1807.05832v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.05832</link>
<description rdf:parseType="Literal">&lt;p&gt;The recently proposed adversarial training methods show the robustness to
both adversarial and original examples and achieve state-of-the-art results in
supervised and semi-supervised learning. All the existing adversarial training
methods con- sider only how the worst perturbed examples (i.e., adversarial
examples) could affect the model output. Despite their success, we argue that
such setting may be in lack of generalization, since the output space (or label
space) is apparently less informative. In this paper, we propose a novel
method, called Manifold Adver- sarial Training (MAT). MAT manages to build an
adversarial framework based on how the worst perturbation could affect the
distributional manifold rather than the output space. Particularly, a latent
data space with the Gaussian Mixture Model (GMM) will be first derived. On one
hand, MAT tries to perturb the input samples in the way that would rough the
distributional manifold the worst. On the other hand, the deep learning model
is trained trying to promote in the latent space the manifold smoothness,
measured by the variation of Gaussian mixtures (given the local perturbation
around the data point). Importantly, since the latent space is more informative
than the output space, the proposed MAT can learn better a ro- bust and compact
data representation, leading to further performance improvemen- t. The proposed
MAT is important in that it can be considered as a superset of one
recently-proposed discriminative feature learning approach called center loss.
We conducted a series of experiments in both supervised and semi-supervised
learn- ing on three benchmark data sets, showing that the proposed MAT can
achieve remarkable performance, much better than those of the state-of-the-art
adversarial approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1&quot;&gt;Shufei Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1&quot;&gt;Kaizhu Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1&quot;&gt;Jianke Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yang Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.05836">
<title>Forecasting market states. (arXiv:1807.05836v1 [q-fin.ST])</title>
<link>http://arxiv.org/abs/1807.05836</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a novel methodology to define, analyse and forecast market states.
In our approach market states are identified by a reference sparse precision
matrix and a vector of expectation values. In our procedure each multivariate
observation is associated to a given market state accordingly to a penalized
likelihood maximization. The procedure is made computationally very efficient
and can be used with a large number of assets. We demonstrate that this
procedure successfully classifies different states of the markets in an
unsupervised manner. In particular, we describe an experiment with one hundred
log-returns and two states in which the methodology automatically associates
one state to periods with average positive returns and the other state to
periods with average negative returns, therefore discovering spontaneously the
common classification of `bull&apos; and `bear&apos; markets. In another experiment, with
again one hundred log-returns and two states, we demonstrate that this
procedure can be efficiently used to forecast off-sample future market states
with significant prediction accuracy. This methodology opens the way to a range
of applications in risk management and trading strategies where the correlation
structure plays a central role.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-fin/1/au:+Procacci_P/0/1/0/all/0/1&quot;&gt;Pier Francesco Procacci&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-fin/1/au:+Aste_T/0/1/0/all/0/1&quot;&gt;Tomaso Aste&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.05926">
<title>Novel Feature-Based Clustering of Micro-Panel Data (CluMP). (arXiv:1807.05926v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1807.05926</link>
<description rdf:parseType="Literal">&lt;p&gt;Micro-panel data are collected and analysed in many research and industry
areas. Cluster analysis of micro-panel data is an unsupervised learning
exploratory method identifying subgroup clusters in a data set which include
homogeneous objects in terms of the development dynamics of monitored
variables. The supply of clustering methods tailored to micro-panel data is
limited. The present paper focuses on a feature-based clustering method,
introducing a novel two-step characteristic-based approach designed for this
type of data. The proposed CluMP method aims to identify clusters that are at
least as internally homogeneous and externally heterogeneous as those obtained
by alternative methods already implemented in the statistical system R. We
compare the clustering performance of the devised algorithm with two extant
methods using simulated micro-panel data sets. Our approach has yielded similar
or better outcomes than the other methods, the advantage of the proposed
algorithm being time efficiency which makes it applicable for large data sets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sobisek_L/0/1/0/all/0/1&quot;&gt;Lukas Sobisek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Stachova_M/0/1/0/all/0/1&quot;&gt;Maria Stachova&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Fojtik_J/0/1/0/all/0/1&quot;&gt;Jan Fojtik&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.05935">
<title>Siamese Survival Analysis with Competing Risks. (arXiv:1807.05935v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.05935</link>
<description rdf:parseType="Literal">&lt;p&gt;Survival analysis in the presence of multiple possible adverse events, i.e.,
competing risks, is a pervasive problem in many industries (healthcare,
finance, etc.). Since only one event is typically observed, the incidence of an
event of interest is often obscured by other related competing events. This
nonidentifiability, or inability to estimate true cause-specific survival
curves from empirical data, further complicates competing risk survival
analysis. We introduce Siamese Survival Prognosis Network (SSPN), a novel deep
learning architecture for estimating personalized risk scores in the presence
of competing risks. SSPN circumvents the nonidentifiability problem by avoiding
the estimation of cause-specific survival curves and instead determines
pairwise concordant time-dependent risks, where longer event times are assigned
lower risks. Furthermore, SSPN is able to directly optimize an approximation to
the C-discrimination index, rather than relying on well-known metrics which are
unable to capture the unique requirements of survival analysis with competing
risks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nemchenko_A/0/1/0/all/0/1&quot;&gt;Anton Nemchenko&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kyono_T/0/1/0/all/0/1&quot;&gt;Trent Kyono&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schaar_M/0/1/0/all/0/1&quot;&gt;Mihaela Van Der Schaar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.05981">
<title>A deep learning architecture to detect events in EEG signals during sleep. (arXiv:1807.05981v1 [eess.SP])</title>
<link>http://arxiv.org/abs/1807.05981</link>
<description rdf:parseType="Literal">&lt;p&gt;Electroencephalography (EEG) during sleep is used by clinicians to evaluate
various neurological disorders. In sleep medicine, it is relevant to detect
macro-events (&amp;gt; 10s) such as sleep stages, and micro-events (&amp;lt;2s) such as
spindles and K-complexes. Annotations of such events require a trained sleep
expert, a time consuming and tedious process with a large inter-scorer
variability. Automatic algorithms have been developed to detect various types
of events but these are event-specific. We propose a deep learning method that
jointly predicts locations, durations and types of events in EEG time series.
It relies on a convolutional neural network that builds a feature
representation from raw EEG signals. Numerical experiments demonstrate
efficiency of this new approach on various event detection tasks compared to
current state-of-the-art, event specific, algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Chambon_S/0/1/0/all/0/1&quot;&gt;Stanislas Chambon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Thorey_V/0/1/0/all/0/1&quot;&gt;Valentin Thorey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Arnal_P/0/1/0/all/0/1&quot;&gt;Pierrick J. Arnal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Mignot_E/0/1/0/all/0/1&quot;&gt;Emmanuel Mignot&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Gramfort_A/0/1/0/all/0/1&quot;&gt;Alexandre Gramfort&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1601.03764">
<title>Linear Algebraic Structure of Word Senses, with Applications to Polysemy. (arXiv:1601.03764v3 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1601.03764</link>
<description rdf:parseType="Literal">&lt;p&gt;Word embeddings are ubiquitous in NLP and information retrieval, but it is
unclear what they represent when the word is polysemous. Here it is shown that
multiple word senses reside in linear superposition within the word embedding
and simple sparse coding can recover vectors that approximately capture the
senses. The success of our approach, which applies to several embedding
methods, is mathematically explained using a variant of the random walk on
discourses model (Arora et al., 2016). A novel aspect of our technique is that
each extracted word sense is accompanied by one of about 2000 &quot;discourse atoms&quot;
that gives a succinct description of which other words co-occur with that word
sense. Discourse atoms can be of independent interest, and make the method
potentially more useful. Empirical tests are used to verify and support the
theory.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Arora_S/0/1/0/all/0/1&quot;&gt;Sanjeev Arora&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yuanzhi Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1&quot;&gt;Yingyu Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_T/0/1/0/all/0/1&quot;&gt;Tengyu Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Risteski_A/0/1/0/all/0/1&quot;&gt;Andrej Risteski&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1605.01559">
<title>High-dimensional Bayesian inference via the Unadjusted Langevin Algorithm. (arXiv:1605.01559v4 [math.ST] UPDATED)</title>
<link>http://arxiv.org/abs/1605.01559</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider in this paper the problem of sampling a high-dimensional
probability distribution $\pi$ having a density with respect to the Lebesgue
measure on $\mathbb{R}^d$, known up to a normalization constant $x \mapsto
\pi(x)= \mathrm{e}^{-U(x)}/\int_{\mathbb{R}^d} \mathrm{e}^{-U(y)} \mathrm{d}
y$. Such problem naturally occurs for example in Bayesian inference and machine
learning. Under the assumption that $U$ is continuously differentiable, $\nabla
U$ is globally Lipschitz and $U$ is strongly convex, we obtain non-asymptotic
bounds for the convergence to stationarity in Wasserstein distance of order $2$
and total variation distance of the sampling method based on the Euler
discretization of the Langevin stochastic differential equation, for both
constant and decreasing step sizes. The dependence on the dimension of the
state space of these bounds is explicit. The convergence of an appropriately
weighted empirical measure is also investigated and bounds for the mean square
error and exponential deviation inequality are reported for functions which are
measurable and bounded. An illustration to Bayesian inference for binary
regression is presented to support our claims.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Durmus_A/0/1/0/all/0/1&quot;&gt;Alain Durmus&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Moulines_E/0/1/0/all/0/1&quot;&gt;Eric Moulines&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1610.06447">
<title>Regularized Optimal Transport and the Rot Mover&apos;s Distance. (arXiv:1610.06447v4 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1610.06447</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents a unified framework for smooth convex regularization of
discrete optimal transport problems. In this context, the regularized optimal
transport turns out to be equivalent to a matrix nearness problem with respect
to Bregman divergences. Our framework thus naturally generalizes a previously
proposed regularization based on the Boltzmann-Shannon entropy related to the
Kullback-Leibler divergence, and solved with the Sinkhorn-Knopp algorithm. We
call the regularized optimal transport distance the rot mover&apos;s distance in
reference to the classical earth mover&apos;s distance. We develop two generic
schemes that we respectively call the alternate scaling algorithm and the
non-negative alternate scaling algorithm, to compute efficiently the
regularized optimal plans depending on whether the domain of the regularizer
lies within the non-negative orthant or not. These schemes are based on
Dykstra&apos;s algorithm with alternate Bregman projections, and further exploit the
Newton-Raphson method when applied to separable divergences. We enhance the
separable case with a sparse extension to deal with high data dimensions. We
also instantiate our proposed framework and discuss the inherent specificities
for well-known regularizers and statistical divergences in the machine learning
and information geometry communities. Finally, we demonstrate the merits of our
methods with experiments using synthetic data to illustrate the effect of
different regularizers and penalties on the solutions, as well as real-world
data for a pattern recognition application to audio scene classification.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Dessein_A/0/1/0/all/0/1&quot;&gt;Arnaud Dessein&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Papadakis_N/0/1/0/all/0/1&quot;&gt;Nicolas Papadakis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rouas_J/0/1/0/all/0/1&quot;&gt;Jean-Luc Rouas&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1702.00748">
<title>QCD-Aware Recursive Neural Networks for Jet Physics. (arXiv:1702.00748v2 [hep-ph] UPDATED)</title>
<link>http://arxiv.org/abs/1702.00748</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent progress in applying machine learning for jet physics has been built
upon an analogy between calorimeters and images. In this work, we present a
novel class of recursive neural networks built instead upon an analogy between
QCD and natural languages. In the analogy, four-momenta are like words and the
clustering history of sequential recombination jet algorithms is like the
parsing of a sentence. Our approach works directly with the four-momenta of a
variable-length set of particles, and the jet-based tree structure varies on an
event-by-event basis. Our experiments highlight the flexibility of our method
for building task-specific jet embeddings and show that recursive architectures
are significantly more accurate and data efficient than previous image-based
networks. We extend the analogy from individual jets (sentences) to full events
(paragraphs), and show for the first time an event-level classifier operating
on all the stable particles produced in an LHC event.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/hep-ph/1/au:+Louppe_G/0/1/0/all/0/1&quot;&gt;Gilles Louppe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/hep-ph/1/au:+Cho_K/0/1/0/all/0/1&quot;&gt;Kyunghyun Cho&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/hep-ph/1/au:+Becot_C/0/1/0/all/0/1&quot;&gt;Cyril Becot&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/hep-ph/1/au:+Cranmer_K/0/1/0/all/0/1&quot;&gt;Kyle Cranmer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1706.03922">
<title>Analyzing the Robustness of Nearest Neighbors to Adversarial Examples. (arXiv:1706.03922v5 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1706.03922</link>
<description rdf:parseType="Literal">&lt;p&gt;Motivated by safety-critical applications, test-time attacks on classifiers
via adversarial examples has recently received a great deal of attention.
However, there is a general lack of understanding on why adversarial examples
arise; whether they originate due to inherent properties of data or due to lack
of training samples remains ill-understood. In this work, we introduce a
theoretical framework analogous to bias-variance theory for understanding these
effects.
&lt;/p&gt;
&lt;p&gt;We use our framework to analyze the robustness of a canonical non-parametric
classifier - the k-nearest neighbors. Our analysis shows that its robustness
properties depend critically on the value of k - the classifier may be
inherently non-robust for small k, but its robustness approaches that of the
Bayes Optimal classifier for fast-growing k. We propose a novel modified
1-nearest neighbor classifier, and guarantee its robustness in the large sample
limit. Our experiments suggest that this classifier may have good robustness
properties even for reasonable data set sizes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yizhen Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Jha_S/0/1/0/all/0/1&quot;&gt;Somesh Jha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chaudhuri_K/0/1/0/all/0/1&quot;&gt;Kamalika Chaudhuri&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.03800">
<title>Drug response prediction by ensemble learning and drug-induced gene expression signatures. (arXiv:1802.03800v3 [q-bio.GN] UPDATED)</title>
<link>http://arxiv.org/abs/1802.03800</link>
<description rdf:parseType="Literal">&lt;p&gt;Chemotherapeutic response of cancer cells to a given compound is one of the
most fundamental information one requires to design anti-cancer drugs. Recent
advances in producing large drug screens against cancer cell lines provided an
opportunity to apply machine learning methods for this purpose. In addition to
cytotoxicity databases, considerable amount of drug-induced gene expression
data has also become publicly available. Following this, several methods that
exploit omics data were proposed to predict drug activity on cancer cells.
However, due to the complexity of cancer drug mechanisms, none of the existing
methods are perfect. One possible direction, therefore, is to combine the
strengths of both the methods and the databases for improved performance. We
demonstrate that integrating a large number of predictions by the proposed
method improves the performance for this task. The predictors in the ensemble
differ in several aspects such as the method itself, the number of tasks method
considers (multi-task vs. single-task) and the subset of data considered
(sub-sampling). We show that all these different aspects contribute to the
success of the final ensemble. In addition, we attempt to use the drug screen
data together with two novel signatures produced from the drug-induced gene
expression profiles of cancer cell lines. Finally, we evaluate the method
predictions by in vitro experiments in addition to the tests on data sets.The
predictions of the methods, the signatures and the software are available from
\url{&lt;a href=&quot;http://mtan.etu.edu.tr/drug-response-prediction/&quot;&gt;this http URL&lt;/a&gt;}.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Tan_M/0/1/0/all/0/1&quot;&gt;Mehmet Tan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Ozgul_O/0/1/0/all/0/1&quot;&gt;Ozan F&amp;#x131;rat &amp;#xd6;zg&amp;#xfc;l&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Bardak_B/0/1/0/all/0/1&quot;&gt;Batuhan Bardak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Eksioglu_I/0/1/0/all/0/1&quot;&gt;I&amp;#x15f;&amp;#x131;ksu Ek&amp;#x15f;io&amp;#x11f;lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Sabuncuoglu_S/0/1/0/all/0/1&quot;&gt;Suna Sabuncuo&amp;#x11f;lu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06455">
<title>Bayesian Uncertainty Estimation for Batch Normalized Deep Networks. (arXiv:1802.06455v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1802.06455</link>
<description rdf:parseType="Literal">&lt;p&gt;We show that training a deep network using batch normalization is equivalent
to approximate inference in Bayesian models. We further demonstrate that this
finding allows us to make meaningful estimates of the model uncertainty using
conventional architectures, without modifications to the network or the
training procedure. Our approach is thoroughly validated by measuring the
quality of uncertainty in a series of empirical experiments on different tasks.
It outperforms baselines with strong statistical significance, and displays
competitive performance with recent Bayesian approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Teye_M/0/1/0/all/0/1&quot;&gt;Mattias Teye&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Azizpour_H/0/1/0/all/0/1&quot;&gt;Hossein Azizpour&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Smith_K/0/1/0/all/0/1&quot;&gt;Kevin Smith&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09902">
<title>Attention-Based Guided Structured Sparsity of Deep Neural Networks. (arXiv:1802.09902v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1802.09902</link>
<description rdf:parseType="Literal">&lt;p&gt;Network pruning is aimed at imposing sparsity in a neural network
architecture by increasing the portion of zero-valued weights for reducing its
size regarding energy-efficiency consideration and increasing evaluation speed.
In most of the conducted research efforts, the sparsity is enforced for network
pruning without any attention to the internal network characteristics such as
unbalanced outputs of the neurons or more specifically the distribution of the
weights and outputs of the neurons. That may cause severe accuracy drop due to
uncontrolled sparsity. In this work, we propose an attention mechanism that
simultaneously controls the sparsity intensity and supervised network pruning
by keeping important information bottlenecks of the network to be active. On
CIFAR-10, the proposed method outperforms the best baseline method by 6% and
reduced the accuracy drop by 2.6x at the same level of sparsity.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Torfi_A/0/1/0/all/0/1&quot;&gt;Amirsina Torfi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shirvani_R/0/1/0/all/0/1&quot;&gt;Rouzbeh A. Shirvani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Soleymani_S/0/1/0/all/0/1&quot;&gt;Sobhan Soleymani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nasrabadi_N/0/1/0/all/0/1&quot;&gt;Nasser M. Nasrabadi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.04204">
<title>Semiparametric Contextual Bandits. (arXiv:1803.04204v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1803.04204</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper studies semiparametric contextual bandits, a generalization of the
linear stochastic bandit problem where the reward for an action is modeled as a
linear function of known action features confounded by an non-linear
action-independent term. We design new algorithms that achieve
$\tilde{O}(d\sqrt{T})$ regret over $T$ rounds, when the linear function is
$d$-dimensional, which matches the best known bounds for the simpler
unconfounded case and improves on a recent result of Greenewald et al. (2017).
Via an empirical evaluation, we show that our algorithms outperform prior
approaches when there are non-linear confounding effects on the rewards.
Technically, our algorithms use a new reward estimator inspired by
doubly-robust approaches and our proofs require new concentration inequalities
for self-normalized martingales.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Krishnamurthy_A/0/1/0/all/0/1&quot;&gt;Akshay Krishnamurthy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wu_Z/0/1/0/all/0/1&quot;&gt;Zhiwei Steven Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Syrgkanis_V/0/1/0/all/0/1&quot;&gt;Vasilis Syrgkanis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.08472">
<title>High Dimensional Estimation and Multi-Factor Models. (arXiv:1804.08472v2 [q-fin.ST] UPDATED)</title>
<link>http://arxiv.org/abs/1804.08472</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper re-investigates the estimation of multiple factor models relaxing
the convention that the number of factors is small and using a new approach for
identifying factors. We first obtain the collection of all possible factors and
then provide a simultaneous test, security by security, of which factors are
significant. Since the collection of risk factors is large and highly
correlated, high-dimension methods (including the LASSO and prototype
clustering) have to be used. The multi-factor model is shown to have a
significantly better fit than the Fama-French 5-factor model. Robustness tests
are also provided.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-fin/1/au:+Zhu_L/0/1/0/all/0/1&quot;&gt;Liao Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-fin/1/au:+Basu_S/0/1/0/all/0/1&quot;&gt;Sumanta Basu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-fin/1/au:+Jarrow_R/0/1/0/all/0/1&quot;&gt;Robert A. Jarrow&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-fin/1/au:+Wells_M/0/1/0/all/0/1&quot;&gt;Martin T. Wells&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.06576">
<title>A Spline Theory of Deep Networks (Extended Version). (arXiv:1805.06576v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1805.06576</link>
<description rdf:parseType="Literal">&lt;p&gt;We build a rigorous bridge between deep networks (DNs) and approximation
theory via spline functions and operators. Our key result is that a large class
of DNs can be written as a composition of max-affine spline operators (MASOs),
which provide a powerful portal through which to view and analyze their inner
workings. For instance, conditioned on the input signal, the output of a MASO
DN can be written as a simple affine transformation of the input. This implies
that a DN constructs a set of signal-dependent, class-specific templates
against which the signal is compared via a simple inner product; we explore the
links to the classical theory of optimal classification via matched filters and
the effects of data memorization. Going further, we propose a simple penalty
term that can be added to the cost function of any DN learning algorithm to
force the templates to be orthogonal with each other; this leads to
significantly improved classifi- cation performance and reduced overfitting
with no change to the DN architecture. The spline partition of the input signal
space that is implicitly induced by a MASO directly links DNs to the theory of
vector quantization (VQ) and K-means clustering, which opens up new geometric
avenue to study how DNs organize signals in a hierarchical fashion. To validate
the utility of the VQ interpretation, we develop and validate a new distance
metric for signals and images that quantifies the difference between their VQ
encodings. (This paper is a significantly expanded version of a paper with the
same title that will appear at ICML 2018.)
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Balestriero_R/0/1/0/all/0/1&quot;&gt;Randall Balestriero&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Baraniuk_R/0/1/0/all/0/1&quot;&gt;Richard Baraniuk&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.01600">
<title>Accelerated Randomized Coordinate Descent Algorithms for Stochastic Optimization and Online Learning. (arXiv:1806.01600v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1806.01600</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose accelerated randomized coordinate descent algorithms for
stochastic optimization and online learning. Our algorithms have significantly
less per-iteration complexity than the known accelerated gradient algorithms.
The proposed algorithms for online learning have better regret performance than
the known randomized online coordinate descent algorithms. Furthermore, the
proposed algorithms for stochastic optimization exhibit as good convergence
rates as the best known randomized coordinate descent algorithms. We also show
simulation results to demonstrate performance of the proposed algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bhandari_A/0/1/0/all/0/1&quot;&gt;Akshita Bhandari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singh_C/0/1/0/all/0/1&quot;&gt;Chandramani Singh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.01771">
<title>Cycle-Consistent Adversarial Learning as Approximate Bayesian Inference. (arXiv:1806.01771v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1806.01771</link>
<description rdf:parseType="Literal">&lt;p&gt;We formalize the problem of learning interdomain correspondences in the
absence of paired data as Bayesian inference in a latent variable model (LVM),
where one seeks the underlying hidden representations of entities from one
domain as entities from the other domain. First, we introduce implicit latent
variable models, where the prior over hidden representations can be specified
flexibly as an implicit distribution. Next, we develop a new variational
inference (VI) algorithm for this model based on minimization of the symmetric
Kullback-Leibler (KL) divergence between a variational joint and the exact
joint distribution. Lastly, we demonstrate that the state-of-the-art
cycle-consistent adversarial learning (CYCLEGAN) models can be derived as a
special case within our proposed VI framework, thus establishing its connection
to approximate Bayesian inference methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tiao_L/0/1/0/all/0/1&quot;&gt;Louis C. Tiao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bonilla_E/0/1/0/all/0/1&quot;&gt;Edwin V. Bonilla&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ramos_F/0/1/0/all/0/1&quot;&gt;Fabio Ramos&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04594">
<title>Exponential Weights on the Hypercube in Polynomial Time. (arXiv:1806.04594v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1806.04594</link>
<description rdf:parseType="Literal">&lt;p&gt;We study a general online linear optimization problem(OLO). At each round, a
subset of objects from a fixed universe of $n$ objects is chosen, and a linear
cost associated with the chosen subset is incurred. We use regret as a measure
of performance of our algorithms. Regret is the difference between the total
cost incurred over all iterations and the cost of the best fixed subset in
hindsight. We consider Full Information, Semi-Bandit and Bandit feedback for
this problem. Using characteristic vectors of the subsets, this problem reduces
to OLO on the $\{0,1\}^n$ hypercube. The Exp2 algorithm and its bandit variants
are commonly used strategies for this problem. It was previously unknown if it
is possible to run Exp2 on the hypercube in polynomial time.
&lt;/p&gt;
&lt;p&gt;In this paper, we present a polynomial time algorithm called PolyExp for OLO
on the hypercube. We show that our algorithm is equivalent to both Exp2 on
$\{0,1\}^n$ as well as Online Mirror Descent(OMD) with Entropic regularization
on $[0,1]^n$ and Bernoulli Sampling. We consider $L_\infty$ adversarial losses.
We show PolyExp achieves expected regret bounds that are a factor of $\sqrt{n}$
better than Exp2 in all the three settings. Because of the equivalence of these
algorithms, this implies an improvement on Exp2&apos;s regret bounds. Moreover,
PolyExp&apos;s regret bounds match the $L_\infty$ lowerbounds in Audibert et al.
(2011). Finally, we show how to use PolyExp on the $\{-1,+1\}^n$ hypercube,
solving an open problem in Bubeck et al. (2012).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Putta_S/0/1/0/all/0/1&quot;&gt;Sudeep Raja Putta&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.04222">
<title>Modified Regularized Dual Averaging Method for Training Sparse Convolutional Neural Networks. (arXiv:1807.04222v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1807.04222</link>
<description rdf:parseType="Literal">&lt;p&gt;We proposed a modified regularized dual averaging method for training sparse
deep convolutional neural networks. The regularized dual averaging method has
been proven to be effective in obtaining sparse solutions in convex
optimization problems, but not applied to deep learning fields before. We
analyzed the new version in convex conditions and prove the convergence of it.
The modified method can obtain more sparse solutions than traditional sparse
optimization methods such as proximal-SGD, while keeping almost the same
accuracy as stochastic gradient method with momentum on certain datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jia_X/0/1/0/all/0/1&quot;&gt;Xiaodong Jia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_L/0/1/0/all/0/1&quot;&gt;Liang Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1&quot;&gt;Lian Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_J/0/1/0/all/0/1&quot;&gt;Juncai He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1&quot;&gt;Jinchao Xu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.05077">
<title>Maximizing Invariant Data Perturbation with Stochastic Optimization. (arXiv:1807.05077v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1807.05077</link>
<description rdf:parseType="Literal">&lt;p&gt;Feature attribution methods, or saliency maps, are one of the most popular
approaches for explaining the decisions of complex machine learning models such
as deep neural networks. In this study, we propose a stochastic optimization
approach for the perturbation-based feature attribution method. While the
original optimization problem of the perturbation-based feature attribution is
difficult to solve because of the complex constraints, we propose to
reformulate the problem as the maximization of a differentiable function, which
can be solved using gradient-based algorithms. In particular, stochastic
optimization is well-suited for the proposed reformulation, and we can solve
the problem using popular algorithms such as SGD, RMSProp, and Adam. The
experiment on the image classification with VGG16 shows that the proposed
method could identify relevant parts of the images effectively.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ikeno_K/0/1/0/all/0/1&quot;&gt;Kouichi Ikeno&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hara_S/0/1/0/all/0/1&quot;&gt;Satoshi Hara&lt;/a&gt;</dc:creator>
</item></rdf:RDF>