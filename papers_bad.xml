<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Boring papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Bad Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-08-01T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.00076"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.00193"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.00206"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.00252"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06464"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.00048"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.00068"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.00089"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.00130"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.00177"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.00329"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.00417"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.00434"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.06202"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.08275"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.02952"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.01442"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.00468"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.11805"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.00004"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.00020"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.00036"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.00079"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.00087"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.00111"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.00131"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.00142"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.00196"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.00197"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.00212"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.00232"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.00331"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.00337"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.00361"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.00441"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1612.05678"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1704.08227"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.01179"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.00673"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.10311"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.05591"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.09518"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07445"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11908"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06317"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.09571"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.02125"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.03931"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1808.00076">
<title>News Session-Based Recommendations using Deep Neural Networks. (arXiv:1808.00076v1 [cs.IR])</title>
<link>http://arxiv.org/abs/1808.00076</link>
<description rdf:parseType="Literal">&lt;p&gt;News recommender systems are aimed to personalize users experiences and help
them to discover relevant articles from a large and dynamic search space.
Therefore, news domain is a challenging scenario for recommendations, due to
its sparse user profiling, fast growing number of items, accelerated item&apos;s
value decay, and users preferences dynamic shift. Some promising results have
been recently achieved by the usage of Deep Learning techniques on Recommender
Systems, specially for item&apos;s feature extraction and for session-based
recommendations with Recurrent Neural Networks. In this paper, its presented a
Deep Learning architecture for Session-Based recommendations of News articles.
This architecture is composed of two modules, the first responsible to learn
news articles representations, based on their text and metadata, and the second
module aimed to provide session-based recommendations using Recurrent Neural
Networks. The recommendation task addressed in this work is next-item
prediction for user sessions: &quot;what is the next most likely article a user
might read in a session?&quot; User session context is leveraged by the architecture
to provide additional information in such extreme cold-start scenario of news
recommendation. Users&apos; behavior and item features are both merged in an hybrid
recommendation approach. A temporal offline evaluation method is also proposed
as a complementary contribution, for a more realistic evaluation of such task,
considering dynamic factors that affect global readership interests like
popularity, recency, and seasonality.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moreira_G/0/1/0/all/0/1&quot;&gt;Gabriel de Souza P. Moreira&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ferreira_F/0/1/0/all/0/1&quot;&gt;Felipe Ferreira&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cunha_A/0/1/0/all/0/1&quot;&gt;Adilson Marques da Cunha&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.00193">
<title>Reinforced Evolutionary Neural Architecture Search. (arXiv:1808.00193v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1808.00193</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural architecture search (NAS) is an important task in network design, but
it remains challenging due to high computational consumption in most methods
and low stability in evolution algorithm (EA) based NAS. In this paper, we
propose the Reinforced Evolutionary Neural Architecture Search (RENAS), an
evolutionary method with reinforced mutation for NAS to address these two
issues. Specifically, we integrate reinforced mutation into an EA based NAS
method by adopting a mutation controller to learn the effects of slight
modifications and make mutation actions. For this reason, the proposed method
is more like the process of model design by human experts than typical RL-based
NAS methods that construct networks sequentially. Furthermore, as the models
are trained by fine-tuning rather than from scratch in model evaluation, the
cell-wise search process becomes much more efficient and only takes less than
1.5 days using 4 GPUs (Titan xp). Experimental results demonstrate the
effectiveness and efficiency of our method. Moreover, the architecture searched
on CIFAR-10 sets a new state-of-the-art on ImageNet in the mobile setting
(top-1/5 accuracy = 75.7%/92.6%).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yukang Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1&quot;&gt;Qian Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_C/0/1/0/all/0/1&quot;&gt;Chang Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mu_L/0/1/0/all/0/1&quot;&gt;Lisen Mu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meng_G/0/1/0/all/0/1&quot;&gt;Gaofeng Meng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;Xinggang Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.00206">
<title>Beetle Swarm Optimization Algorithm:Theory and Application. (arXiv:1808.00206v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1808.00206</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, a new meta-heuristic algorithm, called beetle swarm
optimization algorithm, is proposed by enhancing the performance of swarm
optimization through beetle foraging principles. The performance of 23
benchmark functions is tested and compared with widely used algorithms,
including particle swarm optimization algorithm, genetic algorithm (GA) and
grasshopper optimization algorithm . Numerical experiments show that the beetle
swarm optimization algorithm outperforms its counterparts. Besides, to
demonstrate the practical impact of the proposed algorithm, two classic
engineering design problems, namely, pressure vessel design problem and
himmelblaus optimization problem, are also considered and the proposed beetle
swarm optimization algorithm is shown to be competitive in those applications.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1&quot;&gt;Tiantian Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1&quot;&gt;Long Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1&quot;&gt;Qiang Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.00252">
<title>A Deep Neural Model Of Emotion Appraisal. (arXiv:1808.00252v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1808.00252</link>
<description rdf:parseType="Literal">&lt;p&gt;Emotional concepts play a huge role in our daily life since they take part
into many cognitive processes: from the perception of the environment around us
to different learning processes and natural communication. Social robots need
to communicate with humans, which increased also the popularity of affective
embodied models that adopt different emotional concepts in many everyday tasks.
However, there is still a gap between the development of these solutions and
the integration and development of a complex emotion appraisal system, which is
much necessary for true social robots. In this paper, we propose a deep neural
model which is designed in the light of different aspects of developmental
learning of emotional concepts to provide an integrated solution for internal
and external emotion appraisal. We evaluate the performance of the proposed
model with different challenging corpora and compare it with state-of-the-art
models for external emotion appraisal. To extend the evaluation of the proposed
model, we designed and collected a novel dataset based on a Human-Robot
Interaction (HRI) scenario. We deployed the model in an iCub robot and
evaluated the capability of the robot to learn and describe the affective
behavior of different persons based on observation. The performed experiments
demonstrate that the proposed model is competitive with the state of the art in
describing emotion behavior in general. In addition, it is able to generate
internal emotional concepts that evolve through time: it continuously forms and
updates the formed emotional concepts, which is a step towards creating an
emotional appraisal model grounded in the robot experiences.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barros_P/0/1/0/all/0/1&quot;&gt;Pablo Barros&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barakova_E/0/1/0/all/0/1&quot;&gt;Emilia Barakova&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wermter_S/0/1/0/all/0/1&quot;&gt;Stefan Wermter&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06464">
<title>Learning Policy Representations in Multiagent Systems. (arXiv:1806.06464v2 [cs.MA] UPDATED)</title>
<link>http://arxiv.org/abs/1806.06464</link>
<description rdf:parseType="Literal">&lt;p&gt;Modeling agent behavior is central to understanding the emergence of complex
phenomena in multiagent systems. Prior work in agent modeling has largely been
task-specific and driven by hand-engineering domain-specific prior knowledge.
We propose a general learning framework for modeling agent behavior in any
multiagent system using only a handful of interaction data. Our framework casts
agent modeling as a representation learning problem. Consequently, we construct
a novel objective inspired by imitation learning and agent identification and
design an algorithm for unsupervised learning of representations of agent
policies. We demonstrate empirically the utility of the proposed framework in
(i) a challenging high-dimensional competitive environment for continuous
control and (ii) a cooperative environment for communication, on supervised
predictive tasks, unsupervised clustering, and policy optimization using deep
reinforcement learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grover_A/0/1/0/all/0/1&quot;&gt;Aditya Grover&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Al_Shedivat_M/0/1/0/all/0/1&quot;&gt;Maruan Al-Shedivat&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gupta_J/0/1/0/all/0/1&quot;&gt;Jayesh K. Gupta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Burda_Y/0/1/0/all/0/1&quot;&gt;Yura Burda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Edwards_H/0/1/0/all/0/1&quot;&gt;Harrison Edwards&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.00048">
<title>Web-STAR: A Visual Web-Based IDE for a Story Comprehension System. (arXiv:1808.00048v1 [cs.CY])</title>
<link>http://arxiv.org/abs/1808.00048</link>
<description rdf:parseType="Literal">&lt;p&gt;We present Web-STAR, an online platform for story understanding built on top
of the STAR reasoning engine for STory comprehension through ARgumentation. The
platform includes a web-based IDE, integration with the STAR system, and a web
service infrastructure to support integration with other systems that rely on
story understanding functionality to complete their tasks. The platform also
delivers a number of &quot;social&quot; features, including a community repository for
public story sharing with a built-in commenting system, and tools for
collaborative story editing that can be used for team development projects and
for educational purposes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rodosthenous_C/0/1/0/all/0/1&quot;&gt;Christos Rodosthenous&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Michael_L/0/1/0/all/0/1&quot;&gt;Loizos Michael&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.00068">
<title>A Fuzzy-Rough based Binary Shuffled Frog Leaping Algorithm for Feature Selection. (arXiv:1808.00068v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1808.00068</link>
<description rdf:parseType="Literal">&lt;p&gt;Feature selection and attribute reduction are crucial problems, and widely
used techniques in the field of machine learning, data mining and pattern
recognition to overcome the well-known phenomenon of the Curse of
Dimensionality, by either selecting a subset of features or removing unrelated
ones. This paper presents a new feature selection method that efficiently
carries out attribute reduction, thereby selecting the most informative
features of a dataset. It consists of two components: 1) a measure for feature
subset evaluation, and 2) a search strategy. For the evaluation measure, we
have employed the fuzzy-rough dependency degree (FRFDD) in the lower
approximation-based fuzzy-rough feature selection (L-FRFS) due to its
effectiveness in feature selection. As for the search strategy, a new version
of a binary shuffled frog leaping algorithm is proposed (B-SFLA). The new
feature selection method is obtained by hybridizing the B-SFLA with the FRDD.
Non-parametric statistical tests are conducted to compare the proposed approach
with several existing methods over twenty two datasets, including nine high
dimensional and large ones, from the UCI repository. The experimental results
demonstrate that the B-SFLA approach significantly outperforms other
metaheuristic methods in terms of the number of selected features and the
classification accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Anaraki_J/0/1/0/all/0/1&quot;&gt;Javad Rahimipour Anaraki&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Samet_S/0/1/0/all/0/1&quot;&gt;Saeed Samet&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Eftekhari_M/0/1/0/all/0/1&quot;&gt;Mahdi Eftekhari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ahn_C/0/1/0/all/0/1&quot;&gt;Chang Wook Ahn&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.00089">
<title>Towards Composable Bias Rating of AI Services. (arXiv:1808.00089v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1808.00089</link>
<description rdf:parseType="Literal">&lt;p&gt;A new wave of decision-support systems are being built today using AI
services that draw insights from data (like text and video) and incorporate
them in human-in-the-loop assistance. However, just as we expect humans to be
ethical, the same expectation needs to be met by automated systems that
increasingly get delegated to act on their behalf. A very important aspect of
an ethical behavior is to avoid (intended, perceived, or accidental) bias. Bias
occurs when the data distribution is not representative enough of the natural
phenomenon one wants to model and reason about. The possibly biased behavior of
a service is hard to detect and handle if the AI service is merely being used
and not developed from scratch, since the training data set is not available.
In this situation, we envisage a 3rd party rating agency that is independent of
the API producer or consumer and has its own set of biased and unbiased data,
with customizable distributions. We propose a 2-step rating approach that
generates bias ratings signifying whether the AI service is unbiased
compensating, data-sensitive biased, or biased. The approach also works on
composite services. We implement it in the context of text translation and
report interesting results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Srivastava_B/0/1/0/all/0/1&quot;&gt;Biplav Srivastava&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rossi_F/0/1/0/all/0/1&quot;&gt;Francesca Rossi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.00130">
<title>FMCode: A 3D In-the-Air Finger Motion Based User Login Framework for Gesture Interface. (arXiv:1808.00130v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1808.00130</link>
<description rdf:parseType="Literal">&lt;p&gt;Applications using gesture-based human-computer interface require a new user
login method with gestures because it does not have a traditional input method
to type a password. However, due to various challenges, existing gesture-based
authentication systems are generally considered too weak to be useful in
practice. In this paper, we propose a unified user login framework using 3D
in-air-handwriting, called FMCode. We define new types of features critical to
distinguish legitimate users from attackers and utilize Support Vector Machine
(SVM) for user authentication. The features and data-driven models are
specially designed to accommodate minor behavior variations that existing
gesture authentication methods neglect. In addition, we use deep neural network
approaches to efficiently identify the user based on his or her
in-air-handwriting, which avoids expansive account database search methods
employed by existing work. On a dataset collected by us with over 100 users,
our prototype system achieves 0.1% and 0.5% best Equal Error Rate (EER) for
user authentication, as well as 96.7% and 94.3% accuracy for user
identification, using two types of gesture input devices. Compared to existing
behavioral biometric systems using gesture and in-air-handwriting, our
framework achieves the state-of-the-art performance. In addition, our
experimental results show that FMCode is capable to defend against client-side
spoofing attacks, and it performs persistently in the long run. These results
and discoveries pave the way to practical usage of gesture-based user login
over the gesture interface.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_D/0/1/0/all/0/1&quot;&gt;Duo Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_D/0/1/0/all/0/1&quot;&gt;Dijiang Huang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.00177">
<title>Learning Dexterous In-Hand Manipulation. (arXiv:1808.00177v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1808.00177</link>
<description rdf:parseType="Literal">&lt;p&gt;We use reinforcement learning (RL) to learn dexterous in-hand manipulation
policies which can perform vision-based object reorientation on a physical
Shadow Dexterous Hand. The training is performed in a simulated environment in
which we randomize many of the physical properties of the system like friction
coefficients and an object&apos;s appearance. Our policies transfer to the physical
robot despite being trained entirely in simulation. Our method does not rely on
any human demonstrations, but many behaviors found in human manipulation emerge
naturally, including finger gaiting, multi-finger coordination, and the
controlled use of gravity. Our results were obtained using the same distributed
RL system that was used to train OpenAI Five. We also include a video of our
results: https://youtu.be/jwSbzNHGflM
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+OpenAI/0/1/0/all/0/1&quot;&gt;OpenAI&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.00329">
<title>Imaginary Kinematics. (arXiv:1808.00329v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1808.00329</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce a novel class of adjustment rules for a collection of beliefs.
This is an extension of Lewis&apos; imaging to absorb probabilistic evidence in
generalized settings. Unlike standard tools for belief revision, our proposal
may be used when information is inconsistent with an agent&apos;s belief base. We
show that the functionals we introduce are based on the imaginary counterpart
of probability kinematics for standard belief revision, and prove that, under
certain conditions, all standard postulates for belief revision are satisfied.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Marchetti_S/0/1/0/all/0/1&quot;&gt;Sabina Marchetti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Antonucci_A/0/1/0/all/0/1&quot;&gt;Alessandro Antonucci&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.00417">
<title>Debugging Non-Ground ASP Programs: Technique and Graphical Tools. (arXiv:1808.00417v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1808.00417</link>
<description rdf:parseType="Literal">&lt;p&gt;Answer Set Programming (ASP) is one of the major declarative programming
paradigms in the area of logic programming and non-monotonic reasoning. Despite
that ASP features a simple syntax and an intuitive semantics, errors are common
during the development of ASP programs. In this paper we propose a novel
debugging approach allowing for interactive localization of bugs in non-ground
programs. The new approach points the user directly to a set of non-ground
rules involved in the bug, which might be refined (up to the point in which the
bug is easily identified) by asking the programmer a sequence of questions on
an expected answer set. The approach has been implemented on top of the ASP
solver WASP. The resulting debugger has been complemented by a user-friendly
graphical interface, and integrated in ASPIDE, a rich IDE for answer set
programs. In addition, an empirical analysis shows that the new debugger is not
affected by the grounding blowup limiting the application of previous
approaches based on meta-programming. Under consideration in Theory and
Practice of Logic Programming (TPLP).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dodaro_C/0/1/0/all/0/1&quot;&gt;Carmine Dodaro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gasteiger_P/0/1/0/all/0/1&quot;&gt;Philip Gasteiger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Reale_K/0/1/0/all/0/1&quot;&gt;Kristian Reale&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ricca_F/0/1/0/all/0/1&quot;&gt;Francesco Ricca&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schekotihin_K/0/1/0/all/0/1&quot;&gt;Konstantin Schekotihin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.00434">
<title>Leveraging Knowledge Graph Embedding Techniques for Industry 4.0 Use Cases. (arXiv:1808.00434v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1808.00434</link>
<description rdf:parseType="Literal">&lt;p&gt;Industry is evolving towards Industry 4.0, which holds the promise of
increased flexibility in manufacturing, better quality and improved
productivity. A core actor of this growth is using sensors, which must capture
data that can used in unforeseen ways to achieve a performance not achievable
without them. However, the complexity of this improved setting is much greater
than what is currently used in practice. Hence, it is imperative that the
management cannot only be performed by human labor force, but part of that will
be done by automated algorithms instead. A natural way to represent the data
generated by this large amount of sensors, which are not acting measuring
independent variables, and the interaction of the different devices is by using
a graph data model. Then, machine learning could be used to aid the Industry
4.0 system to, for example, perform predictive maintenance. However, machine
learning directly on graphs, needs feature engineering and has scalability
issues. In this paper we discuss methods to convert (embed) the graph in a
vector space, such that it becomes feasible to use traditional machine learning
methods for Industry 4.0 settings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garofalo_M/0/1/0/all/0/1&quot;&gt;Martina Garofalo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pellegrino_M/0/1/0/all/0/1&quot;&gt;Maria Angela Pellegrino&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Altabba_A/0/1/0/all/0/1&quot;&gt;Abdulrahman Altabba&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cochez_M/0/1/0/all/0/1&quot;&gt;Michael Cochez&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.06202">
<title>A Robust Genetic Algorithm for Learning Temporal Specifications from Data. (arXiv:1711.06202v3 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1711.06202</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the problem of mining signal temporal logical requirements from a
dataset of regular (good) and anomalous (bad) trajectories of a dynamical
system. We assume the training set to be labeled by human experts and that we
have access only to a limited amount of data, typically noisy. We provide a
systematic approach to synthesize both the syntactical structure and the
parameters of the temporal logic formula using a two-steps procedure: first, we
leverage a novel evolutionary algorithm for learning the structure of the
formula; second, we perform the parameter synthesis operating on the
statistical emulation of the average robustness for a candidate formula w.r.t.
its parameters. We compare our results with our previous work [{BufoBSBLB14]
and with a recently proposed decision-tree [bombara_decision_2016] based
method. We present experimental results on two case studies: an anomalous
trajectory detection problem of a naval surveillance system and the
characterization of an Ineffective Respiratory effort, showing the usefulness
of our work.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nenzi_L/0/1/0/all/0/1&quot;&gt;Laura Nenzi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Silvetti_S/0/1/0/all/0/1&quot;&gt;Simone Silvetti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bartocci_E/0/1/0/all/0/1&quot;&gt;Ezio Bartocci&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bortolussi_L/0/1/0/all/0/1&quot;&gt;Luca Bortolussi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.08275">
<title>Approximate Inference-based Motion Planning by Learning and Exploiting Low-Dimensional Latent Variable Models. (arXiv:1711.08275v2 [cs.RO] UPDATED)</title>
<link>http://arxiv.org/abs/1711.08275</link>
<description rdf:parseType="Literal">&lt;p&gt;This work presents an efficient framework to generate a motion plan of a
robot with high degrees of freedom (e.g., a humanoid robot).
High-dimensionality of the robot configuration space often leads to
difficulties in utilizing the widely-used motion planning algorithms, since the
volume of the decision space increases exponentially with the number of
dimensions. To handle complications arising from the large decision space, and
to solve a corresponding motion planning problem efficiently, two key concepts
are adopted in this work: First, the Gaussian process latent variable model
(GP-LVM) is utilized for low-dimensional representation of the original
configuration space. Second, an approximate inference algorithm is used,
exploiting through the duality between control and estimation, to explore the
decision space and to compute a high-quality motion trajectory of the robot.
Utilizing the GP-LVM and the duality between control and estimation, we
construct a fully probabilistic generative model with which a high-dimensional
motion planning problem is transformed into a tractable inference problem.
Finally, we compute the motion trajectory via an approximate inference
algorithm based on a variant of the particle filter. The resulting motions can
be viewed in the supplemental video. ( https://youtu.be/kngEaOR4Esc )
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ha_J/0/1/0/all/0/1&quot;&gt;Jung-Su Ha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chae_H/0/1/0/all/0/1&quot;&gt;Hyeok-Joo Chae&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Choi_H/0/1/0/all/0/1&quot;&gt;Han-Lim Choi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.02952">
<title>A theory of consciousness: computation, algorithm, and neurobiological realization. (arXiv:1804.02952v2 [q-bio.NC] UPDATED)</title>
<link>http://arxiv.org/abs/1804.02952</link>
<description rdf:parseType="Literal">&lt;p&gt;The most enigmatic aspect of consciousness is the fact that it is felt, as a
subjective sensation. This particular aspect is explained by the theory
proposed here. The theory encompasses both the computation that is presumably
involved and the way in which that computation may be realized in the brain&apos;s
neurobiology. It is assumed that the brain makes an internal estimate of an
individual&apos;s own evolutionary fitness, which can be shown to produce an
irreducible, distinct cause. Communicating components of the fitness estimate
(either for external or internal use) requires inverting them. Such inversion
can be performed by the thalamocortical feedback loop in the mammalian brain,
if that loop is operating in a switched, dual-stage mode. A first
(nonconscious) stage produces forward estimates, whereas the second (conscious)
stage inverts those estimates. It is argued that inversion produces
irreducible, distinct, and spatially localized causes, which are plausibly
sensed as the feeling of consciousness.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Hateren_J/0/1/0/all/0/1&quot;&gt;J. H. van Hateren&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.01442">
<title>Modeling Sparse Deviations for Compressed Sensing using Generative Models. (arXiv:1807.01442v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1807.01442</link>
<description rdf:parseType="Literal">&lt;p&gt;In compressed sensing, a small number of linear measurements can be used to
reconstruct an unknown signal. Existing approaches leverage assumptions on the
structure of these signals, such as sparsity or the availability of a
generative model. A domain-specific generative model can provide a stronger
prior and thus allow for recovery with far fewer measurements. However, unlike
sparsity-based approaches, existing methods based on generative models
guarantee exact recovery only over their support, which is typically only a
small subset of the space on which the signals are defined. We propose
Sparse-Gen, a framework that allows for sparse deviations from the support set,
thereby achieving the best of both worlds by using a domain specific prior and
allowing reconstruction over the full space of signals. Theoretically, our
framework provides a new class of signals that can be acquired using compressed
sensing, reducing classic sparse vector recovery to a special case and avoiding
the restrictive support due to a generative model prior. Empirically, we
observe consistent improvements in reconstruction accuracy over competing
approaches, especially in the more practical setting of transfer compressed
sensing where a generative model for a data-rich, source domain aids sensing on
a data-scarce, target domain.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Dhar_M/0/1/0/all/0/1&quot;&gt;Manik Dhar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Grover_A/0/1/0/all/0/1&quot;&gt;Aditya Grover&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ermon_S/0/1/0/all/0/1&quot;&gt;Stefano Ermon&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.00468">
<title>Automated Directed Fairness Testing. (arXiv:1807.00468v2 [cs.LG] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1807.00468</link>
<description rdf:parseType="Literal">&lt;p&gt;Fairness is a critical trait in decision making. As machine-learning models
are increasingly being used in sensitive application domains (e.g. education
and employment) for decision making, it is crucial that the decisions computed
by such models are free of unintended bias. But how can we automatically
validate the fairness of arbitrary machine-learning models? For a given
machine-learning model and a set of sensitive input parameters, our AEQUITAS
approach automatically discovers discriminatory inputs that highlight fairness
violation. At the core of AEQUITAS are three novel strategies to employ
probabilistic search over the input space with the objective of uncovering
fairness violation. Our AEQUITAS approach leverages inherent robustness
property in common machine-learning models to design and implement scalable
test generation methodologies. An appealing feature of our generated test
inputs is that they can be systematically added to the training set of the
underlying model and improve its fairness. To this end, we design a fully
automated module that guarantees to improve the fairness of the underlying
model.
&lt;/p&gt;
&lt;p&gt;We implemented AEQUITAS and we have evaluated it on six state-of-the-art
classifiers, including a classifier that was designed with fairness
constraints. We show that AEQUITAS effectively generates inputs to uncover
fairness violation in all the subject classifiers and systematically improves
the fairness of the respective models using the generated test inputs. In our
evaluation, AEQUITAS generates up to 70% discriminatory inputs (w.r.t. the
total number of inputs generated) and leverages these inputs to improve the
fairness up to 94%.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Udeshi_S/0/1/0/all/0/1&quot;&gt;Sakshi Udeshi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Arora_P/0/1/0/all/0/1&quot;&gt;Pryanshu Arora&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chattopadhyay_S/0/1/0/all/0/1&quot;&gt;Sudipta Chattopadhyay&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.11805">
<title>Disaster Monitoring using Unmanned Aerial Vehicles and Deep Learning. (arXiv:1807.11805v1 [cs.LG] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1807.11805</link>
<description rdf:parseType="Literal">&lt;p&gt;Monitoring of disasters is crucial for mitigating their effects on the
environment and human population, and can be facilitated by the use of unmanned
aerial vehicles (UAV), equipped with camera sensors that produce aerial photos
of the areas of interest. A modern technique for recognition of events based on
aerial photos is deep learning. In this paper, we present the state of the art
work related to the use of deep learning techniques for disaster
identification. We demonstrate the potential of this technique in identifying
disasters with high accuracy, by means of a relatively simple deep learning
model. Based on a dataset of 544 images (containing disaster images such as
fires, earthquakes, collapsed buildings, tsunami and flooding, as well as
non-disaster scenes), our results show an accuracy of 91% achieved, indicating
that deep learning, combined with UAV equipped with camera sensors, have the
potential to predict disasters with high accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kamilaris_A/0/1/0/all/0/1&quot;&gt;Andreas Kamilaris&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Prenafeta_Boldu_F/0/1/0/all/0/1&quot;&gt;Francesc X. Prenafeta-Bold&amp;#xfa;&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.00004">
<title>Graph-Based Recommendation System. (arXiv:1808.00004v1 [cs.IR])</title>
<link>http://arxiv.org/abs/1808.00004</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work, we study recommendation systems modelled as contextual
multi-armed bandit (MAB) problems. We propose a graph-based recommendation
system that learns and exploits the geometry of the user space to create
meaningful clusters in the user domain. This reduces the dimensionality of the
recommendation problem while preserving the accuracy of MAB. We then study the
effect of graph sparsity and clusters size on the MAB performance and provide
exhaustive simulation results both in synthetic and in real-case datasets.
Simulation results show improvements with respect to state-of-the-art MAB
algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_K/0/1/0/all/0/1&quot;&gt;Kaige Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Toni_L/0/1/0/all/0/1&quot;&gt;Laura Toni&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.00020">
<title>Online Adaptative Curriculum Learning for GANs. (arXiv:1808.00020v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1808.00020</link>
<description rdf:parseType="Literal">&lt;p&gt;Generative Adversarial Networks (GANs) can successfully learn a probability
distribution and produce realistic samples. However, open questions such as
sufficient convergence conditions and mode collapse still persist. In this
paper, we build on existing work in the area by proposing a novel framework for
training the generator against an ensemble of discriminator networks, which can
be seen as a one-student/multiple-teachers setting. We formalize this problem
within the non-stationary Multi-Armed Bandit (MAB) framework, where we evaluate
the capability of a bandit algorithm to select discriminators for providing the
generator with feedback during learning. To this end, we propose a reward
function which reflects the amount of knowledge learned by the generator and
dynamically selects the optimal discriminator network. Finally, we connect our
algorithm to stochastic optimization methods and show that existing methods
using multiple discriminators in literature can be recovered from our
parametric model. Experimental results based on the Fr\&apos;echet Inception
Distance (FID) demonstrates faster convergence than existing baselines and show
that our method learns a curriculum.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Doan_T/0/1/0/all/0/1&quot;&gt;Thang Doan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Monteiro_J/0/1/0/all/0/1&quot;&gt;Joao Monteiro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Albuquerque_I/0/1/0/all/0/1&quot;&gt;Isabela Albuquerque&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mazoure_B/0/1/0/all/0/1&quot;&gt;Bogdan Mazoure&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Durand_A/0/1/0/all/0/1&quot;&gt;Audrey Durand&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pineau_J/0/1/0/all/0/1&quot;&gt;Joelle Pineau&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hjelm_R/0/1/0/all/0/1&quot;&gt;R Devon Hjelm&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.00036">
<title>Scalable Multi-Task Gaussian Process Tensor Regression for Normative Modeling of Structured Variation in Neuroimaging Data. (arXiv:1808.00036v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1808.00036</link>
<description rdf:parseType="Literal">&lt;p&gt;Most brain disorders are very heterogeneous in terms of their underlying
biology and developing analysis methods to model such heterogeneity is a major
challenge. A promising approach is to use probabilistic regression methods to
estimate normative models of brain function using (f)MRI data then use these to
map variation across individuals in clinical populations (e.g., via anomaly
detection). To fully capture individual differences, it is crucial to
statistically model the patterns of correlation across different brain regions
and individuals. However, this is very challenging for neuroimaging data
because of high-dimensionality and highly structured patterns of correlation
across multiple axes. Here, we propose a general and flexible multi-task
learning framework to address this problem. Our model uses a tensor-variate
Gaussian process in a Bayesian mixed-effects model and makes use of Kronecker
algebra and a low-rank approximation to scale efficiently to multi-way
neuroimaging data at the whole brain level. On a publicly available clinical
fMRI dataset, we show that our computationally affordable approach
substantially improves detection sensitivity over both a mass-univariate
normative model and a classifier that --unlike our approach-- has full access
to the clinical labels.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kia_S/0/1/0/all/0/1&quot;&gt;Seyed Mostafa Kia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Beckmann_C/0/1/0/all/0/1&quot;&gt;Christian F. Beckmann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Marquand_A/0/1/0/all/0/1&quot;&gt;Andre F. Marquand&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.00079">
<title>Cutting Down Training Memory by Re-fowarding. (arXiv:1808.00079v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1808.00079</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep Neutral Networks(DNN) require huge GPU memory when training on modern
image/video databases. Unfortunately, the GPU memory is always finite, which
limits the image resolution, batch size, and learning rate that could be tuned
for better performances. In this paper, we propose a novel approach, called
Re-forwarding, that substantially reduces memory usage in training. Our
approach only saves the tensors at a subset of layers during the first forward,
and conduct extra local forwards (the Re-forwarding process) to compute the
missing tensors needed during backward. The total memory cost becomes the sum
of (1) the cost at the subset of layers and (2) the maximum cost of the
re-forwarding processes. We propose theories and algorithms that achieve the
optimal memory solutions for DNNs with either linear or arbitrary optimization
graphs. Experiments show that Re-forwarding cut down huge amount of training
memory on all popular DNNs such as Alexnet, VGG net, ResNet, Densenet and
Inception net.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1&quot;&gt;Jianwei Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_D/0/1/0/all/0/1&quot;&gt;Dong Huang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.00087">
<title>Subsampled R\&apos;enyi Differential Privacy and Analytical Moments Accountant. (arXiv:1808.00087v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1808.00087</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the problem of subsampling in differential privacy (DP), a question
that is the centerpiece behind many successful differentially private machine
learning algorithms. Specifically, we provide a tight upper bound on the
R\&apos;enyi Differential Privacy (RDP) (Mironov, 2017) parameters for algorithms
that: (1) subsample the dataset, and then (2) apply a randomized mechanism M to
the subsample, in terms of the RDP parameters of M and the subsampling
probability parameter. This result generalizes the classic subsampling-based
&quot;privacy amplification&quot; property of $(\epsilon,\delta)$-differential privacy
that applies to only one fixed pair of $(\epsilon,\delta)$, to a stronger
version that exploits properties of each specific randomized algorithm and
satisfies an entire family of $(\epsilon(\delta),\delta)$-differential privacy
for all $\delta\in [0,1]$. Our experiments confirm the advantage of using our
techniques over keeping track of $(\epsilon,\delta)$ directly, especially in
the setting where we need to compose many rounds of data access.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yu-Xiang Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Balle_B/0/1/0/all/0/1&quot;&gt;Borja Balle&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kasiviswanathan_S/0/1/0/all/0/1&quot;&gt;Shiva Kasiviswanathan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.00111">
<title>Probability Calibration Trees. (arXiv:1808.00111v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1808.00111</link>
<description rdf:parseType="Literal">&lt;p&gt;Obtaining accurate and well calibrated probability estimates from classifiers
is useful in many applications, for example, when minimising the expected cost
of classifications. Existing methods of calibrating probability estimates are
applied globally, ignoring the potential for improvements by applying a more
fine-grained model. We propose probability calibration trees, a modification of
logistic model trees that identifies regions of the input space in which
different probability calibration models are learned to improve performance. We
compare probability calibration trees to two widely used calibration
methods---isotonic regression and Platt scaling---and show that our method
results in lower root mean squared error on average than both methods, for
estimates produced by a variety of base learners.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leathart_T/0/1/0/all/0/1&quot;&gt;Tim Leathart&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Frank_E/0/1/0/all/0/1&quot;&gt;Eibe Frank&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Holmes_G/0/1/0/all/0/1&quot;&gt;Geoffrey Holmes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pfahringer_B/0/1/0/all/0/1&quot;&gt;Bernhard Pfahringer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.00131">
<title>A Theory of Dichotomous Valuation with Applications to Variable Selection. (arXiv:1808.00131v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1808.00131</link>
<description rdf:parseType="Literal">&lt;p&gt;An econometric or statistical model may undergo a marginal gain when a new
variable is admitted, and a marginal loss if an existing variable is removed.
The value of a variable to the model is quantified by its expected marginal
gain and marginal loss. Assuming the equality of opportunity, we derive a few
formulas which evaluate the overall performance in potential modeling
scenarios. However, the value is not symmetric to marginal gain and marginal
loss; thus, we introduce an unbiased solution. Simulation studies show that our
new approaches significantly outperform a few practice-used variable selection
methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hu_X/0/1/0/all/0/1&quot;&gt;Xingwei Hu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.00142">
<title>Sleep-wake classification via quantifying heart rate variability by convolutional neural network. (arXiv:1808.00142v1 [stat.AP])</title>
<link>http://arxiv.org/abs/1808.00142</link>
<description rdf:parseType="Literal">&lt;p&gt;Fluctuations in heart rate are intimately tied to changes in the
physiological state of the organism. We examine and exploit this relationship
by classifying a human subject&apos;s wake/sleep status using his instantaneous
heart rate (IHR) series. We use a convolutional neural network (CNN) to build
features from the IHR series extracted from a whole-night electrocardiogram
(ECG) and predict every 30 seconds whether the subject is awake or asleep. Our
training database consists of 56 normal subjects, and we consider three
different databases for validation; one is private, and two are public with
different races and apnea severities. On our private database of 27 subjects,
our accuracy, sensitivity, specificity, and AUC values for predicting the wake
stage are 83.1%, 52.4%, 89.4%, and 0.83, respectively. Validation performance
is similar on our two public databases. When we use the photoplethysmography
instead of the ECG to obtain the IHR series, the performance is also
comparable. A robustness check is carried out to confirm the obtained
performance statistics. This result advocates for an effective and scalable
method for recognizing changes in physiological state using non-invasive heart
rate monitoring. The CNN model adaptively quantifies IHR fluctuation as well as
its location in time and is suitable for differentiating between the wake and
sleep stages.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Malik_J/0/1/0/all/0/1&quot;&gt;John Malik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lo_Y/0/1/0/all/0/1&quot;&gt;Yu-Lun Lo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wu_H/0/1/0/all/0/1&quot;&gt;Hau-tieng Wu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.00196">
<title>Manifold: A Model-Agnostic Framework for Interpretation and Diagnosis of Machine Learning Models. (arXiv:1808.00196v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1808.00196</link>
<description rdf:parseType="Literal">&lt;p&gt;Interpretation and diagnosis of machine learning models have gained renewed
interest in recent years with breakthroughs in new approaches. We present
Manifold, a framework that utilizes visual analysis techniques to support
interpretation, debugging, and comparison of machine learning models in a more
transparent and interactive manner. Conventional techniques usually focus on
visualizing the internal logic of a specific model type (i.e., deep neural
networks), lacking the ability to extend to a more complex scenario where
different model types are integrated. To this end, Manifold is designed as a
generic framework that does not rely on or access the internal logic of the
model and solely observes the input (i.e., instances or features) and the
output (i.e., the predicted result and probability distribution). We describe
the workflow of Manifold as an iterative process consisting of three major
phases that are commonly involved in the model development and diagnosis
process: inspection (hypothesis), explanation (reasoning), and refinement
(verification). The visual components supporting these tasks include a
scatterplot-based visual summary that overviews the models&apos; outcome and a
customizable tabular view that reveals feature discrimination. We demonstrate
current applications of the framework on the classification and regression
tasks and discuss other potential machine learning use scenarios where Manifold
can be applied.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Jiawei Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yang Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Molino_P/0/1/0/all/0/1&quot;&gt;Piero Molino&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1&quot;&gt;Lezhi Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ebert_D/0/1/0/all/0/1&quot;&gt;David S. Ebert&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.00197">
<title>MaxMin Linear Initialization for Fuzzy C-Means. (arXiv:1808.00197v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1808.00197</link>
<description rdf:parseType="Literal">&lt;p&gt;Clustering is an extensive research area in data science. The aim of
clustering is to discover groups and to identify interesting patterns in
datasets. Crisp (hard) clustering considers that each data point belongs to one
and only one cluster. However, it is inadequate as some data points may belong
to several clusters, as is the case in text categorization. Thus, we need more
flexible clustering. Fuzzy clustering methods, where each data point can belong
to several clusters, are an interesting alternative. Yet, seeding iterative
fuzzy algorithms to achieve high quality clustering is an issue. In this paper,
we propose a new linear and efficient initialization algorithm MaxMin Linear to
deal with this problem. Then, we validate our theoretical results through
extensive experiments on a variety of numerical real-world and artificial
datasets. We also test several validity indices, including a new validity index
that we propose, Transformed Standardized Fuzzy Difference (TSFD).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ozturk_A/0/1/0/all/0/1&quot;&gt;Ayb&amp;#xfc;k&amp;#xeb; Ozt&amp;#xfc;rk&lt;/a&gt; (ERIC, ArAr), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lallich_S/0/1/0/all/0/1&quot;&gt;St&amp;#xe9;phane Lallich&lt;/a&gt; (ERIC), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Darmont_J/0/1/0/all/0/1&quot;&gt;J&amp;#xe9;r&amp;#xf4;me Darmont&lt;/a&gt; (ERIC), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Waksman_S/0/1/0/all/0/1&quot;&gt;Sylvie Yona Waksman&lt;/a&gt; (ArAr)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.00212">
<title>Model selection by minimum description length: Lower-bound sample sizes for the Fisher information approximation. (arXiv:1808.00212v1 [stat.ME])</title>
<link>http://arxiv.org/abs/1808.00212</link>
<description rdf:parseType="Literal">&lt;p&gt;The Fisher information approximation (FIA) is an implementation of the
minimum description length principle for model selection. Unlike information
criteria such as AIC or BIC, it has the advantage of taking the functional form
of a model into account. Unfortunately, FIA can be misleading in finite
samples, resulting in an inversion of the correct rank order of complexity
terms for competing models in the worst case. As a remedy, we propose a
lower-bound $N&apos;$ for the sample size that suffices to preclude such errors. We
illustrate the approach using three examples from the family of multinomial
processing tree models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Heck_D/0/1/0/all/0/1&quot;&gt;Daniel W. Heck&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Moshagen_M/0/1/0/all/0/1&quot;&gt;Morten Moshagen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Erdfelder_E/0/1/0/all/0/1&quot;&gt;Edgar Erdfelder&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.00232">
<title>Off-Policy Evaluation and Learning from Logged Bandit Feedback: Error Reduction via Surrogate Policy. (arXiv:1808.00232v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1808.00232</link>
<description rdf:parseType="Literal">&lt;p&gt;When learning from a batch of logged bandit feedback, the discrepancy between
the policy to be learned and the off-policy training data imposes statistical
and computational challenges. Unlike classical supervised learning and online
learning settings, in batch contextual bandit learning, one only has access to
a collection of logged feedback from the actions taken by a historical policy,
and expect to learn a policy that takes good actions in possibly unseen
contexts. Such a batch learning setting is ubiquitous in online and interactive
systems, such as ad platforms and recommendation systems. Existing approaches
based on inverse propensity weights, such as Inverse Propensity Scoring (IPS)
and Policy Optimizer for Exponential Models (POEM), enjoy unbiasedness but
often suffer from large mean squared error. In this work, we introduce a new
approach named Maximum Likelihood Inverse Propensity Scoring (MLIPS) for batch
learning from logged bandit feedback. Instead of using the given historical
policy as the proposal in inverse propensity weights, we estimate a maximum
likelihood surrogate policy based on the logged action-context pairs, and then
use this surrogate policy as the proposal. We prove that MLIPS is
asymptotically unbiased, and moreover, has a smaller nonasymptotic mean squared
error than IPS. Such an error reduction phenomenon is somewhat surprising as
the estimated surrogate policy is less accurate than the given historical
policy. Results on multi-label classification problems and a large- scale ad
placement dataset demonstrate the empirical effectiveness of MLIPS.
Furthermore, the proposed surrogate policy technique is complementary to
existing error reduction techniques, and when combined, is able to consistently
boost the performance of several widely used approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1&quot;&gt;Yuan Xie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1&quot;&gt;Boyi Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1&quot;&gt;Qiang Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zhaoran Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1&quot;&gt;Yuan Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peng_J/0/1/0/all/0/1&quot;&gt;Jian Peng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.00331">
<title>SEA: A Combined Model for Heat Demand Prediction. (arXiv:1808.00331v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1808.00331</link>
<description rdf:parseType="Literal">&lt;p&gt;Heat demand prediction is a prominent research topic in the area of
intelligent energy networks. It has been well recognized that periodicity is
one of the important characteristics of heat demand. Seasonal-trend
decomposition based on LOESS (STL) algorithm can analyze the periodicity of a
heat demand series, and decompose the series into seasonal and trend
components. Then, predicting the seasonal and trend components respectively,
and combining their predictions together as the heat demand prediction is a
possible way to predict heat demand. In this paper, STL-ENN-ARIMA (SEA), a
combined model, was proposed based on the combination of the Elman neural
network (ENN) and the autoregressive integrated moving average (ARIMA) model,
which are commonly applied to heat demand prediction. ENN and ARIMA are used to
predict seasonal and trend components, respectively. Experimental results
demonstrate that the proposed SEA model has a promising performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_J/0/1/0/all/0/1&quot;&gt;Jiyang Xie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1&quot;&gt;Jiaxin Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_Z/0/1/0/all/0/1&quot;&gt;Zhanyu Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xue_J/0/1/0/all/0/1&quot;&gt;Jing-Hao Xue&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_Q/0/1/0/all/0/1&quot;&gt;Qie Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1&quot;&gt;Hailong Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_J/0/1/0/all/0/1&quot;&gt;Jun Guo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.00337">
<title>The Importance of Context When Recommending TV Content: Dataset and Algorithms. (arXiv:1808.00337v1 [cs.IR])</title>
<link>http://arxiv.org/abs/1808.00337</link>
<description rdf:parseType="Literal">&lt;p&gt;Home entertainment systems feature in a variety of usage scenarios with one
or more simultaneous users, for whom the complexity of choosing media to
consume has increased rapidly over the last decade. Users&apos; decision processes
are complex and highly influenced by contextual settings, but data supporting
the development and evaluation of context-aware recommender systems are scarce.
In this paper we present a dataset of self-reported TV consumption enriched
with contextual information of viewing situations. We show how choice of genre
associates with, among others, the number of present users and users&apos; attention
levels. Furthermore, we evaluate the performance of predicting chosen genres
given different configurations of contextual information, and compare the
results to contextless predictions. The results suggest that including
contextual features in the prediction cause notable improvements, and both
temporal and social context show significant contributions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kristoffersen_M/0/1/0/all/0/1&quot;&gt;Miklas S. Kristoffersen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shepstone_S/0/1/0/all/0/1&quot;&gt;Sven E. Shepstone&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tan_Z/0/1/0/all/0/1&quot;&gt;Zheng-Hua Tan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.00361">
<title>Structured Differential Learning for Automatic Threshold Setting. (arXiv:1808.00361v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1808.00361</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce a technique that can automatically tune the parameters of a
rule-based computer vision system comprised of thresholds, combinational logic,
and time constants. This lets us retain the flexibility and perspicacity of a
conventionally structured system while allowing us to perform approximate
gradient descent using labeled data. While this is only a heuristic procedure,
as far as we are aware there is no other efficient technique for tuning such
systems. We describe the components of the system and the associated supervised
learning mechanism. We also demonstrate the utility of the algorithm by
comparing its performance versus hand tuning for an automotive headlight
controller. Despite having over 100 parameters, the method is able to
profitably adjust the system values given just the desired output for a number
of videos.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Connell_J/0/1/0/all/0/1&quot;&gt;Jonathan Connell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Herta_B/0/1/0/all/0/1&quot;&gt;Benjamin Herta&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.00441">
<title>Matrix completion and extrapolation via kernel regression. (arXiv:1808.00441v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1808.00441</link>
<description rdf:parseType="Literal">&lt;p&gt;Matrix completion and extrapolation (MCEX) are dealt with here over
reproducing kernel Hilbert spaces (RKHSs) in order to account for prior
information present in the available data. Aiming at a faster and
low-complexity solver, the task is formulated as a kernel ridge regression. The
resultant MCEX algorithm can also afford online implementation, while the class
of kernel functions also encompasses several existing approaches to MC with
prior information. Numerical tests on synthetic and real datasets show that the
novel approach performs faster than widespread methods such as alternating
least squares (ALS) or stochastic gradient descent (SGD), and that the recovery
error is reduced, especially when dealing with noisy data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gimenez_Febrer_P/0/1/0/all/0/1&quot;&gt;Pere Gim&amp;#xe9;nez-Febrer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pages_Zamora_A/0/1/0/all/0/1&quot;&gt;Alba Pag&amp;#xe8;s-Zamora&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Giannakis_G/0/1/0/all/0/1&quot;&gt;Georgios B. Giannakis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1612.05678">
<title>Causal Discovery as Semi-Supervised Learning. (arXiv:1612.05678v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1612.05678</link>
<description rdf:parseType="Literal">&lt;p&gt;We frame causal discovery as a semi-supervised machine learning task. The
idea is to allow direct learning of a causal graph by treating indicators of
causal influence between variables as &quot;labels&quot;. Available data on the variables
of interest are used to provide features for the labelling task. Background
knowledge or any available interventional data provide labels on some edges in
the graph and the remaining edges are treated as unlabelled. To illustrate the
key ideas, we develop a distance-based approach (based on simple bivariate
histograms) within a semi-supervised manifold regularization framework. We
present empirical results on three different biological datasets (including
data where causal effects can be verified by experimental intervention), which
demonstrate the efficacy and highly general nature of the approach as well as
its simplicity from a user&apos;s point of view.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Oates_C/0/1/0/all/0/1&quot;&gt;Chris. J. Oates&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hill_S/0/1/0/all/0/1&quot;&gt;Steven M. Hill&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Blythe_D/0/1/0/all/0/1&quot;&gt;Duncan A. Blythe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mukherjee_S/0/1/0/all/0/1&quot;&gt;Sach Mukherjee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1704.08227">
<title>Accelerating Stochastic Gradient Descent For Least Squares Regression. (arXiv:1704.08227v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1704.08227</link>
<description rdf:parseType="Literal">&lt;p&gt;There is widespread sentiment that it is not possible to effectively utilize
fast gradient methods (e.g. Nesterov&apos;s acceleration, conjugate gradient, heavy
ball) for the purposes of stochastic optimization due to their instability and
error accumulation, a notion made precise in d&apos;Aspremont 2008 and Devolder,
Glineur, and Nesterov 2014. This work considers these issues for the special
case of stochastic approximation for the least squares regression problem, and
our main result refutes the conventional wisdom by showing that acceleration
can be made robust to statistical errors. In particular, this work introduces
an accelerated stochastic gradient method that provably achieves the minimax
optimal statistical risk faster than stochastic gradient descent. Critical to
the analysis is a sharp characterization of accelerated stochastic gradient
descent as a stochastic process. We hope this characterization gives insights
towards the broader question of designing simple and effective accelerated
stochastic methods for more general convex and non-convex optimization
problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Jain_P/0/1/0/all/0/1&quot;&gt;Prateek Jain&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kakade_S/0/1/0/all/0/1&quot;&gt;Sham M. Kakade&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kidambi_R/0/1/0/all/0/1&quot;&gt;Rahul Kidambi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Netrapalli_P/0/1/0/all/0/1&quot;&gt;Praneeth Netrapalli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sidford_A/0/1/0/all/0/1&quot;&gt;Aaron Sidford&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.01179">
<title>Continuous-Time Flows for Efficient Inference and Density Estimation. (arXiv:1709.01179v4 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1709.01179</link>
<description rdf:parseType="Literal">&lt;p&gt;Two fundamental problems in unsupervised learning are efficient inference for
latent-variable models and robust density estimation based on large amounts of
unlabeled data. Algorithms for the two tasks, such as normalizing flows and
generative adversarial networks (GANs), are often developed independently. In
this paper, we propose the concept of {\em continuous-time flows} (CTFs), a
family of diffusion-based methods that are able to asymptotically approach a
target distribution. Distinct from normalizing flows and GANs, CTFs can be
adopted to achieve the above two goals in one framework, with theoretical
guarantees. Our framework includes distilling knowledge from a CTF for
efficient inference, and learning an explicit energy-based distribution with
CTFs for density estimation. Both tasks rely on a new technique for
distribution matching within amortized learning. Experiments on various tasks
demonstrate promising performance of the proposed CTF framework, compared to
related techniques.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chen_C/0/1/0/all/0/1&quot;&gt;Changyou Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Li_C/0/1/0/all/0/1&quot;&gt;Chunyuan Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chen_L/0/1/0/all/0/1&quot;&gt;Liqun Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wang_W/0/1/0/all/0/1&quot;&gt;Wenlin Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pu_Y/0/1/0/all/0/1&quot;&gt;Yunchen Pu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Carin_L/0/1/0/all/0/1&quot;&gt;Lawrence Carin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.00673">
<title>Towards Robust Neural Networks via Random Self-ensemble. (arXiv:1712.00673v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1712.00673</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent studies have revealed the vulnerability of deep neural networks: A
small adversarial perturbation that is imperceptible to human can easily make a
well-trained deep neural network misclassify. This makes it unsafe to apply
neural networks in security-critical applications. In this paper, we propose a
new defense algorithm called Random Self-Ensemble (RSE) by combining two
important concepts: {\bf randomness} and {\bf ensemble}. To protect a targeted
model, RSE adds random noise layers to the neural network to prevent the strong
gradient-based attacks, and ensembles the prediction over random noises to
stabilize the performance. We show that our algorithm is equivalent to ensemble
an infinite number of noisy models $f_\epsilon$ without any additional memory
overhead, and the proposed training procedure based on noisy stochastic
gradient descent can ensure the ensemble model has a good predictive
capability. Our algorithm significantly outperforms previous defense techniques
on real data sets. For instance, on CIFAR-10 with VGG network (which has 92\%
accuracy without any attack), under the strong C\&amp;amp;W attack within a certain
distortion tolerance, the accuracy of unprotected model drops to less than
10\%, the best previous defense technique has $48\%$ accuracy, while our method
still has $86\%$ prediction accuracy under the same level of attack. Finally,
our method is simple and easy to integrate into any neural network.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1&quot;&gt;Xuanqing Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_M/0/1/0/all/0/1&quot;&gt;Minhao Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1&quot;&gt;Huan Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hsieh_C/0/1/0/all/0/1&quot;&gt;Cho-Jui Hsieh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.10311">
<title>Fast Maximum Likelihood estimation via Equilibrium Expectation for Large Network Data. (arXiv:1802.10311v2 [stat.ME] UPDATED)</title>
<link>http://arxiv.org/abs/1802.10311</link>
<description rdf:parseType="Literal">&lt;p&gt;A major line of contemporary research on complex networks is based on the
development of statistical models that specify the local motifs associated with
macro-structural properties observed in actual networks. This statistical
approach becomes increasingly problematic as network size increases. In the
context of current research on efficient estimation of models for large network
data sets, we propose a fast algorithm for maximum likelihood estimation (MLE)
that afords a signifcant increase in the size of networks amenable to direct
empirical analysis. The algorithm we propose in this paper relies on properties
of Markov chains at equilibrium, and for this reason it is called equilibrium
expectation (EE). We demonstrate the performance of the EE algorithm in the
context of exponential random graphmodels (ERGMs) a family of statistical
models commonly used in empirical research based on network data observed at a
single period in time. Thus far, the lack of efcient computational strategies
has limited the empirical scope of ERGMs to relatively small networks with a
few thousand nodes. The approach we propose allows a dramatic increase in the
size of networks that may be analyzed using ERGMs. This is illustrated in an
analysis of several biological networks and one social network with 104,103
nodes
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Byshkin_M/0/1/0/all/0/1&quot;&gt;Maksym Byshkin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Stivala_A/0/1/0/all/0/1&quot;&gt;Alex Stivala&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mira_A/0/1/0/all/0/1&quot;&gt;Antonietta Mira&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Robins_G/0/1/0/all/0/1&quot;&gt;Garry Robins&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lomi_A/0/1/0/all/0/1&quot;&gt;Alessandro Lomi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.05591">
<title>On the insufficiency of existing momentum schemes for Stochastic Optimization. (arXiv:1803.05591v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1803.05591</link>
<description rdf:parseType="Literal">&lt;p&gt;Momentum based stochastic gradient methods such as heavy ball (HB) and
Nesterov&apos;s accelerated gradient descent (NAG) method are widely used in
practice for training deep networks and other supervised learning models, as
they often provide significant improvements over stochastic gradient descent
(SGD). Rigorously speaking, &quot;fast gradient&quot; methods have provable improvements
over gradient descent only for the deterministic case, where the gradients are
exact. In the stochastic case, the popular explanations for their wide
applicability is that when these fast gradient methods are applied in the
stochastic case, they partially mimic their exact gradient counterparts,
resulting in some practical gain. This work provides a counterpoint to this
belief by proving that there exist simple problem instances where these methods
cannot outperform SGD despite the best setting of its parameters. These
negative problem instances are, in an informal sense, generic; they do not look
like carefully constructed pathological instances. These results suggest (along
with empirical evidence) that HB or NAG&apos;s practical performance gains are a
by-product of mini-batching.
&lt;/p&gt;
&lt;p&gt;Furthermore, this work provides a viable (and provable) alternative, which,
on the same set of problem instances, significantly improves over HB, NAG, and
SGD&apos;s performance. This algorithm, referred to as Accelerated Stochastic
Gradient Descent (ASGD), is a simple to implement stochastic algorithm, based
on a relatively less popular variant of Nesterov&apos;s Acceleration. Extensive
empirical results in this paper show that ASGD has performance gains over HB,
NAG, and SGD.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kidambi_R/0/1/0/all/0/1&quot;&gt;Rahul Kidambi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Netrapalli_P/0/1/0/all/0/1&quot;&gt;Praneeth Netrapalli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jain_P/0/1/0/all/0/1&quot;&gt;Prateek Jain&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kakade_S/0/1/0/all/0/1&quot;&gt;Sham M. Kakade&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.09518">
<title>Fr\&apos;echet ChemNet Distance: A metric for generative models for molecules in drug discovery. (arXiv:1803.09518v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1803.09518</link>
<description rdf:parseType="Literal">&lt;p&gt;The new wave of successful generative models in machine learning has
increased the interest in deep learning driven de novo drug design. However,
assessing the performance of such generative models is notoriously difficult.
Metrics that are typically used to assess the performance of such generative
models are the percentage of chemically valid molecules or the similarity to
real molecules in terms of particular descriptors, such as the partition
coefficient (logP) or druglikeness. However, method comparison is difficult
because of the inconsistent use of evaluation metrics, the necessity for
multiple metrics, and the fact that some of these measures can easily be
tricked by simple rule-based systems. We propose a novel distance measure
between two sets of molecules, called Fr\&apos;echet ChemNet distance (FCD), that
can be used as an evaluation metric for generative models. The FCD is similar
to a recently established performance metric for comparing image generation
methods, the Fr\&apos;echet Inception Distance (FID). Whereas the FID uses one of
the hidden layers of InceptionNet, the FCD utilizes the penultimate layer of a
deep neural network called ChemNet, which was trained to predict drug
activities. Thus, the FCD metric takes into account chemically and biologically
relevant information about molecules, and also measures the diversity of the
set via the distribution of generated molecules. The FCD&apos;s advantage over
previous metrics is that it can detect if generated molecules are a) diverse
and have similar b) chemical and c) biological properties as real molecules. We
further provide an easy-to-use implementation that only requires the SMILES
representation of the generated molecules as input to calculate the FCD.
Implementations are available at: https://www.github.com/bioinf-jku/FCD
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Preuer_K/0/1/0/all/0/1&quot;&gt;Kristina Preuer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Renz_P/0/1/0/all/0/1&quot;&gt;Philipp Renz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Unterthiner_T/0/1/0/all/0/1&quot;&gt;Thomas Unterthiner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hochreiter_S/0/1/0/all/0/1&quot;&gt;Sepp Hochreiter&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Klambauer_G/0/1/0/all/0/1&quot;&gt;G&amp;#xfc;nter Klambauer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07445">
<title>DVAE#: Discrete Variational Autoencoders with Relaxed Boltzmann Priors. (arXiv:1805.07445v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1805.07445</link>
<description rdf:parseType="Literal">&lt;p&gt;Boltzmann machines are powerful distributions that have been shown to be an
effective prior over binary latent variables in variational autoencoders
(VAEs). However, previous methods for training discrete VAEs have used the
evidence lower bound and not the tighter importance-weighted bound. We propose
two approaches for relaxing Boltzmann machines to continuous distributions that
permit training with importance-weighted bounds. These relaxations are based on
generalized overlapping transformations and the Gaussian integral trick.
Experiments on the MNIST and OMNIGLOT datasets show that these relaxations
outperform previous discrete VAEs with Boltzmann priors. An implementation
which reproduces these results is available at
https://github.com/QuadrantAI/dvae .
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Vahdat_A/0/1/0/all/0/1&quot;&gt;Arash Vahdat&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Andriyash_E/0/1/0/all/0/1&quot;&gt;Evgeny Andriyash&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Macready_W/0/1/0/all/0/1&quot;&gt;William G. Macready&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11908">
<title>Who Learns Better Bayesian Network Structures: Constraint-Based, Score-based or Hybrid Algorithms?. (arXiv:1805.11908v2 [stat.ME] UPDATED)</title>
<link>http://arxiv.org/abs/1805.11908</link>
<description rdf:parseType="Literal">&lt;p&gt;The literature groups algorithms to learn the structure of Bayesian networks
from data in three separate classes: constraint-based algorithms, which use
conditional independence tests to learn the dependence structure of the data;
score-based algorithms, which use goodness-of-fit scores as objective functions
to maximise; and hybrid algorithms that combine both approaches. Famously,
Cowell (2001) showed that algorithms in the first two classes learn the same
structures when the topological ordering of the network is known and we use
entropy to assess conditional independence and goodness of fit.
&lt;/p&gt;
&lt;p&gt;In this paper we address the complementary question: how do these classes of
algorithms perform outside of the assumptions above? We approach this question
by recognising that structure learning is defined by the combination of a
statistical criterion and an algorithm that determines how the criterion is
applied to the data. Removing the confounding effect of different choices for
the statistical criterion, we find using both simulated and real-world data
that constraint-based algorithms do not appear to be more efficient or more
sensitive to errors than score-based algorithms; and that hybrid algorithms are
not faster or more accurate than constraint-based algorithms. This suggests
that commonly held beliefs on structure learning in the literature are strongly
influenced by the choice of particular statistical criteria rather than just
properties of the algorithms themselves.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Scutari_M/0/1/0/all/0/1&quot;&gt;Marco Scutari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Graafland_C/0/1/0/all/0/1&quot;&gt;Catharina Elisabeth Graafland&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gutierrez_J/0/1/0/all/0/1&quot;&gt;Jos&amp;#xe9; Manuel Guti&amp;#xe9;rrez&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06317">
<title>Laplacian Smoothing Gradient Descent. (arXiv:1806.06317v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1806.06317</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a very simple modification of gradient descent and stochastic
gradient descent. We show that when applied to a variety of machine learning
models including softmax regression, convolutional neural nets, generative
adversarial nets, and deep reinforcement learning, this very simple surrogate
can dramatically reduce the variance and improve the accuracy of the
generalization. The new algorithm, (which depends on one nonnegative parameter)
when applied to non-convex minimization, tends to avoid sharp local minima.
Instead it seeks somewhat flatter local (and often global) minima. The method
only involves preconditioning the gradient by the inverse of a tri-diagonal
matrix that is positive definite. The motivation comes from the theory of
Hamilton-Jacobi partial differential equations. This theory demonstrates that
the new algorithm is almost the same as doing gradient descent on a new
function which (a) has the same global minima as the original function and (b)
is &quot;more convex&quot;. Again, the programming effort in doing this is minimal, in
cost, complexity and effort. We implement our algorithm into both PyTorch and
Tensorflow platforms, which will be made publicly available.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Osher_S/0/1/0/all/0/1&quot;&gt;Stanley Osher&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1&quot;&gt;Bao Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yin_P/0/1/0/all/0/1&quot;&gt;Penghang Yin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_X/0/1/0/all/0/1&quot;&gt;Xiyang Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pham_M/0/1/0/all/0/1&quot;&gt;Minh Pham&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_A/0/1/0/all/0/1&quot;&gt;Alex Lin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.09571">
<title>Asymptotic Properties of Recursive Maximum Likelihood Estimation in Non-Linear State-Space Models. (arXiv:1806.09571v2 [math.ST] UPDATED)</title>
<link>http://arxiv.org/abs/1806.09571</link>
<description rdf:parseType="Literal">&lt;p&gt;Using stochastic gradient search and the optimal filter derivative, it is
possible to perform recursive (i.e., online) maximum likelihood estimation in a
non-linear state-space model. As the optimal filter and its derivative are
analytically intractable for such a model, they need to be approximated
numerically. In [Poyiadjis, Doucet and Singh, Biometrika 2018], a recursive
maximum likelihood algorithm based on a particle approximation to the optimal
filter derivative has been proposed and studied through numerical simulations.
Here, this algorithm and its asymptotic behavior are analyzed theoretically. We
show that the algorithm accurately estimates maxima to the underlying (average)
log-likelihood when the number of particles is sufficiently large. We also
derive (relatively) tight bounds on the estimation error. The obtained results
hold under (relatively) mild conditions and cover several classes of non-linear
state-space models met in practice.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Tadic_V/0/1/0/all/0/1&quot;&gt;Vladislav Z.B. Tadic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Doucet_A/0/1/0/all/0/1&quot;&gt;Arnaud Doucet&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.02125">
<title>Scalable Gaussian Processes with Grid-Structured Eigenfunctions (GP-GRIEF). (arXiv:1807.02125v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1807.02125</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce a kernel approximation strategy that enables computation of the
Gaussian process log marginal likelihood and all hyperparameter derivatives in
$\mathcal{O}(p)$ time. Our GRIEF kernel consists of $p$ eigenfunctions found
using a Nystrom approximation from a dense Cartesian product grid of inducing
points. By exploiting algebraic properties of Kronecker and Khatri-Rao tensor
products, computational complexity of the training procedure can be practically
independent of the number of inducing points. This allows us to use arbitrarily
many inducing points to achieve a globally accurate kernel approximation, even
in high-dimensional problems. The fast likelihood evaluation enables type-I or
II Bayesian inference on large-scale datasets. We benchmark our algorithms on
real-world problems with up to two-million training points and $10^{33}$
inducing points.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Evans_T/0/1/0/all/0/1&quot;&gt;Trefor W. Evans&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Nair_P/0/1/0/all/0/1&quot;&gt;Prasanth B. Nair&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.03931">
<title>A Hierarchical Bayesian Linear Regression Model with Local Features for Stochastic Dynamics Approximation. (arXiv:1807.03931v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1807.03931</link>
<description rdf:parseType="Literal">&lt;p&gt;One of the challenges in model-based control of stochastic dynamical systems
is that the state transition dynamics are involved, and it is not easy or
efficient to make good-quality predictions of the states. Moreover, there are
not many representational models for the majority of autonomous systems, as it
is not easy to build a compact model that captures the entire dynamical
subtleties and uncertainties. In this work, we present a hierarchical Bayesian
linear regression model with local features to learn the dynamics of a
micro-robotic system as well as two simpler examples, consisting of a
stochastic mass-spring damper and a stochastic double inverted pendulum on a
cart. The model is hierarchical since we assume non-stationary priors for the
model parameters. These non-stationary priors make the model more flexible by
imposing priors on the priors of the model. To solve the maximum likelihood
(ML) problem for this hierarchical model, we use the variational expectation
maximization (EM) algorithm, and enhance the procedure by introducing hidden
target variables. The algorithm yields parsimonious model structures, and
consistently provides fast and accurate predictions for all our examples
involving large training and test sets. This demonstrates the effectiveness of
the method in learning stochastic dynamics, which makes it suitable for future
use in a paradigm, such as model-based reinforcement learning, to compute
optimal control policies in real time.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Parsa_B/0/1/0/all/0/1&quot;&gt;Behnoosh Parsa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rajasekaran_K/0/1/0/all/0/1&quot;&gt;Keshav Rajasekaran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meier_F/0/1/0/all/0/1&quot;&gt;Franziska Meier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Banerjee_A/0/1/0/all/0/1&quot;&gt;Ashis G. Banerjee&lt;/a&gt;</dc:creator>
</item></rdf:RDF>