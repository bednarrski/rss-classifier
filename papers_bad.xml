<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Boring papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Bad Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-03-22T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.08353"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.08137"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.08287"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.08343"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.08355"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1705.10217"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.10055"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09640"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.06288"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.07710"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.07712"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.08101"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.08161"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.08178"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.08182"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.08198"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.08276"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.08312"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.08471"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.08475"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1410.3351"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1609.05148"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1704.06977"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.11469"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.03848"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09902"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.02922"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.07612"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.07954"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1803.08353">
<title>Fine-tuning the Ant Colony System algorithm through Particle Swarm Optimization. (arXiv:1803.08353v1 [math.OC])</title>
<link>http://arxiv.org/abs/1803.08353</link>
<description rdf:parseType="Literal">&lt;p&gt;Ant Colony System (ACS) is a distributed (agent- based) algorithm which has
been widely studied on the Symmetric Travelling Salesman Problem (TSP). The
optimum parameters for this algorithm have to be found by trial and error. We
use a Particle Swarm Optimization algorithm (PSO) to optimize the ACS
parameters working in a designed subset of TSP instances. First goal is to
perform the hybrid PSO-ACS algorithm on a single instance to find the optimum
parameters and optimum solutions for the instance. Second goal is to analyze
those sets of optimum parameters, in relation to instance characteristics.
Computational results have shown good quality solutions for single instances
though with high computational times, and that there may be sets of parameters
that work optimally for a majority of instances.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Gomez_Cabrero_D/0/1/0/all/0/1&quot;&gt;D G&amp;#xf3;mez-Cabrero&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Ranasinghe_D/0/1/0/all/0/1&quot;&gt;D. N. Ranasinghe&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.08137">
<title>Robust Blind Deconvolution via Mirror Descent. (arXiv:1803.08137v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1803.08137</link>
<description rdf:parseType="Literal">&lt;p&gt;We revisit the Blind Deconvolution problem with a focus on understanding its
robustness and convergence properties. Provable robustness to noise and other
perturbations is receiving recent interest in vision, from obtaining immunity
to adversarial attacks to assessing and describing failure modes of algorithms
in mission critical applications. Further, many blind deconvolution methods
based on deep architectures internally make use of or optimize the basic
formulation, so a clearer understanding of how this sub-module behaves, when it
can be solved, and what noise injection it can tolerate is a first order
requirement. We derive new insights into the theoretical underpinnings of blind
deconvolution. The algorithm that emerges has nice convergence guarantees and
is provably robust in a sense we formalize in the paper. Interestingly, these
technical results play out very well in practice, where on standard datasets
our algorithm yields results competitive with or superior to the state of the
art. Keywords: blind deconvolution, robust continuous optimization
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ravi_S/0/1/0/all/0/1&quot;&gt;Sathya N. Ravi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mehta_R/0/1/0/all/0/1&quot;&gt;Ronak Mehta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singh_V/0/1/0/all/0/1&quot;&gt;Vikas Singh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.08287">
<title>Learning-based Model Predictive Control for Safe Exploration and Reinforcement Learning. (arXiv:1803.08287v1 [cs.SY])</title>
<link>http://arxiv.org/abs/1803.08287</link>
<description rdf:parseType="Literal">&lt;p&gt;Learning-based methods have been successful in solving complex control tasks
without significant prior knowledge about the system. However, these methods
typically do not provide any safety guarantees, which prevents their use in
safety-critical, real-world applications. In this paper, we present a
learning-based model predictive control scheme that provides provable
high-probability safety guarantees. To this end, we exploit regularity
assumptions on the dynamics in terms of a Gaussian process prior to construct
provably accurate confidence intervals on predicted trajectories. Unlike
previous approaches, we do not assume that model uncertainties are independent.
Based on these predictions, we guarantee that trajectories satisfy safety
constraints. Moreover, we use a terminal set constraint to recursively
guarantee the existence of safe control actions at every iteration. In our
experiments, we show that the resulting algorithm can be used to safely and
efficiently explore and learn about dynamic systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koller_T/0/1/0/all/0/1&quot;&gt;Torsten Koller&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Berkenkamp_F/0/1/0/all/0/1&quot;&gt;Felix Berkenkamp&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Turchetta_M/0/1/0/all/0/1&quot;&gt;Matteo Turchetta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Krause_A/0/1/0/all/0/1&quot;&gt;Andreas Krause&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.08343">
<title>A framework for Culture-aware Robots based on Fuzzy Logic. (arXiv:1803.08343v1 [cs.RO])</title>
<link>http://arxiv.org/abs/1803.08343</link>
<description rdf:parseType="Literal">&lt;p&gt;Cultural adaptation, i.e., the matching of a robot&apos;s behaviours to the
cultural norms and preferences of its user, is a well known key requirement for
the success of any assistive application. However, culture-dependent robot
behaviours are often implicitly set by designers, thus not allowing for an easy
and automatic adaptation to different cultures. This paper presents a method
for the design of culture-aware robots, that can automatically adapt their
behaviour to conform to a given culture. We propose a mapping from cultural
factors to related parameters of robot behaviours which relies on linguistic
variables to encode heterogeneous cultural factors in a uniform formalism, and
on fuzzy rules to encode qualitative relations among multiple variables. We
illustrate the approach in two practical case studies.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bruno_B/0/1/0/all/0/1&quot;&gt;Barbara Bruno&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mastrogiovanni_F/0/1/0/all/0/1&quot;&gt;Fulvio Mastrogiovanni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pecora_F/0/1/0/all/0/1&quot;&gt;Federico Pecora&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sgorbissa_A/0/1/0/all/0/1&quot;&gt;Antonio Sgorbissa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saffiotti_A/0/1/0/all/0/1&quot;&gt;Alessandro Saffiotti&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.08355">
<title>Structured Output Learning with Abstention: Application to Accurate Opinion Prediction. (arXiv:1803.08355v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1803.08355</link>
<description rdf:parseType="Literal">&lt;p&gt;Motivated by Supervised Opinion Analysis, we propose a novel framework
devoted to Structured Output Learning with Abstention (SOLA). The structure
prediction model is able to abstain from predicting some labels in the
structured output at a cost chosen by the user in a flexible way. For that
purpose, we decompose the problem into the learning of a pair of predictors,
one devoted to structured abstention and the other, to structured output
prediction. To compare fully labeled training data with predictions potentially
containing abstentions, we define a wide class of asymmetric abstention-aware
losses. Learning is achieved by surrogate regression in an appropriate feature
space while prediction with abstention is performed by solving a new pre-image
problem. Thus, SOLA extends recent ideas about Structured Output Prediction via
surrogate problems and calibration theory and enjoys statistical guarantees on
the resulting excess risk. Instantiated on a hierarchical abstention-aware
loss, SOLA is shown to be relevant for fine-grained opinion mining and gives
state-of-the-art results on this task. Moreover, the abstention-aware
representations can be used to competitively predict user-review ratings based
on a sentence-level opinion predictor.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garcia_A/0/1/0/all/0/1&quot;&gt;Alexandre Garcia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Essid_S/0/1/0/all/0/1&quot;&gt;Slim Essid&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Clavel_C/0/1/0/all/0/1&quot;&gt;Chlo&amp;#xe9; Clavel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+dAlche_Buc_F/0/1/0/all/0/1&quot;&gt;Florence d&amp;#x27;Alch&amp;#xe9;-Buc&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1705.10217">
<title>Black-box Testing of First-Order Logic Ontologies Using WordNet. (arXiv:1705.10217v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1705.10217</link>
<description rdf:parseType="Literal">&lt;p&gt;Artificial Intelligence aims to provide computer programs with commonsense
knowledge to reason about our world. This paper offers a new practical approach
towards automated commonsense reasoning with first-order logic (FOL)
ontologies. We propose a new black-box testing methodology of FOL SUMO-based
ontologies by exploiting WordNet and its mapping into SUMO. Our proposal
includes a method for the (semi-)automatic creation of a very large benchmark
of competency questions and a procedure for its automated evaluation by using
automated theorem provers (ATPs). Applying different quality criteria, our
testing proposal enables a successful evaluation of a) the competency of
several translations of SUMO into FOL and b) the performance of various
automated ATPs. Finally, we also provide a fine-grained and complete analysis
of the commonsense reasoning competency of current FOL SUMO-based ontologies.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alvez_J/0/1/0/all/0/1&quot;&gt;Javier &amp;#xc1;lvez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lucio_P/0/1/0/all/0/1&quot;&gt;Paqui Lucio&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rigau_G/0/1/0/all/0/1&quot;&gt;German Rigau&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.10055">
<title>Risk-sensitive Inverse Reinforcement Learning via Semi- and Non-Parametric Methods. (arXiv:1711.10055v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1711.10055</link>
<description rdf:parseType="Literal">&lt;p&gt;The literature on Inverse Reinforcement Learning (IRL) typically assumes that
humans take actions in order to minimize the expected value of a cost function,
i.e., that humans are risk neutral. Yet, in practice, humans are often far from
being risk neutral. To fill this gap, the objective of this paper is to devise
a framework for risk-sensitive IRL in order to explicitly account for a human&apos;s
risk sensitivity. To this end, we propose a flexible class of models based on
coherent risk measures, which allow us to capture an entire spectrum of risk
preferences from risk-neutral to worst-case. We propose efficient
non-parametric algorithms based on linear programming and semi-parametric
algorithms based on maximum likelihood for inferring a human&apos;s underlying risk
measure and cost function for a rich class of static and dynamic
decision-making settings. The resulting approach is demonstrated on a simulated
driving game with ten human participants. Our method is able to infer and mimic
a wide range of qualitatively different driving styles from highly risk-averse
to risk-neutral in a data-efficient manner. Moreover, comparisons of the
Risk-Sensitive (RS) IRL approach with a risk-neutral model show that the RS-IRL
framework more accurately captures observed participant behavior both
qualitatively and quantitatively, especially in scenarios where catastrophic
outcomes such as collisions can occur.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1&quot;&gt;Sumeet Singh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lacotte_J/0/1/0/all/0/1&quot;&gt;Jonathan Lacotte&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Majumdar_A/0/1/0/all/0/1&quot;&gt;Anirudha Majumdar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pavone_M/0/1/0/all/0/1&quot;&gt;Marco Pavone&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09640">
<title>Modeling Others using Oneself in Multi-Agent Reinforcement Learning. (arXiv:1802.09640v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1802.09640</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the multi-agent reinforcement learning setting with imperfect
information in which each agent is trying to maximize its own utility. The
reward function depends on the hidden state (or goal) of both agents, so the
agents must infer the other players&apos; hidden goals from their observed behavior
in order to solve the tasks. We propose a new approach for learning in these
domains: Self Other-Modeling (SOM), in which an agent uses its own policy to
predict the other agent&apos;s actions and update its belief of their hidden state
in an online manner. We evaluate this approach on three different tasks and
show that the agents are able to learn better policies using their estimate of
the other players&apos; hidden states, in both cooperative and adversarial settings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Raileanu_R/0/1/0/all/0/1&quot;&gt;Roberta Raileanu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Denton_E/0/1/0/all/0/1&quot;&gt;Emily Denton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Szlam_A/0/1/0/all/0/1&quot;&gt;Arthur Szlam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fergus_R/0/1/0/all/0/1&quot;&gt;Rob Fergus&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.06288">
<title>ORGaNICs: A Theory of Working Memory in Brains and Machines. (arXiv:1803.06288v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1803.06288</link>
<description rdf:parseType="Literal">&lt;p&gt;Working memory is a cognitive process that is responsible for temporarily
holding and manipulating information. Most of the empirical neuroscience
research on working memory has focused on measuring sustained activity in
prefrontal cortex (PFC) and/or parietal cortex during simple delayed-response
tasks, and most of the models of working memory have been based on neural
integrators. But working memory means much more than just holding a piece of
information online. We describe a new theory of working memory, based on a
recurrent neural circuit that we call ORGaNICs (Oscillatory Recurrent GAted
Neural Integrator Circuits). ORGaNICs are a variety of Long Short Term Memory
units (LSTMs), imported from machine learning and artificial intelligence.
ORGaNICs can be used to explain the complex dynamics of delay-period activity
in prefrontal cortex (PFC) during a working memory task. The theory is
analytically tractable so that we can characterize the dynamics, and the theory
provides a means for reading out information from the dynamically varying
responses at any point in time, in spite of the complex dynamics. ORGaNICs can
be implemented with a biophysical (electrical circuit) model of pyramidal
cells, combined with shunting inhibition via a thalamocortical loop. Although
introduced as a computational theory of working memory, ORGaNICs are also
applicable to models of sensory processing, motor preparation and motor
control. ORGaNICs offer computational advantages compared to other varieties of
LSTMs that are commonly used in AI applications. Consequently, ORGaNICs are a
framework for canonical computation in brains and machines.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Heeger_D/0/1/0/all/0/1&quot;&gt;David J. Heeger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mackey_W/0/1/0/all/0/1&quot;&gt;Wayne E. Mackey&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.07710">
<title>Inference in Probabilistic Graphical Models by Graph Neural Networks. (arXiv:1803.07710v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1803.07710</link>
<description rdf:parseType="Literal">&lt;p&gt;A useful computation when acting in a complex environment is to infer the
marginal probabilities or most probable states of task-relevant variables.
Probabilistic graphical models can efficiently represent the structure of such
complex data, but performing these inferences is generally difficult.
Message-passing algorithms, such as belief propagation, are a natural way to
disseminate evidence amongst correlated variables while exploiting the graph
structure, but these algorithms can struggle when the conditional dependency
graphs contain loops. Here we use Graph Neural Networks (GNNs) to learn a
message-passing algorithm that solves these inference tasks. We first show that
the architecture of GNNs is well-matched to inference tasks. We then
demonstrate the efficacy of this inference approach by training GNNs on an
ensemble of graphical models and showing that they substantially outperform
belief propagation on loopy graphs. Our message-passing algorithms generalize
out of the training set to larger graphs and graphs with different structure.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yoon_K/0/1/0/all/0/1&quot;&gt;KiJung Yoon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liao_R/0/1/0/all/0/1&quot;&gt;Renjie Liao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiong_Y/0/1/0/all/0/1&quot;&gt;Yuwen Xiong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1&quot;&gt;Lisa Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fetaya_E/0/1/0/all/0/1&quot;&gt;Ethan Fetaya&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Urtasun_R/0/1/0/all/0/1&quot;&gt;Raquel Urtasun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zemel_R/0/1/0/all/0/1&quot;&gt;Richard Zemel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pitkow_X/0/1/0/all/0/1&quot;&gt;Xaq Pitkow&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.07712">
<title>Causal Inference on Discrete Data via Estimating Distance Correlations. (arXiv:1803.07712v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1803.07712</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we deal with the problem of inferring causal directions when
the data is on discrete domain. By considering the distribution of the cause
$P(X)$ and the conditional distribution mapping cause to effect $P(Y|X)$ as
independent random variables, we propose to infer the causal direction via
comparing the distance correlation between $P(X)$ and $P(Y|X)$ with the
distance correlation between $P(Y)$ and $P(X|Y)$. We infer &quot;$X$ causes $Y$&quot; if
the dependence coefficient between $P(X)$ and $P(Y|X)$ is smaller. Experiments
are performed to show the performance of the proposed method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Liu_F/0/1/0/all/0/1&quot;&gt;Furui Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chan_L/0/1/0/all/0/1&quot;&gt;Laiwan Chan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.08101">
<title>Clustering to Reduce Spatial Data Set Size. (arXiv:1803.08101v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1803.08101</link>
<description rdf:parseType="Literal">&lt;p&gt;Traditionally it had been a problem that researchers did not have access to
enough spatial data to answer pressing research questions or build compelling
visualizations. Today, however, the problem is often that we have too much
data. Spatially redundant or approximately redundant points may refer to a
single feature (plus noise) rather than many distinct spatial features. We use
a machine learning approach with density-based clustering to compress such
spatial data into a set of representative features.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Boeing_G/0/1/0/all/0/1&quot;&gt;Geoff Boeing&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.08161">
<title>Entropy-based closure for probabilistic learning on manifolds. (arXiv:1803.08161v1 [math.PR])</title>
<link>http://arxiv.org/abs/1803.08161</link>
<description rdf:parseType="Literal">&lt;p&gt;In a recent paper, the authors proposed a general methodology for
probabilistic learning on manifolds. The method was used to generate numerical
samples that are statistically consistent with an existing dataset construed as
a realization from a non-Gaussian random vector. The manifold structure is
learned using diffusion manifolds and the statistical sample generation is
accomplished using a projected Ito stochastic differential equation. This
probabilistic learning approach has been extended to polynomial chaos
representation of databases on manifolds and to probabilistic nonconvex
constrained optimization with a fixed budget of function evaluations. The
methodology introduces an isotropic-diffusion kernel with hyperparameter
{\epsilon}. Currently, {\epsilon} is more or less arbitrarily chosen. In this
paper, we propose a selection criterion for identifying an optimal value of
{\epsilon}, based on a maximum entropy argument. The result is a comprehensive,
closed, probabilistic model for characterizing data sets with hidden
constraints. This entropy argument ensures that out of all possible models,
this is the one that is the most uncertain beyond any specified constraints,
which is selected. Applications are presented for several databases.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Soizea_C/0/1/0/all/0/1&quot;&gt;C. Soizea&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Ghanem_R/0/1/0/all/0/1&quot;&gt;R. Ghanem&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Safta_C/0/1/0/all/0/1&quot;&gt;C. Safta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Huan_X/0/1/0/all/0/1&quot;&gt;X. Huan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Vane_Z/0/1/0/all/0/1&quot;&gt;Z. P. Vane&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Oefelein_J/0/1/0/all/0/1&quot;&gt;J. Oefelein&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Lacaz_G/0/1/0/all/0/1&quot;&gt;G. Lacaz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Najm_H/0/1/0/all/0/1&quot;&gt;H. N. Najm&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Tang_Q/0/1/0/all/0/1&quot;&gt;Q. Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Chen_X/0/1/0/all/0/1&quot;&gt;X. Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.08178">
<title>Boosted Density Estimation Remastered. (arXiv:1803.08178v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1803.08178</link>
<description rdf:parseType="Literal">&lt;p&gt;There has recently been a steadily increase in the iterative approaches to
boosted density estimation and sampling, usually proceeding by adding candidate
&quot;iterate&quot; densities to a model that gets more accurate with iterations. The
relative accompanying burst of formal convergence results has not yet changed a
striking picture: all results essentially pay the price of heavy assumptions on
iterates, often unrealistic or hard to check, and offer a blatant contrast with
the original boosting theory where such assumptions would be the weakest
possible. In this paper, we show that all that suffices to achieve boosting for
\textit{density estimation} is a \emph{weak learner} in the original boosting
theory sense, that is, an oracle that supplies \textit{classifiers}. We provide
converge rates that comply with boosting requirements, being better and / or
relying on substantially weaker assumptions than the state of the art. One of
our rates is to our knowledge the first to rely on not just weak but also
\textit{empirically testable} assumptions. We show that the model fit belongs
to exponential families, and obtain in the course of our results a variational
characterization of $f$-divergences better than $f$-GAN&apos;s. Experimental results
on several simulated problems display significantly better results than AdaGAN
during early boosting rounds, in particular for mode capture, and using
architectures less than the fifth&apos;s of AdaGAN&apos;s size.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cranko_Z/0/1/0/all/0/1&quot;&gt;Zac Cranko&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nock_R/0/1/0/all/0/1&quot;&gt;Richard Nock&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.08182">
<title>Enforcing constraints for interpolation and extrapolation in Generative Adversarial Networks. (arXiv:1803.08182v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1803.08182</link>
<description rdf:parseType="Literal">&lt;p&gt;Generative Adversarial Networks (GANs) are becoming popular choices for
unsupervised learning. At the same time there is a concerted effort in the
machine learning community to expand the range of tasks in which learning can
be applied as well as to utilize methods from other disciplines to accelerate
learning. With this in mind, in the current work we suggest ways to enforce
given constraints in the output of a GAN both for interpolation and
extrapolation. The two cases need to be treated differently.
&lt;/p&gt;
&lt;p&gt;For the case of interpolation, the incorporation of constraints is built into
the training of the GAN. The incorporation of the constraints respects the
primary game-theoretic setup of a GAN so it can be combined with existing
algorithms. However, it can exacerbate the problem of instability during
training that is well-known for GANs. We suggest adding small noise to the
constraints as a simple remedy that has performed well in our numerical
experiments.
&lt;/p&gt;
&lt;p&gt;The case of extrapolation (prediction) is more involved. First, we employ a
modified interpolation training process that uses noisy data but does not
necessarily enforce the constraints during training. Second, the resulting
modified interpolator is used for extrapolation where the constraints are
enforced after each step through projection on the space of constraints.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stinis_P/0/1/0/all/0/1&quot;&gt;Panos Stinis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hagge_T/0/1/0/all/0/1&quot;&gt;Tobias Hagge&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tartakovsky_A/0/1/0/all/0/1&quot;&gt;Alexandre M. Tartakovsky&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yeung_E/0/1/0/all/0/1&quot;&gt;Enoch Yeung&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.08198">
<title>SUCAG: Stochastic Unbiased Curvature-aided Gradient Method for Distributed Optimization. (arXiv:1803.08198v1 [math.OC])</title>
<link>http://arxiv.org/abs/1803.08198</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose and analyze a new stochastic gradient method, which we call
Stochastic Unbiased Curvature-aided Gra- dient (SUCAG), for finite sum
optimization problems. SUCAG constitutes an unbiased total gradient tracking
technique that uses Hessian information to accelerate convergence. We an- alyze
our method under the general asynchronous model of computation, in which
functions are selected infinitely often, but with delays that can grow
sublinearly. For strongly convex problems, we establish linear convergence for
the SUCAG method. When the initialization point is sufficiently close to the
optimal solution, the established convergence rate is only dependent on the
condition number of the problem, making it strictly faster than the known rate
for the SAGA method.
&lt;/p&gt;
&lt;p&gt;Furthermore, we describe a Markov-driven approach of implementing the SUCAG
method in a distributed asynchronous multi-agent setting, via gossiping along a
random walk on the communication graph. We show that our analysis applies as
long as the undirected graph is connected and, notably, establishes an
asymptotic linear convergence rate that is robust to the graph topology.
Numerical results demonstrate the merit of our algorithm over existing methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Wai_H/0/1/0/all/0/1&quot;&gt;Hoi-To Wai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Freris_N/0/1/0/all/0/1&quot;&gt;Nikolaos M. Freris&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Nedic_A/0/1/0/all/0/1&quot;&gt;Angelia Nedic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Scaglione_A/0/1/0/all/0/1&quot;&gt;Anna Scaglione&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.08276">
<title>Speaker Clustering With Neural Networks And Audio Processing. (arXiv:1803.08276v1 [cs.SD])</title>
<link>http://arxiv.org/abs/1803.08276</link>
<description rdf:parseType="Literal">&lt;p&gt;Speaker clustering is the task of differentiating speakers in a recording. In
a way, the aim is to answer &quot;who spoke when&quot; in audio recordings. A common
method used in industry is feature extraction directly from the recording
thanks to MFCC features, and by using well-known techniques such as Gaussian
Mixture Models (GMM) and Hidden Markov Models (HMM). In this paper, we studied
neural networks (especially CNN) followed by clustering and audio processing in
the quest to reach similar accuracy to state-of-the-art methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jumelle_M/0/1/0/all/0/1&quot;&gt;Maxime Jumelle&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sakmeche_T/0/1/0/all/0/1&quot;&gt;Taqiyeddine Sakmeche&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.08312">
<title>Learning Eligibility in Clinical Cancer Trials using Deep Neural Networks. (arXiv:1803.08312v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1803.08312</link>
<description rdf:parseType="Literal">&lt;p&gt;Interventional clinical cancer trials are generally too restrictive and
cancer patients are often excluded from them on the basis of comorbidity, past
or concomitant treatments and the fact that they are over a certain age. The
efficacy and safety of new treatments for patients with these characteristics
are not, therefore, defined. In this work, we build a model with which to
automatically predict whether short clinical statements were considered
inclusion or exclusion criteria. We used clinical trials protocols on cancer
that have been available in public registries for the last 18 years to train
word embeddings, and constructed a dataset of 6M short free-texts labeled as
eligible or not eligible. We then trained and validated a text classifier,
using deep neural networks with pre-trained word-embedding as its inputs, to
predict whether or not short free-text statements describing clinical
information were considered eligible. The best model achieved an F-measure of
0.92 and an almost perfect agreement when employing a validation set of 800K
labeled statements. The trained model was also tested on an independent set of
clinical statements mimicking those used in routine clinical practice, yielding
a consistent performance. We additionally analyzed the semantic reasoning of
the word embedding representations obtained, and were able to identify
equivalent treatments for a type of tumor in an analogy with the drugs used to
treat other tumors. The present work shows that representation learning using
neural networks can be successfully leveraged to extract the medical knowledge
available on clinical trial protocols and potentially assist practitioners when
prescribing treatments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bustos_A/0/1/0/all/0/1&quot;&gt;Aurelia Bustos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pertusa_A/0/1/0/all/0/1&quot;&gt;Antonio Pertusa&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.08471">
<title>Locally Private Bayesian Inference for Count Models. (arXiv:1803.08471v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1803.08471</link>
<description rdf:parseType="Literal">&lt;p&gt;As more aspects of social interaction are digitally recorded, there is a
growing need to develop privacy-preserving data analysis methods. Social
scientists will be more likely to adopt these methods if doing so entails
minimal change to their current methodology. Toward that end, we present a
general and modular method for privatizing Bayesian inference for Poisson
factorization, a broad class of models that contains some of the most widely
used models in the social sciences. Our method satisfies local differential
privacy, which ensures that no single centralized server need ever store the
non-privatized data. To formulate our local-privacy guarantees, we introduce
and focus on limited-precision local privacy---the local privacy analog of
limited-precision differential privacy (Flood et al., 2013). We present two
case studies, one involving social networks and one involving text corpora,
that test our method&apos;s ability to form the posterior distribution over latent
variables under different levels of noise, and demonstrate our method&apos;s utility
over a na\&quot;{i}ve approach, wherein inference proceeds as usual, treating the
privatized data as if it were not privatized.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Schein_A/0/1/0/all/0/1&quot;&gt;Aaron Schein&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wu_Z/0/1/0/all/0/1&quot;&gt;Zhiwei Steven Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhou_M/0/1/0/all/0/1&quot;&gt;Mingyuan Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wallach_H/0/1/0/all/0/1&quot;&gt;Hanna Wallach&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.08475">
<title>Attention Solves Your TSP. (arXiv:1803.08475v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1803.08475</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a framework for solving combinatorial optimization problems of
which the output can be represented as a sequence of input elements. As an
alternative to the Pointer Network, we parameterize a policy by a model based
entirely on (graph) attention layers, and train it efficiently using REINFORCE
with a simple and robust baseline based on a deterministic (greedy) rollout of
the best policy found during training. We significantly improve over
state-of-the-art results for learning algorithms for the 2D Euclidean TSP,
reducing the optimality gap for a single tour construction by more than 75% (to
0.33%) and 50% (to 2.28%) for instances with 20 and 50 nodes respectively.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kool_W/0/1/0/all/0/1&quot;&gt;W.W.M. Kool&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Welling_M/0/1/0/all/0/1&quot;&gt;M. Welling&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1410.3351">
<title>Ricci Curvature and the Manifold Learning Problem. (arXiv:1410.3351v5 [math.DG] UPDATED)</title>
<link>http://arxiv.org/abs/1410.3351</link>
<description rdf:parseType="Literal">&lt;p&gt;Consider a sample of $n$ points taken i.i.d from a submanifold $\Sigma$ of
Euclidean space. We show that there is a way to estimate the Ricci curvature of
$\Sigma$ with respect to the induced metric from the sample. Our method is
grounded in the notions of Carr\&apos;e du Champ for diffusion semi-groups, the
theory of Empirical processes and local Principal Component Analysis.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Ache_A/0/1/0/all/0/1&quot;&gt;Antonio G. Ache&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Warren_M/0/1/0/all/0/1&quot;&gt;Micah W. Warren&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1609.05148">
<title>Discovering Relationships and their Structures Across Disparate Data Modalities. (arXiv:1609.05148v5 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1609.05148</link>
<description rdf:parseType="Literal">&lt;p&gt;Determining how certain properties are related to other properties is
fundamental to scientific discovery. As data collection rates accelerate, it is
becoming increasingly difficult yet ever more important to determine whether
one property of data (e.g., cloud density) is related to another (e.g., grass
wetness). Only if two properties are related are further investigations into
the geometry of the relationship warranted. While existing approaches can test
whether two properties are related, they may require unfeasibly large sample
sizes in real data scenarios, and do not address how they are related. Our key
insight is that one can adaptively restrict the analysis to the &quot;jointly local&quot;
observations---that is, one can estimate the scales with the most informative
neighbors for determining the existence and geometry of a relationship.
&quot;Multiscale Graph Correlation&quot; (MGC) is a framework that extends global
procedures to be multiscale; consequently, MGC tests typically require far
fewer samples than existing methods for a wide variety of dependence structures
and dimensionalities, while maintaining computational efficiency. Moreover, MGC
provides a simple and elegant multiscale characterization of the potentially
complex latent geometry underlying the relationship. In several real data
applications, MGC uniquely detects the presence and reveals the geometry of the
relationships.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Shen_C/0/1/0/all/0/1&quot;&gt;Cencheng Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wang_Q/0/1/0/all/0/1&quot;&gt;Qing Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Priebe_C/0/1/0/all/0/1&quot;&gt;Carey E. Priebe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Maggioni_M/0/1/0/all/0/1&quot;&gt;Mauro Maggioni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Vogelstein_J/0/1/0/all/0/1&quot;&gt;Joshua T. Vogelstein&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1704.06977">
<title>Adaptive Estimation in Structured Factor Models with Applications to Overlapping Clustering. (arXiv:1704.06977v3 [stat.ME] UPDATED)</title>
<link>http://arxiv.org/abs/1704.06977</link>
<description rdf:parseType="Literal">&lt;p&gt;This work introduces a novel estimation method, called LOVE, of the entries
and structure of a loading matrix A in a sparse latent factor model X = AZ + E,
for an observable random vector X in Rp, with correlated unobservable factors Z
\in RK, with K unknown, and independent noise E. Each row of A is scaled and
sparse. In order to identify the loading matrix A, we require the existence of
pure variables, which are components of X that are associated, via A, with one
and only one latent factor. Despite the fact that the number of factors K, the
number of the pure variables, and their location are all unknown, we only
require a mild condition on the covariance matrix of Z, and a minimum of only
two pure variables per latent factor to show that A is uniquely defined, up to
signed permutations. Our proofs for model identifiability are constructive, and
lead to our novel estimation method of the number of factors and of the set of
pure variables, from a sample of size n of observations on X. This is the first
step of our LOVE algorithm, which is optimization-free, and has low
computational complexity of order p2. The second step of LOVE is an easily
implementable linear program that estimates A. We prove that the resulting
estimator is minimax rate optimal up to logarithmic factors in p. The model
structure is motivated by the problem of overlapping variable clustering,
ubiquitous in data science. We define the population level clusters as groups
of those components of X that are associated, via the sparse matrix A, with the
same unobservable latent factor, and multi-factor association is allowed.
Clusters are respectively anchored by the pure variables, and form overlapping
sub-groups of the p-dimensional random vector X. The Latent model approach to
OVErlapping clustering is reflected in the name of our algorithm, LOVE.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bing_X/0/1/0/all/0/1&quot;&gt;Xin Bing&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bunea_F/0/1/0/all/0/1&quot;&gt;Florentina Bunea&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ning_Y/0/1/0/all/0/1&quot;&gt;Yang Ning&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wegkamp_M/0/1/0/all/0/1&quot;&gt;Marten Wegkamp&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.11469">
<title>Conditional Variance Penalties and Domain Shift Robustness. (arXiv:1710.11469v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1710.11469</link>
<description rdf:parseType="Literal">&lt;p&gt;When training a deep network for image classification, one can broadly
distinguish between two types of latent features of images that will drive the
classification. Following the notation of Gong et al. (2016), we can divide
latent features into (i) &quot;core&quot; features $X^\text{core}$ whose distribution
$X^\text{core}\vert Y$ does not change substantially across domains and (ii)
&quot;style&quot; features $X^{\text{style}}$ whose distribution $X^{\text{style}}\vert
Y$ can change substantially across domains. These latter orthogonal features
would generally include features such as rotation, image quality or brightness
but also more complex ones like hair color or posture for images of persons.
Guarding against future adversarial domain shifts implies that the influence of
the second type of style features in the prediction has to be limited. We
assume that the domain itself is not observed and hence a latent variable. We
do assume, however, that we can sometimes observe a typically discrete
identifier or $\mathrm{ID}$ variable. We know in some applications, for
example, that two images show the same person, and $\mathrm{ID}$ then refers to
the identity of the person. The method requires only a small fraction of images
to have an $\mathrm{ID}$ variable. We group data samples if they share the same
class and identifier $(Y,\mathrm{ID})=(y,\mathrm{id})$ and penalize the
conditional variance of the prediction if we condition on $(Y,\mathrm{ID})$.
Using this approach is shown to protect against shifts in the distribution of
the style variables for both regression and classification models.
Specifically, the conditional variance penalty CoRe is shown to be equivalent
to minimizing the risk under noise interventions in a regression setting and is
shown to lead to adversarial risk consistency in a partially linear
classification setting.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Heinze_Deml_C/0/1/0/all/0/1&quot;&gt;Christina Heinze-Deml&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Meinshausen_N/0/1/0/all/0/1&quot;&gt;Nicolai Meinshausen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.03848">
<title>Region Detection in Markov Random Fields: Gaussian Case. (arXiv:1802.03848v6 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1802.03848</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work we consider the problem of model selection in Gaussian Markov
fields in the sample deficient scenario. The benchmark information-theoretic
results in the case of d-regular graphs require the number of samples to be at
least proportional to the logarithm of the number of vertices to allow
consistent graph recovery. When the number of samples is less than this amount,
reliable detection of all edges is impossible. In many applications, it is more
important to learn the distribution of the edge (coupling) parameters over the
network than the specific locations of the edges. Assuming that the entire
graph can be partitioned into a number of spatial regions with similar edge
parameters and reasonably regular boundaries, we develop new
information-theoretic sample complexity bounds and show that even bounded
number of samples can be enough to consistently recover these regions. We also
introduce and analyze an efficient region growing algorithm capable of
recovering the regions with high accuracy. We show that it is consistent and
demonstrate its performance benefits in synthetic simulations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Soloveychik_I/0/1/0/all/0/1&quot;&gt;Ilya Soloveychik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tarokh_V/0/1/0/all/0/1&quot;&gt;Vahid Tarokh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09902">
<title>Attention-Based Guided Structured Sparsity of Deep Neural Networks. (arXiv:1802.09902v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1802.09902</link>
<description rdf:parseType="Literal">&lt;p&gt;Network pruning is aimed at imposing sparsity in a neural network
architecture by increasing the portion of zero-valued weights for reducing its
size regarding energy-efficiency consideration and increasing evaluation speed.
In most of the conducted research efforts, the sparsity is enforced for network
pruning without any attention to the internal network characteristics such as
unbalanced outputs of the neurons or more specifically the distribution of the
weights and outputs of the neurons. That may cause severe accuracy drop due to
uncontrolled sparsity. In this work, we propose an attention mechanism that
simultaneously controls the sparsity intensity and supervised network pruning
by keeping important information bottlenecks of the network to be active. On
CIFAR-10, the proposed method outperforms the best baseline method by 6% and
reduced the accuracy drop by 2.6x at the same level of sparsity.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Torfi_A/0/1/0/all/0/1&quot;&gt;Amirsina Torfi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shirvani_R/0/1/0/all/0/1&quot;&gt;Rouzbeh A. Shirvani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Soleymani_S/0/1/0/all/0/1&quot;&gt;Sobhan Soleymani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nasrabadi_N/0/1/0/all/0/1&quot;&gt;Nasser M. Nasrabadi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.02922">
<title>Fast Convergence for Stochastic and Distributed Gradient Descent in the Interpolation Limit. (arXiv:1803.02922v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1803.02922</link>
<description rdf:parseType="Literal">&lt;p&gt;Modern supervised learning techniques, particularly those using so called
deep nets, involve fitting high dimensional labelled data sets with functions
containing very large numbers of parameters. Much of this work is empirical,
and interesting phenomena have been observed that require theoretical
explanations, however the non-convexity of the loss functions complicates the
analysis. Recently it has been proposed that some of the success of these
techniques resides in the effectiveness of the simple stochastic gradient
descent algorithm in the so called interpolation limit in which all labels are
fit perfectly. This analysis is made possible since the SGD algorithm reduces
to a stochastic linear system near the interpolating minimum of the loss
function. Here we exploit this insight by analyzing a distributed algorithm for
gradient descent, also in the interpolating limit. The algorithm corresponds to
gradient descent applied to a simple penalized distributed loss function,
$L({\bf w}_1,...,{\bf w}_n) = \Sigma_i l_i({\bf w}_i) + \mu \sum_{&amp;lt;i,j&amp;gt;}|{\bf
w}_i-{\bf w}_j|^2$. Here each node is allowed its own parameter vector and
$&amp;lt;i,j&amp;gt;$ denotes edges of a connected graph defining the communication links
between nodes. It is shown that this distributed algorithm converges linearly
(ie the error reduces exponentially with iteration number), with a rate
$1-\frac{\eta}{n}\lambda_{min}(H)&amp;lt;R&amp;lt;1$ where $\lambda_{min}(H)$ is the smallest
nonzero eigenvalue of the sample covariance or the Hessian H. In contrast with
previous usage of similar penalty functions to enforce consensus between nodes,
in the interpolating limit it is not required to take the penalty parameter to
infinity for consensus to occur. The analysis further reinforces the utility of
this limit in the theoretical treatment of modern machine learning algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mitra_P/0/1/0/all/0/1&quot;&gt;Partha P Mitra&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.07612">
<title>Generative Multi-Agent Behavioral Cloning. (arXiv:1803.07612v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1803.07612</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose and study the problem of generative multi-agent behavioral
cloning, where the goal is to learn a generative multi-agent policy from
pre-collected demonstration data. Building upon advances in deep generative
models, we present a hierarchical policy framework that can tractably learn
complex mappings from input states to distributions over multi-agent action
spaces. Our framework is flexible and can incorporate high-level domain
knowledge into the structure of the underlying deep graphical model. For
instance, we can effectively learn low-dimensional structures, such as
long-term goals and team coordination, from data. Thus, an additional benefit
of our hierarchical approach is the ability to plan over multiple time scales
for effective long-term planning. We showcase our approach in an application of
modeling team offensive play from basketball tracking data. We show how to
instantiate our framework to effectively model complex interactions between
basketball players and generate realistic multi-agent trajectories of
basketball gameplay over long time periods. We validate our approach using both
quantitative and qualitative evaluations, including a user study comparison
conducted with professional sports analysts.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhan_E/0/1/0/all/0/1&quot;&gt;Eric Zhan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_S/0/1/0/all/0/1&quot;&gt;Stephan Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yue_Y/0/1/0/all/0/1&quot;&gt;Yisong Yue&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lucey_P/0/1/0/all/0/1&quot;&gt;Patrick Lucey&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.07954">
<title>Resilient Monotone Sequential Maximization. (arXiv:1803.07954v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1803.07954</link>
<description rdf:parseType="Literal">&lt;p&gt;Applications in machine learning, optimization, and control require the
sequential selection of a few system elements, such as sensors, data, or
actuators, to optimize the system performance across multiple time steps.
However, in failure-prone and adversarial environments, sensors get attacked,
data get deleted, and actuators fail. Thence, traditional sequential design
paradigms become insufficient and, in contrast, resilient sequential designs
that adapt against system-wide attacks, deletions, or failures become
important. In general, resilient sequential design problems are computationally
hard. Also, even though they often involve objective functions that are
monotone and (possibly) submodular, no scalable approximation algorithms are
known for their solution. In this paper, we provide the first scalable
algorithm, that achieves the following characteristics: system-wide resiliency,
i.e., the algorithm is valid for any number of denial-of-service attacks,
deletions, or failures; adaptiveness, i.e., at each time step, the algorithm
selects system elements based on the history of inflicted attacks, deletions,
or failures; and provable approximation performance, i.e., the algorithm
guarantees for monotone objective functions a solution close to the optimal. We
quantify the algorithm&apos;s approximation performance using a notion of curvature
for monotone (not necessarily submodular) set functions. Finally, we support
our theoretical analyses with simulated experiments, by considering a
control-aware sensor scheduling scenario, namely, sensing-constrained robot
navigation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tzoumas_V/0/1/0/all/0/1&quot;&gt;Vasileios Tzoumas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Jadbabaie_A/0/1/0/all/0/1&quot;&gt;Ali Jadbabaie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pappas_G/0/1/0/all/0/1&quot;&gt;George J. Pappas&lt;/a&gt;</dc:creator>
</item></rdf:RDF>