<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Boring papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Bad Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-05-20T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.06924"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.06992"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07035"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07069"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07075"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07196"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07233"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07239"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07349"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1708.07918"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.10489"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.08094"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.09238"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.04238"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.06632"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.06915"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.06951"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07006"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07051"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07113"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07179"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07194"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07206"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07220"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07281"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07300"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07331"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07346"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1610.00768"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.02840"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.00996"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.10311"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.05345"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.04018"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.06605"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1805.06924">
<title>Learning is Compiling: Experience Shapes Concept Learning by Combining Primitives in a Language of Thought. (arXiv:1805.06924v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1805.06924</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent approaches to human concept learning have successfully combined the
power of symbolic, infinitely productive, rule systems and statistical
learning. The aim of most of these studies is to reveal the underlying language
structuring these representations and providing a general substrate for
thought. Here, we ask about the plasticity of symbolic descriptive languages.
We perform two concept learning experiments, that consistently demonstrate that
humans can change very rapidly the repertoire of symbols they use to identify
concepts, by compiling expressions which are frequently used into new symbols
of the language. The pattern of concept learning times is accurately described
by a Bayesian agent that rationally updates the probability of compiling a new
expression according to how useful it has been to compress concepts so far. By
portraying the Language of Thought as a flexible system of rules, we also
highlight the intrinsic difficulties to pin it down empirically.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tano_P/0/1/0/all/0/1&quot;&gt;Pablo Tano&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Romano_S/0/1/0/all/0/1&quot;&gt;Sergio Romano&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sigman_M/0/1/0/all/0/1&quot;&gt;Mariano Sigman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Salles_A/0/1/0/all/0/1&quot;&gt;Alejo Salles&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Figueira_S/0/1/0/all/0/1&quot;&gt;Santiago Figueira&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.06992">
<title>Practical Algorithms for STV and Ranked Pairs with Parallel Universes Tiebreaking. (arXiv:1805.06992v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1805.06992</link>
<description rdf:parseType="Literal">&lt;p&gt;STV and ranked pairs (RP) are two well-studied voting rules for group
decision-making. They proceed in multiple rounds, and are affected by how ties
are broken in each round. However, the literature is surprisingly vague about
how ties should be broken. We propose the first algorithms for computing the
set of alternatives that are winners under some tiebreaking mechanism under STV
and RP, which is also known as parallel-universes tiebreaking (PUT).
Unfortunately, PUT-winners are NP-complete to compute under STV and RP, and
standard search algorithms from AI do not apply. We propose multiple DFS-based
algorithms along with pruning strategies and heuristics to prioritize search
direction to significantly improve the performance using machine learning. We
also propose novel ILP formulations for PUT-winners under STV and RP,
respectively. Experiments on synthetic and real-world data show that our
algorithms are overall significantly faster than ILP, while there are a few
cases where ILP is significantly faster for RP.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jun Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sikdar_S/0/1/0/all/0/1&quot;&gt;Sujoy Sikdar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shepherd_T/0/1/0/all/0/1&quot;&gt;Tyler Shepherd&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_Z/0/1/0/all/0/1&quot;&gt;Zhibing Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_C/0/1/0/all/0/1&quot;&gt;Chunheng Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xia_L/0/1/0/all/0/1&quot;&gt;Lirong Xia&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07035">
<title>Automated Process Planning for Hybrid Manufacturing. (arXiv:1805.07035v1 [cs.CG])</title>
<link>http://arxiv.org/abs/1805.07035</link>
<description rdf:parseType="Literal">&lt;p&gt;Hybrid manufacturing (HM) technologies combine additive and subtractive
manufacturing (AM/SM) capabilities, leveraging AM&apos;s strengths in fabricating
complex geometries and SM&apos;s precision and quality to produce finished parts. We
present a systematic approach to automated computer-aided process planning
(CAPP) for HM that can identify non-trivial, qualitatively distinct, and
cost-optimal combinations of AM/SM modalities. A multimodal HM process plan is
represented by a finite Boolean expression of AM and SM manufacturing
primitives, such that the expression evaluates to an &apos;as-manufactured&apos;
artifact. We show that primitives that respect spatial constraints such as
accessibility and collision avoidance may be constructed by solving inverse
configuration space problems on the &apos;as-designed&apos; artifact and manufacturing
instruments. The primitives generate a finite Boolean algebra (FBA) that
enumerates the entire search space for planning. The FBA&apos;s canonical
intersection terms (i.e., &apos;atoms&apos;) provide the complete domain decomposition to
reframe manufacturability analysis and process planning into purely symbolic
reasoning, once a subcollection of atoms is found to be interchangeable with
the design target. The approach subsumes unimodal (all-AM or all-SM) process
planning as special cases. We demonstrate the practical potency of our
framework and its computational efficiency when applied to process planning of
complex 3D parts with dramatically different AM and SM instruments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Behandish_M/0/1/0/all/0/1&quot;&gt;Morad Behandish&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nelaturi_S/0/1/0/all/0/1&quot;&gt;Saigopal Nelaturi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kleer_J/0/1/0/all/0/1&quot;&gt;Johan de Kleer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07069">
<title>Multifunction Cognitive Radar Task Scheduling Using Monte Carlo Tree Search and Policy Networks. (arXiv:1805.07069v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1805.07069</link>
<description rdf:parseType="Literal">&lt;p&gt;A modern radar may be designed to perform multiple functions, such as
surveillance, tracking, and fire control. Each function requires the radar to
execute a number of transmit-receive tasks. A radar resource management (RRM)
module makes decisions on parameter selection, prioritization, and scheduling
of such tasks. RRM becomes especially challenging in overload situations, where
some tasks may need to be delayed or even dropped. In general, task scheduling
is an NP-hard problem. In this work, we develop the branch-and-bound (B&amp;amp;B)
method which obtains the optimal solution but at exponential computational
complexity. On the other hand, heuristic methods have low complexity but
provide relatively poor performance. We resort to machine learning-based
techniques to address this issue; specifically we propose an approximate
algorithm based on the Monte Carlo tree search method. Along with using bound
and dominance rules to eliminate nodes from the search tree, we use a policy
network to help to reduce the width of the search. Such a network can be
trained using solutions obtained by running the B&amp;amp;B method offline on problems
with feasible complexity. We show that the proposed method provides
near-optimal performance, but with computational complexity orders of magnitude
smaller than the B&amp;amp;B algorithm.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shaghaghi_M/0/1/0/all/0/1&quot;&gt;Mahdi Shaghaghi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Adve_R/0/1/0/all/0/1&quot;&gt;Raviraj S. Adve&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ding_Z/0/1/0/all/0/1&quot;&gt;Zhen Ding&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07075">
<title>Trusted Neural Networks for Safety-Constrained Autonomous Control. (arXiv:1805.07075v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.07075</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose Trusted Neural Network (TNN) models, which are deep neural network
models that satisfy safety constraints critical to the application domain. We
investigate different mechanisms for incorporating rule-based knowledge in the
form of first-order logic constraints into a TNN model, where rules that encode
safety are accompanied by weights indicating their relative importance. This
framework allows the TNN model to learn from knowledge available in form of
data as well as logical rules. We propose multiple approaches for solving this
problem: (a) a multi-headed model structure that allows trade-off between
satisfying logical constraints and fitting training data in a unified training
framework, and (b) creating a constrained optimization problem and solving it
in dual formulation by posing a new constrained loss function and using a
proximal gradient descent algorithm. We demonstrate the efficacy of our TNN
framework through experiments using the open-source TORCS~\cite{BernhardCAA15}
3D simulator for self-driving cars. Experiments using our first approach of a
multi-headed TNN model, on a dataset generated by a customized version of
TORCS, show that (1) adding safety constraints to a neural network model
results in increased performance and safety, and (2) the improvement increases
with increasing importance of the safety constraints. Experiments were also
performed using the second approach of proximal algorithm for constrained
optimization --- they demonstrate how the proposed method ensures that (1) the
overall TNN model satisfies the constraints even when the training data
violates some of the constraints, and (2) the proximal gradient descent
algorithm on the constrained objective converges faster than the unconstrained
version.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghosh_S/0/1/0/all/0/1&quot;&gt;Shalini Ghosh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mercier_A/0/1/0/all/0/1&quot;&gt;Amaury Mercier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pichapati_D/0/1/0/all/0/1&quot;&gt;Dheeraj Pichapati&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jha_S/0/1/0/all/0/1&quot;&gt;Susmit Jha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yegneswaran_V/0/1/0/all/0/1&quot;&gt;Vinod Yegneswaran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lincoln_P/0/1/0/all/0/1&quot;&gt;Patrick Lincoln&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07196">
<title>Supervisory Control of Probabilistic Discrete Event Systems under Partial Observation. (arXiv:1805.07196v1 [cs.SY])</title>
<link>http://arxiv.org/abs/1805.07196</link>
<description rdf:parseType="Literal">&lt;p&gt;The supervisory control of probabilistic discrete event systems (PDESs) is
investigated under the assumptions that the supervisory controller (supervisor)
is probabilistic and has a partial observation. The probabilistic P-supervisor
is defined, which specifies a probability distribution on the control patterns
for each observation. The notions of the probabilistic controllability and
observability are proposed and demonstrated to be a necessary and sufficient
conditions for the existence of the probabilistic P-supervisors. Moreover, the
polynomial verification algorithms for the probabilistic controllability and
observability are put forward. In addition, the infimal probabilistic
controllable and observable superlanguage is introduced and computed as the
solution of the optimal control problem of PDESs. Several examples are
presented to illustrate the results obtained.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deng_W/0/1/0/all/0/1&quot;&gt;Weilin Deng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1&quot;&gt;Jingkai Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qiu_D/0/1/0/all/0/1&quot;&gt;Daowen Qiu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07233">
<title>Interpretable Parallel Recurrent Neural Networks with Convolutional Attentions for Multi-Modality Activity Modeling. (arXiv:1805.07233v1 [cs.HC])</title>
<link>http://arxiv.org/abs/1805.07233</link>
<description rdf:parseType="Literal">&lt;p&gt;Multimodal features play a key role in wearable sensor-based human activity
recognition (HAR). Selecting the most salient features adaptively is a
promising way to maximize the effectiveness of multimodal sensor data. In this
regard, we propose a &quot;collect fully and select wisely&quot; principle as well as an
interpretable parallel recurrent model with convolutional attentions to improve
the recognition performance. We first collect modality features and the
relations between each pair of features to generate activity frames, and then
introduce an attention mechanism to select the most prominent regions from
activity frames precisely. The selected frames not only maximize the
utilization of valid features but also reduce the number of features to be
computed effectively. We further analyze the accuracy and interpretability of
the proposed model based on extensive experiments. The results show that our
model achieves competitive performance on two benchmarked datasets and works
well in real life scenarios.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_K/0/1/0/all/0/1&quot;&gt;Kaixuan Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yao_L/0/1/0/all/0/1&quot;&gt;Lina Yao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;Xianzhi Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1&quot;&gt;Dalin Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gu_T/0/1/0/all/0/1&quot;&gt;Tao Gu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1&quot;&gt;Zhiwen Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1&quot;&gt;Zheng Yang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07239">
<title>Translation of Algorithmic Descriptions of Discrete Functions to SAT with Applications to Cryptanalysis Problems. (arXiv:1805.07239v1 [cs.LO])</title>
<link>http://arxiv.org/abs/1805.07239</link>
<description rdf:parseType="Literal">&lt;p&gt;In the present paper we describe the technology for translating algorithmic
descriptions of discrete functions to SAT. The proposed methods and algorithms
of translation are aimed at application to the problems of SAT-based
cryptanalysis. In the theoretical part of the paper we justify the main
principles of general reduction to SAT for discrete functions from a class
containing the majority of functions employed in cryptography. Based on these
principles we describe the Transalg software system, developed with SAT-based
cryptanalysis specifics in mind. We show the results of applications of
Transalg to construction of a number of attacks on various cryptographic
functions. Some of the corresponding attacks are state of the art. In the paper
we also present the vast experimental data, obtained using the SAT-solvers that
took first places at the SAT-competitions in the recent several years.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Semenov_A/0/1/0/all/0/1&quot;&gt;Alexander Semenov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Otpuschennikov_I/0/1/0/all/0/1&quot;&gt;Ilya Otpuschennikov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gribanova_I/0/1/0/all/0/1&quot;&gt;Irina Gribanova&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zaikin_O/0/1/0/all/0/1&quot;&gt;Oleg Zaikin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kochemazov_S/0/1/0/all/0/1&quot;&gt;Stepan Kochemazov&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07349">
<title>GumBolt: Extending Gumbel trick to Boltzmann priors. (arXiv:1805.07349v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.07349</link>
<description rdf:parseType="Literal">&lt;p&gt;Boltzmann machines (BMs) are appealing candidates for powerful priors in
variational autoencoders (VAEs), as they are capable of capturing nontrivial
and multi-modal distributions over discrete variables. However,
indifferentiability of the discrete units prohibits using the
reparameterization trick, essential for low-noise back propagation. The Gumbel
trick resolves this problem in a consistent way by relaxing the variables and
distributions, but it is incompatible with BM priors. Here, we propose the
GumBolt, a model that extends the Gumbel trick to BM priors in VAEs. GumBolt is
significantly simpler than the recently proposed methods with BM prior and
outperforms them by a considerable margin. It achieves state-of-the-art
performance on permutation invariant MNIST and OMNIGLOT datasets in the scope
of models with only discrete latent variables. Moreover, the performance can be
further improved by allowing multi-sampled (importance-weighted) estimation of
log-likelihood in training, which was not possible with previous models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khoshaman_A/0/1/0/all/0/1&quot;&gt;Amir H. Khoshaman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Amin_M/0/1/0/all/0/1&quot;&gt;Mohammad H. Amin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1708.07918">
<title>Robust Task Clustering for Deep Many-Task Learning. (arXiv:1708.07918v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1708.07918</link>
<description rdf:parseType="Literal">&lt;p&gt;We investigate task clustering for deep-learning based multi-task and
few-shot learning in a many-task setting. We propose a new method to measure
task similarities with cross-task transfer performance matrix for the deep
learning scenario. Although this matrix provides us critical information
regarding similarity between tasks, its asymmetric property and unreliable
performance scores can affect conventional clustering methods adversely.
Additionally, the uncertain task-pairs, i.e., the ones with extremely
asymmetric transfer scores, may collectively mislead clustering algorithms to
output an inaccurate task-partition. To overcome these limitations, we propose
a novel task-clustering algorithm by using the matrix completion technique. The
proposed algorithm constructs a partially-observed similarity matrix based on
the certainty of cluster membership of the task-pairs. We then use a matrix
completion algorithm to complete the similarity matrix. Our theoretical
analysis shows that under mild constraints, the proposed algorithm will
perfectly recover the underlying &quot;true&quot; similarity matrix with a high
probability. Our results show that the new task clustering method can discover
task clusters for training flexible and superior neural network models in a
multi-task learning setup for sentiment classification and dialog intent
classification tasks. Our task clustering approach also extends metric-based
few-shot learning methods to adapt multiple metrics, which demonstrates
empirical advantages when the tasks are diverse.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_M/0/1/0/all/0/1&quot;&gt;Mo Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_X/0/1/0/all/0/1&quot;&gt;Xiaoxiao Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yi_J/0/1/0/all/0/1&quot;&gt;Jinfeng Yi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chang_S/0/1/0/all/0/1&quot;&gt;Shiyu Chang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Potdar_S/0/1/0/all/0/1&quot;&gt;Saloni Potdar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tesauro_G/0/1/0/all/0/1&quot;&gt;Gerald Tesauro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1&quot;&gt;Haoyu Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_B/0/1/0/all/0/1&quot;&gt;Bowen Zhou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.10489">
<title>Self-supervised Deep Reinforcement Learning with Generalized Computation Graphs for Robot Navigation. (arXiv:1709.10489v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1709.10489</link>
<description rdf:parseType="Literal">&lt;p&gt;Enabling robots to autonomously navigate complex environments is essential
for real-world deployment. Prior methods approach this problem by having the
robot maintain an internal map of the world, and then use a localization and
planning method to navigate through the internal map. However, these approaches
often include a variety of assumptions, are computationally intensive, and do
not learn from failures. In contrast, learning-based methods improve as the
robot acts in the environment, but are difficult to deploy in the real-world
due to their high sample complexity. To address the need to learn complex
policies with few samples, we propose a generalized computation graph that
subsumes value-based model-free methods and model-based methods, with specific
instantiations interpolating between model-free and model-based. We then
instantiate this graph to form a navigation model that learns from raw images
and is sample efficient. Our simulated car experiments explore the design
decisions of our navigation model, and show our approach outperforms
single-step and $N$-step double Q-learning. We also evaluate our approach on a
real-world RC car and show it can learn to navigate through a complex indoor
environment with a few hours of fully autonomous, self-supervised training.
Videos of the experiments and code can be found at github.com/gkahn13/gcg
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kahn_G/0/1/0/all/0/1&quot;&gt;Gregory Kahn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Villaflor_A/0/1/0/all/0/1&quot;&gt;Adam Villaflor&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ding_B/0/1/0/all/0/1&quot;&gt;Bosen Ding&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1&quot;&gt;Pieter Abbeel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1&quot;&gt;Sergey Levine&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.08094">
<title>Adaptive Recurrent Neural Network via Persistent Memory. (arXiv:1801.08094v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1801.08094</link>
<description rdf:parseType="Literal">&lt;p&gt;Although Recurrent Neural Network (RNN) has been a powerful tool for modeling
sequential data, its performance is inadequate when processing sequences with
multiple patterns. In this paper, we address this challenge by introducing a
persistent memory and constructing an adaptive RNN. The persistent memory
augmented RNN (termed as PRNN) captures the principle patterns in training
sequences and stores them in an external memory. By leveraging the persistent
memory, the proposed method can adaptively update states according to the
similarities between encoded inputs and memory slots, leading to a stronger
capacity in assimilating sequences with multiple patterns. Content-based
addressing is suggested in memory accessing, and gradient descent is utilized
for implicitly updating the memory. Our approach can be further extended by
combining the prior knowledge of data. Experiments on several datasets
demonstrate the effectiveness of our method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_K/0/1/0/all/0/1&quot;&gt;Kui Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yuechuan Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1&quot;&gt;Chi Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1&quot;&gt;Cheng Yang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.09238">
<title>Semi-Supervised Learning with Declaratively Specified Entropy Constraints. (arXiv:1804.09238v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1804.09238</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a technique for declaratively specifying strategies for
semi-supervised learning (SSL). The proposed method can be used to specify
ensembles of semi-supervised learning, as well as agreement constraints and
entropic regularization constraints between these learners, and can be used to
model both well-known heuristics such as co-training and novel domain-specific
heuristics. In addition to representing individual SSL heuristics, we show that
multiple heuristics can also be automatically combined using Bayesian
optimization methods. We show consistent improvements on a suite of
well-studied SSL benchmarks, including a new state-of-the-art result on a
difficult relation extraction task.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_H/0/1/0/all/0/1&quot;&gt;Haitian Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cohen_W/0/1/0/all/0/1&quot;&gt;William W. Cohen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bing_L/0/1/0/all/0/1&quot;&gt;Lidong Bing&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.04238">
<title>Stochastic Approximation for Risk-aware Markov Decision Processes. (arXiv:1805.04238v2 [math.OC] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1805.04238</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we develop a stochastic approximation type algorithm to solve
finite state and action, infinite-horizon, risk-aware Markov decision
processes. Our algorithm is based on solving stochastic saddle-point problems
for risk estimation and doing $Q$-learning for finding the optimal risk-aware
policy. We show that several widely investigated risk measures (e.g.
conditional value-at-risk, optimized certainty equivalent, and absolute
semi-deviation) can be expressed as such stochastic saddle-point problems. We
establish the almost sure convergence and convergence rate results for our
overall algorithm. For error tolerance $\epsilon$ and learning rate $k$, the
convergence rate of our algorithm is
$\Omega((\ln(1/\delta\epsilon)/\epsilon^{2})^{1/k}+(\ln(1/\epsilon))^{1/(1-k)})$
with probability $1-\delta$.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Huang_W/0/1/0/all/0/1&quot;&gt;Wenjie Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Haskell_W/0/1/0/all/0/1&quot;&gt;William B. Haskell&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.06632">
<title>Preference Elicitation and Robust Optimization with Multi-Attribute Quasi-Concave Choice Functions. (arXiv:1805.06632v1 [q-fin.RM] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1805.06632</link>
<description rdf:parseType="Literal">&lt;p&gt;Decision maker&apos;s preferences are often captured by some choice functions
which are used to rank prospects. In this paper, we consider ambiguity in
choice functions over a multi-attribute prospect space. Our main result is a
robust preference model where the optimal decision is based on the worst-case
choice function from an ambiguity set constructed through preference
elicitation with pairwise comparisons of prospects. Differing from existing
works in the area, our focus is on quasi-concave choice functions rather than
concave functions and this enables us to cover a wide range of utility/risk
preference problems including multi-attribute expected utility and $S$-shaped
aspirational risk preferences. The robust choice function is increasing and
quasi-concave but not necessarily translation invariant, a key property of
monetary risk measures. We propose two approaches based respectively on the
support functions and level functions of quasi-concave functions to develop
tractable formulations of the maximin preference robust optimization model. The
former gives rise to a mixed integer linear programming problem whereas the
latter is equivalent to solving a sequence of convex risk minimization
problems. To assess the effectiveness of the proposed robust preference
optimization model and numerical schemes, we apply them to a security budget
allocation problem and report some preliminary results from experiments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-fin/1/au:+Haskell_W/0/1/0/all/0/1&quot;&gt;William B. Haskell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-fin/1/au:+Huang_W/0/1/0/all/0/1&quot;&gt;Wenjie Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-fin/1/au:+Xu_H/0/1/0/all/0/1&quot;&gt;Huifu Xu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.06915">
<title>A Note on Coding and Standardization of Categorical Variables in (Sparse) Group Lasso Regression. (arXiv:1805.06915v1 [stat.CO])</title>
<link>http://arxiv.org/abs/1805.06915</link>
<description rdf:parseType="Literal">&lt;p&gt;Categorical regressor variables are usually handled by introducing a set of
indicator variables, and imposing a linear constraint to ensure identifiability
in the presence of an intercept, or equivalently, using one of various coding
schemes. As proposed in Yuan and Lin [J. R. Statist. Soc. B, 68 (2006), 49-67],
the group lasso is a natural and computationally convenient approach to perform
variable selection in settings with categorical covariates. As pointed out by
Simon and Tibshirani [Stat. Sin., 22 (2011), 983-1001], &quot;standardization&quot; by
means of block-wise orthonormalization of column submatrices each corresponding
to one group of variables can substantially boost performance. In this note, we
study the aspect of standardization for the special case of categorical
predictors in detail. The main result is that orthonormalization is not
required; column-wise scaling of the design matrix followed by re-scaling and
centering of the coefficients is shown to have exactly the same effect. Similar
reductions can be achieved in the case of interactions. The extension to the
so-called sparse group lasso, which additionally promotes within-group
sparsity, is considered as well. The importance of proper standardization is
illustrated via extensive simulations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Detmer_F/0/1/0/all/0/1&quot;&gt;Felicitas J. Detmer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Slawski_M/0/1/0/all/0/1&quot;&gt;Martin Slawski&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.06951">
<title>A Forest Mixture Bound for Block-Free Parallel Inference. (arXiv:1805.06951v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.06951</link>
<description rdf:parseType="Literal">&lt;p&gt;Coordinate ascent variational inference is an important algorithm for
inference in probabilistic models, but it is slow because it updates only a
single variable at a time. Block coordinate methods perform inference faster by
updating blocks of variables in parallel. However, the speed and stability of
these algorithms depends on how the variables are partitioned into blocks. In
this paper, we give a stable parallel algorithm for inference in deep
exponential families that doesn&apos;t require the variables to be partitioned into
blocks. We achieve this by lower bounding the ELBO by a new objective we call
the forest mixture bound (FM bound) that separates the inference problem for
variables within a hidden layer. We apply this to the simple case when all
random variables are Gaussian and show empirically that the algorithm converges
faster for models that are inherently more forest-like.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lawton_N/0/1/0/all/0/1&quot;&gt;Neal Lawton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Galstyan_A/0/1/0/all/0/1&quot;&gt;Aram Galstyan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Steeg_G/0/1/0/all/0/1&quot;&gt;Greg Ver Steeg&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07006">
<title>Spectral feature scaling method for supervised dimensionality reduction. (arXiv:1805.07006v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.07006</link>
<description rdf:parseType="Literal">&lt;p&gt;Spectral dimensionality reduction methods enable linear separations of
complex data with high-dimensional features in a reduced space. However, these
methods do not always give the desired results due to irregularities or
uncertainties of the data. Thus, we consider aggressively modifying the scales
of the features to obtain the desired classification. Using prior knowledge on
the labels of partial samples to specify the Fiedler vector, we formulate an
eigenvalue problem of a linear matrix pencil whose eigenvector has the feature
scaling factors. The resulting factors can modify the features of entire
samples to form clusters in the reduced space, according to the known labels.
In this study, we propose new dimensionality reduction methods supervised using
the feature scaling associated with the spectral clustering. Numerical
experiments show that the proposed methods outperform well-established
supervised methods for toy problems with more samples than features, and are
more robust regarding clustering than existing methods. Also, the proposed
methods outperform existing methods regarding classification for real-world
problems with more features than samples of gene expression profiles of cancer
diseases. Furthermore, the feature scaling tends to improve the clustering and
classification accuracies of existing unsupervised methods, as the proportion
of training data increases.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Matsuda_M/0/1/0/all/0/1&quot;&gt;Momo Matsuda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Morikuni_K/0/1/0/all/0/1&quot;&gt;Keiichi Morikuni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sakurai_T/0/1/0/all/0/1&quot;&gt;Tetsuya Sakurai&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07051">
<title>Bayesian Joint Spike-and-Slab Graphical Lasso. (arXiv:1805.07051v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.07051</link>
<description rdf:parseType="Literal">&lt;p&gt;In this article, we propose a new class of priors for Bayesian inference with
multiple Gaussian graphical models. We introduce fully Bayesian treatments of
two popular procedures, the group graphical lasso and the fused graphical
lasso, and extend them to a continuous spike-and-slab framework to allow
self-adaptive shrinkage and model selection simultaneously. We develop an EM
algorithm that performs fast and dynamic explorations of posterior modes. Our
approach selects sparse models efficiently with substantially smaller bias than
would be induced by alternative regularization procedures. The performance of
the proposed methods are demonstrated through simulation and two real data
examples.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Zehang Richard Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+McCormick_T/0/1/0/all/0/1&quot;&gt;Tyler H. McCormick&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Clark_S/0/1/0/all/0/1&quot;&gt;Samuel J. Clark&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07113">
<title>Change Point Methods on a Sequence of Graphs. (arXiv:1805.07113v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.07113</link>
<description rdf:parseType="Literal">&lt;p&gt;The present paper considers a finite sequence of graphs, e.g., coming from
technological, biological, and social networks, each of which is modelled as a
realization of a graph-valued random variable, and proposes a methodology to
identify possible changes in stationarity in its generating stochastic process.
In order to cover a large class of applications, we consider a general family
of attributed graphs, chatacterized by a possible variable topology (edges and
vertices) also in the stationary case. A Change Point Method (CPM) approach is
proposed, that (i) maps graphs into a vector domain; (ii) applies a suitable
statistical test; (iii) detects the change --if any-- according to a confidence
level and provides an estimate for its time of occurrence. Two specific CPMs
are proposed: one detecting shifts in the distribution mean, the other
addressing generic changes affecting the distribution. We ground our proposal
with theoretical results showing how to relate the inference attained in the
numerical vector space to the graph domain, and vice versa. Finally,
simulations on epileptic-seizure detection problems are conducted on real-world
data providing evidence for the CPMs effectiveness.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zambon_D/0/1/0/all/0/1&quot;&gt;Daniele Zambon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Alippi_C/0/1/0/all/0/1&quot;&gt;Cesare Alippi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Livi_L/0/1/0/all/0/1&quot;&gt;Lorenzo Livi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07179">
<title>Markov Chain Importance Sampling - a highly efficient estimator for MCMC. (arXiv:1805.07179v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.07179</link>
<description rdf:parseType="Literal">&lt;p&gt;Markov chain algorithms are ubiquitous in machine learning and statistics and
many other disciplines. In this work we present a novel estimator applicable to
several classes of Markov chains, dubbed Markov chain importance sampling
(MCIS). For a broad class of Metropolis-Hastings algorithms, MCIS efficiently
makes use of rejected proposals. For discretized Langevin diffusions, it
provides a novel way of correcting the discretization error. Our estimator
satisfies a central limit theorem and improves on error per CPU cycle, often to
a large extent. As a by-product it enables estimating the normalizing constant,
an important quantity in Bayesian machine learning and statistics.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Schuster_I/0/1/0/all/0/1&quot;&gt;Ingmar Schuster&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Klebanov_I/0/1/0/all/0/1&quot;&gt;Ilja Klebanov&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07194">
<title>Distributionally Robust Inverse Covariance Estimation: The Wasserstein Shrinkage Estimator. (arXiv:1805.07194v1 [math.OC])</title>
<link>http://arxiv.org/abs/1805.07194</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce a distributionally robust maximum likelihood estimation model
with a Wasserstein ambiguity set to infer the inverse covariance matrix of a
$p$-dimensional Gaussian random vector from $n$ independent samples. The
proposed model minimizes the worst case (maximum) of Stein&apos;s loss across all
normal reference distributions within a prescribed Wasserstein distance from
the normal distribution characterized by the sample mean and the sample
covariance matrix. We prove that this estimation problem is equivalent to a
semidefinite program that is tractable in theory but beyond the reach of
general purpose solvers for practically relevant problem dimensions $p$. In the
absence of any prior structural information, the estimation problem has an
analytical solution that is naturally interpreted as a nonlinear shrinkage
estimator. Besides being invertible and well-conditioned even for $p&amp;gt;n$, the
new shrinkage estimator is rotation-equivariant and preserves the order of the
eigenvalues of the sample covariance matrix. These desirable properties are not
imposed ad hoc but emerge naturally from the underlying distributionally robust
optimization model. Finally, we develop a sequential quadratic approximation
algorithm for efficiently solving the general estimation problem subject to
conditional independence constraints typically encountered in Gaussian
graphical models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Nguyen_V/0/1/0/all/0/1&quot;&gt;Viet Anh Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Kuhn_D/0/1/0/all/0/1&quot;&gt;Daniel Kuhn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Esfahani_P/0/1/0/all/0/1&quot;&gt;Peyman Mohajerin Esfahani&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07206">
<title>Approximate Bayesian inference in spatial environments. (arXiv:1805.07206v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.07206</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose to learn a stochastic recurrent model to solve the problem of
simultaneous localisation and mapping (SLAM). Our model is a deep variational
Bayes filter augmented with a latent global variable---similar to an external
memory component---representing the spatially structured environment. Reasoning
about the pose of an agent and the map of the environment is then naturally
expressed as posterior inference in the resulting generative model. We evaluate
the method on a set of randomly generated mazes which are traversed by an agent
equipped with laser range finders. Path integration based on an accurate motion
model is consistently outperformed, and most importantly, drift practically
eliminated. Our approach inherits favourable properties from neural networks,
such as differentiability, flexibility and the ability to train components
either in isolation or end-to-end.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mirchev_A/0/1/0/all/0/1&quot;&gt;Atanas Mirchev&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kayalibay_B/0/1/0/all/0/1&quot;&gt;Baris Kayalibay&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Smagt_P/0/1/0/all/0/1&quot;&gt;Patrick van der Smagt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bayer_J/0/1/0/all/0/1&quot;&gt;Justin Bayer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07220">
<title>Memoryless Exact Solutions for Deterministic MDPs with Sparse Rewards. (arXiv:1805.07220v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.07220</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose an algorithm for deterministic continuous Markov Decision
Processes with sparse rewards that computes the optimal policy exactly with no
dependency on the size of the state space. The algorithm has time complexity of
$O( |R|^3 \times |A|^2 )$ and memory complexity of $O( |R| \times |A| )$, where
$|R|$ is the number of reward sources and $|A|$ is the number of actions.
Furthermore, we describe a companion algorithm that can follow the optimal
policy from any initial state without computing the entire value function,
instead computing on-demand the value of states as they are needed. The
algorithm to solve the MDP does not depend on the size of the state space for
either time or memory complexity, and the ability to follow the optimal policy
is linear in time and space with the path length of following the optimal
policy from the initial state. We demonstrate the algorithm operation side by
side with value iteration on tractable MDPs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bertram_J/0/1/0/all/0/1&quot;&gt;Joshua R. Bertram&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wei_P/0/1/0/all/0/1&quot;&gt;Peng Wei&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07281">
<title>An Unsupervised Approach to Solving Inverse Problems using Generative Adversarial Networks. (arXiv:1805.07281v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1805.07281</link>
<description rdf:parseType="Literal">&lt;p&gt;Solving inverse problems continues to be a challenge in a wide array of
applications ranging from deblurring, image inpainting, source separation etc.
Most existing techniques solve such inverse problems by either explicitly or
implicitly finding the inverse of the model. The former class of techniques
require explicit knowledge of the measurement process which can be unrealistic,
and rely on strong analytical regularizers to constrain the solution space,
which often do not generalize well. The latter approaches have had remarkable
success in part due to deep learning, but require a large collection of
source-observation pairs, which can be prohibitively expensive. In this paper,
we propose an unsupervised technique to solve inverse problems with generative
adversarial networks (GANs). Using a pre-trained GAN in the space of source
signals, we show that one can reliably recover solutions to under determined
problems in a `blind&apos; fashion, i.e., without knowledge of the measurement
process. We solve this by making successive estimates on the model and the
solution in an iterative fashion. We show promising results in three
challenging applications -- blind source separation, image deblurring, and
recovering an image from its edge map, and perform better than several
baselines.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Anirudh_R/0/1/0/all/0/1&quot;&gt;Rushil Anirudh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Thiagarajan_J/0/1/0/all/0/1&quot;&gt;Jayaraman J. Thiagarajan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kailkhura_B/0/1/0/all/0/1&quot;&gt;Bhavya Kailkhura&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bremer_T/0/1/0/all/0/1&quot;&gt;Timo Bremer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07300">
<title>Multitaper Spectral Estimation HDP-HMMs for EEG Sleep Inference. (arXiv:1805.07300v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.07300</link>
<description rdf:parseType="Literal">&lt;p&gt;Electroencephalographic (EEG) monitoring of neural activity is widely used
for sleep disorder diagnostics and research. The standard of care is to
manually classify 30-second epochs of EEG time-domain traces into 5 discrete
sleep stages. Unfortunately, this scoring process is subjective and
time-consuming, and the defined stages do not capture the heterogeneous
landscape of healthy and clinical neural dynamics. This motivates the search
for a data-driven and principled way to identify the number and composition of
salient, reoccurring brain states present during sleep. To this end, we propose
a Hierarchical Dirichlet Process Hidden Markov Model (HDP-HMM), combined with
wide-sense stationary (WSS) time series spectral estimation to construct a
generative model for personalized subject sleep states. In addition, we employ
multitaper spectral estimation to further reduce the large variance of the
spectral estimates inherent to finite-length EEG measurements. By applying our
method to both simulated and human sleep data, we arrive at three main results:
1) a Bayesian nonparametric automated algorithm that recovers general temporal
dynamics of sleep, 2) identification of subject-specific &quot;microstates&quot; within
canonical sleep stages, and 3) discovery of stage-dependent sub-oscillations
with shared spectral signatures across subjects.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chlon_L/0/1/0/all/0/1&quot;&gt;Leon Chlon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Song_A/0/1/0/all/0/1&quot;&gt;Andrew Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Subramanian_S/0/1/0/all/0/1&quot;&gt;Sandya Subramanian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Soulat_H/0/1/0/all/0/1&quot;&gt;Hugo Soulat&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tauber_J/0/1/0/all/0/1&quot;&gt;John Tauber&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ba_D/0/1/0/all/0/1&quot;&gt;Demba Ba&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Prerau_M/0/1/0/all/0/1&quot;&gt;Michael Prerau&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07331">
<title>Combining Cost-Sensitive Classification with Negative Selection for Protein Function Prediction. (arXiv:1805.07331v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.07331</link>
<description rdf:parseType="Literal">&lt;p&gt;Motivation: Computational methods play a central role in annotating the
functions of large amounts of proteins delivered by high-throughput
technologies. Despite the encouraging results achieved by these methods, many
functions still have a very low number of verified protein annotations, leading
to a pronounced imbalance between annotated and unannotated proteins.
Furthermore, functional taxonomies rarely report negative annotations. This
leaves ill defined the set of negative examples, which is crucial for training
the majority of machine learning methods. In practice, neglecting data
imbalance and the problem of selecing negative examples can strongly limit the
accuracy of protein function prediction. Results: We present a novel approach
combining a suitable imbalance-aware classification strategy, addressing the
scarcity of annotated proteins, with an active learning strategy for selecting
the most reliable negative examples. When implemented in a Support Vector
Machine, this combined approach shows improved accuracy on yeast and human
proteomes over standard SVM and top-performing function prediction tools
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Frasca_M/0/1/0/all/0/1&quot;&gt;Marco Frasca&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bianchi_N/0/1/0/all/0/1&quot;&gt;Nicol&amp;#xf2; Cesa Bianchi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07346">
<title>Accurate Kernel Learning for Linear Gaussian Markov Processes using a Scalable Likelihood Computation. (arXiv:1805.07346v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.07346</link>
<description rdf:parseType="Literal">&lt;p&gt;We report an exact likelihood computation for Linear Gaussian Markov
processes that is more scalable than existing algorithms for complex models and
sparsely sampled signals. Better scaling is achieved through elimination of
repeated computations in the Kalman likelihood, and by using the diagonalized
form of the state transition equation. Using this efficient computation, we
study the accuracy of kernel learning using maximum likelihood and the
posterior mean in a simulation experiment. The posterior mean with a reference
prior is more accurate for complex models and sparse sampling. Because of its
lower computation load, the maximum likelihood estimator is an attractive
option for more densely sampled signals and lower order models. We confirm
estimator behavior in experimental data through their application to speleothem
data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Waele_S/0/1/0/all/0/1&quot;&gt;Stijn de Waele&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1610.00768">
<title>CleverHans v2.1.0: an adversarial machine learning library. (arXiv:1610.00768v5 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1610.00768</link>
<description rdf:parseType="Literal">&lt;p&gt;CleverHans is a software library that provides standardized reference
implementations of adversarial example construction techniques and adversarial
training. The library may be used to develop more robust machine learning
models and to provide standardized benchmarks of models&apos; performance in the
adversarial setting. Benchmarks constructed without a standardized
implementation of adversarial example construction are not comparable to each
other, because a good result may indicate a robust model or it may merely
indicate a weak implementation of the adversarial example construction
procedure.
&lt;/p&gt;
&lt;p&gt;This technical report is structured as follows. Section 1 provides an
overview of adversarial examples in machine learning and of the CleverHans
software. Section 2 presents the core functionalities of the library: namely
the attacks based on adversarial examples and defenses to improve the
robustness of machine learning models to these attacks. Section 3 describes how
to report benchmark results using the library. Section 4 describes the
versioning system.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Papernot_N/0/1/0/all/0/1&quot;&gt;Nicolas Papernot&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Faghri_F/0/1/0/all/0/1&quot;&gt;Fartash Faghri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Carlini_N/0/1/0/all/0/1&quot;&gt;Nicholas Carlini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goodfellow_I/0/1/0/all/0/1&quot;&gt;Ian Goodfellow&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feinman_R/0/1/0/all/0/1&quot;&gt;Reuben Feinman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kurakin_A/0/1/0/all/0/1&quot;&gt;Alexey Kurakin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_C/0/1/0/all/0/1&quot;&gt;Cihang Xie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sharma_Y/0/1/0/all/0/1&quot;&gt;Yash Sharma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brown_T/0/1/0/all/0/1&quot;&gt;Tom Brown&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roy_A/0/1/0/all/0/1&quot;&gt;Aurko Roy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Matyasko_A/0/1/0/all/0/1&quot;&gt;Alexander Matyasko&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Behzadan_V/0/1/0/all/0/1&quot;&gt;Vahid Behzadan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hambardzumyan_K/0/1/0/all/0/1&quot;&gt;Karen Hambardzumyan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1&quot;&gt;Zhishuai Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Juang_Y/0/1/0/all/0/1&quot;&gt;Yi-Lin Juang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Zhi Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sheatsley_R/0/1/0/all/0/1&quot;&gt;Ryan Sheatsley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garg_A/0/1/0/all/0/1&quot;&gt;Abhibhav Garg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Uesato_J/0/1/0/all/0/1&quot;&gt;Jonathan Uesato&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gierke_W/0/1/0/all/0/1&quot;&gt;Willi Gierke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1&quot;&gt;Yinpeng Dong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Berthelot_D/0/1/0/all/0/1&quot;&gt;David Berthelot&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hendricks_P/0/1/0/all/0/1&quot;&gt;Paul Hendricks&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rauber_J/0/1/0/all/0/1&quot;&gt;Jonas Rauber&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Long_R/0/1/0/all/0/1&quot;&gt;Rujun Long&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+McDaniel_P/0/1/0/all/0/1&quot;&gt;Patrick McDaniel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.02840">
<title>A Brief Introduction to Machine Learning for Engineers. (arXiv:1709.02840v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1709.02840</link>
<description rdf:parseType="Literal">&lt;p&gt;This monograph aims at providing an introduction to key concepts, algorithms,
and theoretical results in machine learning. The treatment concentrates on
probabilistic models for supervised and unsupervised learning problems. It
introduces fundamental concepts and algorithms by building on first principles,
while also exposing the reader to more advanced topics with extensive pointers
to the literature, within a unified notation and mathematical framework. The
material is organized according to clearly defined categories, such as
discriminative and generative models, frequentist and Bayesian approaches,
exact and approximate inference, as well as directed and undirected models.
This monograph is meant as an entry point for researchers with a background in
probability and linear algebra.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Simeone_O/0/1/0/all/0/1&quot;&gt;Osvaldo Simeone&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.00996">
<title>Learning to detect chest radiographs containing lung nodules using visual attention networks. (arXiv:1712.00996v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1712.00996</link>
<description rdf:parseType="Literal">&lt;p&gt;Machine learning approaches hold great potential for the automated detection
of lung nodules in chest radiographs, but training the algorithms requires vary
large amounts of manually annotated images, which are difficult to obtain. Weak
labels indicating whether a radiograph is likely to contain pulmonary nodules
are typically easier to obtain at scale by parsing historical free-text
radiological reports associated to the radiographs. Using a repositotory of
over 700,000 chest radiographs, in this study we demonstrate that promising
nodule detection performance can be achieved using weak labels through
convolutional neural networks for radiograph classification. We propose two
network architectures for the classification of images likely to contain
pulmonary nodules using both weak labels and manually-delineated bounding
boxes, when these are available. Annotated nodules are used at training time to
deliver a visual attention mechanism informing the model about its localisation
performance. The first architecture extracts saliency maps from high-level
convolutional layers and compares the estimated position of a nodule against
the ground truth, when this is available. A corresponding localisation error is
then back-propagated along with the softmax classification error. The second
approach consists of a recurrent attention model that learns to observe a short
sequence of smaller image portions through reinforcement learning. When a
nodule annotation is available at training time, the reward function is
modified accordingly so that exploring portions of the radiographs away from a
nodule incurs a larger penalty. Our empirical results demonstrate the potential
advantages of these architectures in comparison to competing methodologies.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pesce_E/0/1/0/all/0/1&quot;&gt;Emanuele Pesce&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ypsilantis_P/0/1/0/all/0/1&quot;&gt;Petros-Pavlos Ypsilantis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Withey_S/0/1/0/all/0/1&quot;&gt;Samuel Withey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bakewell_R/0/1/0/all/0/1&quot;&gt;Robert Bakewell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Goh_V/0/1/0/all/0/1&quot;&gt;Vicky Goh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Montana_G/0/1/0/all/0/1&quot;&gt;Giovanni Montana&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.10311">
<title>How Developers Iterate on Machine Learning Workflows -- A Survey of the Applied Machine Learning Literature. (arXiv:1803.10311v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1803.10311</link>
<description rdf:parseType="Literal">&lt;p&gt;Machine learning workflow development is anecdotally regarded to be an
iterative process of trial-and-error with humans-in-the-loop. However, we are
not aware of quantitative evidence corroborating this popular belief. A
quantitative characterization of iteration can serve as a benchmark for machine
learning workflow development in practice, and can aid the development of
human-in-the-loop machine learning systems. To this end, we conduct a
small-scale survey of the applied machine learning literature from five
distinct application domains. We collect and distill statistics on the role of
iteration within machine learning workflow development, and report preliminary
trends and insights from our investigation, as a starting point towards this
benchmark. Based on our findings, we finally describe desiderata for effective
and versatile human-in-the-loop machine learning systems that can cater to
users in diverse domains.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xin_D/0/1/0/all/0/1&quot;&gt;Doris Xin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_L/0/1/0/all/0/1&quot;&gt;Litian Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_S/0/1/0/all/0/1&quot;&gt;Shuchen Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Parameswaran_A/0/1/0/all/0/1&quot;&gt;Aditya Parameswaran&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.05345">
<title>Data-Dependent Coresets for Compressing Neural Networks with Applications to Generalization Bounds. (arXiv:1804.05345v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1804.05345</link>
<description rdf:parseType="Literal">&lt;p&gt;We present an efficient coresets-based neural network compression algorithm
that provably sparsifies the parameters of a trained fully-connected neural
network in a manner that approximately preserves the network&apos;s output. Our
approach is based on an importance sampling scheme that judiciously defines a
sampling distribution over the neural network parameters, and as a result,
retains parameters of high importance while discarding redundant ones. We
leverage a novel, empirical notion of sensitivity and extend traditional
coreset constructions to the application of compressing parameters. Our
theoretical analysis establishes guarantees on the size and accuracy of the
resulting compressed neural network and gives rise to new generalization bounds
that may provide novel insights on the generalization properties of neural
networks. We demonstrate the practical effectiveness of our algorithm on a
variety of neural network configurations and real-world data sets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Baykal_C/0/1/0/all/0/1&quot;&gt;Cenk Baykal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liebenwein_L/0/1/0/all/0/1&quot;&gt;Lucas Liebenwein&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gilitschenski_I/0/1/0/all/0/1&quot;&gt;Igor Gilitschenski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feldman_D/0/1/0/all/0/1&quot;&gt;Dan Feldman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rus_D/0/1/0/all/0/1&quot;&gt;Daniela Rus&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.04018">
<title>Supervising Nystr\&quot;om Methods via Negative Margin Support Vector Selection. (arXiv:1805.04018v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.04018</link>
<description rdf:parseType="Literal">&lt;p&gt;The Nystr\&quot;om methods have been popular techniques for scalable kernel based
learning. They approximate explicit, low-dimensional feature mappings for
kernel functions from the pairwise comparisons with the training data. However,
Nystr\&quot;om methods are generally applied without the supervision provided by the
training labels in the classification/regression problems. This leads to
pairwise comparisons with randomly chosen training samples in the model.
Conversely, this work studies a supervised Nystr\&quot;om method that chooses the
critical subsets of samples for the success of the Machine Learning model.
Particularly, we select the Nystr\&quot;om support vectors via the negative margin
criterion, and create explicit feature maps that are more suitable for the
classification task on the data. Experimental results on six datasets show
that, without increasing the complexity over unsupervised techniques, our
method can significantly improve the classification performance achieved via
kernel approximation methods and reduce the number of features needed to reach
or exceed the performance of the full-dimensional kernel machines.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Al_M/0/1/0/all/0/1&quot;&gt;Mert Al&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chanyaswad_T/0/1/0/all/0/1&quot;&gt;Thee Chanyaswad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kung_S/0/1/0/all/0/1&quot;&gt;Sun-Yuan Kung&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.06605">
<title>Defense-GAN: Protecting Classifiers Against Adversarial Attacks Using Generative Models. (arXiv:1805.06605v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1805.06605</link>
<description rdf:parseType="Literal">&lt;p&gt;In recent years, deep neural network approaches have been widely adopted for
machine learning tasks, including classification. However, they were shown to
be vulnerable to adversarial perturbations: carefully crafted small
perturbations can cause misclassification of legitimate images. We propose
Defense-GAN, a new framework leveraging the expressive capability of generative
models to defend deep neural networks against such attacks. Defense-GAN is
trained to model the distribution of unperturbed images. At inference time, it
finds a close output to a given image which does not contain the adversarial
changes. This output is then fed to the classifier. Our proposed method can be
used with any classification model and does not modify the classifier structure
or training procedure. It can also be used as a defense against any attack as
it does not assume knowledge of the process for generating the adversarial
examples. We empirically show that Defense-GAN is consistently effective
against different attack methods and improves on existing defense strategies.
Our code has been made publicly available at
https://github.com/kabkabm/defensegan
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Samangouei_P/0/1/0/all/0/1&quot;&gt;Pouya Samangouei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kabkab_M/0/1/0/all/0/1&quot;&gt;Maya Kabkab&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chellappa_R/0/1/0/all/0/1&quot;&gt;Rama Chellappa&lt;/a&gt;</dc:creator>
</item></rdf:RDF>