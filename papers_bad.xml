<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Boring papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Bad Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-06-18T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06296"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06464"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06545"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06676"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.04487"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06093"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.01756"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06108"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06192"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06207"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06232"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06266"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06349"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06371"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06496"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06505"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06514"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06519"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06685"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06790"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06798"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1611.03907"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1703.09700"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.10503"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.10546"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.00119"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.06333"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.02717"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.10829"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08263"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02242"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02711"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06086"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06095"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06100"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06121"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06122"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06123"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06124"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06142"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06209"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06237"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06270"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06317"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06392"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06415"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06438"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06439"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06457"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06553"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06573"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06610"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06720"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06777"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06784"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06802"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06827"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06850"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1508.01248"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1605.07129"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1705.10819"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.00106"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.07283"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.00342"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.00789"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.02621"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.06424"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.02557"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.03888"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05680"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.05554"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.08178"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.01050"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.10109"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10616"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.12573"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00656"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04047"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1806.06296">
<title>Right for the Right Reason: Training Agnostic Networks. (arXiv:1806.06296v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.06296</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the problem of a neural network being requested to classify
images (or other inputs) without making implicit use of a &quot;protected concept&quot;,
that is a concept that should not play any role in the decision of the network.
Typically these concepts include information such as gender or race, or other
contextual information such as image backgrounds that might be implicitly
reflected in unknown correlations with other variables, making it insufficient
to simply remove them from the input features. In other words, making accurate
predictions is not good enough if those predictions rely on information that
should not be used: predictive performance is not the only important metric for
learning systems. We apply a method developed in the context of domain
adaptation to address this problem of &quot;being right for the right reason&quot;, where
we request a classifier to make a decision in a way that is entirely &apos;agnostic&apos;
to a given protected concept (e.g. gender, race, background etc.), even if this
could be implicitly reflected in other attributes via unknown correlations.
After defining the concept of an &apos;agnostic model&apos;, we demonstrate how the
Domain-Adversarial Neural Network can remove unwanted information from a model
using a gradient reversal layer.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jia_S/0/1/0/all/0/1&quot;&gt;Sen Jia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lansdall_Welfare_T/0/1/0/all/0/1&quot;&gt;Thomas Lansdall-Welfare&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cristianini_N/0/1/0/all/0/1&quot;&gt;Nello Cristianini&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06464">
<title>Learning Policy Representations in Multiagent Systems. (arXiv:1806.06464v1 [cs.MA])</title>
<link>http://arxiv.org/abs/1806.06464</link>
<description rdf:parseType="Literal">&lt;p&gt;Modeling agent behavior is central to understanding the emergence of complex
phenomena in multiagent systems. Prior work in agent modeling has largely been
task-specific and driven by hand-engineering domain-specific prior knowledge.
We propose a general learning framework for modeling agent behavior in any
multiagent system using only a handful of interaction data. Our framework casts
agent modeling as a representation learning problem. Consequently, we construct
a novel objective inspired by imitation learning and agent identification and
design an algorithm for unsupervised learning of representations of agent
policies. We demonstrate empirically the utility of the proposed framework in
(i) a challenging high-dimensional competitive environment for continuous
control and (ii) a cooperative environment for communication, on supervised
predictive tasks, unsupervised clustering, and policy optimization using deep
reinforcement learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grover_A/0/1/0/all/0/1&quot;&gt;Aditya Grover&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Al_Shedivat_M/0/1/0/all/0/1&quot;&gt;Maruan Al-Shedivat&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gupta_J/0/1/0/all/0/1&quot;&gt;Jayesh K. Gupta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Burda_Y/0/1/0/all/0/1&quot;&gt;Yura Burda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Edwards_H/0/1/0/all/0/1&quot;&gt;Harrison Edwards&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06545">
<title>A Simple Reservoir Model of Working Memory with Real Values. (arXiv:1806.06545v1 [q-bio.NC])</title>
<link>http://arxiv.org/abs/1806.06545</link>
<description rdf:parseType="Literal">&lt;p&gt;The prefrontal cortex is known to be involved in many high-level cognitive
functions, in particular, working memory. Here, we study to what extent a group
of randomly connected units (namely an Echo State Network, ESN) can store and
maintain (as output) an arbitrary real value from a streamed input, i.e. can
act as a sustained working memory unit. Furthermore, we explore to what extent
such an architecture can take advantage of the stored value in order to produce
non-linear computations. Comparison between different architectures (with and
without feedback, with and without a working memory unit) shows that an
explicit memory improves the performances.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Strock_A/0/1/0/all/0/1&quot;&gt;Anthony Strock&lt;/a&gt; (Mnemosyne), &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Rougier_N/0/1/0/all/0/1&quot;&gt;Nicolas Rougier&lt;/a&gt; (Mnemosyne), &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Hinaut_X/0/1/0/all/0/1&quot;&gt;Xavier Hinaut&lt;/a&gt; (Mnemosyne)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06676">
<title>Towards multi-instrument drum transcription. (arXiv:1806.06676v1 [cs.SD])</title>
<link>http://arxiv.org/abs/1806.06676</link>
<description rdf:parseType="Literal">&lt;p&gt;Automatic drum transcription, a subtask of the more general automatic music
transcription, deals with extracting drum instrument note onsets from an audio
source. Recently, progress in transcription performance has been made using
non-negative matrix factorization as well as deep learning methods. However,
these works primarily focus on transcribing three drum instruments only: snare
drum, bass drum, and hi-hat. Yet, for many applications, the ability to
transcribe more drum instruments which make up standard drum kits used in
western popular music would be desirable. In this work, convolutional and
convolutional recurrent neural networks are trained to transcribe a wider range
of drum instruments. First, the shortcomings of publicly available datasets in
this context are discussed. To overcome these limitations, a larger synthetic
dataset is introduced. Then, methods to train models using the new dataset
focusing on generalization to real world data are investigated. Finally, the
trained models are evaluated on publicly available datasets and results are
discussed. The contributions of this work comprise: (i.) a large-scale
synthetic dataset for drum transcription, (ii.) first steps towards an
automatic drum transcription system that supports a larger range of instruments
by evaluating and discussing training setups and the impact of datasets in this
context, and (iii.) a publicly available set of trained models for drum
transcription. Additional materials are available at
&lt;a href=&quot;http://ifs.tuwien.ac.at/\textasciitilde&quot;&gt;this http URL&lt;/a&gt; vogl/dafx2018.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vogl_R/0/1/0/all/0/1&quot;&gt;Richard Vogl&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Widmer_G/0/1/0/all/0/1&quot;&gt;Gerhard Widmer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Knees_P/0/1/0/all/0/1&quot;&gt;Peter Knees&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.04487">
<title>Better Runtime Guarantees Via Stochastic Domination. (arXiv:1801.04487v4 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1801.04487</link>
<description rdf:parseType="Literal">&lt;p&gt;Apart from few exceptions, the mathematical runtime analysis of evolutionary
algorithms is mostly concerned with expected runtimes. In this work, we argue
that stochastic domination is a notion that should be used more frequently in
this area. Stochastic domination allows to formulate much more informative
performance guarantees, it allows to decouple the algorithm analysis into the
true algorithmic part of detecting a domination statement and the
probability-theoretical part of deriving the desired probabilistic guarantees
from this statement, and it helps finding simpler and more natural proofs.
&lt;/p&gt;
&lt;p&gt;As particular results, we prove a fitness level theorem which shows that the
runtime is dominated by a sum of independent geometric random variables, we
prove the first tail bounds for several classic runtime problems, and we give a
short and natural proof for Witt&apos;s result that the runtime of any $(\mu,p)$
mutation-based algorithm on any function with unique optimum is subdominated by
the runtime of a variant of the \oea on the \onemax function.
&lt;/p&gt;
&lt;p&gt;As side-products, we determine the fastest unbiased (1+1) algorithm for the
\leadingones benchmark problem, both in the general case and when restricted to
static mutation operators, and we prove a Chernoff-type tail bound for sums of
independent coupon collector distributions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Doerr_B/0/1/0/all/0/1&quot;&gt;Benjamin Doerr&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06093">
<title>Gradient descent with identity initialization efficiently learns positive definite linear transformations by deep residual networks. (arXiv:1802.06093v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1802.06093</link>
<description rdf:parseType="Literal">&lt;p&gt;We analyze algorithms for approximating a function $f(x) = \Phi x$ mapping
$\Re^d$ to $\Re^d$ using deep linear neural networks, i.e. that learn a
function $h$ parameterized by matrices $\Theta_1,...,\Theta_L$ and defined by
$h(x) = \Theta_L \Theta_{L-1} ... \Theta_1 x$. We focus on algorithms that
learn through gradient descent on the population quadratic loss in the case
that the distribution over the inputs is isotropic.
&lt;/p&gt;
&lt;p&gt;We provide polynomial bounds on the number of iterations for gradient descent
to approximate the least squares matrix $\Phi$, in the case where the initial
hypothesis $\Theta_1 = ... = \Theta_L = I$ has excess loss bounded by a small
enough constant. On the other hand, we show that gradient descent fails to
converge for $\Phi$ whose distance from the identity is a larger constant, and
we show that some forms of regularization toward the identity in each layer do
not help.
&lt;/p&gt;
&lt;p&gt;If $\Phi$ is symmetric positive definite, we show that an algorithm that
initializes $\Theta_i = I$ learns an $\epsilon$-approximation of $f$ using a
number of updates polynomial in $L$, the condition number of $\Phi$, and
$\log(d/\epsilon)$. In contrast, we show that if the least squares matrix
$\Phi$ is symmetric and has a negative eigenvalue, then all members of a class
of algorithms that perform gradient descent with identity initialization, and
optionally regularize toward the identity in each layer, fail to converge.
&lt;/p&gt;
&lt;p&gt;We analyze an algorithm for the case that $\Phi$ satisfies $u^{\top} \Phi u &amp;gt;
0$ for all $u$, but may not be symmetric. This algorithm uses two regularizers:
one that maintains the invariant $u^{\top} \Theta_L \Theta_{L-1} ... \Theta_1 u
&amp;gt; 0$ for all $u$, and another that &quot;balances&quot; $\Theta_1, ..., \Theta_L$ so that
they have the same singular values.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bartlett_P/0/1/0/all/0/1&quot;&gt;Peter L. Bartlett&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Helmbold_D/0/1/0/all/0/1&quot;&gt;David P. Helmbold&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Long_P/0/1/0/all/0/1&quot;&gt;Philip M. Long&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.01756">
<title>The Kanerva Machine: A Generative Distributed Memory. (arXiv:1804.01756v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1804.01756</link>
<description rdf:parseType="Literal">&lt;p&gt;We present an end-to-end trained memory system that quickly adapts to new
data and generates samples like them. Inspired by Kanerva&apos;s sparse distributed
memory, it has a robust distributed reading and writing mechanism. The memory
is analytically tractable, which enables optimal on-line compression via a
Bayesian update-rule. We formulate it as a hierarchical conditional generative
model, where memory provides a rich data-dependent prior distribution.
Consequently, the top-down memory and bottom-up perception are combined to
produce the code representing an observation. Empirically, we demonstrate that
the adaptive memory significantly improves generative models trained on both
the Omniglot and CIFAR datasets. Compared with the Differentiable Neural
Computer (DNC) and its variants, our memory model has greater capacity and is
significantly easier to train.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wu_Y/0/1/0/all/0/1&quot;&gt;Yan Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wayne_G/0/1/0/all/0/1&quot;&gt;Greg Wayne&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Graves_A/0/1/0/all/0/1&quot;&gt;Alex Graves&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lillicrap_T/0/1/0/all/0/1&quot;&gt;Timothy Lillicrap&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06108">
<title>Non-Negative Networks Against Adversarial Attacks. (arXiv:1806.06108v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.06108</link>
<description rdf:parseType="Literal">&lt;p&gt;Adversarial attacks against Neural Networks are a problem of considerable
importance, for which effective defenses are not yet readily available. We make
progress toward this problem by showing that non-negative weight constraints
can be used to improve resistance in specific scenarios. In particular, we show
that they can provide an effective defense for binary classification problems
with asymmetric cost, such as malware or spam detection. We also show how
non-negativity can be leveraged to reduce an attacker&apos;s ability to perform
targeted misclassification attacks in other domains such as image processing.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Fleshman_W/0/1/0/all/0/1&quot;&gt;William Fleshman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Raff_E/0/1/0/all/0/1&quot;&gt;Edward Raff&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sylvester_J/0/1/0/all/0/1&quot;&gt;Jared Sylvester&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Forsyth_S/0/1/0/all/0/1&quot;&gt;Steven Forsyth&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+McLean_M/0/1/0/all/0/1&quot;&gt;Mark McLean&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06192">
<title>Handling Cold-Start Collaborative Filtering with Reinforcement Learning. (arXiv:1806.06192v1 [cs.IR])</title>
<link>http://arxiv.org/abs/1806.06192</link>
<description rdf:parseType="Literal">&lt;p&gt;A major challenge in recommender systems is handling new users, whom are also
called $\textit{cold-start}$ users. In this paper, we propose a novel approach
for learning an optimal series of questions with which to interview cold-start
users for movie recommender systems. We propose learning interview questions
using Deep Q Networks to create user profiles to make better recommendations to
cold-start users. While our proposed system is trained using a movie
recommender system, our Deep Q Network model should generalize across various
types of recommender systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dureddy_H/0/1/0/all/0/1&quot;&gt;Hima Varsha Dureddy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kaden_Z/0/1/0/all/0/1&quot;&gt;Zachary Kaden&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06207">
<title>Meta-learning: searching in the model space. (arXiv:1806.06207v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.06207</link>
<description rdf:parseType="Literal">&lt;p&gt;There is no free lunch, no single learning algorithm that will outperform
other algorithms on all data. In practice different approaches are tried and
the best algorithm selected. An alternative solution is to build new algorithms
on demand by creating a framework that accommodates many algorithms. The best
combination of parameters and procedures is searched here in the space of all
possible models belonging to the framework of Similarity-Based Methods (SBMs).
Such meta-learning approach gives a chance to find the best method in all
cases. Issues related to the meta-learning and first tests of this approach are
presented.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Duch_W/0/1/0/all/0/1&quot;&gt;W&amp;#x142;odzis&amp;#x142;aw Duch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grudzinsk_K/0/1/0/all/0/1&quot;&gt;Karol Grudzi&amp;#x144;sk&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06232">
<title>Binary Classification in Unstructured Space With Hypergraph Case-Based Reasoning. (arXiv:1806.06232v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.06232</link>
<description rdf:parseType="Literal">&lt;p&gt;Binary classification is one of the most common problem in machine learning.
It consists in predicting whether a given element is of a particular class. In
this paper, a new algorithm for binary classification is proposed using a
hypergraph representation. Each element to be classified is partitioned
according to its interactions with the training set. For each class, the total
support is calculated as a convex combination of the {\it evidence} strength of
the element of the partition. The evidence measure is pre-computed using the
hypergraph induced by the training set and iteratively adjusted through a
training phase. It does not require structured information, each case being
represented by a set of {\it agnostic information} atoms. Empirical validation
demonstrates its high potential on a wide range of well-known datasets and the
results are compared to the state-of-art. The time complexity is given and
empirically validated. Its capacity to provide good performances without
hyperparameter tuning compared to standard classification methods is studied.
Finally, the limitation of the model space is discussed and some potential
solutions proposed.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Quemy_A/0/1/0/all/0/1&quot;&gt;Alexandre Quemy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06266">
<title>On Strategyproof Conference Peer Review. (arXiv:1806.06266v1 [cs.GT])</title>
<link>http://arxiv.org/abs/1806.06266</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider peer review in a conference setting where there is typically an
overlap between the set of reviewers and the set of authors. This overlap can
incentivize strategic reviews to influence the final ranking of one&apos;s own
papers. In this work, we address this problem through the lens of social
choice, and present a theoretical framework for strategyproof and efficient
peer review. We first present and analyze an algorithm for reviewer-assignment
and aggregation that guarantees strategyproofness and a natural efficiency
property called unanimity, when the authorship graph satisfies a simple
property. Our algorithm is based on the so-called partitioning method, and can
be thought as a generalization of this method to conference peer review
settings. We then empirically show that the requisite property on the
authorship graph is indeed satisfied in the ICLR-17 submission data, and
further demonstrate a simple trick to make the partitioning method more
practically appealing for conference peer review. Finally, we complement our
positive results with negative theoretical results where we prove that under
various ways of strengthening the requirements, it is impossible for any
algorithm to be strategyproof and efficient.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1&quot;&gt;Yichong Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_H/0/1/0/all/0/1&quot;&gt;Han Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_X/0/1/0/all/0/1&quot;&gt;Xiaofei Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shah_N/0/1/0/all/0/1&quot;&gt;Nihar B. Shah&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06349">
<title>Incorporating Chinese Characters of Words for Lexical Sememe Prediction. (arXiv:1806.06349v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1806.06349</link>
<description rdf:parseType="Literal">&lt;p&gt;Sememes are minimum semantic units of concepts in human languages, such that
each word sense is composed of one or multiple sememes. Words are usually
manually annotated with their sememes by linguists, and form linguistic
common-sense knowledge bases widely used in various NLP tasks. Recently, the
lexical sememe prediction task has been introduced. It consists of
automatically recommending sememes for words, which is expected to improve
annotation efficiency and consistency. However, existing methods of lexical
sememe prediction typically rely on the external context of words to represent
the meaning, which usually fails to deal with low-frequency and
out-of-vocabulary words. To address this issue for Chinese, we propose a novel
framework to take advantage of both internal character information and external
context information of words. We experiment on HowNet, a Chinese sememe
knowledge base, and demonstrate that our framework outperforms state-of-the-art
baselines by a large margin, and maintains a robust performance even for
low-frequency words.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jin_H/0/1/0/all/0/1&quot;&gt;Huiming Jin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_H/0/1/0/all/0/1&quot;&gt;Hao Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1&quot;&gt;Zhiyuan Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_R/0/1/0/all/0/1&quot;&gt;Ruobing Xie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1&quot;&gt;Maosong Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_F/0/1/0/all/0/1&quot;&gt;Fen Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_L/0/1/0/all/0/1&quot;&gt;Leyu Lin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06371">
<title>Multimodal Grounding for Language Processing. (arXiv:1806.06371v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1806.06371</link>
<description rdf:parseType="Literal">&lt;p&gt;This survey discusses how recent developments in multimodal processing
facilitate conceptual grounding of language. We categorize the information flow
in multimodal processing with respect to cognitive models of human information
processing and analyze different methods for combining multimodal
representations. Based on this methodological inventory, we discuss the benefit
of multimodal grounding for a variety of language processing tasks and the
challenges that arise. We particularly focus on multimodal grounding of verbs
which play a crucial role for the compositional power of language.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Beinborn_L/0/1/0/all/0/1&quot;&gt;Lisa Beinborn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Botschen_T/0/1/0/all/0/1&quot;&gt;Teresa Botschen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gurevych_I/0/1/0/all/0/1&quot;&gt;Iryna Gurevych&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06496">
<title>Detecting Zero-day Controller Hijacking Attacks on the Power-Grid with Enhanced Deep Learning. (arXiv:1806.06496v1 [cs.CR])</title>
<link>http://arxiv.org/abs/1806.06496</link>
<description rdf:parseType="Literal">&lt;p&gt;Attacks against the control processor of a power-grid system, especially
zero-day attacks, can be catastrophic. Earlier detection of the attacks can
prevent further damage. However, detecting zero-day attacks can be challenging
because they have no known code and have unknown behavior.
&lt;/p&gt;
&lt;p&gt;In order to address the zero-day attack problem, we propose a data-driven
defense by training a temporal deep learning model, using only normal data from
legitimate processes that run daily in these power-grid systems, to model the
normal behavior of the power-grid controller. Then, we can quickly find
malicious codes running on the processor, by estimating deviations from the
normal behavior with a statistical test. Experimental results on a real
power-grid controller show that we can detect anomalous behavior with over
99.9% accuracy and nearly zero false positives.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_Z/0/1/0/all/0/1&quot;&gt;Zecheng He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Raghavan_A/0/1/0/all/0/1&quot;&gt;Aswin Raghavan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chai_S/0/1/0/all/0/1&quot;&gt;Sek Chai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_R/0/1/0/all/0/1&quot;&gt;Ruby Lee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06505">
<title>A unified strategy for implementing curiosity and empowerment driven reinforcement learning. (arXiv:1806.06505v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1806.06505</link>
<description rdf:parseType="Literal">&lt;p&gt;Although there are many approaches to implement intrinsically motivated
artificial agents, the combined usage of multiple intrinsic drives remains
still a relatively unexplored research area. Specifically, we hypothesize that
a mechanism capable of quantifying and controlling the evolution of the
information flow between the agent and the environment could be the fundamental
component for implementing a higher degree of autonomy into artificial
intelligent agents. This paper propose a unified strategy for implementing two
semantically orthogonal intrinsic motivations: curiosity and empowerment.
Curiosity reward informs the agent about the relevance of a recent agent
action, whereas empowerment is implemented as the opposite information flow
from the agent to the environment that quantifies the agent&apos;s potential of
controlling its own future. We show that an additional homeostatic drive is
derived from the curiosity reward, which generalizes and enhances the
information gain of a classical curious/heterostatic reinforcement learning
agent. We show how a shared internal model by curiosity and empowerment
facilitates a more efficient training of the empowerment function. Finally, we
discuss future directions for further leveraging the interplay between these
two intrinsic rewards.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abril_I/0/1/0/all/0/1&quot;&gt;Ildefons Magrans de Abril&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kanai_R/0/1/0/all/0/1&quot;&gt;Ryota Kanai&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06514">
<title>The Information Autoencoding Family: A Lagrangian Perspective on Latent Variable Generative Models. (arXiv:1806.06514v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.06514</link>
<description rdf:parseType="Literal">&lt;p&gt;A variety of learning objectives have been proposed for training latent
variable generative models. We show that many of them, including InfoGAN,
ALI/BiGAN, ALICE, CycleGAN, beta-VAE, adversarial autoencoders, AVB, AS-VAE and
InfoVAE, are Lagrangian duals of the same primal optimization problem,
corresponding to different settings of the Lagrange multipliers. The primal
problem optimizes the mutual information between latent and visible variables,
subject to the constraints of accurately modeling the data distribution and
performing correct amortized inference. Based on this observation, we provide
an exhaustive characterization of the statistical and computational trade-offs
made by all the training objectives in this class of Lagrangian duals. Next, we
propose a dual optimization method where we optimize model parameters as well
as the Lagrange multipliers. This method achieves Pareto near-optimal solutions
in terms of optimizing information and satisfying the consistency constraints.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhao_S/0/1/0/all/0/1&quot;&gt;Shengjia Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Song_J/0/1/0/all/0/1&quot;&gt;Jiaming Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ermon_S/0/1/0/all/0/1&quot;&gt;Stefano Ermon&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06519">
<title>HitNet: a neural network with capsules embedded in a Hit-or-Miss layer, extended with hybrid data augmentation and ghost capsules. (arXiv:1806.06519v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1806.06519</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural networks designed for the task of classification have become a
commodity in recent years. Many works target the development of better
networks, which results in a complexification of their architectures with more
layers, multiple sub-networks, or even the combination of multiple classifiers.
In this paper, we show how to redesign a simple network to reach excellent
performances, which are better than the results reproduced with CapsNet on
several datasets, by replacing a layer with a Hit-or-Miss layer. This layer
contains activated vectors, called capsules, that we train to hit or miss a
central capsule by tailoring a specific centripetal loss function. We also show
how our network, named HitNet, is capable of synthesizing a representative
sample of the images of a given class by including a reconstruction network.
This possibility allows to develop a data augmentation step combining
information from the data space and the feature space, resulting in a hybrid
data augmentation process. In addition, we introduce the possibility for
HitNet, to adopt an alternative to the true target when needed by using the new
concept of ghost capsules, which is used here to detect potentially mislabeled
images in the training data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deliege_A/0/1/0/all/0/1&quot;&gt;Adrien Deli&amp;#xe8;ge&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cioppa_A/0/1/0/all/0/1&quot;&gt;Anthony Cioppa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Droogenbroeck_M/0/1/0/all/0/1&quot;&gt;Marc Van Droogenbroeck&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06685">
<title>Solving the Steiner Tree Problem in graphs with Variable Neighborhood Descent. (arXiv:1806.06685v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1806.06685</link>
<description rdf:parseType="Literal">&lt;p&gt;The Steiner Tree Problem (STP) in graphs is an important problem with various
applications in many areas such as design of integrated circuits, evolution
theory, networking, etc. In this paper, we propose an algorithm to solve the
STP. The algorithm includes a reducer and a solver using Variable Neighborhood
Descent (VND), interacting with each other during the search. New constructive
heuristics and a vertex score system for intensification purpose are proposed.
The algorithm is tested on a set of benchmarks which shows encouraging results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Laere_M/0/1/0/all/0/1&quot;&gt;Matthieu De Laere&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pham_S/0/1/0/all/0/1&quot;&gt;San Tu Pham&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Causmaecker_P/0/1/0/all/0/1&quot;&gt;Patrick De Causmaecker&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06790">
<title>Data-Driven Decentralized Optimal Power Flow. (arXiv:1806.06790v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.06790</link>
<description rdf:parseType="Literal">&lt;p&gt;The implementation of optimal power flow (OPF) methods to perform voltage and
power flow regulation in electric networks is generally believed to require
communication. We consider distribution systems with multiple controllable
Distributed Energy Resources (DERs) and present a data-driven approach to learn
control policies for each DER to reconstruct and mimic the solution to a
centralized OPF problem from solely locally available information.
Collectively, all local controllers closely match the centralized OPF solution,
providing near-optimal performance and satisfaction of system constraints. A
rate distortion framework facilitates the analysis of how well the resulting
fully decentralized control policies are able to reconstruct the OPF solution.
Our methodology provides a natural extension to decide what buses a DER should
communicate with to improve the reconstruction of its individual policy. The
method is applied on both single- and three-phase test feeder networks using
data from real loads and distributed generators. It provides a framework for
Distribution System Operators to efficiently plan and operate the contributions
of DERs to active distribution networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dobbe_R/0/1/0/all/0/1&quot;&gt;Roel Dobbe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sondermeijer_O/0/1/0/all/0/1&quot;&gt;Oscar Sondermeijer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fridovich_Keil_D/0/1/0/all/0/1&quot;&gt;David Fridovich-Keil&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Arnold_D/0/1/0/all/0/1&quot;&gt;Daniel Arnold&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Callaway_D/0/1/0/all/0/1&quot;&gt;Duncan Callaway&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tomlin_C/0/1/0/all/0/1&quot;&gt;Claire Tomlin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06798">
<title>Implicit Policy for Reinforcement Learning. (arXiv:1806.06798v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.06798</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce Implicit Policy, a general class of expressive policies that can
flexibly represent complex action distributions in reinforcement learning, with
efficient algorithms to compute entropy regularized policy gradients. We
empirically show that, despite its simplicity in implementation, entropy
regularization combined with a rich policy class can attain desirable
properties displayed under maximum entropy reinforcement learning framework,
such as robustness and multi-modality.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_Y/0/1/0/all/0/1&quot;&gt;Yunhao Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Agrawal_S/0/1/0/all/0/1&quot;&gt;Shipra Agrawal&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1611.03907">
<title>Reinforcement Learning in Rich-Observation MDPs using Spectral Methods. (arXiv:1611.03907v3 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1611.03907</link>
<description rdf:parseType="Literal">&lt;p&gt;Reinforcement learning (RL) in Markov decision processes (MDPs) with large
state spaces is a challenging problem. The performance of standard RL
algorithms degrades drastically with the dimensionality of state space.
However, in practice, these large MDPs typically incorporate a latent or hidden
low-dimensional structure. In this paper, we study the setting of
rich-observation Markov decision processes (ROMDP), where there are a small
number of hidden states which possess an injective mapping to the observation
states. In other words, every observation state is generated through a single
hidden state, and this mapping is unknown a priori. We introduce a spectral
decomposition method that consistently learns this mapping, and more
importantly, achieves it with low regret. The estimated mapping is integrated
into an optimistic RL algorithm (UCRL), which operates on the estimated hidden
space. We derive finite-time regret bounds for our algorithm with a weak
dependence on the dimensionality of the observed space. In fact, our algorithm
asymptotically achieves the same average regret as the oracle UCRL algorithm,
which has the knowledge of the mapping from hidden to observed spaces. Thus, we
derive an efficient spectral RL algorithm for ROMDPs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Azizzadenesheli_K/0/1/0/all/0/1&quot;&gt;Kamyar Azizzadenesheli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lazaric_A/0/1/0/all/0/1&quot;&gt;Alessandro Lazaric&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Anandkumar_A/0/1/0/all/0/1&quot;&gt;Animashree Anandkumar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1703.09700">
<title>Inverse Reinforcement Learning from Summary Data. (arXiv:1703.09700v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1703.09700</link>
<description rdf:parseType="Literal">&lt;p&gt;Inverse reinforcement learning (IRL) aims to explain observed strategic
behavior by fitting reinforcement learning models to behavioral data. However,
traditional IRL methods are only applicable when the observations are in the
form of state-action paths. This assumption may not hold in many real-world
modeling settings, where only partial or summarized observations are available.
In general, we may assume that there is a summarizing function $\sigma$, which
acts as a filter between us and the true state-action paths that constitute the
demonstration. Some initial approaches to extending IRL to such situations have
been presented, but with very specific assumptions about the structure of
$\sigma$, such as that only certain state observations are missing. This paper
instead focuses on the most general case of the problem, where no assumptions
are made about the summarizing function, except that it can be evaluated. We
demonstrate that inference is still possible. The paper presents exact and
approximate inference algorithms that allow full posterior inference, which is
particularly important for assessing parameter uncertainty in this challenging
inference situation. Empirical scalability is demonstrated to reasonably sized
problems, and practical applicability is demonstrated by estimating the
posterior for a cognitive science RL model based on an observed user&apos;s task
completion time only.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kangasraasio_A/0/1/0/all/0/1&quot;&gt;Antti Kangasr&amp;#xe4;&amp;#xe4;si&amp;#xf6;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kaski_S/0/1/0/all/0/1&quot;&gt;Samuel Kaski&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.10503">
<title>Anticipation in Human-Robot Cooperation: A Recurrent Neural Network Approach for Multiple Action Sequences Prediction. (arXiv:1802.10503v2 [cs.HC] UPDATED)</title>
<link>http://arxiv.org/abs/1802.10503</link>
<description rdf:parseType="Literal">&lt;p&gt;Close human-robot cooperation is a key enabler for new developments in
advanced manufacturing and assistive applications. Close cooperation require
robots that can predict human actions and intent, and understand human
non-verbal cues. Recent approaches based on neural networks have led to
encouraging results in the human action prediction problem both in continuous
and discrete spaces. Our approach extends the research in this direction. Our
contributions are three-fold. First, we validate the use of gaze and body pose
cues as a means of predicting human action through a feature selection method.
Next, we address two shortcomings of existing literature: predicting multiple
and variable-length action sequences. This is achieved by introducing an
encoder-decoder recurrent neural network topology in the discrete action
prediction problem. In addition, we theoretically demonstrate the importance of
predicting multiple action sequences as a means of estimating the stochastic
reward in a human robot cooperation scenario. Finally, we show the ability to
effectively train the prediction model on a action prediction dataset,
involving human motion data, and explore the influence of the model&apos;s
parameters on its performance. Source code repository:
https://github.com/pschydlo/ActionAnticipation
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schydlo_P/0/1/0/all/0/1&quot;&gt;Paul Schydlo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rakovic_M/0/1/0/all/0/1&quot;&gt;Mirko Rakovic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jamone_L/0/1/0/all/0/1&quot;&gt;Lorenzo Jamone&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Santos_Victor_J/0/1/0/all/0/1&quot;&gt;Jos&amp;#xe9; Santos-Victor&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.10546">
<title>Computational Theories of Curiosity-Driven Learning. (arXiv:1802.10546v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1802.10546</link>
<description rdf:parseType="Literal">&lt;p&gt;What are the functions of curiosity? What are the mechanisms of
curiosity-driven learning? We approach these questions about the living using
concepts and tools from machine learning and developmental robotics. We argue
that curiosity-driven learning enables organisms to make discoveries to solve
complex problems with rare or deceptive rewards. By fostering exploration and
discovery of a diversity of behavioural skills, and ignoring these rewards,
curiosity can be efficient to bootstrap learning when there is no information,
or deceptive information, about local improvement towards these problems. We
also explain the key role of curiosity for efficient learning of world models.
We review both normative and heuristic computational frameworks used to
understand the mechanisms of curiosity in humans, conceptualizing the child as
a sense-making organism. These frameworks enable us to discuss the
bi-directional causal links between curiosity and learning, and to provide new
hypotheses about the fundamental role of curiosity in self-organizing
developmental structures through curriculum learning. We present various
developmental robotics experiments that study these mechanisms in action, both
supporting these hypotheses to understand better curiosity in humans and
opening new research avenues in machine learning and artificial intelligence.
Finally, we discuss challenges for the design of experimental paradigms for
studying curiosity in psychology and cognitive neuroscience.
&lt;/p&gt;
&lt;p&gt;Keywords: Curiosity, intrinsic motivation, lifelong learning, predictions,
world model, rewards, free-energy principle, learning progress, machine
learning, AI, developmental robotics, development, curriculum learning,
self-organization.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oudeyer_P/0/1/0/all/0/1&quot;&gt;Pierre-Yves Oudeyer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.00119">
<title>Integrating Human-Provided Information Into Belief State Representation Using Dynamic Factorization. (arXiv:1803.00119v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1803.00119</link>
<description rdf:parseType="Literal">&lt;p&gt;In partially observed environments, it can be useful for a human to provide
the robot with declarative information that represents probabilistic relational
constraints on properties of objects in the world, augmenting the robot&apos;s
sensory observations. For instance, a robot tasked with a search-and-rescue
mission may be informed by the human that two victims are probably in the same
room. An important question arises: how should we represent the robot&apos;s
internal knowledge so that this information is correctly processed and combined
with raw sensory information? In this paper, we provide an efficient belief
state representation that dynamically selects an appropriate factoring,
combining aspects of the belief when they are correlated through information
and separating them when they are not. This strategy works in open domains, in
which the set of possible objects is not known in advance, and provides
significant improvements in inference time over a static factoring, leading to
more efficient planning for complex partially observed tasks. We validate our
approach experimentally in two open-domain planning problems: a 2D discrete
gridworld task and a 3D continuous cooking task.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chitnis_R/0/1/0/all/0/1&quot;&gt;Rohan Chitnis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kaelbling_L/0/1/0/all/0/1&quot;&gt;Leslie Pack Kaelbling&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lozano_Perez_T/0/1/0/all/0/1&quot;&gt;Tom&amp;#xe1;s Lozano-P&amp;#xe9;rez&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.06333">
<title>Snap ML: A Hierarchical Framework for Machine Learning. (arXiv:1803.06333v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1803.06333</link>
<description rdf:parseType="Literal">&lt;p&gt;We describe a new software framework for fast training of generalized linear
models. The framework, named Snap Machine Learning (Snap ML), combines recent
advances in machine learning systems and algorithms in a nested manner to
reflect the hierarchical architecture of modern computing systems. We prove
theoretically that such a hierarchical system can accelerate training in
distributed environments where intra-node communication is cheaper than
inter-node communication. Additionally, we provide a review of the
implementation of Snap ML in terms of GPU acceleration, pipelining,
communication patterns and software architecture, highlighting aspects that
were critical for achieving high performance. We evaluate the performance of
Snap ML in both single-node and multi-node environments, quantifying the
benefit of the hierarchical scheme and the data streaming functionality, and
comparing with other widely-used machine learning software frameworks. Finally,
we present a logistic regression benchmark on the Criteo Terabyte Click Logs
dataset and show that Snap ML achieves the same test loss an order of magnitude
faster than any of the previously reported results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dunner_C/0/1/0/all/0/1&quot;&gt;Celestine D&amp;#xfc;nner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Parnell_T/0/1/0/all/0/1&quot;&gt;Thomas Parnell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sarigiannis_D/0/1/0/all/0/1&quot;&gt;Dimitrios Sarigiannis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ioannou_N/0/1/0/all/0/1&quot;&gt;Nikolas Ioannou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Anghel_A/0/1/0/all/0/1&quot;&gt;Andreea Anghel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pozidis_H/0/1/0/all/0/1&quot;&gt;Haralampos Pozidis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.02717">
<title>DeepMimic: Example-Guided Deep Reinforcement Learning of Physics-Based Character Skills. (arXiv:1804.02717v2 [cs.GR] UPDATED)</title>
<link>http://arxiv.org/abs/1804.02717</link>
<description rdf:parseType="Literal">&lt;p&gt;A longstanding goal in character animation is to combine data-driven
specification of behavior with a system that can execute a similar behavior in
a physical simulation, thus enabling realistic responses to perturbations and
environmental variation. We show that well-known reinforcement learning (RL)
methods can be adapted to learn robust control policies capable of imitating a
broad range of example motion clips, while also learning complex recoveries,
adapting to changes in morphology, and accomplishing user-specified goals. Our
method handles keyframed motions, highly-dynamic actions such as
motion-captured flips and spins, and retargeted motions. By combining a
motion-imitation objective with a task objective, we can train characters that
react intelligently in interactive settings, e.g., by walking in a desired
direction or throwing a ball at a user-specified target. This approach thus
combines the convenience and motion quality of using motion clips to define the
desired style and appearance, with the flexibility and generality afforded by
RL methods and physics-based animation. We further explore a number of methods
for integrating multiple clips into the learning process to develop
multi-skilled agents capable of performing a rich repertoire of diverse skills.
We demonstrate results using multiple characters (human, Atlas robot, bipedal
dinosaur, dragon) and a large variety of skills, including locomotion,
acrobatics, and martial arts.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peng_X/0/1/0/all/0/1&quot;&gt;Xue Bin Peng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1&quot;&gt;Pieter Abbeel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1&quot;&gt;Sergey Levine&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Panne_M/0/1/0/all/0/1&quot;&gt;Michiel van de Panne&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.10829">
<title>Formal Security Analysis of Neural Networks using Symbolic Intervals. (arXiv:1804.10829v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1804.10829</link>
<description rdf:parseType="Literal">&lt;p&gt;Due to the increasing deployment of Deep Neural Networks (DNNs) in real-world
security-critical domains including autonomous vehicles and collision avoidance
systems, formally checking security properties of DNNs, especially under
different attacker capabilities, is becoming crucial. Most existing security
testing techniques for DNNs try to find adversarial examples without providing
any formal security guarantees about the non-existence of adversarial examples.
Recently, several projects have used different types of Satisfiability Modulo
Theory (SMT) solvers to formally check security properties of DNNs. However,
all of these approaches are limited by the high overhead caused by the solver.
&lt;/p&gt;
&lt;p&gt;In this paper, we present a new direction for formally checking security
properties of DNNs without using SMT solvers. Instead, we leverage interval
arithmetic to formally check security properties by computing rigorous bounds
on the DNN outputs. Our approach, unlike existing solver-based approaches, is
easily parallelizable. We further present symbolic interval analysis along with
several other optimizations to minimize overestimations.
&lt;/p&gt;
&lt;p&gt;We design, implement, and evaluate our approach as part of ReluVal, a system
for formally checking security properties of Relu-based DNNs. Our extensive
empirical results show that ReluVal outperforms Reluplex, a state-of-the-art
solver-based system, by 200 times on average for the same security properties.
ReluVal is able to prove a security property within 4 hours on a single 8-core
machine without GPUs, while Reluplex deemed inconclusive due to timeout (more
than 5 days). Our experiments demonstrate that symbolic interval analysis is a
promising new direction towards rigorously analyzing different security
properties of DNNs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1&quot;&gt;Shiqi Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pei_K/0/1/0/all/0/1&quot;&gt;Kexin Pei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Whitehouse_J/0/1/0/all/0/1&quot;&gt;Justin Whitehouse&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1&quot;&gt;Junfeng Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jana_S/0/1/0/all/0/1&quot;&gt;Suman Jana&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08263">
<title>Planning to Give Information in Partially Observed Domains with a Learned Weighted Entropy Model. (arXiv:1805.08263v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1805.08263</link>
<description rdf:parseType="Literal">&lt;p&gt;In many robotic applications, an autonomous agent must act within and explore
a partially observed environment that is unobserved by its human teammate. We
consider such a setting in which the agent can, while acting, transmit
declarative information to the human that helps them understand aspects of this
unseen environment. Naturally, the human will have preferences about what
information they are given. This work adopts an information-theoretic view of
the human&apos;s preferences: the human scores information based on the induced
change in weighted entropy of their belief about the environment state. We
formulate this setting as a belief MDP and give an algorithm for solving it
approximately. Then, we give an algorithm that allows the agent to learn the
human&apos;s preferences online. We validate our approach experimentally in
simulated discrete and continuous partially observed search-and-recover
domains.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chitnis_R/0/1/0/all/0/1&quot;&gt;Rohan Chitnis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kaelbling_L/0/1/0/all/0/1&quot;&gt;Leslie Pack Kaelbling&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lozano_Perez_T/0/1/0/all/0/1&quot;&gt;Tom&amp;#xe1;s Lozano-P&amp;#xe9;rez&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02242">
<title>Extraction Of Technical Information From Normative Documents Using Automated Methods Based On Ontologies : Application To The Iso 15531 Mandate Standard - Methodology And First Results. (arXiv:1806.02242v2 [cs.SE] UPDATED)</title>
<link>http://arxiv.org/abs/1806.02242</link>
<description rdf:parseType="Literal">&lt;p&gt;Problems faced by international standardization bodies become more and more
crucial as the number and the size of the standards they produce increase.
Sometimes, also, the lack of coordination among the committees in charge of the
development of standards may lead to overlaps, mistakes or incompatibilities in
the documents. The aim of this study is to present a methodology enabling an
automatic extraction of the technical concepts (terms) found in normative
documents, through the use of semantic tools coming from the field of language
processing. The first part of the paper provides a description of the
standardization world, its structure, its way of working and the problems
faced; we then introduce the concepts of semantic annotation, information
extraction and the software tools available in this domain. The next section
explains the concept of ontology and its potential use in the field of
standardization. We propose here a methodology enabling the extraction of
technical information from a given normative corpus, based on a semantic
annotation process done according to reference ontologies. The application to
the ISO 15531 MANDATE corpus provides a first use case of the methodology
described in this paper. The paper ends with the description of the first
experimental results produced by this approach, and with some issues and
perspectives, notably its application to other standards and, or Technical
Committees and the possibility offered to create pre-defined technical
dictionaries of terms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cutting_Decelle_A/0/1/0/all/0/1&quot;&gt;A.F. Cutting-Decelle&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Digeon_A/0/1/0/all/0/1&quot;&gt;A. Digeon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Young_R/0/1/0/all/0/1&quot;&gt;R.I. Young&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barraud_J/0/1/0/all/0/1&quot;&gt;J.L. Barraud&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lamboley_P/0/1/0/all/0/1&quot;&gt;P. Lamboley&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02711">
<title>POTs: The revolution will not be optimized?. (arXiv:1806.02711v2 [cs.CY] UPDATED)</title>
<link>http://arxiv.org/abs/1806.02711</link>
<description rdf:parseType="Literal">&lt;p&gt;Optimization systems infer, induce, and shape events in the real world to
fulfill objective functions. Protective optimization technologies (POTs)
reconfigure these events as a response to the effects of optimization on a
group of users or local environment. POTs analyze how events (or lack thereof)
affect users and environments, then manipulate these events to influence system
outcomes, e.g., by altering the optimization constraints and poisoning system
inputs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gurses_S/0/1/0/all/0/1&quot;&gt;Seda Gurses&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Overdorf_R/0/1/0/all/0/1&quot;&gt;Rebekah Overdorf&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Balsa_E/0/1/0/all/0/1&quot;&gt;Ero Balsa&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06086">
<title>Minibatch Gibbs Sampling on Large Graphical Models. (arXiv:1806.06086v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.06086</link>
<description rdf:parseType="Literal">&lt;p&gt;Gibbs sampling is the de facto Markov chain Monte Carlo method used for
inference and learning on large scale graphical models. For complicated factor
graphs with lots of factors, the performance of Gibbs sampling can be limited
by the computational cost of executing a single update step of the Markov
chain. This cost is proportional to the degree of the graph, the number of
factors adjacent to each variable. In this paper, we show how this cost can be
reduced by using minibatching: subsampling the factors to form an estimate of
their sum. We introduce several minibatched variants of Gibbs, show that they
can be made unbiased, prove bounds on their convergence rates, and show that
under some conditions they can result in asymptotic single-update-run-time
speedups over plain Gibbs sampling.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sa_C/0/1/0/all/0/1&quot;&gt;Christopher De Sa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_V/0/1/0/all/0/1&quot;&gt;Vincent Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wong_W/0/1/0/all/0/1&quot;&gt;Wing Wong&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06095">
<title>Crime Event Embedding with Unsupervised Feature Selection. (arXiv:1806.06095v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.06095</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a novel event embedding algorithm for crime data that can jointly
capture time, location, and the complex free-text component of each event. The
embedding is achieved by regularized Restricted Boltzmann Machines (RBMs), and
we introduce a new way to regularize by imposing a $\ell_1$ penalty on the
conditional distributions of the observed variables of RBMs. This choice of
regularization performs feature selection and it also leads to efficient
computation since the gradient can be computed in a closed form. The feature
selection forces embedding to be based on the most important keywords, which
captures the common modus operandi (M. O.) in crime series. Using numerical
experiments on a large-scale crime dataset, we show that our regularized RBMs
can achieve better event embedding and the selected features are highly
interpretable from human understanding.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhu_S/0/1/0/all/0/1&quot;&gt;Shixiang Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Xie_Y/0/1/0/all/0/1&quot;&gt;Yao Xie&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06100">
<title>The Limits of Post-Selection Generalization. (arXiv:1806.06100v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.06100</link>
<description rdf:parseType="Literal">&lt;p&gt;While statistics and machine learning offers numerous methods for ensuring
generalization, these methods often fail in the presence of adaptivity---the
common practice in which the choice of analysis depends on previous
interactions with the same dataset. A recent line of work has introduced
powerful, general purpose algorithms that ensure post hoc generalization (also
called robust or post-selection generalization), which says that, given the
output of the algorithm, it is hard to find any statistic for which the data
differs significantly from the population it came from.
&lt;/p&gt;
&lt;p&gt;In this work we show several limitations on the power of algorithms
satisfying post hoc generalization. First, we show a tight lower bound on the
error of any algorithm that satisfies post hoc generalization and answers
adaptively chosen statistical queries, showing a strong barrier to progress in
post selection data analysis. Second, we show that post hoc generalization is
not closed under composition, despite many examples of such algorithms
exhibiting strong composition properties.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nissim_K/0/1/0/all/0/1&quot;&gt;Kobbi Nissim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Smith_A/0/1/0/all/0/1&quot;&gt;Adam Smith&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Steinke_T/0/1/0/all/0/1&quot;&gt;Thomas Steinke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stemmer_U/0/1/0/all/0/1&quot;&gt;Uri Stemmer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ullman_J/0/1/0/all/0/1&quot;&gt;Jonathan Ullman&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06121">
<title>Machine learning for prediction of extreme statistics in modulation instability. (arXiv:1806.06121v1 [physics.comp-ph])</title>
<link>http://arxiv.org/abs/1806.06121</link>
<description rdf:parseType="Literal">&lt;p&gt;A central area of research in nonlinear science is the study of instabilities
that drive the emergence of extreme events. Unfortunately, experimental
techniques for measuring such phenomena often provide only partial
characterization. For example, real-time studies of instabilities in nonlinear
fibre optics frequently use only spectral data, precluding detailed predictions
about the associated temporal properties. Here, we show how Machine Learning
can overcome this limitation by predicting statistics for the maximum intensity
of temporal peaks in modulation instability based only on spectral
measurements. Specifically, we train a neural network based Machine Learning
model to correlate spectral and temporal properties of optical fibre modulation
instability using data from numerical simulations, and we then use this model
to predict the temporal probability distribution based on high-dynamic range
spectral data from experiments. These results open novel perspectives in all
systems exhibiting chaos and instability where direct time-domain observations
are difficult.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Narhi_M/0/1/0/all/0/1&quot;&gt;Mikko N&amp;#xe4;rhi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Salmela_L/0/1/0/all/0/1&quot;&gt;Lauri Salmela&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Toivonen_J/0/1/0/all/0/1&quot;&gt;Juha Toivonen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Billet_C/0/1/0/all/0/1&quot;&gt;Cyril Billet&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Dudley_J/0/1/0/all/0/1&quot;&gt;John M. Dudley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Genty_G/0/1/0/all/0/1&quot;&gt;Go&amp;#xeb;ry Genty&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06122">
<title>Fairness Under Composition. (arXiv:1806.06122v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.06122</link>
<description rdf:parseType="Literal">&lt;p&gt;Much of the literature on fair classifiers considers the case of a single
classifier used once, in isolation. We initiate the study of composition of
fair classifiers. In particular, we address the pitfalls of na{\i}ve
composition and give general constructions for fair composition. Focusing on
the individual fairness setting proposed in [Dwork, Hardt, Pitassi, Reingold,
Zemel, 2011], we also extend our results to a large class of group fairness
definitions popular in the recent literature. We exhibit several cases in which
group fairness definitions give misleading signals under composition and
conclude that additional context is needed to evaluate both group and
individual fairness under composition.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dwork_C/0/1/0/all/0/1&quot;&gt;Cynthia Dwork&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ilvento_C/0/1/0/all/0/1&quot;&gt;Christina Ilvento&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06123">
<title>On the Relationship between Data Efficiency and Error for Uncertainty Sampling. (arXiv:1806.06123v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.06123</link>
<description rdf:parseType="Literal">&lt;p&gt;While active learning offers potential cost savings, the actual data
efficiency---the reduction in amount of labeled data needed to obtain the same
error rate---observed in practice is mixed. This paper poses a basic question:
when is active learning actually helpful? We provide an answer for logistic
regression with the popular active learning algorithm, uncertainty sampling.
Empirically, on 21 datasets from OpenML, we find a strong inverse correlation
between data efficiency and the error rate of the final classifier.
Theoretically, we show that for a variant of uncertainty sampling, the
asymptotic data efficiency is within a constant factor of the inverse error
rate of the limiting classifier.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mussmann_S/0/1/0/all/0/1&quot;&gt;Stephen Mussmann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_P/0/1/0/all/0/1&quot;&gt;Percy Liang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06124">
<title>Supervised Fuzzy Partitioning. (arXiv:1806.06124v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.06124</link>
<description rdf:parseType="Literal">&lt;p&gt;Centroid-based methods including k-means and fuzzy c-means (FCM) are known as
effective and easy-to-implement approaches to clustering purposes in many areas
of application. However, these algorithms cannot be directly applied to
supervised tasks. We propose a generative model extending centroid-based
clustering approaches to be applicable to classification and regression
problems. Given an arbitrary loss function, our approach, termed supervised
fuzzy partitioning (SFP), incorporates labels information into its objective
function through a surrogate term penalizing the risk. We also fuzzify the
partition and assign weights to features alongside entropy-based regularization
terms, enabling the method to capture more complex data structure, to identify
significant features, and to yield better performance facing high-dimensional
data. An iterative algorithm based on block coordinate descent (BCD) scheme was
formulated to efficiently find a local optimizer. The results show that the SFP
performance in classification and supervised dimensionality reduction on
synthetic and real-world datasets is competitive with state-of-the-art
algorithms such as random forest and SVM. Our method has a major advantage over
such methods in that it not only leads to a flexible model but also uses the
loss function in training phase without compromising computational efficiency.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ashtari_P/0/1/0/all/0/1&quot;&gt;Pooya Ashtari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Haredasht_F/0/1/0/all/0/1&quot;&gt;Fateme Nateghi Haredasht&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06142">
<title>Morse Theory and an Impossibility Theorem for Graph Clustering. (arXiv:1806.06142v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.06142</link>
<description rdf:parseType="Literal">&lt;p&gt;Kleinberg introduced three natural clustering properties, or axioms, and
showed they cannot be simultaneously satisfied by any clustering algorithm. We
present a new clustering property, Monotonic Consistency, which avoids the
well-known problematic behaviour of Kleinberg&apos;s Consistency axiom, and the
impossibility result. Namely, we describe a clustering algorithm, Morse
Clustering, inspired by Morse Theory in Differential Topology, which satisfies
Kleinberg&apos;s original axioms with Consistency replaced by Monotonic Consistency.
Morse clustering uncovers the underlying flow structure on a set or graph and
returns a partition into trees representing basins of attraction of critical
vertices. We also generalise Kleinberg&apos;s axiomatic approach to sparse graphs,
showing an impossibility result for Consistency, and a possibility result for
Monotonic Consistency and Morse clustering.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Strazzeri_F/0/1/0/all/0/1&quot;&gt;Fabio Strazzeri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sanchez_Garcia_R/0/1/0/all/0/1&quot;&gt;Rub&amp;#xe9;n J. S&amp;#xe1;nchez-Garc&amp;#xed;a&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06209">
<title>The Reduced PC-Algorithm: Improved Causal Structure Learning in Large Random Networks. (arXiv:1806.06209v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.06209</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the task of estimating a high-dimensional directed acyclic graph,
given observations from a linear structural equation model with arbitrary noise
distribution. By exploiting properties of common random graphs, we develop a
new algorithm that requires conditioning only on small sets of variables. The
proposed algorithm, which is essentially a modified version of the
PC-Algorithm, offers significant gains in both computational complexity and
estimation accuracy. In particular, it results in more efficient and accurate
estimation in large networks containing hub nodes, which are common in
biological systems. We prove the consistency of the proposed algorithm, and
show that it also requires a less stringent faithfulness assumption than the
PC-Algorithm. Simulations in low and high-dimensional settings are used to
illustrate these findings. An application to gene expression data suggests that
the proposed algorithm can identify a greater number of clinically relevant
genes than current methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sondhi_A/0/1/0/all/0/1&quot;&gt;Arjun Sondhi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Shojaie_A/0/1/0/all/0/1&quot;&gt;Ali Shojaie&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06237">
<title>PeerReview4All: Fair and Accurate Reviewer Assignment in Peer Review. (arXiv:1806.06237v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.06237</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the problem of automated assignment of papers to reviewers in
conference peer review, with a focus on fairness and statistical accuracy. Our
fairness objective is to maximize the review quality of the most disadvantaged
paper, in contrast to the commonly used objective of maximizing the total
quality over all papers. We design an assignment algorithm based on an
incremental max-flow procedure that we prove is near-optimally fair. Our
statistical accuracy objective is to ensure correct recovery of the papers that
should be accepted. We provide a sharp minimax analysis of the accuracy of the
peer-review process for a popular objective-score model as well as for a novel
subjective-score model that we propose in the paper. Our analysis proves that
our proposed assignment algorithm also leads to a near-optimal statistical
accuracy. Finally, we design a novel experiment that allows for an objective
comparison of various assignment algorithms, and overcomes the inherent
difficulty posed by the absence of a ground truth in experiments on
peer-review. The results of this experiment corroborate the theoretical
guarantees of our algorithm.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Stelmakh_I/0/1/0/all/0/1&quot;&gt;Ivan Stelmakh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Shah_N/0/1/0/all/0/1&quot;&gt;Nihar B. Shah&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Singh_A/0/1/0/all/0/1&quot;&gt;Aarti Singh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06270">
<title>Stable Prediction across Unknown Environments. (arXiv:1806.06270v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.06270</link>
<description rdf:parseType="Literal">&lt;p&gt;In many important machine learning applications, the training distribution
used to learn a probabilistic classifier differs from the testing distribution
on which the classifier will be used to make predictions. Traditional methods
correct the distribution shift by reweighting the training data with the ratio
of the density between test and training data. In many applications training
takes place without prior knowledge of the testing distribution on which the
algorithm will be applied in the future. Recently, methods have been proposed
to address the shift by learning causal structure, but those methods rely on
the diversity of multiple training data to a good performance, and have
complexity limitations in high dimensions. In this paper, we propose a novel
Deep Global Balancing Regression (DGBR) algorithm to jointly optimize a deep
auto-encoder model for feature selection and a global balancing model for
stable prediction across unknown environments. The global balancing model
constructs balancing weights that facilitate estimating of partial effects of
features (holding fixed all other features), a problem that is challenging in
high dimensions, and thus helps to identify stable, causal relationships
between features and outcomes. The deep auto-encoder model is designed to
reduce the dimensionality of the feature space, thus making global balancing
easier. We show, both theoretically and with empirical experiments, that our
algorithm can make stable predictions across unknown environments. Our
experiments on both synthetic and real world datasets demonstrate that our DGBR
algorithm outperforms the state-of-the-art methods for stable prediction across
unknown environments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kuang_K/0/1/0/all/0/1&quot;&gt;Kun Kuang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiong_R/0/1/0/all/0/1&quot;&gt;Ruoxuan Xiong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cui_P/0/1/0/all/0/1&quot;&gt;Peng Cui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Athey_S/0/1/0/all/0/1&quot;&gt;Susan Athey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1&quot;&gt;Bo Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06317">
<title>Laplacian Smoothing Gradient Descent. (arXiv:1806.06317v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.06317</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a very simple modification of gradient descent and stochastic
gradient descent. We show that when applied to a variety of machine learning
models including softmax regression, convolutional neural nets, generative
adversarial nets, and deep reinforcement learning, this very simple surrogate
can dramatically reduce the variance and improve the accuracy of the
generalization. The new algorithm, (which depends on one nonnegative parameter)
when applied to non-convex minimization, tends to avoid sharp local minima.
Instead it seeks somewhat flatter local (and often global) minima. The method
only involves preconditioning the gradient by the inverse of a tri-diagonal
matrix that is positive definite. The motivation comes from the theory of
Hamilton-Jacobi partial differential equations. This theory demonstrates that
the new algorithm is almost the same as doing gradient descent on a new
function which (a) has the same global minima as the original function and (b)
is &quot;more convex&quot;. Again, the programming effort in doing this is minimal, in
cost, complexity and effort. We implement our algorithm into both PyTorch and
Tensorflow platforms, which will be made publicly available.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Osher_S/0/1/0/all/0/1&quot;&gt;Stanley Osher&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1&quot;&gt;Bao Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yin_P/0/1/0/all/0/1&quot;&gt;Penghang Yin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_X/0/1/0/all/0/1&quot;&gt;Xiyang Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pham_M/0/1/0/all/0/1&quot;&gt;Minh Pham&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_A/0/1/0/all/0/1&quot;&gt;Alex Lin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06392">
<title>Task-Relevant Object Discovery and Categorization for Playing First-person Shooter Games. (arXiv:1806.06392v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.06392</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the problem of learning to play first-person shooter (FPS) video
games using raw screen images as observations and keyboard inputs as actions.
The high-dimensionality of the observations in this type of applications leads
to prohibitive needs of training data for model-free methods, such as the deep
Q-network (DQN), and its recurrent variant DRQN. Thus, recent works focused on
learning low-dimensional representations that may reduce the need for data.
This paper presents a new and efficient method for learning such
representations. Salient segments of consecutive frames are detected from their
optical flow, and clustered based on their feature descriptors. The clusters
typically correspond to different discovered categories of objects. Segments
detected in new frames are then classified based on their nearest clusters.
Because only a few categories are relevant to a given task, the importance of a
category is defined as the correlation between its occurrence and the agent&apos;s
performance. The result is encoded as a vector indicating objects that are in
the frame and their locations, and used as a side input to DRQN. Experiments on
the game Doom provide a good evidence for the benefit of this approach.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_J/0/1/0/all/0/1&quot;&gt;Junchi Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Boularias_A/0/1/0/all/0/1&quot;&gt;Abdeslam Boularias&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06415">
<title>Feature Learning and Classification in Neuroimaging: Predicting Cognitive Impairment from Magnetic Resonance Imaging. (arXiv:1806.06415v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.06415</link>
<description rdf:parseType="Literal">&lt;p&gt;Due to the rapid innovation of technology and the desire to find and employ
biomarkers for neurodegenerative disease, high-dimensional data classification
problems are routinely encountered in neuroimaging studies. To avoid
over-fitting and to explore relationships between disease and potential
biomarkers, feature learning and selection plays an important role in
classifier construction and is an important area in machine learning. In this
article, we review several important feature learning and selection techniques
including lasso-based methods, PCA, the two-sample t-test, and stacked
auto-encoders. We compare these approaches using a numerical study involving
the prediction of Alzheimer&apos;s disease from Magnetic Resonance Imaging.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Shi_S/0/1/0/all/0/1&quot;&gt;Shan Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Nathoo_F/0/1/0/all/0/1&quot;&gt;Farouk Nathoo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06438">
<title>Compressed Sensing with Deep Image Prior and Learned Regularization. (arXiv:1806.06438v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.06438</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a novel method for compressed sensing recovery using untrained
deep generative models. Our method is based on the recently proposed Deep Image
Prior (DIP), wherein the convolutional weights of the network are optimized to
match the observed measurements. We show that this approach can be applied to
solve any differentiable inverse problem. We also introduce a novel learned
regularization technique which incorporates a small amount of prior
information, further reducing the number of measurements required for a given
reconstruction error. Our algorithm requires approximately 4-6x fewer
measurements than classical Lasso methods. Unlike previous approaches based on
generative models, our method does not require the model to be pre-trained. As
such, we can apply our method to various medical imaging datasets for which
data acquisition is expensive and no known generative models exist.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Veen_D/0/1/0/all/0/1&quot;&gt;David Van Veen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Jalal_A/0/1/0/all/0/1&quot;&gt;Ajil Jalal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Price_E/0/1/0/all/0/1&quot;&gt;Eric Price&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Vishwanath_S/0/1/0/all/0/1&quot;&gt;Sriram Vishwanath&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Dimakis_A/0/1/0/all/0/1&quot;&gt;Alexandros G. Dimakis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06439">
<title>Predicting Switching Graph Labelings with Cluster Specialists. (arXiv:1806.06439v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.06439</link>
<description rdf:parseType="Literal">&lt;p&gt;We address the problem of predicting the labeling of a graph in an online
setting when the labeling is changing over time. We provide three
mistake-bounded algorithms based on three paradigmatic methods for online
algorithm design. The algorithm with the strongest guarantee is a
quasi-Bayesian classifier which requires $\mathcal{O}(t \log n)$ time to
predict at trial $t$ on an $n$-vertex graph. The fastest algorithm (with the
weakest guarantee) is based on a specialist [10] approach and surprisingly only
requires $\mathcal{O}(\log n)$ time on any trial $t$. We also give an algorithm
based on a kernelized Perceptron with an intermediate per-trial time complexity
of $\mathcal{O}(n)$ and a mistake bound which is not strictly comparable.
Finally, we provide experiments on simulated data comparing these methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Herbster_M/0/1/0/all/0/1&quot;&gt;Mark Herbster&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Robinson_J/0/1/0/all/0/1&quot;&gt;James Robinson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06457">
<title>Fast Convex Pruning of Deep Neural Networks. (arXiv:1806.06457v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.06457</link>
<description rdf:parseType="Literal">&lt;p&gt;We develop a fast, tractable technique called Net-Trim for simplifying a
trained neural network. The method is a convex post-processing module, which
prunes (sparsifies) a trained network layer by layer, while preserving the
internal responses. We present a comprehensive analysis of Net-Trim from both
the algorithmic and sample complexity standpoints, centered on a fast, scalable
convex optimization program. Our analysis includes consistency results between
the initial and retrained models before and after Net-Trim application and
guarantees on the number of training samples needed to discover a network that
can be expressed using a certain number of nonzero terms. Specifically, if
there is a set of weights that uses at most $s$ terms that can re-create the
layer outputs from the layer inputs, we can find these weights from
$\mathcal{O}(s\log N/s)$ samples, where $N$ is the input size. These
theoretical results are similar to those for sparse regression using the Lasso,
and our analysis uses some of the same recently-developed tools (namely recent
results on the concentration of measure and convex analysis). Finally, we
propose an algorithmic framework based on the alternating direction method of
multipliers (ADMM), which allows a fast and simple implementation of Net-Trim
for network pruning and compression.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aghasi_A/0/1/0/all/0/1&quot;&gt;Alireza Aghasi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abdi_A/0/1/0/all/0/1&quot;&gt;Afshin Abdi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Romberg_J/0/1/0/all/0/1&quot;&gt;Justin Romberg&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06553">
<title>Incremental Sparse Bayesian Ordinal Regression. (arXiv:1806.06553v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.06553</link>
<description rdf:parseType="Literal">&lt;p&gt;Ordinal Regression (OR) aims to model the ordering information between
different data categories, which is a crucial topic in multi-label learning. An
important class of approaches to OR models the problem as a linear combination
of basis functions that map features to a high dimensional non-linear space.
However, most of the basis function-based algorithms are time consuming. We
propose an incremental sparse Bayesian approach to OR tasks and introduce an
algorithm to sequentially learn the relevant basis functions in the ordinal
scenario. Our method, called Incremental Sparse Bayesian Ordinal Regression
(ISBOR), automatically optimizes the hyper-parameters via the type-II maximum
likelihood method. By exploiting fast marginal likelihood optimization, ISBOR
can avoid big matrix inverses, which is the main bottleneck in applying basis
function-based algorithms to OR tasks on large-scale datasets. We show that
ISBOR can make accurate predictions with parsimonious basis functions while
offering automatic estimates of the prediction uncertainty. Extensive
experiments on synthetic and real word datasets demonstrate the efficiency and
effectiveness of ISBOR compared to other basis function-based OR approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1&quot;&gt;Chang Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rijke_M/0/1/0/all/0/1&quot;&gt;Maarten de Rijke&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06573">
<title>Distributed learning with compressed gradients. (arXiv:1806.06573v1 [math.OC])</title>
<link>http://arxiv.org/abs/1806.06573</link>
<description rdf:parseType="Literal">&lt;p&gt;Asynchronous computation and gradient compression have emerged as two key
techniques for achieving scalability in distributed optimization for
large-scale machine learning. This paper presents a unified analysis framework
for distributed gradient methods operating with staled and compressed
gradients. Non-asymptotic bounds on convergence rates and information exchange
are derived for several optimization algorithms. These bounds give explicit
expressions for step-sizes and characterize how the amount of asynchrony and
the compression accuracy affect iteration and communication complexity
guarantees. Numerical results highlight convergence properties of different
gradient compression algorithms and confirm that fast convergence under limited
information exchange is indeed possible.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Khirirat_S/0/1/0/all/0/1&quot;&gt;Sarit Khirirat&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Feyzmahdavian_H/0/1/0/all/0/1&quot;&gt;Hamid Reza Feyzmahdavian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Johansson_M/0/1/0/all/0/1&quot;&gt;Mikael Johansson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06610">
<title>Evaluating and Characterizing Incremental Learning from Non-Stationary Data. (arXiv:1806.06610v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.06610</link>
<description rdf:parseType="Literal">&lt;p&gt;Incremental learning from non-stationary data poses special challenges to the
field of machine learning. Although new algorithms have been developed for
this, assessment of results and comparison of behaviors are still open
problems, mainly because evaluation metrics, adapted from more traditional
tasks, can be ineffective in this context. Overall, there is a lack of common
testing practices. This paper thus presents a testbed for incremental
non-stationary learning algorithms, based on specially designed synthetic
datasets. Also, test results are reported for some well-known algorithms to
show that the proposed methodology is effective at characterizing their
strengths and weaknesses. It is expected that this methodology will provide a
common basis for evaluating future contributions in the field.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cervantes_A/0/1/0/all/0/1&quot;&gt;Alejandro Cervantes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gagne_C/0/1/0/all/0/1&quot;&gt;Christian Gagn&amp;#xe9;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Isasi_P/0/1/0/all/0/1&quot;&gt;Pedro Isasi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Parizeau_M/0/1/0/all/0/1&quot;&gt;Marc Parizeau&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06720">
<title>An Online Prediction Algorithm for Reinforcement Learning with Linear Function Approximation using Cross Entropy Method. (arXiv:1806.06720v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.06720</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we provide two new stable online algorithms for the problem of
prediction in reinforcement learning, \emph{i.e.}, estimating the value
function of a model-free Markov reward process using the linear function
approximation architecture and with memory and computation costs scaling
quadratically in the size of the feature set. The algorithms employ the
multi-timescale stochastic approximation variant of the very popular cross
entropy (CE) optimization method which is a model based search method to find
the global optimum of a real-valued function. A proof of convergence of the
algorithms using the ODE method is provided. We supplement our theoretical
results with experimental comparisons. The algorithms achieve good performance
fairly consistently on many RL benchmark problems with regards to computational
efficiency, accuracy and stability.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Joseph_A/0/1/0/all/0/1&quot;&gt;Ajin George Joseph&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bhatnagar_S/0/1/0/all/0/1&quot;&gt;Shalabh Bhatnagar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06777">
<title>MultiFIT: Multivariate Multiscale Framework for Independence Tests. (arXiv:1806.06777v1 [stat.ME])</title>
<link>http://arxiv.org/abs/1806.06777</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a framework for testing independence between two random vectors
that is scalable to massive data. Taking a &quot;divide-and-conquer&quot; approach, we
break down the nonparametric multivariate test of independence into simple
univariate independence tests on a collection of $2\times 2$ contingency
tables, constructed by sequentially discretizing the original sample space at a
cascade of scales from coarse to fine. This transforms a complex nonparametric
testing problem---that traditionally requires quadratic computational
complexity with respect to the sample size---into a multiple testing problem
that can be addressed with a computational complexity that scales almost
linearly with the sample size. We further consider the scenario when the
dimensionality of the two random vectors also grows large, in which case the
curse of dimensionality arises in the proposed framework through an explosion
in the number of univariate tests to be completed. To overcome this difficulty,
we propose a data-adaptive version of our method that completes a fraction of
the univariate tests, judged to be more likely to contain evidence for
dependency based on exploiting the spatial characteristics of the dependency
structure in the data. We provide an inference recipe based on multiple testing
adjustment that guarantees the inferential validity in terms of properly
controlling the family-wise error rate. We demonstrate the tremendous
computational advantage of the algorithm in comparison to existing approaches
while achieving desirable statistical power through an extensive simulation
study. In addition, we illustrate how our method can be used for learning the
nature of the underlying dependency in addition to hypothesis testing. We
demonstrate the use of our method through analyzing a data set from flow
cytometry.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gorsky_S/0/1/0/all/0/1&quot;&gt;Shai Gorsky&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ma_L/0/1/0/all/0/1&quot;&gt;Li Ma&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06784">
<title>Flexible Collaborative Estimation of the Average Causal Effect of a Treatment using the Outcome-Highly-Adaptive Lasso. (arXiv:1806.06784v1 [stat.ME])</title>
<link>http://arxiv.org/abs/1806.06784</link>
<description rdf:parseType="Literal">&lt;p&gt;Many estimators of the average causal effect of an intervention require
estimation of the propensity score, the outcome regression, or both. For these
estimators, we must carefully con- sider how to estimate the relevant
regressions. It is often beneficial to utilize flexible techniques such as
semiparametric regression or machine learning. However, optimal estimation of
the regression function does not necessarily lead to optimal estimation of the
average causal effect. Therefore, it is important to consider criteria for
evaluating regression estimators and selecting hyper-parameters. A recent
proposal addressed these issues via the outcome-adaptive lasso, a penalized
regression technique for estimating the propensity score. We build on this
proposal and offer a method that is simultaneously more flexible and more
efficient than the previous pro- posal. We propose the outcome-highly-adaptive
LASSO, a semi-parametric regression estimator designed to down-weight regions
of the confounder space that do not contribute variation to the outcome
regression. We show that tuning this method using collaborative targeted
learning leads to superior finite-sample performance relative to competing
estimators.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ju_C/0/1/0/all/0/1&quot;&gt;Cheng Ju&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Benkeser_D/0/1/0/all/0/1&quot;&gt;David Benkeser&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Laan_M/0/1/0/all/0/1&quot;&gt;Mark J. van der Laan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06802">
<title>Collapsing-Fast-Large-Almost-Matching-Exactly: A Matching Method for Causal Inference. (arXiv:1806.06802v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.06802</link>
<description rdf:parseType="Literal">&lt;p&gt;We aim to create the highest possible quality of treatment-control matches
for categorical data in the potential outcomes framework. Matching methods are
heavily used in the social sciences due to their interpretability, but most
matching methods in the past do not pass basic sanity checks in that they fail
when irrelevant variables are introduced. Also, past methods tend to be either
computationally slow or produce poor matches. The method proposed in this work
aims to match units on a weighted Hamming distance, taking into account the
relative importance of the covariates; the algorithm aims to match units on as
many relevant variables as possible. To do this, the algorithm creates a
hierarchy of covariate combinations on which to match (similar to downward
closure), in the process solving an optimization problem for each unit in order
to construct the optimal matches. The algorithm uses a single dynamic program
to solve all of optimization problems simultaneously. Notable advantages of our
method over existing matching procedures are its high-quality matches,
versatility in handling different data distributions that may have irrelevant
variables, and ability to handle missing data by matching on as many available
covariates as possible
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Dieng_A/0/1/0/all/0/1&quot;&gt;Awa Dieng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yameng Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Roy_S/0/1/0/all/0/1&quot;&gt;Sudeepa Roy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rudin_C/0/1/0/all/0/1&quot;&gt;Cynthia Rudin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Volfovsky_A/0/1/0/all/0/1&quot;&gt;Alexander Volfovsky&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06827">
<title>PAC-Bayes bounds for stable algorithms with instance-dependent priors. (arXiv:1806.06827v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.06827</link>
<description rdf:parseType="Literal">&lt;p&gt;PAC-Bayes bounds have been proposed to get risk estimates based on a training
sample. In this paper the PAC-Bayes approach is combined with stability of the
hypothesis learned by a Hilbert space valued algorithm. The PAC-Bayes setting
is used with a Gaussian prior centered at the expected output. Thus a novelty
of our paper is using priors defined in terms of the data-generating
distribution. Our main result estimates the risk of the randomized algorithm in
terms of the hypothesis stability coefficients. We also provide a new bound for
the SVM classifier, which is compared to other known bounds experimentally.
Ours appears to be the first stability-based bound that evaluates to
non-trivial values.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rivasplata_O/0/1/0/all/0/1&quot;&gt;Omar Rivasplata&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Parrado_Hernandez_E/0/1/0/all/0/1&quot;&gt;Emilio Parrado-Hernandez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Shaws_Taylor_J/0/1/0/all/0/1&quot;&gt;John Shaws-Taylor&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sun_S/0/1/0/all/0/1&quot;&gt;Shiliang Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Szepesvari_C/0/1/0/all/0/1&quot;&gt;Csaba Szepesvari&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06850">
<title>Polynomial Regression As an Alternative to Neural Nets. (arXiv:1806.06850v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.06850</link>
<description rdf:parseType="Literal">&lt;p&gt;Despite the success of neural networks (NNs), there is still a concern among
many over their &quot;black box&quot; nature. Why do they work? Here we present a simple
analytic argument that NNs are in fact essentially polynomial regression
models. This view will have various implications for NNs, e.g. providing an
explanation for why convergence problems arise in NNs, and it gives rough
guidance on avoiding overfitting. In addition, we use this phenomenon to
predict and confirm a multicollinearity property of NNs not previously reported
in the literature. Most importantly, given this loose correspondence, one may
choose to routinely use polynomial models instead of NNs, thus avoiding some
major problems of the latter, such as having to set many tuning parameters and
dealing with convergence issues. We present a number of empirical results; in
each case, the accuracy of the polynomial approach matches or exceeds that of
NN approaches. A many-featured, open-source software package, polyreg, is
available.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_X/0/1/0/all/0/1&quot;&gt;Xi Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khomtchouk_B/0/1/0/all/0/1&quot;&gt;Bohdan Khomtchouk&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Matloff_N/0/1/0/all/0/1&quot;&gt;Norman Matloff&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mohanty_P/0/1/0/all/0/1&quot;&gt;Pete Mohanty&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1508.01248">
<title>Sparse Pseudo-input Local Kriging for Large Non-stationary Spatial Datasets with Exogenous Variables. (arXiv:1508.01248v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1508.01248</link>
<description rdf:parseType="Literal">&lt;p&gt;We study large-scale spatial systems that contain exogenous variables, e.g.
environmental factors that are significant predictors in spatial processes.
Building predictive models for such processes involve two major challenges.
First, the spatial processes are highly non-stationary and characterized by a
heterogeneous covariance structure primarily due to the presence of exogenous
variables. Second, it is inefficient to apply full Kriging because of the large
numbers of observations present. The new theorems proposed in this paper form
the basis for a new partitioning policy and a method, which we call Sparse
Pseudo-input Local Kriging (SPLK). The proposed method handles heterogeneity in
covariance and computational complexity by utilizing hyperplanes to partition a
domain into smaller subdomains and then applying a sparse approximation of the
full Kriging to each subdomain. We also develop a procedure to find the optimal
hyperplanes. We impose continuity constraints on the boundaries of the
neighboring subdomains to alleviate the problem of discontinuity of the global
predictor. Numerical experiments demonstrate that SPLK outperforms, or is
comparable to, the algorithms commonly applied to spatial datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Farmanesh_B/0/1/0/all/0/1&quot;&gt;Babak Farmanesh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pourhabib_A/0/1/0/all/0/1&quot;&gt;Arash Pourhabib&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1605.07129">
<title>Sub-Gaussian estimators of the mean of a random matrix with heavy-tailed entries. (arXiv:1605.07129v5 [math.ST] UPDATED)</title>
<link>http://arxiv.org/abs/1605.07129</link>
<description rdf:parseType="Literal">&lt;p&gt;Estimation of the covariance matrix has attracted a lot of attention of the
statistical research community over the years, partially due to important
applications such as Principal Component Analysis. However, frequently used
empirical covariance estimator (and its modifications) is very sensitive to
outliers in the data. As P. J. Huber wrote in 1964, &quot;...This raises a question
which could have been asked already by Gauss, but which was, as far as I know,
only raised a few years ago (notably by Tukey): what happens if the true
distribution deviates slightly from the assumed normal one? As is now well
known, the sample mean then may have a catastrophically bad performance...&quot;
Motivated by this question, we develop a new estimator of the (element-wise)
mean of a random matrix, which includes covariance estimation problem as a
special case. Assuming that the entries of a matrix possess only finite second
moment, this new estimator admits sub-Gaussian or sub-exponential concentration
around the unknown mean in the operator norm. We will explain the key ideas
behind our construction, as well as applications to covariance estimation and
matrix completion problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Minsker_S/0/1/0/all/0/1&quot;&gt;Stanislav Minsker&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1705.10819">
<title>Surface Networks. (arXiv:1705.10819v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1705.10819</link>
<description rdf:parseType="Literal">&lt;p&gt;We study data-driven representations for three-dimensional triangle meshes,
which are one of the prevalent objects used to represent 3D geometry. Recent
works have developed models that exploit the intrinsic geometry of manifolds
and graphs, namely the Graph Neural Networks (GNNs) and its spectral variants,
which learn from the local metric tensor via the Laplacian operator. Despite
offering excellent sample complexity and built-in invariances, intrinsic
geometry alone is invariant to isometric deformations, making it unsuitable for
many applications. To overcome this limitation, we propose several upgrades to
GNNs to leverage extrinsic differential geometry properties of
three-dimensional surfaces, increasing its modeling power.
&lt;/p&gt;
&lt;p&gt;In particular, we propose to exploit the Dirac operator, whose spectrum
detects principal curvature directions --- this is in stark contrast with the
classical Laplace operator, which directly measures mean curvature. We coin the
resulting models \emph{Surface Networks (SN)}. We prove that these models
define shape representations that are stable to deformation and to
discretization, and we demonstrate the efficiency and versatility of SNs on two
challenging tasks: temporal prediction of mesh deformations under non-linear
dynamics and generative models using a variational autoencoder framework with
encoders/decoders given by SNs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kostrikov_I/0/1/0/all/0/1&quot;&gt;Ilya Kostrikov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Jiang_Z/0/1/0/all/0/1&quot;&gt;Zhongshi Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Panozzo_D/0/1/0/all/0/1&quot;&gt;Daniele Panozzo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zorin_D/0/1/0/all/0/1&quot;&gt;Denis Zorin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bruna_J/0/1/0/all/0/1&quot;&gt;Joan Bruna&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.00106">
<title>First and Second Order Methods for Online Convolutional Dictionary Learning. (arXiv:1709.00106v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1709.00106</link>
<description rdf:parseType="Literal">&lt;p&gt;Convolutional sparse representations are a form of sparse representation with
a structured, translation invariant dictionary. Most convolutional dictionary
learning algorithms to date operate in batch mode, requiring simultaneous
access to all training images during the learning process, which results in
very high memory usage and severely limits the training data that can be used.
Very recently, however, a number of authors have considered the design of
online convolutional dictionary learning algorithms that offer far better
scaling of memory and computational cost with training set size than batch
methods. This paper extends our prior work, improving a number of aspects of
our previous algorithm; proposing an entirely new one, with better performance,
and that supports the inclusion of a spatial mask for learning from incomplete
data; and providing a rigorous theoretical analysis of these methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Jialin Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garcia_Cardona_C/0/1/0/all/0/1&quot;&gt;Cristina Garcia-Cardona&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wohlberg_B/0/1/0/all/0/1&quot;&gt;Brendt Wohlberg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yin_W/0/1/0/all/0/1&quot;&gt;Wotao Yin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.07283">
<title>Decomposition of Uncertainty in Bayesian Deep Learning for Efficient and Risk-sensitive Learning. (arXiv:1710.07283v4 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1710.07283</link>
<description rdf:parseType="Literal">&lt;p&gt;Bayesian neural networks with latent variables are scalable and flexible
probabilistic models: They account for uncertainty in the estimation of the
network weights and, by making use of latent variables, can capture complex
noise patterns in the data. We show how to extract and decompose uncertainty
into epistemic and aleatoric components for decision-making purposes. This
allows us to successfully identify informative points for active learning of
functions with heteroscedastic and bimodal noise. Using the decomposition we
further define a novel risk-sensitive criterion for reinforcement learning to
identify policies that balance expected cost, model-bias and noise aversion.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Depeweg_S/0/1/0/all/0/1&quot;&gt;Stefan Depeweg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hernandez_Lobato_J/0/1/0/all/0/1&quot;&gt;Jos&amp;#xe9; Miguel Hern&amp;#xe1;ndez-Lobato&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Doshi_Velez_F/0/1/0/all/0/1&quot;&gt;Finale Doshi-Velez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Udluft_S/0/1/0/all/0/1&quot;&gt;Steffen Udluft&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.00342">
<title>Orthogonal Machine Learning: Power and Limitations. (arXiv:1711.00342v5 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1711.00342</link>
<description rdf:parseType="Literal">&lt;p&gt;Double machine learning provides $\sqrt{n}$-consistent estimates of
parameters of interest even when high-dimensional or nonparametric nuisance
parameters are estimated at an $n^{-1/4}$ rate. The key is to employ
Neyman-orthogonal moment equations which are first-order insensitive to
perturbations in the nuisance parameters. We show that the $n^{-1/4}$
requirement can be improved to $n^{-1/(2k+2)}$ by employing a $k$-th order
notion of orthogonality that grants robustness to more complex or
higher-dimensional nuisance parameters. In the partially linear regression
setting popular in causal inference, we show that we can construct second-order
orthogonal moments if and only if the treatment residual is not normally
distributed. Our proof relies on Stein&apos;s lemma and may be of independent
interest. We conclude by demonstrating the robustness benefits of an explicit
doubly-orthogonal estimation procedure for treatment effect.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mackey_L/0/1/0/all/0/1&quot;&gt;Lester Mackey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Syrgkanis_V/0/1/0/all/0/1&quot;&gt;Vasilis Syrgkanis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zadik_I/0/1/0/all/0/1&quot;&gt;Ilias Zadik&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.00789">
<title>Partition model averaging of Bayesian wavelet regression for multi-dimensional data. (arXiv:1711.00789v2 [stat.ME] UPDATED)</title>
<link>http://arxiv.org/abs/1711.00789</link>
<description rdf:parseType="Literal">&lt;p&gt;Traditional statistical wavelet analysis carries out modeling and inference
under a given, predetermined wavelet transform. This approach can quickly lose
efficiency for multi-dimensional data (e.g., observations measured on a
multi-dimensional grid), because a predetermined wavelet transform does not
adaptively exploit the information or energy distribution in a problem-specific
manner. This work aims to overcome this challenge within the multivariate
wavelet analysis framework by incorporating adaptivity into the wavelet
transform itself in a principled manner. By exploiting a connection between
wavelet transforms and permutations on the index space of multi-dimensional
functions, we show that the desired adaptive wavelet transform can be achieved
by adopting a layer of Bayesian hierarchical modeling on the space of such
permutations. In particular, when combined with the Haar basis, exact Bayesian
inference under the model can be achieved analytically through a recursive
message passing algorithm with an efficient computational complexity that is
linear with sample size. We also provide recipe for incorporating block
shrinkage and general wavelet bases into the framework, all while maintaining
such adaptivity. We demonstrate via extensive numerical experiments that with
our framework even simple 1D Haar wavelets can achieve excellent performance in
the context of 2D and 3D image reconstruction, outperforming state-of-the-art
wavelet and non-wavelet methods especially in noisy, low signal-to-noise ratio
settings at a fraction of the computational cost. Furthermore, we investigate
the source of the gain by quantitatively comparing the efficacy of energy
concentration under our adaptive wavelet transform with that of classical fixed
wavelet transforms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Li_M/0/1/0/all/0/1&quot;&gt;Meng Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ma_L/0/1/0/all/0/1&quot;&gt;Li Ma&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.02621">
<title>Convex Optimization with Unbounded Nonconvex Oracles using Simulated Annealing. (arXiv:1711.02621v2 [cs.DS] UPDATED)</title>
<link>http://arxiv.org/abs/1711.02621</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the problem of minimizing a convex objective function $F$ when
one can only evaluate its noisy approximation $\hat{F}$. Unless one assumes
some structure on the noise, $\hat{F}$ may be an arbitrary nonconvex function,
making the task of minimizing $F$ intractable. To overcome this, prior work has
often focused on the case when $F(x)-\hat{F}(x)$ is uniformly-bounded. In this
paper we study the more general case when the noise has magnitude $\alpha F(x)
+ \beta$ for some $\alpha, \beta &amp;gt; 0$, and present a polynomial time algorithm
that finds an approximate minimizer of $F$ for this noise model. Previously,
Markov chains, such as the stochastic gradient Langevin dynamics, have been
used to arrive at approximate solutions to these optimization problems.
However, for the noise model considered in this paper, no single temperature
allows such a Markov chain to both mix quickly and concentrate near the global
minimizer. We bypass this by combining &quot;simulated annealing&quot; with the
stochastic gradient Langevin dynamics, and gradually decreasing the temperature
of the chain in order to approach the global minimizer. As a corollary one can
approximately minimize a nonconvex function that is close to a convex function;
however, the closeness can deteriorate as one moves away from the optimum.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mangoubi_O/0/1/0/all/0/1&quot;&gt;Oren Mangoubi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vishnoi_N/0/1/0/all/0/1&quot;&gt;Nisheeth K. Vishnoi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.06424">
<title>Learning to Write Stylized Chinese Characters by Reading a Handful of Examples. (arXiv:1712.06424v3 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1712.06424</link>
<description rdf:parseType="Literal">&lt;p&gt;Automatically writing stylized Chinese characters is an attractive yet
challenging task due to its wide applicabilities. In this paper, we propose a
novel framework named Style-Aware Variational Auto-Encoder (SA-VAE) to flexibly
generate Chinese characters. Specifically, we propose to capture the different
characteristics of a Chinese character by disentangling the latent features
into content-related and style-related components. Considering of the complex
shapes and structures, we incorporate the structure information as prior
knowledge into our framework to guide the generation. Our framework shows a
powerful one-shot/low-shot generalization ability by inferring the style
component given a character with unseen style. To the best of our knowledge,
this is the first attempt to learn to write new-style Chinese characters by
observing only one or a few examples. Extensive experiments demonstrate its
effectiveness in generating different stylized Chinese characters by fusing the
feature vectors corresponding to different contents and styles, which is of
significant importance in real-world applications.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_D/0/1/0/all/0/1&quot;&gt;Danyang Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ren_T/0/1/0/all/0/1&quot;&gt;Tongzheng Ren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1&quot;&gt;Chongxun Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Su_H/0/1/0/all/0/1&quot;&gt;Hang Su&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_J/0/1/0/all/0/1&quot;&gt;Jun Zhu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.02557">
<title>Neyman-Pearson classification: parametrics and power enhancement. (arXiv:1802.02557v3 [stat.ME] UPDATED)</title>
<link>http://arxiv.org/abs/1802.02557</link>
<description rdf:parseType="Literal">&lt;p&gt;The Neyman-Pearson (NP) paradigm in binary classification seeks classifiers
that achieve a minimal type II error while enforcing the prioritized type I
error under some user-specified level. This paradigm serves naturally in
applications such as severe disease diagnosis and spam detection, where people
have clear priorities over the two error types. Despite recent advances in NP
classification, the NP oracle inequalities, a core theoretical criterion to
evaluate classifiers under the NP paradigm, were established only for
classifiers based on nonparametric assumptions with bounded feature support. In
this work, we conquer the challenges arisen from unbounded feature support in
parametric settings and develop NP classification theory and methodology under
these settings. Concretely, we propose a new parametric NP classifier NP-sLDA
which satisfies the NP oracle inequalities. Furthermore, we construct an
adaptive sample splitting scheme that can be applied universally to existing NP
classifiers and this adaptive strategy greatly enhances the power of these
classifiers. Through extensive numerical experiments and real data studies, we
demonstrate the competence of NP-sLDA and the new sample splitting scheme.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tong_X/0/1/0/all/0/1&quot;&gt;Xin Tong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Xia_L/0/1/0/all/0/1&quot;&gt;Lucy Xia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jiacheng Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Feng_Y/0/1/0/all/0/1&quot;&gt;Yang Feng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.03888">
<title>Consistent Individualized Feature Attribution for Tree Ensembles. (arXiv:1802.03888v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1802.03888</link>
<description rdf:parseType="Literal">&lt;p&gt;Interpreting predictions from tree ensemble methods such as gradient boosting
machines and random forests is important, yet feature attribution for trees is
often heuristic and not individualized for each prediction. Here we show that
popular feature attribution methods are inconsistent, meaning they can lower a
feature&apos;s assigned importance when the true impact of that feature actually
increases. This is a fundamental problem that casts doubt on any comparison
between features. To address it we turn to recent applications of game theory
and develop fast exact tree solutions for SHAP (SHapley Additive exPlanation)
values, which are the unique consistent and locally accurate attribution
values. We then extend SHAP values to interaction effects and define SHAP
interaction values. We propose a rich visualization of individualized feature
attributions that improves over classic attribution summaries and partial
dependence plots, and a unique &quot;supervised&quot; clustering (clustering based on
feature attributions). We demonstrate better agreement with human intuition
through a user study, exponential improvements in run time, improved clustering
performance, and better identification of influential features. An
implementation of our algorithm has also been merged into XGBoost and LightGBM,
see &lt;a href=&quot;http://github.com/slundberg/shap&quot;&gt;this http URL&lt;/a&gt; for details.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lundberg_S/0/1/0/all/0/1&quot;&gt;Scott M. Lundberg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Erion_G/0/1/0/all/0/1&quot;&gt;Gabriel G. Erion&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1&quot;&gt;Su-In Lee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05680">
<title>Constraining the Dynamics of Deep Probabilistic Models. (arXiv:1802.05680v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1802.05680</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce a novel generative formulation of deep probabilistic models
implementing &quot;soft&quot; constraints on their function dynamics. In particular, we
develop a flexible methodological framework where the modeled functions and
derivatives of a given order are subject to inequality or equality constraints.
We then characterize the posterior distribution over model and constraint
parameters through stochastic variational inference. As a result, the proposed
approach allows for accurate and scalable uncertainty quantification on the
predictions and on all parameters. We demonstrate the application of equality
constraints in the challenging problem of parameter inference in ordinary
differential equation models, while we showcase the application of inequality
constraints on the problem of monotonic regression of count data. The proposed
approach is extensively tested in several experimental settings, leading to
highly competitive results in challenging modeling applications, while offering
high expressiveness, flexibility and scalability.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lorenzi_M/0/1/0/all/0/1&quot;&gt;Marco Lorenzi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Filippone_M/0/1/0/all/0/1&quot;&gt;Maurizio Filippone&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.05554">
<title>Minimal I-MAP MCMC for Scalable Structure Discovery in Causal DAG Models. (arXiv:1803.05554v2 [stat.CO] UPDATED)</title>
<link>http://arxiv.org/abs/1803.05554</link>
<description rdf:parseType="Literal">&lt;p&gt;Learning a Bayesian network (BN) from data can be useful for decision-making
or discovering causal relationships. However, traditional methods often fail in
modern applications, which exhibit a larger number of observed variables than
data points. The resulting uncertainty about the underlying network as well as
the desire to incorporate prior information recommend a Bayesian approach to
learning the BN, but the highly combinatorial structure of BNs poses a striking
challenge for inference. The current state-of-the-art methods such as order
MCMC are faster than previous methods but prevent the use of many natural
structural priors and still have running time exponential in the maximum
indegree of the true directed acyclic graph (DAG) of the BN. We here propose an
alternative posterior approximation based on the observation that, if we
incorporate empirical conditional independence tests, we can focus on a
high-probability DAG associated with each order of the vertices. We show that
our method allows the desired flexibility in prior specification, removes
timing dependence on the maximum indegree and yields provably good posterior
approximations; in addition, we show that it achieves superior accuracy,
scalability, and sampler mixing on several datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Agrawal_R/0/1/0/all/0/1&quot;&gt;Raj Agrawal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Broderick_T/0/1/0/all/0/1&quot;&gt;Tamara Broderick&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Uhler_C/0/1/0/all/0/1&quot;&gt;Caroline Uhler&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.08178">
<title>Boosted Density Estimation Remastered. (arXiv:1803.08178v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1803.08178</link>
<description rdf:parseType="Literal">&lt;p&gt;There has recently been a steady increase in the number iterative approaches
to density estimation. However, an accompanying burst of formal convergence
guarantees has not followed; all results pay the price of heavy assumptions
which are often unrealistic or hard to check. The Generative Adversarial
Network (GAN) literature --- seemingly orthogonal to the aforementioned pursuit
--- has had the side effect of a renewed interest in variational divergence
minimisation (notably $f$-GAN). We show that by introducing a weak learning
assumption (in the sense of the classical boosting framework) we are able to
import some recent results from the GAN literature to develop an iterative
boosted density estimation algorithm, including formal convergence results with
rates, that does not suffer the shortcomings other approaches. We show that the
density fit is an exponential family, and as part of our analysis obtain an
improved variational characterisation of $f$-GAN.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cranko_Z/0/1/0/all/0/1&quot;&gt;Zac Cranko&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nock_R/0/1/0/all/0/1&quot;&gt;Richard Nock&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.01050">
<title>Training VAEs Under Structured Residuals. (arXiv:1804.01050v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1804.01050</link>
<description rdf:parseType="Literal">&lt;p&gt;Variational auto-encoders (VAEs) are a popular and powerful deep generative
model. Previous works on VAEs have assumed a factorized likelihood model,
whereby the output uncertainty of each pixel is assumed to be independent. This
approximation is clearly limited as demonstrated by observing a residual image
from a VAE reconstruction, which often possess a high level of structure. This
paper demonstrates a novel scheme to incorporate a structured Gaussian
likelihood prediction network within the VAE that allows the residual
correlations to be modeled. Our novel architecture, with minimal increase in
complexity, incorporates the covariance matrix prediction within the VAE. We
also propose a new mechanism for allowing structured uncertainty on color
images. Furthermore, we provide a scheme for effectively training this model,
and include some suggestions for improving performance in terms of efficiency
or modeling longer range correlations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Dorta_G/0/1/0/all/0/1&quot;&gt;Garoe Dorta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Vicente_S/0/1/0/all/0/1&quot;&gt;Sara Vicente&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Agapito_L/0/1/0/all/0/1&quot;&gt;Lourdes Agapito&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Campbell_N/0/1/0/all/0/1&quot;&gt;Neill D.F. Campbell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Simpson_I/0/1/0/all/0/1&quot;&gt;Ivor Simpson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.10109">
<title>Quantized Compressive K-Means. (arXiv:1804.10109v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1804.10109</link>
<description rdf:parseType="Literal">&lt;p&gt;The recent framework of compressive statistical learning aims at designing
tractable learning algorithms that use only a heavily compressed
representation-or sketch-of massive datasets. Compressive K-Means (CKM) is such
a method: it estimates the centroids of data clusters from pooled, non-linear,
random signatures of the learning examples. While this approach significantly
reduces computational time on very large datasets, its digital implementation
wastes acquisition resources because the learning examples are compressed only
after the sensing stage. The present work generalizes the sketching procedure
initially defined in Compressive K-Means to a large class of periodic
nonlinearities including hardware-friendly implementations that compressively
acquire entire datasets. This idea is exemplified in a Quantized Compressive
K-Means procedure, a variant of CKM that leverages 1-bit universal quantization
(i.e. retaining the least significant bit of a standard uniform quantizer) as
the periodic sketch nonlinearity. Trading for this resource-efficient signature
(standard in most acquisition schemes) has almost no impact on the clustering
performances, as illustrated by numerical experiments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schellekens_V/0/1/0/all/0/1&quot;&gt;Vincent Schellekens&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jacques_L/0/1/0/all/0/1&quot;&gt;Laurent Jacques&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.10616">
<title>Dynamic Network Model from Partial Observations. (arXiv:1805.10616v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.10616</link>
<description rdf:parseType="Literal">&lt;p&gt;Can evolving networks be inferred and modeled without directly observing
their nodes and edges? In many applications, the edges of a dynamic network
might not be observed, but one can observe the dynamics of stochastic cascading
processes (e.g., information diffusion, virus propagation) occurring over the
unobserved network. While there have been efforts to infer networks based on
such data, providing a generative probabilistic model that is able to identify
the underlying time-varying network remains an open question. Here we consider
the problem of inferring generative dynamic network models based on network
cascade diffusion data. We propose a novel framework for providing a
non-parametric dynamic network model--based on a mixture of coupled
hierarchical Dirichlet processes-- based on data capturing cascade node
infection times. Our approach allows us to infer the evolving community
structure in networks and to obtain an explicit predictive distribution over
the edges of the underlying network--including those that were not involved in
transmission of any cascade, or are likely to appear in the future. We show the
effectiveness of our approach using extensive experiments on synthetic as well
as real-world networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghalebi_E/0/1/0/all/0/1&quot;&gt;Elahe Ghalebi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mirzasoleiman_B/0/1/0/all/0/1&quot;&gt;Baharan Mirzasoleiman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grosu_R/0/1/0/all/0/1&quot;&gt;Radu Grosu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leskovec_J/0/1/0/all/0/1&quot;&gt;Jure Leskovec&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.12573">
<title>Learning a Prior over Intent via Meta-Inverse Reinforcement Learning. (arXiv:1805.12573v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.12573</link>
<description rdf:parseType="Literal">&lt;p&gt;A significant challenge for the practical application of reinforcement
learning in the real world is the need to specify an oracle reward function
that correctly defines a task. Inverse reinforcement learning (IRL) seeks to
avoid this challenge by instead inferring a reward function from expert
behavior. While appealing, it can be impractically expensive to collect
datasets of demonstrations that cover the variation common in the real world
(e.g. opening any type of door). Thus in practice, IRL must commonly be
performed with only a limited set of demonstrations where it can be exceedingly
difficult to unambiguously recover a reward function. In this work, we exploit
the insight that demonstrations from other tasks can be used to constrain the
set of possible reward functions by learning a &quot;prior&quot; that is specifically
optimized for the ability to infer expressive reward functions from limited
numbers of demonstrations. We demonstrate that our method can efficiently
recover rewards from images for novel tasks and provide intuition as to how our
approach is analogous to learning a prior.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_K/0/1/0/all/0/1&quot;&gt;Kelvin Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ratner_E/0/1/0/all/0/1&quot;&gt;Ellis Ratner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dragan_A/0/1/0/all/0/1&quot;&gt;Anca Dragan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1&quot;&gt;Sergey Levine&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Finn_C/0/1/0/all/0/1&quot;&gt;Chelsea Finn&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00656">
<title>Scraping and Preprocessing Commercial Auction Data for Fraud Classification. (arXiv:1806.00656v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1806.00656</link>
<description rdf:parseType="Literal">&lt;p&gt;In the last three decades, we have seen a significant increase in trading
goods and services through online auctions. However, this business created an
attractive environment for malicious moneymakers who can commit different types
of fraud activities, such as Shill Bidding (SB). The latter is predominant
across many auctions but this type of fraud is difficult to detect due to its
similarity to normal bidding behaviour. The unavailability of SB datasets makes
the development of SB detection and classification models burdensome.
Furthermore, to implement efficient SB detection models, we should produce SB
data from actual auctions of commercial sites. In this study, we first scraped
a large number of eBay auctions of a popular product. After preprocessing the
raw auction data, we build a high-quality SB dataset based on the most reliable
SB strategies. The aim of our research is to share the preprocessed auction
dataset as well as the SB training (unlabelled) dataset, thereby researchers
can apply various machine learning techniques by using authentic data of
auctions and fraud.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alzahrani_A/0/1/0/all/0/1&quot;&gt;Ahmad Alzahrani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sadaoui_S/0/1/0/all/0/1&quot;&gt;Samira Sadaoui&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04047">
<title>High Dimensional Data Enrichment: Interpretable, Fast, and Data-Efficient. (arXiv:1806.04047v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1806.04047</link>
<description rdf:parseType="Literal">&lt;p&gt;High dimensional structured data enriched model describes groups of
observations by shared and per-group individual parameters, each with its own
structure such as sparsity or group sparsity. In this paper, we consider the
general form of data enrichment where data comes in a fixed but arbitrary
number of groups G. Any convex function, e.g., norms, can characterize the
structure of both shared and individual parameters. We propose an estimator for
high dimensional data enriched model and provide conditions under which it
consistently estimates both shared and individual parameters. We also delineate
sample complexity of the estimator and present high probability non-asymptotic
bound on estimation error of all parameters. Interestingly the sample
complexity of our estimator translates to conditions on both per-group sample
sizes and the total number of samples. We propose an iterative estimation
algorithm with linear convergence rate and supplement our theoretical analysis
with synthetic and real experimental results. Particularly, we show the
predictive power of data-enriched model along with its interpretable results in
anticancer drug sensitivity analysis.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Asiaee_A/0/1/0/all/0/1&quot;&gt;Amir Asiaee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Oymak_S/0/1/0/all/0/1&quot;&gt;Samet Oymak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Coombes_K/0/1/0/all/0/1&quot;&gt;Kevin R. Coombes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Banerjee_A/0/1/0/all/0/1&quot;&gt;Arindam Banerjee&lt;/a&gt;</dc:creator>
</item></rdf:RDF>