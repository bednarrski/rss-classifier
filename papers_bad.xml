<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Boring papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Bad Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-02-13T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04443"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04491"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04657"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1608.06037"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1703.06846"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.10704"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04337"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04394"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04397"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04403"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04408"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04412"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04434"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04520"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04564"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04592"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04697"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04742"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1707.05176"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.02225"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.02334"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.06294"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.03638"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04307"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04310"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04346"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04365"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04374"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04407"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04422"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04457"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04474"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04475"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04477"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04502"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04537"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04617"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04630"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04664"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04676"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04687"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04712"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04715"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04725"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04734"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04782"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04784"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04791"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1503.02978"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1512.08298"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1606.00389"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1608.03045"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1703.00734"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1707.08092"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.01179"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.01410"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.05115"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.10513"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.06598"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.10581"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.06745"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.03497"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.03848"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.03800"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1802.04443">
<title>On Characterizing the Capacity of Neural Networks using Algebraic Topology. (arXiv:1802.04443v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.04443</link>
<description rdf:parseType="Literal">&lt;p&gt;The learnability of different neural architectures can be characterized
directly by computable measures of data complexity. In this paper, we reframe
the problem of architecture selection as understanding how data determines the
most expressive and generalizable architectures suited to that data, beyond
inductive bias. After suggesting algebraic topology as a measure for data
complexity, we show that the power of a network to express the topological
complexity of a dataset in its decision region is a strictly limiting factor in
its ability to generalize. We then provide the first empirical characterization
of the topological capacity of neural networks. Our empirical analysis shows
that at every level of dataset complexity, neural networks exhibit topological
phase transitions. This observation allowed us to connect existing theory to
empirically driven conjectures on the choice of architectures for
fully-connected neural networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guss_W/0/1/0/all/0/1&quot;&gt;William H. Guss&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Salakhutdinov_R/0/1/0/all/0/1&quot;&gt;Ruslan Salakhutdinov&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04491">
<title>Slice as an Evolutionary Service: Genetic Optimization for Inter-Slice Resource Management in 5G Networks. (arXiv:1802.04491v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1802.04491</link>
<description rdf:parseType="Literal">&lt;p&gt;In the context of Fifth Generation (5G) mobile networks, the concept of
&quot;slice as a service&quot; (SaaS) promotes mobile network operators to flexibly share
infrastructures with mobile service providers and stakeholders. However, it
also challenges with an emerging demand for efficient online algorithms to
optimize the request-and-decision-based inter-slice resource management
strategy. Based on genetic algorithms, this paper presents a novel online
optimizer that efficiently approaches towards the ideal slicing strategy with
maximized long-term network utility. The proposed method requires no a priori
knowledge about the traffic/utility models, while providing solid
effectiveness, good robustness against non-stationary service scenarios, and
high scalability.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Han_B/0/1/0/all/0/1&quot;&gt;Bin Han&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ji_L/0/1/0/all/0/1&quot;&gt;Lianghai Ji&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schotten_H/0/1/0/all/0/1&quot;&gt;Hans D. Schotten&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04657">
<title>Analyzing and Mitigating the Impact of Permanent Faults on a Systolic Array Based Neural Network Accelerator. (arXiv:1802.04657v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.04657</link>
<description rdf:parseType="Literal">&lt;p&gt;Due to their growing popularity and computational cost, deep neural networks
(DNNs) are being targeted for hardware acceleration. A popular architecture for
DNN acceleration, adopted by the Google Tensor Processing Unit (TPU), utilizes
a systolic array based matrix multiplication unit at its core. This paper deals
with the design of fault-tolerant, systolic array based DNN accelerators for
high defect rate technologies. To this end, we empirically show that the
classification accuracy of a baseline TPU drops significantly even at extremely
low fault rates (as low as $0.006\%$). We then propose two novel strategies,
fault-aware pruning (FAP) and fault-aware pruning+retraining (FAP+T), that
enable the TPU to operate at fault rates of up to $50\%$, with negligible drop
in classification accuracy (as low as $0.1\%$) and no run-time performance
overhead. The FAP+T does introduce a one-time retraining penalty per TPU chip
before it is deployed, but we propose optimizations that reduce this one-time
penalty to under 12 minutes. The penalty is then amortized over the entire
lifetime of the TPU&apos;s operation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jeff/0/1/0/all/0/1&quot;&gt;Jeff&lt;/a&gt; (Jun) &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang/0/1/0/all/0/1&quot;&gt;Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gu_T/0/1/0/all/0/1&quot;&gt;Tianyu Gu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Basu_K/0/1/0/all/0/1&quot;&gt;Kanad Basu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garg_S/0/1/0/all/0/1&quot;&gt;Siddharth Garg&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1608.06037">
<title>Lets keep it simple, Using simple architectures to outperform deeper and more complex architectures. (arXiv:1608.06037v6 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1608.06037</link>
<description rdf:parseType="Literal">&lt;p&gt;Major winning Convolutional Neural Networks (CNNs), such as AlexNet, VGGNet,
ResNet, GoogleNet, include tens to hundreds of millions of parameters, which
impose considerable computation and memory overhead. This limits their
practical use for training, optimization and memory efficiency. On the
contrary, light-weight architectures, being proposed to address this issue,
mainly suffer from low accuracy. These inefficiencies mostly stem from
following an ad hoc procedure. We propose a simple architecture, called
SimpleNet, based on a set of designing principles, with which we empirically
show, a well-crafted yet simple and reasonably deep architecture can perform on
par with deeper and more complex architectures. SimpleNet provides a good
tradeoff between the computation/memory efficiency and the accuracy. Our simple
13-layer architecture outperforms most of the deeper and complex architectures
to date such as VGGNet, ResNet, and GoogleNet on several well-known benchmarks
while having 2 to 25 times fewer number of parameters and operations. This
makes it very handy for embedded system or system with computational and memory
limitations. We achieved state-of-the-art result on CIFAR10 outperforming
several heavier architectures, near state of the art on MNIST and competitive
results on CIFAR100 and SVHN. Models are made available at:
https://github.com/Coderx7/SimpleNet
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hasanpour_S/0/1/0/all/0/1&quot;&gt;Seyyed Hossein Hasanpour&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rouhani_M/0/1/0/all/0/1&quot;&gt;Mohammad Rouhani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fayyaz_M/0/1/0/all/0/1&quot;&gt;Mohsen Fayyaz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sabokrou_M/0/1/0/all/0/1&quot;&gt;Mohammad Sabokrou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1703.06846">
<title>Boosting Dilated Convolutional Networks with Mixed Tensor Decompositions. (arXiv:1703.06846v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1703.06846</link>
<description rdf:parseType="Literal">&lt;p&gt;The driving force behind deep networks is their ability to compactly
represent rich classes of functions. The primary notion for formally reasoning
about this phenomenon is expressive efficiency, which refers to a situation
where one network must grow unfeasibly large in order to realize (or
approximate) functions of another. To date, expressive efficiency analyses
focused on the architectural feature of depth, showing that deep networks are
representationally superior to shallow ones. In this paper we study the
expressive efficiency brought forth by connectivity, motivated by the
observation that modern networks interconnect their layers in elaborate ways.
We focus on dilated convolutional networks, a family of deep models delivering
state of the art performance in sequence processing tasks. By introducing and
analyzing the concept of mixed tensor decompositions, we prove that
interconnecting dilated convolutional networks can lead to expressive
efficiency. In particular, we show that even a single connection between
intermediate layers can already lead to an almost quadratic gap, which in
large-scale settings typically makes the difference between a model that is
practical and one that is not. Empirical evaluation demonstrates how the
expressive efficiency of connectivity, similarly to that of depth, translates
into gains in accuracy. This leads us to believe that expressive efficiency may
serve a key role in the development of new tools for deep network design.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cohen_N/0/1/0/all/0/1&quot;&gt;Nadav Cohen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tamari_R/0/1/0/all/0/1&quot;&gt;Ronen Tamari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shashua_A/0/1/0/all/0/1&quot;&gt;Amnon Shashua&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.10704">
<title>Training Probabilistic Spiking Neural Networks with First-to-spike Decoding. (arXiv:1710.10704v2 [stat.ML] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1710.10704</link>
<description rdf:parseType="Literal">&lt;p&gt;Third-generation neural networks, or Spiking Neural Networks (SNNs), aim at
harnessing the energy efficiency of spike-domain processing by building on
computing elements that operate on, and exchange, spikes. In this paper, the
problem of training a two-layer SNN is studied for the purpose of
classification, under a Generalized Linear Model (GLM) probabilistic neural
model that was previously considered within the computational neuroscience
literature. Conventional classification rules for SNNs operate offline based on
the number of output spikes at each output neuron. In contrast, a novel
training method is proposed here for a first-to-spike decoding rule, whereby
the SNN can perform an early classification decision once spike firing is
detected at an output neuron. Numerical results bring insights into the optimal
parameter selection for the GLM neuron and on the accuracy-complexity trade-off
performance of conventional and first-to-spike decoding.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bagheri_A/0/1/0/all/0/1&quot;&gt;Alireza Bagheri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Simeone_O/0/1/0/all/0/1&quot;&gt;Osvaldo Simeone&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rajendran_B/0/1/0/all/0/1&quot;&gt;Bipin Rajendran&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04337">
<title>An Ontology Based Modeling Framework for Design of Educational Technologies. (arXiv:1802.04337v1 [cs.CY])</title>
<link>http://arxiv.org/abs/1802.04337</link>
<description rdf:parseType="Literal">&lt;p&gt;Despite rapid progress, most of the educational technologies today lack a
strong instructional design knowledge basis leading to questionable quality of
instruction. In addition, a major challenge is to customize these educational
technologies for a wide range of instructional designs. Ontologies are one of
the pertinent mechanisms to represent instructional design in the literature.
However, existing approaches do not support modeling of flexible instructional
designs. To address this problem, in this paper, we propose an ontology based
framework for systematic modeling of different aspects of instructional design
knowledge based on domain patterns. As part of the framework, we present
ontologies for modeling goals, instructional processes and instructional
materials. We demonstrate the ontology framework by presenting instances of the
ontology for the large scale case study of adult literacy in India (287 million
learners spread across 22 Indian Languages), which requires creation of 1000
similar but varied eLearning Systems based on flexible instructional designs.
The implemented framework is available at &lt;a href=&quot;http://rice.iiit.ac.in&quot;&gt;this http URL&lt;/a&gt; and is
transferred to National Literacy Mission of Government of India. This framework
could be used for modeling instructional design knowledge of systems for
skills, school education and beyond.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chimalakonda_S/0/1/0/all/0/1&quot;&gt;Sridhar Chimalakonda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nori_K/0/1/0/all/0/1&quot;&gt;Kesav V. Nori&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04394">
<title>ReinforceWalk: Learning to Walk in Graph with Monte Carlo Tree Search. (arXiv:1802.04394v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.04394</link>
<description rdf:parseType="Literal">&lt;p&gt;Learning to walk over a graph towards a target node for a given input query
and a source node is an important problem in applications such as knowledge
graph reasoning. It can be formulated as a reinforcement learning (RL) problem
that has a known state transition model, but with partial observability and
sparse reward. To overcome these challenges, we develop a graph walking agent
called ReinforceWalk, which consists of a deep recurrent neural network (RNN)
and a Monte Carlo Tree Search (MCTS). To address partial observability, the RNN
encodes the history of observations and map it into the Q-value, the policy and
the state value. In order to effectively train the agent from sparse reward, we
combine MCTS with the RNN policy to generate trajectories with more positive
rewards. From these trajectories, we update the network in an off-policy manner
using Q-learning and improves the RNN policy. Our proposed RL algorithm
repeatedly applies this policy improvement step to learn the entire model. At
testing stage, the MCTS is also combined with the RNN to predict the target
node with higher accuracy. Experiment results on several graph-walking
benchmarks show that we are able to learn better policies from less number of
rollouts compared to other baseline methods, which are mainly based on policy
gradient method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1&quot;&gt;Yelong Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_J/0/1/0/all/0/1&quot;&gt;Jianshu Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_P/0/1/0/all/0/1&quot;&gt;Po-Sen Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1&quot;&gt;Yuqing Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_J/0/1/0/all/0/1&quot;&gt;Jianfeng Gao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04397">
<title>Identifiability of Nonparametric Mixture Models and Bayes Optimal Clustering. (arXiv:1802.04397v1 [math.ST])</title>
<link>http://arxiv.org/abs/1802.04397</link>
<description rdf:parseType="Literal">&lt;p&gt;Motivated by problems in data clustering, we establish general conditions
under which families of nonparametric mixture models are identifiable by
introducing a novel framework for clustering overfitted \emph{parametric} (i.e.
misspecified) mixture models. These conditions generalize existing conditions
in the literature, and are flexible enough to include for example mixtures of
Gaussian mixtures. In contrast to the recent literature on estimating
nonparametric mixtures, we allow for general nonparametric mixture components,
and instead impose regularity assumptions on the underlying mixing measure. As
our primary application, we apply these results to partition-based clustering,
generalizing the well-known notion of a Bayes optimal partition from classical
model-based clustering to nonparametric settings. Furthermore, this framework
is constructive in that it yields a practical algorithm for learning identified
mixtures, which is illustrated through several examples. The key conceptual
device in the analysis is the convex, metric geometry of probability
distributions on metric spaces and its connection to optimal transport and the
Wasserstein convergence of mixing measures. The result is a flexible framework
for nonparametric clustering with formal consistency guarantees.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Aragam_B/0/1/0/all/0/1&quot;&gt;Bryon Aragam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Dan_C/0/1/0/all/0/1&quot;&gt;Chen Dan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Ravikumar_P/0/1/0/all/0/1&quot;&gt;Pradeep Ravikumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Xing_E/0/1/0/all/0/1&quot;&gt;Eric P. Xing&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04403">
<title>TVAE: Triplet-Based Variational Autoencoder using Metric Learning. (arXiv:1802.04403v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.04403</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep metric learning has been demonstrated to be highly effective in learning
semantic representation and encoding information that can be used to measure
data similarity, by relying on the embedding learned from metric learning. At
the same time, variational autoencoder (VAE) has widely been used to
approximate inference and proved to have a good performance for directed
probabilistic models. However, for traditional VAE, the data label or feature
information are intractable. Similarly, traditional representation learning
approaches fail to represent many salient aspects of the data. In this project,
we propose a novel integrated framework to learn latent embedding in VAE by
incorporating deep metric learning. The features are learned by optimizing a
triplet loss on the mean vectors of VAE in conjunction with standard evidence
lower bound (ELBO) of VAE. This approach, which we call Triplet based
Variational Autoencoder (TVAE), allows us to capture more fine-grained
information in the latent embedding. Our model is tested on MNIST data set and
achieves a high triplet accuracy of 95.60% while the traditional VAE (Kingma &amp;amp;
Welling, 2013) achieves triplet accuracy of 75.08%.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ishfaq_H/0/1/0/all/0/1&quot;&gt;Haque Ishfaq&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hoogi_A/0/1/0/all/0/1&quot;&gt;Assaf Hoogi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rubin_D/0/1/0/all/0/1&quot;&gt;Daniel Rubin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04408">
<title>REAS: Combining Numerical Optimization with SAT Solving. (arXiv:1802.04408v1 [cs.PL])</title>
<link>http://arxiv.org/abs/1802.04408</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we present ReaS, a technique that combines numerical
optimization with SAT solving to synthesize unknowns in a program that involves
discrete and floating point computation. ReaS makes the program end-to-end
differentiable by smoothing any Boolean expression that introduces
discontinuity such as conditionals and relaxing the Boolean unknowns so that
numerical optimization can be performed. On top of this, ReaS uses a SAT solver
to help the numerical search overcome local solutions by incrementally fixing
values to the Boolean expressions. We evaluated the approach on 5 case studies
involving hybrid systems and show that ReaS can synthesize programs that could
not be solved by previous SMT approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Inala_J/0/1/0/all/0/1&quot;&gt;Jeevana Priya Inala&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_S/0/1/0/all/0/1&quot;&gt;Sicun Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kong_S/0/1/0/all/0/1&quot;&gt;Soonho Kong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Solar_Lezama_A/0/1/0/all/0/1&quot;&gt;Armando Solar-Lezama&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04412">
<title>Efficient Exploration through Bayesian Deep Q-Networks. (arXiv:1802.04412v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.04412</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose Bayesian Deep Q-Network (BDQN), a practical Thompson sampling
based Reinforcement Learning (RL) Algorithm. Thompson sampling allows for
targeted exploration in high dimensions through posterior sampling but is
usually computationally expensive. We address this limitation by introducing
uncertainty only at the output layer of the network through a Bayesian Linear
Regression (BLR) model. This layer can be trained with fast closed-form updates
and its samples can be drawn efficiently through the Gaussian distribution. We
apply our method to a wide range of Atari games in Arcade Learning
Environments. Since BDQN carries out more efficient exploration, it is able to
reach higher rewards substantially faster than a key baseline, the double deep
Q network (DDQN).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Azizzadenesheli_K/0/1/0/all/0/1&quot;&gt;Kamyar Azizzadenesheli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brunskill_E/0/1/0/all/0/1&quot;&gt;Emma Brunskill&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Anandkumar_A/0/1/0/all/0/1&quot;&gt;Animashree Anandkumar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04434">
<title>signSGD: compressed optimisation for non-convex problems. (arXiv:1802.04434v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.04434</link>
<description rdf:parseType="Literal">&lt;p&gt;Training large neural networks requires distributing learning across multiple
workers, where the cost of communicating gradients can be a significant
bottleneck. signSGD alleviates this problem by transmitting just the sign of
each minibatch stochastic gradient. We prove that it can get the best of both
worlds: compressed gradients and SGD-level convergence rate. signSGD can
exploit mismatches between L1 and L2 geometry: when noise and curvature are
much sparser than the gradients, signSGD is expected to converge at the same
rate or faster than full-precision SGD. Measurements of the L1 versus L2
geometry of real networks support our theoretical claims, and we find that the
momentum counterpart of signSGD is able to match the accuracy and convergence
speed of Adam on deep Imagenet models. We extend our theory to the distributed
setting, where the parameter server uses majority vote to aggregate gradient
signs from each worker enabling 1-bit compression of worker-server
communication in both directions. Using a theorem by Gauss, we prove that the
non-convex convergence rate of majority vote matches that of distributed SGD.
Thus, there is great promise for sign-based optimisation schemes to achieve
both communication efficiency and high accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bernstein_J/0/1/0/all/0/1&quot;&gt;Jeremy Bernstein&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yu-Xiang Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Azizzadenesheli_K/0/1/0/all/0/1&quot;&gt;Kamyar Azizzadenesheli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Anandkumar_A/0/1/0/all/0/1&quot;&gt;Anima Anandkumar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04520">
<title>Learning Robust and Adaptive Real-World Continuous Control Using Simulation and Transfer Learning. (arXiv:1802.04520v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.04520</link>
<description rdf:parseType="Literal">&lt;p&gt;We use model-free reinforcement learning, extensive simulation, and transfer
learning to develop a continuous control algorithm that has good zero-shot
performance in a real physical environment. We train a simulated agent to act
optimally across a set of similar environments, each with dynamics drawn from a
prior distribution. We propose that the agent is able to adjust its actions
almost immediately, based on small set of observations. This robust and
adaptive behavior is enabled by using a policy gradient algorithm with an Long
Short Term Memory (LSTM) function approximation. Finally, we train an agent to
navigate a two-dimensional environment with uncertain dynamics and noisy
observations. We demonstrate that this agent has good zero-shot performance in
a real physical environment. Our preliminary results indicate that the agent is
able to infer the environmental dynamics after only a few timesteps, and adjust
its actions accordingly.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ferguson_M/0/1/0/all/0/1&quot;&gt;M Ferguson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Law_K/0/1/0/all/0/1&quot;&gt;K. H. Law&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04564">
<title>Diversity-Driven Exploration Strategy for Deep Reinforcement Learning. (arXiv:1802.04564v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.04564</link>
<description rdf:parseType="Literal">&lt;p&gt;Efficient exploration remains a challenging research problem in reinforcement
learning, especially when an environment contains large state spaces, deceptive
local optima, or sparse rewards. To tackle this problem, we present a
diversity-driven approach for exploration, which can be easily combined with
both off- and on-policy reinforcement learning algorithms. We show that by
simply adding a distance measure to the loss function, the proposed methodology
significantly enhances an agent&apos;s exploratory behaviors, and thus preventing
the policy from being trapped in local optima. We further propose an adaptive
scaling method for stabilizing the learning process. Our experimental results
in Atari 2600 show that our method outperforms baseline approaches in several
tasks in terms of mean scores and exploration efficiency.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hong_Z/0/1/0/all/0/1&quot;&gt;Zhang-Wei Hong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shann_T/0/1/0/all/0/1&quot;&gt;Tzu-Yun Shann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Su_S/0/1/0/all/0/1&quot;&gt;Shih-Yang Su&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chang_Y/0/1/0/all/0/1&quot;&gt;Yi-Hsiang Chang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_C/0/1/0/all/0/1&quot;&gt;Chun-Yi Lee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04592">
<title>Rebalancing Dockless Bike Sharing Systems. (arXiv:1802.04592v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.04592</link>
<description rdf:parseType="Literal">&lt;p&gt;Bike sharing provides an environment-friendly way for traveling and is
booming all over the world. Yet, due to the high similarity of user travel
patterns, the bike imbalance problem constantly occurs, especially for dockless
bike sharing systems, causing significant impact on service quality and company
revenue. Thus, it has become a critical task for bike sharing systems to
resolve such imbalance efficiently. We model this problem as a Markov decision
process (MDP), which takes both temporal and spatial features into
consideration. We propose a novel deep reinforcement learning algorithm called
Loss-Reduced Reinforcement Pricing (LRP), which builds upon the deterministic
policy gradient algorithm. Different from existing methods that often ignore
spatial information and rely heavily on accurate prediction, LRP is embedded
with a novel network architecture to incorporate the dependence of neighboring
regions, for reducing the training loss in Q-function learning. We conduct
extensive experiments to evaluate the performance of the LRP algorithm, based
on trajectory data from Mobike, a major Chinese dockless bike sharing company.
Results show that LRP performs close to the 24-timeslot look-ahead
optimization, and outperforms state-of-the-art methods in both service level
and bike distribution. It also transfers well when applied to unseen areas, and
can even make additional profit with the given budget. We further propose the
first hybrid rebalancing system, which take advantages of both the truck-based
and user-based approaches, and outperforms each individual approach.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pan_L/0/1/0/all/0/1&quot;&gt;Ling Pan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cai_Q/0/1/0/all/0/1&quot;&gt;Qingpeng Cai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fang_Z/0/1/0/all/0/1&quot;&gt;Zhixuan Fang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_P/0/1/0/all/0/1&quot;&gt;Pingzhong Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1&quot;&gt;Longbo Huang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04697">
<title>Learning to Search with MCTSnets. (arXiv:1802.04697v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.04697</link>
<description rdf:parseType="Literal">&lt;p&gt;Planning problems are among the most important and well-studied problems in
artificial intelligence. They are most typically solved by tree search
algorithms that simulate ahead into the future, evaluate future states, and
back-up those evaluations to the root of a search tree. Among these algorithms,
Monte-Carlo tree search (MCTS) is one of the most general, powerful and widely
used. A typical implementation of MCTS uses cleverly designed rules, optimized
to the particular characteristics of the domain. These rules control where the
simulation traverses, what to evaluate in the states that are reached, and how
to back-up those evaluations. In this paper we instead learn where, what and
how to search. Our architecture, which we call an MCTSnet, incorporates
simulation-based search inside a neural network, by expanding, evaluating and
backing-up a vector embedding. The parameters of the network are trained
end-to-end using gradient-based optimisation. When applied to small searches in
the well known planning problem Sokoban, the learned search algorithm
significantly outperformed MCTS baselines.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guez_A/0/1/0/all/0/1&quot;&gt;Arthur Guez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Weber_T/0/1/0/all/0/1&quot;&gt;Th&amp;#xe9;ophane Weber&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Antonoglou_I/0/1/0/all/0/1&quot;&gt;Ioannis Antonoglou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Simonyan_K/0/1/0/all/0/1&quot;&gt;Karen Simonyan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vinyals_O/0/1/0/all/0/1&quot;&gt;Oriol Vinyals&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wierstra_D/0/1/0/all/0/1&quot;&gt;Daan Wierstra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Munos_R/0/1/0/all/0/1&quot;&gt;R&amp;#xe9;mi Munos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Silver_D/0/1/0/all/0/1&quot;&gt;David Silver&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04742">
<title>Quantifying Uncertainty in Discrete-Continuous and Skewed Data with Bayesian Deep Learning. (arXiv:1802.04742v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.04742</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep Learning (DL) methods have been transforming computer vision with
innovative adaptations to other domains including climate change. For DL to
pervade Science and Engineering (S\&amp;amp;E) applications where risk management is a
core component, well-characterized uncertainty estimates must accompany
predictions. However, S\&amp;amp;E observations and model-simulations often follow
heavily skewed distributions and are not well modeled with DL approaches, since
they usually optimize a Gaussian, or Euclidean, likelihood loss. Recent
developments in Bayesian Deep Learning (BDL), which attempts to capture
uncertainties from noisy observations, aleatoric, and from unknown model
parameters, epistemic, provide us a foundation. Here we present a
discrete-continuous BDL model with Gaussian and lognormal likelihoods for
uncertainty quantification (UQ). We demonstrate the approach by developing UQ
estimates on &quot;DeepSD&quot;, a super-resolution based DL model for Statistical
Downscaling (SD) in climate applied to precipitation, which follows an
extremely skewed distribution. We find that the discrete-continuous models
outperform a basic Gaussian distribution in terms of predictive accuracy and
uncertainty calibration. Furthermore, we find that the lognormal distribution,
which can handle skewed distributions, produces quality uncertainty estimates
at the extremes. Such results may be important across S\&amp;amp;E, as well as other
domains such as finance and economics, where extremes are often of significant
interest. Furthermore, to our knowledge, this is the first UQ model in SD where
both aleatoric and epistemic uncertainties are characterized.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vandal_T/0/1/0/all/0/1&quot;&gt;Thomas Vandal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kodra_E/0/1/0/all/0/1&quot;&gt;Evan Kodra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dy_J/0/1/0/all/0/1&quot;&gt;Jennifer Dy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ganguly_S/0/1/0/all/0/1&quot;&gt;Sangram Ganguly&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nemani_R/0/1/0/all/0/1&quot;&gt;Ramakrishna Nemani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ganguly_A/0/1/0/all/0/1&quot;&gt;Auroop R. Ganguly&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1707.05176">
<title>Latent Relational Metric Learning via Memory-based Attention for Collaborative Ranking. (arXiv:1707.05176v3 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1707.05176</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper proposes a new neural architecture for collaborative ranking with
implicit feedback. Our model, LRML (\textit{Latent Relational Metric Learning})
is a novel metric learning approach for recommendation. More specifically,
instead of simple push-pull mechanisms between user and item pairs, we propose
to learn latent relations that describe each user item interaction. This helps
to alleviate the potential geometric inflexibility of existing metric learing
approaches. This enables not only better performance but also a greater extent
of modeling capability, allowing our model to scale to a larger number of
interactions. In order to do so, we employ a augmented memory module and learn
to attend over these memory blocks to construct latent relations. The
memory-based attention module is controlled by the user-item interaction,
making the learned relation vector specific to each user-item pair. Hence, this
can be interpreted as learning an exclusive and optimal relational translation
for each user-item interaction. The proposed architecture demonstrates the
state-of-the-art performance across multiple recommendation benchmarks. LRML
outperforms other metric learning models by $6\%-7.5\%$ in terms of Hits@10 and
nDCG@10 on large datasets such as Netflix and MovieLens20M. Moreover,
qualitative studies also demonstrate evidence that our proposed model is able
to infer and encode explicit sentiment, temporal and attribute information
despite being only trained on implicit feedback. As such, this ascertains the
ability of LRML to uncover hidden relational structure within implicit
datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tay_Y/0/1/0/all/0/1&quot;&gt;Yi Tay&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luu_A/0/1/0/all/0/1&quot;&gt;Anh Tuan Luu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hui_S/0/1/0/all/0/1&quot;&gt;Siu Cheung Hui&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.02225">
<title>Pose-Normalized Image Generation for Person Re-identification. (arXiv:1712.02225v5 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1712.02225</link>
<description rdf:parseType="Literal">&lt;p&gt;Person Re-identification (re-id) faces two major challenges: the lack of
cross-view paired training data and learning discriminative identity-sensitive
and view-invariant features in the presence of large pose variations. In this
work, we address both problems by proposing a novel deep person image
generation model for synthesizing realistic person images conditional on pose.
The model is based on a generative adversarial network (GAN) and used
specifically for pose normalization in re-id, thus termed pose-normalization
GAN (PN-GAN). With the synthesized images, we can learn a new type of deep
re-id feature free of the influence of pose variations. We show that this
feature is strong on its own and highly complementary to features learned with
the original images. Importantly, we now have a model that generalizes to any
new re-id dataset without the need for collecting any training data for model
fine-tuning, thus making a deep re-id model truly scalable. Extensive
experiments on five benchmarks show that our model outperforms the
state-of-the-art models, often significantly. In particular, the features
learned on Market-1501 can achieve a Rank-1 accuracy of 68.67% on VIPeR without
any model fine-tuning, beating almost all existing models fine-tuned on the
dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qian_X/0/1/0/all/0/1&quot;&gt;Xuelin Qian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fu_Y/0/1/0/all/0/1&quot;&gt;Yanwei Fu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1&quot;&gt;Wenxuan Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiang_T/0/1/0/all/0/1&quot;&gt;Tao Xiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1&quot;&gt;Yang Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_Y/0/1/0/all/0/1&quot;&gt;Yu-Gang Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xue_X/0/1/0/all/0/1&quot;&gt;Xiangyang Xue&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.02334">
<title>A generalized concept-cognitive learning: A machine learning viewpoint. (arXiv:1801.02334v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1801.02334</link>
<description rdf:parseType="Literal">&lt;p&gt;Concept-cognitive learning (CCL) is a hot topic in recent years, and it has
attracted much attention from the communities of formal concept analysis,
granular computing and cognitive computing. However, the relationship among
cognitive computing (CC), concept-cognitive computing (CCC) and CCL is not
clearly described. To this end, we explain the relationship of CC, CCC and CCL.
Then, we propose a generalized concept-cognitive learning (GCCL) from the point
of view of machine learning. Finally, experiments on some data sets are
conducted to evaluate concept formation and concept-cognitive processes of the
proposed GCCL.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mi_Y/0/1/0/all/0/1&quot;&gt;Yunlong Mi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_Y/0/1/0/all/0/1&quot;&gt;Yong Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jinhai Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Jiabin Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_B/0/1/0/all/0/1&quot;&gt;Biao Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.06294">
<title>Multi-Task Pharmacovigilance Mining from Social Media Posts. (arXiv:1801.06294v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1801.06294</link>
<description rdf:parseType="Literal">&lt;p&gt;Social media has grown to be a crucial information source for
pharmacovigilance studies where an increasing number of people post adverse
reactions to medical drugs that are previously unreported. Aiming to
effectively monitor various aspects of Adverse Drug Reactions (ADRs) from
diversely expressed social medical posts, we propose a multi-task neural
network framework that learns several tasks associated with ADR monitoring with
different levels of supervisions collectively. Besides being able to correctly
classify ADR posts and accurately extract ADR mentions from online posts, the
proposed framework is also able to further understand reasons for which the
drug is being taken, known as &apos;indication&apos;, from the given social media post. A
coverage-based attention mechanism is adopted in our framework to help the
model properly identify &apos;phrasal&apos; ADRs and Indications that are attentive to
multiple words in a post. Our framework is applicable in situations where
limited parallel data for different pharmacovigilance tasks are available.We
evaluate the proposed framework on real-world Twitter datasets, where the
proposed model outperforms the state-of-the-art alternatives of each individual
task consistently.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chowdhury_S/0/1/0/all/0/1&quot;&gt;Shaika Chowdhury&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1&quot;&gt;Chenwei Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1&quot;&gt;Philip S. Yu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.03638">
<title>Beyond Markov Logic: Efficient Mining of Prediction Rules in Large Graphs. (arXiv:1802.03638v2 [cs.DB] UPDATED)</title>
<link>http://arxiv.org/abs/1802.03638</link>
<description rdf:parseType="Literal">&lt;p&gt;Graph representations of large knowledge bases may comprise billions of
edges. Usually built upon human-generated ontologies, several knowledge bases
do not feature declared ontological rules and are far from being complete.
Current rule mining approaches rely on schemata or store the graph in-memory,
which can be unfeasible for large graphs. In this paper, we introduce
HornConcerto, an algorithm to discover Horn clauses in large graphs without the
need of a schema. Using a standard fact-based confidence score, we can mine
close Horn rules having an arbitrary body size. We show that our method can
outperform existing approaches in terms of runtime and memory consumption and
mine high-quality rules for the link prediction task, achieving
state-of-the-art results on a widely-used benchmark. Moreover, we find that
rules alone can perform inference significantly faster than embedding-based
methods and achieve accuracies on link prediction comparable to
resource-demanding approaches such as Markov Logic Networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Soru_T/0/1/0/all/0/1&quot;&gt;Tommaso Soru&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Valdestilhas_A/0/1/0/all/0/1&quot;&gt;Andr&amp;#xe9; Valdestilhas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Marx_E/0/1/0/all/0/1&quot;&gt;Edgard Marx&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ngomo_A/0/1/0/all/0/1&quot;&gt;Axel-Cyrille Ngonga Ngomo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04307">
<title>A Fast Proximal Point Method for Wasserstein Distance. (arXiv:1802.04307v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.04307</link>
<description rdf:parseType="Literal">&lt;p&gt;Wasserstein distance plays increasingly important roles in machine learning,
stochastic programming and image processing. Major efforts have been under way
to address its high computational complexity, some leading to approximate or
regularized variations such as Sinkhorn distance. However, as we will
demonstrate, several important machine learning applications call for the
computation of exact Wasserstein distance, and regularized variations with
small regularization parameter will fail due to numerical stability issues or
degradate the performance. We address this challenge by developing an Inexact
Proximal point method for Optimal Transport (IPOT) with the proximal operator
approximately evaluated at each iteration using projections to the probability
simplex. We also simplify the architecture for learning generative models based
on optimal transport solution, and generalize the idea of IPOT to a new method
for computing Wasserstein barycenter. We provide convergence analysis of IPOT
and experiments showing our new methods outperform the state-of-the-art methods
in terms of both effectiveness and efficiency.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Xie_Y/0/1/0/all/0/1&quot;&gt;Yujia Xie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;Xiangfeng Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wang_R/0/1/0/all/0/1&quot;&gt;Ruijia Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zha_H/0/1/0/all/0/1&quot;&gt;Hongyuan Zha&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04310">
<title>Stochastic quasi-Newton with adaptive step lengths for large-scale problems. (arXiv:1802.04310v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.04310</link>
<description rdf:parseType="Literal">&lt;p&gt;We provide a numerically robust and fast method capable of exploiting the
local geometry when solving large-scale stochastic optimisation problems. Our
key innovation is an auxiliary variable construction coupled with an inverse
Hessian approximation computed using a receding history of iterates and
gradients. It is the Markov chain nature of the classic stochastic gradient
algorithm that enables this development. The construction offers a mechanism
for stochastic line search adapting the step length. We numerically evaluate
and compare against current state-of-the-art with encouraging performance on
real-world benchmark problems where the number of observations and unknowns is
in the order of millions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wills_A/0/1/0/all/0/1&quot;&gt;Adrian Wills&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Schon_T/0/1/0/all/0/1&quot;&gt;Thomas Sch&amp;#xf6;n&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04346">
<title>Hybrid Decision Making: When Interpretable Models Collaborate With Black-Box Models. (arXiv:1802.04346v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.04346</link>
<description rdf:parseType="Literal">&lt;p&gt;Interpretable machine learning models have received increasing interest in
recent years, especially in domains where humans are involved in the
decision-making process. However, the possible loss of the task performance for
gaining interpretability is often inevitable. This performance downgrade puts
practitioners in a dilemma of choosing between a top-performing black-box model
with no explanations and an interpretable model with unsatisfying task
performance.
&lt;/p&gt;
&lt;p&gt;In this work, we propose a novel framework for building a Hybrid Decision
Model that integrates an interpretable model with any black-box model to
introduce explanations in the decision making process while preserving or
possibly improving the predictive accuracy. We propose a novel metric,
explainability, to measure the percentage of data that are sent to the
interpretable model for decision. We also design a principled objective
function that considers predictive accuracy, model interpretability, and data
explainability. Under this framework, we develop Collaborative Black-box and
RUle Set Hybrid (CoBRUSH) model that combines logic rules and any black-box
model into a joint decision model. An input instance is first sent to the rules
for decision. If a rule is satisfied, a decision will be directly generated.
Otherwise, the black-box model is activated to decide on the instance. To train
a hybrid model, we design an efficient search algorithm that exploits
theoretically grounded strategies to reduce computation. Experiments show that
CoBRUSH models are able to achieve same or better accuracy than their black-box
collaborator working alone while gaining explainability. They also have smaller
model complexity than interpretable baselines.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1&quot;&gt;Tong Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04365">
<title>Learning a Neural-network-based Representation for Open Set Recognition. (arXiv:1802.04365v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.04365</link>
<description rdf:parseType="Literal">&lt;p&gt;Open set recognition problems exist in many domains. For example in security,
new malware classes emerge regularly; therefore malware classification systems
need to identify instances from unknown classes in addition to discriminating
between known classes. In this paper we present a neural network based
representation for addressing the open set recognition problem. In this
representation instances from the same class are close to each other while
instances from different classes are further apart, resulting in statistically
significant improvement when compared to other approaches on three datasets
from two different domains.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hassen_M/0/1/0/all/0/1&quot;&gt;Mehadi Hassen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chan_P/0/1/0/all/0/1&quot;&gt;Philip K. Chan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04374">
<title>Tempered Adversarial Networks. (arXiv:1802.04374v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.04374</link>
<description rdf:parseType="Literal">&lt;p&gt;Generative adversarial networks (GANs) have been shown to produce realistic
samples from high-dimensional distributions, but training them is considered
hard. A possible explanation for training instabilities is the inherent
imbalance between the networks: While the discriminator is trained directly on
both real and fake samples, the generator only has control over the fake
samples it produces since the real data distribution is fixed by the choice of
a given dataset. We propose a simple modification that gives the generator
control over the real samples which leads to a tempered learning process for
both generator and discriminator. The real data distribution passes through a
lens before being revealed to the discriminator, balancing the generator and
discriminator by gradually revealing more detailed features necessary to
produce high-quality results. The proposed module automatically adjusts the
learning process to the current strength of the networks, yet is generic and
easy to add to any GAN variant. In a number of experiments, we show that this
can improve quality, stability and/or convergence speed across a range of
different GAN architectures (DCGAN, LSGAN, WGAN-GP).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sajjadi_M/0/1/0/all/0/1&quot;&gt;Mehdi S. M. Sajjadi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Scholkopf_B/0/1/0/all/0/1&quot;&gt;Bernhard Sch&amp;#xf6;lkopf&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04407">
<title>Adversarially Regularized Graph Autoencoder. (arXiv:1802.04407v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.04407</link>
<description rdf:parseType="Literal">&lt;p&gt;Graph embedding is an effective method to represent graph data in a low
dimensional space for graph analytics. Most existing embedding algorithms
typically focus on preserving the topological structure or minimizing the
reconstruction errors of graph data, but they have mostly ignored the data
distribution of the latent codes from the graphs, which often results in
inferior embedding in real-world graph data. In this paper, we propose a novel
adversarial graph embedding framework for graph data. The framework encodes the
topological structure and node content in a graph to a compact representation,
on which a decoder is trained to reconstruct the graph structure. Furthermore,
the latent representation is enforced to match a prior distribution via an
adversarial training scheme. To learn a robust embedding, two variants of
adversarial approaches, adversarially regularized graph autoencoder (ARGA) and
adversarially regularized variational graph autoencoder (ARVGA), are developed.
Experimental studies on real-world graphs validate our design and demonstrate
that our algorithms outperform baselines by a wide margin in link prediction,
graph clustering, and graph visualization tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pan_S/0/1/0/all/0/1&quot;&gt;Shirui Pan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_R/0/1/0/all/0/1&quot;&gt;Ruiqi Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Long_G/0/1/0/all/0/1&quot;&gt;Guodong Long&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1&quot;&gt;Jing Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yao_L/0/1/0/all/0/1&quot;&gt;Lina Yao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1&quot;&gt;Chengqi Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04422">
<title>A comparative study of fairness-enhancing interventions in machine learning. (arXiv:1802.04422v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.04422</link>
<description rdf:parseType="Literal">&lt;p&gt;Computers are increasingly used to make decisions that have significant
impact in people&apos;s lives. Often, these predictions can affect different
population subgroups disproportionately. As a result, the issue of fairness has
received much recent interest, and a number of fairness-enhanced classifiers
and predictors have appeared in the literature. This paper seeks to study the
following questions: how do these different techniques fundamentally compare to
one another, and what accounts for the differences? Specifically, we seek to
bring attention to many under-appreciated aspects of such fairness-enhancing
interventions. Concretely, we present the results of an open benchmark we have
developed that lets us compare a number of different algorithms under a variety
of fairness measures, and a large number of existing datasets. We find that
although different algorithms tend to prefer specific formulations of fairness
preservations, many of these measures strongly correlate with one another. In
addition, we find that fairness-preserving algorithms tend to be sensitive to
fluctuations in dataset composition (simulated in our benchmark by varying
training-test splits), indicating that fairness interventions might be more
brittle than previously thought.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Friedler_S/0/1/0/all/0/1&quot;&gt;Sorelle A. Friedler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Scheidegger_C/0/1/0/all/0/1&quot;&gt;Carlos Scheidegger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Venkatasubramanian_S/0/1/0/all/0/1&quot;&gt;Suresh Venkatasubramanian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Choudhary_S/0/1/0/all/0/1&quot;&gt;Sonam Choudhary&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hamilton_E/0/1/0/all/0/1&quot;&gt;Evan P. Hamilton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Roth_D/0/1/0/all/0/1&quot;&gt;Derek Roth&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04457">
<title>Predicting Adversarial Examples with High Confidence. (arXiv:1802.04457v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.04457</link>
<description rdf:parseType="Literal">&lt;p&gt;It has been suggested that adversarial examples cause deep learning models to
make incorrect predictions with high confidence. In this work, we take the
opposite stance: an overly confident model is more likely to be vulnerable to
adversarial examples. This work is one of the most proactive approaches taken
to date, as we link robustness with non-calibrated model confidence on noisy
images, providing a data-augmentation-free path forward. The adversarial
examples phenomenon is most easily explained by the trend of increasing
non-regularized model capacity, while the diversity and number of samples in
common datasets has remained flat. Test accuracy has incorrectly been
associated with true generalization performance, ignoring that training and
test splits are often extremely similar in terms of the overall representation
space. The transferability property of adversarial examples was previously used
as evidence against overfitting arguments, a perceived random effect, but
overfitting is not always random.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Galloway_A/0/1/0/all/0/1&quot;&gt;Angus Galloway&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Taylor_G/0/1/0/all/0/1&quot;&gt;Graham W. Taylor&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moussa_M/0/1/0/all/0/1&quot;&gt;Medhat Moussa&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04474">
<title>Deep Neural Networks Learn Non-Smooth Functions Effectively. (arXiv:1802.04474v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.04474</link>
<description rdf:parseType="Literal">&lt;p&gt;We theoretically discuss why deep neural networks (DNNs) performs better than
other models in some cases by investigating statistical properties of DNNs for
non-smooth functions. While DNNs have empirically shown higher performance than
other standard methods, understanding its mechanism is still a challenging
problem. From an aspect of the statistical theory, it is known many standard
methods attain optimal convergence rates, and thus it has been difficult to
find theoretical advantages of DNNs. This paper fills this gap by considering
learning of a certain class of non-smooth functions, which was not covered by
the previous theory. We derive convergence rates of estimators by DNNs with a
ReLU activation, and show that the estimators by DNNs are almost optimal to
estimate the non-smooth functions, while some of the popular models do not
attain the optimal rate. In addition, our theoretical result provides
guidelines for selecting an appropriate number of layers and edges of DNNs. We
provide numerical experiments to support the theoretical results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Imaizumi_M/0/1/0/all/0/1&quot;&gt;Masaaki Imaizumi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Fukumizu_K/0/1/0/all/0/1&quot;&gt;Kenji Fukumizu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04475">
<title>Graph-Based Ascent Algorithms for Function Maximization. (arXiv:1802.04475v1 [cs.SI])</title>
<link>http://arxiv.org/abs/1802.04475</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the problem of finding the maximum of a function defined on the
nodes of a connected graph. The goal is to identify a node where the function
obtains its maximum. We focus on local iterative algorithms, which traverse the
nodes of the graph along a path, and the next iterate is chosen from the
neighbors of the current iterate with probability distribution determined by
the function values at the current iterate and its neighbors. We study two
algorithms corresponding to a Metropolis-Hastings random walk with different
transition kernels: (i) The first algorithm is an exponentially weighted random
walk governed by a parameter $\gamma$. (ii) The second algorithm is defined
with respect to the graph Laplacian and a smoothness parameter $k$. We derive
convergence rates for the two algorithms in terms of total variation distance
and hitting times. We also provide simulations showing the relative convergence
rates of our algorithms in comparison to an unbiased random walk, as a function
of the smoothness of the graph function. Our algorithms may be categorized as a
new class of &quot;descent-based&quot; methods for function maximization on the nodes of
a graph.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pydi_M/0/1/0/all/0/1&quot;&gt;Muni Sreenivas Pydi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jog_V/0/1/0/all/0/1&quot;&gt;Varun Jog&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Loh_P/0/1/0/all/0/1&quot;&gt;Po-Ling Loh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04477">
<title>A Simple Proximal Stochastic Gradient Method for Nonsmooth Nonconvex Optimization. (arXiv:1802.04477v1 [math.OC])</title>
<link>http://arxiv.org/abs/1802.04477</link>
<description rdf:parseType="Literal">&lt;p&gt;We analyze stochastic gradient algorithms for optimizing nonconvex, nonsmooth
finite-sum problems. In particular, the objective function is given by the
summation of a differentiable (possibly nonconvex) component, together with a
possibly non-differentiable but convex component. We propose a proximal
stochastic gradient algorithm based on variance reduction, called ProxSVRG+.
The algorithm is a slight variant of the ProxSVRG algorithm [Reddi et al.,
2016b]. Our main contribution lies in the analysis of ProxSVRG+. It recovers
several existing convergence results (in terms of the number of stochastic
gradient oracle calls and proximal operations), and improves/generalizes some
others. In particular, ProxSVRG+ generalizes the best results given by the SCSG
algorithm, recently proposed by [Lei et al., 2017] for the smooth nonconvex
case. ProxSVRG+ is more straightforward than SCSG and yields simpler analysis.
Moreover, ProxSVRG+ outperforms the deterministic proximal gradient descent
(ProxGD) for a wide range of minibatch sizes, which partially solves an open
problem proposed in [Reddi et al., 2016b]. Finally, for nonconvex functions
satisfied Polyak-{\L}ojasiewicz condition, we show that ProxSVRG+ achieves
global linear convergence rate without restart. ProxSVRG+ is always no worse
than ProxGD and ProxSVRG/SAGA, and sometimes outperforms them (and generalizes
the results of SCSG) in this case.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Zhize Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jian Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04502">
<title>Legendre Tensor Decomposition. (arXiv:1802.04502v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.04502</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a novel nonnegative tensor decomposition method, called Legendre
decomposition, which factorizes an input tensor into a multiplicative
combination of parameters. Thanks to the well-developed theory of information
geometry, the reconstructed tensor is unique and always minimizes the KL
divergence from an input tensor. We empirically show that Legendre
decomposition can more accurately reconstruct tensors than nonnegative CP and
Tucker decompositions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sugiyama_M/0/1/0/all/0/1&quot;&gt;Mahito Sugiyama&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Nakahara_H/0/1/0/all/0/1&quot;&gt;Hiroyuki Nakahara&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tsuda_K/0/1/0/all/0/1&quot;&gt;Koji Tsuda&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04537">
<title>Tighter Variational Bounds are Not Necessarily Better. (arXiv:1802.04537v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.04537</link>
<description rdf:parseType="Literal">&lt;p&gt;We provide theoretical and empirical evidence that using tighter evidence
lower bounds (ELBOs) can be detrimental to the process of learning an inference
network by reducing the signal-to-noise ratio of the gradient estimator. Our
results call into question common implicit assumptions that tighter ELBOs are
better variational objectives for simultaneous model learning and inference
amortization schemes. Based on our insights, we introduce three new algorithms:
the partially importance weighted auto-encoder (PIWAE), the multiply importance
weighted auto-encoder (MIWAE), and the combination importance weighted
auto-encoder (CIWAE), each of which includes the standard importance weighted
auto-encoder (IWAE) as a special case. We show that each can deliver
improvements over IWAE, even when performance is measured by the IWAE target
itself. Moreover, PIWAE can simultaneously deliver improvements in both the
quality of the inference network and generative network, relative to IWAE.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rainforth_T/0/1/0/all/0/1&quot;&gt;Tom Rainforth&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kosiorek_A/0/1/0/all/0/1&quot;&gt;Adam R. Kosiorek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Le_T/0/1/0/all/0/1&quot;&gt;Tuan Anh Le&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Maddison_C/0/1/0/all/0/1&quot;&gt;Chris J. Maddison&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Igl_M/0/1/0/all/0/1&quot;&gt;Maximilian Igl&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wood_F/0/1/0/all/0/1&quot;&gt;Frank Wood&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Teh_Y/0/1/0/all/0/1&quot;&gt;Yee Whye Teh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04617">
<title>Fast Global Convergence via Landscape of Empirical Loss. (arXiv:1802.04617v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.04617</link>
<description rdf:parseType="Literal">&lt;p&gt;While optimizing convex objective (loss) functions has been a powerhouse for
machine learning for at least two decades, non-convex loss functions have
attracted fast growing interests recently, due to many desirable properties
such as superior robustness and classification accuracy, compared with their
convex counterparts. The main obstacle for non-convex estimators is that it is
in general intractable to find the optimal solution. In this paper, we study
the computational issues for some non-convex M-estimators. In particular, we
show that the stochastic variance reduction methods converge to the global
optimal with linear rate, by exploiting the statistical property of the
population loss. En route, we improve the convergence analysis for the batch
gradient method in \cite{mei2016landscape}.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Qu_C/0/1/0/all/0/1&quot;&gt;Chao Qu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yan Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Xu_H/0/1/0/all/0/1&quot;&gt;Huan Xu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04630">
<title>A probabilistic framework for multi-view feature learning with many-to-many associations via neural networks. (arXiv:1802.04630v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.04630</link>
<description rdf:parseType="Literal">&lt;p&gt;A simple framework Probabilistic Multi-view Graph Embedding (PMvGE) is
proposed for multi-view feature learning with many-to-many associations. PMvGE
is a probabilistic model for predicting new associations via graph embedding of
the nodes of data vectors with links of their associations.Multi-view data
vectors with many-to-many associations are transformed by neural networks to
feature vectors in a shared space, and the probability of new association
between two data vectors is modeled by the inner product of their feature
vectors. While existing multi-view feature learning techniques can treat only
either of many-to-many association or non-linear transformation, PMvGE can
treat both simultaneously. By combining Mercer&apos;s theorem and the universal
approximation theorem, we prove that PMvGE learns a wide class of similarity
measures across views. PMvGE generalizes various existing multi-view methods
such as Multiset Canonical Correlation Analysis (MCCA) and Cross-view Graph
Embedding (CvGE). Our likelihood-based estimator enables efficient computation
of non-linear transformations of data vectors in large-scale datasets by
minibatch SGD. Numerical experiments illustrate that PMvGE outperforms existing
multi-view methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Okuno_A/0/1/0/all/0/1&quot;&gt;Akifumi Okuno&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hada_T/0/1/0/all/0/1&quot;&gt;Tetsuya Hada&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Shimodaira_H/0/1/0/all/0/1&quot;&gt;Hidetoshi Shimodaira&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04664">
<title>Recovering Loss to Followup Information Using Denoising Autoencoders. (arXiv:1802.04664v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.04664</link>
<description rdf:parseType="Literal">&lt;p&gt;Loss to followup is a significant issue in healthcare and has serious
consequences for a study&apos;s validity and cost. Methods available at present for
recovering loss to followup information are restricted by their expressive
capabilities and struggle to model highly non-linear relations and complex
interactions. In this paper we propose a model based on overcomplete denoising
autoencoders to recover loss to followup information. Designed to work with
high volume data, results on various simulated and real life datasets show our
model is appropriate under varying dataset and loss to followup conditions and
outperforms the state-of-the-art methods by a wide margin ($\ge 20\%$ in some
scenarios) while preserving the dataset utility for final analysis.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gondara_L/0/1/0/all/0/1&quot;&gt;Lovedeep Gondara&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1&quot;&gt;Ke Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04676">
<title>Variable Selection and Task Grouping for Multi-Task Learning. (arXiv:1802.04676v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.04676</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider multi-task learning, which simultaneously learns related
prediction tasks, to improve generalization performance. We factorize a
coefficient matrix as the product of two matrices based on a low-rank
assumption. These matrices have sparsities to simultaneously perform variable
selection and learn and overlapping group structure among the tasks. The
resulting bi-convex objective function is minimized by alternating optimization
where sub-problems are solved using alternating direction method of multipliers
and accelerated proximal gradient descent. Moreover, we provide the performance
bound of the proposed method. The effectiveness of the proposed method is
validated for both synthetic and real-world datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Jeong_J/0/1/0/all/0/1&quot;&gt;Jun-Yong Jeong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Jun_C/0/1/0/all/0/1&quot;&gt;Chi-Hyuck Jun&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04687">
<title>Neural Relational Inference for Interacting Systems. (arXiv:1802.04687v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.04687</link>
<description rdf:parseType="Literal">&lt;p&gt;Interacting systems are prevalent in nature, from dynamical systems in
physics to complex societal dynamics. The interplay of components can give rise
to complex behavior, which can often be explained using a simple model of the
system&apos;s constituent parts. In this work, we introduce the neural relational
inference (NRI) model: an unsupervised model that learns to infer interactions
while simultaneously learning the dynamics purely from observational data. Our
model takes the form of a variational auto-encoder, in which the latent code
represents the underlying interaction graph and the reconstruction is based on
graph neural networks. In experiments on simulated physical systems, we show
that our NRI model can accurately recover ground-truth interactions in an
unsupervised manner. We further demonstrate that we can find an interpretable
structure and predict complex dynamics in real motion capture and sports
tracking data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kipf_T/0/1/0/all/0/1&quot;&gt;Thomas Kipf&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Fetaya_E/0/1/0/all/0/1&quot;&gt;Ethan Fetaya&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wang_K/0/1/0/all/0/1&quot;&gt;Kuan-Chieh Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Welling_M/0/1/0/all/0/1&quot;&gt;Max Welling&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zemel_R/0/1/0/all/0/1&quot;&gt;Richard Zemel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04712">
<title>Attention-based Deep Multiple Instance Learning. (arXiv:1802.04712v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.04712</link>
<description rdf:parseType="Literal">&lt;p&gt;Multiple instance learning (MIL) is a variation of supervised learning where
a single class label is assigned to a bag of instances. In this paper, we state
the MIL problem as learning the Bernoulli distribution of the bag label where
the bag label probability is fully parameterized by neural networks.
Furthermore, we propose a neural network-based permutation-invariant
aggregation operator that corresponds to the attention mechanism. Notably, an
application of the proposed attention-based operator provides insight into the
contribution of each instance to the bag label. We show empirically that our
approach achieves comparable performance to the best MIL methods on benchmark
MIL datasets and it outperforms other methods on a MNIST-based MIL dataset and
two real-life histopathology datasets without sacrificing interpretability.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ilse_M/0/1/0/all/0/1&quot;&gt;Maximilian Ilse&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tomczak_J/0/1/0/all/0/1&quot;&gt;Jakub M. Tomczak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Welling_M/0/1/0/all/0/1&quot;&gt;Max Welling&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04715">
<title>Online Variance Reduction for Stochastic Optimization. (arXiv:1802.04715v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.04715</link>
<description rdf:parseType="Literal">&lt;p&gt;Modern stochastic optimization methods often rely on uniform sampling which
is agnostic to the underlying characteristics of the data. This might degrade
the convergence by yielding estimates that suffer from a high variance. A
possible remedy is to employ non-uniform importance sampling techniques, which
take the structure of the dataset into account. In this work, we investigate a
recently proposed setting which poses variance reduction as an online
optimization problem with bandit feedback. We devise a novel and efficient
algorithm for this setting that finds a sequence of importance sampling
distributions competitive with the best fixed distribution in hindsight, the
first result of this kind. While we present our method for sampling datapoints,
it naturally extends to selecting coordinates or even blocks of thereof.
Empirical validations underline the benefits of our method in several settings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Borsos_Z/0/1/0/all/0/1&quot;&gt;Zal&amp;#xe1;n Borsos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Krause_A/0/1/0/all/0/1&quot;&gt;Andreas Krause&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Levy_K/0/1/0/all/0/1&quot;&gt;Kfir Y. Levy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04725">
<title>Superposition-Assisted Stochastic Optimization for Hawkes Processes. (arXiv:1802.04725v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.04725</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the learning of multi-agent Hawkes processes, a model containing
multiple Hawkes processes with shared endogenous impact functions and different
exogenous intensities. In the framework of stochastic maximum likelihood
estimation, we explore the associated risk bound. Further, we consider the
superposition of Hawkes processes within the model, and demonstrate that under
certain conditions such an operation is beneficial for tightening the risk
bound. Accordingly, we propose a stochastic optimization algorithm assisted
with a diversity-driven superposition strategy, achieving better learning
results with improved convergence properties. The effectiveness of the proposed
method is verified on synthetic data, and its potential to solve the cold-start
problem of sequential recommendation systems is demonstrated on real-world
data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Xu_H/0/1/0/all/0/1&quot;&gt;Hongteng Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chen_X/0/1/0/all/0/1&quot;&gt;Xu Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Carin_L/0/1/0/all/0/1&quot;&gt;Lawrence Carin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04734">
<title>Substation Signal Matching with a Bagged Token Classifier. (arXiv:1802.04734v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.04734</link>
<description rdf:parseType="Literal">&lt;p&gt;Currently, engineers at substation service providers match customer data with
the corresponding internally used signal names manually. This paper proposes a
machine learning method to automate this process based on substation signal
mapping data from a repository of executed projects. To this end, a bagged
token classifier is proposed, letting words (tokens) in the customer signal
name vote for provider signal names. In our evaluation, the proposed method
exhibits better performance in terms of both accuracy and efficiency over
standard classifiers.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wang_Q/0/1/0/all/0/1&quot;&gt;Qin Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Schoenborn_S/0/1/0/all/0/1&quot;&gt;Sandro Schoenborn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pignolet_Y/0/1/0/all/0/1&quot;&gt;Yvonne-Anne Pignolet&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Widmer_T/0/1/0/all/0/1&quot;&gt;Theo Widmer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Franke_C/0/1/0/all/0/1&quot;&gt;Carsten Franke&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04782">
<title>An Improved Bayesian Framework for Quadrature of Constrained Integrands. (arXiv:1802.04782v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.04782</link>
<description rdf:parseType="Literal">&lt;p&gt;Quadrature is the problem of estimating intractable integrals, a problem that
arises in many Bayesian machine learning settings. We present an improved
Bayesian framework for estimating intractable integrals of specific kinds of
constrained integrands. We derive the necessary approximation scheme for a
specific and especially useful instantiation of this framework: the use of a
log transformation to model non-negative integrands. We also propose a novel
method for optimizing the hyperparameters associated with this framework; we
optimize the hyperparameters in the original space of the integrand as opposed
to in the transformed space, resulting in a model that better explains the
actual data. Experiments on both synthetic and real-world data demonstrate that
the proposed framework achieves more-accurate estimates using less wall-clock
time than previously preposed Bayesian quadrature procedures for non-negative
integrands.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chai_H/0/1/0/all/0/1&quot;&gt;Henry Chai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garnett_R/0/1/0/all/0/1&quot;&gt;Roman Garnett&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04784">
<title>MONK -- Outlier-Robust Mean Embedding Estimation by Median-of-Means. (arXiv:1802.04784v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.04784</link>
<description rdf:parseType="Literal">&lt;p&gt;Mean embeddings provide an extremely flexible and powerful tool in machine
learning and statistics to represent probability distributions and define a
semi-metric (MMD, maximum mean discrepancy; also called N-distance or energy
distance), with numerous successful applications. The representation is
constructed as the expectation of the feature map defined by a kernel. As a
mean, its classical empirical estimator, however, can be arbitrary severely
affected even by a single outlier in case of unbounded features. To the best of
our knowledge, unfortunately even the consistency of the existing few
techniques trying to alleviate this serious sensitivity bottleneck is unknown.
In this paper, we show how the recently emerged principle of median-of-means
can be used to design minimax-optimal estimators for kernel mean embedding and
MMD, with finite-sample strong outlier-robustness guarantees.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lerasle_M/0/1/0/all/0/1&quot;&gt;Matthieu Lerasle&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Szabo_Z/0/1/0/all/0/1&quot;&gt;Zoltan Szabo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Massiot_G/0/1/0/all/0/1&quot;&gt;Gaspar Massiot&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Moulines_E/0/1/0/all/0/1&quot;&gt;Eric Moulines&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04791">
<title>Stochastic Variance-Reduced Hamilton Monte Carlo Methods. (arXiv:1802.04791v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.04791</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a fast stochastic Hamilton Monte Carlo (HMC) method, for sampling
from a smooth and strongly log-concave distribution. At the core of our
proposed method is a variance reduction technique inspired by the recent
advance in stochastic optimization. We show that, to achieve $\epsilon$
accuracy in 2-Wasserstein distance, our algorithm achieves $\tilde
O\big(n+\kappa^{2}d^{1/2}/\epsilon+\kappa^{4/3}d^{1/3}n^{2/3}/\epsilon^{2/3}\big)$
gradient complexity (i.e., number of component gradient evaluations), which
outperforms the state-of-the-art HMC and stochastic gradient HMC methods in a
wide regime. We also extend our algorithm for sampling from smooth and general
log-concave distributions, and prove the corresponding gradient complexity as
well. Experiments on both synthetic and real data demonstrate the superior
performance of our algorithm.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zou_D/0/1/0/all/0/1&quot;&gt;Difan Zou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Xu_P/0/1/0/all/0/1&quot;&gt;Pan Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gu_Q/0/1/0/all/0/1&quot;&gt;Quanquan Gu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1503.02978">
<title>Kernel Meets Sieve: Post-Regularization Confidence Bands for Sparse Additive Model. (arXiv:1503.02978v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1503.02978</link>
<description rdf:parseType="Literal">&lt;p&gt;We develop a novel procedure for constructing confidence bands for components
of a sparse additive model. Our procedure is based on a new kernel-sieve hybrid
estimator that combines two most popular nonparametric estimation methods in
the literature, the kernel regression and the spline method, and is of interest
in its own right. Existing methods for fitting sparse additive model are
primarily based on sieve estimators, while the literature on confidence bands
for nonparametric models are primarily based upon kernel or local polynomial
estimators. Our kernel-sieve hybrid estimator combines the best of both worlds
and allows us to provide a simple procedure for constructing confidence bands
in high-dimensional sparse additive models. We prove that the confidence bands
are asymptotically honest by studying approximation with a Gaussian process.
Thorough numerical results on both synthetic data and real-world neuroscience
data are provided to demonstrate the efficacy of the theory.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lu_J/0/1/0/all/0/1&quot;&gt;Junwei Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kolar_M/0/1/0/all/0/1&quot;&gt;Mladen Kolar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Liu_H/0/1/0/all/0/1&quot;&gt;Han Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1512.08298">
<title>Post-Regularization Inference for Time-Varying Nonparanormal Graphical Models. (arXiv:1512.08298v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1512.08298</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a novel class of time-varying nonparanormal graphical models,
which allows us to model high dimensional heavy-tailed systems and the
evolution of their latent network structures. Under this model, we develop
statistical tests for presence of edges both locally at a fixed index value and
globally over a range of values. The tests are developed for a high-dimensional
regime, are robust to model selection mistakes and do not require commonly
assumed minimum signal strength. The testing procedures are based on a high
dimensional, debiasing-free moment estimator, which uses a novel kernel
smoothed Kendall&apos;s tau correlation matrix as an input statistic. The estimator
consistently estimates the latent inverse Pearson correlation matrix uniformly
in both the index variable and kernel bandwidth. Its rate of convergence is
shown to be minimax optimal. Our method is supported by thorough numerical
simulations and an application to a neural imaging data set.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lu_J/0/1/0/all/0/1&quot;&gt;Junwei Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kolar_M/0/1/0/all/0/1&quot;&gt;Mladen Kolar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Liu_H/0/1/0/all/0/1&quot;&gt;Han Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1606.00389">
<title>Stream Clipper: Scalable Submodular Maximization on Stream. (arXiv:1606.00389v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1606.00389</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a streaming submodular maximization algorithm &quot;stream clipper&quot;
that performs as well as the offline greedy algorithm on document/video
summarization in practice. It adds elements from a stream either to a solution
set $S$ or to an extra buffer $B$ based on two adaptive thresholds, and
improves $S$ by a final greedy step that starts from $S$ adding elements from
$B$. During this process, swapping elements out of $S$ can occur if doing so
yields improvements. The thresholds adapt based on if current memory
utilization exceeds a budget, e.g., it increases the lower threshold, and
removes from the buffer $B$ elements below the new lower threshold. We show
that, while our approximation factor in the worst case is $1/2$ (like in
previous work, and corresponding to the tight bound), we show that there are
data-dependent conditions where our bound falls within the range $[1/2,
1-1/e]$. In news and video summarization experiments, the algorithm
consistently outperforms other streaming methods, and, while using
significantly less computation and memory, performs similarly to the offline
greedy algorithm.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhou_T/0/1/0/all/0/1&quot;&gt;Tianyi Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bilmes_J/0/1/0/all/0/1&quot;&gt;Jeff Bilmes&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1608.03045">
<title>Combinatorial Inference for Graphical Models. (arXiv:1608.03045v3 [math.ST] UPDATED)</title>
<link>http://arxiv.org/abs/1608.03045</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a new family of combinatorial inference problems for graphical
models. Unlike classical statistical inference where the main interest is point
estimation or parameter testing, combinatorial inference aims at testing the
global structure of the underlying graph. Examples include testing the graph
connectivity, the presence of a cycle of certain size, or the maximum degree of
the graph. To begin with, we develop a unified theory for the fundamental
limits of a large family of combinatorial inference problems. We propose new
concepts including structural packing and buffer entropies to characterize how
the complexity of combinatorial graph structures impacts the corresponding
minimax lower bounds. On the other hand, we propose a family of novel and
practical structural testing algorithms to match the lower bounds. We provide
thorough numerical results on both synthetic graphical models and brain
networks to illustrate the usefulness of these proposed methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Neykov_M/0/1/0/all/0/1&quot;&gt;Matey Neykov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Lu_J/0/1/0/all/0/1&quot;&gt;Junwei Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Liu_H/0/1/0/all/0/1&quot;&gt;Han Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1703.00734">
<title>Distributed Bayesian Matrix Factorization with Limited Communication. (arXiv:1703.00734v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1703.00734</link>
<description rdf:parseType="Literal">&lt;p&gt;Bayesian matrix factorization (BMF) is a powerful tool for producing low-rank
representations of matrices and for predicting missing values and their
confidence intervals. Scaling up the posterior inference for massive-scale
matrices is challenging and requires distributing both data and computation
over many workers, making communication the main computational bottleneck.
Embarrassingly parallel inference would remove the communication needed, by
using completely independent computations on different data subsets, but
suffers from the inherent unidentifiability of BMF solutions. We introduce a
hierarchical decomposition of the joint posterior distribution, which couples
the subset inferences, allowing for embarrassingly parallel computations in a
sequence of at most three stages. Using an efficient approximate
implementation, we show empirically on both real and simulated data that our
distributed approach is able to achieve a speed-up of almost an order of
magnitude, with a negligible effect on predictive accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Qin_X/0/1/0/all/0/1&quot;&gt;Xiangju Qin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Blomstedt_P/0/1/0/all/0/1&quot;&gt;Paul Blomstedt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Leppaaho_E/0/1/0/all/0/1&quot;&gt;Eemeli Lepp&amp;#xe4;aho&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Parviainen_P/0/1/0/all/0/1&quot;&gt;Pekka Parviainen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kaski_S/0/1/0/all/0/1&quot;&gt;Samuel Kaski&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1707.08092">
<title>Restricted Eigenvalue from Stable Rank with Applications to Sparse Linear Regression. (arXiv:1707.08092v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1707.08092</link>
<description rdf:parseType="Literal">&lt;p&gt;High-dimensional settings, where the data dimension ($d$) far exceeds the
number of observations ($n$), are common in many statistical and machine
learning applications. Methods based on $\ell_1$-relaxation, such as Lasso, are
very popular for sparse recovery in these settings. Restricted Eigenvalue (RE)
condition is among the weakest and hence the most general condition in
literature imposed on the Gram matrix that guarantees nice statistical
properties for the Lasso estimator. It is natural to ask: what families of
matrices satisfy the RE condition? Following a line of work in this area, we
construct a new broad ensemble of dependent random design matrices that have an
explicit RE bound. Our construction starts with a fixed (deterministic) matrix
$X \in \mathbb{R}^{n \times d}$ satisfying a simple stable rank condition, and
we show that a matrix drawn from the distribution $X \Phi^\top \Phi$, where
$\Phi \in \mathbb{R}^{m \times d}$ is a subgaussian random matrix, with high
probability, satisfies the RE condition. This construction allows incorporating
a fixed matrix that has an easily verifiable condition into the design process,
and allows for generation of compressed design matrices that have a lower
storage requirement than a standard design matrix. We give two applications of
this construction to sparse linear regression problems, including one to a
compressed sparse regression setting where the regression algorithm only has
access to a compressed representation of a fixed design matrix $X$.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kasiviswanathan_S/0/1/0/all/0/1&quot;&gt;Shiva Prasad Kasiviswanathan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rudelson_M/0/1/0/all/0/1&quot;&gt;Mark Rudelson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.01179">
<title>Continuous-Time Flows for Efficient Inference and Density Estimation. (arXiv:1709.01179v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1709.01179</link>
<description rdf:parseType="Literal">&lt;p&gt;Two fundamental problems in unsupervised learning are efficient inference for
latent-variable models and robust density estimation based on large amounts of
unlabeled data. Algorithms for the two tasks, such as normalizing flows and
generative adversarial networks (GANs), are often developed independently. In
this paper, we propose the concept of {\em continuous-time flows} (CTFs), a
family of diffusion-based methods that are able to asymptotically approach a
target distribution. Distinct from normalizing flows and GANs, CTFs can be
adopted to achieve the above two goals in one framework, with theoretical
guarantees. Our framework includes distilling knowledge from a CTF for
efficient inference, and learning an explicit energy-based distribution with
CTFs for density estimation. Both tasks rely on a new technique for
distribution matching within amortized learning. Experiments on various tasks
demonstrate promising performance of the proposed CTF framework, compared to
related techniques.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chen_C/0/1/0/all/0/1&quot;&gt;Changyou Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Li_C/0/1/0/all/0/1&quot;&gt;Chunyuan Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chen_L/0/1/0/all/0/1&quot;&gt;Liqun Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wang_W/0/1/0/all/0/1&quot;&gt;Wenlin Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pu_Y/0/1/0/all/0/1&quot;&gt;Yunchen Pu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Carin_L/0/1/0/all/0/1&quot;&gt;Lawrence Carin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.01410">
<title>Learning Registered Point Processes from Idiosyncratic Observations. (arXiv:1710.01410v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1710.01410</link>
<description rdf:parseType="Literal">&lt;p&gt;A parametric point process model is developed, with modeling based on the
assumption that sequential observations often share latent phenomena, while
also possessing idiosyncratic effects. An alternating optimization method is
proposed to learn a &quot;registered&quot; point process that accounts for shared
structure, as well as &quot;warping&quot; functions that characterize idiosyncratic
aspects of each observed sequence. Under reasonable constraints, in each
iteration we update the sample-specific warping functions by solving a set of
constrained nonlinear programming problems in parallel, and update the model by
maximum likelihood estimation. The justifiability, complexity and robustness of
the proposed method are investigated in detail, and the influence of sequence
stitching on the learning results is examined empirically. Experiments on both
synthetic and real-world data demonstrate that the method yields explainable
point process models, achieving encouraging results compared to
state-of-the-art methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Xu_H/0/1/0/all/0/1&quot;&gt;Hongteng Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Carin_L/0/1/0/all/0/1&quot;&gt;Lawrence Carin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zha_H/0/1/0/all/0/1&quot;&gt;Hongyuan Zha&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.05115">
<title>Benefits from Superposed Hawkes Processes. (arXiv:1710.05115v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1710.05115</link>
<description rdf:parseType="Literal">&lt;p&gt;The superposition of temporal point processes has been studied for many
years, although the usefulness of such models for practical applications has
not be fully developed. We investigate superposed Hawkes process as an
important class of such models, with properties studied in the framework of
least squares estimation. The superposition of Hawkes processes is demonstrated
to be beneficial for tightening the upper bound of excess risk under certain
conditions, and we show the feasibility of the benefit in typical situations.
The usefulness of superposed Hawkes processes is verified on synthetic data,
and its potential to solve the cold-start problem of recommendation systems is
demonstrated on real-world data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Xu_H/0/1/0/all/0/1&quot;&gt;Hongteng Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Luo_D/0/1/0/all/0/1&quot;&gt;Dixin Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chen_X/0/1/0/all/0/1&quot;&gt;Xu Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Carin_L/0/1/0/all/0/1&quot;&gt;Lawrence Carin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.10513">
<title>Crime incidents embedding using restricted Boltzmann machines. (arXiv:1710.10513v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1710.10513</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a new approach for detecting related crime series, by unsupervised
learning of the latent feature embeddings from narratives of crime record via
the Gaussian-Bernoulli Restricted Boltzmann Machines (RBM). This is a
drastically different approach from prior work on crime analysis, which
typically considers only time and location and at most category information.
After the embedding, related cases are closer to each other in the Euclidean
feature space, and the unrelated cases are far apart, which is a good property
can enable subsequent analysis such as detection and clustering of related
cases. Experiments over several series of related crime incidents hand labeled
by the Atlanta Police Department reveal the promise of our embedding methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhu_S/0/1/0/all/0/1&quot;&gt;Shixiang Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Xie_Y/0/1/0/all/0/1&quot;&gt;Yao Xie&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.06598">
<title>How Wrong Am I? - Studying Adversarial Examples and their Impact on Uncertainty in Gaussian Process Machine Learning Models. (arXiv:1711.06598v2 [cs.CR] UPDATED)</title>
<link>http://arxiv.org/abs/1711.06598</link>
<description rdf:parseType="Literal">&lt;p&gt;Machine learning models are vulnerable to Adversarial Examples: minor
perturbations to input samples intended to deliberately cause
misclassification. Current defenses against adversarial examples, especially
for Deep Neural Networks (DNN), are primarily derived from empirical
developments, and their security guarantees are often only justified
retroactively. Many defenses therefore rely on hidden assumptions that are
subsequently subverted by increasingly elaborate attacks. This is not
surprising: deep learning notoriously lacks a comprehensive mathematical
framework to provide meaningful guarantees.
&lt;/p&gt;
&lt;p&gt;In this paper, we leverage Gaussian Processes to investigate adversarial
examples in the framework of Bayesian inference. Across different models and
datasets, we find deviating levels of uncertainty reflect the perturbation
introduced to benign samples by state-of-the-art attacks, including novel
white-box attacks on Gaussian Processes. Our experiments demonstrate that even
unoptimized uncertainty thresholds already reject adversarial examples in many
scenarios.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grosse_K/0/1/0/all/0/1&quot;&gt;Kathrin Grosse&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pfaff_D/0/1/0/all/0/1&quot;&gt;David Pfaff&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Smith_M/0/1/0/all/0/1&quot;&gt;Michael Thomas Smith&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Backes_M/0/1/0/all/0/1&quot;&gt;Michael Backes&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.10581">
<title>Estimation and Optimization of Composite Outcomes. (arXiv:1711.10581v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1711.10581</link>
<description rdf:parseType="Literal">&lt;p&gt;There is tremendous interest in precision medicine as a means to improve
patient outcomes by tailoring treatment to individual characteristics. An
individualized treatment rule formalizes precision medicine as a map from
patient information to a recommended treatment. A rule is defined to be optimal
if it maximizes the mean of a scalar outcome in a population of interest, e.g.,
symptom reduction. However, clinical and intervention scientists often must
balance multiple and possibly competing outcomes, e.g., symptom reduction and
the risk of an adverse event. One approach to precision medicine in this
setting is to elicit a composite outcome which balances all competing outcomes;
unfortunately, eliciting a composite outcome directly from patients is
difficult without a high-quality instrument and an expert-derived composite
outcome may not account for heterogeneity in patient preferences. We consider
estimation of composite outcomes using observational data under the assumption
that clinicians are approximately (i.e., imperfectly) making decisions to
maximize individual patient utility. Estimated composite outcomes are
subsequently used to construct an estimator of an individualized treatment rule
that maximizes the mean of patient-specific composite outcomes. Furthermore,
the estimated composite outcomes and estimated optimal individualized treatment
rule can provide new insights into patient preference heterogeneity, clinician
behavior, and the value of precision medicine in a given domain. We derive
inference procedures for the proposed estimators under mild conditions and
demonstrate their finite sample performance through a suite of simulation
experiments and an illustrative application to data from a study of bipolar
depression.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Luckett_D/0/1/0/all/0/1&quot;&gt;Daniel J. Luckett&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Laber_E/0/1/0/all/0/1&quot;&gt;Eric B. Laber&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kosorok_M/0/1/0/all/0/1&quot;&gt;Michael R. Kosorok&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.06745">
<title>Efficient Algorithms for Searching the Minimum Information Partition in Integrated Information Theory. (arXiv:1712.06745v2 [q-bio.NC] UPDATED)</title>
<link>http://arxiv.org/abs/1712.06745</link>
<description rdf:parseType="Literal">&lt;p&gt;The ability to integrate information in the brain is considered to be an
essential property for cognition and consciousness. Integrated Information
Theory (IIT) hypothesizes that the amount of integrated information ($\Phi$) in
the brain is related to the level of consciousness. IIT proposes that to
quantify information integration in a system as a whole, integrated information
should be measured across the partition of the system at which information loss
caused by partitioning is minimized, called the Minimum Information Partition
(MIP). The computational cost for exhaustively searching for the MIP grows
exponentially with system size, making it difficult to apply IIT to real neural
data. It has been previously shown that if a measure of $\Phi$ satisfies a
mathematical property, submodularity, the MIP can be found in a polynomial
order by an optimization algorithm. However, although the first version of
$\Phi$ is submodular, the later versions are not. In this study, we empirically
explore to what extent the algorithm can be applied to the non-submodular
measures of $\Phi$ by evaluating the accuracy of the algorithm in simulated
data and real neural data. We find that the algorithm identifies the MIP in a
nearly perfect manner even for the non-submodular measures. Our results show
that the algorithm allows us to measure $\Phi$ in large systems within a
practical amount of time.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Kitazono_J/0/1/0/all/0/1&quot;&gt;Jun Kitazono&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Kanai_R/0/1/0/all/0/1&quot;&gt;Ryota Kanai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Oizumi_M/0/1/0/all/0/1&quot;&gt;Masafumi Oizumi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.03497">
<title>Modeling Dynamics with Deep Transition-Learning Networks. (arXiv:1802.03497v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1802.03497</link>
<description rdf:parseType="Literal">&lt;p&gt;Markov processes, both classical and higher order, are often used to model
dynamic processes, such as stock prices, molecular dynamics, and Monte Carlo
methods. Previous works have shown that an autoencoder can be formulated as a
specific type of Markov chain. Here, we propose a generative neural network
known as a transition encoder, or transcoder, which learns such
continuous-state dynamic processes. We show that the transcoder is able to
learn both deterministic and stochastic dynamic processes on several systems.
We explore a number of applications of the transcoder including generating
unseen trajectories and examining the propensity for chaos in a dynamic system.
Further, we show that the transcoder can speed up Markov Chain Monte Carlo
(MCMC) sampling to a convergent distribution by training it to make several
steps at a time. Finally, we show that the hidden layers of a transcoder are
useful for visualization and salient feature extraction of the transition
process itself.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dijk_D/0/1/0/all/0/1&quot;&gt;David van Dijk&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gigante_S/0/1/0/all/0/1&quot;&gt;Scott Gigante&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Strzalkowski_A/0/1/0/all/0/1&quot;&gt;Alexander Strzalkowski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wolf_G/0/1/0/all/0/1&quot;&gt;Guy Wolf&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Krishnaswamy_S/0/1/0/all/0/1&quot;&gt;Smita Krishnaswamy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.03848">
<title>Region Detection in Markov Random Fields: Gaussian Case. (arXiv:1802.03848v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1802.03848</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work we consider the problem of model selection in Gaussian Markov
fields in the sample deficient scenario. The benchmark information-theoretic
results in the case of d-regular graphs require the number of samples to be at
least proportional to the logarithm of the number of vertices to allow
consistent graph recovery. When the number of samples is less than this amount,
reliable detection of all edges is impossible. In many applications, it is more
important to learn the distribution of the edge (coupling) parameters over the
network than the specific locations of the edges. Assuming that the entire
graph can be partitioned into a number of spatial regions with similar edge
parameters and reasonably regular boundaries, we develop new
information-theoretic sample complexity bounds and show that even bounded
number of samples can be enough to consistently recover these regions. We also
introduce and analyze an efficient region growing algorithm capable of
recovering the regions with high accuracy. We show that it is consistent and
demonstrate its performance benefits in synthetic simulations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Soloveychik_I/0/1/0/all/0/1&quot;&gt;Ilya Soloveychik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tarokh_V/0/1/0/all/0/1&quot;&gt;Vahid Tarokh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.03800">
<title>Drug response prediction by ensemble learning and drug-induced gene expression signatures. (arXiv:1802.03800v1 [q-bio.GN] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1802.03800</link>
<description rdf:parseType="Literal">&lt;p&gt;Chemotherapeutic response of cancer cells to a given compound is one of the
most fundamental information one requires to design anti-cancer drugs. Recent
advances in producing large drug screens against cancer cell lines provided an
opportunity to apply machine learning methods for this purpose. In addition to
cytotoxicity databases, considerable amount of drug-induced gene expression
data has also become publicly available. Following this, several methods that
exploit omics data were proposed to predict drug activity on cancer cells.
However, due to the complexity of cancer drug mechanisms, none of the existing
methods are perfect. One possible direction, therefore, is to combine the
strengths of both the methods and the databases for improved performance. We
demonstrate that integrating a large number of predictions by the proposed
method improves the performance for this task. The predictors in the ensemble
differ in several aspects such as the method itself, the number of tasks method
considers (multi-task vs. single-task) and the subset of data considered
(sub-sampling). We show that all these different aspects contribute to the
success of the final ensemble. In addition, we attempt to use the drug screen
data together with two novel signatures produced from the drug-induced gene
expression profiles of cancer cell lines. Finally, we evaluate the method
predictions by in vitro experiments in addition to the tests on data sets.The
predictions of the methods, the signatures and the software are available from
&lt;a href=&quot;http://mtan.etu.edu.tr/drug-response-prediction/.&quot;&gt;this http URL&lt;/a&gt;
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Tan_M/0/1/0/all/0/1&quot;&gt;Mehmet Tan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Ozgul_O/0/1/0/all/0/1&quot;&gt;Ozan F&amp;#x131;rat &amp;#xd6;zg&amp;#xfc;l&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Bardak_B/0/1/0/all/0/1&quot;&gt;Batuhan Bardak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Eksioglu_I/0/1/0/all/0/1&quot;&gt;I&amp;#x15f;&amp;#x131;ksu Ek&amp;#x15f;io&amp;#x11f;lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Sabuncuoglu_S/0/1/0/all/0/1&quot;&gt;Suna Sabuncuo&amp;#x11f;lu&lt;/a&gt;</dc:creator>
</item></rdf:RDF>