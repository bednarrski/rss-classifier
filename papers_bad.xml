<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Boring papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Bad Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-03-20T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.07423"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.09825"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.07244"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.07246"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.07347"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.07438"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.07540"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1703.02660"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1705.09811"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.00344"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.03719"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.07102"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.07152"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.07200"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.07225"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.07247"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.07276"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.07300"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.07418"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.07554"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1612.05276"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1702.02715"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1703.06686"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1706.05374"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1707.04131"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.00483"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.04934"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.10337"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05046"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05193"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08318"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.05104"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.05776"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.06852"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1803.07423">
<title>A Distance Oriented Kalman Filter Particle Swarm Optimizer Applied to Multi-Modality Image Registration. (arXiv:1803.07423v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1803.07423</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper we describe improvements to the particle swarm optimizer (PSO)
made by inclusion of an unscented Kalman filter to guide particle motion. We
demonstrate the effectiveness of the unscented Kalman filter PSO by comparing
it with the original PSO algorithm and its variants designed to improve
performance. The PSOs were tested firstly on a number of common synthetic
benchmarking functions, and secondly applied to a practical three-dimensional
image registration problem. The proposed methods displayed better performances
for 4 out of 8 benchmark functions, and reduced the target registration errors
by at least 2mm when registering down-sampled benchmark brain images. Our
methods also demonstrated an ability to align images featuring motion related
artefacts which all other methods failed to register. These new PSO methods
provide a novel, efficient mechanism to integrate prior knowledge into each
iteration of the optimization process, which can enhance the accuracy and speed
of convergence in the application of medical image registration.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1&quot;&gt;Chengjia Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goatman_K/0/1/0/all/0/1&quot;&gt;Keith A. Goatman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Boardman_J/0/1/0/all/0/1&quot;&gt;James Boardman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Beveridge_E/0/1/0/all/0/1&quot;&gt;Erin Beveridge&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Newby_D/0/1/0/all/0/1&quot;&gt;David Newby&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Semple_S/0/1/0/all/0/1&quot;&gt;Scott Semple&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.09825">
<title>On the role of synaptic stochasticity in training low-precision neural networks. (arXiv:1710.09825v2 [cond-mat.dis-nn] UPDATED)</title>
<link>http://arxiv.org/abs/1710.09825</link>
<description rdf:parseType="Literal">&lt;p&gt;Stochasticity and limited precision of synaptic weights in neural network
models are key aspects of both biological and hardware modeling of learning
processes. Here we show that a neural network model with stochastic binary
weights naturally gives prominence to exponentially rare dense regions of
solutions with a number of desirable properties such as robustness and good
generalization performance, while typical solutions are isolated and hard to
find. Binary solutions of the standard perceptron problem are obtained from a
simple gradient descent procedure on a set of real values parametrizing a
probability distribution over the binary synapses. Both analytical and
numerical results are presented. An algorithmic extension aimed at training
discrete deep neural networks is also investigated.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Baldassi_C/0/1/0/all/0/1&quot;&gt;Carlo Baldassi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Gerace_F/0/1/0/all/0/1&quot;&gt;Federica Gerace&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Kappen_H/0/1/0/all/0/1&quot;&gt;Hilbert J. Kappen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Lucibello_C/0/1/0/all/0/1&quot;&gt;Carlo Lucibello&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Saglietti_L/0/1/0/all/0/1&quot;&gt;Luca Saglietti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Tartaglione_E/0/1/0/all/0/1&quot;&gt;Enzo Tartaglione&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Zecchina_R/0/1/0/all/0/1&quot;&gt;Riccardo Zecchina&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.07244">
<title>The Three Pillars of Machine-Based Programming. (arXiv:1803.07244v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1803.07244</link>
<description rdf:parseType="Literal">&lt;p&gt;In this position paper, we describe our vision of the future of machine-based
programming through a categorical examination of three pillars of research.
Those pillars are: (i) intention, (ii) invention, and(iii) adaptation.
Intention emphasizes advancements in the human-to-computer and
computer-to-machine-learning interfaces. Invention emphasizes the creation or
refinement of algorithms or core hardware and software building blocks through
machine learning (ML). Adaptation emphasizes advances in the use of ML-based
constructs to autonomously evolve software.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gottschlich_J/0/1/0/all/0/1&quot;&gt;Justin Gottschlich&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Solar_Lezama_A/0/1/0/all/0/1&quot;&gt;Armando Solar-Lezama&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tatbul_N/0/1/0/all/0/1&quot;&gt;Nesime Tatbul&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Carbin_M/0/1/0/all/0/1&quot;&gt;Michael Carbin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rinard_M/0/1/0/all/0/1&quot;&gt;Martin Rinard&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barzilay_R/0/1/0/all/0/1&quot;&gt;Regina Barzilay&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Amarasinghe_S/0/1/0/all/0/1&quot;&gt;Saman Amarasinghe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tenenbaum_J/0/1/0/all/0/1&quot;&gt;Joshua B Tenenbaum&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mattson_T/0/1/0/all/0/1&quot;&gt;Tim Mattson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.07246">
<title>Variance Reduction for Policy Gradient with Action-Dependent Factorized Baselines. (arXiv:1803.07246v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1803.07246</link>
<description rdf:parseType="Literal">&lt;p&gt;Policy gradient methods have enjoyed great success in deep reinforcement
learning but suffer from high variance of gradient estimates. The high variance
problem is particularly exasperated in problems with long horizons or
high-dimensional action spaces. To mitigate this issue, we derive a bias-free
action-dependent baseline for variance reduction which fully exploits the
structural form of the stochastic policy itself and does not make any
additional assumptions about the MDP. We demonstrate and quantify the benefit
of the action-dependent baseline through both theoretical analysis as well as
numerical results, including an analysis of the suboptimality of the optimal
state-dependent baseline. The result is a computationally efficient policy
gradient algorithm, which scales to high-dimensional control problems, as
demonstrated by a synthetic 2000-dimensional target matching task. Our
experimental results indicate that action-dependent baselines allow for faster
learning on standard reinforcement learning benchmarks and high-dimensional
hand manipulation and synthetic tasks. Finally, we show that the general idea
of including additional information in baselines for improved variance
reduction can be extended to partially observed and multi-agent tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1&quot;&gt;Cathy Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rajeswaran_A/0/1/0/all/0/1&quot;&gt;Aravind Rajeswaran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Duan_Y/0/1/0/all/0/1&quot;&gt;Yan Duan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kumar_V/0/1/0/all/0/1&quot;&gt;Vikash Kumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bayen_A/0/1/0/all/0/1&quot;&gt;Alexandre M Bayen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kakade_S/0/1/0/all/0/1&quot;&gt;Sham Kakade&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mordatch_I/0/1/0/all/0/1&quot;&gt;Igor Mordatch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1&quot;&gt;Pieter Abbeel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.07347">
<title>Optimizing Sponsored Search Ranking Strategy by Deep Reinforcement Learning. (arXiv:1803.07347v1 [cs.IR])</title>
<link>http://arxiv.org/abs/1803.07347</link>
<description rdf:parseType="Literal">&lt;p&gt;Sponsored search is an indispensable business model and a major revenue
contributor of almost all the search engines. From the advertisers&apos; side,
participating in ranking the search results by paying for the sponsored search
advertisement to attract more awareness and purchase facilitates their
commercial goal. From the users&apos; side, presenting personalized advertisement
reflecting their propensity would make their online search experience more
satisfactory. Sponsored search platforms rank the advertisements by a ranking
function to determine the list of advertisements to show and the charging price
for the advertisers. Hence, it is crucial to find a good ranking function which
can simultaneously satisfy the platform, the users and the advertisers.
Moreover, advertisements showing positions under different queries from
different users may associate with advertisement candidates of different bid
price distributions and click probability distributions, which requires the
ranking functions to be optimized adaptively to the traffic characteristics. In
this work, we proposed a generic framework to optimize the ranking functions by
deep reinforcement learning methods. The framework is composed of two parts: an
offline learning part which initializes the ranking functions by learning from
a simulated advertising environment, allowing adequate exploration of the
ranking function parameter space without hurting the performance of the
commercial platform. An online learning part which further optimizes the
ranking functions by adapting to the online data distribution. Experimental
results on a large-scale sponsored search platform confirm the effectiveness of
the proposed method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_L/0/1/0/all/0/1&quot;&gt;Li He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1&quot;&gt;Liang Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_K/0/1/0/all/0/1&quot;&gt;Kaipeng Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_B/0/1/0/all/0/1&quot;&gt;Bo Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1&quot;&gt;Weinan Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.07438">
<title>Ontology-Based Reasoning about the Trustworthiness of Cyber-Physical Systems. (arXiv:1803.07438v1 [cs.CR])</title>
<link>http://arxiv.org/abs/1803.07438</link>
<description rdf:parseType="Literal">&lt;p&gt;It has been challenging for the technical and regulatory communities to
formulate requirements for trustworthiness of the cyber-physical systems (CPS)
due to the complexity of the issues associated with their design, deployment,
and operations. The US National Institute of Standards and Technology (NIST),
through a public working group, has released a CPS Framework that adopts a
broad and integrated view of CPS and positions trustworthiness among other
aspects of CPS. This paper takes the model created by the CPS Framework and its
further developments one step further, by applying ontological approaches and
reasoning techniques in order to achieve greater understanding of CPS. The
example analyzed in the paper demonstrates the enrichment of the original CPS
model obtained through ontology and reasoning and its ability to deliver
additional insights to the developers and operators of CPS.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Balduccini_M/0/1/0/all/0/1&quot;&gt;Marcello Balduccini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Griffor_E/0/1/0/all/0/1&quot;&gt;Edward Griffor&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huth_M/0/1/0/all/0/1&quot;&gt;Michael Huth&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vishik_C/0/1/0/all/0/1&quot;&gt;Claire Vishik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Burns_M/0/1/0/all/0/1&quot;&gt;Martin Burns&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wollman_D/0/1/0/all/0/1&quot;&gt;David Wollman&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.07540">
<title>Enslaving the Algorithm: From a &quot;Right to an Explanation&quot; to a &quot;Right to Better Decisions&quot;?. (arXiv:1803.07540v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1803.07540</link>
<description rdf:parseType="Literal">&lt;p&gt;As concerns about unfairness and discrimination in &quot;black box&quot; machine
learning systems rise, a legal &quot;right to an explanation&quot; has emerged as a
compellingly attractive approach for challenge and redress. We outline recent
debates on the limited provisions in European data protection law, and
introduce and analyze newer explanation rights in French administrative law and
the draft modernized Council of Europe Convention 108. While individual rights
can be useful, in privacy law they have historically unreasonably burdened the
average data subject. &quot;Meaningful information&quot; about algorithmic logics is more
technically possible than commonly thought, but this exacerbates a new
&quot;transparency fallacy&quot;---an illusion of remedy rather than anything
substantively helpful. While rights-based approaches deserve a firm place in
the toolbox, other forms of governance, such as impact assessments, &quot;soft law,&quot;
judicial review, and model repositories deserve more attention, alongside
catalyzing agencies acting for users to control algorithmic system design.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Edwards_L/0/1/0/all/0/1&quot;&gt;Lilian Edwards&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Veale_M/0/1/0/all/0/1&quot;&gt;Michael Veale&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1703.02660">
<title>Towards Generalization and Simplicity in Continuous Control. (arXiv:1703.02660v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1703.02660</link>
<description rdf:parseType="Literal">&lt;p&gt;This work shows that policies with simple linear and RBF parameterizations
can be trained to solve a variety of continuous control tasks, including the
OpenAI gym benchmarks. The performance of these trained policies are
competitive with state of the art results, obtained with more elaborate
parameterizations such as fully connected neural networks. Furthermore,
existing training and testing scenarios are shown to be very limited and prone
to over-fitting, thus giving rise to only trajectory-centric policies. Training
with a diverse initial state distribution is shown to produce more global
policies with better generalization. This allows for interactive control
scenarios where the system recovers from large on-line perturbations; as shown
in the supplementary video.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rajeswaran_A/0/1/0/all/0/1&quot;&gt;Aravind Rajeswaran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lowrey_K/0/1/0/all/0/1&quot;&gt;Kendall Lowrey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Todorov_E/0/1/0/all/0/1&quot;&gt;Emanuel Todorov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kakade_S/0/1/0/all/0/1&quot;&gt;Sham Kakade&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1705.09811">
<title>Multi-shot ASP solving with clingo. (arXiv:1705.09811v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1705.09811</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce a new flexible paradigm of grounding and solving in Answer Set
Programming (ASP), which we refer to as multi-shot ASP solving, and present its
implementation in the ASP system clingo.
&lt;/p&gt;
&lt;p&gt;Multi-shot ASP solving features grounding and solving processes that deal
with continuously changing logic programs. In doing so, they remain operative
and accommodate changes in a seamless way. For instance, such processes allow
for advanced forms of search, as in optimization or theory solving, or
interaction with an environment, as in robotics or query-answering. Common to
them is that the problem specification evolves during the reasoning process,
either because data or constraints are added, deleted, or replaced. This
evolutionary aspect adds another dimension to ASP since it brings about state
changing operations. We address this issue by providing an operational
semantics that characterizes grounding and solving processes in multi-shot ASP
solving. This characterization provides a semantic account of grounder and
solver states along with the operations manipulating them.
&lt;/p&gt;
&lt;p&gt;The operative nature of multi-shot solving avoids redundancies in relaunching
grounder and solver programs and benefits from the solver&apos;s learning
capacities. clingo accomplishes this by complementing ASP&apos;s declarative input
language with control capacities. On the declarative side, a new directive
allows for structuring logic programs into named and parameterizable
subprograms. The grounding and integration of these subprograms into the
solving process is completely modular and fully controllable from the
procedural side. To this end, clingo offers a new application programming
interface that is conveniently accessible via scripting languages.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gebser_M/0/1/0/all/0/1&quot;&gt;Martin Gebser&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kaminski_R/0/1/0/all/0/1&quot;&gt;Roland Kaminski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kaufmann_B/0/1/0/all/0/1&quot;&gt;Benjamin Kaufmann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schaub_T/0/1/0/all/0/1&quot;&gt;Torsten Schaub&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.00344">
<title>A Deep Learning Approach for Multimodal Deception Detection. (arXiv:1803.00344v1 [cs.CL] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1803.00344</link>
<description rdf:parseType="Literal">&lt;p&gt;Automatic deception detection is an important task that has gained momentum
in computational linguistics due to its potential applications. In this paper,
we propose a simple yet tough to beat multi-modal neural model for deception
detection. By combining features from different modalities such as video,
audio, and text along with Micro-Expression features, we show that detecting
deception in real life videos can be more accurate. Experimental results on a
dataset of real-life deception videos show that our model outperforms existing
techniques for deception detection with an accuracy of 96.14% and ROC-AUC of
0.9799.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Krishnamurthy_G/0/1/0/all/0/1&quot;&gt;Gangeshwar Krishnamurthy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Majumder_N/0/1/0/all/0/1&quot;&gt;Navonil Majumder&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Poria_S/0/1/0/all/0/1&quot;&gt;Soujanya Poria&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cambria_E/0/1/0/all/0/1&quot;&gt;Erik Cambria&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.03719">
<title>DeepMoTIon: Learning to Navigate Like Humans. (arXiv:1803.03719v1 [cs.RO] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1803.03719</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a novel human-aware navigation approach, where the robot learns to
mimic humans to navigate safely in crowds. The presented model referred to as
DeepMoTIon, is trained with pedestrian surveillance data to predict human
velocity. The robot processes LiDAR scans via the trained network to navigate
to the target location. We conduct extensive experiments to assess the
different components of our network and prove the necessity of each to imitate
humans. Our experiments show that DeepMoTIon outperforms state-of-the-art in
terms of human imitation and reaches the target on 100% of the test cases
without breaching humans&apos; safe distance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hamandi_M/0/1/0/all/0/1&quot;&gt;Mahmoud Hamandi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+DArcy_M/0/1/0/all/0/1&quot;&gt;Mike D&amp;#x27;Arcy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fazli_P/0/1/0/all/0/1&quot;&gt;Pooyan Fazli&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.07102">
<title>Learning non-Gaussian Time Series using the Box-Cox Gaussian Process. (arXiv:1803.07102v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1803.07102</link>
<description rdf:parseType="Literal">&lt;p&gt;Gaussian processes (GPs) are Bayesian nonparametric generative models that
provide interpretability of hyperparameters, admit closed-form expressions for
training and inference, and are able to accurately represent uncertainty. To
model general non-Gaussian data with complex correlation structure, GPs can be
paired with an expressive covariance kernel and then fed into a nonlinear
transformation (or warping). However, overparametrising the kernel and the
warping is known to, respectively, hinder gradient-based training and make the
predictions computationally expensive. We remedy this issue by (i) training the
model using derivative-free global-optimisation techniques so as to find
meaningful maxima of the model likelihood, and (ii) proposing a warping
function based on the celebrated Box-Cox transformation that requires minimal
numerical approximations---unlike existing warped GP models. We validate the
proposed approach by first showing that predictions can be computed
analytically, and then on a learning, reconstruction and forecasting experiment
using real-world datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rios_G/0/1/0/all/0/1&quot;&gt;Gonzalo Rios&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tobar_F/0/1/0/all/0/1&quot;&gt;Felipe Tobar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.07152">
<title>Exploring the predictability of range-based volatility estimators using RNNs. (arXiv:1803.07152v1 [q-fin.CP])</title>
<link>http://arxiv.org/abs/1803.07152</link>
<description rdf:parseType="Literal">&lt;p&gt;We investigate the predictability of several range-based stock volatility
estimators, and compare them to the standard close-to-close estimator which is
most commonly acknowledged as the volatility. The patterns of volatility
changes are analyzed using LSTM recurrent neural networks, which are a state of
the art method of sequence learning. We implement the analysis on all current
constituents of the Dow Jones Industrial Average index, and report averaged
evaluation results. We find that changes in the values of range-based
estimators are more predictable than that of the estimator using daily closing
values only.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-fin/1/au:+Petnehazi_G/0/1/0/all/0/1&quot;&gt;G&amp;#xe1;bor Petneh&amp;#xe1;zi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-fin/1/au:+Gall_J/0/1/0/all/0/1&quot;&gt;J&amp;#xf3;zsef G&amp;#xe1;ll&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.07200">
<title>Training Recurrent Neural Networks as a Constraint Satisfaction Problem. (arXiv:1803.07200v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1803.07200</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents a new approach for training artificial neural networks
using techniques for solving the constraint satisfaction problem (CSP). The
quotient gradient system (QGS) is a trajectory based method for solving the
CSP. This study converts the training set of a neural network into a CSP and
uses the QGS to find its solutions. The QGS finds the global minimum of the
optimization problem by tracking trajectories of a nonlinear dynamical system
and does not stop at a local minimum of the optimization problem. Lyapunov
theory is used to prove the asymptotic stability of the solutions with and
without the presence of measurement errors. Numerical examples illustrate the
effectiveness of the proposed methodology and compare it to a genetic algorithm
and error backpropagation
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khodabandehlou_H/0/1/0/all/0/1&quot;&gt;Hamid Khodabandehlou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fadali_M/0/1/0/all/0/1&quot;&gt;Mohammad Sami Fadali&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.07225">
<title>Monte Carlo Information Geometry: The dually flat case. (arXiv:1803.07225v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1803.07225</link>
<description rdf:parseType="Literal">&lt;p&gt;Exponential families and mixture families are parametric probability models
that can be geometrically studied as smooth statistical manifolds with respect
to any statistical divergence like the Kullback-Leibler (KL) divergence or the
Hellinger divergence. When equipping a statistical manifold with the KL
divergence, the induced manifold structure is dually flat, and the KL
divergence between distributions amounts to an equivalent Bregman divergence on
their corresponding parameters. In practice, the corresponding Bregman
generators of mixture/exponential families require to perform definite integral
calculus that can either be too time-consuming (for exponentially large
discrete support case) or even do not admit closed-form formula (for continuous
support case). In these cases, the dually flat construction remains theoretical
and cannot be used by information-geometric algorithms. To bypass this problem,
we consider performing stochastic Monte Carlo (MC) estimation of those
integral-based mixture/exponential family Bregman generators. We show that,
under natural assumptions, these MC generators are almost surely Bregman
generators. We define a series of dually flat information geometries, termed
Monte Carlo Information Geometries, that increasingly-finely approximate the
untractable geometry. The advantage of this MCIG is that it allows a practical
use of the Bregman algorithmic toolbox on a wide range of probability
distribution families. We demonstrate our approach with a clustering task on a
mixture family manifold.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nielsen_F/0/1/0/all/0/1&quot;&gt;Frank Nielsen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hadjeres_G/0/1/0/all/0/1&quot;&gt;Ga&amp;#xeb;tan Hadjeres&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.07247">
<title>Sparse Reduced Rank Regression With Nonconvex Regularization. (arXiv:1803.07247v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1803.07247</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, the estimation problem for sparse reduced rank regression
(SRRR) model is considered. The SRRR model is widely used for dimension
reduction and variable selection with applications in signal processing,
econometrics, etc. The problem is formulated to minimize the least squares loss
with a sparsity-inducing penalty considering an orthogonality constraint.
Convex sparsity-inducing functions have been used for SRRR in literature. In
this work, a nonconvex function is proposed for better sparsity inducing. An
efficient algorithm is developed based on the alternating minimization (or
projection) method to solve the nonconvex optimization problem. Numerical
simulations show that the proposed algorithm is much more efficient compared to
the benchmark methods and the nonconvex function can result in a better
estimation accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhao_Z/0/1/0/all/0/1&quot;&gt;Ziping Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Palomar_D/0/1/0/all/0/1&quot;&gt;Daniel P. Palomar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.07276">
<title>Fair Deep Learning Prediction for Healthcare Applications with Confounder Filtering. (arXiv:1803.07276v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1803.07276</link>
<description rdf:parseType="Literal">&lt;p&gt;The rapid development of deep learning methods has permitted the fast and
accurate medical decision making from complex structured data, like CT images
or MRI. However, some problems still exist in such applications that may lead
to imperfect predictions. Previous observations have shown that, confounding
factors, if handled inappropriately, will lead to biased prediction results
towards some major properties of the data distribution. In other words, naively
applying deep learning methods in these applications will lead to unfair
prediction results for the minority group defined by the characteristics
including age, gender, or even the hospital that collects the data, etc. In
this paper, extending previous successes in correcting confounders, we propose
a more stable method, namely Confounder Filtering, that can effectively reduce
the influence of confounding factors, leading to better generalizability of
trained discriminative deep neural networks, therefore, fairer prediction
results. Our experimental results indicate that the Confounder Filtering method
is able to improve the performance for different neural networks including CNN,
LSTM, and other arbitrary architecture, different data types including CT-scan,
MRI, and EEG brain wave data, as well as different confounding factors
including age, gender, and physical factors of medical devices etc
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wu_Z/0/1/0/all/0/1&quot;&gt;Zhenglin Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wang_H/0/1/0/all/0/1&quot;&gt;Haohan Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Cao_M/0/1/0/all/0/1&quot;&gt;Mingze Cao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yin Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Xing_E/0/1/0/all/0/1&quot;&gt;Eric P. Xing&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.07300">
<title>Risk and parameter convergence of logistic regression. (arXiv:1803.07300v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1803.07300</link>
<description rdf:parseType="Literal">&lt;p&gt;The logistic loss is strictly convex and does not attain its infimum;
consequently the solutions of logistic regression are in general off at
infinity. This work provides a convergence analysis of gradient descent applied
to logistic regression under no assumptions on the problem instance. Firstly,
the risk is shown to converge at a rate $\mathcal{O}(\ln(t)^2/t)$. Secondly,
the parameter convergence is characterized along a unique pair of complementary
subspaces defined by the problem instance: one subspace along which strong
convexity induces parameters to converge at rate
$\mathcal{O}(\ln(t)^2/\sqrt{t})$, and its orthogonal complement along which
separability induces parameters to converge in direction at rate
$\mathcal{O}(\ln\ln(t) / \ln(t))$.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ji_Z/0/1/0/all/0/1&quot;&gt;Ziwei Ji&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Telgarsky_M/0/1/0/all/0/1&quot;&gt;Matus Telgarsky&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.07418">
<title>Large-Scale Model Selection with Misspecification. (arXiv:1803.07418v1 [stat.ME])</title>
<link>http://arxiv.org/abs/1803.07418</link>
<description rdf:parseType="Literal">&lt;p&gt;Model selection is crucial to high-dimensional learning and inference for
contemporary big data applications in pinpointing the best set of covariates
among a sequence of candidate interpretable models. Most existing work assumes
implicitly that the models are correctly specified or have fixed
dimensionality. Yet both features of model misspecification and high
dimensionality are prevalent in practice. In this paper, we exploit the
framework of model selection principles in misspecified models originated in Lv
and Liu (2014) and investigate the asymptotic expansion of Bayesian principle
of model selection in the setting of high-dimensional misspecified models. With
a natural choice of prior probabilities that encourages interpretability and
incorporates Kullback-Leibler divergence, we suggest the high-dimensional
generalized Bayesian information criterion with prior probability (HGBIC_p) for
large-scale model selection with misspecification. Our new information
criterion characterizes the impacts of both model misspecification and high
dimensionality on model selection. We further establish the consistency of
covariance contrast matrix estimation and the model selection consistency of
HGBIC_p in ultra-high dimensions under some mild regularity conditions. The
advantages of our new method are supported by numerical studies.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Demirkaya_E/0/1/0/all/0/1&quot;&gt;Emre Demirkaya&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Feng_Y/0/1/0/all/0/1&quot;&gt;Yang Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Basu_P/0/1/0/all/0/1&quot;&gt;Pallavi Basu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lv_J/0/1/0/all/0/1&quot;&gt;Jinchi Lv&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.07554">
<title>The Leave-one-out Approach for Matrix Completion: Primal and Dual Analysis. (arXiv:1803.07554v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1803.07554</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we introduce a powerful technique, Leave-One-Out, to the
analysis of low-rank matrix completion problems. Using this technique, we
develop a general approach for obtaining fine-grained, entry-wise bounds on
iterative stochastic procedures. We demonstrate the power of this approach in
analyzing two of the most important algorithms for matrix completion: the
non-convex approach based on Singular Value Projection (SVP), and the convex
relaxation approach based on nuclear norm minimization (NNM). In particular, we
prove for the first time that the original form of SVP, without re-sampling or
sample splitting, converges linearly in the infinity norm. We further apply our
leave-one-out approach to an iterative procedure that arises in the analysis of
the dual solutions of NNM. Our results show that NNM recovers the true $ d
$-by-$ d $ rank-$ r $ matrix with $\mathcal{O}(\mu^2 r^3d \log d )$ observed
entries, which has optimal dependence on the dimension and is independent of
the condition number of the matrix. To the best of our knowledge, this is the
first sample complexity result for a tractable matrix completion algorithm that
satisfies these two properties simultaneously.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ding_L/0/1/0/all/0/1&quot;&gt;Lijun Ding&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yudong Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1612.05276">
<title>Learning Optimal Control of Synchronization in Networks of Coupled Oscillators using Genetic Programming-based Symbolic Regression. (arXiv:1612.05276v2 [nlin.AO] UPDATED)</title>
<link>http://arxiv.org/abs/1612.05276</link>
<description rdf:parseType="Literal">&lt;p&gt;Networks of coupled dynamical systems provide a powerful way to model systems
with enormously complex dynamics, such as the human brain. Control of
synchronization in such networked systems has far reaching applications in many
domains, including engineering and medicine. In this paper, we formulate the
synchronization control in dynamical systems as an optimization problem and
present a multi-objective genetic programming-based approach to infer optimal
control functions that drive the system from a synchronized to a
non-synchronized state and vice-versa. The genetic programming-based controller
allows learning optimal control functions in an interpretable symbolic form.
The effectiveness of the proposed approach is demonstrated in controlling
synchronization in coupled oscillator systems linked in networks of increasing
order complexity, ranging from a simple coupled oscillator system to a
hierarchical network of coupled oscillators. The results show that the proposed
method can learn highly-effective and interpretable control functions for such
systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/nlin/1/au:+Gout_J/0/1/0/all/0/1&quot;&gt;Julien Gout&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/nlin/1/au:+Quade_M/0/1/0/all/0/1&quot;&gt;Markus Quade&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/nlin/1/au:+Shafi_K/0/1/0/all/0/1&quot;&gt;Kamran Shafi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/nlin/1/au:+Niven_R/0/1/0/all/0/1&quot;&gt;Robert K. Niven&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/nlin/1/au:+Abel_M/0/1/0/all/0/1&quot;&gt;Markus Abel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1702.02715">
<title>A Fast and Scalable Joint Estimator for Learning Multiple Related Sparse Gaussian Graphical Models. (arXiv:1702.02715v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1702.02715</link>
<description rdf:parseType="Literal">&lt;p&gt;Estimating multiple sparse Gaussian Graphical Models (sGGMs) jointly for many
related tasks (large $K$) under a high-dimensional (large $p$) situation is an
important task. Most previous studies for the joint estimation of multiple
sGGMs rely on penalized log-likelihood estimators that involve expensive and
difficult non-smooth optimizations. We propose a novel approach, FASJEM for
\underline{fa}st and \underline{s}calable \underline{j}oint
structure-\underline{e}stimation of \underline{m}ultiple sGGMs at a large
scale. As the first study of joint sGGM using the Elementary Estimator
framework, our work has three major contributions: (1) We solve FASJEM through
an entry-wise manner which is parallelizable. (2) We choose a proximal
algorithm to optimize FASJEM. This improves the computational efficiency from
$O(Kp^3)$ to $O(Kp^2)$ and reduces the memory requirement from $O(Kp^2)$ to
$O(K)$. (3) We theoretically prove that FASJEM achieves a consistent estimation
with a convergence rate of $O(\log(Kp)/n_{tot})$. On several synthetic and four
real-world datasets, FASJEM shows significant improvements over baselines on
accuracy, computational complexity, and memory costs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wang_B/0/1/0/all/0/1&quot;&gt;Beilun Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gao_J/0/1/0/all/0/1&quot;&gt;Ji Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Qi_Y/0/1/0/all/0/1&quot;&gt;Yanjun Qi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1703.06686">
<title>Copula Index for Detecting Dependence and Monotonicity between Stochastic Signals. (arXiv:1703.06686v4 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1703.06686</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper introduces a nonparametric copula-based index for detecting the
strength and monotonicity structure of linear and nonlinear statistical
dependence between pairs of random variables or stochastic signals. Our index,
termed Copula Index for Detecting Dependence and Monotonicity (CIM), satisfies
several desirable properties of measures of association, including R\&apos;enyi&apos;s
properties, the data processing inequality (DPI), and consequently
self-equitability. Synthetic data simulations reveal that the statistical power
of CIM compares favorably to other state-of-the-art measures of association
that are proven to satisfy the DPI. Simulation results with real-world data
reveal the CIM&apos;s unique ability to detect the monotonicity structure among
stochastic signals to find interesting dependencies in large datasets.
Additionally, simulations show that the CIM shows favorable performance to
estimators of mutual information when discovering Markov network structure.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Karra_K/0/1/0/all/0/1&quot;&gt;Kiran Karra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mili_L/0/1/0/all/0/1&quot;&gt;Lamine Mili&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1706.05374">
<title>Expected Policy Gradients. (arXiv:1706.05374v5 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1706.05374</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose expected policy gradients (EPG), which unify stochastic policy
gradients (SPG) and deterministic policy gradients (DPG) for reinforcement
learning. Inspired by expected sarsa, EPG integrates across the action when
estimating the gradient, instead of relying only on the action in the sampled
trajectory. We establish a new general policy gradient theorem, of which the
stochastic and deterministic policy gradient theorems are special cases. We
also prove that EPG reduces the variance of the gradient estimates without
requiring deterministic policies and, for the Gaussian case, with no
computational overhead. Finally, we show that it is optimal in a certain sense
to explore with a Gaussian policy such that the covariance is proportional to
the exponential of the scaled Hessian of the critic with respect to the
actions. We present empirical results confirming that this new form of
exploration substantially outperforms DPG with the Ornstein-Uhlenbeck heuristic
in four challenging MuJoCo domains.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ciosek_K/0/1/0/all/0/1&quot;&gt;Kamil Ciosek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Whiteson_S/0/1/0/all/0/1&quot;&gt;Shimon Whiteson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1707.04131">
<title>Foolbox: A Python toolbox to benchmark the robustness of machine learning models. (arXiv:1707.04131v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1707.04131</link>
<description rdf:parseType="Literal">&lt;p&gt;Even todays most advanced machine learning models are easily fooled by almost
imperceptible perturbations of their inputs. Foolbox is a new Python package to
generate such adversarial perturbations and to quantify and compare the
robustness of machine learning models. It is build around the idea that the
most comparable robustness measure is the minimum perturbation needed to craft
an adversarial example. To this end, Foolbox provides reference implementations
of most published adversarial attack methods alongside some new ones, all of
which perform internal hyperparameter tuning to find the minimum adversarial
perturbation. Additionally, Foolbox interfaces with most popular deep learning
frameworks such as PyTorch, Keras, TensorFlow, Theano and MXNet and allows
different adversarial criteria such as targeted misclassification and top-k
misclassification as well as different distance measures. The code is licensed
under the MIT license and is openly available at
https://github.com/bethgelab/foolbox . The most up-to-date documentation can be
found at &lt;a href=&quot;http://foolbox.readthedocs.io&quot;&gt;this http URL&lt;/a&gt; .
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rauber_J/0/1/0/all/0/1&quot;&gt;Jonas Rauber&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brendel_W/0/1/0/all/0/1&quot;&gt;Wieland Brendel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bethge_M/0/1/0/all/0/1&quot;&gt;Matthias Bethge&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.00483">
<title>Iteratively Linearized Reweighted Alternating Direction Method of Multipliers for a Class of Nonconvex Problems. (arXiv:1709.00483v4 [cs.NA] UPDATED)</title>
<link>http://arxiv.org/abs/1709.00483</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we consider solving a class of nonconvex and nonsmooth
problems frequently appearing in signal processing and machine learning
research. The traditional alternating direction method of multipliers
encounters troubles in both mathematics and computations in solving the
nonconvex and nonsmooth subproblem. In view of this, we propose a reweighted
alternating direction method of multipliers. In this algorithm, all subproblems
are convex and easy to solve. We also provide several guarantees for the
convergence and prove that the algorithm globally converges to a critical point
of an auxiliary function with the help of the Kurdyka-{\L}ojasiewicz property.
Several numerical results are presented to demonstrate the efficiency of the
proposed algorithm.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_T/0/1/0/all/0/1&quot;&gt;Tao Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1&quot;&gt;Hao Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_L/0/1/0/all/0/1&quot;&gt;Lizhi Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_W/0/1/0/all/0/1&quot;&gt;Wei Zhu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.04934">
<title>Statistically Optimal and Computationally Efficient Low Rank Tensor Completion from Noisy Entries. (arXiv:1711.04934v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1711.04934</link>
<description rdf:parseType="Literal">&lt;p&gt;In this article, we develop methods for estimating a low rank tensor from
noisy observations on a subset of its entries to achieve both statistical and
computational efficiencies. There have been a lot of recent interests in this
problem of noisy tensor completion. Much of the attention has been focused on
the fundamental computational challenges often associated with problems
involving higher order tensors, yet very little is known about their
statistical performance. To fill in this void, in this article, we characterize
the fundamental statistical limits of noisy tensor completion by establishing
minimax optimal rates of convergence for estimating a $k$th order low rank
tensor under the general $\ell_p$ ($1\le p\le 2$) norm which suggest
significant room for improvement over the existing approaches. Furthermore, we
propose a polynomial-time computable estimating procedure based upon power
iteration and a second-order spectral initialization that achieves the optimal
rates of convergence. Our method is fairly easy to implement and numerical
experiments are presented to further demonstrate the practical merits of our
estimator.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Xia_D/0/1/0/all/0/1&quot;&gt;Dong Xia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yuan_M/0/1/0/all/0/1&quot;&gt;Ming Yuan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhang_C/0/1/0/all/0/1&quot;&gt;Cun-Hui Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.10337">
<title>Are GANs Created Equal? A Large-Scale Study. (arXiv:1711.10337v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1711.10337</link>
<description rdf:parseType="Literal">&lt;p&gt;Generative adversarial networks (GAN) are a powerful subclass of generative
models. Despite a very rich research activity leading to numerous interesting
GAN algorithms, it is still very hard to assess which algorithm(s) perform
better than others. We conduct a neutral, multi-faceted large-scale empirical
study on state-of-the art models and evaluation measures. We find that most
models can reach similar scores with enough hyperparameter optimization and
random restarts. This suggests that improvements can arise from a higher
computational budget and tuning more than fundamental algorithmic changes. To
overcome some limitations of the current metrics, we also propose several data
sets on which precision and recall can be computed. Our experimental results
suggest that future GAN research should be based on more systematic and
objective evaluation procedures. Finally, we did not find evidence that any of
the tested algorithms consistently outperforms the original one.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lucic_M/0/1/0/all/0/1&quot;&gt;Mario Lucic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kurach_K/0/1/0/all/0/1&quot;&gt;Karol Kurach&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Michalski_M/0/1/0/all/0/1&quot;&gt;Marcin Michalski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gelly_S/0/1/0/all/0/1&quot;&gt;Sylvain Gelly&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bousquet_O/0/1/0/all/0/1&quot;&gt;Olivier Bousquet&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05046">
<title>Benchmarking Framework for Performance-Evaluation of Causal Inference Analysis. (arXiv:1802.05046v2 [stat.ME] UPDATED)</title>
<link>http://arxiv.org/abs/1802.05046</link>
<description rdf:parseType="Literal">&lt;p&gt;Causal inference analysis is the estimation of the effects of actions on
outcomes. In the context of healthcare data this means estimating the outcome
of counter-factual treatments (i.e. including treatments that were not
observed) on a patient&apos;s outcome. Compared to classic machine learning methods,
evaluation and validation of causal inference analysis is more challenging
because ground truth data of counter-factual outcome can never be obtained in
any real-world scenario. Here, we present a comprehensive framework for
benchmarking algorithms that estimate causal effect. The framework includes
unlabeled data for prediction, labeled data for validation, and code for
automatic evaluation of algorithm predictions using both established and novel
metrics. The data is based on real-world covariates, and the treatment
assignments and outcomes are based on simulations, which provides the basis for
validation. In this framework we address two questions: one of scaling, and the
other of data-censoring. The framework is available as open source code at
https://github.com/IBM-HRL-MLHLS/IBM-Causal-Inference-Benchmarking-Framework
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Shimoni_Y/0/1/0/all/0/1&quot;&gt;Yishai Shimoni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yanover_C/0/1/0/all/0/1&quot;&gt;Chen Yanover&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Karavani_E/0/1/0/all/0/1&quot;&gt;Ehud Karavani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Goldschmnidt_Y/0/1/0/all/0/1&quot;&gt;Yaara Goldschmnidt&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05193">
<title>Security Analysis and Enhancement of Model Compressed Deep Learning Systems under Adversarial Attacks. (arXiv:1802.05193v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1802.05193</link>
<description rdf:parseType="Literal">&lt;p&gt;DNN is presenting human-level performance for many complex intelligent tasks
in real-world applications. However, it also introduces ever-increasing
security concerns. For example, the emerging adversarial attacks indicate that
even very small and often imperceptible adversarial input perturbations can
easily mislead the cognitive function of deep learning systems (DLS). Existing
DNN adversarial studies are narrowly performed on the ideal software-level DNN
models with a focus on single uncertainty factor, i.e. input perturbations,
however, the impact of DNN model reshaping on adversarial attacks, which is
introduced by various hardware-favorable techniques such as hash-based weight
compression during modern DNN hardware implementation, has never been
discussed. In this work, we for the first time investigate the multi-factor
adversarial attack problem in practical model optimized deep learning systems
by jointly considering the DNN model-reshaping (e.g. HashNet based deep
compression) and the input perturbations. We first augment adversarial example
generating method dedicated to the compressed DNN models by incorporating the
software-based approaches and mathematical modeled DNN reshaping. We then
conduct a comprehensive robustness and vulnerability analysis of deep
compressed DNN models under derived adversarial attacks. A defense technique
named &quot;gradient inhibition&quot; is further developed to ease the generating of
adversarial examples thus to effectively mitigate adversarial attacks towards
both software and hardware-oriented DNNs. Simulation results show that
&quot;gradient inhibition&quot; can decrease the average success rate of adversarial
attacks from 87.99% to 4.77% (from 86.74% to 4.64%) on MNIST (CIFAR-10)
benchmark with marginal accuracy degradation across various DNNs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1&quot;&gt;Qi Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1&quot;&gt;Tao Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1&quot;&gt;Zihao Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yanzhi Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jin_Y/0/1/0/all/0/1&quot;&gt;Yier Jin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wen_W/0/1/0/all/0/1&quot;&gt;Wujie Wen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08318">
<title>Proportional Volume Sampling and Approximation Algorithms for A-Optimal Design. (arXiv:1802.08318v2 [cs.DS] UPDATED)</title>
<link>http://arxiv.org/abs/1802.08318</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the $A$-optimal design problem where we are given vectors
$v_1,\ldots,v_n\in\mathbb{R}^d$, an integer $k\geq d$, and the goal is to
select a set $S$ of $k$ vectors that minimizes the trace of $(\sum_{i\in
S}v_iv_i^\top)^{-1}$. Traditionally, the problem is an instance of optimal
design of experiments in statistics where each vector corresponds to a linear
measurement of an unknown vector and the goal is to pick $k$ of them that
minimize the average variance of the error in the maximum likelihood estimate
of the vector being measured. The problem also finds applications in sensor
placement in wireless networks, sparse least squares regression, feature
selection for $k$-means clustering, and matrix approximation. In this paper, we
introduce proportional volume sampling to obtain improved approximation
algorithms for $A$-optimal design.
&lt;/p&gt;
&lt;p&gt;Given a matrix, proportional volume sampling picks a set of columns $S$ of
size $k$ with probability proportional to $\mu(S)$ times $\det(\sum_{i\in
S}v_iv_i^\top)$ for some measure $\mu$. Our main result is to show the
approximability of the $A$-optimal design problem can be reduced to approximate
independence properties of the measure $\mu$. We appeal to hard-core
distributions as candidate distributions $\mu$ that allow us to obtain improved
approximation algorithms for the $A$-optimal design. Our results include a
$d$-approximation when $k=d$, an $(1+\epsilon)$-approximation when
$k=\Omega\left(\frac{d}{\epsilon}+\frac{1}{\epsilon^2}\log\frac{1}{\epsilon}\right)$
and $\frac{k}{k-d+1}$-approximation when repetitions of vectors are allowed in
the solution. We consider generalization of the problem for $k\leq d$ and
obtain a $k$-approximation. The last result implies a restricted invertibility
principle for the harmonic mean of singular values. We also show that the
problem is $\mathsf{NP}$-hard to approximate within a fixed constant when
$k=d$.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nikolov_A/0/1/0/all/0/1&quot;&gt;Aleksandar Nikolov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singh_M/0/1/0/all/0/1&quot;&gt;Mohit Singh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tantipongpipat_U/0/1/0/all/0/1&quot;&gt;Uthaipon Tao Tantipongpipat&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.05104">
<title>Bucket Renormalization for Approximate Inference. (arXiv:1803.05104v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1803.05104</link>
<description rdf:parseType="Literal">&lt;p&gt;Probabilistic graphical models are a key tool in machine learning
applications. Computing the partition function, i.e., normalizing constant, is
a fundamental task of statistical inference but it is generally computationally
intractable, leading to extensive study of approximation methods. Iterative
variational methods are a popular and successful family of approaches. However,
even state of the art variational methods can return poor results or fail to
converge on difficult instances. In this paper, we instead consider computing
the partition function via sequential summation over variables. We develop
robust approximate algorithms by combining ideas from mini-bucket elimination
with tensor network and renormalization group methods from statistical physics.
The resulting &quot;convergence-free&quot; methods show good empirical performance on
both synthetic and real-world benchmark models, even for difficult instances.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ahn_S/0/1/0/all/0/1&quot;&gt;Sungsoo Ahn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chertkov_M/0/1/0/all/0/1&quot;&gt;Michael Chertkov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Weller_A/0/1/0/all/0/1&quot;&gt;Adrian Weller&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Shin_J/0/1/0/all/0/1&quot;&gt;Jinwoo Shin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.05776">
<title>Gaussian Processes Over Graphs. (arXiv:1803.05776v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1803.05776</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose Gaussian processes for signals over graphs (GPG) using the apriori
knowledge that the target vectors lie over a graph. We incorporate this
information using a graph- Laplacian based regularization which enforces the
target vectors to have a specific profile in terms of graph Fourier transform
coeffcients, for example lowpass or bandpass graph signals. We discuss how the
regularization affects the mean and the variance in the prediction output. In
particular, we prove that the predictive variance of the GPG is strictly
smaller than the conventional Gaussian process (GP) for any non-trivial graph.
We validate our concepts by application to various real-world graph signals.
Our experiments show that the performance of the GPG is superior to GP for
small training data sizes and under noisy training.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Venkitaraman_A/0/1/0/all/0/1&quot;&gt;Arun Venkitaraman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chatterjee_S/0/1/0/all/0/1&quot;&gt;Saikat Chatterjee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Handel_P/0/1/0/all/0/1&quot;&gt;Peter H&amp;#xe4;ndel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.06852">
<title>Confounder Detection in High Dimensional Linear Models using First Moments of Spectral Measures. (arXiv:1803.06852v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1803.06852</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we study the confounder detection problem in the linear model,
where the target variable $Y$ is predicted using its $n$ potential causes
$X_n=(x_1,...,x_n)^T$. Based on an assumption of rotation invariant generating
process of the model, recent study shows that the spectral measure induced by
the regression coefficient vector with respect to the covariance matrix of
$X_n$ is close to a uniform measure in purely causal cases, but it differs from
a uniform measure characteristically in the presence of a scalar confounder.
Then, analyzing spectral measure pattern could help to detect confounding. In
this paper, we propose to use the first moment of the spectral measure for
confounder detection. We calculate the first moment of the regression vector
induced spectral measure, and compare it with the first moment of a uniform
spectral measure, both defined with respect to the covariance matrix of $X_n$.
The two moments coincide in non-confounding cases, and differ from each other
in the presence of confounding. This statistical causal-confounding asymmetry
can be used for confounder detection. Without the need of analyzing the
spectral measure pattern, our method does avoid the difficulty of metric choice
and multiple parameter optimization. Experiments on synthetic and real data
show the performance of this method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Liu_F/0/1/0/all/0/1&quot;&gt;Furui Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chan_L/0/1/0/all/0/1&quot;&gt;Laiwan Chan&lt;/a&gt;</dc:creator>
</item></rdf:RDF>