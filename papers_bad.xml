<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Boring papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Bad Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-06-19T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1707.03374"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08760"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.10459"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.01374"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06914"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06920"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06923"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06927"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06931"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06953"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.07011"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.07072"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.07082"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.07111"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.07129"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.07164"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.07172"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.07199"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.07239"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.07247"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.07304"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.07342"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.07346"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.07376"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1605.06593"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1606.03860"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1703.07940"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1704.04651"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.05380"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.10057"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.01186"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.03144"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05594"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06875"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06908"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06945"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.06977"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.07004"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.07066"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.07085"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.07137"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.07139"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.07174"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.07190"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.07200"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.07223"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.07307"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.07348"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.07353"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.07373"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1603.06560"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1612.09413"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1702.06234"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1702.06240"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.10951"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.05654"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.04695"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06894"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08898"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09514"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.10161"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.06826"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07836"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04823"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05490"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05817"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1707.03374">
<title>Imitation from Observation: Learning to Imitate Behaviors from Raw Video via Context Translation. (arXiv:1707.03374v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1707.03374</link>
<description rdf:parseType="Literal">&lt;p&gt;Imitation learning is an effective approach for autonomous systems to acquire
control policies when an explicit reward function is unavailable, using
supervision provided as demonstrations from an expert, typically a human
operator. However, standard imitation learning methods assume that the agent
receives examples of observation-action tuples that could be provided, for
instance, to a supervised learning algorithm. This stands in contrast to how
humans and animals imitate: we observe another person performing some behavior
and then figure out which actions will realize that behavior, compensating for
changes in viewpoint, surroundings, object positions and types, and other
factors. We term this kind of imitation learning &quot;imitation-from-observation,&quot;
and propose an imitation learning method based on video prediction with context
translation and deep reinforcement learning. This lifts the assumption in
imitation learning that the demonstration should consist of observations in the
same environment configuration, and enables a variety of interesting
applications, including learning robotic skills that involve tool use simply by
observing videos of human tool use. Our experimental results show the
effectiveness of our approach in learning a wide range of real-world robotic
tasks modeled after common household chores from videos of a human
demonstrator, including sweeping, ladling almonds, pushing objects as well as a
number of tasks in simulation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;YuXuan Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1&quot;&gt;Abhishek Gupta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1&quot;&gt;Pieter Abbeel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1&quot;&gt;Sergey Levine&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08760">
<title>Sensitivity and Generalization in Neural Networks: an Empirical Study. (arXiv:1802.08760v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1802.08760</link>
<description rdf:parseType="Literal">&lt;p&gt;In practice it is often found that large over-parameterized neural networks
generalize better than their smaller counterparts, an observation that appears
to conflict with classical notions of function complexity, which typically
favor smaller models. In this work, we investigate this tension between
complexity and generalization through an extensive empirical exploration of two
natural metrics of complexity related to sensitivity to input perturbations.
Our experiments survey thousands of models with various fully-connected
architectures, optimizers, and other hyper-parameters, as well as four
different image classification datasets.
&lt;/p&gt;
&lt;p&gt;We find that trained neural networks are more robust to input perturbations
in the vicinity of the training data manifold, as measured by the norm of the
input-output Jacobian of the network, and that it correlates well with
generalization. We further establish that factors associated with poor
generalization $-$ such as full-batch training or using random labels $-$
correspond to lower robustness, while factors associated with good
generalization $-$ such as data augmentation and ReLU non-linearities $-$ give
rise to more robust functions. Finally, we demonstrate how the input-output
Jacobian norm can be predictive of generalization at the level of individual
test points.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Novak_R/0/1/0/all/0/1&quot;&gt;Roman Novak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bahri_Y/0/1/0/all/0/1&quot;&gt;Yasaman Bahri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Abolafia_D/0/1/0/all/0/1&quot;&gt;Daniel A. Abolafia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pennington_J/0/1/0/all/0/1&quot;&gt;Jeffrey Pennington&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sohl_Dickstein_J/0/1/0/all/0/1&quot;&gt;Jascha Sohl-Dickstein&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.10459">
<title>Graphite: Iterative Generative Modeling of Graphs. (arXiv:1803.10459v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1803.10459</link>
<description rdf:parseType="Literal">&lt;p&gt;Graphs are a fundamental abstraction for modeling relational data. However,
graphs are discrete and combinatorial in nature, and learning representations
suitable for machine learning tasks poses statistical and computational
challenges. In this work, we propose Graphite an algorithmic framework for
unsupervised learning of representations over nodes in a graph using deep
latent variable generative models. Our model is based on variational
autoencoders (VAE), and uses graph neural networks for parameterizing both the
generative model (i.e., decoder) and inference model (i.e., encoder). The use
of graph neural networks directly incorporates inductive biases due to the
spatial, local structure of graphs directly in the generative model. We draw
novel connections of our framework with approximate inference via kernel
embeddings. Empirically, Graphite outperforms competing approaches for the
tasks of density estimation, link prediction, and node classification on
synthetic and benchmark datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Grover_A/0/1/0/all/0/1&quot;&gt;Aditya Grover&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zweig_A/0/1/0/all/0/1&quot;&gt;Aaron Zweig&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ermon_S/0/1/0/all/0/1&quot;&gt;Stefano Ermon&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.01374">
<title>RF-PUF: Enhancing IoT Security through Authentication of Wireless Nodes using In-situ Machine Learning. (arXiv:1805.01374v3 [cs.CR] UPDATED)</title>
<link>http://arxiv.org/abs/1805.01374</link>
<description rdf:parseType="Literal">&lt;p&gt;Traditional authentication in radio-frequency (RF) systems enable secure data
communication within a network through techniques such as digital signatures
and hash-based message authentication codes (HMAC), which suffer from key
recovery attacks. State-of-the-art IoT networks such as Nest also use Open
Authentication (OAuth 2.0) protocols that are vulnerable to cross-site-recovery
forgery (CSRF), which shows that these techniques may not prevent an adversary
from copying or modeling the secret IDs or encryption keys using invasive, side
channel, learning or software attacks. Physical unclonable functions (PUF), on
the other hand, can exploit manufacturing process variations to uniquely
identify silicon chips which makes a PUF-based system extremely robust and
secure at low cost, as it is practically impossible to replicate the same
silicon characteristics across dies. Taking inspiration from human
communication, which utilizes inherent variations in the voice signatures to
identify a certain speaker, we present RF- PUF: a deep neural network-based
framework that allows real-time authentication of wireless nodes, using the
effects of inherent process variation on RF properties of the wireless
transmitters (Tx), detected through in-situ machine learning at the receiver
(Rx) end. The proposed method utilizes the already-existing asymmetric RF
communication framework and does not require any additional circuitry for PUF
generation or feature extraction. Simulation results involving the process
variations in a standard 65 nm technology node, and features such as LO offset
and I-Q imbalance detected with a neural network having 50 neurons in the
hidden layer indicate that the framework can distinguish up to 4800
transmitters with an accuracy of 99.9% (~ 99% for 10,000 transmitters) under
varying channel conditions, and without the need for traditional preambles.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chatterjee_B/0/1/0/all/0/1&quot;&gt;Baibhab Chatterjee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Das_D/0/1/0/all/0/1&quot;&gt;Debayan Das&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Maity_S/0/1/0/all/0/1&quot;&gt;Shovan Maity&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sen_S/0/1/0/all/0/1&quot;&gt;Shreyas Sen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06914">
<title>Distributional Advantage Actor-Critic. (arXiv:1806.06914v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.06914</link>
<description rdf:parseType="Literal">&lt;p&gt;In traditional reinforcement learning, an agent maximizes the reward
collected during its interaction with the environment by approximating the
optimal policy through the estimation of value functions. Typically, given a
state s and action a, the corresponding value is the expected discounted sum of
rewards. The optimal action is then chosen to be the action a with the largest
value estimated by value function. However, recent developments have shown both
theoretical and experimental evidence of superior performance when value
function is replaced with value distribution in context of deep Q learning [1].
In this paper, we develop a new algorithm that combines advantage actor-critic
with value distribution estimated by quantile regression. We evaluated this new
algorithm, termed Distributional Advantage Actor-Critic (DA2C or QR-A2C) on a
variety of tasks, and observed it to achieve at least as good as baseline
algorithms, and outperforming baseline in some tasks with smaller variance and
increased stability.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1&quot;&gt;Shangda Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bing_S/0/1/0/all/0/1&quot;&gt;Selina Bing&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1&quot;&gt;Steven Yang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06920">
<title>Maximum a Posteriori Policy Optimisation. (arXiv:1806.06920v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.06920</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce a new algorithm for reinforcement learning called Maximum
aposteriori Policy Optimisation (MPO) based on coordinate ascent on a relative
entropy objective. We show that several existing methods can directly be
related to our derivation. We develop two off-policy algorithms and demonstrate
that they are competitive with the state-of-the-art in deep reinforcement
learning. In particular, for continuous control, our method outperforms
existing methods with respect to sample efficiency, premature convergence and
robustness to hyperparameter settings while achieving similar or better final
performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abdolmaleki_A/0/1/0/all/0/1&quot;&gt;Abbas Abdolmaleki&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Springenberg_J/0/1/0/all/0/1&quot;&gt;Jost Tobias Springenberg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tassa_Y/0/1/0/all/0/1&quot;&gt;Yuval Tassa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Munos_R/0/1/0/all/0/1&quot;&gt;Remi Munos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Heess_N/0/1/0/all/0/1&quot;&gt;Nicolas Heess&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Riedmiller_M/0/1/0/all/0/1&quot;&gt;Martin Riedmiller&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06923">
<title>Implicit Quantile Networks for Distributional Reinforcement Learning. (arXiv:1806.06923v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.06923</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work, we build on recent advances in distributional reinforcement
learning to give a generally applicable, flexible, and state-of-the-art
distributional variant of DQN. We achieve this by using quantile regression to
approximate the full quantile function for the state-action return
distribution. By reparameterizing a distribution over the sample space, this
yields an implicitly defined return distribution and gives rise to a large
class of risk-sensitive policies. We demonstrate improved performance on the 57
Atari 2600 games in the ALE, and use our algorithm&apos;s implicitly defined
distributions to study the effects of risk-sensitive policies in Atari games.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dabney_W/0/1/0/all/0/1&quot;&gt;Will Dabney&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ostrovski_G/0/1/0/all/0/1&quot;&gt;Georg Ostrovski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Silver_D/0/1/0/all/0/1&quot;&gt;David Silver&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Munos_R/0/1/0/all/0/1&quot;&gt;R&amp;#xe9;mi Munos&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06927">
<title>Auto-Meta: Automated Gradient Based Meta Learner Search. (arXiv:1806.06927v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.06927</link>
<description rdf:parseType="Literal">&lt;p&gt;Fully automating machine learning pipeline is one of the outstanding
challenges of general artificial intelligence, as practical machine learning
often requires costly human driven process, such as hyper-parameter tuning,
algorithmic selection, and model selection. In this work, we consider the
problem of executing automated, yet scalable search for finding optimal
gradient based meta-learners in practice. As a solution, we apply progressive
neural architecture search to proto-architectures by appealing to the model
agnostic nature of general gradient based meta learners. In the presence of
recent universality result of Finn \textit{et
al.}\cite{finn:universality_maml:DBLP:/journals/corr/abs-1710-11622}, our
search is a priori motivated in that neural network architecture search
dynamics---automated or not---may be quite different from that of the classical
setting with the same target tasks, due to the presence of the gradient update
operator. A posteriori, our search algorithm, given appropriately designed
search spaces, finds gradient based meta learners with non-intuitive
proto-architectures that are narrowly deep, unlike the inception-like
structures previously observed in the resulting architectures of traditional
NAS algorithms. Along with these notable findings, the searched gradient based
meta-learner achieves state-of-the-art results on the few shot classification
problem on Mini-ImageNet with $76.29\%$ accuracy, which is an $13.18\%$
improvement over results reported in the original MAML paper. To our best
knowledge, this work is the first successful AutoML implementation in the
context of meta learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1&quot;&gt;Jaehong Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Choi_Y/0/1/0/all/0/1&quot;&gt;Youngduck Choi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cha_M/0/1/0/all/0/1&quot;&gt;Moonsu Cha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1&quot;&gt;Jung Kwon Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_S/0/1/0/all/0/1&quot;&gt;Sangyeul Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1&quot;&gt;Sungwan Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Choi_Y/0/1/0/all/0/1&quot;&gt;Yongseok Choi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1&quot;&gt;Jiwon Kim&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06931">
<title>Reinforcement Learning with Function-Valued Action Spaces for Partial Differential Equation Control. (arXiv:1806.06931v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.06931</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent work has shown that reinforcement learning (RL) is a promising
approach to control dynamical systems described by partial differential
equations (PDE). This paper shows how to use RL to tackle more general PDE
control problems that have continuous high-dimensional action spaces with
spatial relationship among action dimensions. In particular, we propose the
concept of action descriptors, which encode regularities among
spatially-extended action dimensions and enable the agent to control
high-dimensional action PDEs. We provide theoretical evidence suggesting that
this approach can be more sample efficient compared to a conventional approach
that treats each action dimension separately and does not explicitly exploit
the spatial regularity of the action space. The action descriptor approach is
then used within the deep deterministic policy gradient algorithm. Experiments
on two PDE control problems, with up to 256-dimensional continuous actions,
show the advantage of the proposed approach over the conventional one.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pan_Y/0/1/0/all/0/1&quot;&gt;Yangchen Pan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Farahmand_A/0/1/0/all/0/1&quot;&gt;Amir-massoud Farahmand&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+White_M/0/1/0/all/0/1&quot;&gt;Martha White&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nabi_S/0/1/0/all/0/1&quot;&gt;Saleh Nabi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grover_P/0/1/0/all/0/1&quot;&gt;Piyush Grover&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nikovski_D/0/1/0/all/0/1&quot;&gt;Daniel Nikovski&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06953">
<title>Qualitative Measurements of Policy Discrepancy for Return-based Deep Q-Network. (arXiv:1806.06953v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.06953</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we focus on policy discrepancy in return-based deep Q-network
(R-DQN) learning. We propose a general framework for R-DQN, with which most of
the return-based reinforcement learning algorithms can be combined with DQN. We
show the performance of traditional DQN can be significantly improved by
introducing returnbased reinforcement learning. In order to further improve the
performance of R-DQN, we present a strategy with two measurements which can
qualitatively measure the policy discrepancy. Moreover, we give two bounds for
these two measurements under the R-DQN framework. Algorithms with our strategy
can accurately express the trace coefficient and achieve a better approximation
to return. The experiments are carried out on several representative tasks from
the OpenAI Gym library. Results show the algorithms with our strategy
outperform the state-of-the-art R-DQN methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meng_W/0/1/0/all/0/1&quot;&gt;Wenjia Meng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_Q/0/1/0/all/0/1&quot;&gt;Qian Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1&quot;&gt;Long Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1&quot;&gt;Pengfei Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pan_G/0/1/0/all/0/1&quot;&gt;Gang Pan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.07011">
<title>VirtualHome: Simulating Household Activities via Programs. (arXiv:1806.07011v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1806.07011</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we are interested in modeling complex activities that occur in
a typical household. We propose to use programs, i.e., sequences of atomic
actions and interactions, as a high level representation of complex tasks.
Programs are interesting because they provide a non-ambiguous representation of
a task, and allow agents to execute them. However, nowadays, there is no
database providing this type of information. Towards this goal, we first
crowd-source programs for a variety of activities that happen in people&apos;s
homes, via a game-like interface used for teaching kids how to code. Using the
collected dataset, we show how we can learn to extract programs directly from
natural language descriptions or from videos. We then implement the most common
atomic (inter)actions in the Unity3D game engine, and use our programs to
&quot;drive&quot; an artificial agent to execute tasks in a simulated household
environment. Our VirtualHome simulator allows us to create a large activity
video dataset with rich ground-truth, enabling training and testing of video
understanding models. We further showcase examples of our agent performing
tasks in our VirtualHome based on language descriptions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Puig_X/0/1/0/all/0/1&quot;&gt;Xavier Puig&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ra_K/0/1/0/all/0/1&quot;&gt;Kevin Ra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Boben_M/0/1/0/all/0/1&quot;&gt;Marko Boben&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jiaman Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_T/0/1/0/all/0/1&quot;&gt;Tingwu Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fidler_S/0/1/0/all/0/1&quot;&gt;Sanja Fidler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Torralba_A/0/1/0/all/0/1&quot;&gt;Antonio Torralba&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.07072">
<title>A New COLD Feature based Handwriting Analysis for Ethnicity/Nationality Identification. (arXiv:1806.07072v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1806.07072</link>
<description rdf:parseType="Literal">&lt;p&gt;Identifying crime for forensic investigating teams when crimes involve people
of different nationals is challenging. This paper proposes a new method for
ethnicity (nationality) identification based on Cloud of Line Distribution
(COLD) features of handwriting components. The proposed method, at first,
explores tangent angle for the contour pixels in each row and the mean of
intensity values of each row in an image for segmenting text lines. For
segmented text lines, we use tangent angle and direction of base lines to
remove rule lines in the image. We use polygonal approximation for finding
dominant points for contours of edge components. Then the proposed method
connects the nearest dominant points of every dominant point, which results in
line segments of dominant point pairs. For each line segment, the proposed
method estimates angle and length, which gives a point in polar domain. For all
the line segments, the proposed method generates dense points in polar domain,
which results in COLD distribution. As character component shapes change,
according to nationals, the shape of the distribution changes. This observation
is extracted based on distance from pixels of distribution to Principal Axis of
the distribution. Then the features are subjected to an SVM classifier for
identifying nationals. Experiments are conducted on a complex dataset, which
show the proposed method is effective and outperforms the existing method
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nag_S/0/1/0/all/0/1&quot;&gt;Sauradip Nag&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shivakumara_P/0/1/0/all/0/1&quot;&gt;Palaiahnakote Shivakumara&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yirui_W/0/1/0/all/0/1&quot;&gt;Wu Yirui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pal_U/0/1/0/all/0/1&quot;&gt;Umapada Pal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_T/0/1/0/all/0/1&quot;&gt;Tong Lu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.07082">
<title>Simplifying Probabilistic Expressions in Causal Inference. (arXiv:1806.07082v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.07082</link>
<description rdf:parseType="Literal">&lt;p&gt;Obtaining a non-parametric expression for an interventional distribution is
one of the most fundamental tasks in causal inference. Such an expression can
be obtained for an identifiable causal effect by an algorithm or by manual
application of do-calculus. Often we are left with a complicated expression
which can lead to biased or inefficient estimates when missing data or
measurement errors are involved. We present an automatic simplification
algorithm that seeks to eliminate symbolically unnecessary variables from these
expressions by taking advantage of the structure of the underlying graphical
model. Our method is applicable to all causal effect formulas and is readily
available in the R package causaleffect.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tikka_S/0/1/0/all/0/1&quot;&gt;Santtu Tikka&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Karvanen_J/0/1/0/all/0/1&quot;&gt;Juha Karvanen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.07111">
<title>Facing Multiple Attacks in Adversarial Patrolling Games with Alarmed Targets. (arXiv:1806.07111v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1806.07111</link>
<description rdf:parseType="Literal">&lt;p&gt;We focus on adversarial patrolling games on arbitrary graphs, where the
Defender can control a mobile resource, the targets are alarmed by an alarm
system, and the Attacker can observe the actions of the mobile resource of the
Defender and perform different attacks exploiting multiple resources. This
scenario can be modeled as a zero-sum extensive-form game in which each player
can play multiple times. The game tree is exponentially large both in the size
of the graph and in the number of attacking resources. We show that when the
number of the Attacker&apos;s resources is free, the problem of computing the
equilibrium path is NP-hard, while when the number of resources is fixed, the
equilibrium path can be computed in poly-time. We provide a dynamic-programming
algorithm that, given the number of the Attacker&apos;s resources, computes the
equilibrium path requiring poly-time in the size of the graph and exponential
time in the number of the resources. Furthermore, since in real-world scenarios
it is implausible that the Defender knows the number of attacking resources, we
study the robustness of the Defender&apos;s strategy when she makes a wrong guess
about that number. We show that even the error of just a single resource can
lead to an arbitrary inefficiency, when the inefficiency is defined as the
ratio of the Defender&apos;s utilities obtained with a wrong guess and a correct
guess. However, a more suitable definition of inefficiency is given by the
difference of the Defender&apos;s utilities: this way, we observe that the higher
the error in the estimation, the higher the loss for the Defender. Then, we
investigate the performance of online algorithms when no information about the
Attacker&apos;s resources is available. Finally, we resort to randomized online
algorithms showing that we can obtain a competitive factor that is twice better
than the one that can be achieved by any deterministic online algorithm.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nittis_G/0/1/0/all/0/1&quot;&gt;Giuseppe De Nittis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gatti_N/0/1/0/all/0/1&quot;&gt;Nicola Gatti&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.07129">
<title>Instance-Level Explanations for Fraud Detection: A Case Study. (arXiv:1806.07129v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.07129</link>
<description rdf:parseType="Literal">&lt;p&gt;Fraud detection is a difficult problem that can benefit from predictive
modeling. However, the verification of a prediction is challenging; for a
single insurance policy, the model only provides a prediction score. We present
a case study where we reflect on different instance-level model explanation
techniques to aid a fraud detection team in their work. To this end, we
designed two novel dashboards combining various state-of-the-art explanation
techniques. These enable the domain expert to analyze and understand
predictions, dramatically speeding up the process of filtering potential fraud
cases. Finally, we discuss the lessons learned and outline open research
issues.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Collaris_D/0/1/0/all/0/1&quot;&gt;Dennis Collaris&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vink_L/0/1/0/all/0/1&quot;&gt;Leo M. Vink&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wijk_J/0/1/0/all/0/1&quot;&gt;Jarke J. van Wijk&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.07164">
<title>Approximation Strategies for Incomplete MaxSAT. (arXiv:1806.07164v1 [cs.LO])</title>
<link>http://arxiv.org/abs/1806.07164</link>
<description rdf:parseType="Literal">&lt;p&gt;Incomplete MaxSAT solving aims to quickly find a solution that attempts to
minimize the sum of the weights of the unsatisfied soft clauses without
providing any optimality guarantees.
&lt;/p&gt;
&lt;p&gt;In this paper, we propose two approximation strategies for improving
incomplete MaxSAT solving. In one of the strategies, we cluster the weights and
approximate them with a representative weight. In another strategy, we break up
the problem of minimizing the sum of weights of unsatisfiable clauses into
multiple minimization subproblems. Experimental results show that approximation
strategies can be used to find better solutions than the best incomplete
solvers in the MaxSAT Evaluation 2017.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Joshi_S/0/1/0/all/0/1&quot;&gt;Saurabh Joshi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kumar_P/0/1/0/all/0/1&quot;&gt;Prateek Kumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Martins_R/0/1/0/all/0/1&quot;&gt;Ruben Martins&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rao_S/0/1/0/all/0/1&quot;&gt;Sukrut Rao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.07172">
<title>Surrogate Outcomes and Transportability. (arXiv:1806.07172v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1806.07172</link>
<description rdf:parseType="Literal">&lt;p&gt;Identification of causal effects is one of the most fundamental tasks of
causal inference. We study a variant of the identifiability problem where the
experimental distribution of interest is partially known. This corresponds to a
real-world setting where experiments were conducted on a set of variables,
which we call surrogate outcomes, but the variables of interest were not 10
measured. We label this problem as surrogate outcome identifiability and show
that the concept of transportability provides a sufficient criteria for
determining surrogate outcome identifiability for a large class of problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tikka_S/0/1/0/all/0/1&quot;&gt;Santtu Tikka&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Karvanen_J/0/1/0/all/0/1&quot;&gt;Juha Karvanen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.07199">
<title>Agent-Mediated Social Choice. (arXiv:1806.07199v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1806.07199</link>
<description rdf:parseType="Literal">&lt;p&gt;Computational studies of voting are mostly motivated by two intended
applications: the coordination of societies of artificial agents, and the study
of human collective decisions whose complexity requires the use of
computational techniques. Both research directions are too often confined to
theoretical studies, with unrealistic assumptions constraining their
significance for real-world situations. Most practical applications of these
results are therefore confined to low-stakes decisions, which are of great
importance in expanding the use of algorithms in society, but are far from
high-stakes choices such as political elections, referenda, or parliamentary
decisions, which societies still make using old-fashioned technologies like
paper ballots. In this paper I argue in favour of conceiving &quot;voting avatars&quot;,
artificial agents that are able to act as proxies for voters in collective
decisions at any level of society. Besides being an ideal test-bed for a large
number of techniques developed in the field of multiagent systems and
artificial intelligence in general, agent-mediated social choice may also
suggests innovative solutions to the low voter participation that is endemic in
most practical implementations of electronic decision processes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grandi_U/0/1/0/all/0/1&quot;&gt;Umberto Grandi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.07239">
<title>PaMpeR: Proof Method Recommendation System for Isabelle/HOL. (arXiv:1806.07239v1 [cs.LO])</title>
<link>http://arxiv.org/abs/1806.07239</link>
<description rdf:parseType="Literal">&lt;p&gt;Deciding which sub-tool to use for a given proof state requires expertise
specific to each ITP. To mitigate this problem, we present PaMpeR, a Proof
Method Recommendation system for Isabelle/HOL. Given a proof state, PaMpeR
recommends proof methods to discharge the proof goal and provides qualitative
explanations as to why it suggests these methods. PaMpeR generates these
recommendations based on existing hand-written proof corpora, thus transferring
experienced users&apos; expertise to new users. Our evaluation shows that PaMpeR
correctly predicts experienced users&apos; proof methods invocation especially when
it comes to special purpose proof methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nagashima_Y/0/1/0/all/0/1&quot;&gt;Yutaka Nagashima&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1&quot;&gt;Yilun He&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.07247">
<title>Tensor-Tensor Product Toolbox. (arXiv:1806.07247v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.07247</link>
<description rdf:parseType="Literal">&lt;p&gt;Tensors are higher-order extensions of matrices. In recent work [Kilmer and
Martin, 2011], the authors introduced the notion of the t-product, a
generalization of matrix multiplication for tensors of order three. The
multiplication is based on a convolution-like operation, which can be
implemented efficiently using the Fast Fourier Transform (FFT). Based on
t-product, there has a similar linear algebraic structure of tensors to
matrices. For example, there has the tensor SVD (t-SVD) which is computable. By
using some properties of FFT, we have a more efficient way for computing
t-product and t-SVD in [C. Lu, et al., 2018]. We develop a Matlab toolbox to
implement several basic operations on tensors based on t-product. The toolbox
is available at https://github.com/canyilu/tproduct.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lu_C/0/1/0/all/0/1&quot;&gt;Canyi Lu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.07304">
<title>Dynamic Multi-Level Multi-Task Learning for Sentence Simplification. (arXiv:1806.07304v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1806.07304</link>
<description rdf:parseType="Literal">&lt;p&gt;Sentence simplification aims to improve readability and understandability,
based on several operations such as splitting, deletion, and paraphrasing.
However, a valid simplified sentence should also be logically entailed by its
input sentence. In this work, we first present a strong pointer-copy mechanism
based sequence-to-sequence sentence simplification model, and then improve its
entailment and paraphrasing capabilities via multi-task learning with related
auxiliary tasks of entailment and paraphrase generation. Moreover, we propose a
novel &apos;multi-level&apos; layered soft sharing approach where each auxiliary task
shares different (higher versus lower) level layers of the sentence
simplification model, depending on the task&apos;s semantic versus lexico-syntactic
nature. We also introduce a novel multi-armed bandit based training approach
that dynamically learns how to effectively switch across tasks during
multi-task learning. Experiments on multiple popular datasets demonstrate that
our model outperforms competitive simplification systems in SARI and FKGL
automatic metrics, and human evaluation. Further, we present several ablation
analyses on alternative layer sharing methods, soft versus hard sharing,
dynamic multi-armed bandit sampling approaches, and our model&apos;s learned
entailment and paraphrasing skills.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_H/0/1/0/all/0/1&quot;&gt;Han Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pasunuru_R/0/1/0/all/0/1&quot;&gt;Ramakanth Pasunuru&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bansal_M/0/1/0/all/0/1&quot;&gt;Mohit Bansal&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.07342">
<title>A Reputation System for Artificial Societies. (arXiv:1806.07342v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1806.07342</link>
<description rdf:parseType="Literal">&lt;p&gt;One approach to achieving artificial general intelligence (AGI) is through
the emergence of complex structures and dynamic properties arising from
decentralized networks of interacting artificial intelligence (AI) agents.
Understanding the principles of consensus in societies and finding ways to make
consensus more reliable becomes critically important as connectivity and
interaction speed increase in modern distributed systems of hybrid collective
intelligences, which include both humans and computer systems. We propose a new
form of reputation-based consensus with greater resistance to reputation gaming
than current systems have. We discuss options for its implementation, and
provide initial practical results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kolonin_A/0/1/0/all/0/1&quot;&gt;Anton Kolonin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goertzel_B/0/1/0/all/0/1&quot;&gt;Ben Goertzel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Duong_D/0/1/0/all/0/1&quot;&gt;Deborah Duong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ikle_M/0/1/0/all/0/1&quot;&gt;Matt Ikle&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.07346">
<title>A Scalable Machine Learning Approach for Inferring Probabilistic US-LI-RADS Categorization. (arXiv:1806.07346v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1806.07346</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a scalable computerized approach for large-scale inference of
Liver Imaging Reporting and Data System (LI-RADS) final assessment categories
in narrative ultrasound (US) reports. Although our model was trained on reports
created using a LI-RADS template, it was also able to infer LI-RADS scoring for
unstructured reports that were created before the LI-RADS guidelines were
established. No human-labelled data was required in any step of this study; for
training, LI-RADS scores were automatically extracted from those reports that
contained structured LI-RADS scores, and it translated the derived knowledge to
reasoning on unstructured radiology reports. By providing automated LI-RADS
categorization, our approach may enable standardizing screening recommendations
and treatment planning of patients at risk for hepatocellular carcinoma, and it
may facilitate AI-based healthcare research with US images by offering large
scale text mining and data gathering opportunities from standard hospital
clinical data repositories.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Banerjee_I/0/1/0/all/0/1&quot;&gt;Imon Banerjee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Choi_H/0/1/0/all/0/1&quot;&gt;Hailey H. Choi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Desser_T/0/1/0/all/0/1&quot;&gt;Terry Desser&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rubin_D/0/1/0/all/0/1&quot;&gt;Daniel L. Rubin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.07376">
<title>Semantic Analysis of (Reflectional) Visual Symmetry: A Human-Centred Computational Model for Declarative Explainability. (arXiv:1806.07376v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1806.07376</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a computational framework for the semantic interpretation of
symmetry in naturalistic scenes. Key features include a human-centred
representation, and a declarative, explainable interpretation model supporting
deep semantic question-answering founded on an integration of methods in
knowledge representation and computer vision. In the backdrop of the visual
arts, we showcase the framework&apos;s capability to generate human-centred,
queryable, relational structures, also evaluating the framework with an
empirical study on the human perception of visual symmetry. Our framework
represents and is driven by the application of foundational Vision and KR
methods in the psychological and social sciences.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Suchan_J/0/1/0/all/0/1&quot;&gt;Jakob Suchan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bhatt_M/0/1/0/all/0/1&quot;&gt;Mehul Bhatt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vardarajan_S/0/1/0/all/0/1&quot;&gt;Srikrishna Vardarajan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Amirshahi_S/0/1/0/all/0/1&quot;&gt;Seyed Ali Amirshahi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_S/0/1/0/all/0/1&quot;&gt;Stella Yu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1605.06593">
<title>Online Influence Maximization under Independent Cascade Model with Semi-Bandit Feedback. (arXiv:1605.06593v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1605.06593</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the online influence maximization problem in social networks under
the independent cascade model. Specifically, we aim to learn the set of &quot;best
influencers&quot; in a social network online while repeatedly interacting with it.
We address the challenges of (i) combinatorial action space, since the number
of feasible influencer sets grows exponentially with the maximum number of
influencers, and (ii) limited feedback, since only the influenced portion of
the network is observed. Under a stochastic semi-bandit feedback, we propose
and analyze IMLinUCB, a computationally efficient UCB-based algorithm. Our
bounds on the cumulative regret are polynomial in all quantities of interest,
achieve near-optimal dependence on the number of interactions and reflect the
topology of the network and the activation probabilities of its edges, thereby
giving insights on the problem complexity. To the best of our knowledge, these
are the first such results. Our experiments show that in several representative
graph topologies, the regret of IMLinUCB scales as suggested by our upper
bounds. IMLinUCB permits linear generalization and thus is both statistically
and computationally suitable for large-scale problems. Our experiments also
show that IMLinUCB with linear generalization can lead to low regret in
real-world online influence maximization.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wen_Z/0/1/0/all/0/1&quot;&gt;Zheng Wen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kveton_B/0/1/0/all/0/1&quot;&gt;Branislav Kveton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Valko_M/0/1/0/all/0/1&quot;&gt;Michal Valko&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vaswani_S/0/1/0/all/0/1&quot;&gt;Sharan Vaswani&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1606.03860">
<title>Robust Probabilistic Modeling with Bayesian Data Reweighting. (arXiv:1606.03860v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1606.03860</link>
<description rdf:parseType="Literal">&lt;p&gt;Probabilistic models analyze data by relying on a set of assumptions. Data
that exhibit deviations from these assumptions can undermine inference and
prediction quality. Robust models offer protection against mismatch between a
model&apos;s assumptions and reality. We propose a way to systematically detect and
mitigate mismatch of a large class of probabilistic models. The idea is to
raise the likelihood of each observation to a weight and then to infer both the
latent variables and the weights from data. Inferring the weights allows a
model to identify observations that match its assumptions and down-weight
others. This enables robust inference and improves predictive accuracy. We
study four different forms of mismatch with reality, ranging from missing
latent groups to structure misspecification. A Poisson factorization analysis
of the Movielens 1M dataset shows the benefits of this approach in a practical
scenario.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yixin Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kucukelbir_A/0/1/0/all/0/1&quot;&gt;Alp Kucukelbir&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Blei_D/0/1/0/all/0/1&quot;&gt;David M. Blei&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1703.07940">
<title>Unsupervised Basis Function Adaptation for Reinforcement Learning. (arXiv:1703.07940v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1703.07940</link>
<description rdf:parseType="Literal">&lt;p&gt;When using reinforcement learning (RL) algorithms it is common, given a large
state space, to introduce some form of approximation architecture for the value
function (VF). The exact form of this architecture can have a significant
effect on an agent&apos;s performance, however, and determining a suitable
approximation architecture can often be a highly complex task. Consequently
there is currently interest among researchers in the potential for allowing RL
algorithms to adaptively generate (i.e. to learn) approximation architectures.
One relatively unexplored method of adapting approximation architectures
involves using feedback regarding the frequency with which an agent has visited
certain states to guide which areas of the state space to approximate with
greater detail. In this article we will: (a) informally discuss the potential
advantages offered by such methods; (b) introduce a new algorithm based on such
methods which adapts a state aggregation approximation architecture on-line and
is designed for use in conjunction with SARSA; (c) provide theoretical results,
in a policy evaluation setting, regarding this particular algorithm&apos;s
complexity, convergence properties and potential to reduce VF error; and
finally (d) test experimentally the extent to which this algorithm can improve
performance given a number of different test problems. Taken together our
results suggest that our algorithm (and potentially such methods more
generally) can provide a versatile and computationally lightweight means of
significantly boosting RL performance given suitable conditions which are
commonly encountered in practice.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barker_E/0/1/0/all/0/1&quot;&gt;Edward Barker&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ras_C/0/1/0/all/0/1&quot;&gt;Charl Ras&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1704.04651">
<title>The Reactor: A fast and sample-efficient Actor-Critic agent for Reinforcement Learning. (arXiv:1704.04651v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1704.04651</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work we present a new agent architecture, called Reactor, which
combines multiple algorithmic and architectural contributions to produce an
agent with higher sample-efficiency than Prioritized Dueling DQN (Wang et al.,
2016) and Categorical DQN (Bellemare et al., 2017), while giving better
run-time performance than A3C (Mnih et al., 2016). Our first contribution is a
new policy evaluation algorithm called Distributional Retrace, which brings
multi-step off-policy updates to the distributional reinforcement learning
setting. The same approach can be used to convert several classes of multi-step
policy evaluation algorithms designed for expected value evaluation into
distributional ones. Next, we introduce the \b{eta}-leave-one-out policy
gradient algorithm which improves the trade-off between variance and bias by
using action values as a baseline. Our final algorithmic contribution is a new
prioritized replay algorithm for sequences, which exploits the temporal
locality of neighboring observations for more efficient replay prioritization.
Using the Atari 2600 benchmarks, we show that each of these innovations
contribute to both the sample efficiency and final agent performance. Finally,
we demonstrate that Reactor reaches state-of-the-art performance after 200
million frames and less than a day of training.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gruslys_A/0/1/0/all/0/1&quot;&gt;Audrunas Gruslys&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dabney_W/0/1/0/all/0/1&quot;&gt;Will Dabney&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Azar_M/0/1/0/all/0/1&quot;&gt;Mohammad Gheshlaghi Azar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Piot_B/0/1/0/all/0/1&quot;&gt;Bilal Piot&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bellemare_M/0/1/0/all/0/1&quot;&gt;Marc Bellemare&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Munos_R/0/1/0/all/0/1&quot;&gt;Remi Munos&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.05380">
<title>The Uncertainty Bellman Equation and Exploration. (arXiv:1709.05380v3 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1709.05380</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the exploration/exploitation problem in reinforcement learning.
For exploitation, it is well known that the Bellman equation connects the value
at any time-step to the expected value at subsequent time-steps. In this paper
we consider a similar \textit{uncertainty} Bellman equation (UBE), which
connects the uncertainty at any time-step to the expected uncertainties at
subsequent time-steps, thereby extending the potential exploratory benefit of a
policy beyond individual time-steps. We prove that the unique fixed point of
the UBE yields an upper bound on the variance of the posterior distribution of
the Q-values induced by any policy. This bound can be much tighter than
traditional count-based bonuses that compound standard deviation rather than
variance. Importantly, and unlike several existing approaches to optimism, this
method scales naturally to large systems with complex generalization.
Substituting our UBE-exploration strategy for $\epsilon$-greedy improves DQN
performance on 51 out of 57 games in the Atari suite.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+ODonoghue_B/0/1/0/all/0/1&quot;&gt;Brendan O&amp;#x27;Donoghue&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Osband_I/0/1/0/all/0/1&quot;&gt;Ian Osband&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Munos_R/0/1/0/all/0/1&quot;&gt;Remi Munos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mnih_V/0/1/0/all/0/1&quot;&gt;Volodymyr Mnih&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.10057">
<title>Multiwinner Voting with Fairness Constraints. (arXiv:1710.10057v2 [cs.CY] UPDATED)</title>
<link>http://arxiv.org/abs/1710.10057</link>
<description rdf:parseType="Literal">&lt;p&gt;Multiwinner voting rules are used to select a small representative subset of
candidates or items from a larger set given the preferences of voters. However,
if candidates have sensitive attributes such as gender or ethnicity (when
selecting a committee), or specified types such as political leaning (when
selecting a subset of news items), an algorithm that chooses a subset by
optimizing a multiwinner voting rule may be unbalanced in its selection -- it
may under or over represent a particular gender or political orientation in the
examples above. We introduce an algorithmic framework for multiwinner voting
problems when there is an additional requirement that the selected subset
should be &quot;fair&quot; with respect to a given set of attributes. Our framework
provides the flexibility to (1) specify fairness with respect to multiple,
non-disjoint attributes (e.g., ethnicity and gender) and (2) specify a score
function. We study the computational complexity of this constrained multiwinner
voting problem for monotone and submodular score functions and present several
approximation algorithms and matching hardness of approximation results for
various attribute group structure and types of score functions. We also present
simulations that suggest that adding fairness constraints may not affect the
scores significantly when compared to the unconstrained case.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Celis_L/0/1/0/all/0/1&quot;&gt;L. Elisa Celis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1&quot;&gt;Lingxiao Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vishnoi_N/0/1/0/all/0/1&quot;&gt;Nisheeth K. Vishnoi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.01186">
<title>Personalized Machine Learning for Robot Perception of Affect and Engagement in Autism Therapy. (arXiv:1802.01186v2 [cs.RO] UPDATED)</title>
<link>http://arxiv.org/abs/1802.01186</link>
<description rdf:parseType="Literal">&lt;p&gt;Robots have great potential to facilitate future therapies for children on
the autism spectrum. However, existing robots lack the ability to automatically
perceive and respond to human affect, which is necessary for establishing and
maintaining engaging interactions. Moreover, their inference challenge is made
harder by the fact that many individuals with autism have atypical and
unusually diverse styles of expressing their affective-cognitive states. To
tackle the heterogeneity in behavioral cues of children with autism, we use the
latest advances in deep learning to formulate a personalized machine learning
(ML) framework for automatic perception of the childrens affective states and
engagement during robot-assisted autism therapy. The key to our approach is a
novel shift from the traditional ML paradigm - instead of using
&apos;one-size-fits-all&apos; ML models, our personalized ML framework is optimized for
each child by leveraging relevant contextual information (demographics and
behavioral assessment scores) and individual characteristics of each child. We
designed and evaluated this framework using a dataset of multi-modal audio,
video and autonomic physiology data of 35 children with autism (age 3-13) and
from 2 cultures (Asia and Europe), participating in a 25-minute child-robot
interaction (~500k datapoints). Our experiments confirm the feasibility of the
robot perception of affect and engagement, showing clear improvements due to
the model personalization. The proposed approach has potential to improve
existing therapies for autism by offering more efficient monitoring and
summarization of the therapy progress.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rudovic_O/0/1/0/all/0/1&quot;&gt;Ognjen Rudovic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1&quot;&gt;Jaeryoung Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dai_M/0/1/0/all/0/1&quot;&gt;Miles Dai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schuller_B/0/1/0/all/0/1&quot;&gt;Bjorn Schuller&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Picard_R/0/1/0/all/0/1&quot;&gt;Rosalind Picard&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.03144">
<title>Neural Dynamic Programming for Musical Self Similarity. (arXiv:1802.03144v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1802.03144</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a neural sequence model designed specifically for symbolic music.
The model is based on a learned edit distance mechanism which generalises a
classic recursion from computer sci- ence, leading to a neural dynamic program.
Re- peated motifs are detected by learning the transfor- mations between them.
We represent the arising computational dependencies using a novel data
structure, the edit tree; this perspective suggests natural approximations
which afford the scaling up of our otherwise cubic time algorithm. We
demonstrate our model on real and synthetic data; in all cases it out-performs
a strong stacked long short-term memory benchmark.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Walder_C/0/1/0/all/0/1&quot;&gt;Christian J. Walder&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1&quot;&gt;Dongwoo Kim&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05594">
<title>Improving Consistency-Based Semi-Supervised Learning with Weight Averaging. (arXiv:1806.05594v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1806.05594</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent advances in deep unsupervised learning have renewed interest in
semi-supervised methods, which can learn from both labeled and unlabeled data.
Presently the most successful approaches to semi-supervised learning are based
on consistency regularization, whereby a model is trained to be robust to small
perturbations of its inputs and parameters. We show that consistency
regularization leads to flatter but narrower optima. We also show that the test
error surface for these methods is approximately convex in regions of weight
space traversed by SGD. Inspired by these observations, we propose to train
consistency based semi-supervised models with stochastic weight averaging
(SWA), a recent method which averages weights along the trajectory of SGD. We
also develop fast-SWA, which further accelerates convergence by averaging
multiple points within each cycle of a cyclical learning rate schedule. With
fast-SWA we achieve the best known semi-supervised results on CIFAR-10 and
CIFAR-100 over many different numbers of observed training labels. For example,
we achieve 95.0% accuracy on CIFAR-10 with only 4000 labels, compared to the
previous best result in the literature of 93.7%. We also improve the best known
accuracy for domain adaptation from CIFAR-10 to STL from 80% to 83%. Finally,
we show that with fast-SWA the simple $\Pi$ model becomes state-of-the-art for
large labeled settings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Athiwaratkun_B/0/1/0/all/0/1&quot;&gt;Ben Athiwaratkun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Finzi_M/0/1/0/all/0/1&quot;&gt;Marc Finzi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Izmailov_P/0/1/0/all/0/1&quot;&gt;Pavel Izmailov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wilson_A/0/1/0/all/0/1&quot;&gt;Andrew Gordon Wilson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06875">
<title>Learning Distributed Representations from Reviews for Collaborative Filtering. (arXiv:1806.06875v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.06875</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent work has shown that collaborative filter-based recommender systems can
be improved by incorporating side information, such as natural language
reviews, as a way of regularizing the derived product representations.
Motivated by the success of this approach, we introduce two different models of
reviews and study their effect on collaborative filtering performance. While
the previous state-of-the-art approach is based on a latent Dirichlet
allocation (LDA) model of reviews, the models we explore are neural network
based: a bag-of-words product-of-experts model and a recurrent neural network.
We demonstrate that the increased flexibility offered by the product-of-experts
model allowed it to achieve state-of-the-art performance on the Amazon review
dataset, outperforming the LDA-based approach. However, interestingly, the
greater modeling power offered by the recurrent neural network appears to
undermine the model&apos;s ability to act as a regularizer of the product
representations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Almahairi_A/0/1/0/all/0/1&quot;&gt;Amjad Almahairi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kastner_K/0/1/0/all/0/1&quot;&gt;Kyle Kastner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cho_K/0/1/0/all/0/1&quot;&gt;Kyunghyun Cho&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Courville_A/0/1/0/all/0/1&quot;&gt;Aaron Courville&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06908">
<title>Designing Optimal Binary Rating Systems. (arXiv:1806.06908v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.06908</link>
<description rdf:parseType="Literal">&lt;p&gt;Modern online platforms rely on effective rating systems to learn about
items. We consider the optimal design of rating systems that collect {\em
binary feedback} after transactions. We make three contributions. First, we
formalize the performance of a rating system as the speed with which it
recovers the true underlying ranking on items (in a large deviations sense),
accounting for both items&apos; underlying match rates and the platform&apos;s
preferences. Second, we provide an efficient algorithm to compute the binary
feedback system that yields the highest such performance. Finally, we show how
this theoretical perspective can be used to empirically design an
implementable, approximately optimal rating system, and validate our approach
using real-world experimental data collected on Amazon Mechanical Turk.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garg_N/0/1/0/all/0/1&quot;&gt;Nikhil Garg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Johari_R/0/1/0/all/0/1&quot;&gt;Ramesh Johari&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06945">
<title>Overlapping Clustering Models, and One (class) SVM to Bind Them All. (arXiv:1806.06945v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.06945</link>
<description rdf:parseType="Literal">&lt;p&gt;People belong to multiple communities, words belong to multiple topics, and
books cover multiple genres; overlapping clusters are commonplace. Many
existing overlapping clustering methods model each person (or word, or book) as
a non-negative weighted combination of &quot;exemplars&quot; who belong solely to one
community, with some small noise. Geometrically, each person is a point on a
cone whose corners are these exemplars. This basic form encompasses the widely
used Mixed Membership Stochastic Blockmodel of networks (Airoldi et al., 2008)
and its degree-corrected variants (Karrer et al. 2011; Jin et al., 2017), as
well as topic models such as LDA (Blei et al., 2003). We show that a simple
one-class SVM yields provably consistent parameter inference for all such
models, and scales to large datasets. Experimental results on several simulated
and real datasets show our algorithm (called SVM-cone) is both accurate and
scalable.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mao_X/0/1/0/all/0/1&quot;&gt;Xueyu Mao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sarkar_P/0/1/0/all/0/1&quot;&gt;Purnamrita Sarkar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chakrabarti_D/0/1/0/all/0/1&quot;&gt;Deepayan Chakrabarti&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.06977">
<title>Using Mode Connectivity for Loss Landscape Analysis. (arXiv:1806.06977v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.06977</link>
<description rdf:parseType="Literal">&lt;p&gt;Mode connectivity is a recently introduced frame- work that empirically
establishes the connected- ness of minima by finding a high accuracy curve
between two independently trained models. To investigate the limits of this
setup, we examine the efficacy of this technique in extreme cases where the
input models are trained or initialized differently. We find that the procedure
is resilient to such changes. Given this finding, we propose using the
framework for analyzing loss surfaces and training trajectories more generally,
and in this direction, study SGD with cosine annealing and restarts (SGDR). We
report that while SGDR moves over barriers in its trajectory, propositions
claiming that it converges to and escapes from multiple local minima are not
substantiated by our empirical results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gotmare_A/0/1/0/all/0/1&quot;&gt;Akhilesh Gotmare&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Keskar_N/0/1/0/all/0/1&quot;&gt;Nitish Shirish Keskar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiong_C/0/1/0/all/0/1&quot;&gt;Caiming Xiong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Socher_R/0/1/0/all/0/1&quot;&gt;Richard Socher&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.07004">
<title>Maximally Invariant Data Perturbation as Explanation. (arXiv:1806.07004v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.07004</link>
<description rdf:parseType="Literal">&lt;p&gt;While several feature scoring methods are proposed to explain the output of
complex machine learning models, most of them lack formal mathematical
definitions. In this study, we propose a novel definition of the feature score
using the maximally invariant data perturbation, which is inspired from the
idea of adversarial example. In adversarial example, one seeks the smallest
data perturbation that changes the model&apos;s output. In our proposed approach, we
consider the opposite: we seek the maximally invariant data perturbation that
does not change the model&apos;s output. In this way, we can identify important
input features as the ones with small allowable data perturbations. To find the
maximally invariant data perturbation, we formulate the problem as linear
programming. The experiment on the image classification with VGG16 shows that
the proposed method could identify relevant parts of the images effectively.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hara_S/0/1/0/all/0/1&quot;&gt;Satoshi Hara&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ikeno_K/0/1/0/all/0/1&quot;&gt;Kouichi Ikeno&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Soma_T/0/1/0/all/0/1&quot;&gt;Tasuku Soma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Maehara_T/0/1/0/all/0/1&quot;&gt;Takanori Maehara&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.07066">
<title>Restricted Boltzmann Machines: Introduction and Review. (arXiv:1806.07066v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.07066</link>
<description rdf:parseType="Literal">&lt;p&gt;The restricted Boltzmann machine is a network of stochastic units with
undirected interactions between pairs of visible and hidden units. This model
was popularized as a building block of deep learning architectures and has
continued to play an important role in applied and theoretical machine
learning. Restricted Boltzmann machines carry a rich structure, with
connections to geometry, applied algebra, probability, statistics, machine
learning, and other areas. The analysis of these models is attractive in its
own right and also as a platform to combine and generalize mathematical tools
for graphical models with hidden variables. This article gives an introduction
to the mathematical analysis of restricted Boltzmann machines, reviews recent
results on the geometry of the sets of probability distributions representable
by these models, and suggests a few directions for further investigation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Montufar_G/0/1/0/all/0/1&quot;&gt;Guido Montufar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.07085">
<title>Enhancing Identification of Causal Effects by Pruning. (arXiv:1806.07085v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.07085</link>
<description rdf:parseType="Literal">&lt;p&gt;Causal models communicate our assumptions about causes and effects in
real-world phe- nomena. Often the interest lies in the identification of the
effect of an action which means deriving an expression from the observed
probability distribution for the interventional distribution resulting from the
action. In many cases an identifiability algorithm may return a complicated
expression that contains variables that are in fact unnecessary. In practice
this can lead to additional computational burden and increased bias or
inefficiency of estimates when dealing with measurement error or missing data.
We present graphical criteria to detect variables which are redundant in
identifying causal effects. We also provide an improved version of a well-known
identifiability algorithm that implements these criteria.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tikka_S/0/1/0/all/0/1&quot;&gt;Santtu Tikka&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Karvanen_J/0/1/0/all/0/1&quot;&gt;Juha Karvanen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.07137">
<title>Large-Scale Stochastic Sampling from the Probability Simplex. (arXiv:1806.07137v1 [stat.CO])</title>
<link>http://arxiv.org/abs/1806.07137</link>
<description rdf:parseType="Literal">&lt;p&gt;Stochastic gradient Markov chain Monte Carlo (SGMCMC) has become a popular
method for scalable Bayesian inference. These methods are based on sampling a
discrete-time approximation to a continuous time process, such as the Langevin
diffusion. When applied to distributions defined on a constrained space, such
as the simplex, the time-discretisation error can dominate when we are near the
boundary of the space. We demonstrate that while current SGMCMC methods for the
simplex perform well in certain cases, they struggle with sparse simplex
spaces; when many of the components are close to zero. However, most popular
large-scale applications of Bayesian inference on simplex spaces, such as
network or topic models, are sparse. We argue that this poor performance is due
to the biases of SGMCMC caused by the discretization error. To get around this,
we propose the stochastic CIR process, which removes all discretization error
and we prove that samples from the stochastic CIR process are asymptotically
unbiased. Use of the stochastic CIR process within a SGMCMC algorithm is shown
to give substantially better performance for a topic model and a Dirichlet
process mixture model than existing SGMCMC approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Baker_J/0/1/0/all/0/1&quot;&gt;Jack Baker&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Fearnhead_P/0/1/0/all/0/1&quot;&gt;Paul Fearnhead&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Fox_E/0/1/0/all/0/1&quot;&gt;Emily B Fox&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Nemeth_C/0/1/0/all/0/1&quot;&gt;Christopher Nemeth&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.07139">
<title>Using J-K fold Cross Validation to Reduce Variance When Tuning NLP Models. (arXiv:1806.07139v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1806.07139</link>
<description rdf:parseType="Literal">&lt;p&gt;K-fold cross validation (CV) is a popular method for estimating the true
performance of machine learning models, allowing model selection and parameter
tuning. However, the very process of CV requires random partitioning of the
data and so our performance estimates are in fact stochastic, with variability
that can be substantial for natural language processing tasks. We demonstrate
that these unstable estimates cannot be relied upon for effective parameter
tuning. The resulting tuned parameters are highly sensitive to how our data is
partitioned, meaning that we often select sub-optimal parameter choices and
have serious reproducibility issues.
&lt;/p&gt;
&lt;p&gt;Instead, we propose to use the less variable J-K-fold CV, in which J
independent K-fold cross validations are used to assess performance. Our main
contributions are extending J-K-fold CV from performance estimation to
parameter tuning and investigating how to choose J and K. We argue that
variability is more important than bias for effective tuning and so advocate
lower choices of K than are typically seen in the NLP literature, instead use
the saved computation to increase J. To demonstrate the generality of our
recommendations we investigate a wide range of case-studies: sentiment
classification (both general and target-specific), part-of-speech tagging and
document classification.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moss_H/0/1/0/all/0/1&quot;&gt;Henry B.Moss&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leslie_D/0/1/0/all/0/1&quot;&gt;David S.Leslie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rayson_P/0/1/0/all/0/1&quot;&gt;Paul Rayson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.07174">
<title>FRnet-DTI: Convolutional Neural Networks for Drug-Target Interaction. (arXiv:1806.07174v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.07174</link>
<description rdf:parseType="Literal">&lt;p&gt;The task of drug-target interaction prediction holds significant importance
in pharmacology and therapeutic drug design. In this paper, we present
FRnet-DTI, an auto encoder and a convolutional classifier for feature
manipulation and drug target interaction prediction. Two convolutional neural
neworks are proposed where one model is used for feature manipulation and the
other one for classification. Using the first method FRnet-1, we generate 4096
features for each of the instances in each of the datasets and use the second
method, FRnet-2, to identify interaction probability employing those features.
We have tested our method on four gold standard datasets exhaustively used by
other researchers. Experimental results shows that our method significantly
improves over the state-of-the-art method on three of the four drug-target
interaction gold standard datasets on both area under curve for Receiver
Operating Characteristic(auROC) and area under Precision Recall curve(auPR)
metric. We also introduce twenty new potential drug-target pairs for
interaction based on high prediction scores. Codes Available: https: // github.
com/ farshidrayhanuiu/ FRnet-DTI/ Web Implementation: http: // farshidrayhan.
pythonanywhere. com/ FRnet-DTI/
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rayhana_F/0/1/0/all/0/1&quot;&gt;Farshid Rayhana&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ahmed_S/0/1/0/all/0/1&quot;&gt;Sajid Ahmed&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mousavian_Z/0/1/0/all/0/1&quot;&gt;Zaynab Mousavian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Farid_D/0/1/0/all/0/1&quot;&gt;Dewan Md Farid&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shatabda_S/0/1/0/all/0/1&quot;&gt;Swakkhar Shatabda&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.07190">
<title>Stable Gaussian Process based Tracking Control of Euler-Lagrange Systems. (arXiv:1806.07190v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.07190</link>
<description rdf:parseType="Literal">&lt;p&gt;Perfect tracking control for real-world Euler-Lagrange systems is challenging
due to uncertainties in the system model and external disturbances. The
magnitude of the tracking error can be reduced either by increasing the
feedback gains or improving the model of the system. The latter is clearly
preferable as it allows to maintain good tracking performance at low feedback
gains. However, accurate models are often difficult to obtain. In this article,
we address the problem of high-performance tracking control for unknown
Euler-Lagrange systems. In particular, we employ Gaussian Process Regression
(GPR) to obtain a data-driven model that is used for the feed-forward
compensation of unknown dynamics of the system. Beneficially, GPR provides not
only an estimate of the uncertainties, but naturally provides a measure of
model confidence depending on the distance to training points. Accordingly, the
feedback gain is adapted based on the model fidelity allowing low feedback
gains in state space regions of high model confidence. Additionally, we study
the stability of GP-based tracking control for Euler-Lagrange systems. The
proposed confidence-adaptive feedback control law guarantees a globally bounded
tracking error with a specific probability. Simulation studies illustrate the
results and demonstrate the superiority over state of the art tracking control
approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Beckers_T/0/1/0/all/0/1&quot;&gt;Thomas Beckers&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kulic_D/0/1/0/all/0/1&quot;&gt;Dana Kuli&amp;#x107;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hirche_S/0/1/0/all/0/1&quot;&gt;Sandra Hirche&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.07200">
<title>Unsupervised Imitation Learning. (arXiv:1806.07200v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.07200</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce a novel method to learn a policy from unsupervised
demonstrations of a process. Given a model of the system and a set of sequences
of outputs, we find a policy that has a comparable performance to the original
policy, without requiring access to the inputs of these demonstrations. We do
so by first estimating the inputs of the system from observed unsupervised
demonstrations. Then, we learn a policy by applying vanilla supervised learning
algorithms to the (estimated)input-output pairs. For the input estimation, we
present a new adaptive linear estimator (AdaL-IE) that explicitly trades-off
variance and bias in the estimation. As we show empirically, AdaL-IE produces
estimates with lower error compared to the state-of-the-art input estimation
method, (UMV-IE) [Gillijns and De Moor, 2007]. Using AdaL-IE in conjunction
with imitation learning enables us to successfully learn control policies that
consistently outperform those using UMV-IE.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Curi_S/0/1/0/all/0/1&quot;&gt;Sebastian Curi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Levy_K/0/1/0/all/0/1&quot;&gt;Kfir Y. Levy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Krause_A/0/1/0/all/0/1&quot;&gt;Andreas Krause&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.07223">
<title>ASIC Implementation of Time-Domain Digital Backpropagation with Deep-Learned Chromatic Dispersion Filters. (arXiv:1806.07223v1 [cs.IT])</title>
<link>http://arxiv.org/abs/1806.07223</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider time-domain digital backpropagation with chromatic dispersion
filters jointly optimized and quantized using machine-learning techniques.
Compared to the baseline implementations, we show improved BER performance and
&amp;gt;40% power dissipation reductions in 28-nm CMOS.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fougstedt_C/0/1/0/all/0/1&quot;&gt;Christoffer Fougstedt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hager_C/0/1/0/all/0/1&quot;&gt;Christian H&amp;#xe4;ger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Svensson_L/0/1/0/all/0/1&quot;&gt;Lars Svensson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pfister_H/0/1/0/all/0/1&quot;&gt;Henry D. Pfister&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Larsson_Edefors_P/0/1/0/all/0/1&quot;&gt;Per Larsson-Edefors&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.07307">
<title>Estimation from Non-Linear Observations via Convex Programming with Application to Bilinear Regression. (arXiv:1806.07307v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.07307</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a computationally efficient estimator, formulated as a convex
program, for a broad class of non-linear regression problems that involve
difference of convex (DC) non-linearities. The proposed method can be viewed as
a significant extension of the &quot;anchored regression&quot; method formulated and
analyzed in [9] for regression with convex non-linearities. Our main
assumption, in addition to other mild statistical and computational
assumptions, is availability of a certain approximation oracle for the average
of the gradients of the observation functions at a ground truth. Under this
assumption and using a PAC-Bayesian analysis we show that the proposed
estimator produces an accurate estimate with high probability. As a concrete
example, we study the proposed framework in the bilinear regression problem
with Gaussian factors and quantify a sufficient sample complexity for exact
recovery. Furthermore, we describe a computationally tractable scheme that
provably produces the required approximation oracle in the considered bilinear
regression problem.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bahmani_S/0/1/0/all/0/1&quot;&gt;Sohail Bahmani&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.07348">
<title>Statistical Optimal Transport via Geodesic Hubs. (arXiv:1806.07348v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.07348</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a new method to estimate Wasserstein distances and optimal
transport plans between two probability distributions from samples in
high-dimension. Unlike plug-in rules that simply replace the true distributions
by their empirical counterpart, we propose a new regularization method that
leverages the clustered nature of data that is often encountered in practice.
Our theoretical results indicate that this method overcomes the curse of
dimensionality. This theoretical guarantee is supported by numerical
experiments on high-dimensional data for various tasks, including domain
adaptation in single-cell RNA sequencing data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Forrow_A/0/1/0/all/0/1&quot;&gt;Aden Forrow&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hutter_J/0/1/0/all/0/1&quot;&gt;Jan-Christian H&amp;#xfc;tter&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Nitzan_M/0/1/0/all/0/1&quot;&gt;Mor Nitzan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Schiebinger_G/0/1/0/all/0/1&quot;&gt;Geoffrey Schiebinger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rigollet_P/0/1/0/all/0/1&quot;&gt;Philippe Rigollet&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Weed_J/0/1/0/all/0/1&quot;&gt;Jonathan Weed&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.07353">
<title>Faster SGD training by minibatch persistency. (arXiv:1806.07353v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.07353</link>
<description rdf:parseType="Literal">&lt;p&gt;It is well known that, for most datasets, the use of large-size minibatches
for Stochastic Gradient Descent (SGD) typically leads to slow convergence and
poor generalization. On the other hand, large minibatches are of great
practical interest as they allow for a better exploitation of modern GPUs.
Previous literature on the subject concentrated on how to adjust the main SGD
parameters (in particular, the learning rate) when using large minibatches. In
this work we introduce an additional feature, that we call minibatch
persistency, that consists in reusing the same minibatch for K consecutive SGD
iterations. The computational conjecture here is that a large minibatch
contains a significant sample of the training set, so one can afford to
slightly overfitting it without worsening generalization too much. The approach
is intended to speedup SGD convergence, and also has the advantage of reducing
the overhead related to data loading on the internal GPU memory. We present
computational results on CIFAR-10 with an AlexNet architecture, showing that
even small persistency values (K=2 or 5) already lead to a significantly faster
convergence and to a comparable (or even better) generalization than the
standard &quot;disposable minibatch&quot; approach (K=1), in particular when large
minibatches are used. The lesson learned is that minibatch persistency can be a
simple yet effective way to deal with large minibatches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fischetti_M/0/1/0/all/0/1&quot;&gt;Matteo Fischetti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mandatelli_I/0/1/0/all/0/1&quot;&gt;Iacopo Mandatelli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Salvagnin_D/0/1/0/all/0/1&quot;&gt;Domenico Salvagnin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.07373">
<title>Few-Shot Segmentation Propagation with Guided Networks. (arXiv:1806.07373v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1806.07373</link>
<description rdf:parseType="Literal">&lt;p&gt;Learning-based methods for visual segmentation have made progress on
particular types of segmentation tasks, but are limited by the necessary
supervision, the narrow definitions of fixed tasks, and the lack of control
during inference for correcting errors. To remedy the rigidity and annotation
burden of standard approaches, we address the problem of few-shot segmentation:
given few image and few pixel supervision, segment any images accordingly. We
propose guided networks, which extract a latent task representation from any
amount of supervision, and optimize our architecture end-to-end for fast,
accurate few-shot segmentation. Our method can switch tasks without further
optimization and quickly update when given more guidance. We report the first
results for segmentation from one pixel per concept and show real-time
interactive video segmentation. Our unified approach propagates pixel
annotations across space for interactive segmentation, across time for video
segmentation, and across scenes for semantic segmentation. Our guided segmentor
is state-of-the-art in accuracy for the amount of annotation and time. See
&lt;a href=&quot;http://github.com/shelhamer/revolver&quot;&gt;this http URL&lt;/a&gt; for code, models, and more details.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rakelly_K/0/1/0/all/0/1&quot;&gt;Kate Rakelly&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shelhamer_E/0/1/0/all/0/1&quot;&gt;Evan Shelhamer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Darrell_T/0/1/0/all/0/1&quot;&gt;Trevor Darrell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Efros_A/0/1/0/all/0/1&quot;&gt;Alexei A. Efros&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1&quot;&gt;Sergey Levine&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1603.06560">
<title>Hyperband: A Novel Bandit-Based Approach to Hyperparameter Optimization. (arXiv:1603.06560v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1603.06560</link>
<description rdf:parseType="Literal">&lt;p&gt;Performance of machine learning algorithms depends critically on identifying
a good set of hyperparameters. While recent approaches use Bayesian
optimization to adaptively select configurations, we focus on speeding up
random search through adaptive resource allocation and early-stopping. We
formulate hyperparameter optimization as a pure-exploration non-stochastic
infinite-armed bandit problem where a predefined resource like iterations, data
samples, or features is allocated to randomly sampled configurations. We
introduce a novel algorithm, Hyperband, for this framework and analyze its
theoretical properties, providing several desirable guarantees. Furthermore, we
compare Hyperband with popular Bayesian optimization methods on a suite of
hyperparameter optimization problems. We observe that Hyperband can provide
over an order-of-magnitude speedup over our competitor set on a variety of
deep-learning and kernel-based learning problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1&quot;&gt;Lisha Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jamieson_K/0/1/0/all/0/1&quot;&gt;Kevin Jamieson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+DeSalvo_G/0/1/0/all/0/1&quot;&gt;Giulia DeSalvo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rostamizadeh_A/0/1/0/all/0/1&quot;&gt;Afshin Rostamizadeh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Talwalkar_A/0/1/0/all/0/1&quot;&gt;Ameet Talwalkar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1612.09413">
<title>Permuted and Augmented Stick-Breaking Bayesian Multinomial Regression. (arXiv:1612.09413v3 [stat.ME] UPDATED)</title>
<link>http://arxiv.org/abs/1612.09413</link>
<description rdf:parseType="Literal">&lt;p&gt;To model categorical response variables given their covariates, we propose a
permuted and augmented stick-breaking (paSB) construction that one-to-one maps
the observed categories to randomly permuted latent sticks. This new
construction transforms multinomial regression into regression analysis of
stick-specific binary random variables that are mutually independent given
their covariate-dependent stick success probabilities, which are parameterized
by the regression coefficients of their corresponding categories. The paSB
construction allows transforming an arbitrary cross-entropy-loss binary
classifier into a Bayesian multinomial one. Specifically, we parameterize the
negative logarithms of the stick failure probabilities with a family of
covariate-dependent softplus functions to construct nonparametric Bayesian
multinomial softplus regression, and transform Bayesian support vector machine
(SVM) into Bayesian multinomial SVM. These Bayesian multinomial regression
models are not only capable of providing probability estimates, quantifying
uncertainty, increasing robustness, and producing nonlinear classification
decision boundaries, but also amenable to posterior simulation. Example results
demonstrate their attractive properties and performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhang_Q/0/1/0/all/0/1&quot;&gt;Quan Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhou_M/0/1/0/all/0/1&quot;&gt;Mingyuan Zhou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1702.06234">
<title>Easily parallelizable and distributable class of algorithms for structured sparsity, with optimal acceleration. (arXiv:1702.06234v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1702.06234</link>
<description rdf:parseType="Literal">&lt;p&gt;Many statistical learning problems can be posed as minimization of a sum of
two convex functions, one typically a composition of non-smooth and linear
functions. Examples include regression under structured sparsity assumptions.
Popular algorithms for solving such problems, e.g., ADMM, often involve
non-trivial optimization subproblems or smoothing approximation. We consider
two classes of primal-dual algorithms that do not incur these difficulties, and
unify them from a perspective of monotone operator theory. From this
unification we propose a continuum of preconditioned forward-backward operator
splitting algorithms amenable to parallel and distributed computing. For the
entire region of convergence of the whole continuum of algorithms, we establish
its rates of convergence. For some known instances of this continuum, our
analysis closes the gap in theory. We further exploit the unification to
propose a continuum of accelerated algorithms. We show that the whole continuum
attains the theoretically optimal rate of convergence. The scalability of the
proposed algorithms, as well as their convergence behavior, is demonstrated up
to 1.2 million variables with a distributed implementation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ko_S/0/1/0/all/0/1&quot;&gt;Seyoon Ko&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yu_D/0/1/0/all/0/1&quot;&gt;Donghyeon Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Won_J/0/1/0/all/0/1&quot;&gt;Joong-Ho Won&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1702.06240">
<title>Simultaneous Inference for Best Linear Predictor of the Conditional Average Treatment Effect and Other Structural Functions. (arXiv:1702.06240v2 [stat.ME] UPDATED)</title>
<link>http://arxiv.org/abs/1702.06240</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper provides estimation and inference methods for a structural
function, such as Conditional Average Treatment Effect (CATE), based on modern
machine learning (ML) tools. We assume that such function can be represented as
an expectation g(x) of a signal Y conditional on X that depends on an unknown
nuisance function. In addition to CATE, examples of such functions include
regression function with Partially Missing Outcome and Conditional Average
Partial Derivative. We approximate g(x) by a linear form that is a product of a
vector of the approximating basis functions p(x) and the Best Linear Predictor
(BLP), which we refer to a pseudo-target. Plugging in the first-stage estimate
of the nuisance function into the signal, we estimate BLP via ordinary least
squares. We deliver a high-quality estimate of the pseudo-target function that
features (a) a pointwise Gaussian approximation, (b) a simultaneous Gaussian
approximation, and (c) optimal rate of simultaneous convergence. In the case,
the misspecification error of the linear form decays sufficiently fast, these
approximations automatically hold for the target function g(x) instead of a
pseudo-target. The first stage nuisance parameter is allowed to be
high-dimensional and is estimated by modern ML tools, such as neural networks,
shrinkage estimators, and random forest. Using our method, we estimate the
average price elasticity conditional on income using Yatchew and No (2001) data
and provide simultaneous confidence bands for the target regression function.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chernozhukov_V/0/1/0/all/0/1&quot;&gt;Victor Chernozhukov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Semenova_V/0/1/0/all/0/1&quot;&gt;Vira Semenova&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.10951">
<title>SGDLibrary: A MATLAB library for stochastic gradient descent algorithms. (arXiv:1710.10951v2 [cs.MS] UPDATED)</title>
<link>http://arxiv.org/abs/1710.10951</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the problem of finding the minimizer of a function $f:
\mathbb{R}^d \rightarrow \mathbb{R}$ of the finite-sum form $\min f(w) =
1/n\sum_{i}^n f_i(w)$. This problem has been studied intensively in recent
years in the field of machine learning (ML). One promising approach for
large-scale data is to use a stochastic optimization algorithm to solve the
problem. SGDLibrary is a readable, flexible and extensible pure-MATLAB library
of a collection of stochastic optimization algorithms. The purpose of the
library is to provide researchers and implementers a comprehensive evaluation
environment for the use of these algorithms on various ML problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kasai_H/0/1/0/all/0/1&quot;&gt;Hiroyuki Kasai&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.05654">
<title>Catalyst Acceleration for First-order Convex Optimization: from Theory to Practice. (arXiv:1712.05654v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1712.05654</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce a generic scheme for accelerating gradient-based optimization
methods in the sense of Nesterov. The approach, called Catalyst, builds upon
the inexact accelerated proximal point algorithm for minimizing a convex
objective function, and consists of approximately solving a sequence of
well-chosen auxiliary problems, leading to faster convergence. One of the keys
to achieve acceleration in theory and in practice is to solve these
sub-problems with appropriate accuracy by using the right stopping criterion
and the right warm-start strategy. We give practical guidelines to use Catalyst
and present a comprehensive analysis of its global complexity. We show that
Catalyst applies to a large class of algorithms, including gradient descent,
block coordinate descent, incremental algorithms such as SAG, SAGA, SDCA, SVRG,
MISO/Finito, and their proximal variants. For all of these methods, we
establish faster rates using the Catalyst acceleration, for strongly convex and
non-strongly convex objectives. We conclude with extensive experiments showing
that acceleration is useful in practice, especially for ill-conditioned
problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lin_H/0/1/0/all/0/1&quot;&gt;Hongzhou Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mairal_J/0/1/0/all/0/1&quot;&gt;Julien Mairal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Harchaoui_Z/0/1/0/all/0/1&quot;&gt;Zaid Harchaoui&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.04695">
<title>Sparsity-based Defense against Adversarial Attacks on Linear Classifiers. (arXiv:1801.04695v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1801.04695</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep neural networks represent the state of the art in machine learning in a
growing number of fields, including vision, speech and natural language
processing. However, recent work raises important questions about the
robustness of such architectures, by showing that it is possible to induce
classification errors through tiny, almost imperceptible, perturbations.
Vulnerability to such &quot;adversarial attacks&quot;, or &quot;adversarial examples&quot;, has
been conjectured to be due to the excessive linearity of deep networks. In this
paper, we study this phenomenon in the setting of a linear classifier, and show
that it is possible to exploit sparsity in natural data to combat
$\ell_{\infty}$-bounded adversarial perturbations. Specifically, we demonstrate
the efficacy of a sparsifying front end via an ensemble averaged analysis, and
experimental results for the MNIST handwritten digit database. To the best of
our knowledge, this is the first work to show that sparsity provides a
theoretically rigorous framework for defense against adversarial attacks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Marzi_Z/0/1/0/all/0/1&quot;&gt;Zhinus Marzi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gopalakrishnan_S/0/1/0/all/0/1&quot;&gt;Soorya Gopalakrishnan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Madhow_U/0/1/0/all/0/1&quot;&gt;Upamanyu Madhow&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pedarsani_R/0/1/0/all/0/1&quot;&gt;Ramtin Pedarsani&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06894">
<title>Learning Hidden Markov Models from Pairwise Co-occurrences with Application to Topic Modeling. (arXiv:1802.06894v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1802.06894</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a new algorithm for identifying the transition and emission
probabilities of a hidden Markov model (HMM) from the emitted data.
Expectation-maximization becomes computationally prohibitive for long
observation records, which are often required for identification. The new
algorithm is particularly suitable for cases where the available sample size is
large enough to accurately estimate second-order output probabilities, but not
higher-order ones. We show that if one is only able to obtain a reliable
estimate of the pairwise co-occurrence probabilities of the emissions, it is
still possible to uniquely identify the HMM if the emission probability is
\emph{sufficiently scattered}. We apply our method to hidden topic Markov
modeling, and demonstrate that we can learn topics with higher quality if
documents are modeled as observations of HMMs sharing the same emission (topic)
probability, compared to the simple but widely used bag-of-words model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1&quot;&gt;Kejun Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fu_X/0/1/0/all/0/1&quot;&gt;Xiao Fu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sidiropoulos_N/0/1/0/all/0/1&quot;&gt;Nicholas D. Sidiropoulos&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08898">
<title>Dimensionally Tight Bounds for Second-Order Hamiltonian Monte Carlo. (arXiv:1802.08898v2 [cs.DS] UPDATED)</title>
<link>http://arxiv.org/abs/1802.08898</link>
<description rdf:parseType="Literal">&lt;p&gt;Hamiltonian Monte Carlo (HMC) is a widely deployed method to sample from
high-dimensional distributions in Statistics and Machine learning. HMC is known
to run very efficiently in practice and its popular second-order &quot;leapfrog&quot;
implementation has long been conjectured to run in $d^{1/4}$ steps. Here we
show that this conjecture is true when sampling from strongly log-concave
target distributions that satisfy a weak third-order regularity property
associated with the input data. Our regularity condition is weaker than the
Lipschitz Hessian property and allows us to show faster running time bounds for
a much larger class of distributions than would be possible with the usual
Lipschitz Hessian constant alone. Important distributions that satisfy our
regularity condition include posterior distributions used in Bayesian logistic
regression for which the data satisfies an &quot;incoherence&quot; property. Our result
compares favorably with the best available running time bounds for the class of
strongly log-concave distributions, which grow like $d^{{1}/{2}}$ with the
dimension. Moreover, our simulations on synthetic data suggest that, when our
regularity condition is satisfied, the leapfrog HMC performs better than its
competitors -- both in terms of accuracy and running time.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mangoubi_O/0/1/0/all/0/1&quot;&gt;Oren Mangoubi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vishnoi_N/0/1/0/all/0/1&quot;&gt;Nisheeth K. Vishnoi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09514">
<title>Best Arm Identification for Contaminated Bandits. (arXiv:1802.09514v3 [math.ST] UPDATED)</title>
<link>http://arxiv.org/abs/1802.09514</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper studies active learning in the context of robust statistics.
Specifically, we propose a variant of the Best Arm Identification problem for
\emph{contaminated bandits}, where each arm pull has probability $\varepsilon$
of generating a sample from an arbitrary contamination distribution instead of
the true underlying distribution. The goal is to identify the best (or
approximately best) true distribution with high probability, with a secondary
goal of providing guarantees on the quality of this distribution. The primary
challenge of the contaminated bandit setting is that the true distributions are
only partially identifiable, even with infinite samples. We first present
tight, non-asymptotic sample complexity bounds for high-probability estimation
of the first two robust moments (median and median absolute deviation) from
contaminated samples, which may be of independent interest. Building on these
results, we adapt several classical Best Arm Identification algorithms to the
contaminated bandit setting and derive sample complexity upper bounds for our
problem. Finally, we provide matching information-theoretic lower bounds on the
sample complexity (up to a small logarithmic factor). Our results suggest an
inherent robustness of classical Best Arm Identification algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Altschuler_J/0/1/0/all/0/1&quot;&gt;Jason Altschuler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Brunel_V/0/1/0/all/0/1&quot;&gt;Victor-Emmanuel Brunel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Malek_A/0/1/0/all/0/1&quot;&gt;Alan Malek&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.10161">
<title>Stein Points. (arXiv:1803.10161v4 [stat.CO] UPDATED)</title>
<link>http://arxiv.org/abs/1803.10161</link>
<description rdf:parseType="Literal">&lt;p&gt;An important task in computational statistics and machine learning is to
approximate a posterior distribution $p(x)$ with an empirical measure supported
on a set of representative points $\{x_i\}_{i=1}^n$. This paper focuses on
methods where the selection of points is essentially deterministic, with an
emphasis on achieving accurate approximation when $n$ is small. To this end, we
present `Stein Points&apos;. The idea is to exploit either a greedy or a conditional
gradient method to iteratively minimise a kernel Stein discrepancy between the
empirical measure and $p(x)$. Our empirical results demonstrate that Stein
Points enable accurate approximation of the posterior at modest computational
cost. In addition, theoretical results are provided to establish convergence of
the method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chen_W/0/1/0/all/0/1&quot;&gt;Wilson Ye Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mackey_L/0/1/0/all/0/1&quot;&gt;Lester Mackey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gorham_J/0/1/0/all/0/1&quot;&gt;Jackson Gorham&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Briol_F/0/1/0/all/0/1&quot;&gt;Fran&amp;#xe7;ois-Xavier Briol&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Oates_C/0/1/0/all/0/1&quot;&gt;Chris J. Oates&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.06826">
<title>The Blessings of Multiple Causes. (arXiv:1805.06826v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1805.06826</link>
<description rdf:parseType="Literal">&lt;p&gt;Causal inference from observational data often assumes &quot;strong ignorability,&quot;
that all confounders are observed. This assumption is standard yet untestable.
However, many scientific studies involve multiple causes, different variables
whose effects are simultaneously of interest. We propose the deconfounder, an
algorithm that combines unsupervised machine learning and predictive model
checking to perform causal inference in multiple-cause settings. The
deconfounder infers a latent variable as a substitute for unobserved
confounders and then uses that substitute to perform causal inference. We
develop theory for when the deconfounder leads to unbiased causal estimates,
and show that it requires weaker assumptions than classical causal inference.
We analyze its performance in three types of studies: semi-simulated data
around smoking and lung cancer, semi-simulated data around genomewide
association studies, and a real dataset about actors and movie revenue. The
deconfounder provides a checkable approach to estimating close-to-truth causal
effects.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yixin Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Blei_D/0/1/0/all/0/1&quot;&gt;David M. Blei&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07836">
<title>Generalized Cross Entropy Loss for Training Deep Neural Networks with Noisy Labels. (arXiv:1805.07836v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.07836</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep neural networks (DNNs) have achieved tremendous success in a variety of
applications across many disciplines. Yet, their superior performance comes
with the expensive cost of requiring correctly annotated large-scale datasets.
Moreover, due to DNNs&apos; rich capacity, errors in training labels can hamper
performance. To combat this problem, mean absolute error (MAE) has recently
been proposed as a noise-robust alternative to the commonly-used categorical
cross entropy (CCE) loss. However, as we show in this paper, MAE can perform
poorly with DNNs and challenging datasets. Here, we present a theoretically
grounded set of noise-robust loss functions that can be seen as a
generalization of MAE and CCE. Proposed loss functions can be readily applied
with any existing DNN architecture and algorithm, while yielding good
performance in a wide range of noisy label scenarios. We report results from
experiments conducted with CIFAR-10, CIFAR-100 and FASHION-MNIST datasets and
synthetically generated noisy labels.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1&quot;&gt;Zhilu Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sabuncu_M/0/1/0/all/0/1&quot;&gt;Mert R. Sabuncu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04823">
<title>Plug-in Regularized Estimation of High-Dimensional Parameters in Nonlinear Semiparametric Models. (arXiv:1806.04823v2 [math.ST] UPDATED)</title>
<link>http://arxiv.org/abs/1806.04823</link>
<description rdf:parseType="Literal">&lt;p&gt;We develop a theory for estimation of a high-dimensional sparse parameter
$\theta$ defined as a minimizer of a population loss function $L_D(\theta,g_0)$
which, in addition to $\theta$, depends on a, potentially infinite dimensional,
nuisance parameter $g_0$. Our approach is based on estimating $\theta$ via an
$\ell_1$-regularized minimization of a sample analog of $L_S(\theta, \hat{g})$,
plugging in a first-stage estimate $\hat{g}$, computed on a hold-out sample. We
define a population loss to be (Neyman) orthogonal if the gradient of the loss
with respect to $\theta$, has pathwise derivative with respect to $g$ equal to
zero, when evaluated at the true parameter and nuisance component. We show that
orthogonality implies a second-order impact of the first stage nuisance error
on the second stage target parameter estimate. Our approach applies to both
convex and non-convex losses, albeit the latter case requires a small
adaptation of our method with a preliminary estimation step of the target
parameter. Our result enables oracle convergence rates for $\theta$ under
assumptions on the first stage rates, typically of the order of $n^{-1/4}$.
&lt;/p&gt;
&lt;p&gt;We show how such an orthogonal loss can be constructed via a novel
orthogonalization process for a general model defined by conditional moment
restrictions. We apply our theory to high-dimensional versions of standard
estimation problems in statistics and econometrics, such as: estimation of
conditional moment models with missing data, estimation of structural utilities
in games of incomplete information and estimation of treatment effects in
regression models with non-linear link functions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Chernozhukov_V/0/1/0/all/0/1&quot;&gt;Victor Chernozhukov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Nekipelov_D/0/1/0/all/0/1&quot;&gt;Denis Nekipelov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Semenova_V/0/1/0/all/0/1&quot;&gt;Vira Semenova&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Syrgkanis_V/0/1/0/all/0/1&quot;&gt;Vasilis Syrgkanis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05490">
<title>Inference in Deep Gaussian Processes using Stochastic Gradient Hamiltonian Monte Carlo. (arXiv:1806.05490v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1806.05490</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep Gaussian Processes (DGPs) are hierarchical generalizations of Gaussian
Processes that combine well calibrated uncertainty estimates with the high
flexibility of multilayer models. One of the biggest challenges with these
models is that exact inference is intractable. The current state-of-the-art
inference method, Variational Inference (VI), employs a Gaussian approximation
to the posterior distribution. This can be a potentially poor unimodal
approximation of the generally multimodal posterior. In this work, we provide
evidence for the non-Gaussian nature of the posterior and we apply the
Stochastic Gradient Hamiltonian Monte Carlo method to directly sample from it.
To efficiently optimize the hyperparameters, we introduce the Moving Window
MCEM algorithm. This results in significantly better predictions at a lower
computational cost than its VI counterpart. Thus our method establishes a new
state-of-the-art for inference in DGPs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Havasi_M/0/1/0/all/0/1&quot;&gt;Marton Havasi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hernandez_Lobato_J/0/1/0/all/0/1&quot;&gt;Jos&amp;#xe9; Miguel Hern&amp;#xe1;ndez-Lobato&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Murillo_Fuentes_J/0/1/0/all/0/1&quot;&gt;Juan Jos&amp;#xe9; Murillo-Fuentes&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05817">
<title>Safe Active Feature Selection for Sparse Learning. (arXiv:1806.05817v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1806.05817</link>
<description rdf:parseType="Literal">&lt;p&gt;We present safe active incremental feature selection~(SAIF) to scale up the
computation of LASSO solutions. SAIF does not require a solution from a heavier
penalty parameter as in sequential screening or updating the full model for
each iteration as in dynamic screening. Different from these existing screening
methods, SAIF starts from a small number of features and incrementally recruits
active features and updates the significantly reduced model. Hence, it is much
more computationally efficient and scalable with the number of features. More
critically, SAIF has the safe guarantee as it has the convergence guarantee to
the optimal solution to the original full LASSO problem. Such an incremental
procedure and theoretical convergence guarantee can be extended to fused LASSO
problems. Compared with state-of-the-art screening methods as well as working
set and homotopy methods, which may not always guarantee the optimal solution,
SAIF can achieve superior or comparable efficiency and high scalability with
the safe guarantee when facing extremely high dimensional data sets.
Experiments with both synthetic and real-world data sets show that SAIF can be
up to 50 times faster than dynamic screening, and hundreds of times faster than
computing LASSO or fused LASSO solutions without screening.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ren_S/0/1/0/all/0/1&quot;&gt;Shaogang Ren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1&quot;&gt;Jianhua Z. Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_S/0/1/0/all/0/1&quot;&gt;Shuai Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qian_X/0/1/0/all/0/1&quot;&gt;Xiaoning Qian&lt;/a&gt;</dc:creator>
</item></rdf:RDF>