<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Boring papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Bad Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-02-05T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.00938"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.00948"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.01016"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.01353"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.01548"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1707.08101"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.08116"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.00864"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.00923"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.00924"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.00927"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.00977"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.00981"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.01013"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.01177"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.01186"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.01274"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.01282"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.01435"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.01451"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.01482"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.01518"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.01526"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.01549"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.01557"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1506.08009"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.10903"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.07341"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.05931"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.05950"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.06294"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.09061"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.09354"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.00822"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.00926"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.01152"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.01301"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.01334"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.01458"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.01504"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1403.2310"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1602.04265"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1605.07950"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1707.01212"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.00379"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.01604"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.09710"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.08936"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.00393"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.07889"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1802.00938">
<title>Memory-Augmented Neural Networks for Predictive Process Analytics. (arXiv:1802.00938v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1802.00938</link>
<description rdf:parseType="Literal">&lt;p&gt;Process analytics involves a sophisticated layer of data analytics built over
the traditional notion of process mining. The flexible execution of business
process instances involves multiple critical decisions including what task to
perform next and what resources to allocate to a task. In this paper, we
explore the application of deep learning techniques for solving various process
analytics related problems. Based on recent advances in the field we
specifically look at memory-augmented neural networks (MANN)s and adapt the
latest model to date, namely the Differential Neural Computer. We introduce two
modifications to account for a variety of tasks in predictive process
analytics: (i) separating the encoding phase and decoding phase, resulting dual
controllers, one for each phase; (ii) implementing a write-protected policy for
the memory during the decoding phase. We demonstrate the feasibility and
usefulness of our approach by solving a number of common process analytics
tasks such as next activity prediction, time to completion and suffix
prediction. We also introduce the notion of MANN based process analytics
recommendation machinery that once deployed can serve as an effective business
process recommendation engine enabling organizations to answer various
prescriptive process analytics related questions.Using real-world datasets, we
benchmark our results against those obtained from the state-of-art methods. We
show that MANNs based process analytics methods can acheive state-of-the-art
performance and have a lot of value to offer for enterprise specific process
anlaytics applications.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khan_A/0/1/0/all/0/1&quot;&gt;Asjad Khan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Le_H/0/1/0/all/0/1&quot;&gt;Hung Le&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Do_K/0/1/0/all/0/1&quot;&gt;Kien Do&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tran_T/0/1/0/all/0/1&quot;&gt;Truyen Tran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghose_A/0/1/0/all/0/1&quot;&gt;Aditya Ghose&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dam_H/0/1/0/all/0/1&quot;&gt;Hoa Dam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sindhgatta_R/0/1/0/all/0/1&quot;&gt;Renuka Sindhgatta&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.00948">
<title>Resset: A Recurrent Model for Sequence of Sets with Applications to Electronic Medical Records. (arXiv:1802.00948v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1802.00948</link>
<description rdf:parseType="Literal">&lt;p&gt;Modern healthcare is ripe for disruption by AI. A game changer would be
automatic understanding the latent processes from electronic medical records,
which are being collected for billions of people worldwide. However, these
healthcare processes are complicated by the interaction between at least three
dynamic components: the illness which involves multiple diseases, the care
which involves multiple treatments, and the recording practice which is biased
and erroneous. Existing methods are inadequate in capturing the dynamic
structure of care. We propose Resset, an end-to-end recurrent model that reads
medical record and predicts future risk. The model adopts the algebraic view in
that discrete medical objects are embedded into continuous vectors lying in the
same space. We formulate the problem as modeling sequences of sets, a novel
setting that have rarely, if not, been addressed. Within Resset, the bag of
diseases recorded at each clinic visit is modeled as function of sets. The same
hold for the bag of treatments. The interaction between the disease bag and the
treatment bag at a visit is modeled in several, one of which as residual of
diseases minus the treatments. Finally, the health trajectory, which is a
sequence of visits, is modeled using a recurrent neural network. We report
results on over a hundred thousand hospital visits by patients suffered from
two costly chronic diseases -- diabetes and mental health. Resset shows
promises in multiple predictive tasks such as readmission prediction,
treatments recommendation and diseases progression.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_P/0/1/0/all/0/1&quot;&gt;Phuoc Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tran_T/0/1/0/all/0/1&quot;&gt;Truyen Tran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Venkatesh_S/0/1/0/all/0/1&quot;&gt;Svetha Venkatesh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.01016">
<title>An Area and Energy Efficient Design of Domain-Wall Memory-Based Deep Convolutional Neural Networks using Stochastic Computing. (arXiv:1802.01016v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1802.01016</link>
<description rdf:parseType="Literal">&lt;p&gt;With recent trend of wearable devices and Internet of Things (IoTs), it
becomes attractive to develop hardware-based deep convolutional neural networks
(DCNNs) for embedded applications, which require low power/energy consumptions
and small hardware footprints. Recent works demonstrated that the Stochastic
Computing (SC) technique can radically simplify the hardware implementation of
arithmetic units and has the potential to satisfy the stringent power
requirements in embedded devices. However, in these works, the memory design
optimization is neglected for weight storage, which will inevitably result in
large hardware cost. Moreover, if conventional volatile SRAM or DRAM cells are
utilized for weight storage, the weights need to be re-initialized whenever the
DCNN platform is re-started.
&lt;/p&gt;
&lt;p&gt;In order to overcome these limitations, in this work we adopt an emerging
non-volatile Domain-Wall Memory (DWM), which can achieve ultra-high density, to
replace SRAM for weight storage in SC-based DCNNs. We propose DW-CNN, the first
comprehensive design optimization framework of DWM-based weight storage method.
We derive the optimal memory type, precision, and organization, as well as
whether to store binary or stochastic numbers. We present effective resource
sharing scheme for DWM-based weight storage in the convolutional and
fully-connected layers of SC-based DCNNs to achieve a desirable balance among
area, power (energy) consumption, and application-level accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1&quot;&gt;Xiaolong Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yipeng Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yuan_G/0/1/0/all/0/1&quot;&gt;Geng Yuan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ren_A/0/1/0/all/0/1&quot;&gt;Ao Ren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Zhe Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Han_J/0/1/0/all/0/1&quot;&gt;Jie Han&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_J/0/1/0/all/0/1&quot;&gt;Jingtong Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yanzhi Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.01353">
<title>Lie Transform Based Polynomial Neural Networks for Dynamical Systems Simulation and Identification. (arXiv:1802.01353v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1802.01353</link>
<description rdf:parseType="Literal">&lt;p&gt;In the article, we discuss the architecture of the polynomial neural network
that corresponds to the matrix representation of Lie transform. The matrix form
of Lie transform is an approximation of general solution for the nonlinear
system of ordinary differential equations. Thus, it can be used for simulation
and modeling task. On the other hand, one can identify dynamical system from
time series data simply by optimization of the coefficient matrices of the Lie
transform. Representation of the approach by polynomial neural networks
integrates the strength of both neural networks and traditional model-based
methods for dynamical systems investigation. We provide a theoretical
explanation of learning dynamical systems from time series for the proposed
method, as well as demonstrate it in several applications. Namely, we show
results of modeling and identification for both well-known systems like
Lotka-Volterra equation and more complicated examples from retail,
biochemistry, and accelerator physics.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ivanov_A/0/1/0/all/0/1&quot;&gt;Andrei Ivanov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Andrianov_S/0/1/0/all/0/1&quot;&gt;Sergei Andrianov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sholokhova_A/0/1/0/all/0/1&quot;&gt;Alena Sholokhova&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.01548">
<title>Regularized Evolution for Image Classifier Architecture Search. (arXiv:1802.01548v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1802.01548</link>
<description rdf:parseType="Literal">&lt;p&gt;The effort devoted to hand-crafting image classifiers has motivated the use
of architecture search to discover them automatically. Reinforcement learning
and evolution have both shown promise for this purpose. This study introduces a
regularized version of a popular asynchronous evolutionary algorithm. We
rigorously compare it to the non-regularized form and to a highly-successful
reinforcement learning baseline. Using the same hardware, compute effort and
neural network training code, we conduct repeated experiments side-by-side,
exploring different datasets, search spaces and scales. We show regularized
evolution consistently produces models with similar or higher accuracy, across
a variety of contexts without need for re-tuning parameters. In addition,
regularized evolution exhibits considerably better performance than
reinforcement learning at early search stages, suggesting it may be the better
choice when fewer compute resources are available. This constitutes the first
controlled comparison of the two search algorithms in this context. Finally, we
present new architectures discovered with regularized evolution that we
nickname AmoebaNets. These models set a new state of the art for CIFAR-10 (mean
test error = 2.13%) and mobile-size ImageNet (top-5 accuracy = 92.1% with 5.06M
parameters), and reach the current state of the art for ImageNet (top-5
accuracy = 96.2%).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Real_E/0/1/0/all/0/1&quot;&gt;Esteban Real&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aggarwal_A/0/1/0/all/0/1&quot;&gt;Alok Aggarwal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1&quot;&gt;Yanping Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Le_Q/0/1/0/all/0/1&quot;&gt;Quoc V Le&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1707.08101">
<title>Learning to Singulate Objects using a Push Proposal Network. (arXiv:1707.08101v2 [cs.RO] UPDATED)</title>
<link>http://arxiv.org/abs/1707.08101</link>
<description rdf:parseType="Literal">&lt;p&gt;Learning to act in unstructured environments, such as cluttered piles of
objects, poses a substantial challenge for manipulation robots. We present a
novel neural network-based approach that separates unknown objects in clutter
by selecting favourable push actions. Our network is trained from data
collected through autonomous interaction of a PR2 robot with randomly organized
tabletop scenes. The model is designed to propose meaningful push actions based
on over-segmented RGB-D images. We evaluate our approach by singulating up to 8
unknown objects in clutter. We demonstrate that our method enables the robot to
perform the task with a high success rate and a low number of required push
actions. Our results based on real-world experiments show that our network is
able to generalize to novel objects of various sizes and shapes, as well as to
arbitrary object configurations. Videos of our experiments can be viewed at
&lt;a href=&quot;http://robotpush.cs.uni-freiburg.de&quot;&gt;this http URL&lt;/a&gt;
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Eitel_A/0/1/0/all/0/1&quot;&gt;Andreas Eitel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hauff_N/0/1/0/all/0/1&quot;&gt;Nico Hauff&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Burgard_W/0/1/0/all/0/1&quot;&gt;Wolfram Burgard&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.08116">
<title>Psychlab: A Psychology Laboratory for Deep Reinforcement Learning Agents. (arXiv:1801.08116v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1801.08116</link>
<description rdf:parseType="Literal">&lt;p&gt;Psychlab is a simulated psychology laboratory inside the first-person 3D game
world of DeepMind Lab (Beattie et al. 2016). Psychlab enables implementations
of classical laboratory psychological experiments so that they work with both
human and artificial agents. Psychlab has a simple and flexible API that
enables users to easily create their own tasks. As examples, we are releasing
Psychlab implementations of several classical experimental paradigms including
visual search, change detection, random dot motion discrimination, and multiple
object tracking. We also contribute a study of the visual psychophysics of a
specific state-of-the-art deep reinforcement learning agent: UNREAL (Jaderberg
et al. 2016). This study leads to the surprising conclusion that UNREAL learns
more quickly about larger target stimuli than it does about smaller stimuli. In
turn, this insight motivates a specific improvement in the form of a simple
model of foveal vision that turns out to significantly boost UNREAL&apos;s
performance, both on Psychlab tasks, and on standard DeepMind Lab tasks. By
open-sourcing Psychlab we hope to facilitate a range of future such studies
that simultaneously advance deep reinforcement learning and improve its links
with cognitive science.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leibo_J/0/1/0/all/0/1&quot;&gt;Joel Z. Leibo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+dAutume_C/0/1/0/all/0/1&quot;&gt;Cyprien de Masson d&amp;#x27;Autume&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zoran_D/0/1/0/all/0/1&quot;&gt;Daniel Zoran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Amos_D/0/1/0/all/0/1&quot;&gt;David Amos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Beattie_C/0/1/0/all/0/1&quot;&gt;Charles Beattie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Anderson_K/0/1/0/all/0/1&quot;&gt;Keith Anderson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Castaneda_A/0/1/0/all/0/1&quot;&gt;Antonio Garc&amp;#xed;a Casta&amp;#xf1;eda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sanchez_M/0/1/0/all/0/1&quot;&gt;Manuel Sanchez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Green_S/0/1/0/all/0/1&quot;&gt;Simon Green&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gruslys_A/0/1/0/all/0/1&quot;&gt;Audrunas Gruslys&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Legg_S/0/1/0/all/0/1&quot;&gt;Shane Legg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hassabis_D/0/1/0/all/0/1&quot;&gt;Demis Hassabis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Botvinick_M/0/1/0/all/0/1&quot;&gt;Matthew M. Botvinick&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.00864">
<title>Onto2Vec: joint vector-based representation of biological entities and their ontology-based annotations. (arXiv:1802.00864v1 [q-bio.QM])</title>
<link>http://arxiv.org/abs/1802.00864</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose the Onto2Vec method, an approach to learn feature vectors for
biological entities based on their annotations to biomedical ontologies. Our
method can be applied to a wide range of bioinformatics research problems such
as similarity-based prediction of interactions between proteins, classification
of interaction types using supervised learning, or clustering.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Smaili_F/0/1/0/all/0/1&quot;&gt;Fatima Zohra Smaili&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Gao_X/0/1/0/all/0/1&quot;&gt;Xin Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Hoehndorf_R/0/1/0/all/0/1&quot;&gt;Robert Hoehndorf&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.00923">
<title>Multi-attention Recurrent Network for Human Communication Comprehension. (arXiv:1802.00923v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.00923</link>
<description rdf:parseType="Literal">&lt;p&gt;Human face-to-face communication is a complex multimodal signal. We use words
(language modality), gestures (vision modality) and changes in tone (acoustic
modality) to convey our intentions. Humans easily process and understand
face-to-face communication, however, comprehending this form of communication
remains a significant challenge for Artificial Intelligence (AI). AI must
understand each modality and the interactions between them that shape human
communication. In this paper, we present a novel neural architecture for
understanding human communication called the Multi-attention Recurrent Network
(MARN). The main strength of our model comes from discovering interactions
between modalities through time using a neural component called the
Multi-attention Block (MAB) and storing them in the hybrid memory of a
recurrent component called the Long-short Term Hybrid Memory (LSTHM). We
perform extensive comparisons on six publicly available datasets for multimodal
sentiment analysis, speaker trait recognition and emotion recognition. MARN
shows state-of-the-art performance on all the datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zadeh_A/0/1/0/all/0/1&quot;&gt;Amir Zadeh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_P/0/1/0/all/0/1&quot;&gt;Paul Pu Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Poria_S/0/1/0/all/0/1&quot;&gt;Soujanya Poria&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vij_P/0/1/0/all/0/1&quot;&gt;Prateek Vij&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cambria_E/0/1/0/all/0/1&quot;&gt;Erik Cambria&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Morency_L/0/1/0/all/0/1&quot;&gt;Louis-Philippe Morency&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.00924">
<title>Multimodal Sentiment Analysis with Word-Level Fusion and Reinforcement Learning. (arXiv:1802.00924v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.00924</link>
<description rdf:parseType="Literal">&lt;p&gt;With the increasing popularity of video sharing websites such as YouTube and
Facebook, multimodal sentiment analysis has received increasing attention from
the scientific community. Contrary to previous works in multimodal sentiment
analysis which focus on holistic information in speech segments such as bag of
words representations and average facial expression intensity, we develop a
novel deep architecture for multimodal sentiment analysis that performs
modality fusion at the word level. In this paper, we propose the Gated
Multimodal Embedding LSTM with Temporal Attention (GME-LSTM(A)) model that is
composed of 2 modules. The Gated Multimodal Embedding alleviates the
difficulties of fusion when there are noisy modalities. The LSTM with Temporal
Attention performs word level fusion at a finer fusion resolution between input
modalities and attends to the most important time steps. As a result, the
GME-LSTM(A) is able to better model the multimodal structure of speech through
time and perform better sentiment comprehension. We demonstrate the
effectiveness of this approach on the publicly-available Multimodal Corpus of
Sentiment Intensity and Subjectivity Analysis (CMU-MOSI) dataset by achieving
state-of-the-art sentiment classification and regression results. Qualitative
analysis on our model emphasizes the importance of the Temporal Attention Layer
in sentiment prediction because the additional acoustic and visual modalities
are noisy. We also demonstrate the effectiveness of the Gated Multimodal
Embedding in selectively filtering these noisy modalities out. Our results and
analysis open new areas in the study of sentiment analysis in human
communication and provide new models for multimodal fusion.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_M/0/1/0/all/0/1&quot;&gt;Minghai Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1&quot;&gt;Sen Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_P/0/1/0/all/0/1&quot;&gt;Paul Pu Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Baltrusaitis_T/0/1/0/all/0/1&quot;&gt;Tadas Baltru&amp;#x161;aitis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zadeh_A/0/1/0/all/0/1&quot;&gt;Amir Zadeh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Morency_L/0/1/0/all/0/1&quot;&gt;Louis-Philippe Morency&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.00927">
<title>Memory Fusion Network for Multi-view Sequential Learning. (arXiv:1802.00927v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.00927</link>
<description rdf:parseType="Literal">&lt;p&gt;Multi-view sequential learning is a fundamental problem in machine learning
dealing with multi-view sequences. In a multi-view sequence, there exists two
forms of interactions between different views: view-specific interactions and
cross-view interactions. In this paper, we present a new neural architecture
for multi-view sequential learning called the Memory Fusion Network (MFN) that
explicitly accounts for both interactions in a neural architecture and
continuously models them through time. The first component of the MFN is called
the System of LSTMs, where view-specific interactions are learned in isolation
through assigning an LSTM function to each view. The cross-view interactions
are then identified using a special attention mechanism called the Delta-memory
Attention Network (DMAN) and summarized through time with a Multi-view Gated
Memory. Through extensive experimentation, MFN is compared to various proposed
approaches for multi-view sequential learning on multiple publicly available
benchmark datasets. MFN outperforms all the existing multi-view approaches.
Furthermore, MFN outperforms all current state-of-the-art models, setting new
state-of-the-art results for these multi-view datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zadeh_A/0/1/0/all/0/1&quot;&gt;Amir Zadeh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_P/0/1/0/all/0/1&quot;&gt;Paul Pu Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mazumder_N/0/1/0/all/0/1&quot;&gt;Navonil Mazumder&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Poria_S/0/1/0/all/0/1&quot;&gt;Soujanya Poria&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cambria_E/0/1/0/all/0/1&quot;&gt;Erik Cambria&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Morency_L/0/1/0/all/0/1&quot;&gt;Louis-Philippe Morency&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.00977">
<title>Pose Flow: Efficient Online Pose Tracking. (arXiv:1802.00977v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1802.00977</link>
<description rdf:parseType="Literal">&lt;p&gt;Multi-person articulated pose tracking in complex unconstrained videos is an
important and challenging problem. In this paper, going along the road of
top-down approaches, we propose a decent and efficient pose tracker based on
pose flows. First, we design an online optimization framework to build
association of cross-frame poses and form pose flows. Second, a novel pose flow
non maximum suppression (NMS) is designed to robustly reduce redundant pose
flows and re-link temporal disjoint pose flows. Extensive experiments show our
method significantly outperforms best reported results on two standard Pose
Tracking datasets (PoseTrack dataset and PoseTrack Challenge dataset) by 13 mAP
25 MOTA and 6 mAP 3 MOTA respectively. Moreover, in the case of working on
detected poses in individual frames, the extra computation of proposed pose
tracker is very minor, requiring 0.01 second per frame only.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiu_Y/0/1/0/all/0/1&quot;&gt;Yuliang Xiu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jiefeng Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_H/0/1/0/all/0/1&quot;&gt;Haoyu Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fang_Y/0/1/0/all/0/1&quot;&gt;Yinghong Fang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_C/0/1/0/all/0/1&quot;&gt;Cewu Lu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.00981">
<title>Adaptive Representation Selection in Contextual Bandit with Unlabeled History. (arXiv:1802.00981v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.00981</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider an extension of the contextual bandit setting, motivated by
several practical applications, where an unlabeled history of contexts can
become available for pre-training before the online decision-making begins. We
propose an approach for improving the performance of contextual bandit in such
setting, via adaptive, dynamic representation learning, which combines offline
pre-training on unlabeled history of contexts with online selection and
modification of embedding functions. Our experiments on a variety of datasets
and in different nonstationary environments demonstrate clear advantages of our
approach over the standard contextual bandit.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_B/0/1/0/all/0/1&quot;&gt;Baihan Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cecchi_G/0/1/0/all/0/1&quot;&gt;Guillermo Cecchi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bouneffouf_D/0/1/0/all/0/1&quot;&gt;Djallel Bouneffouf&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rish_I/0/1/0/all/0/1&quot;&gt;Irina Rish&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.01013">
<title>Plan Explanations as Model Reconciliation -- An Empirical Study. (arXiv:1802.01013v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.01013</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent work in explanation generation for decision making agents has looked
at how unexplained behavior of autonomous systems can be understood in terms of
differences in the model of the system and the human&apos;s understanding of the
same, and how the explanation process as a result of this mismatch can be then
seen as a process of reconciliation of these models. Existing algorithms in
such settings, while having been built on contrastive, selective and social
properties of explanations as studied extensively in the psychology literature,
have not, to the best of our knowledge, been evaluated in settings with actual
humans in the loop. As such, the applicability of such explanations to human-AI
and human-robot interactions remains suspect. In this paper, we set out to
evaluate these explanation generation algorithms in a series of studies in a
mock search and rescue scenario with an internal semi-autonomous robot and an
external human commander. We demonstrate to what extent the properties of these
algorithms hold as they are evaluated by humans, and how the dynamics of trust
between the human and the robot evolve during the process of these
interactions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chakraborti_T/0/1/0/all/0/1&quot;&gt;Tathagata Chakraborti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sreedharan_S/0/1/0/all/0/1&quot;&gt;Sarath Sreedharan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grover_S/0/1/0/all/0/1&quot;&gt;Sachin Grover&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kambhampati_S/0/1/0/all/0/1&quot;&gt;Subbarao Kambhampati&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.01177">
<title>A Scheme-Driven Approach to Learning Programs from Input/Output Equations. (arXiv:1802.01177v1 [cs.LO])</title>
<link>http://arxiv.org/abs/1802.01177</link>
<description rdf:parseType="Literal">&lt;p&gt;We describe an approach to learn, in a term-rewriting setting, function
definitions from input/output equations. By confining ourselves to structurally
recursive definitions we obtain a fairly fast learning algorithm that often
yields definitions close to intuitive expectations. We provide a Prolog
prototype implementation of our approach, and indicate open issues of further
investigation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Burghardt_J/0/1/0/all/0/1&quot;&gt;Jochen Burghardt&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.01186">
<title>Personalized Machine Learning for Robot Perception of Affect and Engagement in Autism Therapy. (arXiv:1802.01186v1 [cs.RO])</title>
<link>http://arxiv.org/abs/1802.01186</link>
<description rdf:parseType="Literal">&lt;p&gt;Robots have great potential to facilitate future therapies for children on
the autism spectrum. However, existing robots lack the ability to automatically
perceive and respond to human affect, which is necessary for establishing and
maintaining engaging interactions. Moreover, their inference challenge is made
harder by the fact that many individuals with autism have atypical and
unusually diverse styles of expressing their affective-cognitive states. To
tackle the heterogeneity in behavioral cues of children with autism, we use the
latest advances in deep learning to formulate a personalized machine learning
(ML) framework for automatic perception of the childrens affective states and
engagement during robot-assisted autism therapy. The key to our approach is a
novel shift from the traditional ML paradigm - instead of using
&apos;one-size-fits-all&apos; ML models, our personalized ML framework is optimized for
each child by leveraging relevant contextual information (demographics and
behavioral assessment scores) and individual characteristics of each child. We
designed and evaluated this framework using a dataset of multi-modal audio,
video and autonomic physiology data of 35 children with autism (age 3-13) and
from 2 cultures (Asia and Europe), participating in a 25-minute child-robot
interaction (~500k datapoints). Our experiments confirm the feasibility of the
robot perception of affect and engagement, showing clear improvements due to
the model personalization. The proposed approach has potential to improve
existing therapies for autism by offering more efficient monitoring and
summarization of the therapy progress.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rudovic_O/0/1/0/all/0/1&quot;&gt;Ognjen Rudovic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1&quot;&gt;Jaeryoung Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dai_M/0/1/0/all/0/1&quot;&gt;Miles Dai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schuller_B/0/1/0/all/0/1&quot;&gt;Bjorn Schuller&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Picard_R/0/1/0/all/0/1&quot;&gt;Rosalind Picard&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.01274">
<title>Dream Formulations and Deep Neural Networks: Humanistic Themes in the Iconology of the Machine-Learned Image. (arXiv:1802.01274v1 [cs.CY])</title>
<link>http://arxiv.org/abs/1802.01274</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper addresses the interpretability of deep learning-enabled image
recognition processes in computer vision science in relation to theories in art
history and cognitive psychology on the vision-related perceptual capabilities
of humans. Examination of what is determinable about the machine-learned image
in comparison to humanistic theories of visual perception, particularly in
regard to art historian Erwin Panofsky&apos;s methodology for image analysis and
psychologist Eleanor Rosch&apos;s theory of graded categorization according to
prototypes, finds that there are surprising similarities between the two that
suggest that researchers in the arts and the sciences would have much to
benefit from closer collaborations. Utilizing the examples of Google&apos;s
DeepDream and the Machine Learning and Perception Lab at Georgia Tech&apos;s
Grad-CAM: Gradient-weighted Class Activation Mapping programs, this study
suggests that a revival of art historical research in iconography and formalism
in the age of AI is essential for shaping the future navigation and
interpretation of all machine-learned images, given the rapid developments in
image recognition technologies.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Spratt_E/0/1/0/all/0/1&quot;&gt;Emily L. Spratt&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.01282">
<title>Coordinated Exploration in Concurrent Reinforcement Learning. (arXiv:1802.01282v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.01282</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider a team of reinforcement learning agents that concurrently learn
to operate in a common environment. We identify three properties - adaptivity,
commitment, and diversity - which are necessary for efficient coordinated
exploration and demonstrate that straightforward extensions to single-agent
optimistic and posterior sampling approaches fail to satisfy them. As an
alternative, we propose seed sampling, which extends posterior sampling in a
manner that meets these requirements. Simulation results investigate how
per-agent regret decreases as the number of agents grows, establishing
substantial advantages of seed sampling over alternative exploration schemes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dimakopoulou_M/0/1/0/all/0/1&quot;&gt;Maria Dimakopoulou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roy_B/0/1/0/all/0/1&quot;&gt;Benjamin Van Roy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.01435">
<title>A Method for Restoring the Training Set Distribution in an Image Classifier. (arXiv:1802.01435v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.01435</link>
<description rdf:parseType="Literal">&lt;p&gt;Convolutional Neural Networks are a well-known staple of modern image
classification. However, it can be difficult to assess the quality and
robustness of such models. Deep models are known to perform well on a given
training and estimation set, but can easily be fooled by data that is
specifically generated for the purpose. It has been shown that one can produce
an artificial example that does not represent the desired class, but activates
the network in the desired way. This paper describes a new way of
reconstructing a sample from the training set distribution of an image
classifier without deep knowledge about the underlying distribution. This
enables access to the elements of images that most influence the decision of a
convolutional network and to extract meaningful information about the training
distribution.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chaplygin_A/0/1/0/all/0/1&quot;&gt;Alexey Chaplygin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chacksfield_J/0/1/0/all/0/1&quot;&gt;Joshua Chacksfield&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.01451">
<title>Quantitative Fine-Grained Human Evaluation of Machine Translation Systems: a Case Study on English to Croatian. (arXiv:1802.01451v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1802.01451</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents a quantitative fine-grained manual evaluation approach to
comparing the performance of different machine translation (MT) systems. We
build upon the well-established Multidimensional Quality Metrics (MQM) error
taxonomy and implement a novel method that assesses whether the differences in
performance for MQM error types between different MT systems are statistically
significant. We conduct a case study for English-to-Croatian, a language
direction that involves translating into a morphologically rich language, for
which we compare three MT systems belonging to different paradigms: pure
phrase-based, factored phrase-based and neural. First, we design an
MQM-compliant error taxonomy tailored to the relevant linguistic phenomena of
Slavic languages, which made the annotation process feasible and accurate.
Errors in MT outputs were then annotated by two annotators following this
taxonomy. Subsequently, we carried out a statistical analysis which showed that
the best-performing system (neural) reduces the errors produced by the worst
system (pure phrase-based) by more than half (54\%). Moreover, we conducted an
additional analysis of agreement errors in which we distinguished between short
(phrase-level) and long distance (sentence-level) errors. We discovered that
phrase-based MT approaches are of limited use for long distance agreement
phenomena, for which neural MT was found to be especially effective.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Klubicka_F/0/1/0/all/0/1&quot;&gt;Filip Klubi&amp;#x10d;ka&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Toral_A/0/1/0/all/0/1&quot;&gt;Antonio Toral&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sanchez_Cartagena_V/0/1/0/all/0/1&quot;&gt;V&amp;#xed;ctor M. S&amp;#xe1;nchez-Cartagena&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.01482">
<title>The Sea Exploration Problem: Data-driven Orienteering on a Continuous Surface. (arXiv:1802.01482v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.01482</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper describes a problem arising in sea exploration, where the aim is
to schedule the expedition of a ship for collecting information about the
resources on the seafloor. The aim is to collect data by probing on a set of
carefully chosen locations, so that the information available is optimally
enriched. This problem has similarities with the orienteering problem, where
the aim is to plan a time-limited trip for visiting a set of vertices,
collecting a prize at each of them, in such a way that the total value
collected is maximum. In our problem, the score at each vertex is associated
with an estimation of the level of the resource on the given surface, which is
done by regression using Gaussian processes. Hence, there is a correlation
among scores on the selected vertices; this is a first difference with respect
to the standard orienteering problem. The second difference is the location of
each vertex, which in our problem is a freely chosen point on a given surface.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pedroso_J/0/1/0/all/0/1&quot;&gt;Jo&amp;#xe3;o Pedro Pedroso&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kramer_A/0/1/0/all/0/1&quot;&gt;Alpar Vajk Kramer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1&quot;&gt;Ke Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.01518">
<title>Guided Policy Exploration for Markov Decision Processes using an Uncertainty-Based Value-of-Information Criterion. (arXiv:1802.01518v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.01518</link>
<description rdf:parseType="Literal">&lt;p&gt;Reinforcement learning in environments with many action-state pairs is
challenging. At issue is the number of episodes needed to thoroughly search the
policy space. Most conventional heuristics address this search problem in a
stochastic manner. This can leave large portions of the policy space unvisited
during the early training stages. In this paper, we propose an
uncertainty-based, information-theoretic approach for performing guided
stochastic searches that more effectively cover the policy space. Our approach
is based on the value of information, a criterion that provides the optimal
trade-off between expected costs and the granularity of the search process. The
value of information yields a stochastic routine for choosing actions during
learning that can explore the policy space in a coarse to fine manner. We
augment this criterion with a state-transition uncertainty factor, which guides
the search process into previously unexplored regions of the policy space.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sledge_I/0/1/0/all/0/1&quot;&gt;Isaac J. Sledge&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Emigh_M/0/1/0/all/0/1&quot;&gt;Matthew S. Emigh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Principe_J/0/1/0/all/0/1&quot;&gt;Jose C. Principe&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.01526">
<title>Abstractly Interpreting Argumentation Frameworks for Sharpening Extensions. (arXiv:1802.01526v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.01526</link>
<description rdf:parseType="Literal">&lt;p&gt;Cycles of attacking arguments pose non-trivial issues in Dung style
argumentation theory, apparent behavioural difference between odd and even
length cycles being a notable one. While a few methods were proposed for
treating them, to - in particular - enable selection of acceptable arguments in
an odd-length cycle when Dung semantics could select none, so far the issues
have been observed from a purely argument-graph-theoretic perspective. Per
contra, we consider argument graphs together with a certain lattice like
semantic structure over arguments e.g. ontology. As we show, the
semantic-argumentgraphic hybrid theory allows us to apply abstract
interpretation, a widely known methodology in static program analysis, to
formal argumentation. With this, even where no arguments in a cycle could be
selected sensibly, we could say more about arguments acceptability of an
argument framework that contains it. In a certain sense, we can verify Dung
extensions with respect to a semantic structure in this hybrid theory, to
consolidate our confidence in their suitability. By defining the theory, and by
making comparisons to existing approaches, we ultimately discover that whether
Dung semantics, or an alternative semantics such as cf2, is adequate or
problematic depends not just on an argument graph but also on the semantic
relation among the arguments in the graph.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Arisaka_R/0/1/0/all/0/1&quot;&gt;Ryuta Arisaka&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dauphin_J/0/1/0/all/0/1&quot;&gt;Jeremie Dauphin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.01549">
<title>Robust Pre-Processing: A Robust Defense Method Against Adversary Attack. (arXiv:1802.01549v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.01549</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep learning algorithms and networks are vulnerable to perturbed inputs
which are known as the adversarial attack. Many defense methodologies have been
investigated to defend such adversarial attack. In this work, we propose a
novel methodology to defend the existing powerful attack model. Such attack
models have achieved record success against MNIST dataset to force it to
miss-classify all of its inputs. Whereas Our proposed defense method robust
pre-processing achieves the best accuracy among the current state of the art
defenses. It consists of Tanh (hyperbolic tangent) function, smoothing and
batch normalization to process the input data which will make it more robust
over the adversarial attack. robust pre-processing improves the white box
attack accuracy of MNIST from 94.3% to 98.7%. Even with increasing defense when
others defenses completely fail, robust pre-processing remains one of the
strongest ever reported. Another strength of our defense is that it eliminates
the need for adversarial training as it can significantly increase the MNIST
accuracy without adversarial training as well. This makes it a more generalized
defense method with almost half training overhead and much-improved accuracy.
robust pre-processing can also increase the inference accuracy in the face of
the powerful attack on CIFAR-10 and SVHN data set as well without much
sacrificing clean data accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rakin_A/0/1/0/all/0/1&quot;&gt;Adnan Siraj Rakin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_Z/0/1/0/all/0/1&quot;&gt;Zhezhi He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gong_B/0/1/0/all/0/1&quot;&gt;Boqing Gong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fan_D/0/1/0/all/0/1&quot;&gt;Deliang Fan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.01557">
<title>One-Shot Imitation from Observing Humans via Domain-Adaptive Meta-Learning. (arXiv:1802.01557v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.01557</link>
<description rdf:parseType="Literal">&lt;p&gt;Humans and animals are capable of learning a new behavior by observing others
perform the skill just once. We consider the problem of allowing a robot to do
the same -- learning from a raw video pixels of a human, even when there is
substantial domain shift in the perspective, environment, and embodiment
between the robot and the observed human. Prior approaches to this problem have
hand-specified how human and robot actions correspond and often relied on
explicit human pose detection systems. In this work, we present an approach for
one-shot learning from a video of a human by using human and robot
demonstration data from a variety of previous tasks to build up prior knowledge
through meta-learning. Then, combining this prior knowledge and only a single
video demonstration from a human, the robot can perform the task that the human
demonstrated. We show experiments on both a PR2 arm and a Sawyer arm,
demonstrating that after meta-learning, the robot can learn to place, push, and
pick-and-place new objects using just one video of a human performing the
manipulation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_T/0/1/0/all/0/1&quot;&gt;Tianhe Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Finn_C/0/1/0/all/0/1&quot;&gt;Chelsea Finn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_A/0/1/0/all/0/1&quot;&gt;Annie Xie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dasari_S/0/1/0/all/0/1&quot;&gt;Sudeep Dasari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1&quot;&gt;Tianhao Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1&quot;&gt;Pieter Abbeel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1&quot;&gt;Sergey Levine&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1506.08009">
<title>Skopus: Mining top-k sequential patterns under leverage. (arXiv:1506.08009v4 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1506.08009</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents a framework for exact discovery of the top-k sequential
patterns under Leverage. It combines (1) a novel definition of the expected
support for a sequential pattern - a concept on which most interestingness
measures directly rely - with (2) SkOPUS: a new branch-and-bound algorithm for
the exact discovery of top-k sequential patterns under a given measure of
interest. Our interestingness measure employs the partition approach. A pattern
is interesting to the extent that it is more frequent than can be explained by
assuming independence between any of the pairs of patterns from which it can be
composed. The larger the support compared to the expectation under
independence, the more interesting is the pattern. We build on these two
elements to exactly extract the k sequential patterns with highest leverage,
consistent with our definition of expected support. We conduct experiments on
both synthetic data with known patterns and real-world datasets; both
experiments confirm the consistency and relevance of our approach with regard
to the state of the art. This article was published in Data Mining and
Knowledge Discovery and is accessible at
&lt;a href=&quot;http://dx.doi.org/10.1007/s10618-016-0467-9.&quot;&gt;this http URL&lt;/a&gt;
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Petitjean_F/0/1/0/all/0/1&quot;&gt;Francois Petitjean&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_T/0/1/0/all/0/1&quot;&gt;Tao Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tatti_N/0/1/0/all/0/1&quot;&gt;Nikolaj Tatti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Webb_G/0/1/0/all/0/1&quot;&gt;Geoffrey I. Webb&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.10903">
<title>Graph Attention Networks. (arXiv:1710.10903v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1710.10903</link>
<description rdf:parseType="Literal">&lt;p&gt;We present graph attention networks (GATs), novel neural network
architectures that operate on graph-structured data, leveraging masked
self-attentional layers to address the shortcomings of prior methods based on
graph convolutions or their approximations. By stacking layers in which nodes
are able to attend over their neighborhoods&apos; features, we enable (implicitly)
specifying different weights to different nodes in a neighborhood, without
requiring any kind of costly matrix operation (such as inversion) or depending
on knowing the graph structure upfront. In this way, we address several key
challenges of spectral-based graph neural networks simultaneously, and make our
model readily applicable to inductive as well as transductive problems. Our GAT
models have achieved or matched state-of-the-art results across four
established transductive and inductive graph benchmarks: the Cora, Citeseer and
Pubmed citation network datasets, as well as a protein-protein interaction
dataset (wherein test graphs remain unseen during training).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Velickovic_P/0/1/0/all/0/1&quot;&gt;Petar Veli&amp;#x10d;kovi&amp;#x107;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Cucurull_G/0/1/0/all/0/1&quot;&gt;Guillem Cucurull&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Casanova_A/0/1/0/all/0/1&quot;&gt;Arantxa Casanova&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Romero_A/0/1/0/all/0/1&quot;&gt;Adriana Romero&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lio_P/0/1/0/all/0/1&quot;&gt;Pietro Li&amp;#xf2;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bengio_Y/0/1/0/all/0/1&quot;&gt;Yoshua Bengio&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.07341">
<title>FusionNet: Fusing via Fully-Aware Attention with Application to Machine Comprehension. (arXiv:1711.07341v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1711.07341</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper introduces a new neural structure called FusionNet, which extends
existing attention approaches from three perspectives. First, it puts forward a
novel concept of &quot;history of word&quot; to characterize attention information from
the lowest word-level embedding up to the highest semantic-level
representation. Second, it introduces an improved attention scoring function
that better utilizes the &quot;history of word&quot; concept. Third, it proposes a
fully-aware multi-level attention mechanism to capture the complete information
in one text (such as a question) and exploit it in its counterpart (such as
context or passage) layer by layer. We apply FusionNet to the Stanford Question
Answering Dataset (SQuAD) and it achieves the first position for both single
and ensemble model on the official SQuAD leaderboard at the time of writing
(Oct. 4th, 2017). Meanwhile, we verify the generalization of FusionNet with two
adversarial SQuAD datasets and it sets up the new state-of-the-art on both
datasets: on AddSent, FusionNet increases the best F1 metric from 46.6% to
51.4%; on AddOneSent, FusionNet boosts the best F1 metric from 56.0% to 60.7%.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_H/0/1/0/all/0/1&quot;&gt;Hsin-Yuan Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_C/0/1/0/all/0/1&quot;&gt;Chenguang Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1&quot;&gt;Yelong Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1&quot;&gt;Weizhu Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.05931">
<title>Faster Algorithms for Large-scale Machine Learning using Simple Sampling Techniques. (arXiv:1801.05931v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1801.05931</link>
<description rdf:parseType="Literal">&lt;p&gt;Now a days, the major challenge in machine learning is the `Big~Data&apos;
challenge. The big data problems due to large number of data points or large
number of features in each data point, or both, the training of models have
become very slow. The training time has two major components: Time to access
the data and time to process (learn from) the data. In this paper, we have
proposed one possible solution to handle the big data problems in machine
learning. The idea is to reduce the training time through reducing data access
time by proposing systematic sampling and cyclic/sequential sampling to select
mini-batches from the dataset. To prove the effectiveness of proposed sampling
techniques, we have used Empirical Risk Minimization, which is commonly used
machine learning problem, for strongly convex and smooth case. The problem has
been solved using SAG, SAGA, SVRG, SAAG-II and MBSGD (Mini-batched SGD), each
using two step determination techniques, namely, constant step size and
backtracking line search method. Theoretical results prove the same convergence
for systematic sampling, cyclic sampling and the widely used random sampling
technique, in expectation. Experimental results with bench marked datasets
prove the efficacy of the proposed sampling techniques.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chauhan_V/0/1/0/all/0/1&quot;&gt;Vinod Kumar Chauhan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dahiya_K/0/1/0/all/0/1&quot;&gt;Kalpana Dahiya&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1&quot;&gt;Anuj Sharma&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.05950">
<title>Toward Scalable Verification for Safety-Critical Deep Networks. (arXiv:1801.05950v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1801.05950</link>
<description rdf:parseType="Literal">&lt;p&gt;The increasing use of deep neural networks for safety-critical applications,
such as autonomous driving and flight control, raises concerns about their
safety and reliability. Formal verification can address these concerns by
guaranteeing that a deep learning system operates as intended, but the state of
the art is limited to small systems. In this work-in-progress report we give an
overview of our work on mitigating this difficulty, by pursuing two
complementary directions: devising scalable verification techniques, and
identifying design choices that result in deep learning systems that are more
amenable to verification.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kuper_L/0/1/0/all/0/1&quot;&gt;Lindsey Kuper&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Katz_G/0/1/0/all/0/1&quot;&gt;Guy Katz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gottschlich_J/0/1/0/all/0/1&quot;&gt;Justin Gottschlich&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Julian_K/0/1/0/all/0/1&quot;&gt;Kyle Julian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barrett_C/0/1/0/all/0/1&quot;&gt;Clark Barrett&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kochenderfer_M/0/1/0/all/0/1&quot;&gt;Mykel Kochenderfer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.06294">
<title>Multi-Task Pharmacovigilance Mining from Social Media Posts. (arXiv:1801.06294v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1801.06294</link>
<description rdf:parseType="Literal">&lt;p&gt;Social media has grown to be a crucial information source for
pharmacovigilance studies where an increasing number of people post adverse
reactions to medical drugs that are previously unreported. Aiming to
effectively monitor various aspects of Adverse Drug Reactions (ADRs) from
diversely expressed social medical posts, we propose a multi-task neural
network framework that learns several tasks associated with ADR monitoring with
different levels of supervisions collectively. Besides being able to correctly
classify ADR posts and accurately extract ADR mentions from online posts, the
proposed framework is also able to further understand reasons for which the
drug is being taken, known as &apos;indication&apos;, from the given social media post. A
coverage-based attention mechanism is adopted in our framework to help the
model properly identify &apos;phrasal&apos; ADRs and Indications that are attentive to
multiple words in a post. Our framework is applicable in situations where
limited parallel data for different pharmacovigilance tasks are available.We
evaluate the proposed framework on real-world Twitter datasets, where the
proposed model outperforms the state-of-the-art alternatives of each individual
task consistently.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chowdhury_S/0/1/0/all/0/1&quot;&gt;Shaika Chowdhury&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1&quot;&gt;Chenwei Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1&quot;&gt;Philip S. Yu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.09061">
<title>SWRL2SPIN: A tool for transforming SWRL rule bases in OWL ontologies to object-oriented SPIN rules. (arXiv:1801.09061v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1801.09061</link>
<description rdf:parseType="Literal">&lt;p&gt;SWRL is a semantic web rule language that combines OWL ontologies with Horn
Logic rules of the RuleML family of rule languages, extending the set of OWL
axioms to include Horn-like rules. Being supported by the Prot\&apos;eg\&apos;e ontology
editor as well as by popular rule engines and ontology reasoners, such as Jess,
Drools and Pellet, SWRL has become a very popular choice for developing
rule-based applications on top of ontologies. However, SWRL being around for
more than 10 years now, it is most probable that it will never become a W3C
standard; therefore, its scope is difficult to reach out to the industrial
world. On the other hand, SPIN has become a de-facto industry standard to
represent SPARQL rules and constraints on Semantic Web models, building on the
widespread acceptance of the SPARQL query language for querying and processing
Linked Open Data. In this paper, we argue that the life of existing SWRL
rule-based ontology applications can be prolonged by being transformed into
SPIN. To this end, we have developed a prototype tool using SWI-Prolog that
takes as in-put an OWL ontology with a SWRL rule base and transforms SWRL rules
into SPIN rules in the same ontology, taking into consideration the
object-oriented scent of SPIN, i.e. linking rules to the appropriate ontology
classes as derived by analyzing the rule conditions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bassiliades_N/0/1/0/all/0/1&quot;&gt;Nick Bassiliades&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.09354">
<title>On the Inter-relationships among Drift rate, Forgetting rate, Bias/variance profile and Error. (arXiv:1801.09354v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1801.09354</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose two general and falsifiable hypotheses about expectations on
generalization error when learning in the context of concept drift. One posits
that as drift rate increases, the forgetting rate that minimizes generalization
error will also increase and vice versa. The other posits that as a learner&apos;s
forgetting rate increases, the bias/variance profile that minimizes
generalization error will have lower variance and vice versa. These hypotheses
lead to the concept of the sweet path, a path through the 3-d space of
alternative drift rates, forgetting rates and bias/variance profiles on which
generalization error will be minimized, such that slow drift is coupled with
low forgetting and low bias, while rapid drift is coupled with fast forgetting
and low variance. We present experiments that support the existence of such a
sweet path. We also demonstrate that simple learners that select appropriate
forgetting rates and bias/variance profiles are highly competitive with the
state-of-the-art in incremental learners for concept drift on real-world drift
problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zaidi_N/0/1/0/all/0/1&quot;&gt;Nayyar A. Zaidi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Webb_G/0/1/0/all/0/1&quot;&gt;Geoffrey I. Webb&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Petitjean_F/0/1/0/all/0/1&quot;&gt;Francois Petitjean&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Forestier_G/0/1/0/all/0/1&quot;&gt;Germain Forestier&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.00822">
<title>VIBNN: Hardware Acceleration of Bayesian Neural Networks. (arXiv:1802.00822v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.00822</link>
<description rdf:parseType="Literal">&lt;p&gt;Bayesian Neural Networks (BNNs) have been proposed to address the problem of
model uncertainty in training and inference. By introducing weights associated
with conditioned probability distributions, BNNs are capable of resolving the
overfitting issue commonly seen in conventional neural networks and allow for
small-data training, through the variational inference process. Frequent usage
of Gaussian random variables in this process requires a properly optimized
Gaussian Random Number Generator (GRNG). The high hardware cost of conventional
GRNG makes the hardware implementation of BNNs challenging.
&lt;/p&gt;
&lt;p&gt;In this paper, we propose VIBNN, an FPGA-based hardware accelerator design
for variational inference on BNNs. We explore the design space for massive
amount of Gaussian variable sampling tasks in BNNs. Specifically, we introduce
two high performance Gaussian (pseudo) random number generators: the RAM-based
Linear Feedback Gaussian Random Number Generator (RLF-GRNG), which is inspired
by the properties of binomial distribution and linear feedback logics; and the
Bayesian Neural Network-oriented Wallace Gaussian Random Number Generator. To
achieve high scalability and efficient memory access, we propose a deep
pipelined accelerator architecture with fast execution and good hardware
utilization. Experimental results demonstrate that the proposed VIBNN
implementations on an FPGA can achieve throughput of 321,543.4 Images/s and
energy efficiency upto 52,694.8 Images/J while maintaining similar accuracy as
its software counterpart.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cai_R/0/1/0/all/0/1&quot;&gt;Ruizhe Cai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ren_A/0/1/0/all/0/1&quot;&gt;Ao Ren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_N/0/1/0/all/0/1&quot;&gt;Ning Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ding_C/0/1/0/all/0/1&quot;&gt;Caiwen Ding&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1&quot;&gt;Luhao Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qian_X/0/1/0/all/0/1&quot;&gt;Xuehai Qian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pedram_M/0/1/0/all/0/1&quot;&gt;Massoud Pedram&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yanzhi Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.00926">
<title>On the Minimax Misclassification Ratio of Hypergraph Community Detection. (arXiv:1802.00926v1 [cs.IT])</title>
<link>http://arxiv.org/abs/1802.00926</link>
<description rdf:parseType="Literal">&lt;p&gt;Community detection in hypergraphs is explored. Under a generative hypergraph
model called &quot;d-wise hypergraph stochastic block model&quot; (d-hSBM) which
naturally extends the Stochastic Block Model from graphs to d-uniform
hypergraphs, the asymptotic minimax mismatch ratio is characterized. For
proving the achievability, we propose a two-step polynomial time algorithm that
achieves the fundamental limit. The first step of the algorithm is a hypergraph
spectral clustering method which achieves partial recovery to a certain
precision level. The second step is a local refinement method which leverages
the underlying probabilistic model along with parameter estimation from the
outcome of the first step. To characterize the asymptotic performance of the
proposed algorithm, we first derive a sufficient condition for attaining weak
consistency in the hypergraph spectral clustering step. Then, under the
guarantee of weak consistency in the first step, we upper bound the worst-case
risk attained in the local refinement step by an exponentially decaying
function of the size of the hypergraph and characterize the decaying rate. For
proving the converse, the lower bound of the minimax mismatch ratio is set by
finding a smaller parameter space which contains the most dominant error
events, inspired by the analysis in the achievability part. It turns out that
the minimax mismatch ratio decays exponentially fast to zero as the number of
nodes tends to infinity, and the rate function is a weighted combination of
several divergence terms, each of which is the Renyi divergence of order 1/2
between two Bernoulli&apos;s. The Bernoulli&apos;s involved in the characterization of
the rate function are those governing the random instantiation of hyperedges in
d-hSBM. Experimental results on synthetic data validate our theoretical finding
that the refinement step is critical in achieving the optimal statistical
limit.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chien_I/0/1/0/all/0/1&quot;&gt;I Chien&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_C/0/1/0/all/0/1&quot;&gt;Chung-Yi Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_I/0/1/0/all/0/1&quot;&gt;I-Hsiang Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.01152">
<title>Testing to distinguish measures on metric spaces. (arXiv:1802.01152v1 [stat.ME])</title>
<link>http://arxiv.org/abs/1802.01152</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the problem of distinguishing between two distributions on a metric
space; i.e., given metric measure spaces $({\mathbb X}, d, \mu_1)$ and
$({\mathbb X}, d, \mu_2)$, we are interested in the problem of determining from
finite data whether or not $\mu_1$ is $\mu_2$. The key is to use pairwise
distances between observations and, employing a reconstruction theorem of
Gromov, we can perform such a test using a two sample Kolmogorov--Smirnov test.
A real analysis using phylogenetic trees and flu data is presented.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Blumberg_A/0/1/0/all/0/1&quot;&gt;Andrew J. Blumberg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bhaumik_P/0/1/0/all/0/1&quot;&gt;Prithwish Bhaumik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Walker_S/0/1/0/all/0/1&quot;&gt;Stephen G. Walker&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.01301">
<title>Comparison of computer systems and ranking criteria for automatic melanoma detection in dermoscopic images. (arXiv:1802.01301v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.01301</link>
<description rdf:parseType="Literal">&lt;p&gt;Melanoma is the deadliest form of skin cancer. Computer systems can assist in
melanoma detection, but are not widespread in clinical practice. In 2016, an
open challenge in classification of dermoscopic images of skin lesions was
announced. A training set of 900 images with corresponding class labels and
semi-automatic/manual segmentation masks was released for the challenge. An
independent test set of 379 images was used to rank the participants. This
article demonstrates the impact of ranking criteria, segmentation method and
classifier, and highlights the clinical perspective. We compare five different
measures for diagnostic accuracy by analysing the resulting ranking of the
computer systems in the challenge. Choice of performance measure had great
impact on the ranking. Systems that were ranked among the top three for one
measure, dropped to the bottom half when changing performance measure. Nevus
Doctor, a computer system previously developed by the authors, was used to
investigate the impact of segmentation and classifier. The unexpected small
impact of automatic versus semi-automatic/manual segmentation suggests that
improvements of the automatic segmentation method w.r.t. resemblance to
semi-automatic/manual segmentation will not improve diagnostic accuracy
substantially. A small set of similar classification algorithms are used to
investigate the impact of classifier on the diagnostic accuracy. The
variability in diagnostic accuracy for different classifier algorithms was
larger than the variability for segmentation methods, and suggests a focus for
future investigations. From a clinical perspective, the misclassification of a
melanoma as benign has far greater cost than the misclassification of a benign
lesion. For computer systems to have clinical impact, their performance should
be ranked by a high-sensitivity measure.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mollersen_K/0/1/0/all/0/1&quot;&gt;Kajsa M&amp;#xf8;llersen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zortea_M/0/1/0/all/0/1&quot;&gt;Maciel Zortea&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Schopf_T/0/1/0/all/0/1&quot;&gt;Thomas R. Schopf&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kirchesch_H/0/1/0/all/0/1&quot;&gt;Herbert Kirchesch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Godtliebsen_F/0/1/0/all/0/1&quot;&gt;Fred Godtliebsen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.01334">
<title>Information Assisted Dictionary Learning for fMRI data analysis. (arXiv:1802.01334v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.01334</link>
<description rdf:parseType="Literal">&lt;p&gt;Extracting information from functional magnetic resonance images (fMRI) has
been a major area of research for many years, but is still demanding more
accurate techniques. Nowadays, we have a plenty of available information about
the brain-behavior that can be used to develop more precise methods. Thus, this
paper presents a new Dictionary Learning method that allows incorporating
external information regarding the studied problem, through a novel sets of
constraints. Finally, we apply this proposed method to synthetic fMRI data,
where several tests show an improvement in the performance compared with other
common techniques.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Morante_M/0/1/0/all/0/1&quot;&gt;Manuel Morante&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kopsinis_Y/0/1/0/all/0/1&quot;&gt;Yannis Kopsinis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Theodoridis_S/0/1/0/all/0/1&quot;&gt;Sergios Theodoridis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.01458">
<title>Image restoration with generalized Gaussian mixture model patch priors. (arXiv:1802.01458v1 [eess.IV])</title>
<link>http://arxiv.org/abs/1802.01458</link>
<description rdf:parseType="Literal">&lt;p&gt;Patch priors have became an important component of image restoration. A
powerful approach in this category of restoration algorithms is the popular
Expected Patch Log-likelihood (EPLL) algorithm. EPLL uses a Gaussian mixture
model (GMM) prior learned on clean image patches as a way to regularize
degraded patches. In this paper, we show that a generalized Gaussian mixture
model (GGMM) captures the underlying distribution of patches better than a GMM.
Even though GGMM is a powerful prior to combine with EPLL, the non-Gaussianity
of its components presents major challenges to be applied to a computationally
intensive process of image restoration. Specifically, each patch has to undergo
a patch classification step and a shrinkage step. These two steps can be
efficiently solved with a GMM prior but are computationally impractical when
using a GGMM prior. In this paper, we provide approximations and computational
recipes for fast evaluation of these two steps, so that EPLL can embed a GGMM
prior on an image with more than tens of thousands of patches. Our main
contribution is to analyze the accuracy of our approximations based on thorough
theoretical analysis. Our evaluations indicate that the GGMM prior is
consistently a better fit for modeling image patch distribution and performs
better on average in image denoising task.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Deledalle_C/0/1/0/all/0/1&quot;&gt;Charles-Alban Deledalle&lt;/a&gt; (IMB, UCSD), &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Parameswaran_S/0/1/0/all/0/1&quot;&gt;Shibin Parameswaran&lt;/a&gt; (UCSD), &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Nguyen_T/0/1/0/all/0/1&quot;&gt;Truong Q. Nguyen&lt;/a&gt; (UCSD)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.01504">
<title>Linear Convergence of the Primal-Dual Gradient Method for Convex-Concave Saddle Point Problems without Strong Convexity. (arXiv:1802.01504v1 [math.OC])</title>
<link>http://arxiv.org/abs/1802.01504</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the convex-concave saddle point problem $\min_{x}\max_{y}
f(x)+y^\top A x-g(y)$ where $f$ is smooth and convex and $g$ is smooth and
strongly convex. We prove that if the coupling matrix $A$ has full column rank,
the vanilla primal-dual gradient method can achieve linear convergence even if
$f$ is not strongly convex. Our result generalizes previous work which either
requires $f$ and $g$ to be quadratic functions or requires proximal mappings
for both $f$ and $g$. We adopt a novel analysis technique that in each
iteration uses a &quot;ghost&quot; update as a reference, and show that the iterates in
the primal-dual gradient method converge to this &quot;ghost&quot; sequence. Using the
same technique we further give an analysis for the primal-dual stochastic
variance reduced gradient (SVRG) method for convex-concave saddle point
problems with a finite-sum structure.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Du_S/0/1/0/all/0/1&quot;&gt;Simon S. Du&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Hu_W/0/1/0/all/0/1&quot;&gt;Wei Hu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1403.2310">
<title>Penalized Estimation of Directed Acyclic Graphs From Discrete Data. (arXiv:1403.2310v4 [stat.ME] UPDATED)</title>
<link>http://arxiv.org/abs/1403.2310</link>
<description rdf:parseType="Literal">&lt;p&gt;Bayesian networks, with structure given by a directed acyclic graph (DAG),
are a popular class of graphical models. However, learning Bayesian networks
from discrete or categorical data is particularly challenging, due to the large
parameter space and the difficulty in searching for a sparse structure. In this
article, we develop a maximum penalized likelihood method to tackle this
problem. Instead of the commonly used multinomial distribution, we model the
conditional distribution of a node given its parents by multi-logit regression,
in which an edge is parameterized by a set of coefficient vectors with dummy
variables encoding the levels of a node. To obtain a sparse DAG, a group norm
penalty is employed, and a blockwise coordinate descent algorithm is developed
to maximize the penalized likelihood subject to the acyclicity constraint of a
DAG. When interventional data are available, our method constructs a causal
network, in which a directed edge represents a causal relation. We apply our
method to various simulated and real data sets. The results show that our
method is very competitive, compared to many existing methods, in DAG
estimation from both interventional and high-dimensional observational data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gu_J/0/1/0/all/0/1&quot;&gt;Jiaying Gu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Fu_F/0/1/0/all/0/1&quot;&gt;Fei Fu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhou_Q/0/1/0/all/0/1&quot;&gt;Qing Zhou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1602.04265">
<title>Lasso Guarantees for Time Series Estimation Under Subgaussian Tails and $ \beta $-Mixing. (arXiv:1602.04265v4 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1602.04265</link>
<description rdf:parseType="Literal">&lt;p&gt;Many theoretical results on estimation of high dimensional time series
require specifying an underlying data generating model (DGM). Instead, along
the footsteps of~\cite{wong2017lasso}, this paper relies only on (strict)
stationarity and $ \beta $-mixing condition to establish consistency of lasso
when data comes from a $\beta$-mixing process with marginals having subgaussian
tails. Because of the general assumptions, the data can come from DGMs
different than standard time series models such as VAR or ARCH. When the true
DGM is not VAR, the lasso estimates correspond to those of the best linear
predictors using the past observations. We establish non-asymptotic
inequalities for estimation and prediction errors of the lasso estimates.
Together with~\cite{wong2017lasso}, we provide lasso guarantees that cover full
spectrum of the parameters in specifications of $ \beta $-mixing subgaussian
time series. Applications of these results potentially extend to non-Gaussian,
non-Markovian and non-linear times series models as the examples we provide
demonstrate. In order to prove our results, we derive a novel Hanson-Wright
type concentration inequality for $\beta$-mixing subgaussian random vectors
that may be of independent interest.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wong_K/0/1/0/all/0/1&quot;&gt;Kam Chung Wong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Zifan Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tewari_A/0/1/0/all/0/1&quot;&gt;Ambuj Tewari&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1605.07950">
<title>On Fast Convergence of Proximal Algorithms for SQRT-Lasso Optimization: Don&apos;t Worry About Its Nonsmooth Loss Function. (arXiv:1605.07950v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1605.07950</link>
<description rdf:parseType="Literal">&lt;p&gt;Many machine learning techniques sacrifice convenient computational
structures to gain estimation robustness and modeling flexibility. However, by
exploring the modeling structures, we find these &quot;sacrifices&quot; do not always
require more computational efforts. To shed light on such a &quot;free-lunch&quot;
phenomenon, we study the square-root-Lasso (SQRT-Lasso) type regression
problem. Specifically, we show that the nonsmooth loss functions of SQRT-Lasso
type regression ease tuning effort and gain adaptivity to inhomogeneous noise,
but is not necessarily more challenging than Lasso in computation. We can
directly apply proximal algorithms (e.g. proximal gradient descent, proximal
Newton, and proximal Quasi-Newton algorithms) without worrying the
nonsmoothness of the loss function. Theoretically, we prove that the proximal
algorithms combined with the pathwise optimization scheme enjoy fast
convergence guarantees with high probability. Numerical results are provided to
support our theory.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xingguo Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1&quot;&gt;Haoming Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Haupt_J/0/1/0/all/0/1&quot;&gt;Jarvis Haupt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Arora_R/0/1/0/all/0/1&quot;&gt;Raman Arora&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1&quot;&gt;Han Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hong_M/0/1/0/all/0/1&quot;&gt;Mingyi Hong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_T/0/1/0/all/0/1&quot;&gt;Tuo Zhao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1707.01212">
<title>ProtoDash: Fast Interpretable Prototype Selection. (arXiv:1707.01212v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1707.01212</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper we propose an efficient algorithm ProtoDash for selecting
prototypical examples from complex datasets. Our generalizes the learn to
criticize (L2C) work by Kim et al. (2016) to not only select prototypes for a
given sparsity level $m$ but also to associate non-negative (for
interpretability) weights with each of them indicative of the importance of
each prototype. This extension provides a single coherent framework under which
both prototypes and criticisms can be found. Furthermore, our framework works
for any symmetric positive definite kernel thus addressing one of the key open
questions laid out in Kim et al. (2016). Our additional requirement of learning
non-negative weights no longer maintains submodularity of the objective as in
the previous work, however, we show that the problem is weakly submodular and
derive approximation guarantees for our fast ProtoDash algorithm. We
demonstrate the efficacy of our method on diverse domains such as retail, digit
recognition (MNIST) and on publicly available 40 health questionnaires obtained
from the Center for Disease Control (CDC) website maintained by the US Dept. of
Health. We validate the results quantitatively as well as qualitatively based
on expert feedback and recently published scientific studies on public health,
thus showcasing the power of our method in providing actionability (for
retail), utility (for MNIST) and insight (on CDC datasets), which presumably
are the hallmark of an effective interpretable method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gurumoorthy_K/0/1/0/all/0/1&quot;&gt;Karthik S. Gurumoorthy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Dhurandhar_A/0/1/0/all/0/1&quot;&gt;Amit Dhurandhar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Cecchi_G/0/1/0/all/0/1&quot;&gt;Guillermo Cecchi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.00379">
<title>Sparse Regularization in Marketing and Economics. (arXiv:1709.00379v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1709.00379</link>
<description rdf:parseType="Literal">&lt;p&gt;Sparse alpha-norm regularization has many data-rich applications in Marketing
and Economics. Alpha-norm, in contrast to lasso and ridge regularization, jumps
to a sparse solution. This feature is attractive for ultra high-dimensional
problems that occur in demand estimation and forecasting. The alpha-norm
objective is nonconvex and requires coordinate descent and proximal operators
to find the sparse solution. We study a typical marketing demand forecasting
problem, grocery store sales for salty snacks, that has many dummy variables as
controls. The key predictors of demand include price, equivalized volume,
promotion, flavor, scent, and brand effects. By comparing with many commonly
used machine learning methods, alpha-norm regularization achieves its goal of
providing accurate out-of-sample estimates for the promotion lift effects.
Finally, we conclude with directions for future research.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Feng_G/0/1/0/all/0/1&quot;&gt;Guanhao Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Polson_N/0/1/0/all/0/1&quot;&gt;Nicholas Polson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yuexi Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Xu_J/0/1/0/all/0/1&quot;&gt;Jianeng Xu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.01604">
<title>Privacy Risk in Machine Learning: Analyzing the Connection to Overfitting. (arXiv:1709.01604v4 [cs.CR] UPDATED)</title>
<link>http://arxiv.org/abs/1709.01604</link>
<description rdf:parseType="Literal">&lt;p&gt;Machine learning algorithms, when applied to sensitive data, pose a distinct
threat to privacy. A growing body of prior work demonstrates that models
produced by these algorithms may leak specific private information in the
training data to an attacker, either through the models&apos; structure or their
observable behavior. However, the underlying cause of this privacy risk is not
well understood beyond a handful of anecdotal accounts that suggest overfitting
and influence might play a role.
&lt;/p&gt;
&lt;p&gt;This paper examines the effect that overfitting and influence have on the
ability of an attacker to learn information about the training data from
machine learning models, either through training set membership inference or
attribute inference attacks. Using both formal and empirical analyses, we
illustrate a clear relationship between these factors and the privacy risk that
arises in several popular machine learning algorithms. We find that overfitting
is sufficient to allow an attacker to perform membership inference and, when
the target attribute meets certain conditions about its influence, attribute
inference attacks. Interestingly, our formal analysis also shows that
overfitting is not necessary for these attacks and begins to shed light on what
other factors may be in play. Finally, we explore the connection between
membership inference and attribute inference, showing that there are deep
connections between the two that lead to effective new attacks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yeom_S/0/1/0/all/0/1&quot;&gt;Samuel Yeom&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Giacomelli_I/0/1/0/all/0/1&quot;&gt;Irene Giacomelli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fredrikson_M/0/1/0/all/0/1&quot;&gt;Matt Fredrikson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jha_S/0/1/0/all/0/1&quot;&gt;Somesh Jha&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.09710">
<title>Weighting Scheme for a Pairwise Multi-label Classifier Based on the Fuzzy Confusion Matrix. (arXiv:1710.09710v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1710.09710</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work we addressed the issue of applying a stochastic classifier and a
local, fuzzy confusion matrix under the framework of multi-label
classification. We proposed a novel solution to the problem of correcting label
pairwise ensembles. The main step of the correction procedure is to compute
classifier-specific competence and cross-competence measures, which estimates
error pattern of the underlying classifier. At the fusion phase we employed two
weighting approaches based on information theory. The classifier weights
promote base classifiers which are the most susceptible to the correction based
on the fuzzy confusion matrix. During the experimental study, the proposed
approach was compared against two reference methods. The comparison was made in
terms of six different quality criteria. The conducted experiments reveals that
the proposed approach eliminates one of main drawbacks of the original
FCM-based approach i.e. the original approach is vulnerable to the imbalanced
class/label distribution. What is more, the obtained results shows that the
introduced method achieves satisfying classification quality under all
considered quality criteria. Additionally, the impact of fluctuations of data
set characteristics is reduced.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Trajdos_P/0/1/0/all/0/1&quot;&gt;Pawel Trajdos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kurzynski_M/0/1/0/all/0/1&quot;&gt;Marek Kurzynski&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.08936">
<title>Causal Generative Neural Networks. (arXiv:1711.08936v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1711.08936</link>
<description rdf:parseType="Literal">&lt;p&gt;We present Causal Generative Neural Networks (CGNNs) to learn functional
causal models from observational data. CGNNs leverage conditional
independencies and distributional asymmetries to discover bivariate and
multivariate causal structures. CGNNs make no assumption regarding the lack of
confounders, and learn a differentiable generative model of the data by using
backpropagation. Extensive experiments show their good performances
comparatively to the state of the art in observational causal discovery on both
simulated and real data, with respect to cause-effect inference, v-structure
identification, and multivariate causal discovery.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Goudet_O/0/1/0/all/0/1&quot;&gt;Olivier Goudet&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kalainathan_D/0/1/0/all/0/1&quot;&gt;Diviyan Kalainathan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Caillou_P/0/1/0/all/0/1&quot;&gt;Philippe Caillou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Guyon_I/0/1/0/all/0/1&quot;&gt;Isabelle Guyon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lopez_Paz_D/0/1/0/all/0/1&quot;&gt;David Lopez-Paz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sebag_M/0/1/0/all/0/1&quot;&gt;Mich&amp;#xe8;le Sebag&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.00393">
<title>Theoretical Analysis of Sparse Subspace Clustering with Missing Entries. (arXiv:1801.00393v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1801.00393</link>
<description rdf:parseType="Literal">&lt;p&gt;Sparse Subspace Clustering (SSC) is a popular unsupervised machine learning
method for clustering data lying close to an unknown union of low-dimensional
linear subspaces; a problem with numerous applications in pattern recognition
and computer vision. Even though the behavior of SSC for uncorrupted data is by
now well-understood, little is known about its theoretical properties when
applied to data with missing entries. In this paper we give the first
interpretable and correct theoretical guarantees for SSC with incomplete data,
and analytically establish that projecting the zero-filled data onto the
observation pattern of the point being expressed leads to a substantial
improvement in performance. The main insight that stems from our analysis is
that even though the projection induces additional missing entries, this is
counterbalanced by the fact that the projected and zero-filled data are in
effect incomplete points associated with the union of the corresponding
projected subspaces, with respect to which the point being expressed is
complete. The significance of this phenomenon potentially extends to the entire
class of self-expressive methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tsakiris_M/0/1/0/all/0/1&quot;&gt;Manolis C. Tsakiris&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vidal_R/0/1/0/all/0/1&quot;&gt;Rene Vidal&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.07889">
<title>A Theoretical Investigation of Graph Degree as an Unsupervised Normality Measure. (arXiv:1801.07889v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1801.07889</link>
<description rdf:parseType="Literal">&lt;p&gt;For a graph representation of a dataset, a straightforward normality measure
for a sample can be its graph degree. Considering a weighted graph, degree of a
sample is the sum of the corresponding row&apos;s values in a similarity matrix. The
measure is intuitive given the abnormal samples are usually rare and they are
dissimilar to the rest of the data. In order to have an in-depth theoretical
understanding, in this manuscript, we investigate the graph degree in spectral
graph clustering based and kernel based point of views and draw connections to
a recent kernel method for the two sample problem. We show that our analyses
guide us to choose fully-connected graphs whose edge weights are calculated via
universal kernels. We show that a simple graph degree based unsupervised
anomaly detection method with the above properties, achieves higher accuracy
compared to other unsupervised anomaly detection methods on average over 10
widely used datasets. We also provide an extensive analysis on the effect of
the kernel parameter on the method&apos;s accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aytekin_C/0/1/0/all/0/1&quot;&gt;Caglar Aytekin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cricri_F/0/1/0/all/0/1&quot;&gt;Francesco Cricri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fan_L/0/1/0/all/0/1&quot;&gt;Lixin Fan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aksu_E/0/1/0/all/0/1&quot;&gt;Emre Aksu&lt;/a&gt;</dc:creator>
</item></rdf:RDF>