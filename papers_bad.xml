<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Boring papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Bad Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-02-06T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.02026"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.05443"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.01548"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1701.06106"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.01730"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.01772"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.01780"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.01812"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.01933"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1503.08381"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1707.06354"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.09480"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.07983"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.09373"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1610.03761"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.01610"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.01697"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.01709"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.01737"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.01751"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.01756"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.01765"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.01786"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1701.04831"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1708.08333"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.09026"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.06104"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.01887"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1611.09461"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1802.02026">
<title>Brain-inspired photonic signal processor for periodic pattern generation and chaotic system emulation. (arXiv:1802.02026v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1802.02026</link>
<description rdf:parseType="Literal">&lt;p&gt;Reservoir computing is a bio-inspired computing paradigm for processing
time-dependent signals. Its hardware implementations have received much
attention because of their simplicity and remarkable performance on a series of
benchmark tasks. In previous experiments the output was uncoupled from the
system and in most cases simply computed offline on a post-processing computer.
However, numerical investigations have shown that feeding the output back into
the reservoir would open the possibility of long-horizon time series
forecasting. Here we present a photonic reservoir computer with output
feedback, and demonstrate its capacity to generate periodic time series and to
emulate chaotic systems. We study in detail the effect of experimental noise on
system performance. In the case of chaotic systems, this leads us to introduce
several metrics, based on standard signal processing techniques, to evaluate
the quality of the emulation. Our work significantly enlarges the range of
tasks that can be solved by hardware reservoir computers, and therefore the
range of applications they could potentially tackle. It also raises novel
questions in nonlinear dynamics and chaos theory.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Antonik_P/0/1/0/all/0/1&quot;&gt;Piotr Antonik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Haelterman_M/0/1/0/all/0/1&quot;&gt;Marc Haelterman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Massar_S/0/1/0/all/0/1&quot;&gt;Serge Massar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.05443">
<title>Human and Machine Speaker Recognition Based on Short Trivial Events. (arXiv:1711.05443v3 [cs.SD] UPDATED)</title>
<link>http://arxiv.org/abs/1711.05443</link>
<description rdf:parseType="Literal">&lt;p&gt;Trivial events are ubiquitous in human to human conversations, e.g., cough,
laugh and sniff. Compared to regular speech, these trivial events are usually
short and unclear, thus generally regarded as not speaker discriminative and so
are largely ignored by present speaker recognition research. However, these
trivial events are highly valuable in some particular circumstances such as
forensic examination, as they are less subjected to intentional change, so can
be used to discover the genuine speaker from disguised speech. In this paper,
we collect a trivial event speech database that involves 75 speakers and 6
types of events, and report preliminary speaker recognition results on this
database, by both human listeners and machines. Particularly, the deep feature
learning technique recently proposed by our group is utilized to analyze and
recognize the trivial events, which leads to acceptable equal error rates
(EERs) despite the extremely short durations (0.2-0.5 seconds) of these events.
Comparing different types of events, &apos;hmm&apos; seems more speaker discriminative.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1&quot;&gt;Miao Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kang_X/0/1/0/all/0/1&quot;&gt;Xiaofei Kang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yanqing Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1&quot;&gt;Lantian Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_Z/0/1/0/all/0/1&quot;&gt;Zhiyuan Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dai_H/0/1/0/all/0/1&quot;&gt;Haisheng Dai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1&quot;&gt;Dong Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.01548">
<title>Regularized Evolution for Image Classifier Architecture Search. (arXiv:1802.01548v2 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1802.01548</link>
<description rdf:parseType="Literal">&lt;p&gt;The effort devoted to hand-crafting image classifiers has motivated the use
of architecture search to discover them automatically. Reinforcement learning
and evolution have both shown promise for this purpose. This study employs a
regularized version of a popular asynchronous evolutionary algorithm. We
rigorously compare it to the non-regularized form and to a highly-successful
reinforcement learning baseline. Using the same hardware, compute effort and
neural network training code, we conduct repeated experiments side-by-side,
exploring different datasets, search spaces and scales. We show regularized
evolution consistently produces models with similar or higher accuracy, across
a variety of contexts without need for re-tuning parameters. In addition,
evolution exhibits considerably better performance than reinforcement learning
at early search stages, suggesting it may be the better choice when fewer
compute resources are available. This constitutes the first controlled
comparison of the two search algorithms in this context. Finally, we present
new architectures discovered with evolution that we nickname AmoebaNets. These
models set a new state of the art for CIFAR-10 (mean test error = 2.13%) and
mobile-size ImageNet (top-5 accuracy = 92.1% with 5.06M parameters), and reach
the current state of the art for ImageNet (top-5 accuracy = 96.2%).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Real_E/0/1/0/all/0/1&quot;&gt;Esteban Real&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aggarwal_A/0/1/0/all/0/1&quot;&gt;Alok Aggarwal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_Y/0/1/0/all/0/1&quot;&gt;Yanping Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Le_Q/0/1/0/all/0/1&quot;&gt;Quoc V Le&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1701.06106">
<title>Neurogenesis-Inspired Dictionary Learning: Online Model Adaption in a Changing World. (arXiv:1701.06106v2 [cs.LG] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1701.06106</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we focus on online representation learning in non-stationary
environments which may require continuous adaptation of model architecture. We
propose a novel online dictionary-learning (sparse-coding) framework which
incorporates the addition and deletion of hidden units (dictionary elements),
and is inspired by the adult neurogenesis phenomenon in the dentate gyrus of
the hippocampus, known to be associated with improved cognitive function and
adaptation to new environments. In the online learning setting, where new input
instances arrive sequentially in batches, the neuronal-birth is implemented by
adding new units with random initial weights (random dictionary elements); the
number of new units is determined by the current performance (representation
error) of the dictionary, higher error causing an increase in the birth rate.
Neuronal-death is implemented by imposing l1/l2-regularization (group sparsity)
on the dictionary within the block-coordinate descent optimization at each
iteration of our online alternating minimization scheme, which iterates between
the code and dictionary updates. Finally, hidden unit connectivity adaptation
is facilitated by introducing sparsity in dictionary elements. Our empirical
evaluation on several real-life datasets (images and language) as well as on
synthetic data demonstrates that the proposed approach can considerably
outperform the state-of-art fixed-size (nonadaptive) online sparse coding of
Mairal et al. (2009) in the presence of nonstationary data. Moreover, we
identify certain properties of the data (e.g., sparse inputs with nearly
non-overlapping supports) and of the model (e.g., dictionary sparsity)
associated with such improvements.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garg_S/0/1/0/all/0/1&quot;&gt;Sahil Garg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rish_I/0/1/0/all/0/1&quot;&gt;Irina Rish&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cecchi_G/0/1/0/all/0/1&quot;&gt;Guillermo Cecchi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lozano_A/0/1/0/all/0/1&quot;&gt;Aurelie Lozano&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.01730">
<title>Local Wealth Redistribution Promotes Cooperation in Multiagent Systems. (arXiv:1802.01730v1 [cs.MA])</title>
<link>http://arxiv.org/abs/1802.01730</link>
<description rdf:parseType="Literal">&lt;p&gt;Designing mechanisms that leverage cooperation between agents has been a
long-lasting goal in Multiagent Systems. The task is especially challenging
when agents are selfish, lack common goals and face social dilemmas, i.e.,
situations in which individual interest conflicts with social welfare. Past
works explored mechanisms that explain cooperation in biological and social
systems, providing important clues for the aim of designing cooperative
artificial societies. In particular, several works show that cooperation is
able to emerge when specific network structures underlie agents&apos; interactions.
Notwithstanding, social dilemmas in which defection is highly tempting still
pose challenges concerning the effective sustainability of cooperation. Here we
propose a new redistribution mechanism that can be applied in structured
populations of agents. Importantly, we show that, when implemented locally
(i.e., agents share a fraction of their wealth surplus with their nearest
neighbors), redistribution excels in promoting cooperation under regimes where,
before, only defection prevailed.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pinheiro_F/0/1/0/all/0/1&quot;&gt;Fl&amp;#xe1;vio L. Pinheiro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Santos_F/0/1/0/all/0/1&quot;&gt;Fernando P. Santos&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.01772">
<title>Utility Decomposition with Deep Corrections for Scalable Planning under Uncertainty. (arXiv:1802.01772v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.01772</link>
<description rdf:parseType="Literal">&lt;p&gt;Decomposition methods have been proposed in the past to approximate solutions
to large sequential decision making problems. In contexts where an agent
interacts with multiple entities, utility decomposition can be used where each
individual entity is considered independently. The individual utility functions
are then combined in real time to solve the global problem. Although these
techniques can perform well empirically, they sacrifice optimality. This paper
proposes an approach inspired from multi-fidelity optimization to learn a
correction term with a neural network representation. Learning this correction
can significantly improve performance. We demonstrate this approach on a
pedestrian avoidance problem for autonomous driving. By leveraging strategies
to avoid a single pedestrian, the decomposition method can scale to avoid
multiple pedestrians. We verify empirically that the proposed correction method
leads to a significant improvement over the decomposition method alone and
outperforms a policy trained on the full scale problem without utility
decomposition.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bouton_M/0/1/0/all/0/1&quot;&gt;Maxime Bouton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Julian_K/0/1/0/all/0/1&quot;&gt;Kyle Julian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nakhaei_A/0/1/0/all/0/1&quot;&gt;Alireza Nakhaei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fujimura_K/0/1/0/all/0/1&quot;&gt;Kikuo Fujimura&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kochenderfer_M/0/1/0/all/0/1&quot;&gt;Mykel J. Kochenderfer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.01780">
<title>Goal Inference Improves Objective and Perceived Performance in Human-Robot Collaboration. (arXiv:1802.01780v1 [cs.RO])</title>
<link>http://arxiv.org/abs/1802.01780</link>
<description rdf:parseType="Literal">&lt;p&gt;The study of human-robot interaction is fundamental to the design and use of
robotics in real-world applications. Robots will need to predict and adapt to
the actions of human collaborators in order to achieve good performance and
improve safety and end-user adoption. This paper evaluates a human-robot
collaboration scheme that combines the task allocation and motion levels of
reasoning: the robotic agent uses Bayesian inference to predict the next goal
of its human partner from his or her ongoing motion, and re-plans its own
actions in real time. This anticipative adaptation is desirable in many
practical scenarios, where humans are unable or unwilling to take on the
cognitive overhead required to explicitly communicate their intent to the
robot. A behavioral experiment indicates that the combination of goal inference
and dynamic task planning significantly improves both objective and perceived
performance of the human-robot team. Participants were highly sensitive to the
differences between robot behaviors, preferring to work with a robot that
adapted to their actions over one that did not.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1&quot;&gt;Chang Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hamrick_J/0/1/0/all/0/1&quot;&gt;Jessica B. Hamrick&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fisac_J/0/1/0/all/0/1&quot;&gt;Jaime F. Fisac&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dragan_A/0/1/0/all/0/1&quot;&gt;Anca D. Dragan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hedrick_J/0/1/0/all/0/1&quot;&gt;J. Karl Hedrick&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sastry_S/0/1/0/all/0/1&quot;&gt;S. Shankar Sastry&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Griffiths_T/0/1/0/all/0/1&quot;&gt;Thomas L. Griffiths&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.01812">
<title>Decoding-History-Based Adaptive Control of Attention for Neural Machine Translation. (arXiv:1802.01812v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1802.01812</link>
<description rdf:parseType="Literal">&lt;p&gt;Attention-based sequence-to-sequence model has proved successful in Neural
Machine Translation (NMT). However, the attention without consideration of
decoding history, which includes the past information in the decoder and the
attention mechanism, often causes much repetition. To address this problem, we
propose the decoding-history-based Adaptive Control of Attention (ACA) for the
NMT model. ACA learns to control the attention by keeping track of the decoding
history and the current information with a memory vector, so that the model can
take the translated contents and the current information into consideration.
Experiments on Chinese-English translation and the English-Vietnamese
translation have demonstrated that our model significantly outperforms the
strong baselines. The analysis shows that our model is capable of generating
translation with less repetition and higher accuracy. The code will be
available at https://github.com/lancopku
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1&quot;&gt;Junyang Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_S/0/1/0/all/0/1&quot;&gt;Shuming Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Su_Q/0/1/0/all/0/1&quot;&gt;Qi Su&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1&quot;&gt;Xu Sun&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.01933">
<title>A Survey Of Methods For Explaining Black Box Models. (arXiv:1802.01933v1 [cs.CY])</title>
<link>http://arxiv.org/abs/1802.01933</link>
<description rdf:parseType="Literal">&lt;p&gt;In the last years many accurate decision support systems have been
constructed as black boxes, that is as systems that hide their internal logic
to the user. This lack of explanation constitutes both a practical and an
ethical issue. The literature reports many approaches aimed at overcoming this
crucial weakness sometimes at the cost of scarifying accuracy for
interpretability. The applications in which black box decision systems can be
used are various, and each approach is typically developed to provide a
solution for a specific problem and, as a consequence, delineating explicitly
or implicitly its own definition of interpretability and explanation. The aim
of this paper is to provide a classification of the main problems addressed in
the literature with respect to the notion of explanation and the type of black
box system. Given a problem definition, a black box type, and a desired
explanation this survey should help the researcher to find the proposals more
useful for his own work. The proposed classification of approaches to open
black box models should also be useful for putting the many research open
questions in perspective.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guidotti_R/0/1/0/all/0/1&quot;&gt;Riccardo Guidotti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Monreale_A/0/1/0/all/0/1&quot;&gt;Anna Monreale&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Turini_F/0/1/0/all/0/1&quot;&gt;Franco Turini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pedreschi_D/0/1/0/all/0/1&quot;&gt;Dino Pedreschi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Giannotti_F/0/1/0/all/0/1&quot;&gt;Fosca Giannotti&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1503.08381">
<title>Towards Shockingly Easy Structured Classification: A Search-based Probabilistic Online Learning Framework. (arXiv:1503.08381v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1503.08381</link>
<description rdf:parseType="Literal">&lt;p&gt;There are two major approaches for structured classification. One is the
probabilistic gradient-based methods such as conditional random fields (CRF),
which has high accuracy but with drawbacks: slow training, and no support of
search-based optimization (which is important in many cases). The other one is
the search-based learning methods such as perceptrons and margin infused
relaxed algorithm (MIRA), which have fast training but also with drawbacks: low
accuracy, no probabilistic information, and non-convergence in real-world
tasks. We propose a novel and &quot;shockingly easy&quot; solution, a search-based
probabilistic online learning method, to address most of those issues. This
method searches the output candidates, derives probabilities, and conduct
efficient online learning. We show that this method is with fast training,
support search-based optimization, very easy to implement, with top accuracy,
with probabilities, and with theoretical guarantees of convergence. Experiments
on well-known tasks show that our method has better accuracy than CRF and
almost as fast training speed as perceptron and MIRA. Results also show that
SAPO can easily beat the state-of-the-art systems on those highly-competitive
tasks, achieving record-breaking accuracies. The codes can be found at
https://github.com/lancopku
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_X/0/1/0/all/0/1&quot;&gt;Xu Sun&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1707.06354">
<title>Pragmatic-Pedagogic Value Alignment. (arXiv:1707.06354v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1707.06354</link>
<description rdf:parseType="Literal">&lt;p&gt;As intelligent systems gain autonomy and capability, it becomes vital to
ensure that their objectives match those of their human users; this is known as
the value-alignment problem. In robotics, value alignment is key to the design
of collaborative robots that can integrate into human workflows, successfully
inferring and adapting to their users&apos; objectives as they go. We argue that a
meaningful solution to value alignment must combine multi-agent decision theory
with rich mathematical models of human cognition, enabling robots to tap into
people&apos;s natural collaborative capabilities. We present a solution to the
cooperative inverse reinforcement learning (CIRL) dynamic game based on
well-established cognitive models of decision making and theory of mind. The
solution captures a key reciprocity relation: the human will not plan her
actions in isolation, but rather reason pedagogically about how the robot might
learn from them; the robot, in turn, can anticipate this and interpret the
human&apos;s actions pragmatically. To our knowledge, this work constitutes the
first formal analysis of value alignment grounded in empirically validated
cognitive models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fisac_J/0/1/0/all/0/1&quot;&gt;Jaime F. Fisac&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gates_M/0/1/0/all/0/1&quot;&gt;Monica A. Gates&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hamrick_J/0/1/0/all/0/1&quot;&gt;Jessica B. Hamrick&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1&quot;&gt;Chang Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hadfield_Menell_D/0/1/0/all/0/1&quot;&gt;Dylan Hadfield-Menell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Palaniappan_M/0/1/0/all/0/1&quot;&gt;Malayandi Palaniappan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Malik_D/0/1/0/all/0/1&quot;&gt;Dhruv Malik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sastry_S/0/1/0/all/0/1&quot;&gt;S. Shankar Sastry&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Griffiths_T/0/1/0/all/0/1&quot;&gt;Thomas L. Griffiths&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dragan_A/0/1/0/all/0/1&quot;&gt;Anca D. Dragan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.09480">
<title>A Benchmark Environment Motivated by Industrial Control Problems. (arXiv:1709.09480v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1709.09480</link>
<description rdf:parseType="Literal">&lt;p&gt;In the research area of reinforcement learning (RL), frequently novel and
promising methods are developed and introduced to the RL community. However,
although many researchers are keen to apply their methods on real-world
problems, implementing such methods in real industry environments often is a
frustrating and tedious process. Generally, academic research groups have only
limited access to real industrial data and applications. For this reason, new
methods are usually developed, evaluated and compared by using artificial
software benchmarks. On one hand, these benchmarks are designed to provide
interpretable RL training scenarios and detailed insight into the learning
process of the method on hand. On the other hand, they usually do not share
much similarity with industrial real-world applications. For this reason we
used our industry experience to design a benchmark which bridges the gap
between freely available, documented, and motivated artificial benchmarks and
properties of real industrial problems. The resulting industrial benchmark (IB)
has been made publicly available to the RL community by publishing its Java and
Python code, including an OpenAI Gym wrapper, on Github. In this paper we
motivate and describe in detail the IB&apos;s dynamics and identify prototypic
experimental settings that capture common situations in real-world industry
control problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hein_D/0/1/0/all/0/1&quot;&gt;Daniel Hein&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Depeweg_S/0/1/0/all/0/1&quot;&gt;Stefan Depeweg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tokic_M/0/1/0/all/0/1&quot;&gt;Michel Tokic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Udluft_S/0/1/0/all/0/1&quot;&gt;Steffen Udluft&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hentschel_A/0/1/0/all/0/1&quot;&gt;Alexander Hentschel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Runkler_T/0/1/0/all/0/1&quot;&gt;Thomas A. Runkler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sterzing_V/0/1/0/all/0/1&quot;&gt;Volkmar Sterzing&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.07983">
<title>Safety-Aware Apprenticeship Learning. (arXiv:1710.07983v3 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1710.07983</link>
<description rdf:parseType="Literal">&lt;p&gt;Apprenticeship learning (AL) is a class of &quot;learning from demonstrations&quot;
techniques where the reward function of a Markov Decision Process (MDP) is
unknown to the learning agent and the agent has to derive a good policy by
observing an expert&apos;s demonstrations. In this paper, we study the problem of
how to make AL algorithms inherently safe while still meeting its learning
objective. We consider a setting where the unknown reward function is assumed
to be a linear combination of a set of state features, and the safety property
is specified in Probabilistic Computation Tree Logic (PCTL). By embedding
probabilistic model checking inside AL, we propose a novel
counterexample-guided approach that can ensure both safety and performance of
the learnt policy. We demonstrate the effectiveness of our approach on several
challenging AL scenarios where safety is essential.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_W/0/1/0/all/0/1&quot;&gt;Weichao Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1&quot;&gt;Wenchao Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.09373">
<title>Search Based Code Generation for Machine Learning Programs. (arXiv:1801.09373v2 [cs.SE] UPDATED)</title>
<link>http://arxiv.org/abs/1801.09373</link>
<description rdf:parseType="Literal">&lt;p&gt;Machine Learning (ML) has revamped every domain of life as it provides
powerful tools to build complex systems that learn and improve from experience
and data. Our key insight is that to solve a machine learning problem, data
scientists do not invent a new algorithm each time, but evaluate a range of
existing models with different configurations and select the best one. This
task is laborious, error-prone, and drains a large chunk of project budget and
time. In this paper we present a novel framework inspired by programming by
Sketching and Partial Evaluation to minimize human intervention in developing
ML solutions. We templatize machine learning algorithms to expose configuration
choices as holes to be searched. We share code and computation between
different algorithms, and only partially evaluate configuration space of
algorithms based on information gained from initial algorithm evaluations. We
also employ hierarchical and heuristic based pruning to reduce the search
space. Our initial findings indicate that our approach can generate highly
accurate ML models. Interviews with data scientists show that they feel our
framework can eliminate sources of common errors and significantly reduce
development time.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Malik_M/0/1/0/all/0/1&quot;&gt;Muhammad Zubair Malik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nawaz_M/0/1/0/all/0/1&quot;&gt;Muhammad Nawaz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mustafa_N/0/1/0/all/0/1&quot;&gt;Nimrah Mustafa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Siddiqui_J/0/1/0/all/0/1&quot;&gt;Junaid Haroon Siddiqui&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1610.03761">
<title>Detecting Unseen Falls from Wearable Devices using Channel-wise Ensemble of Autoencoders. (arXiv:1610.03761v3 [cs.CV] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1610.03761</link>
<description rdf:parseType="Literal">&lt;p&gt;A fall is an abnormal activity that occurs rarely, so it is hard to collect
real data for falls. It is, therefore, difficult to use supervised learning
methods to automatically detect falls. Another challenge in using machine
learning methods to automatically detect falls is the choice of engineered
features. In this paper, we propose to use an ensemble of autoencoders to
extract features from different channels of wearable sensor data trained only
on normal activities. We show that the traditional approach of choosing a
threshold as the maximum of the reconstruction error on the training normal
data is not the right way to identify unseen falls. We propose two methods for
automatic tightening of reconstruction error from only the normal activities
for better identification of unseen falls. We present our results on two
activity recognition datasets and show the efficacy of our proposed method
against traditional autoencoder models and two standard one-class
classification methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khan_S/0/1/0/all/0/1&quot;&gt;Shehroz S. Khan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Taati_B/0/1/0/all/0/1&quot;&gt;Babak Taati&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.01610">
<title>Fast and accurate approximation of the full conditional for gamma shape parameters. (arXiv:1802.01610v1 [stat.CO])</title>
<link>http://arxiv.org/abs/1802.01610</link>
<description rdf:parseType="Literal">&lt;p&gt;The gamma distribution arises frequently in Bayesian models, but there is not
an easy-to-use conjugate prior for the shape parameter of a gamma. This
inconvenience is usually dealt with by using either Metropolis-Hastings moves,
rejection sampling methods, or numerical integration. However, in models with a
large number of shape parameters, these existing methods are slower or more
complicated than one would like, making them burdensome in practice. It turns
out that the full conditional distribution of the gamma shape parameter is well
approximated by a gamma distribution, even for small sample sizes. This article
introduces a quick and easy algorithm for finding a gamma distribution that
approximates the full conditional distribution of the shape parameter. We
empirically demonstrate the speed and accuracy of the approximation across a
wide range of conditions. If exactness is required, the approximation can be
used as a proposal distribution for Metropolis-Hastings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Miller_J/0/1/0/all/0/1&quot;&gt;Jeffrey W. Miller&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.01697">
<title>Deep Learning with a Rethinking Structure for Multi-label Classification. (arXiv:1802.01697v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.01697</link>
<description rdf:parseType="Literal">&lt;p&gt;Multi-label classification (MLC) is an important learning problem that
expects the learning algorithm to take the hidden correlation of the labels
into account. Extracting the hidden correlation is generally a challenging
task. In this work, we propose a novel deep learning framework to better
extract the hidden correlation with the help of the memory structure within
recurrent neural networks. The memory stores the temporary guesses on the
labels and effectively allows the framework to rethink about the goodness and
correlation of the guesses before making the final prediction. Furthermore, the
rethinking process makes it easy to adapt to different evaluation criterion to
match real-world application needs. Experimental results across many real-world
data sets justify that the rethinking process indeed improves MLC performance
across different evaluation criteria and leads to superior performance over
state-of-the-art MLC algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1&quot;&gt;Yao-Yuan Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1&quot;&gt;Yi-An Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chu_H/0/1/0/all/0/1&quot;&gt;Hong-Min Chu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1&quot;&gt;Hsuan-Tien Lin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.01709">
<title>Weakly-supervised Dictionary Learning. (arXiv:1802.01709v1 [eess.SP])</title>
<link>http://arxiv.org/abs/1802.01709</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a probabilistic modeling and inference framework for
discriminative analysis dictionary learning under a weak supervision setting.
Dictionary learning approaches have been widely used for tasks such as
low-level signal denoising and restoration as well as high-level classification
tasks, which can be applied to audio and image analysis. Synthesis dictionary
learning aims at jointly learning a dictionary and corresponding sparse
coefficients to provide accurate data representation. This approach is useful
for denoising and signal restoration, but may lead to sub-optimal
classification performance. By contrast, analysis dictionary learning provides
a transform that maps data to a sparse discriminative representation suitable
for classification. We consider the problem of analysis dictionary learning for
time-series data under a weak supervision setting in which signals are assigned
with a global label instead of an instantaneous label signal. We propose a
discriminative probabilistic model that incorporates both label information and
sparsity constraints on the underlying latent instantaneous label signal using
cardinality control. We present the expectation maximization (EM) procedure for
maximum likelihood estimation (MLE) of the proposed model. To facilitate a
computationally efficient E-step, we propose both a chain and a novel tree
graph reformulation of the graphical model. The performance of the proposed
model is demonstrated on both synthetic and real-world data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+You_Z/0/1/0/all/0/1&quot;&gt;Zeyu You&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Raich_R/0/1/0/all/0/1&quot;&gt;Raviv Raich&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Fern_X/0/1/0/all/0/1&quot;&gt;Xiaoli Z. Fern&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Kim_J/0/1/0/all/0/1&quot;&gt;Jinsub Kim&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.01737">
<title>Bayesian Coreset Construction via Greedy Iterative Geodesic Ascent. (arXiv:1802.01737v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.01737</link>
<description rdf:parseType="Literal">&lt;p&gt;Coherent uncertainty quantification is a key strength of Bayesian methods.
But modern algorithms for approximate Bayesian posterior inference often
sacrifice accurate posterior uncertainty estimation in the pursuit of
scalability. This work shows that previous Bayesian coreset construction
algorithms---which build a small, weighted subset of the data that approximates
the full dataset---are no exception. We demonstrate that these algorithms scale
the coreset log-likelihood suboptimally, resulting in underestimated posterior
uncertainty. To address this shortcoming, we develop greedy iterative geodesic
ascent (GIGA), a novel algorithm for Bayesian coreset construction that scales
the coreset log-likelihood optimally. GIGA provides geometric decay in
posterior approximation error as a function of coreset size, and maintains the
fast running time of its predecessors. The paper concludes with validation of
GIGA on both synthetic and real datasets, demonstrating that it reduces
posterior approximation error by orders of magnitude compared with previous
coreset constructions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Campbell_T/0/1/0/all/0/1&quot;&gt;Trevor Campbell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Broderick_T/0/1/0/all/0/1&quot;&gt;Tamara Broderick&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.01751">
<title>Near-Optimal Coresets of Kernel Density Estimates. (arXiv:1802.01751v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.01751</link>
<description rdf:parseType="Literal">&lt;p&gt;We construct near-optimal coresets for kernel density estimate for points in
$\mathbb{R^d}$ when the kernel is positive definite. Specifically we show a
polynomial time construction for a coreset of size $O(\sqrt{d\log
(1/\epsilon)}/\epsilon)$, and we show a near-matching lower bound of size
$\Omega(\sqrt{d}/\epsilon)$. The upper bound is a polynomial in $1/\epsilon$
improvement when $d \in [3,1/\epsilon^2)$ (for all kernels except the Gaussian
kernel which had a previous upper bound of $O((1/\epsilon) \log^d
(1/\epsilon))$) and the lower bound is the first known lower bound to depend on
$d$ for this problem. Moreover, the upper bound restriction that the kernel is
positive definite is significant in that it applies to a wide-variety of
kernels, specifically those most important for machine learning. This includes
kernels for information distances and the sinc kernel which can be negative.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Phillips_J/0/1/0/all/0/1&quot;&gt;Jeff M. Phillips&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tai_W/0/1/0/all/0/1&quot;&gt;Wai Ming Tai&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.01756">
<title>Highly accurate model for prediction of lung nodule malignancy with CT scans. (arXiv:1802.01756v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1802.01756</link>
<description rdf:parseType="Literal">&lt;p&gt;Computed tomography (CT) examinations are commonly used to predict lung
nodule malignancy in patients, which are shown to improve noninvasive early
diagnosis of lung cancer. It remains challenging for computational approaches
to achieve performance comparable to experienced radiologists. Here we present
NoduleX, a systematic approach to predict lung nodule malignancy from CT data,
based on deep learning convolutional neural networks (CNN). For training and
validation, we analyze &amp;gt;1000 lung nodules in images from the LIDC/IDRI cohort.
All nodules were identified and classified by four experienced thoracic
radiologists who participated in the LIDC project. NoduleX achieves high
accuracy for nodule malignancy classification, with an AUC of ~0.99. This is
commensurate with the analysis of the dataset by experienced radiologists. Our
approach, NoduleX, provides an effective framework for highly accurate nodule
malignancy prediction with the model trained on a large patient population. Our
results are replicable with software available at
&lt;a href=&quot;http://bioinformatics.astate.edu/NoduleX.&quot;&gt;this http URL&lt;/a&gt;
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Causey_J/0/1/0/all/0/1&quot;&gt;Jason Causey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Junyu Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_S/0/1/0/all/0/1&quot;&gt;Shiqian Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_B/0/1/0/all/0/1&quot;&gt;Bo Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qualls_J/0/1/0/all/0/1&quot;&gt;Jake Qualls&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Politte_D/0/1/0/all/0/1&quot;&gt;David G. Politte&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Prior_F/0/1/0/all/0/1&quot;&gt;Fred Prior&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_S/0/1/0/all/0/1&quot;&gt;Shuzhong Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_X/0/1/0/all/0/1&quot;&gt;Xiuzhen Huang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.01765">
<title>Training Generative Adversarial Networks via Primal-Dual Subgradient Methods: A Lagrangian Perspective on GAN. (arXiv:1802.01765v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.01765</link>
<description rdf:parseType="Literal">&lt;p&gt;We relate the minimax game of generative adversarial networks (GANs) to
finding the saddle points of the Lagrangian function for a convex optimization
problem, where the discriminator outputs and the distribution of generator
outputs play the roles of primal variables and dual variables, respectively.
This formulation shows the connection between the standard GAN training process
and the primal-dual subgradient methods for convex optimization. The inherent
connection does not only provide a theoretical convergence proof for training
GANs in the function space, but also inspires a novel objective function for
training. The modified objective function forces the distribution of generator
outputs to be updated along the direction according to the primal-dual
subgradient methods. A toy example shows that the proposed method is able to
resolve mode collapse, which in this case cannot be avoided by the standard GAN
or Wasserstein GAN. Experiments on both Gaussian mixture synthetic data and
real-world image datasets demonstrate the performance of the proposed method on
generating diverse samples.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1&quot;&gt;Xu Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jiang Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ge_H/0/1/0/all/0/1&quot;&gt;Hao Ge&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.01786">
<title>Mining Public Opinion about Economic Issues: Twitter and the U.S. Presidential Election. (arXiv:1802.01786v1 [cs.SI])</title>
<link>http://arxiv.org/abs/1802.01786</link>
<description rdf:parseType="Literal">&lt;p&gt;Opinion polls have been the bridge between public opinion and politicians in
elections. However, developing surveys to disclose people&apos;s feedback with
respect to economic issues is limited, expensive, and time-consuming. In recent
years, social media such as Twitter has enabled people to share their opinions
regarding elections. Social media has provided a platform for collecting a
large amount of social media data. This paper proposes a computational public
opinion mining approach to explore the discussion of economic issues in social
media during an election. Current related studies use text mining methods
independently for election analysis and election prediction; this research
combines two text mining methods: sentiment analysis and topic modeling. The
proposed approach has effectively been deployed on millions of tweets to
analyze economic concerns of people during the 2012 US presidential election.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Karami_A/0/1/0/all/0/1&quot;&gt;Amir Karami&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bennett_L/0/1/0/all/0/1&quot;&gt;London S. Bennett&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1&quot;&gt;Xiaoyun He&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1701.04831">
<title>Equivalence of restricted Boltzmann machines and tensor network states. (arXiv:1701.04831v2 [cond-mat.str-el] UPDATED)</title>
<link>http://arxiv.org/abs/1701.04831</link>
<description rdf:parseType="Literal">&lt;p&gt;The restricted Boltzmann machine (RBM) is one of the fundamental building
blocks of deep learning. RBM finds wide applications in dimensional reduction,
feature extraction, and recommender systems via modeling the probability
distributions of a variety of input data including natural images, speech
signals, and customer ratings, etc. We build a bridge between RBM and tensor
network states (TNS) widely used in quantum many-body physics research. We
devise efficient algorithms to translate an RBM into the commonly used TNS.
Conversely, we give sufficient and necessary conditions to determine whether a
TNS can be transformed into an RBM of given architectures. Revealing these
general and constructive connections can cross-fertilize both deep learning and
quantum many-body physics. Notably, by exploiting the entanglement entropy
bound of TNS, we can rigorously quantify the expressive power of RBM on complex
data sets. Insights into TNS and its entanglement capacity can guide the design
of more powerful deep learning architectures. On the other hand, RBM can
represent quantum many-body states with fewer parameters compared to TNS, which
may allow more efficient classical simulations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Chen_J/0/1/0/all/0/1&quot;&gt;Jing Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Cheng_S/0/1/0/all/0/1&quot;&gt;Song Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Xie_H/0/1/0/all/0/1&quot;&gt;Haidong Xie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Wang_L/0/1/0/all/0/1&quot;&gt;Lei Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Xiang_T/0/1/0/all/0/1&quot;&gt;Tao Xiang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1708.08333">
<title>Framing U-Net via Deep Convolutional Framelets: Application to Sparse-view CT. (arXiv:1708.08333v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1708.08333</link>
<description rdf:parseType="Literal">&lt;p&gt;X-ray computed tomography (CT) using sparse projection views is a recent
approach to reduce the radiation dose. However, due to the insufficient
projection views, an analytic reconstruction approach using the filtered back
projection (FBP) produces severe streaking artifacts. Recently, deep learning
approaches using large receptive field neural networks such as U-Net have
demonstrated impressive performance for sparse- view CT reconstruction.
However, theoretical justification is still lacking. Inspired by the recent
theory of deep convolutional framelets, the main goal of this paper is,
therefore, to reveal the limitation of U-Net and propose new multi-resolution
deep learning schemes. In particular, we show that the alternative U- Net
variants such as dual frame and the tight frame U-Nets satisfy the so-called
frame condition which make them better for effective recovery of high frequency
edges in sparse view- CT. Using extensive experiments with real patient data
set, we demonstrate that the new network architectures provide better
reconstruction performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Han_Y/0/1/0/all/0/1&quot;&gt;Yoseob Han&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1&quot;&gt;Jong Chul Ye&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.09026">
<title>Trace norm regularization and faster inference for embedded speech recognition RNNs. (arXiv:1710.09026v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1710.09026</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose and evaluate new techniques for compressing and speeding up dense
matrix multiplications as found in the fully connected and recurrent layers of
neural networks for embedded large vocabulary continuous speech recognition
(LVCSR). For compression, we introduce and study a trace norm regularization
technique for training low rank factored versions of matrix multiplications.
Compared to standard low rank training, we show that our method leads to good
accuracy versus number of parameter trade-offs and can be used to speed up
training of large models. For speedup, we enable faster inference on ARM
processors through new open sourced kernels optimized for small batch sizes,
resulting in 3x to 7x speed ups over the widely used gemmlowp library. Beyond
LVCSR, we expect our techniques and kernels to be more generally applicable to
embedded neural networks with large fully connected or recurrent layers.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kliegl_M/0/1/0/all/0/1&quot;&gt;Markus Kliegl&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goyal_S/0/1/0/all/0/1&quot;&gt;Siddharth Goyal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_K/0/1/0/all/0/1&quot;&gt;Kexin Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Srinet_K/0/1/0/all/0/1&quot;&gt;Kavya Srinet&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shoeybi_M/0/1/0/all/0/1&quot;&gt;Mohammad Shoeybi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.06104">
<title>Towards better understanding of gradient-based attribution methods for Deep Neural Networks. (arXiv:1711.06104v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1711.06104</link>
<description rdf:parseType="Literal">&lt;p&gt;Understanding the flow of information in Deep Neural Networks (DNNs) is a
challenging problem that has gain increasing attention over the last few years.
While several methods have been proposed to explain network predictions, there
have been only a few attempts to compare them from a theoretical perspective.
What is more, no exhaustive empirical comparison has been performed in the
past. In this work, we analyze four gradient-based attribution methods and
formally prove conditions of equivalence and approximation between them. By
reformulating two of these methods, we construct a unified framework which
enables a direct comparison, as well as an easier implementation. Finally, we
propose a novel evaluation metric, called Sensitivity-n and test the
gradient-based attribution methods alongside with a simple perturbation-based
attribution method on several datasets in the domains of image and text
classification, using various network architectures.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ancona_M/0/1/0/all/0/1&quot;&gt;Marco Ancona&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ceolini_E/0/1/0/all/0/1&quot;&gt;Enea Ceolini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oztireli_C/0/1/0/all/0/1&quot;&gt;Cengiz &amp;#xd6;ztireli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gross_M/0/1/0/all/0/1&quot;&gt;Markus Gross&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.01887">
<title>Deep Gradient Compression: Reducing the Communication Bandwidth for Distributed Training. (arXiv:1712.01887v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1712.01887</link>
<description rdf:parseType="Literal">&lt;p&gt;Large-scale distributed training requires significant communication bandwidth
for gradient exchange that limits the scalability of multi-node training, and
requires expensive high-bandwidth network infrastructure. The situation gets
even worse with distributed training on mobile devices (federated learning),
which suffers from higher latency, lower throughput, and intermittent poor
connections. In this paper, we find 99.9% of the gradient exchange in
distributed SGD is redundant, and propose Deep Gradient Compression (DGC) to
greatly reduce the communication bandwidth. To preserve accuracy during
compression, DGC employs four methods: momentum correction, local gradient
clipping, momentum factor masking, and warm-up training. We have applied Deep
Gradient Compression to image classification, speech recognition, and language
modeling with multiple datasets including Cifar10, ImageNet, Penn Treebank, and
Librispeech Corpus. On these scenarios, Deep Gradient Compression achieves a
gradient compression ratio from 270x to 600x without losing accuracy, cutting
the gradient size of ResNet-50 from 97MB to 0.35MB, and for DeepSpeech from
488MB to 0.74MB. Deep gradient compression enables large-scale distributed
training on inexpensive commodity 1Gbps Ethernet and facilitates distributed
training on mobile.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_Y/0/1/0/all/0/1&quot;&gt;Yujun Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1&quot;&gt;Song Han&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mao_H/0/1/0/all/0/1&quot;&gt;Huizi Mao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yu Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dally_W/0/1/0/all/0/1&quot;&gt;William J. Dally&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1611.09461">
<title>Cost-Sensitive Reference Pair Encoding for Multi-Label Learning. (arXiv:1611.09461v2 [cs.LG] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1611.09461</link>
<description rdf:parseType="Literal">&lt;p&gt;A general framework for multi-label classification(MLC) called multi-label
error-correcting code (ML-ECC) utilizes coding schemes in communication to
improve MLC performance. The framework includes some key algorithms for some
special cases of MLC, such as binary relevance and random k-labelsets.
Nevertheless, current ML-ECC algorithms are usually designed for one or a few
evaluation criteria, and thus may suffer from bad performance with respect to
other criteria. In this paper, we propose a ML-ECC algorithm that takes the
evaluation criteria into account within the error-correcting code.This
algorithm, named cost-sensitive reference pair encoding(CSRPE), first
transforms the MLC problem into exponentially many binary classification
problems based on the criterion information and a series of reduction steps
from MLC to multi-class classification and then to binary classification. The
exponentially many binary classifiers cause training and prediction
challenges.We resolve the training challenge by random sampling and the
prediction challenge by nearest-neighbor decoding. Extensive experimental
results show that CSRPE achieves stable convergence, and performs better than
other ML-ECC algorithms and the state-of-the-art cost-sensitive MLC algorithms
across different criteria. Furthermore, we demonstrate the potential of CSRPE
in preserving the criterion information by extending it to a novel multi-label
active learning algorithm. The algorithm calculates the uncertainty of each
unlabeled example in the coding space of CSRPE and queries the most uncertain
one. Experimental results demonstrate that the proposed algorithm is superior
to existing multi-label active learning algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1&quot;&gt;Yao-Yuan Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_K/0/1/0/all/0/1&quot;&gt;Kuan-Hao Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chang_C/0/1/0/all/0/1&quot;&gt;Chih-Wei Chang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_H/0/1/0/all/0/1&quot;&gt;Hsuan-Tien Lin&lt;/a&gt;</dc:creator>
</item></rdf:RDF>