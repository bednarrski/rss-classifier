<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Boring papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Bad Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-04-29T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.10306"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.09877"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.09558"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.10227"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.10247"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.10332"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.10392"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.10437"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.10447"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.10467"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.10544"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.10601"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1703.08100"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.04342"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.01193"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.03824"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.09843"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.10204"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.10266"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.10279"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.10299"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.10318"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.10328"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.10390"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.10454"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.10488"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.10500"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.10535"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.10556"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.05852"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.00543"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1804.10306">
<title>Universal approximations of invariant maps by neural networks. (arXiv:1804.10306v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1804.10306</link>
<description rdf:parseType="Literal">&lt;p&gt;We describe generalizations of the universal approximation theorem for neural
networks to maps invariant or equivariant with respect to linear
representations of groups. Our goal is to establish network-like computational
models that are both invariant/equivariant and provably complete in the sense
of their ability to approximate any continuous invariant/equivariant map. Our
contribution is three-fold. First, in the general case of compact groups we
propose a construction of a complete invariant/equivariant network using an
intermediate polynomial layer. We invoke classical theorems of Hilbert and Weyl
to justify and simplify this construction; in particular, we describe an
explicit complete ansatz for approximation of permutation-invariant maps.
Second, we consider groups of translations and prove several versions of the
universal approximation theorem for convolutional networks in the limit of
continuous signals on euclidean spaces. Finally, we consider 2D signal
transformations equivariant with respect to the group SE(2) of rigid euclidean
motions. In this case we introduce the &quot;charge--conserving convnet&quot; -- a
convnet-like computational model based on the decomposition of the feature
space into isotypic representations of SO(2). We prove this model to be a
universal approximator for continuous SE(2)--equivariant signal
transformations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yarotsky_D/0/1/0/all/0/1&quot;&gt;Dmitry Yarotsky&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.09877">
<title>DRACO: Robust Distributed Training via Redundant Gradients. (arXiv:1803.09877v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1803.09877</link>
<description rdf:parseType="Literal">&lt;p&gt;Distributed model training is vulnerable to worst-case system failures and
adversarial compute nodes, i.e., nodes that use malicious updates to corrupt
the global model stored at a parameter server (PS). To tolerate node failures
and adversarial attacks, recent work suggests using variants of the geometric
median to aggregate distributed updates at the PS, in place of bulk averaging.
Although median-based update rules are robust to adversarial nodes, their
computational cost can be prohibitive in large-scale settings and their
convergence guarantees often require relatively strong assumptions.
&lt;/p&gt;
&lt;p&gt;In this work, we present DRACO, a scalable framework for robust distributed
training that uses ideas from coding theory. In DRACO, each compute node
evaluates redundant gradients that are then used by the parameter server to
eliminate the effects of adversarial updates. We present problem-independent
robustness guarantees for DRACO and show that the model it produces is
identical to the one trained in the adversary-free setup. We provide extensive
experiments on real datasets and distributed setups across a variety of
large-scale models, where we show that DRACO is several times to orders of
magnitude faster than median-based approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chen_L/0/1/0/all/0/1&quot;&gt;Lingjiao Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wang_H/0/1/0/all/0/1&quot;&gt;Hongyi Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Charles_Z/0/1/0/all/0/1&quot;&gt;Zachary Charles&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Papailiopoulos_D/0/1/0/all/0/1&quot;&gt;Dimitris Papailiopoulos&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.09558">
<title>A Visual Distance for WordNet. (arXiv:1804.09558v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1804.09558</link>
<description rdf:parseType="Literal">&lt;p&gt;Measuring the distance between concepts is an important field of study of
Natural Language Processing, as it can be used to improve tasks related to the
interpretation of those same concepts. WordNet, which includes a wide variety
of concepts associated with words (i.e., synsets), is often used as a source
for computing those distances. In this paper, we explore a distance for WordNet
synsets based on visual features, instead of lexical ones. For this purpose, we
extract the graphic features generated within a deep convolutional neural
networks trained with ImageNet and use those features to generate a
representative of each synset. Based on those representatives, we define a
distance measure of synsets, which complements the traditional lexical
distances. Finally, we propose some experiments to evaluate its performance and
compare it with the current state-of-the-art.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Perez_Arnal_R/0/1/0/all/0/1&quot;&gt;Raquel P&amp;#xe9;rez-Arnal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vilalta_A/0/1/0/all/0/1&quot;&gt;Armand Vilalta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garcia_Gasulla_D/0/1/0/all/0/1&quot;&gt;Dario Garcia-Gasulla&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cortes_U/0/1/0/all/0/1&quot;&gt;Ulises Cort&amp;#xe9;s&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ayguade_E/0/1/0/all/0/1&quot;&gt;Eduard Ayguad&amp;#xe9;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Labarta_J/0/1/0/all/0/1&quot;&gt;Jesus Labarta&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.10227">
<title>Temporal Answer Set Programming on Finite Traces. (arXiv:1804.10227v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1804.10227</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we introduce an alternative approach to Temporal Answer Set
Programming that relies on a variation of Temporal Equilibrium Logic (TEL) for
finite traces. This approach allows us to even out the expressiveness of TEL
over infinite traces with the computational capacity of (incremental) Answer
Set Programming (ASP). Also, we argue that finite traces are more natural when
reasoning about action and change. As a result, our approach is readily
implementable via multi-shot ASP systems and benefits from an extension of
ASP&apos;s full-fledged input language with temporal operators. This includes future
as well as past operators whose combination offers a rich temporal modeling
language. For computation, we identify the class of temporal logic programs and
prove that it constitutes a normal form for our approach. Finally, we outline
two implementations, a generic one and an extension of clingo.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cabalar_P/0/1/0/all/0/1&quot;&gt;Pedro Cabalar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kaminski_R/0/1/0/all/0/1&quot;&gt;Roland Kaminski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schaub_T/0/1/0/all/0/1&quot;&gt;Torsten Schaub&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schuhmann_A/0/1/0/all/0/1&quot;&gt;Anna Schuhmann&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.10247">
<title>Experimenting with robotic intra-logistics domains. (arXiv:1804.10247v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1804.10247</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce the asprilo [1] framework to facilitate experimental studies of
approaches addressing complex dynamic applications. For this purpose, we have
chosen the domain of robotic intra-logistics. This domain is not only highly
relevant in the context of today&apos;s fourth industrial revolution but it moreover
combines a multitude of challenging issues within a single uniform framework.
This includes multi-agent planning, reasoning about action, change, resources,
strategies, etc. In return, asprilo allows users to study alternative solutions
as regards effectiveness and scalability. Although asprilo relies on Answer Set
Programming and Python, it is readily usable by any system complying with its
fact-oriented interface format. This makes it attractive for benchmarking and
teaching well beyond logic programming. More precisely, asprilo consists of a
versatile benchmark generator, solution checker and visualizer as well as a
bunch of reference encodings featuring various ASP techniques. Importantly, the
visualizer&apos;s animation capabilities are indispensable for complex scenarios
like intra-logistics in order to inspect valid as well as invalid solution
candidates. Also, it allows for graphically editing benchmark layouts that can
be used as a basis for generating benchmark suites.
&lt;/p&gt;
&lt;p&gt;[1] asprilo stands for Answer Set Programming for robotic intra-logistics
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gebser_M/0/1/0/all/0/1&quot;&gt;Martin Gebser&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Obermeier_P/0/1/0/all/0/1&quot;&gt;Philipp Obermeier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Otto_T/0/1/0/all/0/1&quot;&gt;Thomas Otto&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schaub_T/0/1/0/all/0/1&quot;&gt;Torsten Schaub&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sabuncu_O/0/1/0/all/0/1&quot;&gt;Orkunt Sabuncu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_V/0/1/0/all/0/1&quot;&gt;Van Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Son_T/0/1/0/all/0/1&quot;&gt;Tran Cao Son&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.10332">
<title>Sim-to-Real: Learning Agile Locomotion For Quadruped Robots. (arXiv:1804.10332v1 [cs.RO])</title>
<link>http://arxiv.org/abs/1804.10332</link>
<description rdf:parseType="Literal">&lt;p&gt;Designing agile locomotion for quadruped robots often requires extensive
expertise and tedious manual tuning. In this paper, we present a system to
automate this process by leveraging deep reinforcement learning techniques. Our
system can learn quadruped locomotion from scratch using simple reward signals.
In addition, users can provide an open loop reference to guide the learning
process when more control over the learned gait is needed. The control policies
are learned in a physics simulator and then deployed on real robots. In
robotics, policies trained in simulation often do not transfer to the real
world. We narrow this reality gap by improving the physics simulator and
learning robust policies. We improve the simulation using system
identification, developing an accurate actuator model and simulating latency.
We learn robust controllers by randomizing the physical environments, adding
perturbations and designing a compact observation space. We evaluate our system
on two agile locomotion gaits: trotting and galloping. After learning in
simulation, a quadruped robot can successfully perform both gaits in the real
world.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tan_J/0/1/0/all/0/1&quot;&gt;Jie Tan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1&quot;&gt;Tingnan Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Coumans_E/0/1/0/all/0/1&quot;&gt;Erwin Coumans&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Iscen_A/0/1/0/all/0/1&quot;&gt;Atil Iscen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bai_Y/0/1/0/all/0/1&quot;&gt;Yunfei Bai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hafner_D/0/1/0/all/0/1&quot;&gt;Danijar Hafner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bohez_S/0/1/0/all/0/1&quot;&gt;Steven Bohez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vanhoucke_V/0/1/0/all/0/1&quot;&gt;Vincent Vanhoucke&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.10392">
<title>An adaptive self-organizing fuzzy logic controller in a serious game for motor impairment rehabilitation. (arXiv:1804.10392v1 [cs.HC])</title>
<link>http://arxiv.org/abs/1804.10392</link>
<description rdf:parseType="Literal">&lt;p&gt;Rehabilitation robotics combined with video game technology provides a means
of assisting in the rehabilitation of patients with neuromuscular disorders by
performing various facilitation movements. The current work presents ReHabGame,
a serious game using a fusion of implemented technologies that can be easily
used by patients and therapists to assess and enhance sensorimotor performance
and also increase the activities in the daily lives of patients. The game
allows a player to control avatar movements through a Kinect Xbox, Myo armband
and rudder foot pedal, and involves a series of reach-grasp-collect tasks whose
difficulty levels are learnt by a fuzzy interface. The orientation, angular
velocity, head and spine tilts and other data generated by the player are
monitored and saved, whilst the task completion is calculated by solving an
inverse kinematics algorithm which orientates the upper limb joints of the
avatar. The different values in upper body quantities of movement provide fuzzy
input from which crisp output is determined and used to generate an appropriate
subsequent rehabilitation game level. The system can thus provide personalised,
autonomously-learnt rehabilitation programmes for patients with neuromuscular
disorders with superior predictions to guide the development of improved
clinical protocols compared to traditional theraputic activities.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Esfahlani_S/0/1/0/all/0/1&quot;&gt;Shabnam Sadeghi Esfahlani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cirstea_S/0/1/0/all/0/1&quot;&gt;Silvia Cirstea&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sanaei_A/0/1/0/all/0/1&quot;&gt;Alireza Sanaei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wilson_G/0/1/0/all/0/1&quot;&gt;George Wilson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.10437">
<title>Routing Driverless Transport Vehicles in Car Assembly with Answer Set Programming. (arXiv:1804.10437v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1804.10437</link>
<description rdf:parseType="Literal">&lt;p&gt;Automated storage and retrieval systems are principal components of modern
production and warehouse facilities. In particular, automated guided vehicles
nowadays substitute human-operated pallet trucks in transporting production
materials between storage locations and assembly stations. While low-level
control systems take care of navigating such driverless vehicles along
programmed routes and avoid collisions even under unforeseen circumstances, in
the common case of multiple vehicles sharing the same operation area, the
problem remains how to set up routes such that a collection of transport tasks
is accomplished most effectively. We address this prevalent problem in the
context of car assembly at Mercedes-Benz Ludwigsfelde GmbH, a large-scale
producer of commercial vehicles, where routes for automated guided vehicles
used in the production process have traditionally been hand-coded by human
engineers. Such ad-hoc methods may suffice as long as a running production
process remains in place, while any change in the factory layout or production
targets necessitates tedious manual reconfiguration, not to mention the missing
portability between different production plants. Unlike this, we propose a
declarative approach based on Answer Set Programming to optimize the routes
taken by automated guided vehicles for accomplishing transport tasks. The
advantages include a transparent and executable problem formalization, provable
optimality of routes relative to objective criteria, as well as elaboration
tolerance towards particular factory layouts and production targets. Moreover,
we demonstrate that our approach is efficient enough to deal with the transport
tasks evolving in realistic production processes at the car factory of
Mercedes-Benz Ludwigsfelde GmbH.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gebser_M/0/1/0/all/0/1&quot;&gt;Martin Gebser&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Obermeier_P/0/1/0/all/0/1&quot;&gt;Philipp Obermeier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ratsch_Heitmann_M/0/1/0/all/0/1&quot;&gt;Michel Ratsch-Heitmann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Runge_M/0/1/0/all/0/1&quot;&gt;Mario Runge&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schaub_T/0/1/0/all/0/1&quot;&gt;Torsten Schaub&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.10447">
<title>Generalized Logical Operations among Conditional Events. (arXiv:1804.10447v1 [math.PR])</title>
<link>http://arxiv.org/abs/1804.10447</link>
<description rdf:parseType="Literal">&lt;p&gt;We generalize, by a progressive procedure, the notions of conjunction and
disjunction of two conditional events to the case of $n$ conditional events. In
our coherence-based approach, conjunctions and disjunctions are suitable
conditional random quantities. We define the notion of negation, by verifying
De Morgan&apos;s Laws. We also show that conjunction and disjunction satisfy the
associative and commutative properties, and a monotonicity property. Then, we
give some results on coherence of prevision assessments for some families of
compounded conditionals; in particular we examine the Fr\&apos;echet-Hoeffding
bounds. Moreover, we study the reverse probabilistic inference from the
conjunction $\mathcal{C}_{n+1}$ of $n+1$ conditional events to the family
$\{\mathcal{C}_{n},E_{n+1}|H_{n+1}\}$. We consider the relation with the notion
of quasi-conjunction and we examine in detail the coherence of the prevision
assessments related with the conjunction of three conditional events. Based on
conjunction, we also give a characterization of p-consistency and of
p-entailment, with applications to several inference rules in probabilistic
nonmonotonic reasoning. Finally, we examine some non p-valid inference rules;
then, we illustrate by an example two methods which allow to suitably modify
non p-valid inference rules in order to get inferences which are p-valid.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Gilio_A/0/1/0/all/0/1&quot;&gt;Angelo Gilio&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Sanfilippo_G/0/1/0/all/0/1&quot;&gt;Giuseppe Sanfilippo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.10467">
<title>Interaction-Aware Probabilistic Behavior Prediction in Urban Environments. (arXiv:1804.10467v1 [cs.RO])</title>
<link>http://arxiv.org/abs/1804.10467</link>
<description rdf:parseType="Literal">&lt;p&gt;Planning for autonomous driving in complex, urban scenarios requires accurate
trajectory prediction of the surrounding drivers. Their future behavior depends
on their route intentions, the road-geometry, traffic rules and mutual
interaction, resulting in interdependencies between their trajectories. We
present a probabilistic prediction framework based on a dynamic Bayesian
network, which represents the state of the complete scene including all agents
and respects the aforementioned dependencies. We propose Markovian,
context-dependent motion models to define the interaction-aware behavior of
drivers. At first, the state of the dynamic Bayesian network is estimated over
time by tracking the single agents via sequential Monte Carlo inference.
Secondly, we perform a probabilistic forward simulation of the network&apos;s
estimated belief state to generate the different combinatorial scene
developments. This provides the corresponding trajectories for the set of
possible, future scenes. Our framework can handle various road layouts and
number of traffic participants. We evaluate the approach in online simulations
and real-world scenarios. It is shown that our interaction-aware prediction
outperforms interaction-unaware physics- and map-based approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schulz_J/0/1/0/all/0/1&quot;&gt;Jens Schulz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hubmann_C/0/1/0/all/0/1&quot;&gt;Constantin Hubmann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lochner_J/0/1/0/all/0/1&quot;&gt;Julian L&amp;#xf6;chner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Burschka_D/0/1/0/all/0/1&quot;&gt;Darius Burschka&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.10544">
<title>Persistent Monitoring of Stochastic Spatio-temporal Phenomena with a Small Team of Robots. (arXiv:1804.10544v1 [cs.RO])</title>
<link>http://arxiv.org/abs/1804.10544</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents a solution for persistent monitoring of real-world
stochastic phenomena, where the underlying covariance structure changes sharply
across time, using a small number of mobile robot sensors. We propose an
adaptive solution for the problem where stochastic real-world dynamics are
modeled as a Gaussian Process (GP). The belief on the underlying covariance
structure is learned from recently observed dynamics as a Gaussian Mixture (GM)
in the low-dimensional hyper-parameters space of the GP and adapted across time
using Sequential Monte Carlo methods. Each robot samples a belief point from
the GM and locally optimizes a set of informative regions by greedy
maximization of the submodular entropy function. The key contributions of this
paper are threefold: adapting the belief on the covariance using Markov Chain
Monte Carlo (MCMC) sampling such that particles survive even under sharp
covariance changes across time; exploiting the belief to transform the problem
of entropy maximization into a decentralized one; and developing an
approximation algorithm to maximize entropy on a set of informative regions in
the continuous space. We illustrate the application of the proposed solution
through extensive simulations using an artificial dataset and multiple real
datasets from fixed sensor deployments, and compare it to three competing
state-of-the-art approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garg_S/0/1/0/all/0/1&quot;&gt;Sahil Garg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ayanian_N/0/1/0/all/0/1&quot;&gt;Nora Ayanian&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.10601">
<title>Expectation Optimization with Probabilistic Guarantees in POMDPs with Discounted-sum Objectives. (arXiv:1804.10601v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1804.10601</link>
<description rdf:parseType="Literal">&lt;p&gt;Partially-observable Markov decision processes (POMDPs) with discounted-sum
payoff are a standard framework to model a wide range of problems related to
decision making under uncertainty. Traditionally, the goal has been to obtain
policies that optimize the expectation of the discounted-sum payoff. A key
drawback of the expectation measure is that even low probability events with
extreme payoff can significantly affect the expectation, and thus the obtained
policies are not necessarily risk-averse. An alternate approach is to optimize
the probability that the payoff is above a certain threshold, which allows
obtaining risk-averse policies, but ignores optimization of the expectation. We
consider the expectation optimization with probabilistic guarantee (EOPG)
problem, where the goal is to optimize the expectation ensuring that the payoff
is above a given threshold with at least a specified probability. We present
several results on the EOPG problem, including the first algorithm to solve it.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chatterjee_K/0/1/0/all/0/1&quot;&gt;Krishnendu Chatterjee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Elgyutt_A/0/1/0/all/0/1&quot;&gt;Adri&amp;#xe1;n Elgy&amp;#xfc;tt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Novotny_P/0/1/0/all/0/1&quot;&gt;Petr Novotn&amp;#xfd;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rouille_O/0/1/0/all/0/1&quot;&gt;Owen Rouill&amp;#xe9;&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1703.08100">
<title>Semi-supervised Embedding in Attributed Networks with Outliers. (arXiv:1703.08100v4 [cs.SI] UPDATED)</title>
<link>http://arxiv.org/abs/1703.08100</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we propose a novel framework, called Semi-supervised Embedding
in Attributed Networks with Outliers (SEANO), to learn a low-dimensional vector
representation that systematically captures the topological proximity,
attribute affinity and label similarity of vertices in a partially labeled
attributed network (PLAN). Our method is designed to work in both transductive
and inductive settings while explicitly alleviating noise effects from
outliers. Experimental results on various datasets drawn from the web, text and
image domains demonstrate the advantages of SEANO over state-of-the-art methods
in semi-supervised classification under transductive as well as inductive
settings. We also show that a subset of parameters in SEANO is interpretable as
outlier score and can significantly outperform baseline methods when applied
for detecting network outliers. Finally, we present the use of SEANO in a
challenging real-world setting -- flood mapping of satellite images and show
that it is able to outperform modern remote sensing algorithms for this task.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_J/0/1/0/all/0/1&quot;&gt;Jiongqian Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jacobs_P/0/1/0/all/0/1&quot;&gt;Peter Jacobs&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1&quot;&gt;Jiankai Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Parthasarathy_S/0/1/0/all/0/1&quot;&gt;Srinivasan Parthasarathy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.04342">
<title>Combining Symbolic Expressions and Black-box Function Evaluations in Neural Programs. (arXiv:1801.04342v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1801.04342</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural programming involves training neural networks to learn programs,
mathematics, or logic from data. Previous works have failed to achieve good
generalization performance, especially on problems and programs with high
complexity or on large domains. This is because they mostly rely either on
black-box function evaluations that do not capture the structure of the
program, or on detailed execution traces that are expensive to obtain, and
hence the training data has poor coverage of the domain under consideration. We
present a novel framework that utilizes black-box function evaluations, in
conjunction with symbolic expressions that define relationships between the
given functions. We employ tree LSTMs to incorporate the structure of the
symbolic expression trees. We use tree encoding for numbers present in function
evaluation data, based on their decimal representation. We present an
evaluation benchmark for this task to demonstrate our proposed model combines
symbolic reasoning and function evaluation in a fruitful manner, obtaining high
accuracies in our experiments. Our framework generalizes significantly better
to expressions of higher depth and is able to fill partial equations with valid
completions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Arabshahi_F/0/1/0/all/0/1&quot;&gt;Forough Arabshahi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singh_S/0/1/0/all/0/1&quot;&gt;Sameer Singh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Anandkumar_A/0/1/0/all/0/1&quot;&gt;Animashree Anandkumar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.01193">
<title>The Logical Essentials of Bayesian Reasoning. (arXiv:1804.01193v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1804.01193</link>
<description rdf:parseType="Literal">&lt;p&gt;This chapter offers an accessible introduction to the channel-based approach
to Bayesian probability theory. This framework rests on algebraic and logical
foundations, inspired by the methodologies of programming language semantics.
It offers a uniform, structured and expressive language for describing Bayesian
phenomena in terms of familiar programming concepts, like channel, predicate
transformation and state transformation. The introduction also covers inference
in Bayesian networks, which will be modelled by a suitable calculus of string
diagrams.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jacobs_B/0/1/0/all/0/1&quot;&gt;Bart Jacobs&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zanasi_F/0/1/0/all/0/1&quot;&gt;Fabio Zanasi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.03824">
<title>Reference-less Measure of Faithfulness for Grammatical Error Correction. (arXiv:1804.03824v3 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1804.03824</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose {\sc USim}, a semantic measure for Grammatical Error Correction
(GEC) that measures the semantic faithfulness of the output to the source,
thereby complementing existing reference-less measures (RLMs) for measuring the
output&apos;s grammaticality. {\sc USim} operates by comparing the semantic symbolic
structure of the source and the correction, without relying on manually-curated
references. Our experiments establish the validity of {\sc USim}, by showing
that (1) semantic annotation can be consistently applied to ungrammatical text;
(2) valid corrections obtain a high {\sc USim} similarity score to the source;
and (3) invalid corrections obtain a lower score.\footnote{Our code is
available in \url{https://github.com/borgr/USim}.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Choshen_L/0/1/0/all/0/1&quot;&gt;Leshem Choshen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abend_O/0/1/0/all/0/1&quot;&gt;Omri Abend&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.09843">
<title>Hierarchical Density Order Embeddings. (arXiv:1804.09843v1 [cs.CL] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1804.09843</link>
<description rdf:parseType="Literal">&lt;p&gt;By representing words with probability densities rather than point vectors,
probabilistic word embeddings can capture rich and interpretable semantic
information and uncertainty. The uncertainty information can be particularly
meaningful in capturing entailment relationships -- whereby general words such
as &quot;entity&quot; correspond to broad distributions that encompass more specific
words such as &quot;animal&quot; or &quot;instrument&quot;. We introduce density order embeddings,
which learn hierarchical representations through encapsulation of probability
densities. In particular, we propose simple yet effective loss functions and
distance metrics, as well as graph-based schemes to select negative samples to
better learn hierarchical density representations. Our approach provides
state-of-the-art performance on the WordNet hypernym relationship prediction
task and the challenging HyperLex lexical entailment dataset -- while retaining
a rich and interpretable density representation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Athiwaratkun_B/0/1/0/all/0/1&quot;&gt;Ben Athiwaratkun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wilson_A/0/1/0/all/0/1&quot;&gt;Andrew Gordon Wilson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.10204">
<title>End-to-End Speech Separation with Unfolded Iterative Phase Reconstruction. (arXiv:1804.10204v1 [cs.SD])</title>
<link>http://arxiv.org/abs/1804.10204</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper proposes an end-to-end approach for single-channel
speaker-independent multi-speaker speech separation, where time-frequency (T-F)
masking, the short-time Fourier transform (STFT), and its inverse are
represented as layers within a deep network. Previous approaches, rather than
computing a loss on the reconstructed signal, used a surrogate loss based on
the target STFT magnitudes. This ignores reconstruction error introduced by
phase inconsistency. In our approach, the loss function is directly defined on
the reconstructed signals, which are optimized for best separation. In
addition, we train through unfolded iterations of a phase reconstruction
algorithm, represented as a series of STFT and inverse STFT layers. While mask
values are typically limited to lie between zero and one for approaches using
the mixture phase for reconstruction, this limitation is less relevant if the
estimated magnitudes are to be used together with phase reconstruction. We thus
propose several novel activation functions for the output layer of the T-F
masking, to allow mask values beyond one. On the publicly-available wsj0-2mix
dataset, our approach achieves state-of-the-art 12.6 dB scale-invariant
signal-to-distortion ratio (SI-SDR) and 13.1 dB SDR, revealing new
possibilities for deep learning based phase reconstruction and representing a
fundamental progress towards solving the notoriously-hard cocktail party
problem.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zhong-Qiu Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roux_J/0/1/0/all/0/1&quot;&gt;Jonathan Le Roux&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1&quot;&gt;DeLiang Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hershey_J/0/1/0/all/0/1&quot;&gt;John R. Hershey&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.10266">
<title>Tensor Methods for Nonlinear Matrix Completion. (arXiv:1804.10266v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1804.10266</link>
<description rdf:parseType="Literal">&lt;p&gt;In the low rank matrix completion (LRMC) problem, the low rank assumption
means that the columns (or rows) of the matrix to be completed are points on a
low-dimensional linear algebraic variety. This paper extends this thinking to
cases where the columns are points on a low-dimensional nonlinear algebraic
variety, a problem we call Low Algebraic Dimension Matrix Completion (LADMC).
Matrices whose columns belong to a union of subspaces (UoS) are an important
special case. We propose a LADMC algorithm that leverages existing LRMC methods
on a tensorized representation of the data. For example, a second-order
tensorization representation is formed by taking the outer product of each
column with itself, and we consider higher order tensorizations as well. This
approach will succeed in many cases where traditional LRMC is guaranteed to
fail because the data are low-rank in the tensorized representation but not in
the original representation. We also provide a formal mathematical
justification for the success of our method. In particular, we show bounds of
the rank of these data in the tensorized representation, and we prove sampling
requirements to guarantee uniqueness of the solution. Interestingly, the
sampling requirements of our LADMC algorithm nearly match the information
theoretic lower bounds for matrix completion under a UoS model. We also provide
experimental results showing that the new approach significantly outperforms
existing state-of-the-art methods for matrix completion in many situations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ongie_G/0/1/0/all/0/1&quot;&gt;Greg Ongie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Balzano_L/0/1/0/all/0/1&quot;&gt;Laura Balzano&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pimentel_Alarcon_D/0/1/0/all/0/1&quot;&gt;Daniel Pimentel-Alarc&amp;#xf3;n&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Willett_R/0/1/0/all/0/1&quot;&gt;Rebecca Willett&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Nowak_R/0/1/0/all/0/1&quot;&gt;Robert D. Nowak&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.10279">
<title>Adaptive Sensing for Learning Nonstationary Environment Models. (arXiv:1804.10279v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1804.10279</link>
<description rdf:parseType="Literal">&lt;p&gt;Most environmental phenomena, such as wind profiles, ozone concentration and
sunlight distribution under a forest canopy, exhibit nonstationary dynamics
i.e. phenomenon variation change depending on the location and time of
occurrence. Non-stationary dynamics pose both theoretical and practical
challenges to statistical machine learning algorithms aiming to accurately
capture the complexities governing the evolution of such processes. In this
paper, we address the sampling aspects of the problem of learning nonstationary
spatio-temporal models, and propose an efficient yet simple algorithm - LISAL.
The core idea in LISAL is to learn two models using Gaussian processes (GPs)
wherein the first is a nonstationary GP directly modeling the phenomenon. The
second model uses a stationary GP representing a latent space corresponding to
changes in dynamics, or the nonstationarity characteristics of the first model.
LISAL involves adaptively sampling the latent space dynamics using information
theory quantities to reduce the computational cost during the learning phase.
The relevance of LISAL is extensively validated using multiple real world
datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garg_S/0/1/0/all/0/1&quot;&gt;Sahil Garg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1&quot;&gt;Amarjeet Singh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ramos_F/0/1/0/all/0/1&quot;&gt;Fabio Ramos&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.10299">
<title>Distributed Differentially-Private Algorithms for Matrix and Tensor Factorization. (arXiv:1804.10299v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1804.10299</link>
<description rdf:parseType="Literal">&lt;p&gt;In many signal processing and machine learning applications, datasets
containing private information are held at different locations, requiring the
development of distributed privacy-preserving algorithms. Tensor and matrix
factorizations are key components of many processing pipelines. In the
distributed setting, differentially private algorithms suffer because they
introduce noise to guarantee privacy. This paper designs new and improved
distributed and differentially private algorithms for two popular matrix and
tensor factorization methods: principal component analysis (PCA) and orthogonal
tensor decomposition (OTD). The new algorithms employ a correlated noise design
scheme to alleviate the effects of noise and can achieve the same noise level
as the centralized scenario. Experiments on synthetic and real data illustrate
the regimes in which the correlated noise allows performance matching with the
centralized setting, outperforming previous methods and demonstrating that
meaningful utility is possible while guaranteeing differential privacy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Imtiaz_H/0/1/0/all/0/1&quot;&gt;Hafiz Imtiaz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sarwate_A/0/1/0/all/0/1&quot;&gt;Anand D. Sarwate&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.10318">
<title>Efficiently Learning Nonstationary Gaussian Processes. (arXiv:1804.10318v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1804.10318</link>
<description rdf:parseType="Literal">&lt;p&gt;Most real world phenomena such as sunlight distribution under a forest
canopy, minerals concentration, stock valuation, exhibit nonstationary dynamics
i.e. phenomenon variation changes depending on the locality. Nonstationary
dynamics pose both theoretical and practical challenges to statistical machine
learning algorithms that aim to accurately capture the complexities governing
the evolution of such processes. Typically the nonstationary dynamics are
modeled using nonstationary Gaussian Process models (NGPS) that employ local
latent dynamics parameterization to correspondingly model the nonstationary
real observable dynamics. Recently, an approach based on most likely induced
latent dynamics representation attracted research community&apos;s attention for a
while. The approach could not be employed for large scale real world
applications because learning a most likely latent dynamics representation
involves maximization of marginal likelihood of the observed real dynamics that
becomes intractable as the number of induced latent points grows with problem
size. We have established a direct relationship between informativeness of the
induced latent dynamics and the marginal likelihood of the observed real
dynamics. This opens up the possibility of maximizing marginal likelihood of
observed real dynamics indirectly by near optimally maximizing entropy or
mutual information gain on the induced latent dynamics using greedy algorithms.
Therefore, for an efficient yet accurate inference, we propose to build an
induced latent dynamics representation using a novel algorithm LISAL that
adaptively maximizes entropy or mutual information on the induced latent
dynamics and marginal likelihood of observed real dynamics in an iterative
manner. The relevance of LISAL is validated using real world sensing datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garg_S/0/1/0/all/0/1&quot;&gt;Sahil Garg&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.10328">
<title>Scalable Bilinear $\pi$ Learning Using State and Action Features. (arXiv:1804.10328v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1804.10328</link>
<description rdf:parseType="Literal">&lt;p&gt;Approximate linear programming (ALP) represents one of the major algorithmic
families to solve large-scale Markov decision processes (MDP). In this work, we
study a primal-dual formulation of the ALP, and develop a scalable, model-free
algorithm called bilinear $\pi$ learning for reinforcement learning when a
sampling oracle is provided. This algorithm enjoys a number of advantages.
First, it adopts (bi)linear models to represent the high-dimensional value
function and state-action distributions, using given state and action features.
Its run-time complexity depends on the number of features, not the size of the
underlying MDPs. Second, it operates in a fully online fashion without having
to store any sample, thus having minimal memory footprint. Third, we prove that
it is sample-efficient, solving for the optimal policy to high precision with a
sample complexity linear in the dimension of the parameter space.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yichen Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1&quot;&gt;Lihong Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1&quot;&gt;Mengdi Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.10390">
<title>Automatic classification of trees using a UAV onboard camera and deep learning. (arXiv:1804.10390v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1804.10390</link>
<description rdf:parseType="Literal">&lt;p&gt;Automatic classification of trees using remotely sensed data has been a dream
of many scientists and land use managers. Recently, Unmanned aerial vehicles
(UAV) has been expected to be an easy-to-use, cost-effective tool for remote
sensing of forests, and deep learning has attracted attention for its ability
concerning machine vision. In this study, using a commercially available UAV
and a publicly available package for deep learning, we constructed a machine
vision system for the automatic classification of trees. In our method, we
segmented a UAV photography image of forest into individual tree crowns and
carried out object-based deep learning. As a result, the system was able to
classify 7 tree types at 89.0% accuracy. This performance is notable because we
only used basic RGB images from a standard UAV. In contrast, most of previous
studies used expensive hardware such as multispectral imagers to improve the
performance. This result means that our method has the potential to classify
individual trees in a cost-effective manner. This can be a usable tool for many
forest researchers and managements.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Onishi_M/0/1/0/all/0/1&quot;&gt;Masanori Onishi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ise_T/0/1/0/all/0/1&quot;&gt;Takeshi Ise&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.10454">
<title>Method to assess the functional role of noisy brain signals by mining envelope dynamics. (arXiv:1804.10454v1 [eess.SP])</title>
<link>http://arxiv.org/abs/1804.10454</link>
<description rdf:parseType="Literal">&lt;p&gt;Data-driven spatial filtering approaches are commonly used to assess rhythmic
brain activity from multichannel recordings such as electroencephalography
(EEG). As spatial filter estimation is prone to noise, non-stationarity effects
and limited data, a high model variability induced by slight changes of, e.g.,
involved hyperparameters is generally encountered. These aspects challenge the
assessment of functionally relevant features which are of special importance in
closed-loop applications as, e.g., in the field of rehabilitation. We propose a
data-driven method to identify groups of reliable and functionally relevant
oscillatory components computed by a spatial filtering approach. Therefore, we
initially embrace the variability of decoding models in a large configuration
space before condensing information by density-based clustering of components&apos;
functional signatures. Exemplified for a hand force task with rich within-trial
structure, the approach was evaluated on EEG data of 18 healthy subjects. We
found that functional characteristics of single components are revealed by
distinct temporal dynamics of their event-related power changes. Based on a
within-subject analysis, our clustering revealed seven groups of homogeneous
envelope dynamics on average. To support introspection by practitioners, we
provide a set of metrics to characterize and validate single clusterings. We
show that identified clusters contain components of strictly confined frequency
ranges, dominated by the alpha and beta band. Our method is applicable to any
spatial filtering algorithm. Despite high model variability, it allows
capturing and monitoring relevant oscillatory features. We foresee its
application in closed-loop applications such as brain-computer interface based
protocols in stroke rehabilitation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Meinel_A/0/1/0/all/0/1&quot;&gt;Andreas Meinel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Kolkhorst_H/0/1/0/all/0/1&quot;&gt;Henrich Kolkhorst&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Tangermann_M/0/1/0/all/0/1&quot;&gt;Michael Tangermann&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.10488">
<title>Offline Evaluation of Ranking Policies with Click Models. (arXiv:1804.10488v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1804.10488</link>
<description rdf:parseType="Literal">&lt;p&gt;Many web systems rank and present a list of items to users, from recommender
systems to search and advertising. An important problem in practice is to
evaluate new ranking policies offline and optimize them before they are
deployed. We address this problem by proposing new evaluation algorithms for
estimating the expected number of clicks on ranked lists from stored logs of
past results. The existing algorithms are not guaranteed to be statistically
efficient in our problem because the number of recommended lists can grow
exponentially with their length. To overcome this challenge, we use models of
user interaction with the list of items, the so-called click models, to
construct estimators that learn statistically efficiently. We analyze our
estimators and prove that they are more efficient than the estimators that do
not use the structure of the click model, under the assumption that the click
model holds. We evaluate our estimators in a series of experiments on a
real-world dataset and show that they consistently outperform prior estimators.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1&quot;&gt;Shuai Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abbasi_Yadkori_Y/0/1/0/all/0/1&quot;&gt;Yasin Abbasi-Yadkori&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kveton_B/0/1/0/all/0/1&quot;&gt;Branislav Kveton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Muthukrishnan_S/0/1/0/all/0/1&quot;&gt;S. Muthukrishnan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vinay_V/0/1/0/all/0/1&quot;&gt;Vishwa Vinay&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wen_Z/0/1/0/all/0/1&quot;&gt;Zheng Wen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.10500">
<title>Deep Reinforcement Learning to Acquire Navigation Skills for Wheel-Legged Robots in Complex Environments. (arXiv:1804.10500v1 [cs.RO])</title>
<link>http://arxiv.org/abs/1804.10500</link>
<description rdf:parseType="Literal">&lt;p&gt;Mobile robot navigation in complex and dynamic environments is a challenging
but important problem. Reinforcement learning approaches fail to solve these
tasks efficiently due to reward sparsities, temporal complexities and
high-dimensionality of sensorimotor spaces which are inherent in such problems.
We present a novel approach to train action policies to acquire navigation
skills for wheel-legged robots using deep reinforcement learning. The policy
maps height-map image observations to motor commands to navigate to a target
position while avoiding obstacles. We propose to acquire the multifaceted
navigation skill by learning and exploiting a number of manageable navigation
behaviors. We also introduce a domain randomization technique to improve the
versatility of the training samples. We demonstrate experimentally a
significant improvement in terms of data-efficiency, success rate, robustness
against irrelevant sensory data, and also the quality of the maneuver skills.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1&quot;&gt;Xi Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghadirzadeh_A/0/1/0/all/0/1&quot;&gt;Ali Ghadirzadeh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Folkesson_J/0/1/0/all/0/1&quot;&gt;John Folkesson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jensfelt_P/0/1/0/all/0/1&quot;&gt;Patric Jensfelt&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.10535">
<title>Learning Non-Stationary Space-Time Models for Environmental Monitoring. (arXiv:1804.10535v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1804.10535</link>
<description rdf:parseType="Literal">&lt;p&gt;One of the primary aspects of sustainable development involves accurate
understanding and modeling of environmental phenomena. Many of these phenomena
exhibit variations in both space and time and it is imperative to develop a
deeper understanding of techniques that can model space-time dynamics
accurately. In this paper we propose NOSTILL-GP - NOn-stationary Space TIme
variable Latent Length scale GP, a generic non-stationary, spatio-temporal
Gaussian Process (GP) model. We present several strategies, for efficient
training of our model, necessary for real-world applicability. Extensive
empirical validation is performed using three real-world environmental
monitoring datasets, with diverse dynamics across space and time. Results from
the experiments clearly demonstrate general applicability and effectiveness of
our approach for applications in environmental monitoring.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garg_S/0/1/0/all/0/1&quot;&gt;Sahil Garg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1&quot;&gt;Amarjeet Singh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ramos_F/0/1/0/all/0/1&quot;&gt;Fabio Ramos&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.10556">
<title>Convergence and Concentration of Empirical Measures under Wasserstein Distance in Unbounded Functional Spaces. (arXiv:1804.10556v1 [math.ST])</title>
<link>http://arxiv.org/abs/1804.10556</link>
<description rdf:parseType="Literal">&lt;p&gt;We provide upper bounds of the expected Wasserstein distance between a
probability measure and its empirical version, generalizing recent results for
finite dimensional Euclidean spaces and bounded functional spaces. Such a
generalization can cover Euclidean spaces with large dimensionality, with the
optimal dependence on the dimensionality. Our method also covers the important
case of Gaussian processes in separable Hilbert spaces, with rate-optimal upper
bounds for functional data distributions whose coordinates decay geometrically
or polynomially. Moreover, our bounds of the expected value can be combined
with mean-concentration results to yield improved exponential tail probability
bounds for the Wasserstein error of empirical measures under a Bernstein-type
tail condition.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Lei_J/0/1/0/all/0/1&quot;&gt;Jing Lei&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.05852">
<title>Network Representation Learning: A Survey. (arXiv:1801.05852v2 [cs.SI] UPDATED)</title>
<link>http://arxiv.org/abs/1801.05852</link>
<description rdf:parseType="Literal">&lt;p&gt;With the widespread use of information technologies, information networks are
becoming increasingly popular to capture complex relationships across various
disciplines, such as social networks, citation networks, telecommunication
networks, and biological networks. Analyzing these networks sheds light on
different aspects of social life such as the structure of societies,
information diffusion, and communication patterns. In reality, however, the
large scale of information networks often makes network analytic tasks
computationally expensive or intractable. Network representation learning has
been recently proposed as a new learning paradigm to embed network vertices
into a low-dimensional vector space, by preserving network topology structure,
vertex content, and other side information. This facilitates the original
network to be easily handled in the new vector space for further analysis. In
this survey, we perform a comprehensive review of the current literature on
network representation learning in the data mining and machine learning field.
We propose new taxonomies to categorize and summarize the state-of-the-art
network representation learning techniques according to the underlying learning
mechanisms, the network information intended to preserve, as well as the
algorithmic designs and methodologies. We summarize evaluation protocols used
for validating network representation learning including published benchmark
datasets, evaluation methods, and open source projects. We also perform
empirical studies to compare the performance of representative algorithms on
common datasets, and analyze their computational complexity. Finally, we
suggest promising research directions to facilitate future study.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_D/0/1/0/all/0/1&quot;&gt;Daokun Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yin_J/0/1/0/all/0/1&quot;&gt;Jie Yin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1&quot;&gt;Xingquan Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1&quot;&gt;Chengqi Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.00543">
<title>Modeling polypharmacy side effects with graph convolutional networks. (arXiv:1802.00543v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1802.00543</link>
<description rdf:parseType="Literal">&lt;p&gt;The use of drug combinations, termed polypharmacy, is common to treat
patients with complex diseases and co-existing conditions. However, a major
consequence of polypharmacy is a much higher risk of adverse side effects for
the patient. Polypharmacy side effects emerge because of drug-drug
interactions, in which activity of one drug may change if taken with another
drug. The knowledge of drug interactions is limited because these complex
relationships are rare, and are usually not observed in relatively small
clinical testing. Discovering polypharmacy side effects thus remains an
important challenge with significant implications for patient mortality. Here,
we present Decagon, an approach for modeling polypharmacy side effects. The
approach constructs a multimodal graph of protein-protein interactions,
drug-protein target interactions, and the polypharmacy side effects, which are
represented as drug-drug interactions, where each side effect is an edge of a
different type. Decagon is developed specifically to handle such multimodal
graphs with a large number of edge types. Our approach develops a new graph
convolutional neural network for multirelational link prediction in multimodal
networks. Decagon predicts the exact side effect, if any, through which a given
drug combination manifests clinically. Decagon accurately predicts polypharmacy
side effects, outperforming baselines by up to 69%. We find that it
automatically learns representations of side effects indicative of
co-occurrence of polypharmacy in patients. Furthermore, Decagon models
particularly well side effects with a strong molecular basis, while on
predominantly non-molecular side effects, it achieves good performance because
of effective sharing of model parameters across edge types. Decagon creates
opportunities to use large pharmacogenomic and patient data to flag and
prioritize side effects for follow-up analysis.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zitnik_M/0/1/0/all/0/1&quot;&gt;Marinka Zitnik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Agrawal_M/0/1/0/all/0/1&quot;&gt;Monica Agrawal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leskovec_J/0/1/0/all/0/1&quot;&gt;Jure Leskovec&lt;/a&gt;</dc:creator>
</item></rdf:RDF>