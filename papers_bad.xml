<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Boring papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Bad Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-04-17T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.05978"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.06173"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.06318"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1703.09865"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.11573"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.00338"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.05364"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.05906"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.05917"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.05929"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.05950"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.06078"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.06088"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.06111"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.06264"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.05825"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.05862"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.05981"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.06021"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.06027"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.06218"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.06219"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.06223"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.06300"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.06327"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.06352"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1609.06840"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.03431"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.00474"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05695"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.07756"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.07200"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.10840"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.05484"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.05436"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1804.05978">
<title>Controlling the Charging of Electric Vehicles with Neural Networks. (arXiv:1804.05978v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1804.05978</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose and evaluate controllers for the coordination of the charging of
electric vehicles. The controllers are based on neural networks and are
completely de-centralized, in the sense that the charging current is completely
decided by the controller itself. One of the versions of the controllers does
not require any outside communication at all.
&lt;/p&gt;
&lt;p&gt;We test controllers based on two different architectures of neural networks -
the feed-forward networks and the echo state networks. The networks are
optimized by either an evolutionary algorithm (CMA-ES) or by a gradient-based
method. The results of the different architectures and the different
optimization algorithms are compared in a realistic scenario. We show that the
controllers are able to charge the cars while keeping the peak consumptions
almost the same as when no charging is performed. Moreover, the controllers
fill the valleys of the consumption thus reducing the difference between the
maximum and minimum consumption in the grid.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pilat_M/0/1/0/all/0/1&quot;&gt;Martin Pil&amp;#xe1;t&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.06173">
<title>Memetic Algorithms Beat Evolutionary Algorithms on the Class of Hurdle Problems. (arXiv:1804.06173v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1804.06173</link>
<description rdf:parseType="Literal">&lt;p&gt;Memetic algorithms are popular hybrid search heuristics that integrate local
search into the search process of an evolutionary algorithm in order to combine
the advantages of rapid exploitation and global optimisation. However, these
algorithms are not well understood and the field is lacking a solid theoretical
foundation that explains when and why memetic algorithms are effective.
&lt;/p&gt;
&lt;p&gt;We provide a rigorous runtime analysis of a simple memetic algorithm, the
$(1+1)$ MA, on the Hurdle problem class, a landscape class of tuneable
difficulty that shows a &quot;big valley structure&quot;, a characteristic feature of
many hard problems from combinatorial optimisation. The only parameter of this
class is the hurdle width w, which describes the length of fitness valleys that
have to be overcome. We show that the $(1+1)$ EA requires $\Theta(n^w)$
expected function evaluations to find the optimum, whereas the $(1+1)$ MA with
best-improvement and first-improvement local search can find the optimum in
$\Theta(n^2+n^3/w^2)$ and $\Theta(n^3/w^2)$ function evaluations, respectively.
Surprisingly, while increasing the hurdle width makes the problem harder for
evolutionary algorithms, the problem becomes easier for memetic algorithms. We
discuss how these findings can explain and illustrate the success of memetic
algorithms for problems with big valley structures.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_P/0/1/0/all/0/1&quot;&gt;Phan Trung Hai Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sudholt_D/0/1/0/all/0/1&quot;&gt;Dirk Sudholt&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.06318">
<title>Learning Awareness Models. (arXiv:1804.06318v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1804.06318</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the setting of an agent with a fixed body interacting with an
unknown and uncertain external world. We show that models trained to predict
proprioceptive information about the agent&apos;s body come to represent objects in
the external world. In spite of being trained with only internally available
signals, these dynamic body models come to represent external objects through
the necessity of predicting their effects on the agent&apos;s own body. That is, the
model learns holistic persistent representations of objects in the world, even
though the only training signals are body signals. Our dynamics model is able
to successfully predict distributions over 132 sensor readings over 100 steps
into the future and we demonstrate that even when the body is no longer in
contact with an object, the latent variables of the dynamics model continue to
represent its shape. We show that active data collection by maximizing the
entropy of predictions about the body---touch sensors, proprioception and
vestibular information---leads to learning of dynamic models that show superior
performance when used for control. We also collect data from a real robotic
hand and show that the same models can be used to answer questions about
properties of objects in the real world. Videos with qualitative results of our
models are available at https://goo.gl/mZuqAV.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Amos_B/0/1/0/all/0/1&quot;&gt;Brandon Amos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dinh_L/0/1/0/all/0/1&quot;&gt;Laurent Dinh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cabi_S/0/1/0/all/0/1&quot;&gt;Serkan Cabi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rothorl_T/0/1/0/all/0/1&quot;&gt;Thomas Roth&amp;#xf6;rl&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Colmenarejo_S/0/1/0/all/0/1&quot;&gt;Sergio G&amp;#xf3;mez Colmenarejo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Muldal_A/0/1/0/all/0/1&quot;&gt;Alistair Muldal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Erez_T/0/1/0/all/0/1&quot;&gt;Tom Erez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tassa_Y/0/1/0/all/0/1&quot;&gt;Yuval Tassa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Freitas_N/0/1/0/all/0/1&quot;&gt;Nando de Freitas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Denil_M/0/1/0/all/0/1&quot;&gt;Misha Denil&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1703.09865">
<title>Experience-based Optimization: A Coevolutionary Approach. (arXiv:1703.09865v2 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1703.09865</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper studies improving solvers based on their past solving experiences,
and focuses on improving solvers by offline training. Specifically, the key
issues of offline training methods are discussed, and research belonging to
this category but from different areas are reviewed in a unified framework.
Existing training methods generally adopt a two-stage strategy in which
selecting the training instances and training instances are treated in two
independent phases. This paper proposes a new training method, dubbed LiangYi,
which addresses these two issues simultaneously. LiangYi includes a training
module for a population-based solver and an instance sampling module for
updating the training instances. The idea behind LiangYi is to promote the
population-based solver by training it (with the training module) to improve
its performance on those instances (discovered by the sampling module) on which
it performs badly, while keeping the good performances obtained by it on
previous instances. An instantiation of LiangYi on the Travelling Salesman
Problem is also proposed. Empirical results on a huge testing set containing
10000 instances showed LiangYi could train solvers that perform significantly
better than the solvers trained by other state-of-the-art training method.
Moreover, empirical investigation of the behaviours of LiangYi confirmed it was
able to continuously improve the solver through training.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1&quot;&gt;Shengcai Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_K/0/1/0/all/0/1&quot;&gt;Ke Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yao_X/0/1/0/all/0/1&quot;&gt;Xin Yao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.11573">
<title>Deep Learning as a Mixed Convex-Combinatorial Optimization Problem. (arXiv:1710.11573v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1710.11573</link>
<description rdf:parseType="Literal">&lt;p&gt;As neural networks grow deeper and wider, learning networks with
hard-threshold activations is becoming increasingly important, both for network
quantization, which can drastically reduce time and energy requirements, and
for creating large integrated systems of deep networks, which may have
non-differentiable components and must avoid vanishing and exploding gradients
for effective learning. However, since gradient descent is not applicable to
hard-threshold functions, it is not clear how to learn networks of them in a
principled way. We address this problem by observing that setting targets for
hard-threshold hidden units in order to minimize loss is a discrete
optimization problem, and can be solved as such. The discrete optimization goal
is to find a set of targets such that each unit, including the output, has a
linearly separable problem to solve. Given these targets, the network
decomposes into individual perceptrons, which can then be learned with standard
convex approaches. Based on this, we develop a recursive mini-batch algorithm
for learning deep hard-threshold networks that includes the popular but poorly
justified straight-through estimator as a special case. Empirically, we show
that our algorithm improves classification accuracy in a number of settings,
including for AlexNet and ResNet-18 on ImageNet, when compared to the
straight-through estimator.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Friesen_A/0/1/0/all/0/1&quot;&gt;Abram L. Friesen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Domingos_P/0/1/0/all/0/1&quot;&gt;Pedro Domingos&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.00338">
<title>Synthesizing realistic neural population activity patterns using Generative Adversarial Networks. (arXiv:1803.00338v2 [q-bio.NC] UPDATED)</title>
<link>http://arxiv.org/abs/1803.00338</link>
<description rdf:parseType="Literal">&lt;p&gt;The ability to synthesize realistic patterns of neural activity is crucial
for studying neural information processing. Here we used the Generative
Adversarial Networks (GANs) framework to simulate the concerted activity of a
population of neurons. We adapted the Wasserstein-GAN variant to facilitate the
generation of unconstrained neural population activity patterns while still
benefiting from parameter sharing in the temporal domain. We demonstrate that
our proposed GAN, which we termed Spike-GAN, generates spike trains that match
accurately the first- and second-order statistics of datasets of tens of
neurons and also approximates well their higher-order statistics. We applied
Spike-GAN to a real dataset recorded from salamander retina and showed that it
performs as well as state-of-the-art approaches based on the maximum entropy
and the dichotomized Gaussian frameworks. Importantly, Spike-GAN does not
require to specify a priori the statistics to be matched by the model, and so
constitutes a more flexible method than these alternative approaches. Finally,
we show how to exploit a trained Spike-GAN to construct &apos;importance maps&apos; to
detect the most relevant statistical structures present in a spike train.
Spike-GAN provides a powerful, easy-to-use technique for generating realistic
spiking neural activity and for describing the most relevant features of the
large-scale neural population recordings studied in modern systems
neuroscience.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Molano_Mazon_M/0/1/0/all/0/1&quot;&gt;Manuel Molano-Mazon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Onken_A/0/1/0/all/0/1&quot;&gt;Arno Onken&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Piasini_E/0/1/0/all/0/1&quot;&gt;Eugenio Piasini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Panzeri_S/0/1/0/all/0/1&quot;&gt;Stefano Panzeri&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.05364">
<title>Data-efficient Neuroevolution with Kernel-Based Surrogate Models. (arXiv:1804.05364v2 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1804.05364</link>
<description rdf:parseType="Literal">&lt;p&gt;Surrogate-assistance approaches have long been used in computationally
expensive domains to improve the data-efficiency of optimization algorithms.
Neuroevolution, however, has so far resisted the application of these
techniques because it requires the surrogate model to make fitness predictions
based on variable topologies, instead of a vector of parameters. Our main
insight is that we can sidestep this problem by using kernel-based surrogate
models, which require only the definition of a distance measure between
individuals. Our second insight is that the well-established Neuroevolution of
Augmenting Topologies (NEAT) algorithm provides a computationally efficient
distance measure between dissimilar networks in the form of &quot;compatibility
distance&quot;, initially designed to maintain topological diversity. Combining
these two ideas, we introduce a surrogate-assisted neuroevolution algorithm
that combines NEAT and a surrogate model built using a compatibility distance
kernel. We demonstrate the data-efficiency of this new algorithm on the low
dimensional cart-pole swing-up problem, as well as the higher dimensional
half-cheetah running task. In both tasks the surrogate-assisted variant
achieves the same or better results with several times fewer function
evaluations as the original NEAT.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gaier_A/0/1/0/all/0/1&quot;&gt;Adam Gaier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Asteroth_A/0/1/0/all/0/1&quot;&gt;Alexander Asteroth&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mouret_J/0/1/0/all/0/1&quot;&gt;Jean-Baptiste Mouret&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.05906">
<title>An information-theoretic on-line update principle for perception-action coupling. (arXiv:1804.05906v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1804.05906</link>
<description rdf:parseType="Literal">&lt;p&gt;Inspired by findings of sensorimotor coupling in humans and animals, there
has recently been a growing interest in the interaction between action and
perception in robotic systems [Bogh et al., 2016]. Here we consider perception
and action as two serial information channels with limited
information-processing capacity. We follow [Genewein et al., 2015] and
formulate a constrained optimization problem that maximizes utility under
limited information-processing capacity in the two channels. As a solution we
obtain an optimal perceptual channel and an optimal action channel that are
coupled such that perceptual information is optimized with respect to
downstream processing in the action module. The main novelty of this study is
that we propose an online optimization procedure to find bounded-optimal
perception and action channels in parameterized serial perception-action
systems. In particular, we implement the perceptual channel as a multi-layer
neural network and the action channel as a multinomial distribution. We
illustrate our method in a NAO robot simulator with a simplified cup lifting
task.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peng_Z/0/1/0/all/0/1&quot;&gt;Zhen Peng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Genewein_T/0/1/0/all/0/1&quot;&gt;Tim Genewein&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leibfried_F/0/1/0/all/0/1&quot;&gt;Felix Leibfried&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Braun_D/0/1/0/all/0/1&quot;&gt;Daniel A. Braun&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.05917">
<title>Heuristic Approaches for Goal Recognition in Incomplete Domain Models. (arXiv:1804.05917v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1804.05917</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent approaches to goal recognition have progressively relaxed the
assumptions about the amount and correctness of domain knowledge and available
observations, yielding accurate and efficient algorithms. These approaches,
however, assume completeness and correctness of the domain theory against which
their algorithms match observations: this is too strong for most real-world
domains. In this paper, we develop goal recognition techniques that are capable
of recognizing goals using \textit{incomplete} (and possibly incorrect) domain
theories. We show the efficiency and accuracy of our approaches empirically
against a large dataset of goal and plan recognition problems with incomplete
domains.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pereira_R/0/1/0/all/0/1&quot;&gt;Ramon Fraga Pereira&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meneguzzi_F/0/1/0/all/0/1&quot;&gt;Felipe Meneguzzi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.05929">
<title>UCBoost: A Boosting Approach to Tame Complexity and Optimality for Stochastic Bandits. (arXiv:1804.05929v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1804.05929</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work, we address the open problem of finding low-complexity
near-optimal multi-armed bandit algorithms for sequential decision making
problems. Existing bandit algorithms are either sub-optimal and computationally
simple (e.g., UCB1) or optimal and computationally complex (e.g., kl-UCB). We
propose a boosting approach to Upper Confidence Bound based algorithms for
stochastic bandits, that we call UCBoost. Specifically, we propose two types of
UCBoost algorithms. We show that UCBoost($D$) enjoys $O(1)$ complexity for each
arm per round as well as regret guarantee that is $1/e$-close to that of the
kl-UCB algorithm. We propose an approximation-based UCBoost algorithm,
UCBoost($\epsilon$), that enjoys a regret guarantee $\epsilon$-close to that of
kl-UCB as well as $O(\log(1/\epsilon))$ complexity for each arm per round.
Hence, our algorithms provide practitioners a practical way to trade optimality
with computational complexity. Finally, we present numerical results which show
that UCBoost($\epsilon$) can achieve the same regret performance as the
standard kl-UCB while incurring only $1\%$ of the computational cost of kl-UCB.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_F/0/1/0/all/0/1&quot;&gt;Fang Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1&quot;&gt;Sinong Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Buccapatnam_S/0/1/0/all/0/1&quot;&gt;Swapna Buccapatnam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shroff_N/0/1/0/all/0/1&quot;&gt;Ness Shroff&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.05950">
<title>Distribution Estimation in Discounted MDPs via a Transformation. (arXiv:1804.05950v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1804.05950</link>
<description rdf:parseType="Literal">&lt;p&gt;Although the general deterministic reward function in MDPs takes three
arguments - current state, action, and next state; it is often simplified to a
function of two arguments - current state and action. The former is called a
transition-based reward function, whereas the latter is called a state-based
reward function. When the objective is a function of the expected cumulative
reward only, this simplification works perfectly. However, when the objective
is risk-sensitive - e.g., depends on the reward distribution, this
simplification leads to incorrect values of the objective. This paper studies
the distribution estimation of the cumulative discounted reward in
infinite-horizon MDPs with finite state and action spaces. First, by taking the
Value-at-Risk (VaR) objective as an example, we illustrate and analyze the
error from the above simplification on the reward distribution. Next, we
propose a transformation for MDPs to preserve the reward distribution and
convert transition-based reward functions to deterministic state-based reward
functions. This transformation works whether the transition-based reward
function is deterministic or stochastic. Lastly, we show how to estimate the
reward distribution after applying the proposed transformation in different
settings, provided that the distribution is approximately normal.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_S/0/1/0/all/0/1&quot;&gt;Shuai Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_J/0/1/0/all/0/1&quot;&gt;Jia Yuan Yu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.06078">
<title>Cross-Domain Adversarial Auto-Encoder. (arXiv:1804.06078v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1804.06078</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we propose the Cross-Domain Adversarial Auto-Encoder (CDAAE)
to address the problem of cross-domain image inference, generation and
transformation. We make the assumption that images from different domains share
the same latent code space for content, while having separate latent code space
for style. The proposed framework can map cross-domain data to a latent code
vector consisting of a content part and a style part. The latent code vector is
matched with a prior distribution so that we can generate meaningful samples
from any part of the prior space. Consequently, given a sample of one domain,
our framework can generate various samples of the other domain with the same
content of the input. This makes the proposed framework different from the
current work of cross-domain transformation. Besides, the proposed framework
can be trained with both labeled and unlabeled data, which makes it also
suitable for domain adaptation. Experimental results on data sets SVHN, MNIST
and CASIA show the proposed framework achieved visually appealing performance
for image generation task. Besides, we also demonstrate the proposed method
achieved superior results for domain adaptation. Code of our experiments is
available in https://github.com/luckycallor/CDAAE.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hou_H/0/1/0/all/0/1&quot;&gt;Haodi Hou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huo_J/0/1/0/all/0/1&quot;&gt;Jing Huo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_Y/0/1/0/all/0/1&quot;&gt;Yang Gao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.06088">
<title>Automatic Construction of Parallel Portfolios via Explicit Instance Grouping. (arXiv:1804.06088v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1804.06088</link>
<description rdf:parseType="Literal">&lt;p&gt;Simultaneously utilizing several complementary solvers is a simple yet
effective strategy for solving computationally hard problems. However, manually
building such solver portfolios typically requires considerable domain
knowledge and plenty of human effort. As an alternative, automatic construction
of parallel portfolios (ACPP) aims at automatically building effective parallel
portfolios based on a given problem instance set and a given rich design space.
One promising way to solve the ACPP problem is to explicitly group the
instances into different subsets and promote a component solver to handle each
of them.This paper investigates solving ACPP from this perspective, and
especially studies how to obtain a good instance grouping.The experimental
results showed that the parallel portfolios constructed by the proposed method
could achieve consistently superior performances to the ones constructed by the
state-of-the-art ACPP methods,and could even rival sophisticated hand-designed
parallel solvers.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1&quot;&gt;Shengcai Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_K/0/1/0/all/0/1&quot;&gt;Ke Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yao_X/0/1/0/all/0/1&quot;&gt;Xin Yao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.06111">
<title>Feature Propagation on Graph: A New Perspective to Graph Representation Learning. (arXiv:1804.06111v1 [cs.SI])</title>
<link>http://arxiv.org/abs/1804.06111</link>
<description rdf:parseType="Literal">&lt;p&gt;We study feature propagation on graph, an inference process involved in graph
representation learning tasks. It&apos;s to spread the features over the whole graph
to the $t$-th orders, thus to expand the end&apos;s features. The process has been
successfully adopted in graph embedding or graph neural networks, however few
works studied the convergence of feature propagation. Without convergence
guarantees, it may lead to unexpected numerical overflows and task failures. In
this paper, we first define the concept of feature propagation on graph
formally, and then study its convergence conditions to equilibrium states. We
further link feature propagation to several established approaches such as
node2vec and structure2vec. In the end of this paper, we extend existing
approaches from represent nodes to edges (edge2vec) and demonstrate its
applications on fraud transaction detection in real world scenario. Experiments
show that it is quite competitive.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiang_B/0/1/0/all/0/1&quot;&gt;Biao Xiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1&quot;&gt;Ziqi Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1&quot;&gt;Jun Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xiaolong Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.06264">
<title>Automated vehicle&apos;s behavior decision making using deep reinforcement learning and high-fidelity simulation environment. (arXiv:1804.06264v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1804.06264</link>
<description rdf:parseType="Literal">&lt;p&gt;Automated vehicles are deemed to be the key element for the intelligent
transportation system in the future. Many studies have been made to improve the
Automated vehicles&apos; ability of environment recognition and vehicle control,
while the attention paid to decision making is not enough though the decision
algorithms so far are very preliminary. Therefore, a framework of the
decision-making training and learning is put forward in this paper. It consists
of two parts: the deep reinforcement learning training program and the
high-fidelity virtual simulation environment. Then the basic microscopic
behavior, car-following, is trained within this framework. In addition,
theoretical analysis and experiments were conducted on setting reward function
for accelerating training using deep reinforcement learning. The results show
that on the premise of driving comfort, the efficiency of the trained Automated
vehicle increases 7.9% compared to the classical traffic model, intelligent
driver model. Later on, on a more complex three-lane section, we trained the
integrated model combines both car-following and lane-changing behavior, the
average speed further grows 2.4%. It indicates that our framework is effective
for Automated vehicle&apos;s decision-making learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ye_Y/0/1/0/all/0/1&quot;&gt;Yingjun Ye&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xiaohui Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1&quot;&gt;Jian Sun&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.05825">
<title>Relational Marginal Problems: Theory and Estimation. (arXiv:1709.05825v3 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1709.05825</link>
<description rdf:parseType="Literal">&lt;p&gt;In the propositional setting, the marginal problem is to find a
(maximum-entropy) distribution that has some given marginals. We study this
problem in a relational setting and make the following contributions. First, we
compare two different notions of relational marginals. Second, we show a
duality between the resulting relational marginal problems and the maximum
likelihood estimation of the parameters of relational models, which generalizes
a well-known duality from the propositional setting. Third, by exploiting the
relational marginal formulation, we present a statistically sound method to
learn the parameters of relational models that will be applied in settings
where the number of constants differs between the training and test data.
Furthermore, based on a relational generalization of marginal polytopes, we
characterize cases where the standard estimators based on feature&apos;s number of
true groundings needs to be adjusted and we quantitatively characterize the
consequences of these adjustments. Fourth, we prove bounds on expected errors
of the estimated parameters, which allows us to lower-bound, among other
things, the effective sample size of relational training data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kuzelka_O/0/1/0/all/0/1&quot;&gt;Ondrej Kuzelka&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yuyi Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Davis_J/0/1/0/all/0/1&quot;&gt;Jesse Davis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schockaert_S/0/1/0/all/0/1&quot;&gt;Steven Schockaert&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.05862">
<title>Compressibility and Generalization in Large-Scale Deep Learning. (arXiv:1804.05862v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1804.05862</link>
<description rdf:parseType="Literal">&lt;p&gt;Modern neural networks are highly overparameterized, with capacity to
substantially overfit to training data. Nevertheless, these networks often
generalize well in practice. It has also been observed that trained networks
can often be &quot;compressed&quot; to much smaller representations. The purpose of this
paper is to connect these two empirical observations. Our main technical result
is a generalization bound for compressed networks based on the compressed size.
Combined with off-the-shelf compression algorithms, the bound leads to state of
the art generalization guarantees; in particular, we provide the first
non-vacuous generalization guarantees for realistic architectures applied to
the ImageNet classification problem. As additional evidence connecting
compression and generalization, we show that compressibility of models that
tend to overfit is limited: We establish an absolute limit on expected
compressibility as a function of expected generalization error, where the
expectations are over the random choice of training examples. The bounds are
complemented by empirical results that show an increase in overfitting implies
an increase in the number of bits required to describe a trained network.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhou_W/0/1/0/all/0/1&quot;&gt;Wenda Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Veitch_V/0/1/0/all/0/1&quot;&gt;Victor Veitch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Austern_M/0/1/0/all/0/1&quot;&gt;Morgane Austern&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Adams_R/0/1/0/all/0/1&quot;&gt;Ryan P. Adams&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Orbanz_P/0/1/0/all/0/1&quot;&gt;Peter Orbanz&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.05981">
<title>A Univariate Bound of Area Under ROC. (arXiv:1804.05981v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1804.05981</link>
<description rdf:parseType="Literal">&lt;p&gt;Area under ROC (AUC) is an important metric for binary classification and
bipartite ranking problems. However, it is difficult to directly optimizing AUC
as a learning objective, so most existing algorithms are based on optimizing a
surrogate loss to AUC. One significant drawback of these surrogate losses is
that they require pairwise comparisons among training data, which leads to slow
running time and increasing local storage for online learning. In this work, we
describe a new surrogate loss based on a reformulation of the AUC risk, which
does not require pairwise comparison but rankings of the predictions. We
further show that the ranking operation can be avoided, and the learning
objective obtained based on this surrogate enjoys linear complexity in time and
storage. We perform experiments to demonstrate the effectiveness of the online
and batch algorithms for AUC optimization based on the proposed surrogate loss.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lyu_S/0/1/0/all/0/1&quot;&gt;Siwei Lyu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.06021">
<title>Regret Bounds for Model-Free Linear Quadratic Control. (arXiv:1804.06021v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1804.06021</link>
<description rdf:parseType="Literal">&lt;p&gt;Model-free approaches for reinforcement learning (RL) and continuous control
find policies based only on past states and rewards, without fitting a model of
the system dynamics. They are appealing as they are general purpose and easy to
implement; however, they also come with fewer theoretical guarantees than
model-based approaches. In this work, we present a model-free algorithm for
controlling linear quadratic (LQ) systems, which is the simplest setting for
continuous control and widely used in practice. Our approach is based on a
reduction of the control of Markov decision processes to an expert prediction
problem. We show that the algorithm regret scales as $O(T^{3/4})$, where $T$ is
the number of rounds.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abbasi_Yadkori_Y/0/1/0/all/0/1&quot;&gt;Yasin Abbasi-Yadkori&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lazic_N/0/1/0/all/0/1&quot;&gt;Nevena Lazic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Szepesvari_C/0/1/0/all/0/1&quot;&gt;Csaba Szepesvari&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.06027">
<title>A Boosting Framework of Factorization Machine. (arXiv:1804.06027v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1804.06027</link>
<description rdf:parseType="Literal">&lt;p&gt;Recently, Factorization Machines (FM) has become more and more popular for
recommendation systems, due to its effectiveness in finding informative
interactions between features. Usually, the weights for the interactions is
learnt as a low rank weight matrix, which is formulated as an inner product of
two low rank matrices. This low rank can help improve the generalization
ability of Factorization Machines. However, to choose the rank properly, it
usually needs to run the algorithm for many times using different ranks, which
clearly is inefficient for some large-scale datasets. To alleviate this issue,
we propose an Adaptive Boosting framework of Factorization Machines (AdaFM),
which can adaptively search for proper ranks for different datasets without
re-training. Instead of using a fixed rank for FM, the proposed algorithm will
adaptively gradually increases its rank according to its performance until the
performance does not grow, using boosting strategy. To verify the performance
of our proposed framework, we conduct an extensive set of experiments on many
real-world datasets. Encouraging empirical results shows that the proposed
algorithms are generally more effective than state-of-the-art other
Factorization Machines.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1&quot;&gt;Longfei Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_P/0/1/0/all/0/1&quot;&gt;Peilin Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1&quot;&gt;Jun Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xiaolong Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.06218">
<title>Hierarchical correlation reconstruction with missing data. (arXiv:1804.06218v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1804.06218</link>
<description rdf:parseType="Literal">&lt;p&gt;Machine learning often needs to estimate density from a multidimensional data
sample, where we would also like to model correlations between coordinates.
Additionally, we often have missing data case: that data points have only
partial information - can miss information about some coordinates. This paper
adapts rapid parametric density estimation technique for this purpose:
modelling density as a linear combination, for which $L^2$ optimization says
that estimated coefficient for a given function is just average over the sample
of this function. Hierarchical correlation reconstruction first models
probability density for each separate coordinate using all its appearances in
data sample, then adds corrections from independently modelled pairwise
correlations using all samples having both coordinates, and so on independently
adding correlations for growing numbers of variables using decreasing evidence
in our data sample. A basic application of such modelled multidimensional
density can be imputation of missing coordinates: by inserting known
coordinates to the density, and taking expected values for the missing
coordinates, and maybe also variance to estimate their uncertainty.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Duda_J/0/1/0/all/0/1&quot;&gt;Jarek Duda&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.06219">
<title>Application of the Ranking Relative Principal Component Attributes Network Model (REL-PCANet) for the Inclusive Development Index Estimation. (arXiv:1804.06219v1 [cs.CE])</title>
<link>http://arxiv.org/abs/1804.06219</link>
<description rdf:parseType="Literal">&lt;p&gt;In 2018, at the World Economic Forum in Davos it was presented a new
countries&apos; economic performance metric named the Inclusive Development Index
(IDI) composed of 12 indicators. The new metric implies that countries might
need to realize structural reforms for improving both economic expansion and
social inclusion performance. That is why, it is vital for the IDI calculation
method to have strong statistical and mathematical basis, so that results are
accurate and transparent for public purposes. In the current work, we propose a
novel approach for the IDI estimation - the Ranking Relative Principal
Component Attributes Network Model (REL-PCANet). The model is based on RELARM
and RankNet principles and combines elements of PCA, techniques applied in
image recognition and learning to rank mechanisms. Also, we define a new
approach for estimation of target probabilities matrix to reflect dynamic
changes in countries&apos; inclusive development. Empirical study proved that
REL-PCANet ensures reliable and robust scores and rankings, thus is recommended
for practical implementation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Irmatov_A/0/1/0/all/0/1&quot;&gt;Anwar Irmatov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Irmatova_E/0/1/0/all/0/1&quot;&gt;Elnura Irmatova&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.06223">
<title>A Comparison of Machine Learning Algorithms for the Surveillance of Autism Spectrum Disorder. (arXiv:1804.06223v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1804.06223</link>
<description rdf:parseType="Literal">&lt;p&gt;The Centers for Disease Control and Prevention (CDC) coordinates a
labor-intensive process to measure the prevalence of autism spectrum disorder
(ASD) among children in the United States. Random forests methods have shown
promise in speeding up this process, but they lag behind human classification
accuracy by about 5 percent. We explore whether newer document classification
algorithms can close this gap. We applied 6 supervised learning algorithms to
predict whether children meet the case definition for ASD based solely on the
words in their evaluations. We compared the algorithms? performance across 10
random train-test splits of the data, and then, we combined our top 3
classifiers to estimate the Bayes error rate in the data. Across the 10
train-test cycles, the random forest, neural network, and support vector
machine with Naive Bayes features (NB-SVM) each achieved slightly more than
86.5 percent mean accuracy. The Bayes error rate is estimated at approximately
12 percent meaning that the model error for even the simplest of our
algorithms, the random forest, is below 2 percent. NB-SVM produced
significantly more false positives than false negatives. The random forest
performed as well as newer models like the NB-SVM and the neural network.
NB-SVM may not be a good candidate for use in a fully-automated surveillance
workflow due to increased false positives. More sophisticated algorithms, like
hierarchical convolutional neural networks, would not perform substantially
better due to characteristics of the data. Deep learning models performed
similarly to traditional machine learning methods at predicting the
clinician-assigned case status for CDC&apos;s autism surveillance system. While deep
learning methods had limited benefit in this task, they may have applications
in other surveillance systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lee_S/0/1/0/all/0/1&quot;&gt;Scott H Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Maenner_M/0/1/0/all/0/1&quot;&gt;Matthew J Maenner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Heilig_C/0/1/0/all/0/1&quot;&gt;Charles M Heilig&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.06300">
<title>PredRNN++: Towards A Resolution of the Deep-in-Time Dilemma in Spatiotemporal Predictive Learning. (arXiv:1804.06300v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1804.06300</link>
<description rdf:parseType="Literal">&lt;p&gt;We present PredRNN++, an improved recurrent network for video predictive
learning. In pursuit of a greater spatiotemporal modeling capability, our
approach increases the transition depth between adjacent states by leveraging a
novel recurrent unit, which is named Causal LSTM for re-organizing the spatial
and temporal memories in a cascaded mechanism. However, there is still a
dilemma in video predictive learning: increasingly deep-in-time models have
been designed for capturing complex variations, while introducing more
difficulties in the gradient back-propagation. To alleviate this undesirable
effect, we propose a Gradient Highway architecture, which provides alternative
shorter routes for gradient flows from outputs back to long-range inputs. This
architecture works seamlessly with causal LSTMs, enabling PredRNN++ to capture
short-term and long-term dependencies adaptively. We assess our model on both
synthetic and real video datasets, showing its ability to ease the vanishing
gradient problem and yield state-of-the-art prediction results even in a
difficult objects occlusion scenario.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yunbo Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_Z/0/1/0/all/0/1&quot;&gt;Zhifeng Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Long_M/0/1/0/all/0/1&quot;&gt;Mingsheng Long&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jianmin Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_P/0/1/0/all/0/1&quot;&gt;Philip S. Yu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.06327">
<title>Classifying Antimicrobial and Multifunctional Peptides with Bayesian Network Models. (arXiv:1804.06327v1 [stat.AP])</title>
<link>http://arxiv.org/abs/1804.06327</link>
<description rdf:parseType="Literal">&lt;p&gt;Bayesian network models are finding success in characterizing
enzyme-catalyzed reactions, slow conformational changes, predicting enzyme
inhibition, and genomics. In this work, we apply them to statistical modeling
of peptides by simultaneously identifying amino acid sequence motifs and using
a motif-based model to clarify the role motifs may play in antimicrobial
activity. We construct models of increasing sophistication, demonstrating how
chemical knowledge of a peptide system may be embedded without requiring new
derivation of model fitting equations after changing model structure. These
models are used to construct classifiers with good performance (94% accuracy,
Matthews correlation coefficient of 0.87) at predicting antimicrobial activity
in peptides, while at the same time being built of interpretable parameters. We
demonstrate use of these models to identify peptides that are potentially both
antimicrobial and antifouling, and show that the background distribution of
amino acids could play a greater role in activity than sequence motifs do. This
provides an advancement in the type of peptide activity modeling that can be
done and the ease in which models can be constructed.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Barrett_R/0/1/0/all/0/1&quot;&gt;Rainier Barrett&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Jiang_S/0/1/0/all/0/1&quot;&gt;Shaoyi Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+White_A/0/1/0/all/0/1&quot;&gt;Andrew D White&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.06352">
<title>High Dimensional Time Series Generators. (arXiv:1804.06352v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1804.06352</link>
<description rdf:parseType="Literal">&lt;p&gt;Multidimensional time series are sequences of real valued vectors. They occur
in different areas, for example handwritten characters, GPS tracking, and
gestures of modern virtual reality motion controllers. Within these areas, a
common task is to search for similar time series. Dynamic Time Warping (\dtw)
is a common distance function to compare two time series. The Edit Distance
with Real Penalty (\erp) and the Dog Keeper Distance (\frechet) are two more
distance functions on time series. Their behaviour has been analyzed on
1-dimensional time series. However, it is not easy to evaluate their behaviour
in relation to growing dimensionality. For this reason we propose two new data
synthesizers generating multidimensional time series. The first synthesizer
extends the well known cylinder-bell-funnel (CBF) dataset to multidimensional
time series. Here, each time series has an arbitrary type (cylinder, bell, or
funnel) in each dimension, thus for $d$-dimensional time series there are
$3^{d}$ different classes. The second synthesizer (\ram) creates time series
with ideas adapted from Brownian motions which is a common model of movement in
physics. Finally, we evaluate the applicability of a 1-nearest neighbor
classifier using \dtw{} on datasets generated by our synthesizers.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bachmann_J/0/1/0/all/0/1&quot;&gt;J&amp;#xf6;rg P. Bachmann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Freytag_J/0/1/0/all/0/1&quot;&gt;Johann-Christoph Freytag&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1609.06840">
<title>Exact Sampling from Determinantal Point Processes. (arXiv:1609.06840v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1609.06840</link>
<description rdf:parseType="Literal">&lt;p&gt;Determinantal point processes (DPPs) are an important concept in random
matrix theory and combinatorics. They have also recently attracted interest in
the study of numerical methods for machine learning, as they offer an elegant
&quot;missing link&quot; between independent Monte Carlo sampling and deterministic
evaluation on regular grids, applicable to a general set of spaces. This is
helpful whenever an algorithm explores to reduce uncertainty, such as in active
learning, Bayesian optimization, reinforcement learning, and marginalization in
graphical models. To draw samples from a DPP in practice, existing literature
focuses on approximate schemes of low cost, or comparably inefficient exact
algorithms like rejection sampling. We point out that, for many settings of
relevance to machine learning, it is also possible to draw exact samples from
DPPs on continuous domains. We start from an intuitive example on the real
line, which is then generalized to multivariate real vector spaces. We also
compare to previously studied approximations, showing that exact sampling,
despite higher cost, can be preferable where precision is needed.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hennig_P/0/1/0/all/0/1&quot;&gt;Philipp Hennig&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garnett_R/0/1/0/all/0/1&quot;&gt;Roman Garnett&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.03431">
<title>Can clustering scale sublinearly with its clusters? A variational EM acceleration of GMMs and $k$-means. (arXiv:1711.03431v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1711.03431</link>
<description rdf:parseType="Literal">&lt;p&gt;One iteration of standard $k$-means (i.e., Lloyd&apos;s algorithm) or standard EM
for Gaussian mixture models (GMMs) scales linearly with the number of clusters
$C$, data points $N$, and data dimensionality $D$. In this study, we explore
whether one iteration of $k$-means or EM for GMMs can scale sublinearly with
$C$ at run-time, while improving the clustering objective remains effective.
The tool we apply for complexity reduction is variational EM, which is
typically used to make training of generative models with exponentially many
hidden states tractable. Here, we apply novel theoretical results on truncated
variational EM to make tractable clustering algorithms more efficient. The
basic idea is to use a partial variational E-step which reduces the linear
complexity of $\mathcal{O}(NCD)$ required for a full E-step to a sublinear
complexity. Our main observation is that the linear dependency on $C$ can be
reduced to a dependency on a much smaller parameter $G$ which relates to
cluster neighborhood relations. We focus on two versions of partial variational
EM for clustering: variational GMM, scaling with $\mathcal{O}(NG^2D)$, and
variational $k$-means, scaling with $\mathcal{O}(NGD)$ per iteration. Empirical
results show that these algorithms still require comparable numbers of
iterations to improve the clustering objective to same values as $k$-means. For
data with many clusters, we consequently observe reductions of net
computational demands between two and three orders of magnitude. More
generally, our results provide substantial empirical evidence in favor of
clustering to scale sublinearly with $C$.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Forster_D/0/1/0/all/0/1&quot;&gt;Dennis Forster&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lucke_J/0/1/0/all/0/1&quot;&gt;J&amp;#xf6;rg L&amp;#xfc;cke&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.00474">
<title>Bayesian Modeling via Goodness-of-fit. (arXiv:1802.00474v3 [stat.ME] UPDATED)</title>
<link>http://arxiv.org/abs/1802.00474</link>
<description rdf:parseType="Literal">&lt;p&gt;The two key issues of modern Bayesian statistics are: (i) establishing
principled approach for distilling statistical prior that is consistent with
the given data from an initial believable scientific prior; and (ii)
development of a Bayes-frequentist consolidated data analysis workflow that is
more effective than either of the two separately. In this paper, we propose the
idea of &quot;Bayes via goodness of fit&quot; as a framework for exploring these
fundamental questions, in a way that is general enough to embrace almost all of
the familiar probability models. Several illustrative examples show the benefit
of this new point of view as a practical data analysis tool. Relationship with
other Bayesian cultures is also discussed.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Subhadeep/0/1/0/all/0/1&quot;&gt;Subhadeep&lt;/a&gt; (Deep) &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mukhopadhyay/0/1/0/all/0/1&quot;&gt;Mukhopadhyay&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Fletcher_D/0/1/0/all/0/1&quot;&gt;Douglas Fletcher&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05695">
<title>Explainable Prediction of Medical Codes from Clinical Text. (arXiv:1802.05695v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1802.05695</link>
<description rdf:parseType="Literal">&lt;p&gt;Clinical notes are text documents that are created by clinicians for each
patient encounter. They are typically accompanied by medical codes, which
describe the diagnosis and treatment. Annotating these codes is labor intensive
and error prone; furthermore, the connection between the codes and the text is
not annotated, obscuring the reasons and details behind specific diagnoses and
treatments. We present an attentional convolutional network that predicts
medical codes from clinical text. Our method aggregates information across the
document using a convolutional neural network, and uses an attention mechanism
to select the most relevant segments for each of the thousands of possible
codes. The method is accurate, achieving precision@8 of 0.71 and a Micro-F1 of
0.54, which are both better than the prior state of the art. Furthermore,
through an interpretability evaluation by a physician, we show that the
attention mechanism identifies meaningful explanations for each code assignment
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mullenbach_J/0/1/0/all/0/1&quot;&gt;James Mullenbach&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wiegreffe_S/0/1/0/all/0/1&quot;&gt;Sarah Wiegreffe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Duke_J/0/1/0/all/0/1&quot;&gt;Jon Duke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_J/0/1/0/all/0/1&quot;&gt;Jimeng Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Eisenstein_J/0/1/0/all/0/1&quot;&gt;Jacob Eisenstein&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.07756">
<title>Determining the best classifier for predicting the value of a boolean field on a blood donor database using genetic algorithms. (arXiv:1802.07756v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1802.07756</link>
<description rdf:parseType="Literal">&lt;p&gt;Motivation: Thanks to digitization, we often have access to large databases,
consisting of various fields of information, ranging from numbers to texts and
even boolean values. Such databases lend themselves especially well to machine
learning, classification and big data analysis tasks. We are able to train
classifiers, using already existing data and use them for predicting the values
of a certain field, given that we have information regarding the other fields.
Most specifically, in this study, we look at the Electronic Health Records
(EHRs) that are compiled by hospitals. These EHRs are convenient means of
accessing data of individual patients, but there processing as a whole still
remains a task. However, EHRs that are composed of coherent, well-tabulated
structures lend themselves quite well to the application to machine language,
via the usage of classifiers. In this study, we look at a Blood Transfusion
Service Center Data Set (Data taken from the Blood Transfusion Service Center
in Hsin-Chu City in Taiwan). We used scikit-learn machine learning in python.
From Support Vector Machines(SVM), we use Support Vector Classification(SVC),
from the linear model we import Perceptron. We also used the
K.neighborsclassifier and the decision tree classifiers. We segmented the
database into the 2 parts. Using the first, we trained the classifiers and the
next part was used to verify if the classifier prediction matched that of the
actual values.
&lt;/p&gt;
&lt;p&gt;Contact: ritabratamaiti@hiretrex.com
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Maiti_R/0/1/0/all/0/1&quot;&gt;Ritabrata Maiti&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.07200">
<title>Training Recurrent Neural Networks as a Constraint Satisfaction Problem. (arXiv:1803.07200v5 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1803.07200</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents a new approach for training artificial neural networks
using techniques for solving the constraint satisfaction problem (CSP). The
quotient gradient system (QGS) is a trajectory based method for solving the
CSP. This study converts the training set of a neural network into a CSP and
uses the QGS to find its solutions. The QGS finds the global minimum of the
optimization problem by tracking trajectories of a nonlinear dynamical system
and does not stop at a local minimum of the optimization problem. Lyapunov
theory is used to prove the asymptotic stability of the solutions with and
without the presence of measurement errors. Numerical examples illustrate the
effectiveness of the proposed methodology and compare it to a genetic algorithm
and error backpropagation
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khodabandehlou_H/0/1/0/all/0/1&quot;&gt;Hamid Khodabandehlou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fadali_M/0/1/0/all/0/1&quot;&gt;Mohammad Sami Fadali&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.10840">
<title>Defending against Adversarial Images using Basis Functions Transformations. (arXiv:1803.10840v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1803.10840</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the effectiveness of various approaches that defend against
adversarial attacks on deep networks via manipulations based on basis function
representations of images. Specifically, we experiment with low-pass filtering,
PCA, JPEG compression, low resolution wavelet approximation, and
soft-thresholding. We evaluate these defense techniques using three types of
popular attacks in black, gray and white-box settings. Our results show JPEG
compression tends to outperform the other tested defenses in most of the
settings considered, in addition to soft-thresholding, which performs well in
specific cases, and yields a more mild decrease in accuracy on benign examples.
In addition, we also mathematically derive a novel white-box attack in which
the adversarial perturbation is composed only of terms corresponding a to
pre-determined subset of the basis functions, of which a &quot;low frequency attack&quot;
is a special case.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Shaham_U/0/1/0/all/0/1&quot;&gt;Uri Shaham&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Garritano_J/0/1/0/all/0/1&quot;&gt;James Garritano&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yamada_Y/0/1/0/all/0/1&quot;&gt;Yutaro Yamada&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Weinberger_E/0/1/0/all/0/1&quot;&gt;Ethan Weinberger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Cloninger_A/0/1/0/all/0/1&quot;&gt;Alex Cloninger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Cheng_X/0/1/0/all/0/1&quot;&gt;Xiuyuan Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Stanton_K/0/1/0/all/0/1&quot;&gt;Kelly Stanton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kluger_Y/0/1/0/all/0/1&quot;&gt;Yuval Kluger&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.05484">
<title>Block Mean Approximation for Efficient Second Order Optimization. (arXiv:1804.05484v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1804.05484</link>
<description rdf:parseType="Literal">&lt;p&gt;Advanced optimization algorithms such as Newton method and AdaGrad benefit
from second order derivative or second order statistics to achieve better
descent directions and faster convergence rates. At their heart, such
algorithms need to compute the inverse or inverse square root of a matrix whose
size is quadratic of the dimensionality of the search space. For high
dimensional search spaces, the matrix inversion or inversion of square root
becomes overwhelming which in turn demands for approximate methods. In this
work, we propose a new matrix approximation method which divides a matrix into
blocks and represents each block by one or two numbers. The method allows
efficient computation of matrix inverse and inverse square root. We apply our
method to AdaGrad in training deep neural networks. Experiments show
encouraging results compared to the diagonal approximation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1&quot;&gt;Yao Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Harandi_M/0/1/0/all/0/1&quot;&gt;Mehrtash Harandi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hartley_R/0/1/0/all/0/1&quot;&gt;Richard Hartley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pascanu_R/0/1/0/all/0/1&quot;&gt;Razvan Pascanu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.05436">
<title>Hidden Hamiltonian Cycle Recovery via Linear Programming. (arXiv:1804.05436v1 [cs.DM] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1804.05436</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce the problem of hidden Hamiltonian cycle recovery, where there is
an unknown Hamiltonian cycle in an $n$-vertex complete graph that needs to be
inferred from noisy edge measurements. The measurements are independent and
distributed according to $\calP_n$ for edges in the cycle and $\calQ_n$
otherwise. This formulation is motivated by a problem in genome assembly, where
the goal is to order a set of contigs (genome subsequences) according to their
positions on the genome using long-range linking measurements between the
contigs. Computing the maximum likelihood estimate in this model reduces to a
Traveling Salesman Problem (TSP). Despite the NP-hardness of TSP, we show that
a simple linear programming (LP) relaxation, namely the fractional $2$-factor
(F2F) LP, recovers the hidden Hamiltonian cycle with high probability as $n \to
\infty$ provided that $\alpha_n - \log n \to \infty$, where $\alpha_n
\triangleq -2 \log \int \sqrt{d P_n d Q_n}$ is the R\&apos;enyi divergence of order
$\frac{1}{2}$. This condition is information-theoretically optimal in the sense
that, under mild distributional assumptions, $\alpha_n \geq (1+o(1)) \log n$ is
necessary for any algorithm to succeed regardless of the computational cost.
&lt;/p&gt;
&lt;p&gt;Departing from the usual proof techniques based on dual witness construction,
the analysis relies on the combinatorial characterization (in particular, the
half-integrality) of the extreme points of the F2F polytope. Represented as
bicolored multi-graphs, these extreme points are further decomposed into
simpler &quot;blossom-type&quot; structures for the large deviation analysis and counting
arguments. Evaluation of the algorithm on real data shows improvements over
existing approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bagaria_V/0/1/0/all/0/1&quot;&gt;Vivek Bagaria&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ding_J/0/1/0/all/0/1&quot;&gt;Jian Ding&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tse_D/0/1/0/all/0/1&quot;&gt;David Tse&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1&quot;&gt;Yihong Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1&quot;&gt;Jiaming Xu&lt;/a&gt;</dc:creator>
</item></rdf:RDF>