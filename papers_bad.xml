<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Boring papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Bad Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-05-17T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.06732"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.06503"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.06524"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.06539"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.06549"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.06606"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.06664"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.06753"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.06861"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.06881"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.01364"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.10150"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.10332"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.02785"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.06368"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.06126"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.06530"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.06576"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.06595"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.06605"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.06619"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.06627"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.06639"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.06649"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.06826"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.06834"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.06837"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1504.06043"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1510.02267"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1610.02962"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1701.01064"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.02823"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.10919"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.07875"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.08694"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.03752"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04085"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08429"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.04918"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.02587"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.02532"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.08837"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1804.06732">
<title>DPRed: Making Typical Activation Values Matter In Deep Learning Computing. (arXiv:1804.06732v2 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1804.06732</link>
<description rdf:parseType="Literal">&lt;p&gt;We show that selecting a fixed precision for all values in Convolutional
Neural Networks, even if that precision is different per layer, amounts to
worst case design. We show that much lower precisions can be used if we could
target the common case instead by tailoring the precision at a much finer
granularity than that of a layer. While this observation may not be surprising,
to date no design takes advantage of it in practice. We propose Dynamic
Prediction Reduction (DPRed), where hardware on-the-fly detects the precision
activations need at a much finer granularity than a whole layer. Further we
encode activations and weights using the respective per group dynamically and
statically detected precisions to reduce off- and on-chip storage and
communication. We demonstrate a practical implementation of DPRed with DPRed
Stripes (DPRS), a data-parallel hardware accelerator that adjusts precision
on-the-fly to accommodate the values of the activations it processes
concurrently. DPRS accelerates convolutional layers and executes unmodified
convolutional neural networks. Ignoring offchip communication, DPRS is 2.61x
faster and 1.84x more energy efficient than a fixed-precision accelerator for a
set of convolutional neural networks. We further extend DPRS to exploit
activation and weight precisions for fully-connected layers. The enhanced
design improves average performance and energy efficiency respectively by 2.59x
and 1.19x over the fixed-precision accelerator for a broader set of neural
networks. Finally, we consider a lower cost variant that supports only even
precision widths which offers better energy efficiency. Taking into account
off-chip communication, DPRed compression reduces off-chip traffic to nearly
35% on average compared to no compression making it possible to sustain higher
performance for a given off-chip memory interface while also boosting energy
efficiency.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Delmas_A/0/1/0/all/0/1&quot;&gt;Alberto Delmas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sharify_S/0/1/0/all/0/1&quot;&gt;Sayeh Sharify&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Judd_P/0/1/0/all/0/1&quot;&gt;Patrick Judd&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Siu_K/0/1/0/all/0/1&quot;&gt;Kevin Siu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nikolic_M/0/1/0/all/0/1&quot;&gt;Milos Nikolic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moshovos_A/0/1/0/all/0/1&quot;&gt;Andreas Moshovos&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.06503">
<title>Weight Initialization in Neural Language Models. (arXiv:1805.06503v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1805.06503</link>
<description rdf:parseType="Literal">&lt;p&gt;Semantic Similarity is an important application which finds its use in many
downstream NLP applications. Though the task is mathematically defined,
semantic similarity&apos;s essence is to capture the notions of similarity
impregnated in humans. Machines use some heuristics to calculate the similarity
between words, but these are typically corpus dependent or are useful for
specific domains. The difference between Semantic Similarity and Semantic
Relatedness motivates the development of new algorithms. For a human, the word
car and road are probably as related as car and bus. But this may not be the
case for computational methods. Ontological methods are good at encoding
Semantic Similarity and Vector Space models are better at encoding Semantic
Relatedness. There is a dearth of methods which leverage ontologies to create
better vector representations. The aim of this proposal is to explore in the
direction of a hybrid method which combines statistical/vector space methods
like Word2Vec and Ontological methods like WordNet to leverage the advantages
provided by both.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deshpande_A/0/1/0/all/0/1&quot;&gt;Ameet Deshpande&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Somani_V/0/1/0/all/0/1&quot;&gt;Vedant Somani&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.06524">
<title>Hybrid Adaptive Fuzzy Extreme Learning Machine for text classification. (arXiv:1805.06524v1 [cs.IR])</title>
<link>http://arxiv.org/abs/1805.06524</link>
<description rdf:parseType="Literal">&lt;p&gt;In traditional ELM and its improved versions suffer from the problems of
outliers or noises due to overfitting and imbalance due to distribution. We
propose a novel hybrid adaptive fuzzy ELM(HA-FELM), which introduces a fuzzy
membership function to the traditional ELM method to deal with the above
problems. We define the fuzzy membership function not only basing on the
distance between each sample and the center of the class but also the density
among samples which based on the quantum harmonic oscillator model. The
proposed fuzzy membership function overcomes the shortcoming of the traditional
fuzzy membership function and could make itself adjusted according to the
specific distribution of different samples adaptively. Experiments show the
proposed HA-FELM can produce better performance than SVM, ELM, and RELM in text
classification.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1&quot;&gt;Ming Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiao_P/0/1/0/all/0/1&quot;&gt;Peilun Xiao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Ju Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.06539">
<title>Generalized Strucutral Causal Models. (arXiv:1805.06539v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1805.06539</link>
<description rdf:parseType="Literal">&lt;p&gt;Structural causal models are a popular tool to describe causal relations in
systems in many fields such as economy, the social sciences, and biology. In
this work, we show that these models are not flexible enough in general to give
a complete causal representation of equilibrium states in dynamical systems
that do not have a unique stable equilibrium independent of initial conditions.
We prove that our proposed generalized structural causal models do capture the
essential causal semantics that characterize these systems. We illustrate the
power and flexibility of this extension on a dynamical system corresponding to
a basic enzymatic reaction. We motivate our approach further by showing that it
also efficiently describes the effects of interventions on functional laws such
as the ideal gas law.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Blom_T/0/1/0/all/0/1&quot;&gt;Tineke Blom&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mooij_J/0/1/0/all/0/1&quot;&gt;Joris M. Mooij&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.06549">
<title>Defoiling Foiled Image Captions. (arXiv:1805.06549v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1805.06549</link>
<description rdf:parseType="Literal">&lt;p&gt;We address the task of detecting foiled image captions, i.e. identifying
whether a caption contains a word that has been deliberately replaced by a
semantically similar word, thus rendering it inaccurate with respect to the
image being described. Solving this problem should in principle require a
fine-grained understanding of images to detect linguistically valid
perturbations in captions. In such contexts, encoding sufficiently descriptive
image information becomes a key challenge. In this paper, we demonstrate that
it is possible to solve this task using simple, interpretable yet powerful
representations based on explicit object information. Our models achieve
state-of-the-art performance on a standard dataset, with scores exceeding those
achieved by humans on the task. We also measure the upper-bound performance of
our models using gold standard annotations. Our analysis reveals that the
simpler model performs well even without image information, suggesting that the
dataset contains strong linguistic bias.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Madhyastha_P/0/1/0/all/0/1&quot;&gt;Pranava Madhyastha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Josiah Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Specia_L/0/1/0/all/0/1&quot;&gt;Lucia Specia&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.06606">
<title>Convolutional Attention Networks for Multimodal Emotion Recognition from Speech and Text Data. (arXiv:1805.06606v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1805.06606</link>
<description rdf:parseType="Literal">&lt;p&gt;Emotion recognition has become a popular topic of interest, especially in the
field of human computer interaction. Previous works involve unimodal analysis
of emotion, while recent efforts focus on multi-modal emotion recognition from
vision and speech. In this paper, we propose a new method of learning about the
hidden representations between just speech and text data using convolutional
attention networks. Compared to the shallow model which employs simple
concatenation of feature vectors, the proposed attention model performs much
better in classifying emotion from speech and text data contained in the
CMU-MOSEI dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_C/0/1/0/all/0/1&quot;&gt;Chan Woo Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_K/0/1/0/all/0/1&quot;&gt;Kyu Ye Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jeong_J/0/1/0/all/0/1&quot;&gt;Jihoon Jeong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Choi_W/0/1/0/all/0/1&quot;&gt;Woo Yong Choi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.06664">
<title>Evolutionary RL for Container Loading. (arXiv:1805.06664v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1805.06664</link>
<description rdf:parseType="Literal">&lt;p&gt;Loading the containers on the ship from a yard, is an impor- tant part of
port operations. Finding the optimal sequence for the loading of containers, is
known to be computationally hard and is an example of combinatorial
optimization, which leads to the application of simple heuristics in practice.
In this paper, we propose an approach which uses a mix of Evolutionary
Strategies and Reinforcement Learning (RL) tech- niques to find an
approximation of the optimal solution. The RL based agent uses the Policy
Gradient method, an evolutionary reward strategy and a Pool of good
(not-optimal) solutions to find the approximation. We find that the RL agent
learns near-optimal solutions that outperforms the heuristic solutions. We also
observe that the RL agent assisted with a pool generalizes better for unseen
problems than an RL agent without a pool. We present our results on synthetic
data as well as on subsets of real-world problems taken from container
terminal. The results validate that our approach does comparatively better than
the heuristics solutions available, and adapts to unseen problems better.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saikia_S/0/1/0/all/0/1&quot;&gt;S Saikia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Verma_R/0/1/0/all/0/1&quot;&gt;R Verma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Agarwal_P/0/1/0/all/0/1&quot;&gt;P Agarwal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shroff_G/0/1/0/all/0/1&quot;&gt;G Shroff&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vig_L/0/1/0/all/0/1&quot;&gt;L Vig&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Srinivasan_A/0/1/0/all/0/1&quot;&gt;A Srinivasan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.06753">
<title>Interpolatron: Interpolation or Extrapolation Schemes to Accelerate Optimization for Deep Neural Networks. (arXiv:1805.06753v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.06753</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper we explore acceleration techniques for large scale nonconvex
optimization problems with special focuses on deep neural networks. The
extrapolation scheme is a classical approach for accelerating stochastic
gradient descent for convex optimization, but it does not work well for
nonconvex optimization typically. Alternatively, we propose an interpolation
scheme to accelerate nonconvex optimization and call the method Interpolatron.
We explain motivation behind Interpolatron and conduct a thorough empirical
analysis. Empirical results on DNNs of great depths (e.g., 98-layer ResNet and
200-layer ResNet) on CIFAR-10 and ImageNet show that Interpolatron can converge
much faster than the state-of-the-art methods such as the SGD with momentum and
Adam. Furthermore, Anderson&apos;s acceleration, in which mixing coefficients are
computed by least-squares estimation, can also be used to improve the
performance. Both Interpolatron and Anderson&apos;s acceleration are easy to
implement and tune. We also show that Interpolatron has linear convergence rate
under certain regularity assumptions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Xie_G/0/1/0/all/0/1&quot;&gt;Guangzeng Xie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yitan Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhou_S/0/1/0/all/0/1&quot;&gt;Shuchang Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhang_Z/0/1/0/all/0/1&quot;&gt;Zhihua Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.06861">
<title>Answer Set Programming Modulo `Space-Time&apos;. (arXiv:1805.06861v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1805.06861</link>
<description rdf:parseType="Literal">&lt;p&gt;We present ASP Modulo `Space-Time&apos;, a declarative representational and
computational framework to perform commonsense reasoning about regions with
both spatial and temporal components. Supported are capabilities for mixed
qualitative-quantitative reasoning, consistency checking, and inferring
compositions of space-time relations; these capabilities combine and synergise
for applications in a range of AI application areas where the processing and
interpretation of spatio-temporal data is crucial. The framework and resulting
system is the only general KR-based method for declaratively reasoning about
the dynamics of `space-time&apos; regions as first-class objects. We present an
empirical evaluation (with scalability and robustness results), and include
diverse application examples involving interpretation and control tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schultz_C/0/1/0/all/0/1&quot;&gt;Carl Schultz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bhatt_M/0/1/0/all/0/1&quot;&gt;Mehul Bhatt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Suchan_J/0/1/0/all/0/1&quot;&gt;Jakob Suchan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Walega_P/0/1/0/all/0/1&quot;&gt;Przemys&amp;#x142;aw Wa&amp;#x142;&amp;#x119;ga&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.06881">
<title>Changing Observations in Epistemic Temporal Logic. (arXiv:1805.06881v1 [cs.LO])</title>
<link>http://arxiv.org/abs/1805.06881</link>
<description rdf:parseType="Literal">&lt;p&gt;We study dynamic changes of agents&apos; observational power in logics of
knowledge and time. We consider CTL*K, the extension of CTL* with knowledge
operators, and enrich it with a new operator that models a change in an agent&apos;s
way of observing the system. We extend the classic semantics of knowledge for
perfect-recall agents to account for changes of observation, and we show that
this new operator strictly increases the expressivity of CTL*K. We reduce the
model-checking problem for our logic to that for CTL*K, which is known to be
decidable. This provides a solution to the model-checking problem for our
logic, but its complexity is not optimal. Indeed we provide a direct decision
procedure with better complexity.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barriere_A/0/1/0/all/0/1&quot;&gt;Aur&amp;#xe8;le Barri&amp;#xe8;re&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Maubert_B/0/1/0/all/0/1&quot;&gt;Bastien Maubert&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Murano_A/0/1/0/all/0/1&quot;&gt;Aniello Murano&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rubin_S/0/1/0/all/0/1&quot;&gt;Sasha Rubin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.01364">
<title>SAFE: Spectral Evolution Analysis Feature Extraction for Non-Stationary Time Series Prediction. (arXiv:1803.01364v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1803.01364</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents a practical approach for detecting non-stationarity in
time series prediction. This method is called SAFE and works by monitoring the
evolution of the spectral contents of time series through a distance function.
This method is designed to work in combination with state-of-the-art machine
learning methods in real time by informing the online predictors to perform
necessary adaptation when a non-stationarity presents. We also propose an
algorithm to proportionally include some past data in the adaption process to
overcome the Catastrophic Forgetting problem. To validate our hypothesis and
test the effectiveness of our approach, we present comprehensive experiments in
different elements of the approach involving artificial and real-world
datasets. The experiments show that the proposed method is able to
significantly save computational resources in term of processor or GPU cycles
while maintaining high prediction performances.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koesdwiady_A/0/1/0/all/0/1&quot;&gt;Arief Koesdwiady&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Karray_F/0/1/0/all/0/1&quot;&gt;Fakhri Karray&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.10150">
<title>Learning to Branch. (arXiv:1803.10150v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1803.10150</link>
<description rdf:parseType="Literal">&lt;p&gt;Tree search algorithms, such as branch-and-bound, are the most widely used
tools for solving combinatorial and nonconvex problems. For example, they are
the foremost method for solving (mixed) integer programs and constraint
satisfaction problems. Tree search algorithms recursively partition the search
space to find an optimal solution. In order to keep the tree size small, it is
crucial to carefully decide, when expanding a tree node, which question
(typically variable) to branch on at that node in order to partition the
remaining space. Numerous partitioning techniques (e.g., variable selection)
have been proposed, but there is no theory describing which technique is
optimal. We show how to use machine learning to determine an optimal weighting
of any set of partitioning procedures for the instance distribution at hand
using samples from the distribution. We provide the first sample complexity
guarantees for tree search algorithm configuration. These guarantees bound the
number of samples sufficient to ensure that the empirical performance of an
algorithm over the samples nearly matches its expected performance on the
unknown instance distribution. This thorough theoretical investigation
naturally gives rise to our learning algorithm. Via experiments, we show that
learning an optimal weighting of partitioning procedures can dramatically
reduce tree size, and we prove that this reduction can even be exponential.
Through theory and experiments, we show that learning to branch is both
practical and hugely beneficial.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Balcan_M/0/1/0/all/0/1&quot;&gt;Maria-Florina Balcan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dick_T/0/1/0/all/0/1&quot;&gt;Travis Dick&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sandholm_T/0/1/0/all/0/1&quot;&gt;Tuomas Sandholm&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vitercik_E/0/1/0/all/0/1&quot;&gt;Ellen Vitercik&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.10332">
<title>Sim-to-Real: Learning Agile Locomotion For Quadruped Robots. (arXiv:1804.10332v2 [cs.RO] UPDATED)</title>
<link>http://arxiv.org/abs/1804.10332</link>
<description rdf:parseType="Literal">&lt;p&gt;Designing agile locomotion for quadruped robots often requires extensive
expertise and tedious manual tuning. In this paper, we present a system to
automate this process by leveraging deep reinforcement learning techniques. Our
system can learn quadruped locomotion from scratch using simple reward signals.
In addition, users can provide an open loop reference to guide the learning
process when more control over the learned gait is needed. The control policies
are learned in a physics simulator and then deployed on real robots. In
robotics, policies trained in simulation often do not transfer to the real
world. We narrow this reality gap by improving the physics simulator and
learning robust policies. We improve the simulation using system
identification, developing an accurate actuator model and simulating latency.
We learn robust controllers by randomizing the physical environments, adding
perturbations and designing a compact observation space. We evaluate our system
on two agile locomotion gaits: trotting and galloping. After learning in
simulation, a quadruped robot can successfully perform both gaits in the real
world.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tan_J/0/1/0/all/0/1&quot;&gt;Jie Tan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1&quot;&gt;Tingnan Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Coumans_E/0/1/0/all/0/1&quot;&gt;Erwin Coumans&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Iscen_A/0/1/0/all/0/1&quot;&gt;Atil Iscen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bai_Y/0/1/0/all/0/1&quot;&gt;Yunfei Bai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hafner_D/0/1/0/all/0/1&quot;&gt;Danijar Hafner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bohez_S/0/1/0/all/0/1&quot;&gt;Steven Bohez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vanhoucke_V/0/1/0/all/0/1&quot;&gt;Vincent Vanhoucke&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.02785">
<title>Fast Online Exact Solutions for Deterministic MDPs with Sparse Rewards. (arXiv:1805.02785v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.02785</link>
<description rdf:parseType="Literal">&lt;p&gt;Markov Decision Processes (MDPs) are a mathematical framework for modeling
sequential decision making under uncertainty. The classical approaches for
solving MDPs are well known and have been widely studied, some of which rely on
approximation techniques to solve MDPs with large state space and/or action
space. However, most of these classical solution approaches and their
approximation techniques still take much computation time to converge and
usually must be re-computed if the reward function is changed. This paper
introduces a novel alternative approach for exactly and efficiently solving
deterministic, continuous MDPs with sparse reward sources. When the environment
is such that the &quot;distance&quot; between states can be determined in constant time,
e.g. grid world, our algorithm offers $O( |R|^2 \times |A|^2 \times |S|)$,
where $|R|$ is the number of reward sources, $|A|$ is the number of actions,
and $|S|$ is the number of states. Memory complexity for the algorithm is $O(
|S| + |R| \times |A|)$. This new approach opens new avenues for boosting
computational performance for certain classes of MDPs and is of tremendous
value for MDP applications such as robotics and unmanned systems. This paper
describes the algorithm and presents numerical experiment results to
demonstrate its powerful computational performance. We also provide rigorous
mathematical description of the approach.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bertram_J/0/1/0/all/0/1&quot;&gt;Joshua R. Bertram&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1&quot;&gt;Xuxi Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wei_P/0/1/0/all/0/1&quot;&gt;Peng Wei&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.06368">
<title>Strict Very Fast Decision Tree: a memory conservative algorithm for data stream mining. (arXiv:1805.06368v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1805.06368</link>
<description rdf:parseType="Literal">&lt;p&gt;Dealing with memory and time constraints are current challenges when learning
from data streams with a massive amount of data. Many algorithms have been
proposed to handle these difficulties, among them, the Very Fast Decision Tree
(VFDT) algorithm. Although the VFDT has been widely used in data stream mining,
in the last years, several authors have suggested modifications to increase its
performance, putting aside memory concerns by proposing memory-costly
solutions. Besides, most data stream mining solutions have been centred around
ensembles, which combine the memory costs of their weak learners, usually
VFDTs. To reduce the memory cost, keeping the predictive performance, this
study proposes the Strict VFDT (SVFDT), a novel algorithm based on the VFDT.
The SVFDT algorithm minimises unnecessary tree growth, substantially reducing
memory usage and keeping competitive predictive performance. Moreover, since it
creates much more shallow trees than VFDT, SVFDT can achieve a shorter
processing time. Experiments were carried out comparing the SVFDT with the VFDT
in 11 benchmark data stream datasets. This comparison assessed the trade-off
between accuracy, memory, and processing time. Statistical analysis showed that
the proposed algorithm obtained similar predictive performance and
significantly reduced processing time and memory use. Thus, SVFDT is a suitable
option for data stream mining with memory and time limitations, recommended as
a weak learner in ensemble-based solutions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Costa_V/0/1/0/all/0/1&quot;&gt;Victor Guilherme Turrisi da Costa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Carvalho_A/0/1/0/all/0/1&quot;&gt;Andr&amp;#xe9; Carlos Ponce de Leon Ferreira de Carvalho&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Junior_S/0/1/0/all/0/1&quot;&gt;Sylvio Barbon Junior&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.06126">
<title>Market Self-Learning of Signals, Impact and Optimal Trading: Invisible Hand Inference with Free Energy. (arXiv:1805.06126v1 [q-fin.CP] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1805.06126</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a simple model of a non-equilibrium self-organizing market where
asset prices are partially driven by investment decisions of a bounded-rational
agent. The agent acts in a stochastic market environment driven by various
exogenous &quot;alpha&quot; signals, agent&apos;s own actions (via market impact), and noise.
Unlike traditional agent-based models, our agent aggregates all traders in the
market, rather than being a representative agent. Therefore, it can be
identified with a bounded-rational component of the market itself, providing a
particular implementation of an Invisible Hand market mechanism. In such
setting, market dynamics are modeled as a fictitious self-play of such
bounded-rational market-agent in its adversarial stochastic environment. As
rewards obtained by such self-playing market agent are not observed from market
data, we formulate and solve a simple model of such market dynamics based on a
neuroscience-inspired Bounded Rational Information Theoretic Inverse
Reinforcement Learning (BRIT-IRL). This results in effective asset price
dynamics with a non-linear mean reversion - which in our model is generated
dynamically, rather than being postulated. We argue that our model can be used
in a similar way to the Black-Litterman model. In particular, it represents, in
a simple modeling framework, market views of common predictive signals, market
impacts and implied optimal dynamic portfolio allocations, and can be used to
assess values of private signals. Moreover, it allows one to quantify a
&quot;market-implied&quot; optimal investment strategy, along with a measure of market
rationality. Our approach is numerically light, and can be implemented using
standard off-the-shelf software such as TensorFlow.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-fin/1/au:+Halperin_I/0/1/0/all/0/1&quot;&gt;Igor Halperin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-fin/1/au:+Feldshteyn_I/0/1/0/all/0/1&quot;&gt;Ilya Feldshteyn&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.06530">
<title>Improving the Gaussian Mechanism for Differential Privacy: Analytical Calibration and Optimal Denoising. (arXiv:1805.06530v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.06530</link>
<description rdf:parseType="Literal">&lt;p&gt;The Gaussian mechanism is an essential building block used in multitude of
differentially private data analysis algorithms. In this paper we revisit the
Gaussian mechanism and show that the original analysis has several important
limitations. Our analysis reveals that the variance formula for the original
mechanism is far from tight in the high privacy regime ($\varepsilon \to 0$)
and it cannot be extended to the low privacy regime ($\varepsilon \to \infty$).
We address this limitations by developing an analytic Gaussian mechanism whose
variance is calibrated directly using the Gaussian cumulative density function
instead of a tail bound approximation. We also propose to equip the Gaussian
mechanism with a post-processing step based on adaptive denoising estimators by
leveraging that the variance of the perturbation is known. Our experiments show
that analytical calibration removes at least a third of the variance of the
noise compared to the classical Gaussian mechanism, and that denoising
dramatically improves the accuracy of the Gaussian mechanism in the
high-dimensional regime.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Balle_B/0/1/0/all/0/1&quot;&gt;Borja Balle&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yu-Xiang Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.06576">
<title>A Spline Theory of Deep Networks (Extended Version). (arXiv:1805.06576v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.06576</link>
<description rdf:parseType="Literal">&lt;p&gt;We build a rigorous bridge between deep networks (DNs) and approximation
theory via spline functions and operators. Our key result is that a large class
of DNs can be written as a composition of max-affine spline operators (MASOs),
which provide a powerful portal through which to view and analyze their inner
workings. For instance, conditioned on the input signal, the output of a MASO
DN can be written as a simple affine transformation of the input. This implies
that a DN constructs a set of signal-dependent, class-specific templates
against which the signal is compared via a simple inner product; we explore the
links to the classical theory of optimal classification via matched filters and
the effects of data memorization. Going further, we propose a simple penalty
term that can be added to the cost function of any DN learning algorithm to
force the templates to be orthogonal with each other; this leads to
significantly improved classifi- cation performance and reduced overfitting
with no change to the DN architecture. The spline partition of the input signal
space that is implicitly induced by a MASO directly links DNs to the theory of
vector quantization (VQ) and K-means clustering, which opens up new geometric
avenue to study how DNs organize signals in a hierarchical fashion. To validate
the utility of the VQ interpretation, we develop and validate a new distance
metric for signals and images that quantifies the difference between their VQ
encodings. (This paper is a significantly expanded version of a paper with the
same title that will appear at ICML 2018.)
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Balestriero_R/0/1/0/all/0/1&quot;&gt;Randall Balestriero&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Baraniuk_R/0/1/0/all/0/1&quot;&gt;Richard Baraniuk&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.06595">
<title>Covariance-Insured Screening. (arXiv:1805.06595v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.06595</link>
<description rdf:parseType="Literal">&lt;p&gt;Modern bio-technologies have produced a vast amount of high-throughput data
with the number of predictors far greater than the sample size. In order to
identify more novel biomarkers and understand biological mechanisms, it is
vital to detect signals weakly associated with outcomes among
ultrahigh-dimensional predictors. However, existing screening methods, which
typically ignore correlation information, are likely to miss these weak
signals. By incorporating the inter-feature dependence, we propose a
covariance-insured screening methodology to identify predictors that are
jointly informative but only marginally weakly associated with outcomes. The
validity of the method is examined via extensive simulations and real data
studies for selecting potential genetic factors related to the onset of cancer.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+He_K/0/1/0/all/0/1&quot;&gt;Kevin He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kang_J/0/1/0/all/0/1&quot;&gt;Jian Kang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hong_H/0/1/0/all/0/1&quot;&gt;Hyokyoung Grace Hong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhu_J/0/1/0/all/0/1&quot;&gt;Ji Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yanming Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lin_H/0/1/0/all/0/1&quot;&gt;Huazhen Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Xu_H/0/1/0/all/0/1&quot;&gt;Han Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yi Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.06605">
<title>Defense-GAN: Protecting Classifiers Against Adversarial Attacks Using Generative Models. (arXiv:1805.06605v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1805.06605</link>
<description rdf:parseType="Literal">&lt;p&gt;In recent years, deep neural network approaches have been widely adopted for
machine learning tasks, including classification. However, they were shown to
be vulnerable to adversarial perturbations: carefully crafted small
perturbations can cause misclassification of legitimate images. We propose
Defense-GAN, a new framework leveraging the expressive capability of generative
models to defend deep neural networks against such attacks. Defense-GAN is
trained to model the distribution of unperturbed images. At inference time, it
finds a close output to a given image which does not contain the adversarial
changes. This output is then fed to the classifier. Our proposed method can be
used with any classification model and does not modify the classifier structure
or training procedure. It can also be used as a defense against any attack as
it does not assume knowledge of the process for generating the adversarial
examples. We empirically show that Defense-GAN is consistently effective
against different attack methods and improves on existing defense strategies.
Our code has been made publicly available at
https://github.com/kabkabm/defensegan.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Samangouei_P/0/1/0/all/0/1&quot;&gt;Pouya Samangouei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kabkab_M/0/1/0/all/0/1&quot;&gt;Maya Kabkab&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chellappa_R/0/1/0/all/0/1&quot;&gt;Rama Chellappa&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.06619">
<title>Taxi demand forecasting: A HEDGE based tessellation strategy for improved accuracy. (arXiv:1805.06619v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.06619</link>
<description rdf:parseType="Literal">&lt;p&gt;A key problem in location-based modeling and forecasting lies in identifying
suitable spatial and temporal resolutions. In particular, judicious spatial
partitioning can play a significant role in enhancing the performance of
location-based forecasting models. In this work, we investigate two widely used
tessellation strategies for partitioning city space, in the context of
real-time taxi demand forecasting. Our study compares (i) Geohash tessellation,
and (ii) Voronoi tessellation, using two distinct taxi demand datasets, over
multiple time scales. For the purpose of comparison, we employ classical
time-series tools to model the spatio-temporal demand. Our study finds that the
performance of each tessellation strategy is highly dependent on the city
geography, spatial distribution of the data, and the time of the day, and that
neither strategy is found to perform optimally across the forecast horizon. We
propose a hybrid tessellation algorithm that picks the best tessellation
strategy at each instant, based on their performance in the recent past. Our
hybrid algorithm is a non-stationary variant of the well-known HEDGE algorithm
for choosing the best advice from multiple experts. We show that the hybrid
tessellation strategy performs consistently better than either of the two
strategies across the data sets considered, at multiple time scales, and with
different performance metrics. We achieve an average accuracy of above 80% per
km^2 for both data sets considered at 60 minute aggregation levels.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Davis_N/0/1/0/all/0/1&quot;&gt;Neema Davis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Raina_G/0/1/0/all/0/1&quot;&gt;Gaurav Raina&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jagannathan_K/0/1/0/all/0/1&quot;&gt;Krishna Jagannathan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.06627">
<title>Probabilistic Embedding of Knowledge Graphs with Box Lattice Measures. (arXiv:1805.06627v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.06627</link>
<description rdf:parseType="Literal">&lt;p&gt;Embedding methods which enforce a partial order or lattice structure over the
concept space, such as Order Embeddings (OE) (Vendrov et al., 2016), are a
natural way to model transitive relational data (e.g. entailment graphs).
However, OE learns a deterministic knowledge base, limiting expressiveness of
queries and the ability to use uncertainty for both prediction and learning
(e.g. learning from expectations). Probabilistic extensions of OE (Lai and
Hockenmaier, 2017) have provided the ability to somewhat calibrate these
denotational probabilities while retaining the consistency and inductive bias
of ordered models, but lack the ability to model the negative correlations
found in real-world knowledge. In this work we show that a broad class of
models that assign probability measures to OE can never capture negative
correlation, which motivates our construction of a novel box lattice and
accompanying probability measure to capture anticorrelation and even disjoint
concepts, while still providing the benefits of probabilistic modeling, such as
the ability to perform rich joint and conditional queries over arbitrary sets
of concepts, and both learning from and predicting calibrated uncertainty. We
show improvements over previous approaches in modeling the Flickr and WordNet
entailment graphs, and investigate the power of the model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Vilnis_L/0/1/0/all/0/1&quot;&gt;Luke Vilnis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xiang Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Murty_S/0/1/0/all/0/1&quot;&gt;Shikhar Murty&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+McCallum_A/0/1/0/all/0/1&quot;&gt;Andrew McCallum&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.06639">
<title>Independent Component Analysis via Energy-based and Kernel-based Mutual Dependence Measures. (arXiv:1805.06639v1 [stat.ME])</title>
<link>http://arxiv.org/abs/1805.06639</link>
<description rdf:parseType="Literal">&lt;p&gt;We apply both distance-based (Jin and Matteson, 2017) and kernel-based
(Pfister et al., 2016) mutual dependence measures to independent component
analysis (ICA), and generalize dCovICA (Matteson and Tsay, 2017) to MDMICA,
minimizing empirical dependence measures as an objective function in both
deflation and parallel manners. Solving this minimization problem, we introduce
Latin hypercube sampling (LHS) (McKay et al., 2000), and a global optimization
method, Bayesian optimization (BO) (Mockus, 1994) to improve the initialization
of the Newton-type local optimization method. The performance of MDMICA is
evaluated in various simulation studies and an image data example. When the ICA
model is correct, MDMICA achieves competitive results compared to existing
approaches. When the ICA model is misspecified, the estimated independent
components are less mutually dependent than the observed components using
MDMICA, while they are prone to be even more mutually dependent than the
observed components using other approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Jin_Z/0/1/0/all/0/1&quot;&gt;Ze Jin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Matteson_D/0/1/0/all/0/1&quot;&gt;David S. Matteson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.06649">
<title>Day-ahead electricity price forecasting with high-dimensional structures: Univariate vs. multivariate modeling frameworks. (arXiv:1805.06649v1 [stat.AP])</title>
<link>http://arxiv.org/abs/1805.06649</link>
<description rdf:parseType="Literal">&lt;p&gt;We conduct an extensive empirical study on short-term electricity price
forecasting (EPF) to address the long-standing question if the optimal model
structure for EPF is univariate or multivariate. We provide evidence that
despite a minor edge in predictive performance overall, the multivariate
modeling framework does not uniformly outperform the univariate one across all
12 considered datasets, seasons of the year or hours of the day, and at times
is outperformed by the latter. This is an indication that combining advanced
structures or the corresponding forecasts from both modeling approaches can
bring a further improvement in forecasting accuracy. We show that this indeed
can be the case, even for a simple averaging scheme involving only two models.
Finally, we also analyze variable selection for the best performing
high-dimensional lasso-type models, thus provide guidelines to structuring
better performing forecasting model designs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ziel_F/0/1/0/all/0/1&quot;&gt;Florian Ziel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Weron_R/0/1/0/all/0/1&quot;&gt;Rafal Weron&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.06826">
<title>The Blessings of Multiple Causes. (arXiv:1805.06826v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.06826</link>
<description rdf:parseType="Literal">&lt;p&gt;Causal inference from observation data often assumes &quot;strong ignorability,&quot;
that all confounders are observed. This assumption is standard yet untestable.
However, many scientific studies involve multiple causes, different variables
whose effects are simultaneously of interest. We propose the deconfounder, an
algorithm that combines unsupervised machine learning and predictive model
checking to perform causal inference in multiple-cause settings. The
deconfounder infers a latent variable as a substitute for unobserved
confounders and then uses that substitute to perform causal inference. We
develop theory for when the deconfounder leads to unbiased causal estimates,
and show that it requires weaker assumptions than classical causal inference.
We analyze its performance in three types of studies: semi-simulated data
around smoking and lung cancer, semi-simulated data around genomewide
association studies, and a real dataset about actors and movie revenue. The
deconfounder provides a checkable approach to estimating close-to-truth causal
effects.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yixin Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Blei_D/0/1/0/all/0/1&quot;&gt;David M. Blei&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.06834">
<title>Subspace Estimation from Incomplete Observations: A High-Dimensional Analysis. (arXiv:1805.06834v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.06834</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a high-dimensional analysis of three popular algorithms, namely,
Oja&apos;s method, GROUSE and PETRELS, for subspace estimation from streaming and
highly incomplete observations. We show that, with proper time scaling, the
time-varying principal angles between the true subspace and its estimates given
by the algorithms converge weakly to deterministic processes when the ambient
dimension $n$ tends to infinity. Moreover, the limiting processes can be
exactly characterized as the unique solutions of certain ordinary differential
equations (ODEs). A finite sample bound is also given, showing that the rate of
convergence towards such limits is $\mathcal{O}(1/\sqrt{n})$. In addition to
providing asymptotically exact predictions of the dynamic performance of the
algorithms, our high-dimensional analysis yields several insights, including an
asymptotic equivalence between Oja&apos;s method and GROUSE, and a precise scaling
relationship linking the amount of missing data to the signal-to-noise ratio.
By analyzing the solutions of the limiting ODEs, we also establish phase
transition phenomena associated with the steady-state performance of these
techniques.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_C/0/1/0/all/0/1&quot;&gt;Chuang Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Eldar_Y/0/1/0/all/0/1&quot;&gt;Yonina C. Eldar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_Y/0/1/0/all/0/1&quot;&gt;Yue M. Lu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.06837">
<title>A fast algorithm with minimax optimal guarantees for topic models with an unknown number of topics. (arXiv:1805.06837v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.06837</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a new method of estimation in topic models, that is not a
variation on the existing simplex finding algorithms, and that estimates the
number of topics K from the observed data. We derive new finite sample minimax
lower bounds for the estimation of A, as well as new upper bounds for our
proposed estimator. We describe the scenarios where our estimator is minimax
adaptive. Our finite sample analysis is valid for any number of documents (n),
individual document length (N_i), dictionary size (p) and number of topics (K),
and both p and K are allowed to increase with n, a situation not handled well
by previous analyses. We complement our theoretical results with a detailed
simulation study. We illustrate that the new algorithm is faster and more
accurate than the current ones, although we start out with a computational and
theoretical disadvantage of not knowing the correct number of topics K, while
we provide the competing methods with the correct value in our simulations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bing_X/0/1/0/all/0/1&quot;&gt;Xin Bing&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bunea_F/0/1/0/all/0/1&quot;&gt;Florentina Bunea&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wegkamp_M/0/1/0/all/0/1&quot;&gt;Marten Wegkamp&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1504.06043">
<title>Stability of Stochastic Approximations with `Controlled Markov&apos; Noise and Temporal Difference Learning. (arXiv:1504.06043v2 [cs.SY] UPDATED)</title>
<link>http://arxiv.org/abs/1504.06043</link>
<description rdf:parseType="Literal">&lt;p&gt;We are interested in understanding stability (almost sure boundedness) of
stochastic approximation algorithms (SAs) driven by a `controlled Markov&apos;
process. Analyzing this class of algorithms is important, since many
reinforcement learning (RL) algorithms can be cast as SAs driven by a
`controlled Markov&apos; process. In this paper, we present easily verifiable
sufficient conditions for stability and convergence of SAs driven by a
`controlled Markov&apos; process. Many RL applications involve continuous state
spaces. While our analysis readily ensures stability for such continuous state
applications, traditional analyses do not. As compared to literature, our
analysis presents a two-fold generalization (a) the Markov process may evolve
in a continuous state space and (b) the process need not be ergodic under any
given stationary policy. Temporal difference learning (TD) is an important
policy evaluation method in reinforcement learning. The theory developed
herein, is used to analyze generalized $TD(0)$, an important variant of TD. Our
theory is also used to analyze a TD formulation of supervised learning for
forecasting problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ramaswamy_A/0/1/0/all/0/1&quot;&gt;Arunselvan Ramaswamy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bhatnagar_S/0/1/0/all/0/1&quot;&gt;Shalabh Bhatnagar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1510.02267">
<title>Reduced-Order Modeling Of Hidden Dynamics. (arXiv:1510.02267v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1510.02267</link>
<description rdf:parseType="Literal">&lt;p&gt;The objective of this paper is to investigate how noisy and incomplete
observations can be integrated in the process of building a reduced-order
model.
&lt;/p&gt;
&lt;p&gt;This problematic arises in many scientific domains where there exists a need
for accurate low-order descriptions of highly-complex phenomena, which can not
be directly and/or deterministically observed. Within this context, the paper
proposes a probabilistic framework for the construction of &quot;POD-Galerkin&quot;
reduced-order models. Assuming a hidden Markov chain, the inference integrates
the uncertainty of the hidden states relying on their posterior distribution.
Simulations show the benefits obtained by exploiting the proposed framework.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Heas_P/0/1/0/all/0/1&quot;&gt;Patrick H&amp;#xe9;as&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Herzet_C/0/1/0/all/0/1&quot;&gt;C&amp;#xe9;dric Herzet&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1610.02962">
<title>Low-Rank Dynamic Mode Decomposition: Optimal Solution in Polynomial-Time. (arXiv:1610.02962v5 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1610.02962</link>
<description rdf:parseType="Literal">&lt;p&gt;This work studies the linear approximation of high-dimensional dynamical
systems using low-rank dynamic mode decomposition (DMD). Searching this
approximation in a data-driven approach can be formalised as attempting to
solve a low-rank constrained optimisation problem. This problem is non-convex
and state-of-the-art algorithms are all sub-optimal. This paper shows that
there exists a closed-form solution, which can be computed in polynomial-time,
and characterises the $\ell_2$-norm of the optimal approximation error. The
theoretical results serve to design low-complexity algorithms building reduced
models from the optimal solution, based on singular value decomposition or
low-rank DMD. The algorithms are evaluated by numerical simulations using
synthetic and physical data benchmarks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Heas_P/0/1/0/all/0/1&quot;&gt;Patrick H&amp;#xe9;as&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Herzet_C/0/1/0/all/0/1&quot;&gt;C&amp;#xe9;dric Herzet&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1701.01064">
<title>Optimal Low-Rank Dynamic Mode Decomposition. (arXiv:1701.01064v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1701.01064</link>
<description rdf:parseType="Literal">&lt;p&gt;Dynamic Mode Decomposition (DMD) has emerged as a powerful tool for analyzing
the dynamics of non-linear systems from experimental datasets. Recently,
several attempts have extended DMD to the context of low-rank approximations.
This extension is of particular interest for reduced-order modeling in various
applicative domains, e.g. for climate prediction, to study molecular dynamics
or micro-electromechanical devices. This low-rank extension takes the form of a
non-convex optimization problem. To the best of our knowledge, only sub-optimal
algorithms have been proposed in the literature to compute the solution of this
problem. In this paper, we prove that there exists a closed-form optimal
solution to this problem and design an effective algorithm to compute it based
on Singular Value Decomposition (SVD). A toy-example illustrates the gain in
performance of the proposed algorithm compared to state-of-the-art techniques.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Heas_P/0/1/0/all/0/1&quot;&gt;Patrick H&amp;#xe9;as&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Herzet_C/0/1/0/all/0/1&quot;&gt;C&amp;#xe9;dric Herzet&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.02823">
<title>Structural Feature Selection for Event Logs. (arXiv:1710.02823v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1710.02823</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the problem of classifying business process instances based on
structural features derived from event logs. The main motivation is to provide
machine learning based techniques with quick response times for interactive
computer assisted root cause analysis. In particular, we create structural
features from process mining such as activity and transition occurrence counts,
and ordering of activities to be evaluated as potential features for
classification. We show that adding such structural features increases the
amount of information thus potentially increasing classification accuracy.
However, there is an inherent trade-off as using too many features leads to too
long run-times for machine learning classification models. One way to improve
the machine learning algorithms&apos; run-time is to only select a small number of
features by a feature selection algorithm. However, the run-time required by
the feature selection algorithm must also be taken into account. Also, the
classification accuracy should not suffer too much from the feature selection.
The main contributions of this paper are as follows: First, we propose and
compare six different feature selection algorithms by means of an experimental
setup comparing their classification accuracy and achievable response times.
Second, we discuss the potential use of feature selection results for computer
assisted root cause analysis as well as the properties of different types of
structural features in the context of feature selection.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hinkka_M/0/1/0/all/0/1&quot;&gt;Markku Hinkka&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lehto_T/0/1/0/all/0/1&quot;&gt;Teemu Lehto&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Heljanko_K/0/1/0/all/0/1&quot;&gt;Keijo Heljanko&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jung_A/0/1/0/all/0/1&quot;&gt;Alexander Jung&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.10919">
<title>Optimal Kernel-Based Dynamic Mode Decomposition. (arXiv:1710.10919v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1710.10919</link>
<description rdf:parseType="Literal">&lt;p&gt;The state-of-the-art algorithm known as kernel-based dynamic mode
decomposition (K-DMD) provides a sub-optimal solution to the problem of reduced
modeling of a dynamical system based on a finite approximation of the Koopman
operator. It relies on crude approximations and on restrictive assumptions. The
purpose of this work is to propose a kernel-based algorithm solving exactly
this low-rank approximation problem in a general setting.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Heas_P/0/1/0/all/0/1&quot;&gt;Patrick H&amp;#xe9;as&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Herzet_C/0/1/0/all/0/1&quot;&gt;C&amp;#xe9;dric Herzet&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.07875">
<title>Support Vector Machine Active Learning Algorithms with Query-by-Committee versus Closest-to-Hyperplane Selection. (arXiv:1801.07875v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1801.07875</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper investigates and evaluates support vector machine active learning
algorithms for use with imbalanced datasets, which commonly arise in many
applications such as information extraction applications. Algorithms based on
closest-to-hyperplane selection and query-by-committee selection are combined
with methods for addressing imbalance such as positive amplification based on
prevalence statistics from initial random samples. Three algorithms (ClosestPA,
QBagPA, and QBoostPA) are presented and carefully evaluated on datasets for
text classification and relation extraction. The ClosestPA algorithm is shown
to consistently outperform the other two in a variety of ways and insights are
provided as to why this is the case.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bloodgood_M/0/1/0/all/0/1&quot;&gt;Michael Bloodgood&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.08694">
<title>PDNet: Semantic Segmentation integrated with a Primal-Dual Network for Document binarization. (arXiv:1801.08694v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1801.08694</link>
<description rdf:parseType="Literal">&lt;p&gt;Binarization of digital documents is the task of classifying each pixel in an
image of the document as belonging to the background (parchment/paper) or
foreground (text/ink). Historical documents are often subjected to
degradations, that make the task challenging. In the current work a deep neural
network architecture is proposed that combines a fully convolutional network
with an unrolled primal-dual network that can be trained end-to-end to achieve
state of the art binarization on four out of seven datasets. Document
binarization is formulated as an energy minimization problem. A fully
convolutional neural network is trained for semantic segmentation of pixels
that provides labeling cost associated with each pixel. This cost estimate is
refined along the edges to compensate for any over or under estimation of the
foreground class using a primal-dual approach. We provide necessary overview on
proximal operator that facilitates theoretical underpinning required to train a
primal-dual network using a gradient descent algorithm. Numerical instabilities
encountered due to the recurrent nature of primal-dual approach are handled. We
provide experimental results on document binarization competition dataset along
with network changes and hyperparameter tuning required for stability and
performance of the network. The network when pre-trained on synthetic dataset
performs better as per the competition metrics.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ayyalasomayajula_K/0/1/0/all/0/1&quot;&gt;Kalyan Ram Ayyalasomayajula&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Malmberg_F/0/1/0/all/0/1&quot;&gt;Filip Malmberg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Brun_A/0/1/0/all/0/1&quot;&gt;Anders Brun&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.03752">
<title>Supervised classification of Dermatological diseases by Deep learning. (arXiv:1802.03752v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1802.03752</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper introduces a deep-learning based efficient classifier for common
dermatological conditions, aimed at people without easy access to skin
specialists. We report approximately 80% accuracy, in a situation where primary
care doctors have attained 57% success rate, according to recent literature.
The rationale of its design is centered on deploying and updating it on
handheld devices in near future. Dermatological diseases are common in every
population and have a wide spectrum in severity. With a shortage of
dermatological expertise being observed in several countries, machine learning
solutions can augment medical services and advise regarding existence of common
diseases. The paper implements supervised classification of nine distinct
conditions which have high occurrence in East Asian countries. Our current
attempt establishes that deep learning based techniques are viable avenues for
preliminary information to aid patients.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mishra_S/0/1/0/all/0/1&quot;&gt;Sourav Mishra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yamasaki_T/0/1/0/all/0/1&quot;&gt;Toshihiko Yamasaki&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Imaizumi_H/0/1/0/all/0/1&quot;&gt;Hideaki Imaizumi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04085">
<title>Empirical Risk Minimization in Non-interactive Local Differential Privacy: Efficiency and High Dimensional Case. (arXiv:1802.04085v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1802.04085</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we study the Empirical Risk Minimization problem in the
non-interactive local model of differential privacy. In the case of constant or
low dimensionality ($p\ll n$), we first show that if the ERM loss function is
$(\infty, T)$-smooth, then we can avoid a dependence of the sample complexity,
to achieve error $\alpha$, on the exponential of the dimensionality $p$ with
base $1/\alpha$ (i.e., $\alpha^{-p}$), which answers a question in [smith 2017
interaction]. Our approach is based on polynomial approximation. Then, we
propose player-efficient algorithms with $1$-bit communication complexity and
$O(1)$ computation cost for each player. The error bound is asymptotically the
same as the original one. Also with additional assumptions we show a server
efficient algorithm. Next we consider the high dimensional case ($n\ll p$), we
show that if the loss function is Generalized Linear function and convex, then
we could get an error bound which is dependent on the Gaussian width of the
underlying constrained set instead of $p$, which is lower than that in [smith
2017 interaction].
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1&quot;&gt;Di Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gaboardi_M/0/1/0/all/0/1&quot;&gt;Marco Gaboardi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1&quot;&gt;Jinhui Xu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08429">
<title>Exact Sampling of Determinantal Point Processes without Eigendecomposition. (arXiv:1802.08429v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1802.08429</link>
<description rdf:parseType="Literal">&lt;p&gt;Determinantal point processes (DPPs) enable the modelling of repulsion: they
provide diverse sets of points. This repulsion is encoded in a kernel K that we
can see as a matrix storing the similarity between points. The usual algorithm
to sample DPPs is exact but it uses the spectral decomposition of K, a
computation that becomes costly when dealing with a high number of points.
Here, we present an alternative exact algorithm that avoids the eigenvalues and
the eigenvectors computation and that is, for some applications, faster than
the original algorithm.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Launay_C/0/1/0/all/0/1&quot;&gt;Claire Launay&lt;/a&gt; (MAP5 - UMR 8145), &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Galerne_B/0/1/0/all/0/1&quot;&gt;Bruno Galerne&lt;/a&gt; (MAP5 - UMR 8145), &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Desolneux_A/0/1/0/all/0/1&quot;&gt;Agn&amp;#xe8;s Desolneux&lt;/a&gt; (CMLA, CNRS)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.04918">
<title>Distributed Collaborative Hashing and Its Applications in Ant Financial. (arXiv:1804.04918v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1804.04918</link>
<description rdf:parseType="Literal">&lt;p&gt;Collaborative filtering, especially latent factor model, has been popularly
used in personalized recommendation. Latent factor model aims to learn user and
item latent factors from user-item historic behaviors. To apply it into real
big data scenarios, efficiency becomes the first concern, including offline
model training efficiency and online recommendation efficiency. In this paper,
we propose a Distributed Collaborative Hashing (DCH) model which can
significantly improve both efficiencies. Specifically, we first propose a
distributed learning framework, following the state-of-the-art parameter server
paradigm, to learn the offline collaborative model. Our model can be learnt
efficiently by distributedly computing subgradients in minibatches on workers
and updating model parameters on servers asynchronously. We then adopt hashing
technique to speedup the online recommendation procedure. Recommendation can be
quickly made through exploiting lookup hash tables. We conduct thorough
experiments on two real large-scale datasets. The experimental results
demonstrate that, comparing with the classic and state-of-the-art (distributed)
latent factor models, DCH has comparable performance in terms of recommendation
accuracy but has both fast convergence speed in offline model training
procedure and realtime efficiency in online recommendation procedure.
Furthermore, the encouraging performance of DCH is also shown for several
real-world applications in Ant Financial.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1&quot;&gt;Chaochao Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1&quot;&gt;Ziqi Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_P/0/1/0/all/0/1&quot;&gt;Peilin Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1&quot;&gt;Longfei Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1&quot;&gt;Jun Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xiaolong Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.02587">
<title>Complete Analysis of a Random Forest Model. (arXiv:1805.02587v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1805.02587</link>
<description rdf:parseType="Literal">&lt;p&gt;Random forests have become an important tool for improving accuracy in
regression problems since their popularization by (Breiman, 2001) and others.
In this paper, we revisit a random forest model originally proposed by
(Breiman, 2004) and later studied by (Biau, 2012), where a feature is selected
at random and the split occurs at the midpoint of the box containing the chosen
feature. If the Lipschitz regression function is sparse and depends only on a
small, unknown subset of $S$ out of $d$ features, we show that given $n$
observations, this random forest model outputs a predictor that has a
mean-squared prediction error of order $(n(\sqrt{\log
n})^{S-1})^{-\frac{1}{S\log2+1}}$. When $S \leq \lfloor 0.72 d \rfloor$, this
rate is better than the minimax optimal rate $n^{-\frac{2}{d+2}}$ for
$d$-dimensional, Lipschitz function classes. The second part of this article
shows that the prediction error for this random forest model cannot generally
be improved.
&lt;/p&gt;
&lt;p&gt;As a striking consequence of our analysis, we show that if $\ell_{avg}$
(resp. $\ell_{max}$) is the average (resp. maximum) number of observations per
leaf node, then the variance of this forest is
$\Theta(\ell^{-1}_{avg}(\sqrt{\log n})^{-(S-1)})$, which for the case of $S =
d$, is similar in form to the lower bound $\Omega(\ell^{-1}_{max}(\log
n)^{-(d-1)})$ of (Lin and Jeon, 2006) for any random forest model with a
nonadaptive splitting scheme. We also show that the bias is tight for any
linear model with nonzero parameter vector. Our new analysis also implies that
better theoretical performance can be achieved if the trees are grown to a
shallower depth than previous work would otherwise recommend.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Klusowski_J/0/1/0/all/0/1&quot;&gt;Jason M. Klusowski&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.02532">
<title>Generalizing Distance Covariance to Measure and Test Multivariate Mutual Dependence. (arXiv:1709.02532v5 [math.ST] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1709.02532</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose three measures of mutual dependence between multiple random
vectors. All the measures are zero if and only if the random vectors are
mutually independent. The first measure generalizes distance covariance from
pairwise dependence to mutual dependence, while the other two measures are sums
of squared distance covariance. All the measures share similar properties and
asymptotic distributions to distance covariance, and capture non-linear and
non-monotone mutual dependence between the random vectors. Inspired by complete
and incomplete V-statistics, we define the empirical measures and simplified
empirical measures as a trade-off between the complexity and power when testing
mutual independence. Implementation of the tests is demonstrated by both
simulation results and real data examples.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Jin_Z/0/1/0/all/0/1&quot;&gt;Ze Jin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Matteson_D/0/1/0/all/0/1&quot;&gt;David S. Matteson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.08837">
<title>Optimization and Testing in Linear Non-Gaussian Component Analysis. (arXiv:1712.08837v2 [stat.ME] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1712.08837</link>
<description rdf:parseType="Literal">&lt;p&gt;Independent component analysis (ICA) decomposes multivariate data into
mutually independent components (ICs). The ICA model is subject to a constraint
that at most one of these components is Gaussian, which is required for model
identifiability. Linear non-Gaussian component analysis (LNGCA) generalizes the
ICA model to a linear latent factor model with any number of both non-Gaussian
components (signals) and Gaussian components (noise), where observations are
linear combinations of independent components. Although the individual Gaussian
components are not identifiable, the Gaussian subspace is identifiable. We
introduce an estimator along with its optimization approach in which
non-Gaussian and Gaussian components are estimated simultaneously, maximizing
the discrepancy of each non-Gaussian component from Gaussianity while
minimizing the discrepancy of each Gaussian component from Gaussianity. When
the number of non-Gaussian components is unknown, we develop a statistical test
to determine it based on resampling and the discrepancy of estimated
components. Through a variety of simulation studies, we demonstrate the
improvements of our estimator over competing estimators, and we illustrate the
effectiveness of the test to determine the number of non-Gaussian components.
Further, we apply our method to real data examples and demonstrate its
practical value.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Jin_Z/0/1/0/all/0/1&quot;&gt;Ze Jin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Risk_B/0/1/0/all/0/1&quot;&gt;Benjamin B. Risk&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Matteson_D/0/1/0/all/0/1&quot;&gt;David S. Matteson&lt;/a&gt;</dc:creator>
</item></rdf:RDF>