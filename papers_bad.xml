<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Boring papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Bad Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-06-03T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00201"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00299"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00300"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.02017"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.05284"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00047"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00054"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00064"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00069"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00119"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00143"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00153"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00352"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00358"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09904"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09197"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1605.03035"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00040"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00125"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00144"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00159"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00176"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00265"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00271"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00319"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00336"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00370"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00413"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00416"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00437"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00451"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1612.04899"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1702.08134"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1703.09165"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.06818"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08318"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.00606"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.07300"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.00013"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.00020"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.00063"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.02136"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07808"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08114"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08498"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11686"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.12421"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.12528"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1806.00201">
<title>Being curious about the answers to questions: novelty search with learned attention. (arXiv:1806.00201v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1806.00201</link>
<description rdf:parseType="Literal">&lt;p&gt;We investigate the use of attentional neural network layers in order to learn
a `behavior characterization&apos; which can be used to drive novelty search and
curiosity-based policies. The space is structured towards answering a
particular distribution of questions, which are used in a supervised way to
train the attentional neural network. We find that in a 2d exploration task,
the structure of the space successfully encodes local sensory-motor
contingencies such that even a greedy local `do the most novel action&apos; policy
with no reinforcement learning or evolution can explore the space quickly. We
also apply this to a high/low number guessing game task, and find that guessing
according to the learned attention profile performs active inference and can
discover the correct number more quickly than an exact but passive approach.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guttenberg_N/0/1/0/all/0/1&quot;&gt;Nicholas Guttenberg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Biehl_M/0/1/0/all/0/1&quot;&gt;Martin Biehl&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Virgo_N/0/1/0/all/0/1&quot;&gt;Nathaniel Virgo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kanai_R/0/1/0/all/0/1&quot;&gt;Ryota Kanai&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00299">
<title>Fast Artificial Immune Systems. (arXiv:1806.00299v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1806.00299</link>
<description rdf:parseType="Literal">&lt;p&gt;Various studies have shown that characteristic Artificial Immune System (AIS)
operators such as hypermutations and ageing can be very efficient at escaping
local optima of multimodal optimisation problems. However, this efficiency
comes at the expense of considerably slower runtimes during the exploitation
phase compared to standard evolutionary algorithms. We propose modifications to
the traditional `hypermutations with mutation potential&apos; (HMP) that allow them
to be efficient at exploitation as well as maintaining their effective
explorative characteristics. Rather than deterministically evaluating fitness
after each bitflip of a hypermutation, we sample the fitness function
stochastically with a `parabolic&apos; distribution which allows the `stop at first
constructive mutation&apos; (FCM) variant of HMP to reduce the linear amount of
wasted function evaluations when no improvement is found to a constant. By
returning the best sampled solution during the hypermutation, rather than the
first constructive mutation, we then turn the extremely inefficient HMP
operator without FCM, into a very effective operator for the standard Opt-IA
AIS using hypermutation, cloning and ageing. We rigorously prove the
effectiveness of the two proposed operators by analysing them on all problems
where the performance of HPM is rigorously understood in the literature. %
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Corus_D/0/1/0/all/0/1&quot;&gt;Dogan Corus&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oliveto_P/0/1/0/all/0/1&quot;&gt;Pietro S. Oliveto&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yazdani_D/0/1/0/all/0/1&quot;&gt;Donya Yazdani&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00300">
<title>Artificial Immune Systems Can Find Arbitrarily Good Approximations for the NP-Hard Partition Problem. (arXiv:1806.00300v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1806.00300</link>
<description rdf:parseType="Literal">&lt;p&gt;Typical Artificial Immune System (AIS) operators such as hypermutations with
mutation potential and ageing allow to efficiently overcome local optima from
which Evolutionary Algorithms (EAs) struggle to escape. Such behaviour has been
shown for artificial example functions such as Jump, Cliff or Trap constructed
especially to show difficulties that EAs may encounter during the optimisation
process. However, no evidence is available indicating that similar effects may
also occur in more realistic problems. In this paper we perform an analysis for
the standard NP-Hard \partition problem from combinatorial optimisation and
rigorously show that hypermutations and ageing allow AISs to efficiently escape
from local optima where standard EAs require exponential time. As a result we
prove that while EAs and Random Local Search may get trapped on 4/3
approximations, AISs find arbitrarily good approximate solutions of ratio
(1+$\epsilon$) for any constant $\epsilon$ within a time that is polynomial in
the problem size and exponential only in $1/\epsilon$.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Corus_D/0/1/0/all/0/1&quot;&gt;Dogan Corus&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oliveto_P/0/1/0/all/0/1&quot;&gt;Pietro S. Oliveto&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yazdani_D/0/1/0/all/0/1&quot;&gt;Donya Yazdani&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.02017">
<title>NeST: A Neural Network Synthesis Tool Based on a Grow-and-Prune Paradigm. (arXiv:1711.02017v3 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1711.02017</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep neural networks (DNNs) have begun to have a pervasive impact on various
applications of machine learning. However, the problem of finding an optimal
DNN architecture for large applications is challenging. Common approaches go
for deeper and larger DNN architectures but may incur substantial redundancy.
To address these problems, we introduce a network growth algorithm that
complements network pruning to learn both weights and compact DNN architectures
during training. We propose a DNN synthesis tool (NeST) that combines both
methods to automate the generation of compact and accurate DNNs. NeST starts
with a randomly initialized sparse network called the seed architecture. It
iteratively tunes the architecture with gradient-based growth and
magnitude-based pruning of neurons and connections. Our experimental results
show that NeST yields accurate, yet very compact DNNs, with a wide range of
seed architecture selection. For the LeNet-300-100 (LeNet-5) architecture, we
reduce network parameters by 70.2x (74.3x) and floating-point operations
(FLOPs) by 79.4x (43.7x). For the AlexNet and VGG-16 architectures, we reduce
network parameters (FLOPs) by 15.7x (4.6x) and 30.2x (8.6x), respectively.
NeST&apos;s grow-and-prune paradigm delivers significant additional parameter and
FLOPs reduction relative to pruning-only methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dai_X/0/1/0/all/0/1&quot;&gt;Xiaoliang Dai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yin_H/0/1/0/all/0/1&quot;&gt;Hongxu Yin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jha_N/0/1/0/all/0/1&quot;&gt;Niraj K. Jha&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.05284">
<title>Adaptation to criticality through organizational invariance in embodied agents. (arXiv:1712.05284v3 [nlin.AO] UPDATED)</title>
<link>http://arxiv.org/abs/1712.05284</link>
<description rdf:parseType="Literal">&lt;p&gt;Many biological and cognitive systems do not operate deep within one or other
regime of activity. Instead, they are poised at critical points located at
phase transitions in their parameter space. The pervasiveness of criticality
suggests that there may be general principles inducing this behaviour, yet
there is no well-founded theory for understanding how criticality is generated
at a wide span of levels and contexts. In order to explore how criticality
might emerge from general adaptive mechanisms, we propose a simple learning
rule that maintains an internal organizational structure from a specific family
of systems at criticality. We implement the mechanism in artificial embodied
agents controlled by a neural network maintaining a correlation structure
randomly sampled from an Ising model at critical temperature. Agents are
evaluated in two classical reinforcement learning scenarios: the Mountain Car
and the Acrobot double pendulum. In both cases the neural controller appears to
reach a point of criticality, which coincides with a transition point between
two regimes of the agent&apos;s behaviour. These results suggest that adaptation to
criticality could be used as a general adaptive mechanism in some
circumstances, providing an alternative explanation for the pervasive presence
of criticality in biological and cognitive systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/nlin/1/au:+Aguilera_M/0/1/0/all/0/1&quot;&gt;Miguel Aguilera&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/nlin/1/au:+Bedia_M/0/1/0/all/0/1&quot;&gt;Manuel G. Bedia&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00047">
<title>Following High-level Navigation Instructions on a Simulated Quadcopter with Imitation Learning. (arXiv:1806.00047v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1806.00047</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce a method for following high-level navigation instructions by
mapping directly from images, instructions and pose estimates to continuous
low-level velocity commands for real-time control. The Grounded Semantic
Mapping Network (GSMN) is a fully-differentiable neural network architecture
that builds an explicit semantic map in the world reference frame by
incorporating a pinhole camera projection model within the network. The
information stored in the map is learned from experience, while the
local-to-world transformation is computed explicitly. We train the model using
DAggerFM, a modified variant of DAgger that trades tabular convergence
guarantees for improved training speed and memory use. We test GSMN in virtual
environments on a realistic quadcopter simulator and show that incorporating an
explicit mapping and grounding modules allows GSMN to outperform strong neural
baselines and almost reach an expert policy performance. Finally, we analyze
the learned map representations and show that using an explicit map leads to an
interpretable instruction-following model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Blukis_V/0/1/0/all/0/1&quot;&gt;Valts Blukis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brukhim_N/0/1/0/all/0/1&quot;&gt;Nataly Brukhim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bennett_A/0/1/0/all/0/1&quot;&gt;Andrew Bennett&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Knepper_R/0/1/0/all/0/1&quot;&gt;Ross A. Knepper&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Artzi_Y/0/1/0/all/0/1&quot;&gt;Yoav Artzi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00054">
<title>Defending Against Model Stealing Attacks Using Deceptive Perturbations. (arXiv:1806.00054v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.00054</link>
<description rdf:parseType="Literal">&lt;p&gt;Machine learning models are vulnerable to simple model stealing attacks if
the adversary can obtain output labels for chosen inputs. To protect against
these attacks, it has been proposed to limit the information provided to the
adversary by omitting probability scores, significantly impacting the utility
of the provided service. In this work, we illustrate how a service provider can
still provide useful, albeit misleading, class probability information, while
significantly limiting the success of the attack. Our defense forces the
adversary to discard the class probabilities, requiring significantly more
queries before they can train a model with comparable performance. We evaluate
several attack strategies, model architectures, and hyperparameters under
varying adversarial models, and evaluate the efficacy of our defense against
the strongest adversary. Finally, we quantify the amount of noise injected into
the class probabilities to mesure the loss in utility, e.g., adding 1.74 nats
per query on CIFAR-10 and 3.27 on MNIST. Our extensive evaluation shows our
defense can degrade the accuracy of the stolen model at least 20%, or require
4x more queries while keeping the accuracy of the protected model almost
intact.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_T/0/1/0/all/0/1&quot;&gt;Taesung Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Edwards_B/0/1/0/all/0/1&quot;&gt;Benjamin Edwards&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Molloy_I/0/1/0/all/0/1&quot;&gt;Ian Molloy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Su_D/0/1/0/all/0/1&quot;&gt;Dong Su&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00064">
<title>Efficient Low-rank Multimodal Fusion with Modality-Specific Factors. (arXiv:1806.00064v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1806.00064</link>
<description rdf:parseType="Literal">&lt;p&gt;Multimodal research is an emerging field of artificial intelligence, and one
of the main research problems in this field is multimodal fusion. The fusion of
multimodal data is the process of integrating multiple unimodal representations
into one compact multimodal representation. Previous research in this field has
exploited the expressiveness of tensors for multimodal representation. However,
these methods often suffer from exponential increase in dimensions and in
computational complexity introduced by transformation of input into tensor. In
this paper, we propose the Low-rank Multimodal Fusion method, which performs
multimodal fusion using low-rank tensors to improve efficiency. We evaluate our
model on three different tasks: multimodal sentiment analysis, speaker trait
analysis, and emotion recognition. Our model achieves competitive results on
all these tasks while drastically reducing computational complexity. Additional
experiments also show that our model can perform robustly for a wide range of
low-rank settings, and is indeed much more efficient in both training and
inference compared to other methods that utilize tensor representations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1&quot;&gt;Zhun Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_Y/0/1/0/all/0/1&quot;&gt;Ying Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lakshminarasimhan_V/0/1/0/all/0/1&quot;&gt;Varun Bharadhwaj Lakshminarasimhan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_P/0/1/0/all/0/1&quot;&gt;Paul Pu Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zadeh_A/0/1/0/all/0/1&quot;&gt;Amir Zadeh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Morency_L/0/1/0/all/0/1&quot;&gt;Louis-Philippe Morency&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00069">
<title>Explaining Explanations: An Approach to Evaluating Interpretability of Machine Learning. (arXiv:1806.00069v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1806.00069</link>
<description rdf:parseType="Literal">&lt;p&gt;There has recently been a surge of work in explanatory artificial
intelligence (XAI). This research area tackles the important problem that
complex machines and algorithms often cannot provide insights into their
behavior and thought processes. XAI allows users and parts of the internal
system to be more transparent, providing explanations of their decisions in
some level of detail. These explanations are important to ensure algorithmic
fairness, identify potential bias/problems in the training data, and to ensure
that the algorithms perform as expected. However, explanations produced by
these systems is neither standardized nor systematically assessed. In an effort
to create best practices and identify open challenges, we provide our
definition of explainability and show how it can be used to classify existing
literature. We discuss why current approaches to explanatory methods especially
for deep neural networks are insufficient. Finally, based on our survey, we
conclude with suggested future research directions for explanatory artificial
intelligence.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gilpin_L/0/1/0/all/0/1&quot;&gt;Leilani H. Gilpin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bau_D/0/1/0/all/0/1&quot;&gt;David Bau&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yuan_B/0/1/0/all/0/1&quot;&gt;Ben Z. Yuan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bajwa_A/0/1/0/all/0/1&quot;&gt;Ayesha Bajwa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Specter_M/0/1/0/all/0/1&quot;&gt;Michael Specter&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kagal_L/0/1/0/all/0/1&quot;&gt;Lalana Kagal&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00119">
<title>Technical Report: Inconsistency in Answer Set Programs and Extensions. (arXiv:1806.00119v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1806.00119</link>
<description rdf:parseType="Literal">&lt;p&gt;Answer Set Programming (ASP) is a well-known problem solving approach based
on nonmonotonic logic programs. HEX-programs extend ASP with external atoms for
accessing arbitrary external information, which can introduce values that do
not appear in the input program. In this work we consider inconsistent ASP- and
HEX-programs, i.e., programs without answer sets. We study characterizations of
inconsistency, introduce a novel notion for explaining inconsistencies in terms
of input facts, analyze the complexity of reasoning tasks in context of
inconsistency analysis, and present techniques for computing inconsistency
reasons. This theoretical work is motivated by two concrete applications, which
we also present. The first one is the new modeling technique of query answering
over subprograms as a convenient alternative to the well-known saturation
technique. The second application is a new evaluation algorithm for
HEX-programs based on conflict-driven learning for programs with multiple
components: while for certain program classes previous techniques suffer an
evaluation bottleneck, the new approach shows significant, potentially
exponential speedup in our experiments. Since well-known ASP extensions such as
constraint ASP and DL-programs correspond to special cases of HEX, all
presented results are interesting beyond the specific formalism.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Redl_C/0/1/0/all/0/1&quot;&gt;Christoph Redl&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00143">
<title>Modeling Preemptive Behaviors for Uncommon Hazardous Situations From Demonstrations. (arXiv:1806.00143v1 [cs.RO])</title>
<link>http://arxiv.org/abs/1806.00143</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents a learning from demonstration approach to programming
safe, autonomous behaviors for uncommon driving scenarios. Simulation is used
to re-create a targeted driving situation, one containing a road-side hazard
creating a significant occlusion in an urban neighborhood, and collect optimal
driving behaviors from 24 users. Paper employs a key-frame based approach
combined with an algorithm to linearly combine models in order to extend the
behavior to novel variations of the target situation. This approach is
theoretically agnostic to the kind of LfD framework used for modeling data and
our results suggest it generalizes well to variations containing an additional
number of hazards occurring in sequence. The linear combination algorithm is
informed by analysis of driving data, which also suggests that decision-making
algorithms need to consider a trade-off between road-rules and immediate
rewards to tackle some complex cases.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Parashar_P/0/1/0/all/0/1&quot;&gt;Priyam Parashar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cosgun_A/0/1/0/all/0/1&quot;&gt;Akansel Cosgun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nakhaei_A/0/1/0/all/0/1&quot;&gt;Alireza Nakhaei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fujimura_K/0/1/0/all/0/1&quot;&gt;Kikuo Fujimura&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00153">
<title>k-Space Deep Learning for Reference-free EPI Ghost Correction. (arXiv:1806.00153v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1806.00153</link>
<description rdf:parseType="Literal">&lt;p&gt;Nyquist ghost artifacts in EPI images are originated from phase mismatch
between the even and odd echoes. However, conventional correction methods using
reference scans often produce erroneous results especially in high-field MRI
due to the non-linear and time-varying local magnetic field changes. It has
been shown that the problem of ghost correction can be transformed into k-space
data interpolation problem that can be solved using the annihilating
filter-based low-rank Hankel structured matrix completion approach (ALOHA).
Another recent discovery has shown that the deep convolutional neural network
is closely related to the data-driven Hankel matrix decomposition. By
synergistically combining these findings, here we propose a k-space deep
learning approach that immediately corrects the k- space phase mismatch without
a reference scan. Reconstruction results using 7T in vivo data showed that the
proposed reference-free k-space deep learning approach for EPI ghost correction
significantly improves the image quality compared to the existing methods and
the computing time is several orders of magnitude faster.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1&quot;&gt;Juyoung Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Han_Y/0/1/0/all/0/1&quot;&gt;Yoseob Han&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1&quot;&gt;Jong Chul Ye&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00352">
<title>Too Fast Causal Inference under Causal Insufficiency. (arXiv:1806.00352v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1806.00352</link>
<description rdf:parseType="Literal">&lt;p&gt;Causally insufficient structures (models with latent or hidden variables, or
with confounding etc.) of joint probability distributions have been subject of
intense study not only in statistics, but also in various AI systems. In AI,
belief networks, being representations of joint probability distribution with
an underlying directed acyclic graph structure, are paid special attention due
to the fact that efficient reasoning (uncertainty propagation) methods have
been developed for belief network structures. Algorithms have been therefore
developed to acquire the belief network structure from data. As artifacts due
to variable hiding negatively influence the performance of derived belief
networks, models with latent variables have been studied and several algorithms
for learning belief network structure under causal insufficiency have also been
developed.
&lt;/p&gt;
&lt;p&gt;Regrettably, some of them are known already to be erroneous (e.g. IC
algorithm of [Pearl:Verma:91]. This paper is devoted to another algorithm, the
Fast Causal Inference (FCI) Algorithm of [Spirtes:93]. It is proven by a
specially constructed example that this algorithm, as it stands in
[Spirtes:93], is also erroneous. Fundamental reason for failure of this
algorithm is the temporary introduction of non-real links between nodes of the
network with the intention of later removal. While for trivial dependency
structures these non-real links may be actually removed, this may not be the
case for complex ones, e.g. for the case described in this paper. A remedy of
this failure is proposed.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Klopotek_M/0/1/0/all/0/1&quot;&gt;Mieczys&amp;#x142;aw A. K&amp;#x142;opotek&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00358">
<title>A Systematic Classification of Knowledge, Reasoning, and Context within the ARC Dataset. (arXiv:1806.00358v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1806.00358</link>
<description rdf:parseType="Literal">&lt;p&gt;The recent work of Clark et al. introduces the AI2 Reasoning Challenge (ARC)
and the associated ARC dataset that partitions open domain, complex science
questions into an Easy Set and a Challenge Set. That paper includes an analysis
of 100 questions with respect to the types of knowledge and reasoning required
to answer them; however, it does not include clear definitions of these types,
nor does it offer information about the quality of the labels. We propose a
comprehensive set of definitions of knowledge and reasoning types necessary for
answering the questions in the ARC dataset. Using ten annotators and a
sophisticated annotation interface, we analyze the distribution of labels
across the Challenge Set and statistics related to them. Additionally, we
demonstrate that although naive information retrieval methods return sentences
that are irrelevant to answering the query, sufficient supporting text is often
present in the (ARC) corpus. Evaluating with human-selected relevant sentences
improves the performance of a neural machine comprehension model by 42 points.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Boratko_M/0/1/0/all/0/1&quot;&gt;Michael Boratko&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Padigela_H/0/1/0/all/0/1&quot;&gt;Harshit Padigela&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mikkilineni_D/0/1/0/all/0/1&quot;&gt;Divyendra Mikkilineni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yuvraj_P/0/1/0/all/0/1&quot;&gt;Pritish Yuvraj&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Das_R/0/1/0/all/0/1&quot;&gt;Rajarshi Das&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+McCallum_A/0/1/0/all/0/1&quot;&gt;Andrew McCallum&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chang_M/0/1/0/all/0/1&quot;&gt;Maria Chang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fokoue_Nkoutche_A/0/1/0/all/0/1&quot;&gt;Achille Fokoue-Nkoutche&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kapanipathi_P/0/1/0/all/0/1&quot;&gt;Pavan Kapanipathi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mattei_N/0/1/0/all/0/1&quot;&gt;Nicholas Mattei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Musa_R/0/1/0/all/0/1&quot;&gt;Ryan Musa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Talamadupula_K/0/1/0/all/0/1&quot;&gt;Kartik Talamadupula&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Witbrock_M/0/1/0/all/0/1&quot;&gt;Michael Witbrock&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09904">
<title>Ab initio Algorithmic Causal Deconvolution of Intertwined Programs and Networks by Generative Mechanism. (arXiv:1802.09904v5 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1802.09904</link>
<description rdf:parseType="Literal">&lt;p&gt;Complex data is usually produced by interacting sources with different
mechanisms. Here we introduce a parameter-free model-based approach, based upon
the seminal concept of Algorithmic Probability, that decomposes an observation
and signal into its most likely algorithmic generative sources. Our methods use
a causal calculus to infer model representations. We demonstrate the method
ability to distinguish interacting mechanisms and deconvolve them, regardless
of whether the objects produce strings, space-time evolution diagrams, images
or networks. We numerically test and evaluate our causal separation methods and
find that it can disentangle examples of observations from discrete dynamical
systems, and complex networks. We think that these causal separating techniques
can contribute to tackle the challenge of causation for estimations of better
rooted probability distributions thereby complementing more limited
statistical-oriented techniques that otherwise would lack model inference
capabilities.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zenil_H/0/1/0/all/0/1&quot;&gt;Hector Zenil&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kiani_N/0/1/0/all/0/1&quot;&gt;Narsis A. Kiani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zea_A/0/1/0/all/0/1&quot;&gt;Allan A. Zea&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tegner_J/0/1/0/all/0/1&quot;&gt;Jesper Tegn&amp;#xe9;r&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09197">
<title>ASR-based Features for Emotion Recognition: A Transfer Learning Approach. (arXiv:1805.09197v3 [eess.AS] UPDATED)</title>
<link>http://arxiv.org/abs/1805.09197</link>
<description rdf:parseType="Literal">&lt;p&gt;During the last decade, the applications of signal processing have
drastically improved with deep learning. However areas of affecting computing
such as emotional speech synthesis or emotion recognition from spoken language
remains challenging. In this paper, we investigate the use of a neural
Automatic Speech Recognition (ASR) as a feature extractor for emotion
recognition. We show that these features outperform the eGeMAPS feature set to
predict the valence and arousal emotional dimensions, which means that the
audio-to-text mapping learning by the ASR system contain information related to
the emotional dimensions in spontaneous speech. We also examine the
relationship between first layers (closer to speech) and last layers (closer to
text) of the ASR and valence/arousal.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Tits_N/0/1/0/all/0/1&quot;&gt;No&amp;#xe9; Tits&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Haddad_K/0/1/0/all/0/1&quot;&gt;Kevin El Haddad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Dutoit_T/0/1/0/all/0/1&quot;&gt;Thierry Dutoit&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1605.03035">
<title>Context-Aware Adaptive Framework for e-Health Monitoring. (arXiv:1605.03035v1 [cs.CY] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1605.03035</link>
<description rdf:parseType="Literal">&lt;p&gt;For improving e-health services, we propose a context-aware framework to
monitor the activities of daily living of dependent persons. We define a
strategy for generating long-term realistic scenarios and a framework
containing an adaptive monitoring algorithm based on three approaches for
optimizing resource usage. The used approaches provide a deep knowledge about
the person&apos;s context by considering: the person&apos;s profile, the activities and
the relationships between activities. We evaluate the performances of our
framework and show its adaptability and significant reduction in network,
energy and processing usage over a traditional monitoring implementation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mshali_H/0/1/0/all/0/1&quot;&gt;Haider Mshali&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lemlouma_T/0/1/0/all/0/1&quot;&gt;Tayeb Lemlouma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Magoni_D/0/1/0/all/0/1&quot;&gt;Damien Magoni&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00040">
<title>Efficient Algorithms and Lower Bounds for Robust Linear Regression. (arXiv:1806.00040v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.00040</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the problem of high-dimensional linear regression in a robust model
where an $\epsilon$-fraction of the samples can be adversarially corrupted. We
focus on the fundamental setting where the covariates of the uncorrupted
samples are drawn from a Gaussian distribution $\mathcal{N}(0, \Sigma)$ on
$\mathbb{R}^d$. We give nearly tight upper bounds and computational lower
bounds for this problem. Specifically, our main contributions are as follows:
&lt;/p&gt;
&lt;p&gt;For the case that the covariance matrix is known to be the identity, we give
a sample near-optimal and computationally efficient algorithm that outputs a
candidate hypothesis vector $\widehat{\beta}$ which approximates the unknown
regression vector $\beta$ within $\ell_2$-norm $O(\epsilon \log(1/\epsilon)
\sigma)$, where $\sigma$ is the standard deviation of the random observation
noise. An error of $\Omega (\epsilon \sigma)$ is information-theoretically
necessary, even with infinite sample size. Prior work gave an algorithm for
this problem with sample complexity $\tilde{\Omega}(d^2/\epsilon^2)$ whose
error guarantee scales with the $\ell_2$-norm of $\beta$.
&lt;/p&gt;
&lt;p&gt;For the case of unknown covariance, we show that we can efficiently achieve
the same error guarantee as in the known covariance case using an additional
$\tilde{O}(d^2/\epsilon^2)$ unlabeled examples. On the other hand, an error of
$O(\epsilon \sigma)$ can be information-theoretically attained with
$O(d/\epsilon^2)$ samples. We prove a Statistical Query (SQ) lower bound
providing evidence that this quadratic tradeoff in the sample size is inherent.
More specifically, we show that any polynomial time SQ learning algorithm for
robust linear regression (in Huber&apos;s contamination model) with estimation
complexity $O(d^{2-c})$, where $c&amp;gt;0$ is an arbitrarily small constant, must
incur an error of $\Omega(\sqrt{\epsilon} \sigma)$.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Diakonikolas_I/0/1/0/all/0/1&quot;&gt;Ilias Diakonikolas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kong_W/0/1/0/all/0/1&quot;&gt;Weihao Kong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stewart_A/0/1/0/all/0/1&quot;&gt;Alistair Stewart&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00125">
<title>On Curvature-aided Incremental Aggregated Gradient Methods. (arXiv:1806.00125v1 [math.OC])</title>
<link>http://arxiv.org/abs/1806.00125</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper studies an acceleration technique for incremental aggregated
gradient methods which exploits curvature information for solving strongly
convex finite sum optimization problems. These optimization problems of
interest arise in large-scale learning applications relevant to machine
learning systems. The proposed methods utilizes a novel curvature-aided
gradient tracking technique to produce gradient estimates using the aids of
Hessian information during computation. We propose and analyze two
curvature-aided methods --- the first method, called curvature-aided
incremental aggregated gradient (CIAG) method, can be developed from the
standard gradient method and it computes an $\epsilon$-optimal solution using
${\cal O}( \kappa \log ( 1 / \epsilon ) )$ iterations for a small $\epsilon$;
the second method, called accelerated CIAG (A-CIAG) method, incorporates
Nesterov&apos;s acceleration into CIAG and requires ${\cal O}( \sqrt{\kappa} \log (
1 / \epsilon ) )$ iterations for a small $\epsilon$, where $\kappa$ is the
problem&apos;s condition number. Importantly, the asymptotic convergence rates above
are the same as those of the full gradient and accelerated full gradient
methods, respectively, and they are independent of the number of component
functions involved. The proposed methods are significantly faster than the
state-of-the-art methods, especially for large-scale problems with a massive
amount of data.
&lt;/p&gt;
&lt;p&gt;The source codes are available at https://github.com/hoitowai/ciag/
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Wai_H/0/1/0/all/0/1&quot;&gt;Hoi-To Wai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Shi_W/0/1/0/all/0/1&quot;&gt;Wei Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Uribe_C/0/1/0/all/0/1&quot;&gt;Cesar A. Uribe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Nedich_A/0/1/0/all/0/1&quot;&gt;Angelia Nedich&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Scaglione_A/0/1/0/all/0/1&quot;&gt;Anna Scaglione&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00144">
<title>Sea surface temperature prediction and reconstruction using patch-level neural network representations. (arXiv:1806.00144v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.00144</link>
<description rdf:parseType="Literal">&lt;p&gt;The forecasting and reconstruction of ocean and atmosphere dynamics from
satellite observation time series are key challenges. While model-driven
representations remain the classic approaches, data-driven representations
become more and more appealing to benefit from available large-scale
observation and simulation datasets. In this work we investigate the relevance
of recently introduced bilinear residual neural network representations, which
mimic numerical integration schemes such as Runge-Kutta, for the forecasting
and assimilation of geophysical fields from satellite-derived remote sensing
data. As a case-study, we consider satellite-derived Sea Surface Temperature
time series off South Africa, which involves intense and complex upper ocean
dynamics. Our numerical experiments demonstrate that the proposed patch-level
neural-network-based representations outperform other data-driven models,
including analog schemes, both in terms of forecasting and missing data
interpolation performance with a relative gain up to 50\% for highly dynamic
areas.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ouala_S/0/1/0/all/0/1&quot;&gt;Said Ouala&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Herzet_C/0/1/0/all/0/1&quot;&gt;Cedric Herzet&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Fablet_R/0/1/0/all/0/1&quot;&gt;Ronan Fablet&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00159">
<title>Neural Control Variates for Variance Reduction. (arXiv:1806.00159v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.00159</link>
<description rdf:parseType="Literal">&lt;p&gt;In statistics and machine learning, approximation of an intractable
integration is often achieved by using the unbiased Monte Carlo estimator, but
the variances of the estimation are generally high in many applications.
Control variates approaches are well-known to reduce the variance of the
estimation. These control variates are typically constructed by employing
predefined parametric functions or polynomials, determined by using those
samples drawn from the relevant distributions. Instead, we propose to construct
those control variates by learning neural networks to handle the cases when
test functions are complex. In many applications, obtaining a large number of
samples for Monte Carlo estimation is expensive, which may result in
overfitting when training a neural network. We thus further propose to employ
auxiliary random variables induced by the original ones to extend data samples
for training the neural networks. We apply the proposed control variates with
augmented variables to thermodynamic integration and reinforcement learning.
Experimental results demonstrate that our method can achieve significant
variance reduction compared with other alternatives.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhu_Z/0/1/0/all/0/1&quot;&gt;Zhanxing Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wan_R/0/1/0/all/0/1&quot;&gt;Ruosi Wan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhong_M/0/1/0/all/0/1&quot;&gt;Mingjun Zhong&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00176">
<title>Reparameterization Gradient for Non-differentiable Models. (arXiv:1806.00176v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.00176</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a new algorithm for stochastic variational inference that targets
at models with non-differentiable densities. One of the key challenges in
stochastic variational inference is to come up with a low-variance estimator of
the gradient of a variational objective. We tackle the challenge by
generalizing the reparameterization trick, one of the most effective techniques
for addressing the variance issue for differentiable models, so that the trick
works for non-differentiable models as well. Our algorithm splits the space of
latent variables into regions where the density of the variables is
differentiable, and their boundaries where the density may fail to be
differentiable. For each differentiable region, the algorithm applies the
standard reparameterization trick and estimates the gradient restricted to the
region. For each potentially non-differentiable boundary, it uses a form of
manifold sampling and computes the direction for variational parameters that,
if followed, would increase the boundary&apos;s contribution to the variational
objective. The sum of all the estimates becomes the gradient estimate of our
algorithm. Our estimator enjoys the reduced variance of the reparameterization
gradient while remaining unbiased even for non-differentiable models. The
experiments with our preliminary implementation confirm the benefit of reduced
variance and unbiasedness.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_W/0/1/0/all/0/1&quot;&gt;Wonyeol Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1&quot;&gt;Hangyeol Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1&quot;&gt;Hongseok Yang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00265">
<title>Learn the new, keep the old: Extending pretrained models with new anatomy and images. (arXiv:1806.00265v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1806.00265</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep learning has been widely accepted as a promising solution for medical
image segmentation, given a sufficiently large representative dataset of images
with corresponding annotations. With ever increasing amounts of annotated
medical datasets, it is infeasible to train a learning method always with all
data from scratch. This is also doomed to hit computational limits, e.g.,
memory or runtime feasible for training. Incremental learning can be a
potential solution, where new information (images or anatomy) is introduced
iteratively. Nevertheless, for the preservation of the collective information,
it is essential to keep some &quot;important&quot; (i.e. representative) images and
annotations from the past, while adding new information. In this paper, we
introduce a framework for applying incremental learning for segmentation and
propose novel methods for selecting representative data therein. We
comparatively evaluate our methods in different scenarios using MR images and
validate the increased learning capacity with using our methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ozdemir_F/0/1/0/all/0/1&quot;&gt;Firat Ozdemir&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fuernstahl_P/0/1/0/all/0/1&quot;&gt;Philipp Fuernstahl&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goksel_O/0/1/0/all/0/1&quot;&gt;Orcun Goksel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00271">
<title>Learning Neural Random Fields with Inclusive Auxiliary Generators. (arXiv:1806.00271v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.00271</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper we develop Neural Random Field learning with
Inclusive-divergence minimized Auxiliary Generators (NRF-IAG), which is
under-appreciated in the literature. The contributions are two-fold. First, we
rigorously apply the stochastic approximation algorithm to solve the joint
optimization and provide theoretical justification. The new approach of
learning NRF-IAG achieves superior unsupervised learning performance
competitive with state-of-the-art deep generative models (DGMs) in terms of
sample generation quality. Second, semi-supervised learning (SSL) with NRF-IAG
gives rise to strong classification results comparable to state-of-art
DGM-based SSL methods, and simultaneously achieves superior generation. This is
in contrast to the conflict of good classification and good generation, as
observed in GAN-based SSL.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Song_Y/0/1/0/all/0/1&quot;&gt;Yunfu Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ou_Z/0/1/0/all/0/1&quot;&gt;Zhijian Ou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00319">
<title>Learning convex bounds for linear quadratic control policy synthesis. (arXiv:1806.00319v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.00319</link>
<description rdf:parseType="Literal">&lt;p&gt;Learning to make decisions from observed data in dynamic environments remains
a problem of fundamental importance in a number of fields, from artificial
intelligence and robotics, to medicine and finance. This paper concerns the
problem of learning control policies for unknown linear dynamical systems so as
to maximize a quadratic reward function. We present a method to optimize the
expected value of the reward over the posterior distribution of the unknown
system parameters, given data. The algorithm involves sequential convex
programing, and enjoys reliable local convergence and robust stability
guarantees. Numerical simulations and stabilization of a real-world inverted
pendulum are used to demonstrate the approach, with strong performance and
robustness properties observed in both.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Umenberger_J/0/1/0/all/0/1&quot;&gt;Jack Umenberger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Schon_T/0/1/0/all/0/1&quot;&gt;Thomas B. Sch&amp;#xf6;n&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00336">
<title>A Reinforcement Learning Approach to Age of Information in Multi-User Networks. (arXiv:1806.00336v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.00336</link>
<description rdf:parseType="Literal">&lt;p&gt;Scheduling the transmission of time-sensitive data to multiple users over
error-prone communication channels is studied with the goal of minimizing the
long-term average age of information (AoI) at the users under a constraint on
the average number of transmissions at the source node. After each
transmission, the source receives an instantaneous ACK/NACK feedback from the
intended receiver and decides on what time and to which user to transmit the
next update. The optimal scheduling policy is first studied under different
feedback mechanisms when the channel statistics are known; in particular, the
standard automatic repeat request (ARQ) and hybrid ARQ (HARQ) protocols are
considered. Then a reinforcement learning (RL) approach is introduced, which
does not assume any a priori information on the random processes governing the
channel states. Different RL methods are verified and compared through
numerical simulations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ceran_E/0/1/0/all/0/1&quot;&gt;Elif Tu&amp;#x11f;&amp;#xe7;e Ceran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gunduz_D/0/1/0/all/0/1&quot;&gt;Deniz G&amp;#xfc;nd&amp;#xfc;z&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gyorgy_A/0/1/0/all/0/1&quot;&gt;Andr&amp;#xe1;s Gy&amp;#xf6;rgy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00370">
<title>Nonlinear Acceleration of CNNs. (arXiv:1806.00370v1 [math.OC])</title>
<link>http://arxiv.org/abs/1806.00370</link>
<description rdf:parseType="Literal">&lt;p&gt;The Regularized Nonlinear Acceleration (RNA) algorithm is an acceleration
method capable of improving the rate of convergence of many optimization
schemes such as gradient descend, SAGA or SVRG. Until now, its analysis is
limited to convex problems, but empirical observations shows that RNA may be
extended to wider settings. In this paper, we investigate further the benefits
of RNA when applied to neural networks, in particular for the task of image
recognition on CIFAR10 and ImageNet. With very few modifications of exiting
frameworks, RNA improves slightly the optimization process of CNNs, after
training.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Scieur_D/0/1/0/all/0/1&quot;&gt;Damien Scieur&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Oyallon_E/0/1/0/all/0/1&quot;&gt;Edouard Oyallon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+dAspremont_A/0/1/0/all/0/1&quot;&gt;Alexandre d&amp;#x27;Aspremont&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Bach_F/0/1/0/all/0/1&quot;&gt;Francis Bach&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00413">
<title>Global linear convergence of Newton&apos;s method without strong-convexity or Lipschitz gradients. (arXiv:1806.00413v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.00413</link>
<description rdf:parseType="Literal">&lt;p&gt;We show that Newton&apos;s method converges globally at a linear rate for
objective functions whose Hessians are stable. This class of problems includes
many functions which are not strongly convex, such as logistic regression. Our
linear convergence result is (i) affine-invariant, and holds even if an (ii)
approximate Hessian is used, and if the subproblems are (iii) only solved
approximately. Thus we theoretically demonstrate the superiority of Newton&apos;s
method over first-order methods, which would only achieve a sublinear
$O(1/t^2)$ rate under similar conditions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Karimireddy_S/0/1/0/all/0/1&quot;&gt;Sai Praneeth Karimireddy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stich_S/0/1/0/all/0/1&quot;&gt;Sebastian U. Stich&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jaggi_M/0/1/0/all/0/1&quot;&gt;Martin Jaggi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00416">
<title>Pattern Search MDS. (arXiv:1806.00416v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.00416</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a novel view of nonlinear manifold learning using derivative-free
optimization techniques. Specifically, we propose an extension of the classical
multi-dimensional scaling (MDS) method, where instead of performing gradient
descent, we sample and evaluate possible &quot;moves&quot; in a sphere of fixed radius
for each point in the embedded space. A fixed-point convergence guarantee can
be shown by formulating the proposed algorithm as an instance of General
Pattern Search (GPS) framework. Evaluation on both clean and noisy synthetic
datasets shows that pattern search MDS can accurately infer the intrinsic
geometry of manifolds embedded in high-dimensional spaces. Additionally,
experiments on real data, even under noisy conditions, demonstrate that the
proposed pattern search MDS yields state-of-the-art results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Paraskevopoulos_G/0/1/0/all/0/1&quot;&gt;Georgios Paraskevopoulos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tzinis_E/0/1/0/all/0/1&quot;&gt;Efthymios Tzinis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vlatakis_Gkaragkounis_E/0/1/0/all/0/1&quot;&gt;Emmanuel-Vasileios Vlatakis-Gkaragkounis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Potamianos_A/0/1/0/all/0/1&quot;&gt;Alexandros Potamianos&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00437">
<title>Large-Margin Classification in Hyperbolic Space. (arXiv:1806.00437v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.00437</link>
<description rdf:parseType="Literal">&lt;p&gt;Representing data in hyperbolic space can effectively capture latent
hierarchical relationships. With the goal of enabling accurate classification
of points in hyperbolic space while respecting their hyperbolic geometry, we
introduce hyperbolic SVM, a hyperbolic formulation of support vector machine
classifiers, and elucidate through new theoretical work its connection to the
Euclidean counterpart. We demonstrate the performance improvement of hyperbolic
SVM for multi-class prediction tasks on real-world complex networks as well as
simulated datasets. Our work allows analytic pipelines that take the inherent
hyperbolic geometry of the data into account in an end-to-end fashion without
resorting to ill-fitting tools developed for Euclidean space.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cho_H/0/1/0/all/0/1&quot;&gt;Hyunghoon Cho&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+DeMeo_B/0/1/0/all/0/1&quot;&gt;Benjamin DeMeo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peng_J/0/1/0/all/0/1&quot;&gt;Jian Peng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Berger_B/0/1/0/all/0/1&quot;&gt;Bonnie Berger&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00451">
<title>Do CIFAR-10 Classifiers Generalize to CIFAR-10?. (arXiv:1806.00451v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.00451</link>
<description rdf:parseType="Literal">&lt;p&gt;Machine learning is currently dominated by largely experimental work focused
on improvements in a few key tasks. However, the impressive accuracy numbers of
the best performing models are questionable because the same test sets have
been used to select these models for multiple years now. To understand the
danger of overfitting, we measure the accuracy of CIFAR-10 classifiers by
creating a new test set of truly unseen images. Although we ensure that the new
test set is as close to the original data distribution as possible, we find a
large drop in accuracy (4% to 10%) for a broad range of deep learning models.
Yet more recent models with higher original accuracy show a smaller drop and
better overall performance, indicating that this drop is likely not due to
overfitting based on adaptivity. Instead, we view our results as evidence that
current accuracy numbers are brittle and susceptible to even minute natural
variations in the data distribution.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Recht_B/0/1/0/all/0/1&quot;&gt;Benjamin Recht&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roelofs_R/0/1/0/all/0/1&quot;&gt;Rebecca Roelofs&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schmidt_L/0/1/0/all/0/1&quot;&gt;Ludwig Schmidt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shankar_V/0/1/0/all/0/1&quot;&gt;Vaishaal Shankar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1612.04899">
<title>Semi-Supervised Phone Classification using Deep Neural Networks and Stochastic Graph-Based Entropic Regularization. (arXiv:1612.04899v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1612.04899</link>
<description rdf:parseType="Literal">&lt;p&gt;We describe a graph-based semi-supervised learning framework in the context
of deep neural networks that uses a graph-based entropic regularizer to favor
smooth solutions over a graph induced by the data. The main contribution of
this work is a computationally efficient, stochastic graph-regularization
technique that uses mini-batches that are consistent with the graph structure,
but also provides enough stochasticity (in terms of mini-batch data diversity)
for convergence of stochastic gradient descent methods to good solutions. For
this work, we focus on results of frame-level phone classification accuracy on
the TIMIT speech corpus but our method is general and scalable to much larger
data sets. Results indicate that our method significantly improves
classification accuracy compared to the fully-supervised case when the fraction
of labeled data is low, and it is competitive with other methods in the fully
labeled case.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Thulasidasan_S/0/1/0/all/0/1&quot;&gt;Sunil Thulasidasan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bilmes_J/0/1/0/all/0/1&quot;&gt;Jeffrey Bilmes&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1702.08134">
<title>Dropping Convexity for More Efficient and Scalable Online Multiview Learning. (arXiv:1702.08134v8 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1702.08134</link>
<description rdf:parseType="Literal">&lt;p&gt;Multiview representation learning is very popular for latent factor analysis.
It naturally arises in many data analysis, machine learning, and information
retrieval applications to model dependent structures among multiple data
sources. For computational convenience, existing approaches usually formulate
the multiview representation learning as convex optimization problems, where
global optima can be obtained by certain algorithms in polynomial time.
However, many pieces of evidence have corroborated that heuristic nonconvex
approaches also have good empirical computational performance and convergence
to the global optima, although there is a lack of theoretical justification.
Such a gap between theory and practice motivates us to study a nonconvex
formulation for multiview representation learning, which can be efficiently
solved by a simple stochastic gradient descent (SGD) algorithm. We first
illustrate the geometry of the nonconvex formulation; Then, we establish
asymptotic global rates of convergence to the global optima by diffusion
approximations. Numerical experiments are provided to support our theory.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1&quot;&gt;Zhehui Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1&quot;&gt;Lin F. Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1&quot;&gt;Chris J. Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_T/0/1/0/all/0/1&quot;&gt;Tuo Zhao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1703.09165">
<title>PWLS-ULTRA: An Efficient Clustering and Learning-Based Approach for Low-Dose 3D CT Image Reconstruction. (arXiv:1703.09165v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1703.09165</link>
<description rdf:parseType="Literal">&lt;p&gt;The development of computed tomography (CT) image reconstruction methods that
significantly reduce patient radiation exposure while maintaining high image
quality is an important area of research in low-dose CT (LDCT) imaging. We
propose a new penalized weighted least squares (PWLS) reconstruction method
that exploits regularization based on an efficient Union of Learned TRAnsforms
(PWLS-ULTRA). The union of square transforms is pre-learned from numerous image
patches extracted from a dataset of CT images or volumes. The proposed
PWLS-based cost function is optimized by alternating between a CT image
reconstruction step, and a sparse coding and clustering step. The CT image
reconstruction step is accelerated by a relaxed linearized augmented Lagrangian
method with ordered-subsets that reduces the number of forward and back
projections. Simulations with 2-D and 3-D axial CT scans of the extended
cardiac-torso phantom and 3D helical chest and abdomen scans show that for both
normal-dose and low-dose levels, the proposed method significantly improves the
quality of reconstructed images compared to PWLS reconstruction with a
nonadaptive edge-preserving regularizer (PWLS-EP). PWLS with regularization
based on a union of learned transforms leads to better image reconstructions
than using a single learned square transform. We also incorporate patch-based
weights in PWLS-ULTRA that enhance image quality and help improve image
resolution uniformity. The proposed approach achieves comparable or better
image quality compared to learned overcomplete synthesis dictionaries, but
importantly, is much faster (computationally more efficient).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zheng_X/0/1/0/all/0/1&quot;&gt;Xuehang Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ravishankar_S/0/1/0/all/0/1&quot;&gt;Saiprasad Ravishankar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Long_Y/0/1/0/all/0/1&quot;&gt;Yong Long&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Fessler_J/0/1/0/all/0/1&quot;&gt;Jeffrey A. Fessler&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.06818">
<title>Recovering a Hidden Community in a Preferential Attachment Graph. (arXiv:1801.06818v4 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1801.06818</link>
<description rdf:parseType="Literal">&lt;p&gt;A message passing algorithm is derived for recovering a dense subgraph within
a graph generated by a variation of the Barab\&apos;{a}si-Albert preferential
attachment model. The estimator is assumed to know the arrival times, or order
of attachment, of the vertices. The derivation of the algorithm is based on
belief propagation under an independence assumption. Two precursors to the
message passing algorithm are analyzed: the first is a degree thresholding (DT)
algorithm and the second is an algorithm based on the arrival times of the
children (C) of a given vertex, where the children of a given vertex are the
vertices that attached to it. Algorithm C significantly outperforms DT, showing
it is beneficial to know the arrival times of the children, beyond simply
knowing the number of them. For fixed fraction of vertices in the community,
fixed number of new edges per arriving vertex, and fixed affinity between
vertices in the community, the probability of error for recovering the label of
a vertex is found as a function of the time of attachment, for either algorithm
DT or C, in the large graph limit. By averaging over the time of attachment,
the limit in probability of the fraction of label errors made over all vertices
is identified, for either of the algorithms DT or C. A message passing
algorithm is also described and simulation results are given for the problem of
recovering two symmetric communities in a graph.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hajek_B/0/1/0/all/0/1&quot;&gt;Bruce Hajek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sankagiri_S/0/1/0/all/0/1&quot;&gt;Suryanarayana Sankagiri&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08318">
<title>Proportional Volume Sampling and Approximation Algorithms for A-Optimal Design. (arXiv:1802.08318v3 [cs.DS] UPDATED)</title>
<link>http://arxiv.org/abs/1802.08318</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the $A$-optimal design problem where we are given vectors
$v_1,\ldots,v_n\in\mathbb{R}^d$, an integer $k\geq d$, and the goal is to
select a set $S$ of $k$ vectors that minimizes the trace of $(\sum_{i\in
S}v_iv_i^\top)^{-1}$. Traditionally, the problem is an instance of optimal
design of experiments in statistics where each vector corresponds to a linear
measurement of an unknown vector and the goal is to pick $k$ of them that
minimize the average variance of the error in the maximum likelihood estimate
of the vector being measured. The problem also finds applications in sensor
placement in wireless networks, sparse least squares regression, feature
selection for $k$-means clustering, and matrix approximation. In this paper, we
introduce proportional volume sampling to obtain improved approximation
algorithms for $A$-optimal design.
&lt;/p&gt;
&lt;p&gt;Given a matrix, proportional volume sampling picks a set of columns $S$ of
size $k$ with probability proportional to $\mu(S)$ times $\det(\sum_{i\in
S}v_iv_i^\top)$ for some measure $\mu$. Our main result is to show the
approximability of the $A$-optimal design problem can be reduced to approximate
independence properties of the measure $\mu$. We appeal to hard-core
distributions as candidate distributions $\mu$ that allow us to obtain improved
approximation algorithms for the $A$-optimal design. Our results include a
$d$-approximation when $k=d$, an $(1+\epsilon)$-approximation when
$k=\Omega\left(\frac{d}{\epsilon}+\frac{1}{\epsilon^2}\log\frac{1}{\epsilon}\right)$
and $\frac{k}{k-d+1}$-approximation when repetitions of vectors are allowed in
the solution. We consider generalization of the problem for $k\leq d$ and
obtain a $k$-approximation. The last result implies a restricted invertibility
principle for the harmonic mean of singular values. We also show that the
problem is $\mathsf{NP}$-hard to approximate within a fixed constant when
$k=d$.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nikolov_A/0/1/0/all/0/1&quot;&gt;Aleksandar Nikolov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singh_M/0/1/0/all/0/1&quot;&gt;Mohit Singh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tantipongpipat_U/0/1/0/all/0/1&quot;&gt;Uthaipon Tao Tantipongpipat&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.00606">
<title>On Oracle-Efficient PAC Reinforcement Learning with Rich Observations. (arXiv:1803.00606v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1803.00606</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the computational tractability of provably sample-efficient (PAC)
reinforcement learning in episodic environments with rich observations. We
present new sample-efficient algorithms for environments with deterministic
hidden state dynamics and stochastic rich observations. These methods operate
in an oracle model of computation -- accessing policy and value function
classes exclusively through standard optimization primitives -- and therefore
represent computationally efficient alternatives to prior algorithms that
require enumeration. In the more general stochastic transition setting, we
prove that the only known sample-efficient algorithm, Olive [1], cannot be
implemented in our oracle model. We also present several examples that
illustrate fundamental challenges of tractable PAC reinforcement learning in
such general settings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dann_C/0/1/0/all/0/1&quot;&gt;Christoph Dann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_N/0/1/0/all/0/1&quot;&gt;Nan Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Krishnamurthy_A/0/1/0/all/0/1&quot;&gt;Akshay Krishnamurthy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Agarwal_A/0/1/0/all/0/1&quot;&gt;Alekh Agarwal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Langford_J/0/1/0/all/0/1&quot;&gt;John Langford&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schapire_R/0/1/0/all/0/1&quot;&gt;Robert E. Schapire&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.07300">
<title>Risk and parameter convergence of logistic regression. (arXiv:1803.07300v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1803.07300</link>
<description rdf:parseType="Literal">&lt;p&gt;The logistic loss is strictly convex and does not attain its infimum;
consequently the solutions of logistic regression are in general off at
infinity. This work provides a convergence analysis of stochastic and batch
gradient descent for logistic regression. Firstly, under the assumption of
separability, stochastic gradient descent minimizes the population risk at rate
$\mathcal{O}(\ln(t)^2/t)$ with high probability. Secondly, with or without
separability, batch gradient descent minimizes the empirical risk at rate
$\mathcal{O}(\ln(t)^2/t)$. Furthermore, parameter convergence can be
characterized along a unique pair of complementary subspaces defined by the
problem instance: one subspace along which strong convexity induces parameters
to converge at rate $\mathcal{O}(\ln(t)^2/\sqrt{t})$, and its orthogonal
complement along which separability induces parameters to converge in direction
at rate $\mathcal{O}(\ln\ln(t) / \ln(t))$.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ji_Z/0/1/0/all/0/1&quot;&gt;Ziwei Ji&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Telgarsky_M/0/1/0/all/0/1&quot;&gt;Matus Telgarsky&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.00013">
<title>Constraining Effective Field Theories with Machine Learning. (arXiv:1805.00013v3 [hep-ph] UPDATED)</title>
<link>http://arxiv.org/abs/1805.00013</link>
<description rdf:parseType="Literal">&lt;p&gt;We present powerful new analysis techniques to constrain effective field
theories at the LHC. By leveraging the structure of particle physics processes,
we extract extra information from Monte-Carlo simulations, which can be used to
train neural network models that estimate the likelihood ratio. These methods
scale well to processes with many observables and theory parameters, do not
require any approximations of the parton shower or detector response, and can
be evaluated in microseconds. We show that they allow us to put significantly
stronger bounds on dimension-six operators than existing methods, demonstrating
their potential to improve the precision of the LHC legacy constraints.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/hep-ph/1/au:+Brehmer_J/0/1/0/all/0/1&quot;&gt;Johann Brehmer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/hep-ph/1/au:+Cranmer_K/0/1/0/all/0/1&quot;&gt;Kyle Cranmer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/hep-ph/1/au:+Louppe_G/0/1/0/all/0/1&quot;&gt;Gilles Louppe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/hep-ph/1/au:+Pavez_J/0/1/0/all/0/1&quot;&gt;Juan Pavez&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.00020">
<title>A Guide to Constraining Effective Field Theories with Machine Learning. (arXiv:1805.00020v3 [hep-ph] UPDATED)</title>
<link>http://arxiv.org/abs/1805.00020</link>
<description rdf:parseType="Literal">&lt;p&gt;We develop, discuss, and compare several inference techniques to constrain
theory parameters in collider experiments. By harnessing the latent-space
structure of particle physics processes, we extract extra information from the
simulator. This augmented data can be used to train neural networks that
precisely estimate the likelihood ratio. The new methods scale well to many
observables and high-dimensional parameter spaces, do not require any
approximations of the parton shower and detector response, and can be evaluated
in microseconds. Using weak-boson-fusion Higgs production as an example
process, we compare the performance of several techniques. The best results are
found for likelihood ratio estimators trained with extra information about the
score, the gradient of the log likelihood function with respect to the theory
parameters. The score also provides sufficient statistics that contain all the
information needed for inference in the neighborhood of the Standard Model.
These methods enable us to put significantly stronger bounds on effective
dimension-six operators than the traditional approach based on histograms. They
also outperform generic machine learning methods that do not make use of the
particle physics structure, demonstrating their potential to substantially
improve the new physics reach of the LHC legacy results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/hep-ph/1/au:+Brehmer_J/0/1/0/all/0/1&quot;&gt;Johann Brehmer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/hep-ph/1/au:+Cranmer_K/0/1/0/all/0/1&quot;&gt;Kyle Cranmer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/hep-ph/1/au:+Louppe_G/0/1/0/all/0/1&quot;&gt;Gilles Louppe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/hep-ph/1/au:+Pavez_J/0/1/0/all/0/1&quot;&gt;Juan Pavez&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.00063">
<title>Improved Image Captioning with Adversarial Semantic Alignment. (arXiv:1805.00063v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.00063</link>
<description rdf:parseType="Literal">&lt;p&gt;We study image captioning as a conditional GAN training, proposing both a
context-aware LSTM captioner and co-attentive discriminator, which enforces
semantic alignment between images and captions. We empirically study the
viability of two training methods: Self-critical Sequence Training (SCST) and
Gumbel Straight-Through (ST). We show that, surprisingly, SCST (a policy
gradient method) shows more stable gradient behavior and improved results over
Gumbel ST, even without accessing the discriminator gradients directly. We also
address the open question of automatic evaluation for these models and
introduce a new semantic score and demonstrate its strong correlation to human
judgement. As an evaluation paradigm, we suggest that an important criterion is
the ability of a captioner to generalize to compositions between objects that
do not usually occur together, for which we introduce a captioned Out of
Context (OOC) test set. The OOC dataset combined with our semantic score is a
new benchmark for the captioning community. Under this OOC benchmark, and the
traditional MSCOCO dataset, we show that SCST has a strong performance in both
semantic score and human evaluation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dognin_P/0/1/0/all/0/1&quot;&gt;Pierre L. Dognin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Melnyk_I/0/1/0/all/0/1&quot;&gt;Igor Melnyk&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mroueh_Y/0/1/0/all/0/1&quot;&gt;Youssef Mroueh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ross_J/0/1/0/all/0/1&quot;&gt;Jarret Ross&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sercu_T/0/1/0/all/0/1&quot;&gt;Tom Sercu&lt;/a&gt; (IBM Research, USA)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.02136">
<title>Private Sequential Learning. (arXiv:1805.02136v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.02136</link>
<description rdf:parseType="Literal">&lt;p&gt;We formulate a private learning model to study an intrinsic tradeoff between
privacy and query complexity in sequential learning. Our model involves a
learner who aims to determine a scalar value, $v^*$, by sequentially querying
an external database and receiving binary responses. In the meantime, an
adversary observes the learner&apos;s queries, though not the responses, and tries
to infer from them the value of $v^*$. The objective of the learner is to
obtain an accurate estimate of $v^*$ using only a small number of queries,
while simultaneously protecting her privacy by making $v^*$ provably difficult
to learn for the adversary. Our main results provide tight upper and lower
bounds on the learner&apos;s query complexity as a function of desired levels of
privacy and estimation accuracy. We also construct explicit query strategies
whose complexity is optimal up to an additive constant.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tsitsiklis_J/0/1/0/all/0/1&quot;&gt;John N. Tsitsiklis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_K/0/1/0/all/0/1&quot;&gt;Kuang Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1&quot;&gt;Zhi Xu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07808">
<title>Multi-layer Kernel Ridge Regression for One-class Classification. (arXiv:1805.07808v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.07808</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, a multi-layer architecture (in a hierarchical fashion) by
stacking various Kernel Ridge Regression (KRR) based Auto-Encoder for one-class
classification is proposed and is referred as MKOC. MKOC has many layers of
Auto-Encoders to project the input features into new feature space and the last
layer was regression based one class classifier. The Auto-Encoders use an
unsupervised approach of learning and the final layer uses semi-supervised
(trained by only positive samples) approach of learning. The proposed MKOC is
experimentally evaluated on 15 publicly available benchmark datasets.
Experimental results verify the effectiveness of the proposed approach over 11
existing state-of-the-art kernel-based one-class classifiers. Friedman test is
also performed to verify the statistical significance of the claim of the
superiority of the proposed one-class classifiers over the existing
state-of-the-art methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gautam_C/0/1/0/all/0/1&quot;&gt;Chandan Gautam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tiwari_A/0/1/0/all/0/1&quot;&gt;Aruna Tiwari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Suresh_S/0/1/0/all/0/1&quot;&gt;Sundaram Suresh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Iosifidis_A/0/1/0/all/0/1&quot;&gt;Alexandros Iosifidis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08114">
<title>On the Convergence of Stochastic Gradient Descent with Adaptive Stepsizes. (arXiv:1805.08114v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1805.08114</link>
<description rdf:parseType="Literal">&lt;p&gt;Stochastic gradient descent is the method of choice for large scale
optimization of machine learning objective functions. Yet, its performance is
greatly variable and heavily depends on the choice of the stepsizes. This has
motivated a large body of research on adaptive stepsizes. However, there is
currently a gap in our theoretical understanding of these methods, especially
in the non-convex setting. In this paper, we start closing this gap: we
theoretically analyze the use of adaptive stepsizes, like the ones in AdaGrad,
in the non-convex setting. We show sufficient conditions for almost sure
convergence to a stationary point when the adaptive stepsizes are used, proving
the first guarantee for AdaGrad in the non-convex setting. Moreover, we show
explicit rates of convergence that automatically interpolates between $O(1/T)$
and $O(1/\sqrt{T})$ depending on the noise of the stochastic gradients, in both
the convex and non-convex setting.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xiaoyu Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Orabona_F/0/1/0/all/0/1&quot;&gt;Francesco Orabona&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08498">
<title>Implicit Reparameterization Gradients. (arXiv:1805.08498v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.08498</link>
<description rdf:parseType="Literal">&lt;p&gt;By providing a simple and efficient way of computing low-variance gradients
of continuous random variables, the reparameterization trick has become the
technique of choice for training a variety of latent variable models. However,
it is not applicable to a number of important continuous distributions. We
introduce an alternative approach to computing reparameterization gradients
based on implicit differentiation and demonstrate its broader applicability by
applying it to Gamma, Beta, Dirichlet, and von Mises distributions, which
cannot be used with the classic reparameterization trick. Our experiments show
that the proposed approach is faster and more accurate than the existing
gradient estimators for these distributions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Figurnov_M/0/1/0/all/0/1&quot;&gt;Michael Figurnov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mohamed_S/0/1/0/all/0/1&quot;&gt;Shakir Mohamed&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mnih_A/0/1/0/all/0/1&quot;&gt;Andriy Mnih&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11686">
<title>Variational Inverse Control with Events: A General Framework for Data-Driven Reward Definition. (arXiv:1805.11686v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.11686</link>
<description rdf:parseType="Literal">&lt;p&gt;The design of a reward function often poses a major practical challenge to
real-world applications of reinforcement learning. Approaches such as inverse
reinforcement learning attempt to overcome this challenge, but require expert
demonstrations, which can be difficult or expensive to obtain in practice. We
propose variational inverse control with events (VICE), which generalizes
inverse reinforcement learning methods to cases where full demonstrations are
not needed, such as when only samples of desired goal states are available. Our
method is grounded in an alternative perspective on control and reinforcement
learning, where an agent&apos;s goal is to maximize the probability that one or more
events will happen at some point in the future, rather than maximizing
cumulative rewards. We demonstrate the effectiveness of our methods on
continuous control tasks, with a focus on high-dimensional observations like
images where rewards are hard or even impossible to specify.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fu_J/0/1/0/all/0/1&quot;&gt;Justin Fu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singh_A/0/1/0/all/0/1&quot;&gt;Avi Singh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghosh_D/0/1/0/all/0/1&quot;&gt;Dibya Ghosh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1&quot;&gt;Larry Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1&quot;&gt;Sergey Levine&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.12421">
<title>HOPF: Higher Order Propagation Framework for Deep Collective Classification. (arXiv:1805.12421v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.12421</link>
<description rdf:parseType="Literal">&lt;p&gt;Given a graph wherein every node has certain attributes associated with it
and some nodes have labels associated with them, Collective Classification (CC)
is the task of assigning labels to every unlabeled node using information from
the node as well as its neighbors. It is often the case that a node is not only
influenced by its immediate neighbors but also by its higher order neighbors,
multiple hops away. Recent state-of-the-art models for CC use differentiable
variations of Weisfeiler-Lehman kernels to aggregate multi-hop neighborhood
information. However, in this work, we show that these models suffer from the
problem of Node Information Morphing wherein the information of the node is
morphed or overwhelmed by the information of its neighbors when considering
multiple hops. Further, existing models are not scalable as the memory and
computation needs grow exponentially with the number of hops considered. To
circumvent these problems, we propose a generic Higher Order Propagation
Framework (HOPF) which includes (i) a differentiable Node Information
Preserving (NIP) kernel and (ii) a scalable iterative learning and inferencing
mechanism to aggregate information over larger hops. We do an extensive
evaluation using 11 datasets from different domains and show that unlike
existing CC models, our NIP model with iterative inference is robust across all
the datasets and can handle much larger neighborhoods in a scalable manner.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vijayan_P/0/1/0/all/0/1&quot;&gt;Priyesh Vijayan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chandak_Y/0/1/0/all/0/1&quot;&gt;Yash Chandak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khapra_M/0/1/0/all/0/1&quot;&gt;Mitesh M. Khapra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ravindran_B/0/1/0/all/0/1&quot;&gt;Balaraman Ravindran&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.12528">
<title>Fusion Graph Convolutional Networks. (arXiv:1805.12528v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.12528</link>
<description rdf:parseType="Literal">&lt;p&gt;Semi-supervised node classification involves learning to classify unlabelled
nodes given a partially labeled graph. In transductive learning, all unlabelled
nodes to be classified are observed during training and in inductive learning,
predictions are to be made for nodes not seen at training. In this paper, we
focus on both these settings for node classification in attributed graphs,
i.e., graphs in which nodes have additional features. State-of-the-art models
for node classification on such attributed graphs use differentiable recursive
functions. These differentiable recursive functions enable aggregation and
filtering of neighborhood information from multiple hops (depths). Despite
being powerful, these variants are limited in their ability to combine
information from different hops efficiently. In this work, we analyze this
limitation of recursive graph functions in terms of their representation
capacity to effectively capture multi-hop neighborhood information. Further, we
provide a simple fusion component which is mathematically motivated to address
this limitation and improve the existing models to explicitly learn the
importance of information from different hops. This proposed mechanism is shown
to improve over existing methods across 8 popular datasets from different
domains. Specifically, our model improves the Graph Convolutional Network (GCN)
and a variant of Graph SAGE by a significant margin providing highly
competitive state-of-the-art results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vijayan_P/0/1/0/all/0/1&quot;&gt;Priyesh Vijayan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chandak_Y/0/1/0/all/0/1&quot;&gt;Yash Chandak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khapra_M/0/1/0/all/0/1&quot;&gt;Mitesh M. Khapra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ravindran_B/0/1/0/all/0/1&quot;&gt;Balaraman Ravindran&lt;/a&gt;</dc:creator>
</item></rdf:RDF>