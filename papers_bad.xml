<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Boring papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Bad Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-02-27T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09703"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09746"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09816"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.10196"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09564"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09640"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09647"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09751"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09756"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09810"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09904"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09911"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.10026"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1708.01425"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1708.07607"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.03339"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.04569"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.06892"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08757"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09355"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09548"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09568"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09578"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09596"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09631"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09646"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09650"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09656"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09691"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09700"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09720"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09736"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09794"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09841"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09902"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09932"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09933"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09963"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.10031"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1504.06964"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1611.02440"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1704.09011"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1705.10467"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1707.03815"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.01233"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.06564"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.10230"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.06711"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.08289"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.00823"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.03848"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09246"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08714"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09514"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1802.09703">
<title>Boosting Cooperative Coevolution for Large Scale Optimization with a Fine-Grained Computation Resource Allocation Strategy. (arXiv:1802.09703v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1802.09703</link>
<description rdf:parseType="Literal">&lt;p&gt;Cooperative coevolution (CC) has shown great potential in solving large scale
optimization problems (LSOPs). However, traditional CC algorithms often waste
part of computation resource (CR) as they equally allocate CR among all the
subproblems. The recently developed contribution-based CC (CBCC) algorithms
improve the traditional ones to a certain extent by adaptively allocating CR
according to some heuristic rules. Different from existing works, this study
explicitly constructs a mathematical model for the CR allocation (CRA) problem
in CC and proposes a novel fine-grained CRA (FCRA) strategy by fully
considering both the theoretically optimal solution of the CRA model and the
evolution characteristics of CC. FCRA takes a single iteration as a basic CRA
unit and always selects the subproblem which is most likely to make the largest
contribution to the total fitness improvement to undergo a new iteration, where
the contribution of a subproblem at a new iteration is estimated according to
its current contribution, current evolution status as well as the estimation
for its current contribution. We verified the efficiency of FCRA by combining
it with SHADE which is an excellent differential evolution variant but has
never been employed in the CC framework. Experimental results on two benchmark
suites for LSOPs demonstrate that FCRA significantly outperforms existing CRA
strategies and the resultant CC algorithm is highly competitive in solving
LSOPs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ren_Z/0/1/0/all/0/1&quot;&gt;Zhigang Ren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1&quot;&gt;Yongsheng Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_A/0/1/0/all/0/1&quot;&gt;Aimin Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Y/0/1/0/all/0/1&quot;&gt;Yang Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feng_Z/0/1/0/all/0/1&quot;&gt;Zuren Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1&quot;&gt;Lin Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09746">
<title>Surrogate Model Assisted Cooperative Coevolution for Large Scale Optimization. (arXiv:1802.09746v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1802.09746</link>
<description rdf:parseType="Literal">&lt;p&gt;It has been shown that cooperative coevolution (CC) can effectively deal with
large scale optimization problems (LSOPs) through a divide-and-conquer
strategy. However, its performance is severely restricted by the current
context-vector-based sub-solution evaluation method since this method needs to
access the original high dimensional simulation model when evaluating each
sub-solution and thus requires many computation resources. To alleviate this
issue, this study proposes a novel surrogate model assisted cooperative
coevolution (SACC) framework. SACC constructs a surrogate model for each
sub-problem obtained via decomposition and employs it to evaluate corresponding
sub-solutions. The original simulation model is only adopted to reevaluate some
good sub-solutions selected by surrogate models, and these real evaluated
sub-solutions will be in turn employed to update surrogate models. By this
means, the computation cost could be greatly reduced without significantly
sacrificing evaluation quality. To show the efficiency of SACC, this study uses
radial basis function (RBF) and success-history based adaptive differential
evolution (SHADE) as surrogate model and optimizer, respectively. RBF and SHADE
have been proved to be effective on small and medium scale problems. This study
first scales them up to LSOPs of 1000 dimensions under the SACC framework,
where they are tailored to a certain extent for adapting to the characteristics
of LSOP and SACC. Empirical studies on IEEE CEC 2010 benchmark functions
demonstrate that SACC significantly enhances the evaluation efficiency on
sub-solutions, and even with much fewer computation resource, the resultant
RBF-SHADE-SACC algorithm is able to find much better solutions than traditional
CC algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ren_Z/0/1/0/all/0/1&quot;&gt;Zhigang Ren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pang_B/0/1/0/all/0/1&quot;&gt;Bei Pang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_Y/0/1/0/all/0/1&quot;&gt;Yongsheng Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_A/0/1/0/all/0/1&quot;&gt;An Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yipeng Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09816">
<title>Coarse to fine non-rigid registration: a chain of scale-specific neural networks for multimodal image alignment with application to remote sensing. (arXiv:1802.09816v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1802.09816</link>
<description rdf:parseType="Literal">&lt;p&gt;We tackle here the problem of multimodal image non-rigid registration, which
is of prime importance in remote sensing and medical imaging. The difficulties
encountered by classical registration approaches include feature design and
slow optimization by gradient descent. By analyzing these methods, we note the
significance of the notion of scale. We design easy-to-train,
fully-convolutional neural networks able to learn scale-specific features. Once
chained appropriately, they perform global registration in linear time, getting
rid of gradient descent schemes by predicting directly the deformation.We show
their performance in terms of quality and speed through various tasks of remote
sensing multimodal image alignment. In particular, we are able to register
correctly cadastral maps of buildings as well as road polylines onto RGB
images, and outperform current keypoint matching methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zampieri_A/0/1/0/all/0/1&quot;&gt;Armand Zampieri&lt;/a&gt; (TITANE), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Charpiat_G/0/1/0/all/0/1&quot;&gt;Guillaume Charpiat&lt;/a&gt; (TAU), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tarabalka_Y/0/1/0/all/0/1&quot;&gt;Yuliya Tarabalka&lt;/a&gt; (TITANE)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.10196">
<title>Progressive Growing of GANs for Improved Quality, Stability, and Variation. (arXiv:1710.10196v3 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1710.10196</link>
<description rdf:parseType="Literal">&lt;p&gt;We describe a new training methodology for generative adversarial networks.
The key idea is to grow both the generator and discriminator progressively:
starting from a low resolution, we add new layers that model increasingly fine
details as training progresses. This both speeds the training up and greatly
stabilizes it, allowing us to produce images of unprecedented quality, e.g.,
CelebA images at 1024^2. We also propose a simple way to increase the variation
in generated images, and achieve a record inception score of 8.80 in
unsupervised CIFAR10. Additionally, we describe several implementation details
that are important for discouraging unhealthy competition between the generator
and discriminator. Finally, we suggest a new metric for evaluating GAN results,
both in terms of image quality and variation. As an additional contribution, we
construct a higher-quality version of the CelebA dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Karras_T/0/1/0/all/0/1&quot;&gt;Tero Karras&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aila_T/0/1/0/all/0/1&quot;&gt;Timo Aila&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Laine_S/0/1/0/all/0/1&quot;&gt;Samuli Laine&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lehtinen_J/0/1/0/all/0/1&quot;&gt;Jaakko Lehtinen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09564">
<title>Reinforcement and Imitation Learning for Diverse Visuomotor Skills. (arXiv:1802.09564v1 [cs.RO])</title>
<link>http://arxiv.org/abs/1802.09564</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a model-free deep reinforcement learning method that leverages a
small amount of demonstration data to assist a reinforcement learning agent. We
apply this approach to robotic manipulation tasks and train end-to-end
visuomotor policies that map directly from RGB camera inputs to joint
velocities. We demonstrate that our approach can solve a wide variety of
visuomotor tasks, for which engineering a scripted controller would be
laborious. Our experiments indicate that our reinforcement and imitation agent
achieves significantly better performances than agents trained with
reinforcement learning or imitation learning alone. We also illustrate that
these policies, trained with large visual and dynamics variations, can achieve
preliminary successes in zero-shot sim2real transfer. A brief visual
description of this work can be viewed in https://youtu.be/EDl8SQUNjj0
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_Y/0/1/0/all/0/1&quot;&gt;Yuke Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Ziyu Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Merel_J/0/1/0/all/0/1&quot;&gt;Josh Merel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rusu_A/0/1/0/all/0/1&quot;&gt;Andrei Rusu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Erez_T/0/1/0/all/0/1&quot;&gt;Tom Erez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cabi_S/0/1/0/all/0/1&quot;&gt;Serkan Cabi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tunyasuvunakool_S/0/1/0/all/0/1&quot;&gt;Saran Tunyasuvunakool&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kramar_J/0/1/0/all/0/1&quot;&gt;J&amp;#xe1;nos Kram&amp;#xe1;r&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hadsell_R/0/1/0/all/0/1&quot;&gt;Raia Hadsell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Freitas_N/0/1/0/all/0/1&quot;&gt;Nando de Freitas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Heess_N/0/1/0/all/0/1&quot;&gt;Nicolas Heess&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09640">
<title>Modeling Others using Oneself in Multi-Agent Reinforcement Learning. (arXiv:1802.09640v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.09640</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the multi-agent reinforcement learning setting with imperfect
information in which each agent is trying to maximize its own utility. The
reward function depends on the hidden state (or goal) of both agents, so the
agents must infer the other players&apos; hidden goals from their observed behavior
in order to solve the tasks. We propose a new approach for learning in these
domains: Self Other-Modeling (SOM), in which an agent uses its own policy to
predict the other agent&apos;s actions and update its belief of their hidden state
in an online manner. We evaluate this approach on three different tasks and
show that the agents are able to learn better policies using their estimate of
the other players&apos; hidden states, in both cooperative and adversarial settings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Raileanu_R/0/1/0/all/0/1&quot;&gt;Roberta Raileanu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Denton_E/0/1/0/all/0/1&quot;&gt;Emily Denton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Szlam_A/0/1/0/all/0/1&quot;&gt;Arthur Szlam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fergus_R/0/1/0/all/0/1&quot;&gt;Rob Fergus&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09647">
<title>Shaping Influence and Influencing Shaping: A Computational Red Teaming Trust-based Swarm Intelligence Model. (arXiv:1802.09647v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.09647</link>
<description rdf:parseType="Literal">&lt;p&gt;Sociotechnical systems are complex systems, where nonlinear interaction among
different players can obscure causal relationships. The absence of mechanisms
to help us understand how to create a change in the system makes it hard to
manage these systems.
&lt;/p&gt;
&lt;p&gt;Influencing and shaping are social operators acting on sociotechnical systems
to design a change. However, the two operators are usually discussed in an
ad-hoc manner, without proper guiding models and metrics which assist in
adopting these models successfully. Moreover, both social operators rely on
accurate understanding of the concept of trust. Without such understanding,
neither of these operators can create the required level to create a change in
a desirable direction.
&lt;/p&gt;
&lt;p&gt;In this paper, we define these concepts in a concise manner suitable for
modelling the concepts and understanding their dynamics. We then introduce a
model for influencing and shaping and use Computational Red Teaming principles
to design and demonstrate how this model operates. We validate the results
computationally through a simulation environment to show social influencing and
shaping in an artificial society.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1&quot;&gt;Jiangjun Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Petraki_E/0/1/0/all/0/1&quot;&gt;Eleni Petraki&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abbass_H/0/1/0/all/0/1&quot;&gt;Hussein Abbass&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09751">
<title>Generalized Binary Search For Split-Neighborly Problems. (arXiv:1802.09751v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.09751</link>
<description rdf:parseType="Literal">&lt;p&gt;In sequential hypothesis testing, Generalized Binary Search (GBS) greedily
chooses the test with the highest information gain at each step. It is known
that GBS obtains the gold standard query cost of $O(\log n)$ for problems
satisfying the $k$-neighborly condition, which requires any two tests to be
connected by a sequence of tests where neighboring tests disagree on at most
$k$ hypotheses. In this paper, we introduce a weaker condition,
split-neighborly, which requires that for the set of hypotheses two neighbors
disagree on, any subset is splittable by some test. For four problems that are
not $k$-neighborly for any constant $k$, we prove that they are
split-neighborly, which allows us to obtain the optimal $O(\log n)$ worst-case
query cost.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mussmann_S/0/1/0/all/0/1&quot;&gt;Stephen Mussmann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_P/0/1/0/all/0/1&quot;&gt;Percy Liang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09756">
<title>Real-Time Bidding with Multi-Agent Reinforcement Learning in Display Advertising. (arXiv:1802.09756v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.09756</link>
<description rdf:parseType="Literal">&lt;p&gt;Real-time advertising allows advertisers to bid for each impression for a
visiting user. To optimize a specific goal such as maximizing the revenue led
by ad placements, advertisers not only need to estimate the relevance between
the ads and user&apos;s interests, but most importantly require a strategic response
with respect to other advertisers bidding in the market. In this paper, we
formulate bidding optimization with multi-agent reinforcement learning. To deal
with a large number of advertisers, we propose a clustering method and assign
each cluster with a strategic bidding agent. A practical Distributed
Coordinated Multi-Agent Bidding (DCMAB) has been proposed and implemented to
balance the tradeoff between the competition and cooperation among advertisers.
The empirical study on our industry-scaled real-world data has demonstrated the
effectiveness of our modeling methods. Our results show that a cluster based
bidding would largely outperform single-agent and bandit approaches, and the
coordinated bidding achieves better overall objectives than the purely
self-interested bidding agents.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Jin_J/0/1/0/all/0/1&quot;&gt;Junqi Jin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Song_C/0/1/0/all/0/1&quot;&gt;Chengru Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Li_H/0/1/0/all/0/1&quot;&gt;Han Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gai_K/0/1/0/all/0/1&quot;&gt;Kun Gai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jun Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhang_W/0/1/0/all/0/1&quot;&gt;Weinan Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09810">
<title>Human-in-the-Loop Synthesis for Partially Observable Markov Decision Processes. (arXiv:1802.09810v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.09810</link>
<description rdf:parseType="Literal">&lt;p&gt;We study planning problems where autonomous agents operate inside
environments that are subject to uncertainties and not fully observable.
Partially observable Markov decision processes (POMDPs) are a natural formal
model to capture such problems. Because of the potentially huge or even
infinite belief space in POMDPs, synthesis with safety guarantees is, in
general, computationally intractable. We propose an approach that aims to
circumvent this difficulty: in scenarios that can be partially or fully
simulated in a virtual environment, we actively integrate a human user to
control an agent. While the user repeatedly tries to safely guide the agent in
the simulation, we collect data from the human input. Via behavior cloning, we
translate the data into a strategy for the POMDP. The strategy resolves all
nondeterminism and non-observability of the POMDP, resulting in a discrete-time
Markov chain (MC). The efficient verification of this MC gives quantitative
insights into the quality of the inferred human strategy by proving or
disproving given system specifications. For the case that the quality of the
strategy is not sufficient, we propose a refinement method using
counterexamples presented to the human. Experiments show that by including
humans into the POMDP verification loop we improve the state of the art by
orders of magnitude in terms of scalability.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Carr_S/0/1/0/all/0/1&quot;&gt;Steven Carr&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jansen_N/0/1/0/all/0/1&quot;&gt;Nils Jansen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wimmer_R/0/1/0/all/0/1&quot;&gt;Ralf Wimmer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fu_J/0/1/0/all/0/1&quot;&gt;Jie Fu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Topcu_U/0/1/0/all/0/1&quot;&gt;Ufuk Topcu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09904">
<title>Ab initio Algorithmic Causal Deconvolution of Intertwined Programs and Networks by Generative Mechanism. (arXiv:1802.09904v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.09904</link>
<description rdf:parseType="Literal">&lt;p&gt;To extract and learn representations leading to generative mechanisms from
data, especially without making arbitrary decisions and biased assumptions, is
a central challenge in most areas of scientific research particularly in
connection to current major limitations of influential topics and methods of
machine and deep learning as they have often lost sight of the model component.
Complex data is usually produced by interacting sources with different
mechanisms. Here we introduce a parameter-free model-based approach, based upon
the seminal concept of Algorithmic Probability, that decomposes an observation
and signal into its most likely algorithmic generative mechanisms. Our methods
use a causal calculus to infer model representations. We demonstrate the method
ability to distinguish interacting mechanisms and deconvolve them, regardless
of whether the objects produce strings, space-time evolution diagrams, images
or networks. We numerically test and evaluate our method and find that it can
disentangle observations from discrete dynamic systems, random and complex
networks. We think that these causal inference techniques can contribute as key
pieces of information for estimations of probability distributions
complementing other more statistical-oriented techniques that otherwise lack
model inference capabilities.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zenil_H/0/1/0/all/0/1&quot;&gt;Hector Zenil&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kiani_N/0/1/0/all/0/1&quot;&gt;Narsis A. Kiani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tegner_J/0/1/0/all/0/1&quot;&gt;Jesper Tegn&amp;#xe9;r&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09911">
<title>Discovering Bayesian Market Views for Intelligent Asset Allocation. (arXiv:1802.09911v1 [q-fin.CP])</title>
<link>http://arxiv.org/abs/1802.09911</link>
<description rdf:parseType="Literal">&lt;p&gt;Along with the advance of opinion mining techniques, public mood has been
found to be a key element for stock market prediction. However, in what manner
the market participants are affected by public mood has been rarely discussed.
As a result, there has been little progress in leveraging public mood for the
asset allocation problem, as the application is preferred in a trusted and
interpretable way. In order to address the issue of incorporating public mood
analyzed from social media, we propose to formalize it into market views that
can be integrated into the modern portfolio theory. In this framework, the
optimal market views will maximize returns in each period with a Bayesian asset
allocation model. We train two neural models to generate the market views, and
benchmark the performance of our model using market views on other popular
asset allocation strategies. Our experimental results suggest that the
formalization of market views significantly increases the profitability (5% to
10%) of the simulated portfolio at a given risk level.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-fin/1/au:+Xing_F/0/1/0/all/0/1&quot;&gt;Frank Z. Xing&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-fin/1/au:+Cambria_E/0/1/0/all/0/1&quot;&gt;Erik Cambria&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-fin/1/au:+Malandri_L/0/1/0/all/0/1&quot;&gt;Lorenzo Malandri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-fin/1/au:+Vercellis_C/0/1/0/all/0/1&quot;&gt;Carlo Vercellis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.10026">
<title>Loss Surfaces, Mode Connectivity, and Fast Ensembling of DNNs. (arXiv:1802.10026v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.10026</link>
<description rdf:parseType="Literal">&lt;p&gt;The loss functions of deep neural networks are complex and their geometric
properties are not well understood. We show that the optima of these complex
loss functions are in fact connected by a simple polygonal chain with only one
bend, over which training and test accuracy are nearly constant. We introduce a
training procedure to discover these high-accuracy pathways between modes.
Inspired by this new geometric insight, we propose a new ensembling method
entitled Fast Geometric Ensembling (FGE). Using FGE we can train
high-performing ensembles in the time required to train a single model. We
achieve improved performance compared to the recent state-of-the-art Snapshot
Ensembles, on CIFAR-10 and CIFAR-100, using state-of-the-art deep residual
networks. On ImageNet we improve the top-1 error-rate of a pre-trained ResNet
by 0.56% by running FGE for just 5 epochs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Garipov_T/0/1/0/all/0/1&quot;&gt;Timur Garipov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Izmailov_P/0/1/0/all/0/1&quot;&gt;Pavel Izmailov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Podoprikhin_D/0/1/0/all/0/1&quot;&gt;Dmitrii Podoprikhin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Vetrov_D/0/1/0/all/0/1&quot;&gt;Dmitry P. Vetrov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wilson_A/0/1/0/all/0/1&quot;&gt;Andrew Gordon Wilson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1708.01425">
<title>The Argument Reasoning Comprehension Task: Identification and Reconstruction of Implicit Warrants. (arXiv:1708.01425v4 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1708.01425</link>
<description rdf:parseType="Literal">&lt;p&gt;Reasoning is a crucial part of natural language argumentation. To comprehend
an argument, one must analyze its warrant, which explains why its claim follows
from its premises. As arguments are highly contextualized, warrants are usually
presupposed and left implicit. Thus, the comprehension does not only require
language understanding and logic skills, but also depends on common sense. In
this paper we develop a methodology for reconstructing warrants systematically.
We operationalize it in a scalable crowdsourcing process, resulting in a freely
licensed dataset with warrants for 2k authentic arguments from news comments.
On this basis, we present a new challenging task, the argument reasoning
comprehension task. Given an argument with a claim and a premise, the goal is
to choose the correct implicit warrant from two options. Both warrants are
plausible and lexically close, but lead to contradicting claims. A solution to
this task will define a substantial step towards automatic warrant
reconstruction. However, experiments with several neural attention and language
models reveal that current approaches do not suffice.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Habernal_I/0/1/0/all/0/1&quot;&gt;Ivan Habernal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wachsmuth_H/0/1/0/all/0/1&quot;&gt;Henning Wachsmuth&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gurevych_I/0/1/0/all/0/1&quot;&gt;Iryna Gurevych&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stein_B/0/1/0/all/0/1&quot;&gt;Benno Stein&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1708.07607">
<title>Reinforcement Mechanism Design for e-commerce. (arXiv:1708.07607v3 [cs.MA] UPDATED)</title>
<link>http://arxiv.org/abs/1708.07607</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the problem of allocating impressions to sellers in e-commerce
websites, such as Amazon, eBay or Taobao, aiming to maximize the total revenue
generated by the platform. We employ a general framework of reinforcement
mechanism design, which uses deep reinforcement learning to design efficient
algorithms, taking the strategic behaviour of the sellers into account.
Specifically, we model the impression allocation problem as a Markov decision
process, where the states encode the history of impressions, prices,
transactions and generated revenue and the actions are the possible impression
allocations in each round. To tackle the problem of continuity and
high-dimensionality of states and actions, we adopt the ideas of the DDPG
algorithm to design an actor-critic policy gradient algorithm which takes
advantage of the problem domain in order to achieve convergence and stability.
We evaluate our proposed algorithm, coined IA(GRU), by comparing it against
DDPG, as well as several natural heuristics, under different rationality models
for the sellers - we assume that sellers follow well-known no-regret type
strategies which may vary in their degree of sophistication. We find that
IA(GRU) outperforms all algorithms in terms of the total revenue.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cai_Q/0/1/0/all/0/1&quot;&gt;Qingpeng Cai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Filos_Ratsikas_A/0/1/0/all/0/1&quot;&gt;Aris Filos-Ratsikas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_P/0/1/0/all/0/1&quot;&gt;Pingzhong Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yiwei Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.03339">
<title>Autonomous Quadrotor Landing using Deep Reinforcement Learning. (arXiv:1709.03339v3 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1709.03339</link>
<description rdf:parseType="Literal">&lt;p&gt;Landing an unmanned aerial vehicle (UAV) on a ground marker is an open
problem despite the effort of the research community. Previous attempts mostly
focused on the analysis of hand-crafted geometric features and the use of
external sensors in order to allow the vehicle to approach the land-pad. In
this article, we propose a method based on deep reinforcement learning that
only requires low-resolution images taken from a down-looking camera in order
to identify the position of the marker and land the UAV on it. The proposed
approach is based on a hierarchy of Deep Q-Networks (DQNs) used as high-level
control policy for the navigation toward the marker. We implemented different
technical solutions, such as the combination of vanilla and double DQNs, and a
partitioned buffer replay. Using domain randomization we trained the vehicle on
uniform textures and we tested it on a large variety of simulated and
real-world environments. The overall performance is comparable with a
state-of-the-art algorithm and human pilots.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Polvara_R/0/1/0/all/0/1&quot;&gt;Riccardo Polvara&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Patacchiola_M/0/1/0/all/0/1&quot;&gt;Massimiliano Patacchiola&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sharma_S/0/1/0/all/0/1&quot;&gt;Sanjay Sharma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wan_J/0/1/0/all/0/1&quot;&gt;Jian Wan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Manning_A/0/1/0/all/0/1&quot;&gt;Andrew Manning&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sutton_R/0/1/0/all/0/1&quot;&gt;Robert Sutton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cangelosi_A/0/1/0/all/0/1&quot;&gt;Angelo Cangelosi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.04569">
<title>Multilingual Adaptation of RNN Based ASR Systems. (arXiv:1711.04569v2 [eess.AS] UPDATED)</title>
<link>http://arxiv.org/abs/1711.04569</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work, we focus on multilingual systems based on recurrent neural
networks (RNNs), trained using the Connectionist Temporal Classification (CTC)
loss function. Using a multilingual set of acoustic units poses difficulties.
To address this issue, we proposed Language Feature Vectors (LFVs) to train
language adaptive multilingual systems. Language adaptation, in contrast to
speaker adaptation, needs to be applied not only on the feature level, but also
to deeper layers of the network. In this work, we therefore extended our
previous approach by introducing a novel technique which we call &quot;modulation&quot;.
Based on this method, we modulated the hidden layers of RNNs using LFVs. We
evaluated this approach in both full and low resource conditions, as well as
for grapheme and phone based systems. Lower error rates throughout the
different conditions could be achieved by the use of the modulation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Muller_M/0/1/0/all/0/1&quot;&gt;Markus M&amp;#xfc;ller&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Stuker_S/0/1/0/all/0/1&quot;&gt;Sebastian St&amp;#xfc;ker&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Waibel_A/0/1/0/all/0/1&quot;&gt;Alex Waibel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.06892">
<title>Learning to select computations. (arXiv:1711.06892v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1711.06892</link>
<description rdf:parseType="Literal">&lt;p&gt;Efficient use of limited computational resources is essential to
intelligence. Selecting computations optimally according to rational
metareasoning would achieve this, but rational metareasoning is computationally
intractable. Inspired by psychology and neuroscience, we propose the first
learning algorithm for approximating the optimal selection of computations. We
derive a general, sample-efficient reinforcement learning algorithm for
learning to select computations from the insight that the value of computation
lies between the myopic value of computation and the value of perfect
information. We evaluate the performance of our method against two
state-of-the-art methods for approximate metareasoning--the meta-greedy
heuristic and the blinkered policy--on three increasingly difficult
metareasoning problems: metareasoning about when to terminate computation,
metareasoning about how to choose between multiple actions, and metareasoning
about planning. Across all three domains, our method achieved near-optimal
performance and significantly outperformed the meta-greedy heuristic. The
blinkered policy performed on par with our method in metareasoning about
decision-making, but it is not directly applicable to metareasoning about
planning where our method outperformed both the meta-greedy heuristic and a
generalization of the blinkered policy. Our results are a step towards building
self-improving AI systems that can learn to make optimal use of their limited
computational resources to efficiently solve complex problems in real-time.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lieder_F/0/1/0/all/0/1&quot;&gt;Falk Lieder&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Callaway_F/0/1/0/all/0/1&quot;&gt;Frederick Callaway&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gul_S/0/1/0/all/0/1&quot;&gt;Sayan Gul&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Krueger_P/0/1/0/all/0/1&quot;&gt;Paul M. Krueger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Griffiths_T/0/1/0/all/0/1&quot;&gt;Thomas L. Griffiths&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08757">
<title>Fully Decentralized Multi-Agent Reinforcement Learning with Networked Agents. (arXiv:1802.08757v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1802.08757</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the problem of \emph{fully decentralized} multi-agent
reinforcement learning (MARL), where the agents are located at the nodes of a
time-varying communication network. Specifically, we assume that the reward
functions of the agents might correspond to different tasks, and are only known
to the corresponding agent. Moreover, each agent makes individual decisions
based on both the information observed locally and the messages received from
its neighbors over the network. Within this setting, the collective goal of the
agents is to maximize the globally averaged return over the network through
exchanging information with their neighbors. To this end, we propose two
decentralized actor-critic algorithms with function approximation, which are
applicable to large-scale MARL problems where both the number of states and the
number of agents are massively large. Under the decentralized structure, the
actor step is performed individually by each agent with no need to infer the
policies of others. For the critic step, we propose a consensus update via
communication over the network. Our algorithms are fully incremental and can be
implemented in an online fashion. Convergence analyses of the algorithms are
provided when the value functions are approximated within the class of linear
functions. Extensive simulation results with both linear and nonlinear function
approximations are presented to validate the proposed algorithms. Our work
appears to be the first study of fully decentralized MARL algorithms for
networked agents with function approximation, with provable convergence
guarantees.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1&quot;&gt;Kaiqing Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1&quot;&gt;Zhuoran Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1&quot;&gt;Han Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1&quot;&gt;Tong Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Basar_T/0/1/0/all/0/1&quot;&gt;Tamer Ba&amp;#x15f;ar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09355">
<title>Teaching Autonomous Driving Using a Modular and Integrated Approach. (arXiv:1802.09355v2 [cs.CY] UPDATED)</title>
<link>http://arxiv.org/abs/1802.09355</link>
<description rdf:parseType="Literal">&lt;p&gt;Autonomous driving is not one single technology but rather a complex system
integrating many technologies, which means that teaching autonomous driving is
a challenging task. Indeed, most existing autonomous driving classes focus on
one of the technologies involved. This not only fails to provide a
comprehensive coverage, but also sets a high entry barrier for students with
different technology backgrounds. In this paper, we present a modular,
integrated approach to teaching autonomous driving. Specifically, we organize
the technologies used in autonomous driving into modules. This is described in
the textbook we have developed as well as a series of multimedia online
lectures designed to provide technical overview for each module. Then, once the
students have understood these modules, the experimental platforms for
integration we have developed allow the students to fully understand how the
modules interact with each other. To verify this teaching approach, we present
three case studies: an introductory class on autonomous driving for students
with only a basic technology background; a new session in an existing embedded
systems class to demonstrate how embedded system technologies can be applied to
autonomous driving; and an industry professional training session to quickly
bring up experienced engineers to work in autonomous driving. The results show
that students can maintain a high interest level and make great progress by
starting with familiar concepts before moving onto other modules.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1&quot;&gt;Jie Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1&quot;&gt;Shaoshan Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pei_S/0/1/0/all/0/1&quot;&gt;Songwen Pei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zuckerman_S/0/1/0/all/0/1&quot;&gt;Stephane Zuckerman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1&quot;&gt;Chen Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_W/0/1/0/all/0/1&quot;&gt;Weisong Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gaudiot_J/0/1/0/all/0/1&quot;&gt;Jean-Luc Gaudiot&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09548">
<title>Human Perceptions of Fairness in Algorithmic Decision Making: A Case Study of Criminal Risk Prediction. (arXiv:1802.09548v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.09548</link>
<description rdf:parseType="Literal">&lt;p&gt;As algorithms are increasingly used to make important decisions that affect
human lives, ranging from social benefit assignment to predicting risk of
criminal recidivism, concerns have been raised about the fairness of
algorithmic decision making. Most prior works on algorithmic fairness
normatively prescribe how fair decisions ought to be made. In contrast, here,
we descriptively survey users for how they perceive and reason about fairness
in algorithmic decision making.
&lt;/p&gt;
&lt;p&gt;A key contribution of this work is the framework we propose to understand why
people perceive certain features as fair or unfair to be used in algorithms.
Our framework identifies eight properties of features, such as relevance,
volitionality and reliability, as latent considerations that inform people&apos;s
moral judgments about the fairness of feature use in decision-making
algorithms. We validate our framework through a series of scenario-based
surveys with 576 people. We find that, based on a person&apos;s assessment of the
eight latent properties of a feature in our exemplar scenario, we can
accurately (&amp;gt; 85%) predict if the person will judge the use of the feature as
fair.
&lt;/p&gt;
&lt;p&gt;Our findings have important implications. At a high-level, we show that
people&apos;s unfairness concerns are multi-dimensional and argue that future
studies need to address unfairness concerns beyond discrimination. At a
low-level, we find considerable disagreements in people&apos;s fairness judgments.
We identify root causes of the disagreements, and note possible pathways to
resolve them.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Grgic_Hlaca_N/0/1/0/all/0/1&quot;&gt;Nina Grgi&amp;#x107;-Hla&amp;#x10d;a&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Redmiles_E/0/1/0/all/0/1&quot;&gt;Elissa M. Redmiles&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gummadi_K/0/1/0/all/0/1&quot;&gt;Krishna P. Gummadi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Weller_A/0/1/0/all/0/1&quot;&gt;Adrian Weller&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09568">
<title>Shampoo: Preconditioned Stochastic Tensor Optimization. (arXiv:1802.09568v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.09568</link>
<description rdf:parseType="Literal">&lt;p&gt;Preconditioned gradient methods are among the most general and powerful tools
in optimization. However, preconditioning requires storing and manipulating
prohibitively large matrices. We describe and analyze a new structure-aware
preconditioning algorithm, called Shampoo, for stochastic optimization over
tensor spaces. Shampoo maintains a set of preconditioning matrices, each of
which operates on a single dimension, contracting over the remaining
dimensions. We establish convergence guarantees in the stochastic convex
setting, the proof of which builds upon matrix trace inequalities. Our
experiments with state-of-the-art deep learning models show that Shampoo is
capable of converging considerably faster than commonly used optimizers.
Although it involves a more complex update rule, Shampoo&apos;s runtime per step is
comparable to that of simple gradient methods such as SGD, AdaGrad, and Adam.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gupta_V/0/1/0/all/0/1&quot;&gt;Vineet Gupta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koren_T/0/1/0/all/0/1&quot;&gt;Tomer Koren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singer_Y/0/1/0/all/0/1&quot;&gt;Yoram Singer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09578">
<title>Near-Linear Time Local Polynomial Nonparametric Estimation. (arXiv:1802.09578v1 [stat.CO])</title>
<link>http://arxiv.org/abs/1802.09578</link>
<description rdf:parseType="Literal">&lt;p&gt;Local polynomial regression (Fan &amp;amp; Gijbels, 1996) is an important class of
methods for nonparametric density estimation and regression problems. However,
straightforward implementation of local polynomial regression has quadratic
time complexity which hinders its applicability in large-scale data analysis.
In this paper, we significantly accelerate the computation of local polynomial
estimates by novel applications of multi-dimensional binary indexed trees
(Fenwick, 1994). Both time and space complexities of our proposed algorithm are
nearly linear in the number of inputs. Simulation results confirm the
efficiency and effectiveness of our approach.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yining Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wu_Y/0/1/0/all/0/1&quot;&gt;Yi Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Du_S/0/1/0/all/0/1&quot;&gt;Simon S. Du&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09596">
<title>Tunability: Importance of Hyperparameters of Machine Learning Algorithms. (arXiv:1802.09596v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.09596</link>
<description rdf:parseType="Literal">&lt;p&gt;Modern machine learning algorithms for classification or regression such as
gradient boosting, random forest and neural networks involve a number of
parameters that have to be fixed before running them. Such parameters are
commonly denoted as hyperparameters in machine learning, a terminology we also
adopt here. The term tuning parameter is also frequently used to denote
parameters that should be carefully tuned, i.e. optimized with respect to
performance.
&lt;/p&gt;
&lt;p&gt;The users of these algorithms can use defaults of these hyperparameters that
are specified in the employed software package, set them to alternative
specific values or use a tuning strategy to choose them appropriately for the
specific dataset at hand. In this context, we define tunability as the amount
of performance gain that can be achieved by setting the considered
hyperparameter to the best possible value instead of the default value. The
goal of this paper is two-fold. Firstly, we formalize the problem of tuning
from a statistical point of view and suggest general measures quantifying the
tunability of hyperparameters of algorithms. Secondly, we conduct a large-scale
benchmarking study based on 38 datasets from the OpenML platform (Vanschoren et
al., 2013) using six of the most common machine learning algorithms for
classification and regression and apply our measures to assess the tunability
of their parameters. The results yield interesting insights into the
investigated hyperparameters that in some cases allow general conclusions on
their tunability. Our results may help users of the algorithms to decide
whether it is worth to conduct a possibly time consuming tuning strategy, to
focus on the most important hyperparameters and to chose adequate
hyperparameter spaces for tuning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Probst_P/0/1/0/all/0/1&quot;&gt;Philipp Probst&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bischl_B/0/1/0/all/0/1&quot;&gt;Bernd Bischl&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Boulesteix_A/0/1/0/all/0/1&quot;&gt;Anne-Laure Boulesteix&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09631">
<title>Bayesian shape modelling of cross-sectional geological data. (arXiv:1802.09631v1 [stat.ME])</title>
<link>http://arxiv.org/abs/1802.09631</link>
<description rdf:parseType="Literal">&lt;p&gt;Shape information is of great importance in many applications. For example,
the oil-bearing capacity of sand bodies, the subterranean remnants of ancient
rivers, is related to their cross-sectional shapes. The analysis of these
shapes is therefore of some interest, but current classifications are
simplistic and ad hoc. In this paper, we describe the first steps towards a
coherent statistical analysis of these shapes by deriving the integrated
likelihood for data shapes given class parameters. The result is of interest
beyond this particular application.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tsiftsi_T/0/1/0/all/0/1&quot;&gt;Thomai Tsiftsi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Jermyn_I/0/1/0/all/0/1&quot;&gt;Ian H. Jermyn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Einbeck_J/0/1/0/all/0/1&quot;&gt;Jochen Einbeck&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09646">
<title>Optimizing over a Restricted Policy Class in Markov Decision Processes. (arXiv:1802.09646v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.09646</link>
<description rdf:parseType="Literal">&lt;p&gt;We address the problem of finding an optimal policy in a Markov decision
process under a restricted policy class defined by the convex hull of a set of
base policies. This problem is of great interest in applications in which a
number of reasonably good (or safe) policies are already known and we are only
interested in optimizing in their convex hull. We show that this problem is
NP-hard to solve exactly as well as to approximate to arbitrary accuracy.
However, under a condition that is akin to the occupancy measures of the base
policies having large overlap, we show that there exists an efficient algorithm
that finds a policy that is almost as good as the best convex combination of
the base policies. The running time of the proposed algorithm is linear in the
number of states and polynomial in the number of base policies. In practice, we
demonstrate an efficient implementation for large state problems. Compared to
traditional policy gradient methods, the proposed approach has the advantage
that, apart from the computation of occupancy measures of some base policies,
the iterative method need not interact with the environment during the
optimization process. This is especially important in complex systems where
estimating the value of a policy can be a time consuming process.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Banijamali_E/0/1/0/all/0/1&quot;&gt;Ershad Banijamali&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abbasi_Yadkori_Y/0/1/0/all/0/1&quot;&gt;Yasin Abbasi-Yadkori&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghavamzadeh_M/0/1/0/all/0/1&quot;&gt;Mohammad Ghavamzadeh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vlassis_N/0/1/0/all/0/1&quot;&gt;Nikos Vlassis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09650">
<title>ABC Samplers. (arXiv:1802.09650v1 [stat.CO])</title>
<link>http://arxiv.org/abs/1802.09650</link>
<description rdf:parseType="Literal">&lt;p&gt;This Chapter, &quot;ABC Samplers&quot;, is to appear in the forthcoming Handbook of
Approximate Bayesian Computation (2018). It details the main ideas and
algorithms used to sample from the ABC approximation to the posterior
distribution, including methods based on rejection/importance sampling, MCMC
and sequential Monte Carlo.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Fan_Y/0/1/0/all/0/1&quot;&gt;Y. Fan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sisson_S/0/1/0/all/0/1&quot;&gt;S. A. Sisson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09656">
<title>Learning Binary Latent Variable Models: A Tensor Eigenpair Approach. (arXiv:1802.09656v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.09656</link>
<description rdf:parseType="Literal">&lt;p&gt;Latent variable models with hidden binary units appear in various
applications. Learning such models, in particular in the presence of noise, is
a challenging computational problem. In this paper we propose a novel spectral
approach to this problem, based on the eigenvectors of both the second order
moment matrix and third order moment tensor of the observed data. We prove that
under mild non-degeneracy conditions, our method consistently estimates the
model parameters at the optimal parametric rate. Our tensor-based method
generalizes previous orthogonal tensor decomposition approaches, where the
hidden units were assumed to be either statistically independent or mutually
exclusive. We illustrate the consistency of our method on simulated data and
demonstrate its usefulness in learning a common model for population mixtures
in genetics.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Jaffe_A/0/1/0/all/0/1&quot;&gt;Ariel Jaffe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Weiss_R/0/1/0/all/0/1&quot;&gt;Roi Weiss&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Carmi_S/0/1/0/all/0/1&quot;&gt;Shai Carmi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kluger_Y/0/1/0/all/0/1&quot;&gt;Yuval Kluger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Nadler_B/0/1/0/all/0/1&quot;&gt;Boaz Nadler&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09691">
<title>Link Prediction Based on Graph Neural Networks. (arXiv:1802.09691v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.09691</link>
<description rdf:parseType="Literal">&lt;p&gt;Traditional methods for link prediction can be categorized into three main
types: graph structure feature-based, latent feature-based, and explicit
feature-based. Graph structure feature methods leverage some handcrafted node
proximity scores, e.g., common neighbors, to estimate the likelihood of links.
Latent feature methods rely on factorizing networks&apos; matrix representations to
learn an embedding for each node. Explicit feature methods train a machine
learning model on two nodes&apos; explicit attributes. Each of the three types of
methods has its unique merits. In this paper, we propose SEAL (learning from
Subgraphs, Embeddings, and Attributes for Link prediction), a new framework for
link prediction which combines the power of all the three types into a single
graph neural network (GNN). GNN is a new type of neural network which directly
accepts graphs as input and outputs their labels. In SEAL, the input to the GNN
is a local subgraph around each target link. We prove theoretically that our
local subgraphs also reserve a great deal of high-order graph structure
features related to link existence. Another key feature is that our GNN can
naturally incorporate latent features and explicit features. It is achieved by
concatenating node embeddings (latent features) and node attributes (explicit
features) in the node information matrix for each subgraph, thus combining the
three types of features to enhance GNN learning. Through extensive experiments,
SEAL shows unprecedentedly strong performance against a wide range of baseline
methods, including various link prediction heuristics and network embedding
methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1&quot;&gt;Muhan Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yixin Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09700">
<title>Robust GANs against Dishonest Adversaries. (arXiv:1802.09700v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.09700</link>
<description rdf:parseType="Literal">&lt;p&gt;Robustness of deep learning models is a property that has recently gained
increasing attention. We formally define a notion of robustness for generative
adversarial models, and show that, perhaps surprisingly, the GAN in its
original form is not robust. Indeed, the discriminator in GANs may be viewed as
merely offering &quot;teaching feedback&quot;. Our notion of robustness relies on a
dishonest discriminator, or noisy, adversarial interference with its feedback.
We explore, theoretically and empirically, the effect of model and training
properties on this robustness. In particular, we show theoretical conditions
for robustness that are supported by empirical evidence. We also test the
effect of regularization. Our results suggest variations of GANs that are
indeed more robust to noisy attacks, and have overall more stable training
behavior.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1&quot;&gt;Zhi Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1&quot;&gt;Chengtao Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jegelka_S/0/1/0/all/0/1&quot;&gt;Stefanie Jegelka&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09720">
<title>Overview of Approximate Bayesian Computation. (arXiv:1802.09720v1 [stat.CO])</title>
<link>http://arxiv.org/abs/1802.09720</link>
<description rdf:parseType="Literal">&lt;p&gt;This Chapter, &quot;Overview of Approximate Bayesian Computation&quot;, is to appear as
the first chapter in the forthcoming Handbook of Approximate Bayesian
Computation (2018). It details the main ideas and concepts behind ABC methods
with many examples and illustrations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sisson_S/0/1/0/all/0/1&quot;&gt;S. A. Sisson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Fan_Y/0/1/0/all/0/1&quot;&gt;Y. Fan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Beaumont_M/0/1/0/all/0/1&quot;&gt;M. A. Beaumont&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09736">
<title>Cognitive Radar Antenna Selection via Deep Learning. (arXiv:1802.09736v1 [eess.SP])</title>
<link>http://arxiv.org/abs/1802.09736</link>
<description rdf:parseType="Literal">&lt;p&gt;Direction of arrival (DoA) estimation of targets improves with the number of
elements employed by a phased array radar antenna. Since larger arrays have
high associated cost, area and computational load, there is recent interest in
thinning the antenna arrays without loss of far-field DoA accuracy. In this
context, a cognitive radar may deploy a full array and then select an optimal
subarray to transmit and receive the signals in response to changes in the
target environment. Prior works have used optimization and greedy search
methods to pick the best subarrays cognitively. In this paper, we leverage deep
learning to address the antenna selection problem. Specifically, we construct a
convolutional neural network (CNN) as a multi-class classification framework
where each class designates a different subarray. The proposed network
determines a new array every time data is received by the radar, thereby making
antenna selection a cognitive operation. Our numerical experiments show that
the proposed CNN structure outperforms existing random thinning and other
machine learning approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Elbir_A/0/1/0/all/0/1&quot;&gt;Ahmet M. Elbir&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Mishra_K/0/1/0/all/0/1&quot;&gt;Kumar Vijay Mishra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Eldar_Y/0/1/0/all/0/1&quot;&gt;Yonina C. Eldar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09794">
<title>Identification of LTV Dynamical Models with Smooth or Discontinuous Time Evolution by means of Convex Optimization. (arXiv:1802.09794v1 [cs.SY])</title>
<link>http://arxiv.org/abs/1802.09794</link>
<description rdf:parseType="Literal">&lt;p&gt;We establish a connection between trend filtering and system identification
which results in a family of new identification methods for linear,
time-varying (LTV) dynamical models based on convex optimization. We
demonstrate how the design of the cost function promotes a model with either a
continuous change in dynamics over time, or causes discontinuous changes in
model coefficients occurring at a finite (sparse) set of time instances. We
further discuss the introduction of priors on the model parameters for
situations where excitation is insufficient for identification. The
identification problems are cast as convex optimization problems and are
applicable to, e.g., ARX models and state-space models with time-varying
parameters. We illustrate usage of the methods in simulations of jump-linear
systems, a nonlinear robot arm with non-smooth friction and stiff contacts as
well as in model-based, trajectory centric reinforcement learning on a smooth
nonlinear system.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Carlson_F/0/1/0/all/0/1&quot;&gt;Fredrik Bagge Carlson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Robertsson_A/0/1/0/all/0/1&quot;&gt;Anders Robertsson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Johansson_R/0/1/0/all/0/1&quot;&gt;Rolf Johansson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09841">
<title>Adversarial Active Learning for Deep Networks: a Margin Based Approach. (arXiv:1802.09841v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.09841</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a new active learning strategy designed for deep neural networks.
The goal is to minimize the number of data annotation queried from an oracle
during training. Previous active learning strategies scalable for deep networks
were mostly based on uncertain sample selection. In this work, we focus on
examples lying close to the decision boundary. Based on theoretical works on
margin theory for active learning, we know that such examples may help to
considerably decrease the number of annotations. While measuring the exact
distance to the decision boundaries is intractable, we propose to rely on
adversarial examples. We do not consider anymore them as a threat instead we
exploit the information they provide on the distribution of the input space in
order to approximate the distance to decision boundaries. We demonstrate
empirically that adversarial active queries yield faster convergence of CNNs
trained on MNIST, the Shoe-Bag and the Quick-Draw datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ducoffe_M/0/1/0/all/0/1&quot;&gt;Melanie Ducoffe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Precioso_F/0/1/0/all/0/1&quot;&gt;Frederic Precioso&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09902">
<title>Attention-Based Guided Structured Sparsity of Deep Neural Networks. (arXiv:1802.09902v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.09902</link>
<description rdf:parseType="Literal">&lt;p&gt;Network pruning is aimed at imposing sparsity in a neural network
architecture by increasing the portion of zero-valued weights for reducing its
size regarding energy-efficiency consideration and increasing evaluation speed.
In most of the conducted research efforts, the sparsity is enforced for network
pruning without any attention to the internal network characteristics such as
unbalanced outputs of the neurons or more specifically the distribution of the
weights and outputs of the neurons. That may cause severe accuracy drop due to
uncontrolled sparsity. In this work, we propose an attention mechanism that
simultaneously controls the sparsity intensity and supervised network pruning
by keeping important information bottlenecks of the network to be active. On
CIFAR-10, the proposed method outperforms the best baseline method by 6% and
reduced the accuracy drop by 2.6x at the same level of sparsity.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Torfi_A/0/1/0/all/0/1&quot;&gt;Amirsina Torfi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shirvani_R/0/1/0/all/0/1&quot;&gt;Rouzbeh A. Shirvani&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09932">
<title>VR-SGD: A Simple Stochastic Variance Reduction Method for Machine Learning. (arXiv:1802.09932v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.09932</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we propose a simple variant of the original SVRG, called
variance reduced stochastic gradient descent (VR-SGD). Unlike the choices of
snapshot and starting points in SVRG and its proximal variant, Prox-SVRG, the
two vectors of VR-SGD are set to the average and last iterate of the previous
epoch, respectively. The settings allow us to use much larger learning rates,
and also make our convergence analysis more challenging. We also design two
different update rules for smooth and non-smooth objective functions,
respectively, which means that VR-SGD can tackle non-smooth and/or non-strongly
convex problems directly without any reduction techniques. Moreover, we analyze
the convergence properties of VR-SGD for strongly convex problems, which show
that VR-SGD attains linear convergence. Different from its counterparts that
have no convergence guarantees for non-strongly convex problems, we also
provide the convergence guarantees of VR-SGD for this case, and empirically
verify that VR-SGD with varying learning rates achieves similar performance to
its momentum accelerated variant that has the optimal convergence rate
$\mathcal{O}(1/T^2)$. Finally, we apply VR-SGD to solve various machine
learning problems, such as convex and non-convex empirical risk minimization,
leading eigenvalue computation, and neural networks. Experimental results show
that VR-SGD converges significantly faster than SVRG and Prox-SVRG, and usually
outperforms state-of-the-art accelerated methods, e.g., Katyusha.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shang_F/0/1/0/all/0/1&quot;&gt;Fanhua Shang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_K/0/1/0/all/0/1&quot;&gt;Kaiwen Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_J/0/1/0/all/0/1&quot;&gt;James Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tsang_I/0/1/0/all/0/1&quot;&gt;Ivor W. Tsang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1&quot;&gt;Lijun Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tao_D/0/1/0/all/0/1&quot;&gt;Dacheng Tao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09933">
<title>Guaranteed Sufficient Decrease for Stochastic Variance Reduced Gradient Optimization. (arXiv:1802.09933v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.09933</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we propose a novel sufficient decrease technique for
stochastic variance reduced gradient descent methods such as SVRG and SAGA. In
order to make sufficient decrease for stochastic optimization, we design a new
sufficient decrease criterion, which yields sufficient decrease versions of
stochastic variance reduction algorithms such as SVRG-SD and SAGA-SD as a
byproduct. We introduce a coefficient to scale current iterate and to satisfy
the sufficient decrease property, which takes the decisions to shrink, expand
or even move in the opposite direction, and then give two specific update rules
of the coefficient for Lasso and ridge regression. Moreover, we analyze the
convergence properties of our algorithms for strongly convex problems, which
show that our algorithms attain linear convergence rates. We also provide the
convergence guarantees of our algorithms for non-strongly convex problems. Our
experimental results further verify that our algorithms achieve significantly
better performance than their counterparts.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Shang_F/0/1/0/all/0/1&quot;&gt;Fanhua Shang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yuanyuan Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhou_K/0/1/0/all/0/1&quot;&gt;Kaiwen Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Cheng_J/0/1/0/all/0/1&quot;&gt;James Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ng_K/0/1/0/all/0/1&quot;&gt;Kelvin K.W. Ng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yoshida_Y/0/1/0/all/0/1&quot;&gt;Yuichi Yoshida&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09963">
<title>Breaking the $1/\sqrt{n}$ Barrier: Faster Rates for Permutation-based Models in Polynomial Time. (arXiv:1802.09963v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.09963</link>
<description rdf:parseType="Literal">&lt;p&gt;Many applications, including rank aggregation and crowd-labeling, can be
modeled in terms of a bivariate isotonic matrix with unknown permutations
acting on its rows and columns. We consider the problem of estimating such a
matrix based on noisy observations of a subset of its entries, and design and
analyze polynomial-time algorithms that improve upon the state of the art. In
particular, our results imply that any such $n \times n$ matrix can be
estimated efficiently in the normalized Frobenius norm at rate
$\widetilde{\mathcal O}(n^{-3/4})$, thus narrowing the gap between
$\widetilde{\mathcal O}(n^{-1})$ and $\widetilde{\mathcal O}(n^{-1/2})$, which
were hitherto the rates of the most statistically and computationally efficient
methods, respectively.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mao_C/0/1/0/all/0/1&quot;&gt;Cheng Mao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pananjady_A/0/1/0/all/0/1&quot;&gt;Ashwin Pananjady&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wainwright_M/0/1/0/all/0/1&quot;&gt;Martin J. Wainwright&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.10031">
<title>The Mirage of Action-Dependent Baselines in Reinforcement Learning. (arXiv:1802.10031v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.10031</link>
<description rdf:parseType="Literal">&lt;p&gt;Policy gradient methods are a widely used class of model-free reinforcement
learning algorithms where a state-dependent baseline is used to reduce gradient
estimator variance. Several recent papers extend the baseline to depend on both
the state and action and suggest that this significantly reduces variance and
improves sample efficiency without introducing bias into the gradient
estimates. To better understand this development, we decompose the variance of
the policy gradient estimator and numerically show that learned
state-action-dependent baselines do not in fact reduce variance over a
state-dependent baseline in commonly tested benchmark domains. We confirm this
unexpected result by reviewing the open-source code accompanying these prior
papers, and show that subtle implementation decisions cause deviations from the
methods presented in the papers and explain the source of the previously
observed empirical gains. Furthermore, the variance decomposition highlights
areas for improvement, which we demonstrate by illustrating a simple change to
the typical value function parameterization that can significantly improve
performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tucker_G/0/1/0/all/0/1&quot;&gt;George Tucker&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bhupatiraju_S/0/1/0/all/0/1&quot;&gt;Surya Bhupatiraju&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gu_S/0/1/0/all/0/1&quot;&gt;Shixiang Gu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Turner_R/0/1/0/all/0/1&quot;&gt;Richard E. Turner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghahramani_Z/0/1/0/all/0/1&quot;&gt;Zoubin Ghahramani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1&quot;&gt;Sergey Levine&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1504.06964">
<title>Modeling Recovery Curves With Application to Prostatectomy. (arXiv:1504.06964v5 [stat.ME] UPDATED)</title>
<link>http://arxiv.org/abs/1504.06964</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a Bayesian model that predicts recovery curves based on
information available before the disruptive event. A recovery curve of interest
is the quantified sexual function of prostate cancer patients after
prostatectomy surgery. We illustrate the utility of our model as a
pre-treatment medical decision aid, producing personalized predictions that are
both interpretable and accurate. We uncover covariate relationships that agree
with and supplement that in existing medical literature.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wang_F/0/1/0/all/0/1&quot;&gt;Fulton Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+McCormick_T/0/1/0/all/0/1&quot;&gt;Tyler H. McCormick&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rudin_C/0/1/0/all/0/1&quot;&gt;Cynthia Rudin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gore_J/0/1/0/all/0/1&quot;&gt;John Gore&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1611.02440">
<title>A Bayesian optimization approach to find Nash equilibria. (arXiv:1611.02440v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1611.02440</link>
<description rdf:parseType="Literal">&lt;p&gt;Game theory finds nowadays a broad range of applications in engineering and
machine learning. However, in a derivative-free, expensive black-box context,
very few algorithmic solutions are available to find game equilibria. Here, we
propose a novel Gaussian-process based approach for solving games in this
context. We follow a classical Bayesian optimization framework, with sequential
sampling decisions based on acquisition functions. Two strategies are proposed,
based either on the probability of achieving equilibrium or on the Stepwise
Uncertainty Reduction paradigm. Practical and numerical aspects are discussed
in order to enhance the scalability and reduce computation time. Our approach
is evaluated on several synthetic game problems with varying number of players
and decision space dimensions. We show that equilibria can be found reliably
for a fraction of the cost (in terms of black-box evaluations) compared to
classical, derivative-based algorithms. The method is available in the R
package GPGame available on CRAN at https://cran.r-project.org/package=GPGame.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Picheny_V/0/1/0/all/0/1&quot;&gt;Victor Picheny&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Binois_M/0/1/0/all/0/1&quot;&gt;Mickael Binois&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Habbal_A/0/1/0/all/0/1&quot;&gt;Abderrahmane Habbal&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1704.09011">
<title>Mostly Exploration-Free Algorithms for Contextual Bandits. (arXiv:1704.09011v4 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1704.09011</link>
<description rdf:parseType="Literal">&lt;p&gt;The contextual bandit literature has traditionally focused on algorithms that
address the exploration-exploitation tradeoff. In particular, greedy algorithms
that exploit current estimates without any exploration may be sub-optimal in
general. However, exploration-free greedy algorithms are desirable in practical
settings where exploration may be costly or unethical (e.g., clinical trials).
Surprisingly, we find that a simple greedy algorithm can be rate-optimal if
there is sufficient randomness in the observed contexts. We prove that this is
always the case for a two-armed bandit under a general class of context
distributions that satisfy a condition we term covariate diversity.
Furthermore, even absent this condition, we show that a greedy algorithm can be
rate-optimal with nonzero probability. Thus, standard bandit algorithms may
unnecessarily explore. Motivated by these results, we introduce Greedy-First, a
new algorithm that uses only observed contexts and rewards to determine whether
to follow a greedy algorithm or to explore. We prove that this algorithm is
rate-optimal without any additional assumptions on the context distribution or
the number of arms. Extensive simulations demonstrate that Greedy-First
successfully reduces experimentation and outperforms existing
(exploration-based) contextual bandit algorithms such as Thompson sampling or
UCB.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bastani_H/0/1/0/all/0/1&quot;&gt;Hamsa Bastani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bayati_M/0/1/0/all/0/1&quot;&gt;Mohsen Bayati&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Khosravi_K/0/1/0/all/0/1&quot;&gt;Khashayar Khosravi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1705.10467">
<title>Federated Multi-Task Learning. (arXiv:1705.10467v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1705.10467</link>
<description rdf:parseType="Literal">&lt;p&gt;Federated learning poses new statistical and systems challenges in training
machine learning models over distributed networks of devices. In this work, we
show that multi-task learning is naturally suited to handle the statistical
challenges of this setting, and propose a novel systems-aware optimization
method, MOCHA, that is robust to practical systems issues. Our method and
theory for the first time consider issues of high communication cost,
stragglers, and fault tolerance for distributed multi-task learning. The
resulting method achieves significant speedups compared to alternatives in the
federated setting, as we demonstrate through simulations on real-world
federated datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Smith_V/0/1/0/all/0/1&quot;&gt;Virginia Smith&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chiang_C/0/1/0/all/0/1&quot;&gt;Chao-Kai Chiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sanjabi_M/0/1/0/all/0/1&quot;&gt;Maziar Sanjabi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Talwalkar_A/0/1/0/all/0/1&quot;&gt;Ameet Talwalkar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1707.03815">
<title>Deep Gaussian Embedding of Graphs: Unsupervised Inductive Learning via Ranking. (arXiv:1707.03815v4 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1707.03815</link>
<description rdf:parseType="Literal">&lt;p&gt;Methods that learn representations of nodes in a graph play a critical role
in network analysis since they enable many downstream learning tasks. We
propose Graph2Gauss - an approach that can efficiently learn versatile node
embeddings on large scale (attributed) graphs that show strong performance on
tasks such as link prediction and node classification. Unlike most approaches
that represent nodes as point vectors in a low-dimensional continuous space, we
embed each node as a Gaussian distribution, allowing us to capture uncertainty
about the representation. Furthermore, we propose an unsupervised method that
handles inductive learning scenarios and is applicable to different types of
graphs: plain/attributed, directed/undirected. By leveraging both the network
structure and the associated node attributes, we are able to generalize to
unseen nodes without additional training. To learn the embeddings we adopt a
personalized ranking formulation w.r.t. the node distances that exploits the
natural ordering of the nodes imposed by the network structure. Experiments on
real world networks demonstrate the high performance of our approach,
outperforming state-of-the-art network embedding methods on several different
tasks. Additionally, we demonstrate the benefits of modeling uncertainty - by
analyzing it we can estimate neighborhood diversity and detect the intrinsic
latent dimensionality of a graph.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bojchevski_A/0/1/0/all/0/1&quot;&gt;Aleksandar Bojchevski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gunnemann_S/0/1/0/all/0/1&quot;&gt;Stephan G&amp;#xfc;nnemann&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.01233">
<title>Linear Optimal Low Rank Projection for High-Dimensional Multi-Class Data. (arXiv:1709.01233v5 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1709.01233</link>
<description rdf:parseType="Literal">&lt;p&gt;Classifying samples into categories becomes intractable when a single sample
can have millions to billions of features, such as in genetics or imaging data.
Principal Components Analysis (PCA) is widely used to identify a
low-dimensional representation of such features for further analysis. However,
PCA ignores class labels, such as whether or not a subject has cancer, thereby
discarding information that could substantially improve downstream
classification performance. We describe an approach, &quot;Linear Optimal Low-rank&quot;
projection (LOL), which extends PCA by incorporating the class labels in a
fashion that is advantageous over existing supervised dimensionality reduction
techniques. We prove, and substantiate with synthetic experiments, that LOL
leads to a better representation of the data for subsequent classification than
other linear approaches, while adding negligible computational cost. We then
demonstrate that LOL substantially outperforms PCA in differentiating cancer
patients from healthy controls using genetic data, and in differentiating
gender using magnetic resonance imaging data with $&amp;gt;$500 million features and
400 gigabytes of data. LOL therefore allows the solution of previous
intractable problems, yet requires only a few minutes to run on a desktop
computer.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Vogelstein_J/0/1/0/all/0/1&quot;&gt;Joshua T. Vogelstein&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tang_M/0/1/0/all/0/1&quot;&gt;Minh Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bridgeford_E/0/1/0/all/0/1&quot;&gt;Eric Bridgeford&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zheng_D/0/1/0/all/0/1&quot;&gt;Da Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Burns_R/0/1/0/all/0/1&quot;&gt;Randal Burns&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Maggioni_M/0/1/0/all/0/1&quot;&gt;Mauro Maggioni&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.06564">
<title>Replacement AutoEncoder: A Privacy-Preserving Algorithm for Sensory Data Analysis. (arXiv:1710.06564v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1710.06564</link>
<description rdf:parseType="Literal">&lt;p&gt;An increasing number of sensors on mobile, Internet of things (IoT), and
wearable devices generate time-series measurements of physical activities.
Though access to the sensory data is critical to the success of many beneficial
applications such as health monitoring or activity recognition, a wide range of
potentially sensitive information about the individuals can also be discovered
through access to sensory data and this cannot easily be protected using
traditional privacy approaches.
&lt;/p&gt;
&lt;p&gt;In this paper, we propose a privacy-preserving sensing framework for managing
access to time-series data in order to provide utility while protecting
individuals&apos; privacy. We introduce Replacement AutoEncoder, a novel algorithm
which learns how to transform discriminative features of data that correspond
to sensitive inferences, into some features that have been more observed in
non-sensitive inferences, to protect users&apos; privacy. This efficiency is
achieved by defining a user-customized objective function for deep
autoencoders. Our replacement method will not only eliminate the possibility of
recognizing sensitive inferences, it also eliminates the possibility of
detecting the occurrence of them. That is the main weakness of other approaches
such as filtering or randomization. We evaluate the efficacy of the algorithm
with an activity recognition task in a multi-sensing environment using
extensive experiments on three benchmark datasets. We show that it can retain
the recognition accuracy of state-of-the-art techniques while simultaneously
preserving the privacy of sensitive information. Finally, we utilize the GANs
for detecting the occurrence of replacement, after releasing data, and show
that this can be done only if the adversarial network is trained on the users&apos;
original data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Malekzadeh_M/0/1/0/all/0/1&quot;&gt;Mohammad Malekzadeh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Clegg_R/0/1/0/all/0/1&quot;&gt;Richard G. Clegg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Haddadi_H/0/1/0/all/0/1&quot;&gt;Hamed Haddadi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.10230">
<title>Not-So-Random Features. (arXiv:1710.10230v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1710.10230</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a principled method for kernel learning, which relies on a
Fourier-analytic characterization of translation-invariant or
rotation-invariant kernels. Our method produces a sequence of feature maps,
iteratively refining the SVM margin. We provide rigorous guarantees for
optimality and generalization, interpreting our algorithm as online
equilibrium-finding dynamics in a certain two-player min-max game. Evaluations
on synthetic and real-world datasets demonstrate scalability and consistent
improvements over related random features-based methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bullins_B/0/1/0/all/0/1&quot;&gt;Brian Bullins&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1&quot;&gt;Cyril Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yi Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.06711">
<title>Manifold learning with bi-stochastic kernels. (arXiv:1711.06711v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1711.06711</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper we answer the following question: what is the infinitesimal
generator of the diffusion process defined by a kernel that is normalized such
that it is bi-stochastic with respect to a specified measure? More precisely,
under the assumption that data is sampled from a Riemannian manifold we
determine how the resulting infinitesimal generator depends on the potentially
nonuniform distribution of the sample points, and the specified measure for the
bi-stochastic normalization. In a special case, we demonstrate a connection to
the heat kernel. We consider both the case where only a single data set is
given, and the case where a data set and a reference set are given. The
spectral theory of the constructed operators is studied, and Nystr\&quot;om
extension formulas for the gradients of the eigenfunctions are computed.
Applications to discrete point sets and manifold learning are discussed.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Marshall_N/0/1/0/all/0/1&quot;&gt;Nicholas F. Marshall&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Coifman_R/0/1/0/all/0/1&quot;&gt;Ronald R. Coifman&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.08289">
<title>Learning and Transferring IDs Representation in E-commerce. (arXiv:1712.08289v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1712.08289</link>
<description rdf:parseType="Literal">&lt;p&gt;Many machine intelligence techniques are developed in E-commerce and one of
the most essential components is the representation of IDs, including user ID,
item ID, product ID, store ID, brand ID, category ID etc. The classical
encoding based methods (like one-hot encoding) are inefficient in that it
suffers sparsity problems due to its high dimension, and it cannot reflect the
relationships among IDs, either homogeneous or heterogeneous ones. In this
paper, we propose an embedding based framework to learn and transfer the
representation of IDs. As the the implicit feedbacks of users, a tremendous
amount of item ID sequences can be easily collected from the interactive
sessions. By jointly using these informative sequences and the structural
connections among IDs, all types of IDs can be embedded into one
low-dimensional semantic space. Subsequently, the learned representations are
utilized and transferred in four scenarios: (i) measuring the similarity
between items, (ii) transferring from seen items to unseen items, (iii)
transferring across different domains, (iv) transferring across different
tasks. We deploy and evaluate the proposed approach in Hema App and the results
validate its effectiveness.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_K/0/1/0/all/0/1&quot;&gt;Kui Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yuechuan Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shuai_Z/0/1/0/all/0/1&quot;&gt;Zhaoqian Shuai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1&quot;&gt;Cheng Yang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.00823">
<title>MVG Mechanism: Differential Privacy under Matrix-Valued Query. (arXiv:1801.00823v2 [cs.CR] UPDATED)</title>
<link>http://arxiv.org/abs/1801.00823</link>
<description rdf:parseType="Literal">&lt;p&gt;Differential privacy mechanism design has traditionally been tailored for a
scalar-valued query function. Although many mechanisms such as the Laplace and
Gaussian mechanisms can be extended to a matrix-valued query function by adding
i.i.d. noise to each element of the matrix, this method is often suboptimal as
it forfeits an opportunity to exploit the structural characteristics typically
associated with matrix analysis. To address this challenge, we propose a novel
differential privacy mechanism called the Matrix-Variate Gaussian (MVG)
mechanism, which adds a matrix-valued noise drawn from a matrix-variate
Gaussian distribution, and we rigorously prove that the MVG mechanism preserves
$(\epsilon,\delta)$-differential privacy. Furthermore, we introduce the concept
of directional noise made possible by the design of the MVG mechanism.
Directional noise allows the impact of the noise on the utility of the
matrix-valued query function to be moderated. Finally, we experimentally
demonstrate the performance of our mechanism using three matrix-valued queries
on three privacy-sensitive datasets. We find that the MVG mechanism notably
outperforms four previous state-of-the-art approaches, and provides comparable
utility to the non-private baseline.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chanyaswad_T/0/1/0/all/0/1&quot;&gt;Thee Chanyaswad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dytso_A/0/1/0/all/0/1&quot;&gt;Alex Dytso&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Poor_H/0/1/0/all/0/1&quot;&gt;H. Vincent Poor&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mittal_P/0/1/0/all/0/1&quot;&gt;Prateek Mittal&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.03848">
<title>Region Detection in Markov Random Fields: Gaussian Case. (arXiv:1802.03848v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1802.03848</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work we consider the problem of model selection in Gaussian Markov
fields in the sample deficient scenario. The benchmark information-theoretic
results in the case of d-regular graphs require the number of samples to be at
least proportional to the logarithm of the number of vertices to allow
consistent graph recovery. When the number of samples is less than this amount,
reliable detection of all edges is impossible. In many applications, it is more
important to learn the distribution of the edge (coupling) parameters over the
network than the specific locations of the edges. Assuming that the entire
graph can be partitioned into a number of spatial regions with similar edge
parameters and reasonably regular boundaries, we develop new
information-theoretic sample complexity bounds and show that even bounded
number of samples can be enough to consistently recover these regions. We also
introduce and analyze an efficient region growing algorithm capable of
recovering the regions with high accuracy. We show that it is consistent and
demonstrate its performance benefits in synthetic simulations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Soloveychik_I/0/1/0/all/0/1&quot;&gt;Ilya Soloveychik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tarokh_V/0/1/0/all/0/1&quot;&gt;Vahid Tarokh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09246">
<title>Scalable kernel-based variable selection with sparsistency. (arXiv:1802.09246v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1802.09246</link>
<description rdf:parseType="Literal">&lt;p&gt;Variable selection is central to high-dimensional data analysis, and various
algorithms have been developed. Ideally, a variable selection algorithm shall
be flexible, scalable, and with theoretical guarantee, yet most existing
algorithms cannot attain these properties at the same time. In this article, a
three-step variable selection algorithm is developed, involving kernel-based
estimation of the regression function and its gradient functions as well as a
hard thresholding. Its key advantage is that it assumes no explicit model
assumption, admits general predictor effects, allows for scalable computation,
and attains desirable asymptotic sparsistency. The proposed algorithm can be
adapted to any reproducing kernel Hilbert space (RKHS) with different kernel
functions, and can be extended to interaction selection with slight
modification. Its computational cost is only linear in the data dimension, and
can be further improved through parallel computing. The sparsistency of the
proposed algorithm is established for general RKHS under mild conditions,
including linear and Gaussian kernels as special cases. Its effectiveness is
also supported by a variety of simulated and real examples.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+He_X/0/1/0/all/0/1&quot;&gt;Xin He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Junhui Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lv_S/0/1/0/all/0/1&quot;&gt;Shaogao Lv&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08714">
<title>Deep Multi-View Spatial-Temporal Network for Taxi Demand Prediction. (arXiv:1802.08714v2 [cs.LG] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1802.08714</link>
<description rdf:parseType="Literal">&lt;p&gt;Taxi demand prediction is an important building block to enabling intelligent
transportation systems in a smart city. An accurate prediction model can help
the city pre-allocate resources to meet travel demand and to reduce empty taxis
on streets which waste energy and worsen the traffic congestion. With the
increasing popularity of taxi requesting services such as Uber and Didi Chuxing
(in China), we are able to collect large-scale taxi demand data continuously.
How to utilize such big data to improve the demand prediction is an interesting
and critical real-world problem. Traditional demand prediction methods mostly
rely on time series forecasting techniques, which fail to model the complex
non-linear spatial and temporal relations. Recent advances in deep learning
have shown superior performance on traditionally challenging tasks such as
image classification by learning the complex features and correlations from
large-scale data. This breakthrough has inspired researchers to explore deep
learning techniques on traffic prediction problems. However, existing methods
on traffic prediction have only considered spatial relation (e.g., using CNN)
or temporal relation (e.g., using LSTM) independently. We propose a Deep
Multi-View Spatial-Temporal Network (DMVST-Net) framework to model both spatial
and temporal relations. Specifically, our proposed model consists of three
views: temporal view (modeling correlations between future demand values with
near time points via LSTM), spatial view (modeling local spatial correlation
via local CNN), and semantic view (modeling correlations among regions sharing
similar temporal patterns). Experiments on large-scale real taxi demand data
demonstrate effectiveness of our approach over state-of-the-art methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yao_H/0/1/0/all/0/1&quot;&gt;Huaxiu Yao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_F/0/1/0/all/0/1&quot;&gt;Fei Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ke_J/0/1/0/all/0/1&quot;&gt;Jintao Ke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_X/0/1/0/all/0/1&quot;&gt;Xianfeng Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jia_Y/0/1/0/all/0/1&quot;&gt;Yitian Jia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_S/0/1/0/all/0/1&quot;&gt;Siyu Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gong_P/0/1/0/all/0/1&quot;&gt;Pinghua Gong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1&quot;&gt;Jieping Ye&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Zhenhui Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09514">
<title>Best Arm Identification for Contaminated Bandits. (arXiv:1802.09514v1 [math.ST] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1802.09514</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose the Contaminated Best Arm Identification variant of the
Multi-Armed Bandit problem, in which every arm pull has some probability
$\varepsilon$ of generating a sample from an arbitrary \emph{contamination}
distribution instead of the \emph{true} underlying distribution. We would still
like to guarantee that we can identify the best (or approximately best) true
distribution with high probability, as well as provide guarantees on how good
that arm&apos;s underlying distribution is. It is simple to see that in this
contamination model, there are no consistent estimators for statistics (e.g.
median) of the underlying distribution, and that even with infinite samples
they can be estimated only up to some unavoidable bias. We give novel tight,
finite-sample complexity bounds for estimating the first two robust moments
(median and median absolute deviation) with high probability. We then show how
to use these algorithmically for our problem by adapting Best Arm
Identification algorithms from the classical Multi-Armed Bandit literature. We
present matching upper and lower bounds (up to a small logarithmic factor) on
these algorithm&apos;s sample complexity. These results suggest an inherent
robustness of classical Best Arm Identification algorithm.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Altschuler_J/0/1/0/all/0/1&quot;&gt;Jason Altschuler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Brunel_V/0/1/0/all/0/1&quot;&gt;Victor-Emmanuel Brunel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Malek_A/0/1/0/all/0/1&quot;&gt;Alan Malek&lt;/a&gt;</dc:creator>
</item></rdf:RDF>