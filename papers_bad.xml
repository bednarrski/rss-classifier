<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Boring papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Bad Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-07-25T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.09374"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.09488"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1708.06525"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.06704"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.03294"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.07741"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.09358"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.09388"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.09530"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.09647"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.09754"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.06871"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.05931"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.10217"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.02348"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.05464"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.08920"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.09289"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.09306"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.09331"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.09356"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.09386"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.09387"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.09419"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.09462"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.09571"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.09586"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.09596"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.09705"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.09737"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.09741"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1705.06211"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.00515"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.07615"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.03877"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.06722"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.07306"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1807.09374">
<title>Unsupervised Learning with Self-Organizing Spiking Neural Networks. (arXiv:1807.09374v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1807.09374</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a system comprising a hybridization of self-organized map (SOM)
properties with spiking neural networks (SNNs) that retain many of the features
of SOMs. Networks are trained in an unsupervised manner to learn a
self-organized lattice of filters via excitatory-inhibitory interactions among
populations of neurons. We develop and test various inhibition strategies, such
as growing with inter-neuron distance and two distinct levels of inhibition.
The quality of the unsupervised learning algorithm is evaluated using examples
with known labels. Several biologically-inspired classification tools are
proposed and compared, including population-level confidence rating, and
n-grams using spike motif algorithm. Using the optimal choice of parameters,
our approach produces improvements over state-of-art spiking neural networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hazan_H/0/1/0/all/0/1&quot;&gt;Hananel Hazan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saunders_D/0/1/0/all/0/1&quot;&gt;Daniel J. Saunders&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sanghavi_D/0/1/0/all/0/1&quot;&gt;Darpan T. Sanghavi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Siegelmann_H/0/1/0/all/0/1&quot;&gt;Hava T. Siegelmann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kozma_R/0/1/0/all/0/1&quot;&gt;Robert Kozma&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.09488">
<title>Prototype Discovery using Quality-Diversity. (arXiv:1807.09488v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1807.09488</link>
<description rdf:parseType="Literal">&lt;p&gt;An iterative computer-aided ideation procedure is introduced, building on
recent quality-diversity algorithms, which search for diverse as well as
high-performing solutions. Dimensionality reduction is used to define a
similarity space, in which solutions are clustered into classes. These classes
are represented by prototypes, which are presented to the user for selection.
In the next iteration, quality-diversity focuses on searching within the
selected class. A quantitative analysis is performed on a 2D airfoil, and a
more complex 3D side view mirror domain shows how computer-aided ideation can
help to enhance engineers&apos; intuition while allowing their design decisions to
influence the design process.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hagg_A/0/1/0/all/0/1&quot;&gt;Alexander Hagg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Asteroth_A/0/1/0/all/0/1&quot;&gt;Alexander Asteroth&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Back_T/0/1/0/all/0/1&quot;&gt;Thomas B&amp;#xe4;ck&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1708.06525">
<title>Neural Network-based Graph Embedding for Cross-Platform Binary Code Similarity Detection. (arXiv:1708.06525v2 [cs.CR] UPDATED)</title>
<link>http://arxiv.org/abs/1708.06525</link>
<description rdf:parseType="Literal">&lt;p&gt;The problem of cross-platform binary code similarity detection aims at
detecting whether two binary functions coming from different platforms are
similar or not. It has many security applications, including plagiarism
detection, malware detection, vulnerability search, etc. Existing approaches
rely on approximate graph matching algorithms, which are inevitably slow and
sometimes inaccurate, and hard to adapt to a new task. To address these issues,
in this work, we propose a novel neural network-based approach to compute the
embedding, i.e., a numeric vector, based on the control flow graph of each
binary function, then the similarity detection can be done efficiently by
measuring the distance between the embeddings for two functions. We implement a
prototype called Gemini. Our extensive evaluation shows that Gemini outperforms
the state-of-the-art approaches by large margins with respect to similarity
detection accuracy. Further, Gemini can speed up prior art&apos;s embedding
generation time by 3 to 4 orders of magnitude and reduce the required training
time from more than 1 week down to 30 minutes to 10 hours. Our real world case
studies demonstrate that Gemini can identify significantly more vulnerable
firmware images than the state-of-the-art, i.e., Genius. Our research showcases
a successful application of deep learning on computer security problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1&quot;&gt;Xiaojun Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1&quot;&gt;Chang Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feng_Q/0/1/0/all/0/1&quot;&gt;Qian Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yin_H/0/1/0/all/0/1&quot;&gt;Heng Yin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_L/0/1/0/all/0/1&quot;&gt;Le Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_D/0/1/0/all/0/1&quot;&gt;Dawn Song&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.06704">
<title>Repeatability Is Not Enough: Learning Affine Regions via Discriminability. (arXiv:1711.06704v3 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1711.06704</link>
<description rdf:parseType="Literal">&lt;p&gt;A method for learning local affine-covariant regions is presented. We show
that maximizing geometric repeatability does not lead to local regions, a.k.a
features,that are reliably matched and this necessitates descriptor-based
learning. We explore factors that influence such learning and registration: the
loss function, descriptor type, geometric parametrization and the trade-off
between matchability and geometric accuracy and propose a novel hard
negative-constant loss function for learning of affine regions. The affine
shape estimator -- AffNet -- trained with the hard negative-constant loss
outperforms the state-of-the-art in bag-of-words image retrieval and wide
baseline stereo. The proposed training process does not require precisely
geometrically aligned patches.The source codes and trained weights are
available at https://github.com/ducha-aiki/affnet
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mishkin_D/0/1/0/all/0/1&quot;&gt;Dmytro Mishkin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Radenovic_F/0/1/0/all/0/1&quot;&gt;Filip Radenovic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Matas_J/0/1/0/all/0/1&quot;&gt;Jiri Matas&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.03294">
<title>A Systematic DNN Weight Pruning Framework using Alternating Direction Method of Multipliers. (arXiv:1804.03294v3 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1804.03294</link>
<description rdf:parseType="Literal">&lt;p&gt;Weight pruning methods for deep neural networks (DNNs) have been investigated
recently, but prior work in this area is mainly heuristic, iterative pruning,
thereby lacking guarantees on the weight reduction ratio and convergence time.
To mitigate these limitations, we present a systematic weight pruning framework
of DNNs using the alternating direction method of multipliers (ADMM). We first
formulate the weight pruning problem of DNNs as a nonconvex optimization
problem with combinatorial constraints specifying the sparsity requirements,
and then adopt the ADMM framework for systematic weight pruning. By using ADMM,
the original nonconvex optimization problem is decomposed into two subproblems
that are solved iteratively. One of these subproblems can be solved using
stochastic gradient descent, the other can be solved analytically. Besides, our
method achieves a fast convergence rate.
&lt;/p&gt;
&lt;p&gt;The weight pruning results are very promising and consistently outperform the
prior work. On the LeNet-5 model for the MNIST data set, we achieve 71.2 times
weight reduction without accuracy loss. On the AlexNet model for the ImageNet
data set, we achieve 21 times weight reduction without accuracy loss. When we
focus on the convolutional layer pruning for computation reductions, we can
reduce the total computation by five times compared with the prior work
(achieving a total of 13.4 times weight reduction in convolutional layers). Our
models and codes are released at https://github.com/KaiqiZhang/admm-pruning
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_T/0/1/0/all/0/1&quot;&gt;Tianyun Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ye_S/0/1/0/all/0/1&quot;&gt;Shaokai Ye&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_K/0/1/0/all/0/1&quot;&gt;Kaiqi Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1&quot;&gt;Jian Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wen_W/0/1/0/all/0/1&quot;&gt;Wujie Wen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fardad_M/0/1/0/all/0/1&quot;&gt;Makan Fardad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yanzhi Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.07741">
<title>A large-scale evaluation framework for EEG deep learning architectures. (arXiv:1806.07741v2 [eess.SP] UPDATED)</title>
<link>http://arxiv.org/abs/1806.07741</link>
<description rdf:parseType="Literal">&lt;p&gt;EEG is the most common signal source for noninvasive BCI applications. For
such applications, the EEG signal needs to be decoded and translated into
appropriate actions. A recently emerging EEG decoding approach is deep learning
with Convolutional or Recurrent Neural Networks (CNNs, RNNs) with many
different architectures already published. Here we present a novel framework
for the large-scale evaluation of different deep-learning architectures on
different EEG datasets. This framework comprises (i) a collection of EEG
datasets currently including 100 examples (recording sessions) from six
different classification problems, (ii) a collection of different EEG decoding
algorithms, and (iii) a wrapper linking the decoders to the data as well as
handling structured documentation of all settings and (hyper-) parameters and
statistics, designed to ensure transparency and reproducibility. As an
applications example we used our framework by comparing three publicly
available CNN architectures: the Braindecode Deep4 ConvNet, Braindecode Shallow
ConvNet, and two versions of EEGNet. We also show how our framework can be used
to study similarities and differences in the performance of different decoding
methods across tasks. We argue that the deep learning EEG framework as
described here could help to tap the full potential of deep learning for BCI
applications.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Heilmeyer_F/0/1/0/all/0/1&quot;&gt;Felix A. Heilmeyer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Schirrmeister_R/0/1/0/all/0/1&quot;&gt;Robin T. Schirrmeister&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Fiederer_L/0/1/0/all/0/1&quot;&gt;Lukas D. J. Fiederer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Volker_M/0/1/0/all/0/1&quot;&gt;Martin V&amp;#xf6;lker&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Behncke_J/0/1/0/all/0/1&quot;&gt;Joos Behncke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Ball_T/0/1/0/all/0/1&quot;&gt;Tonio Ball&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.09358">
<title>An Approximation Algorithm for Risk-averse Submodular Optimization. (arXiv:1807.09358v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1807.09358</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the problem of incorporating risk while making combinatorial
decisions under uncertainty. We formulate a discrete submodular maximization
problem for selecting a set using Conditional-Value-at-Risk (CVaR), a risk
metric commonly used in financial analysis. While CVaR has recently been used
in optimization of linear costs functions in robotics, we take the first stages
towards extending this to discrete submodular optimization and provide several
positive results. Specifically, we propose the Sequential Greedy Algorithm that
provides an approximation guarantee on finding the maxima of the CVaR cost
function under a matroidal constraint. The approximation guarantee shows that
the solution produced by our algorithm is within a constant factor of the
optimal and an additive term that depends on the optimal. Our analysis uses the
curvature of the submodular set function, and proves that the algorithm runs in
polynomial time. This formulates a number of combinatorial optimization
problems that appear in robotics. We use two such problems, vehicle assignment
under uncertainty for mobility-on-demand and sensor selection with failures for
environmental monitoring, as case studies to demonstrate the efficacy of our
formulation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_L/0/1/0/all/0/1&quot;&gt;Lifeng Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tokekar_P/0/1/0/all/0/1&quot;&gt;Pratap Tokekar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.09388">
<title>LAPRAN: A Scalable Laplacian Pyramid Reconstructive Adversarial Network for Flexible Compressive Sensing Reconstruction. (arXiv:1807.09388v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1807.09388</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper addresses the single-image compressive sensing (CS) and
reconstruction problem. We propose a scalable Laplacian pyramid reconstructive
adversarial network (LAPRAN) that enables high-fidelity, flexible and fast CS
images reconstruction. LAPRAN progressively reconstructs an image following the
concept of Laplacian pyramid through multiple stages of reconstructive
adversarial networks (RANs). At each pyramid level, CS measurements are fused
with a contextual latent vector to generate a high-frequency image residual.
Consequently, LAPRAN can produce hierarchies of reconstructed images and each
with an incremental resolution and improved quality. The scalable pyramid
structure of LAPRAN enables high-fidelity CS reconstruction with a flexible
resolution that is adaptive to a wide range of compression ratios (CRs), which
is infeasible with existing methods. Experimental results on multiple public
datasets show that LAPRAN offers an average 7.47dB and 5.98dB PSNR, and an
average 57.93% and 33.20% SSIM improvement compared to model-based and
data-driven baselines, respectively.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_K/0/1/0/all/0/1&quot;&gt;Kai Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1&quot;&gt;Zhikang Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ren_F/0/1/0/all/0/1&quot;&gt;Fengbo Ren&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.09530">
<title>Decentralized Cooperative Planning for Automated Vehicles with Hierarchical Monte Carlo Tree Search. (arXiv:1807.09530v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1807.09530</link>
<description rdf:parseType="Literal">&lt;p&gt;Today&apos;s automated vehicles lack the ability to cooperate implicitly with
others. This work presents a Monte Carlo Tree Search (MCTS) based approach for
decentralized cooperative planning using macro-actions for automated vehicles
in heterogeneous environments. Based on cooperative modeling of other agents
and Decoupled-UCT (a variant of MCTS), the algorithm evaluates the
state-action-values of each agent in a cooperative and decentralized manner,
explicitly modeling the interdependence of actions between traffic
participants. Macro-actions allow for temporal extension over multiple time
steps and increase the effective search depth requiring fewer iterations to
plan over longer horizons. Without predefined policies for macro-actions, the
algorithm simultaneously learns policies over and within macro-actions. The
proposed method is evaluated under several conflict scenarios, showing that the
algorithm can achieve effective cooperative planning with learned macro-actions
in heterogeneous environments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kurzer_K/0/1/0/all/0/1&quot;&gt;Karl Kurzer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_C/0/1/0/all/0/1&quot;&gt;Chenyang Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zollner_J/0/1/0/all/0/1&quot;&gt;J. Marius Z&amp;#xf6;llner&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.09647">
<title>Variational Bayesian Reinforcement Learning with Regret Bounds. (arXiv:1807.09647v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.09647</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the exploration-exploitation trade-off in reinforcement learning
and we show that an agent imbued with a risk-seeking utility function is able
to explore efficiently, as measured by regret. The parameter that controls how
risk-seeking the agent is can be optimized exactly, or annealed according to a
schedule. We call the resulting algorithm K-learning and show that the
corresponding K-values are optimistic for the expected Q-values at each
state-action pair. The K-values induce a natural Boltzmann exploration policy
for which the `temperature&apos; parameter is equal to the risk-seeking parameter.
This policy achieves an expected regret bound of $\tilde O(L^{3/2} \sqrt{S A
T})$, where $L$ is the time horizon, $S$ is the number of states, $A$ is the
number of actions, and $T$ is the total number of elapsed time-steps. This
bound is only a factor of $L$ larger than the established lower bound.
K-learning can be interpreted as mirror descent in the policy space, and it is
similar to other well-known methods in the literature, including Q-learning,
soft-Q-learning, and maximum entropy policy gradient, and is closely related to
optimism and count based exploration methods. K-learning is simple to
implement, as it only requires adding a bonus to the reward at each
state-action and then solving a Bellman equation. We conclude with a numerical
example demonstrating that K-learning is competitive with other
state-of-the-art algorithms in practice.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+ODonoghue_B/0/1/0/all/0/1&quot;&gt;Brendan O&amp;#x27;Donoghue&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.09754">
<title>Data Infrastructure and Approaches for Ontology-Based Drug Repurposing. (arXiv:1807.09754v1 [cs.IR])</title>
<link>http://arxiv.org/abs/1807.09754</link>
<description rdf:parseType="Literal">&lt;p&gt;We report development of a data infrastructure for drug repurposing that
takes advantage of two currently available chemical ontologies. The data
infrastructure includes a database of compound- target associations augmented
with molecular ontological labels. It also contains two computational tools for
prediction of new associations. We describe two drug-repurposing systems: one,
Nascent Ontological Information Retrieval for Drug Repurposing (NOIR-DR), based
on an information retrieval strategy, and another, based on non-negative matrix
factorization together with compound similarity, that was inspired by
recommender systems. We report the performance of both tools on a
drug-repurposing task.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Boyer_S/0/1/0/all/0/1&quot;&gt;Stephen Boyer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Griffin_T/0/1/0/all/0/1&quot;&gt;Thomas Griffin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Swaminathan_S/0/1/0/all/0/1&quot;&gt;Sarath Swaminathan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Clarkson_K/0/1/0/all/0/1&quot;&gt;Kenneth L. Clarkson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zubarev_D/0/1/0/all/0/1&quot;&gt;Dmitry Zubarev&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.06871">
<title>Anonymous Hedonic Game for Task Allocation in a Large-Scale Multiple Agent System. (arXiv:1711.06871v2 [cs.MA] UPDATED)</title>
<link>http://arxiv.org/abs/1711.06871</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper proposes a novel game-theoretical autonomous decision-making
framework to address a task allocation problem for a swarm of multiple agents.
We consider cooperation of self-interested agents, and show that our proposed
decentralized algorithm guarantees convergence of agents with social inhibition
to a Nash stable partition (i.e., social agreement) within polynomial time. The
algorithm is simple and executable based on local interactions with neighbor
agents under a strongly-connected communication network and even in
asynchronous environments. We analytically present a mathematical formulation
for computing the lower bound of suboptimality of the solution, and
additionally show that 50% of suboptimality can be at least guaranteed if
social utilities are non-decreasing functions with respect to the number of
co-working agents. The results of numerical experiments confirm that the
proposed framework is scalable, fast adaptable against dynamical environments,
and robust even in a realistic situation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jang_I/0/1/0/all/0/1&quot;&gt;Inmo Jang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shin_H/0/1/0/all/0/1&quot;&gt;Hyo-Sang Shin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tsourdos_A/0/1/0/all/0/1&quot;&gt;Antonios Tsourdos&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.05931">
<title>Faster Learning by Reduction of Data Access Time. (arXiv:1801.05931v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1801.05931</link>
<description rdf:parseType="Literal">&lt;p&gt;Nowadays, the major challenge in machine learning is the Big Data challenge.
The big data problems due to large number of data points or large number of
features in each data point, or both, the training of models have become very
slow. The training time has two major components: Time to access the data and
time to process (learn from) the data. So far, the research has focused only on
the second part, i.e., learning from the data. In this paper, we have proposed
one possible solution to handle the big data problems in machine learning. The
idea is to reduce the training time through reducing data access time by
proposing systematic sampling and cyclic/sequential sampling to select
mini-batches from the dataset. To prove the effectiveness of proposed sampling
techniques, we have used Empirical Risk Minimization, which is commonly used
machine learning problem, for strongly convex and smooth case. The problem has
been solved using SAG, SAGA, SVRG, SAAG-II and MBSGD (Mini-batched SGD), each
using two step determination techniques, namely, constant step size and
backtracking line search method. Theoretical results prove the same convergence
for systematic sampling, cyclic sampling and the widely used random sampling
technique, in expectation. Experimental results with bench marked datasets
prove the efficacy of the proposed sampling techniques and show up to six times
faster training.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chauhan_V/0/1/0/all/0/1&quot;&gt;Vinod Kumar Chauhan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sharma_A/0/1/0/all/0/1&quot;&gt;Anuj Sharma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dahiya_K/0/1/0/all/0/1&quot;&gt;Kalpana Dahiya&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.10217">
<title>Investigating Human Priors for Playing Video Games. (arXiv:1802.10217v3 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1802.10217</link>
<description rdf:parseType="Literal">&lt;p&gt;What makes humans so good at solving seemingly complex video games? Unlike
computers, humans bring in a great deal of prior knowledge about the world,
enabling efficient decision making. This paper investigates the role of human
priors for solving video games. Given a sample game, we conduct a series of
ablation studies to quantify the importance of various priors on human
performance. We do this by modifying the video game environment to
systematically mask different types of visual information that could be used by
humans as priors. We find that removal of some prior knowledge causes a drastic
degradation in the speed with which human players solve the game, e.g. from 2
minutes to over 20 minutes. Furthermore, our results indicate that general
priors, such as the importance of objects and visual consistency, are critical
for efficient game-play. Videos and the game manipulations are available at
https://rach0012.github.io/humanRL_website/
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dubey_R/0/1/0/all/0/1&quot;&gt;Rachit Dubey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Agrawal_P/0/1/0/all/0/1&quot;&gt;Pulkit Agrawal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pathak_D/0/1/0/all/0/1&quot;&gt;Deepak Pathak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Griffiths_T/0/1/0/all/0/1&quot;&gt;Thomas L. Griffiths&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Efros_A/0/1/0/all/0/1&quot;&gt;Alexei A. Efros&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.02348">
<title>Smoothed Action Value Functions for Learning Gaussian Policies. (arXiv:1803.02348v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1803.02348</link>
<description rdf:parseType="Literal">&lt;p&gt;State-action value functions (i.e., Q-values) are ubiquitous in reinforcement
learning (RL), giving rise to popular algorithms such as SARSA and Q-learning.
We propose a new notion of action value defined by a Gaussian smoothed version
of the expected Q-value. We show that such smoothed Q-values still satisfy a
Bellman equation, making them learnable from experience sampled from an
environment. Moreover, the gradients of expected reward with respect to the
mean and covariance of a parameterized Gaussian policy can be recovered from
the gradient and Hessian of the smoothed Q-value function. Based on these
relationships, we develop new algorithms for training a Gaussian policy
directly from a learned smoothed Q-value approximator. The approach is
additionally amenable to proximal optimization by augmenting the objective with
a penalty on KL-divergence from a previous policy. We find that the ability to
learn both a mean and covariance during training leads to significantly
improved results on standard continuous control benchmarks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nachum_O/0/1/0/all/0/1&quot;&gt;Ofir Nachum&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Norouzi_M/0/1/0/all/0/1&quot;&gt;Mohammad Norouzi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tucker_G/0/1/0/all/0/1&quot;&gt;George Tucker&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schuurmans_D/0/1/0/all/0/1&quot;&gt;Dale Schuurmans&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.05464">
<title>Tractable Querying and Learning in Hybrid Domains via Sum-Product Networks. (arXiv:1807.05464v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1807.05464</link>
<description rdf:parseType="Literal">&lt;p&gt;Probabilistic representations, such as Bayesian and Markov networks, are
fundamental to much of statistical machine learning. Thus, learning
probabilistic representations directly from data is a deep challenge, the main
computational bottleneck being inference that is intractable. Tractable
learning is a powerful new paradigm that attempts to learn distributions that
support efficient probabilistic querying. By leveraging local structure,
representations such as sum-product networks (SPNs) can capture high tree-width
models with many hidden layers, essentially a deep architecture, while still
admitting a range of probabilistic queries to be computable in time polynomial
in the network size. The leaf nodes in SPNs, from which more intricate mixtures
are formed, are tractable univariate distributions, and so the literature has
focused on Bernoulli and Gaussian random variables. This is clearly a
restriction for handling mixed discrete-continuous data, especially if the
continuous features are generated from non-parametric and non-Gaussian
distribution families. In this work, we present a framework that systematically
integrates SPN structure learning with weighted model integration, a recently
introduced computational abstraction for performing inference in hybrid
domains, by means of piecewise polynomial approximations of density functions
of arbitrary shape. Our framework is instantiated by exploiting the notion of
propositional abstractions, thus minimally interfering with the SPN structure
learning module, and supports a powerful query interface for conditioning on
interval constraints. Our empirical results show that our approach is
effective, and allows a study of the trade off between the granularity of the
learned model and its predictive power.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bueff_A/0/1/0/all/0/1&quot;&gt;Andreas Bueff&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Speichert_S/0/1/0/all/0/1&quot;&gt;Stefanie Speichert&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Belle_V/0/1/0/all/0/1&quot;&gt;Vaishak Belle&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.08920">
<title>Competitive Inner-Imaging Squeeze and Excitation for Residual Network. (arXiv:1807.08920v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1807.08920</link>
<description rdf:parseType="Literal">&lt;p&gt;Residual Networks make the very deep convolutional architecture works well,
which use the residual unit to supplement the identity mappings. On the other
hand, Squeeze-Excitation (SE) network propose an adaptively recalibrates
channel-wise attention approach to model the relationship of feature maps from
different convolutional channel. In this work, we propose the competitive SE
mechanism for residual network, rescaling value for each channel in this
structure will be determined by residual and identity mappings jointly, this
design enables us to expand the meaning of channel relationship modeling in
residual blocks: the modeling of competition between residual and identity
mappings make identity flow can controll the complement of residual feature
maps for itself. Further, we design a novel pair-view competitive SE block to
shrink the consumption and re-image the global characterizations of
intermediate convolutional channels. We carry out experiments on datasets:
CIFAR, SVHN, ImageNet, the proposed method can be compared with the
state-of-the-art results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1&quot;&gt;Yang Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wen_G/0/1/0/all/0/1&quot;&gt;Guihua Wen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_M/0/1/0/all/0/1&quot;&gt;Mingnan Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dai_D/0/1/0/all/0/1&quot;&gt;Dan Dai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_J/0/1/0/all/0/1&quot;&gt;Jiajiong Ma&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.09289">
<title>Reliable Uncertainty Estimates in Deep Neural Networks using Noise Contrastive Priors. (arXiv:1807.09289v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1807.09289</link>
<description rdf:parseType="Literal">&lt;p&gt;Obtaining reliable uncertainty estimates of neural network predictions is a
long standing challenge. Bayesian neural networks have been proposed as a
solution, but it remains open how to specify the prior. In particular, the
common practice of a standard normal prior in weight space imposes only weak
regularities, causing the function posterior to possibly generalize in
unforeseen ways on out-of-distribution inputs. We propose noise contrastive
priors (NCPs). The key idea is to train the model to output high uncertainty
for data points outside of the training distribution. NCPs do so using an input
prior, which adds noise to the inputs of the current mini batch, and an output
prior, which is a wide distribution given these inputs. NCPs are compatible
with any model that represents predictive uncertainty, are easy to scale, and
yield reliable uncertainty estimates throughout training. Empirically, we show
that NCPs offer clear improvements as an addition to existing baselines. We
demonstrate the scalability on the flight delays data set, where we
significantly improve upon previously published results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hafner_D/0/1/0/all/0/1&quot;&gt;Danijar Hafner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tran_D/0/1/0/all/0/1&quot;&gt;Dustin Tran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Irpan_A/0/1/0/all/0/1&quot;&gt;Alex Irpan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lillicrap_T/0/1/0/all/0/1&quot;&gt;Timothy Lillicrap&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Davidson_J/0/1/0/all/0/1&quot;&gt;James Davidson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.09306">
<title>Automatic Bayesian Density Analysis. (arXiv:1807.09306v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1807.09306</link>
<description rdf:parseType="Literal">&lt;p&gt;Making sense of a dataset in an automatic and unsupervised fashion is a
challenging problem in statistics and AI. Classical approaches for density
estimation, even when taking into account mixtures of probabilistic models, are
not flexible enough to deal with the uncertainty inherent to real-world data:
they are generally restricted to a priori fixed homogeneous likelihood model
and to latent variable structures where expressiveness comes at the price of
tractability. We propose Automatic Bayesian Density Analysis (ABDA) to go
beyond classical mixture model density estimation, casting uncertainty
estimation on both the underlying structure in the data, as well as the
selection of adequate likelihood models for the data---thus statistical data
types of the variable in the data---into a joint inference problem.
Specifically, ABDA relies on a hierarchical model explicitly incorporating
arbitrarily rich collections of likelihood models at a local level, while
capturing global variable interactions by an expressive deep structure built on
a sum-product network. Extensive empirical evidence shows that ABDA is more
accurate than density estimators in the literature at dealing with both kinds
of uncertainties, at modeling and predicting real-world (mixed continuous and
discrete) data in both transductive and inductive scenarios, and at recovering
the statistical data types.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Vergari_A/0/1/0/all/0/1&quot;&gt;Antonio Vergari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Molina_A/0/1/0/all/0/1&quot;&gt;Alejandro Molina&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Peharz_R/0/1/0/all/0/1&quot;&gt;Robert Peharz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ghahramani_Z/0/1/0/all/0/1&quot;&gt;Zoubin Ghahramani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kersting_K/0/1/0/all/0/1&quot;&gt;Kristian Kersting&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Valera_I/0/1/0/all/0/1&quot;&gt;Isabel Valera&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.09331">
<title>Singular Value Decomposition of Operators on Reproducing Kernel Hilbert Spaces. (arXiv:1807.09331v1 [math.FA])</title>
<link>http://arxiv.org/abs/1807.09331</link>
<description rdf:parseType="Literal">&lt;p&gt;Reproducing kernel Hilbert spaces (RKHSs) play an important role in many
statistics and machine learning applications ranging from support vector
machines to Gaussian processes and kernel embeddings of distributions.
Operators acting on such spaces are, for instance, required to embed
conditional probability distributions in order to implement the kernel Bayes
rule and build sequential data models. It was recently shown that transfer
operators such as the Perron-Frobenius or Koopman operator can also be
approximated in a similar fashion using covariance and cross-covariance
operators and that eigenfunctions of these operators can be obtained by solving
associated matrix eigenvalue problems. The goal of this paper is to provide a
solid functional analytic foundation for the eigenvalue decomposition of RKHS
operators and to extend the approach to the singular value decomposition. The
results are illustrated with simple guiding examples.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Mollenhauer_M/0/1/0/all/0/1&quot;&gt;Mattes Mollenhauer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Schuster_I/0/1/0/all/0/1&quot;&gt;Ingmar Schuster&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Klus_S/0/1/0/all/0/1&quot;&gt;Stefan Klus&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Schutte_C/0/1/0/all/0/1&quot;&gt;Christof Sch&amp;#xfc;tte&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.09356">
<title>Iterative Amortized Inference. (arXiv:1807.09356v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.09356</link>
<description rdf:parseType="Literal">&lt;p&gt;Inference models are a key component in scaling variational inference to deep
latent variable models, most notably as encoder networks in variational
auto-encoders (VAEs). By replacing conventional optimization-based inference
with a learned model, inference is amortized over data examples and therefore
more computationally efficient. However, standard inference models are
restricted to direct mappings from data to approximate posterior estimates. The
failure of these models to reach fully optimized approximate posterior
estimates results in an amortization gap. We aim toward closing this gap by
proposing iterative inference models, which learn to perform inference
optimization through repeatedly encoding gradients. Our approach generalizes
standard inference models in VAEs and provides insight into several empirical
findings, including top-down inference techniques. We demonstrate the inference
optimization capabilities of iterative inference models and show that they
outperform standard inference models on several benchmark data sets of images
and text.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Marino_J/0/1/0/all/0/1&quot;&gt;Joseph Marino&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yue_Y/0/1/0/all/0/1&quot;&gt;Yisong Yue&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mandt_S/0/1/0/all/0/1&quot;&gt;Stephan Mandt&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.09386">
<title>On the Randomized Complexity of Minimizing a Convex Quadratic Function. (arXiv:1807.09386v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.09386</link>
<description rdf:parseType="Literal">&lt;p&gt;Minimizing a convex, quadratic objective is a fundamental problem in machine
learning and optimization. In this work, we study prove
\emph{information-theoretic} gradient-query complexity lower bounds for
minimizing convex quadratic functions, which, unlike prior works, apply even
for \emph{randomized} algorithms. Specifically, we construct a distribution
over quadratic functions that witnesses lower bounds which match those known
for deterministic algorithms, up to multiplicative constants. The distribution
which witnesses our lower bound is in fact quite benign: it is both closed
form, and derived from classical ensembles in random matrix theory. We believe
that our construction constitutes a plausible ``average case&apos;&apos; setting, and
thus provides compelling evidence that the worst case and average case
complexity of convex-quadratic optimization are essentially identical.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Simchowitz_M/0/1/0/all/0/1&quot;&gt;Max Simchowitz&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.09387">
<title>Learning from Delayed Outcomes with Intermediate Observations. (arXiv:1807.09387v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.09387</link>
<description rdf:parseType="Literal">&lt;p&gt;Optimizing for long term value is desirable in many practical applications,
e.g. recommender systems. The most common approach for long term value
optimization is supervised learning using long term value as the target.
Unfortunately, long term metrics take a long time to measure (e.g., will
customers finish reading an ebook?), and vanilla forecasters cannot learn from
examples until the outcome is observed. In practical systems where new items
arrive frequently, such delay can increase the training-serving skew, thereby
negatively affecting the model&apos;s predictions for new products. We argue that
intermediate observations (e.g., if customers read a third of the book in 24
hours) can improve a model&apos;s predictions. We formalize the problem as a
semi-stochastic model, where instances are selected by an adversary but, given
an instance, the intermediate observation and the outcome are sampled from a
factored joint distribution. We propose an algorithm that exploits intermediate
observations and theoretically quantify how much it can outperform any
prediction method that ignores the intermediate observations. Motivated by the
theoretical analysis, we propose two neural network architectures: Factored
Forecaster (FF) which is ideal if our assumptions are satisfied, and Residual
Factored Forecaster (RFF) that is more robust to model mis-specification.
Experiments on two real world datasets, a dataset derived from GitHub
repositories and another dataset from a popular marketplace, show that RFF
outperforms both FF as well as an algorithm that ignores intermediate
observations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mann_T/0/1/0/all/0/1&quot;&gt;Timothy A. Mann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gowal_S/0/1/0/all/0/1&quot;&gt;Sven Gowal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_R/0/1/0/all/0/1&quot;&gt;Ray Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_H/0/1/0/all/0/1&quot;&gt;Huiyi Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lakshminarayanan_B/0/1/0/all/0/1&quot;&gt;Balaji Lakshminarayanan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gyorgy_A/0/1/0/all/0/1&quot;&gt;Andras Gyorgy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.09419">
<title>Topics in Random Matrices and Statistical Machine Learning. (arXiv:1807.09419v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1807.09419</link>
<description rdf:parseType="Literal">&lt;p&gt;This thesis consists of two independent parts: random matrices, which form
the first one-third of this thesis, and machine learning, which constitutes the
remaining part. The main results of this thesis are as follows: a necessary and
sufficient condition for the inverse moments of $(m,n,\beta)$-Laguerre matrices
and compound Wishart matrices to be finite; the universal weak consistency and
the strong consistency of the $k$-nearest neighbor rule in metrically
sigma-finite dimensional spaces and metrically finite dimensional spaces
respectively. In Part I, the Chapter 1 introduces the $(m,n,\beta)$-Laguerre
matrix, Wishart and compound Wishart matrix and their joint eigenvalue
distribution. While in Chapter 2, a necessary and sufficient condition to have
finite inverse moments has been derived. In Part II, the Chapter 1 introduces
the various notions of metric dimension and differentiation property followed
by our proof for the necessary part of Preiss&apos; result. Further, Chapter 2 gives
an introduction to the mathematical concepts in statistical machine learning
and then the $k$-nearest neighbor rule is presented in Chapter 3 with a proof
of Stone&apos;s theorem. In chapters 4 and 5, we present our main results and some
possible future directions based on it.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kumari_S/0/1/0/all/0/1&quot;&gt;Sushma Kumari&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.09462">
<title>Propensity score estimation using classification and regression trees in the presence of missing covariate data. (arXiv:1807.09462v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1807.09462</link>
<description rdf:parseType="Literal">&lt;p&gt;Data mining and machine learning techniques such as classification and
regression trees (CART) represent a promising alternative to conventional
logistic regression for propensity score estimation. Whereas incomplete data
preclude the fitting of a logistic regression on all subjects, CART is
appealing in part because some implementations allow for incomplete records to
be incorporated in the tree fitting and provide propensity score estimates for
all subjects. Based on theoretical considerations, we argue that the automatic
handling of missing data by CART may however not be appropriate. Using a series
of simulation experiments, we examined the performance of different approaches
to handling missing covariate data; (i) applying the CART algorithm directly to
the (partially) incomplete data, (ii) complete case analysis, and (iii)
multiple imputation. Performance was assessed in terms of bias in estimating
exposure-outcome effects \add{among the exposed}, standard error, mean squared
error and coverage. Applying the CART algorithm directly to incomplete data
resulted in bias, even in scenarios where data were missing completely at
random. Overall, multiple imputation followed by CART resulted in the best
performance. Our study showed that automatic handling of missing data in CART
can cause serious bias and does not outperform multiple imputation as a means
to account for missing data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Vries_B/0/1/0/all/0/1&quot;&gt;Bas B.L. Penning de Vries&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Smeden_M/0/1/0/all/0/1&quot;&gt;Maarten van Smeden&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Groenwold_R/0/1/0/all/0/1&quot;&gt;Rolf H.H. Groenwold&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.09571">
<title>Deep Learning Detection Networks in MIMO Decode-Forward Relay Channels. (arXiv:1807.09571v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1807.09571</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we consider signal detection algorithms in a multiple-input
multiple-output (MIMO) decode-forward (DF) relay channel with one source, one
relay, and one destination. The existing suboptimal near maximum likelihood
(NML) detector and the NML with two-level pair-wise error probability
(NMLw2PEP) detector achieve excellent performance with instantaneous channel
state information (CSI) of the source-relay (SR) link and with statistical CSI
of the SR link, respectively. However, the NML detectors require an
exponentially increasing complexity as the number of transmit antennas
increases. Using deep learning algorithms, NML-based detection networks
(NMLDNs) are proposed with and without the CSI of the SR link at the
destination. The NMLDNs detect signals in changing channels after a single
training using a large number of randomly distributed channels. The detection
networks require much lower detection complexity than the exhaustive search NML
detectors while exhibiting good performance. To evaluate the performance, we
introduce semidefinite relaxation detectors with polynomial complexity based on
the NML detectors. Additionally, new linear detectors based on the zero
gradient of the NML metrics are proposed. Applying various detection algorithms
at the relay (DetR) and detection algorithms at the destination (DetD), we
present some DetR-DetD methods in MIMO DF relay channels. An appropriate
DetR-DetD method can be employed according to the required error probability
and detection complexity. The complexity analysis and simulation results
validate the arguments of this paper.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Jin_X/0/1/0/all/0/1&quot;&gt;Xianglan Jin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kim_H/0/1/0/all/0/1&quot;&gt;Hyoung-Nam Kim&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.09586">
<title>Perturb and Combine to Identify Influential Spreaders in Real-World Networks. (arXiv:1807.09586v1 [cs.SI])</title>
<link>http://arxiv.org/abs/1807.09586</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent research has shown that graph degeneracy algorithms, which decompose a
network into a hierarchy of nested subgraphs of decreasing size and increasing
density, are very effective at detecting the good spreaders in a network.
However, it is also known that degeneracy-based decompositions of a graph are
unstable to small perturbations of the network structure. In Machine Learning,
the performance of unstable classification and regression methods, such as
fully-grown decision trees, can be greatly improved by using Perturb and
Combine (P&amp;amp;C) strategies such as bagging (bootstrap aggregating). Therefore, we
propose a P&amp;amp;C procedure for networks that (1) creates many perturbed versions
of a given graph, (2) applies a node scoring function separately to each graph
(such as a degeneracy-based one), and (3) combines the results. We conduct
real-world experiments on the tasks of identifying influential spreaders in
large social networks, and influential words (keywords) in small word
co-occurrence networks. We use the k-core, generalized k-core, and PageRank
algorithms as our vertex scoring functions. In each case, using the aggregated
scores brings significant improvements compared to using the scores computed on
the original graphs. Finally, a bias-variance analysis suggests that our P&amp;amp;C
procedure works mainly by reducing bias, and that therefore, it should be
capable of improving the performance of all vertex scoring functions, not only
unstable ones.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tixier_A/0/1/0/all/0/1&quot;&gt;Antoine J.-P. Tixier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rossi_M/0/1/0/all/0/1&quot;&gt;Maria-Evgenia G. Rossi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Malliaros_F/0/1/0/all/0/1&quot;&gt;Fragkiskos D. Malliaros&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Read_J/0/1/0/all/0/1&quot;&gt;Jesse Read&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vazirgiannis_M/0/1/0/all/0/1&quot;&gt;Michalis Vazirgiannis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.09596">
<title>Contextual Stochastic Block Models. (arXiv:1807.09596v1 [cs.SI])</title>
<link>http://arxiv.org/abs/1807.09596</link>
<description rdf:parseType="Literal">&lt;p&gt;We provide the first information theoretic tight analysis for inference of
latent community structure given a sparse graph along with high dimensional
node covariates, correlated with the same latent communities. Our work bridges
recent theoretical breakthroughs in the detection of latent community structure
without nodes covariates and a large body of empirical work using diverse
heuristics for combining node covariates with graphs for inference. The
tightness of our analysis implies in particular, the information theoretical
necessity of combining the different sources of information. Our analysis holds
for networks of large degrees as well as for a Gaussian version of the model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deshpande_Y/0/1/0/all/0/1&quot;&gt;Yash Deshpande&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Montanari_A/0/1/0/all/0/1&quot;&gt;Andrea Montanari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mossel_E/0/1/0/all/0/1&quot;&gt;Elchanan Mossel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sen_S/0/1/0/all/0/1&quot;&gt;Subhabrata Sen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.09705">
<title>Limitations of the Lipschitz constant as a defense against adversarial examples. (arXiv:1807.09705v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.09705</link>
<description rdf:parseType="Literal">&lt;p&gt;Several recent papers have discussed utilizing Lipschitz constants to limit
the susceptibility of neural networks to adversarial examples. We analyze
recently proposed methods for computing the Lipschitz constant. We show that
the Lipschitz constant may indeed enable adversarially robust neural networks.
However, the methods currently employed for computing it suffer from
theoretical and practical limitations. We argue that addressing this
shortcoming is a promising direction for future research into certified
adversarial defenses.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huster_T/0/1/0/all/0/1&quot;&gt;Todd Huster&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chiang_C/0/1/0/all/0/1&quot;&gt;Cho-Yu Jason Chiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chadha_R/0/1/0/all/0/1&quot;&gt;Ritu Chadha&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.09737">
<title>Convergence Rates of Gaussian ODE Filters. (arXiv:1807.09737v1 [math.NA])</title>
<link>http://arxiv.org/abs/1807.09737</link>
<description rdf:parseType="Literal">&lt;p&gt;A recently-introduced class of probabilistic (uncertainty-aware) solvers for
ordinary differential equations (ODEs) applies Gaussian (Kalman) filtering to
initial value problems. These methods model the true solution $x$ and its first
$q$ derivatives a priori as a Gauss--Markov process $\boldsymbol{X}$, which is
then iteratively conditioned on information about $\dot{x}$. We prove
worst-case local convergence rates of order $h^{q+1}$ for a wide range of
versions of this Gaussian ODE filter, as well as global convergence rates of
order $h^q$ in the case of $q=1$ and an integrated Brownian motion prior, and
analyze how inaccurate information on $\dot{x}$ coming from approximate
evaluations of $f$ affects these rates. Moreover, we present explicit formulas
for the steady states and show that the posterior confidence intervals are well
calibrated in all considered cases that exhibit global convergence---in the
sense that they globally contract at the same rate as the truncation error.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Kersting_H/0/1/0/all/0/1&quot;&gt;Hans Kersting&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Sullivan_T/0/1/0/all/0/1&quot;&gt;T. J. Sullivan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Hennig_P/0/1/0/all/0/1&quot;&gt;Philipp Hennig&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.09741">
<title>PADME: A Deep Learning-based Framework for Drug-Target Interaction Prediction. (arXiv:1807.09741v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.09741</link>
<description rdf:parseType="Literal">&lt;p&gt;In silico Drug-target Interaction (DTI) prediction is an important and
challenging problem in medicinal chemistry with a huge potential benefit to the
pharmaceutical industry and patients. Most existing methods for DTI prediction
generally have binary endpoints, which could be an oversimplification of the
problem. With the advent of deep learning, some deep learning models were
devised to solve the DTI prediction problem, but most of them still use binary
endpoints, and they are generally unable to handle cold-target problems, i.e.,
problems involving target protein that never appeared in the training set. We
contrived PADME (Protein And Drug Molecule interaction prEdiction), a framework
based on Deep Neural Networks, to predict real-valued interaction strength
between compounds and proteins. PADME inputs both compound and protein
information into the model, so it is applicable to cold-target problems. To our
knowledge, we are also the first to incorporate Molecular Graph Convolution
(MGC) into the model for compound featurization. We used different
Cross-Validation split schemes and different metrics to measure the performance
of PADME on multiple datasets (in which we are the first to use ToxCast for
such problems), and PADME consistently dominates baseline methods. We also
conducted a case study, predicting the interaction between compounds and
androgen receptor (AR) and compared the prediction results with growth
inhibition activity of the compounds in NCI60, which also gave us satisfactory
results, suggesting PADME&apos;s potential in drug development. We expect different
variants of PADME to be proposed and experimented on in the future, and we
believe Deep Learning will transform the field of cheminformatics.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feng_Q/0/1/0/all/0/1&quot;&gt;Qingyuan Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dueva_E/0/1/0/all/0/1&quot;&gt;Evgenia Dueva&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cherkasov_A/0/1/0/all/0/1&quot;&gt;Artem Cherkasov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ester_M/0/1/0/all/0/1&quot;&gt;Martin Ester&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1705.06211">
<title>An Investigation of Newton-Sketch and Subsampled Newton Methods. (arXiv:1705.06211v3 [math.OC] UPDATED)</title>
<link>http://arxiv.org/abs/1705.06211</link>
<description rdf:parseType="Literal">&lt;p&gt;The concepts of sketching and subsampling have recently received much
attention by the optimization and statistics communities. In this paper, we
study Newton-Sketch and Subsampled Newton (SSN) methods for the finite-sum
optimization problem. We consider practical versions of the two methods in
which the Newton equations are solved approximately using the conjugate
gradient (CG) method or a stochastic gradient iteration. We establish new
complexity results for the SSN-CG method that exploit the spectral properties
of CG. Controlled numerical experiments compare the relative strengths of
Newton-Sketch and SSN methods and show that for many finite-sum problems, they
are far more efficient than SVRG, a popular first-order method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Berahas_A/0/1/0/all/0/1&quot;&gt;Albert S. Berahas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Bollapragada_R/0/1/0/all/0/1&quot;&gt;Raghu Bollapragada&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Nocedal_J/0/1/0/all/0/1&quot;&gt;Jorge Nocedal&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.00515">
<title>A convergence analysis of the perturbed compositional gradient flow: averaging principle and normal deviations. (arXiv:1709.00515v3 [math.PR] UPDATED)</title>
<link>http://arxiv.org/abs/1709.00515</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider in this work a system of two stochastic differential equations
named the perturbed compositional gradient flow. By introducing a separation of
fast and slow scales of the two equations, we show that the limit of the slow
motion is given by an averaged ordinary differential equation. We then
demonstrate that the deviation of the slow motion from the averaged equation,
after proper rescaling, converges to a stochastic process with Gaussian inputs.
This indicates that the slow motion can be approximated in the weak sense by a
standard perturbed gradient flow or the continuous-time stochastic gradient
descent algorithm that solves the optimization problem for a composition of two
functions. As an application, the perturbed compositional gradient flow
corresponds to the diffusion limit of the Stochastic Composite Gradient Descent
(SCGD) algorithm for minimizing a composition of two expected-value functions
in the optimization literatures. For the strongly convex case, such an analysis
implies that the SCGD algorithm has the same convergence time asymptotic as the
classical stochastic gradient descent algorithm. Thus it validates, at the
level of continuous approximation, the effectiveness of using the SCGD
algorithm in the strongly convex case.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Hu_W/0/1/0/all/0/1&quot;&gt;Wenqing Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Li_C/0/1/0/all/0/1&quot;&gt;Chris Junchi Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.07615">
<title>Fast Point Spread Function Modeling with Deep Learning. (arXiv:1801.07615v2 [astro-ph.IM] UPDATED)</title>
<link>http://arxiv.org/abs/1801.07615</link>
<description rdf:parseType="Literal">&lt;p&gt;Modeling the Point Spread Function (PSF) of wide-field surveys is vital for
many astrophysical applications and cosmological probes including weak
gravitational lensing. The PSF smears the image of any recorded object and
therefore needs to be taken into account when inferring properties of galaxies
from astronomical images. In the case of cosmic shear, the PSF is one of the
dominant sources of systematic errors and must be treated carefully to avoid
biases in cosmological parameters. Recently, forward modeling approaches to
calibrate shear measurements within the Monte-Carlo Control Loops ($MCCL$)
framework have been developed. These methods typically require simulating a
large amount of wide-field images, thus, the simulations need to be very fast
yet have realistic properties in key features such as the PSF pattern. Hence,
such forward modeling approaches require a very flexible PSF model, which is
quick to evaluate and whose parameters can be estimated reliably from survey
data. We present a PSF model that meets these requirements based on a fast
deep-learning method to estimate its free parameters. We demonstrate our
approach on publicly available SDSS data. We extract the most important
features of the SDSS sample via principal component analysis. Next, we
construct our model based on perturbations of a fixed base profile, ensuring
that it captures these features. We then train a Convolutional Neural Network
to estimate the free parameters of the model from noisy images of the PSF. This
allows us to render a model image of each star, which we compare to the SDSS
stars to evaluate the performance of our method. We find that our approach is
able to accurately reproduce the SDSS PSF at the pixel level, which, due to the
speed of both the model evaluation and the parameter estimation, offers good
prospects for incorporating our method into the $MCCL$ framework.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Herbel_J/0/1/0/all/0/1&quot;&gt;J&amp;#xf6;rg Herbel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Kacprzak_T/0/1/0/all/0/1&quot;&gt;Tomasz Kacprzak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Amara_A/0/1/0/all/0/1&quot;&gt;Adam Amara&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Refregier_A/0/1/0/all/0/1&quot;&gt;Alexandre Refregier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Lucchi_A/0/1/0/all/0/1&quot;&gt;Aurelien Lucchi&lt;/a&gt; (ETH Zurich)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.03877">
<title>On dynamic ensemble selection and data preprocessing for multi-class imbalance learning. (arXiv:1803.03877v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1803.03877</link>
<description rdf:parseType="Literal">&lt;p&gt;Class-imbalance refers to classification problems in which many more
instances are available for certain classes than for others. Such imbalanced
datasets require special attention because traditional classifiers generally
favor the majority class which has a large number of instances. Ensemble of
classifiers have been reported to yield promising results. However, the
majority of ensemble methods applied too imbalanced learning are static ones.
Moreover, they only deal with binary imbalanced problems. Hence, this paper
presents an empirical analysis of dynamic selection techniques and data
preprocessing methods for dealing with multi-class imbalanced problems. We
considered five variations of preprocessing methods and four dynamic selection
methods. Our experiments conducted on 26 multi-class imbalanced problems show
that the dynamic ensemble improves the F-measure and the G-mean as compared to
the static ensemble. Moreover, data preprocessing plays an important role in
such cases.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Cruz_R/0/1/0/all/0/1&quot;&gt;Rafael M. O. Cruz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sabourin_R/0/1/0/all/0/1&quot;&gt;Robert Sabourin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Cavalcanti_G/0/1/0/all/0/1&quot;&gt;George D. C. Cavalcanti&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.06722">
<title>Machine Learning Interpretability: A Science rather than a tool. (arXiv:1807.06722v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1807.06722</link>
<description rdf:parseType="Literal">&lt;p&gt;The term &quot;interpretability&quot; is oftenly used by machine learning researchers
each with their own intuitive understanding of it. There is no universal well
agreed upon definition of interpretability in machine learning. As any type of
science discipline is mainly driven by the set of formulated questions rather
than by different tools in that discipline, e.g. astrophysics is the discipline
that learns the composition of stars, not as the discipline that use the
spectroscopes. Similarly, we propose that machine learning interpretability
should be a discipline that answers specific questions related to
interpretability. These questions can be of statistical, causal and
counterfactual nature. Therefore, there is a need to look into the
interpretability problem of machine learning in the context of questions that
need to be addressed rather than different tools. We discuss about a
hypothetical interpretability framework driven by a question based scientific
approach rather than some specific machine learning model. Using a question
based notion of interpretability, we can step towards understanding the science
of machine learning rather than its engineering. This notion will also help us
understanding any specific problem more in depth rather than relying solely on
machine learning methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Karim_A/0/1/0/all/0/1&quot;&gt;Abdul Karim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mishra_A/0/1/0/all/0/1&quot;&gt;Avinash Mishra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Newton_M/0/1/0/all/0/1&quot;&gt;MA Hakim Newton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sattar_A/0/1/0/all/0/1&quot;&gt;Abdul Sattar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.07306">
<title>Bounded Information Rate Variational Autoencoders. (arXiv:1807.07306v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1807.07306</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper introduces a new member of the family of Variational Autoencoders
(VAE) that constrains the rate of information transferred by the latent layer.
The latent layer is interpreted as a communication channel, the information
rate of which is bound by imposing a pre-set signal-to-noise ratio. The new
constraint subsumes the mutual information between the input and latent
variables, combining naturally with the likelihood objective of the observed
data as used in a conventional VAE. The resulting Bounded-Information-Rate
Variational Autoencoder (BIR-VAE) provides a meaningful latent representation
with an information resolution that can be specified directly in bits by the
system designer. The rate constraint can be used to prevent overtraining, and
the method naturally facilitates quantisation of the latent variables at the
set rate. Our experiments confirm that the BIR-VAE has a meaningful latent
representation and that its performance is at least as good as state-of-the-art
competing algorithms, but with lower computational complexity.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Braithwaite_D/0/1/0/all/0/1&quot;&gt;D. T. Braithwaite&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kleijn_W/0/1/0/all/0/1&quot;&gt;W. B. Kleijn&lt;/a&gt;</dc:creator>
</item></rdf:RDF>