<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Boring papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Bad Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-02-19T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06093"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06367"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06591"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1707.09952"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.10304"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.09206"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04657"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06108"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06137"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06139"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06259"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06306"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06314"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06318"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06357"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06382"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06416"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06426"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06444"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06476"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06480"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06485"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06516"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06588"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06604"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06698"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06739"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1507.07045"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1603.01182"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1708.01425"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1708.08722"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.02169"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.05199"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.08875"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.01933"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06095"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06132"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06182"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06226"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06286"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06292"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06293"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06300"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06307"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06308"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06355"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06394"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06398"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06402"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06428"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06439"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06455"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06458"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06501"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06526"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06678"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1601.06207"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1603.06038"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1705.02436"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1705.02737"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1705.07107"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1705.08435"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1705.09869"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1707.06618"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1707.08092"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.07804"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.00382"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.01921"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.02795"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.07168"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.08244"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.06818"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.03532"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.03692"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04826"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05910"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1802.06093">
<title>Gradient descent with identity initialization efficiently learns positive definite linear transformations by deep residual networks. (arXiv:1802.06093v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.06093</link>
<description rdf:parseType="Literal">&lt;p&gt;We analyze algorithms for approximating a function $f(x) = \Phi x$ mapping
$\Re^d$ to $\Re^d$ using deep linear neural networks, i.e. that learn a
function $h$ parameterized by matrices $\Theta_1,...,\Theta_L$ and defined by
$h(x) = \Theta_L \Theta_{L-1} ... \Theta_1 x$. We focus on algorithms that
learn through gradient descent on the population quadratic loss in the case
that the distribution over the inputs is isotropic.
&lt;/p&gt;
&lt;p&gt;We provide polynomial bounds on the number of iterations for gradient descent
to approximate the optimum, in the case where the initial hypothesis $\Theta_1
= ... = \Theta_L = I$ has loss bounded by a small enough constant. On the other
hand, we show that gradient descent fails to converge for $\Phi$ whose distance
from the identity is a larger constant, and we show that some forms of
regularization toward the identity in each layer do not help.
&lt;/p&gt;
&lt;p&gt;If $\Phi$ is symmetric positive definite, we show that an algorithm that
initializes $\Theta_i = I$ learns an $\epsilon$-approximation of $f$ using a
number of updates polynomial in $L$, the condition number of $\Phi$, and
$\log(d/\epsilon)$. In contrast, we show that if the target $\Phi$ is symmetric
and has a negative eigenvalue, then all members of a class of algorithms that
perform gradient descent with identity initialization, and optionally
regularize toward the identity in each layer, fail to converge.
&lt;/p&gt;
&lt;p&gt;We analyze an algorithm for the case that $\Phi$ satisfies $u^{\top} \Phi u &amp;gt;
0$ for all $u$, but may not be symmetric. This algorithm uses two regularizers:
one that maintains the invariant $u^{\top} \Theta_L \Theta_{L-1} ... \Theta_1 u
&amp;gt; 0$ for all $u$, and another that &quot;balances&quot; $\Theta_1 ... \Theta_L$ so that
they have the same singular values.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bartlett_P/0/1/0/all/0/1&quot;&gt;Peter L. Bartlett&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Helmbold_D/0/1/0/all/0/1&quot;&gt;David P. Helmbold&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Long_P/0/1/0/all/0/1&quot;&gt;Philip M. Long&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06367">
<title>Efficient Sparse-Winograd Convolutional Neural Networks. (arXiv:1802.06367v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1802.06367</link>
<description rdf:parseType="Literal">&lt;p&gt;Convolutional Neural Networks (CNNs) are computationally intensive, which
limits their application on mobile devices. Their energy is dominated by the
number of multiplies needed to perform the convolutions. Winograd&apos;s minimal
filtering algorithm (Lavin, 2015) and network pruning (Han et al., 2015) can
reduce the operation count, but these two methods cannot be directly combined
$-$ applying the Winograd transform fills in the sparsity in both the weights
and the activations. We propose two modifications to Winograd-based CNNs to
enable these methods to exploit sparsity. First, we move the ReLU operation
into the Winograd domain to increase the sparsity of the transformed
activations. Second, we prune the weights in the Winograd domain to exploit
static weight sparsity. For models on CIFAR-10, CIFAR-100 and ImageNet
datasets, our method reduces the number of multiplications by $10.4\times$,
$6.8\times$ and $10.8\times$ respectively with loss of accuracy less than
$0.1\%$, outperforming previous baselines by $2.0\times$-$3.0\times$. We also
show that moving ReLU to the Winograd domain allows more aggressive pruning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_X/0/1/0/all/0/1&quot;&gt;Xingyu Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pool_J/0/1/0/all/0/1&quot;&gt;Jeff Pool&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1&quot;&gt;Song Han&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dally_W/0/1/0/all/0/1&quot;&gt;William J. Dally&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06591">
<title>Closing the loop on multisensory interactions: A neural architecture for multisensory causal inference and recalibration. (arXiv:1802.06591v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1802.06591</link>
<description rdf:parseType="Literal">&lt;p&gt;When the brain receives input from multiple sensory systems, it is faced with
the question of whether it is appropriate to process the inputs in combination,
as if they originated from the same event, or separately, as if they originated
from distinct events. Furthermore, it must also have a mechanism through which
it can keep sensory inputs calibrated to maintain the accuracy of its internal
representations. We have developed a neural network architecture capable of i)
approximating optimal multisensory spatial integration, based on Bayesian
causal inference, and ii) recalibrating the spatial encoding of sensory
systems. The architecture is based on features of the dorsal processing
hierarchy, including the spatial tuning properties of unisensory neurons and
the convergence of different sensory inputs onto multisensory neurons.
Furthermore, we propose that these unisensory and multisensory neurons play
dual roles in i) encoding spatial location as separate or integrated estimates
and ii) accumulating evidence for the independence or relatedness of
multisensory stimuli. We further propose that top-down feedback connections
spanning the dorsal pathway play key a role in recalibrating spatial encoding
at the level of early unisensory cortices. Our proposed architecture provides
possible explanations for a number of human electrophysiological and
neuroimaging results and generates testable predictions linking neurophysiology
with behaviour.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tong_J/0/1/0/all/0/1&quot;&gt;Jonathan Tong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Parisi_G/0/1/0/all/0/1&quot;&gt;German I. Parisi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wermter_S/0/1/0/all/0/1&quot;&gt;Stefan Wermter&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roder_B/0/1/0/all/0/1&quot;&gt;Brigitte R&amp;#xf6;der&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1707.09952">
<title>Multiscale Co-Design Analysis of Energy, Latency, Area, and Accuracy of a ReRAM Analog Neural Training Accelerator. (arXiv:1707.09952v2 [cs.AR] UPDATED)</title>
<link>http://arxiv.org/abs/1707.09952</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural networks are an increasingly attractive algorithm for natural language
processing and pattern recognition. Deep networks with &amp;gt;50M parameters are made
possible by modern GPU clusters operating at &amp;lt;50 pJ per op and more recently,
production accelerators capable of &amp;lt;5pJ per operation at the board level.
However, with the slowing of CMOS scaling, new paradigms will be required to
achieve the next several orders of magnitude in performance per watt gains.
Using an analog resistive memory (ReRAM) crossbar to perform key matrix
operations in an accelerator is an attractive option. This work presents a
detailed design using a state of the art 14/16 nm PDK for of an analog crossbar
circuit block designed to process three key kernels required in training and
inference of neural networks. A detailed circuit and device-level analysis of
energy, latency, area, and accuracy are given and compared to relevant designs
using standard digital ReRAM and SRAM operations. It is shown that the analog
accelerator has a 270x energy and 540x latency advantage over a similar block
utilizing only digital ReRAM and takes only 11 fJ per multiply and accumulate
(MAC). Compared to an SRAM based accelerator, the energy is 430X better and
latency is 34X better. Although training accuracy is degraded in the analog
accelerator, several options to improve this are presented. The possible gains
over a similar digital-only version of this accelerator block suggest that
continued optimization of analog resistive memories is valuable. This detailed
circuit and device analysis of a training accelerator may serve as a foundation
for further architecture-level studies.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Marinella_M/0/1/0/all/0/1&quot;&gt;Matthew J. Marinella&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Agarwal_S/0/1/0/all/0/1&quot;&gt;Sapan Agarwal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hsia_A/0/1/0/all/0/1&quot;&gt;Alexander Hsia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Richter_I/0/1/0/all/0/1&quot;&gt;Isaac Richter&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jacobs_Gedrim_R/0/1/0/all/0/1&quot;&gt;Robin Jacobs-Gedrim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Niroula_J/0/1/0/all/0/1&quot;&gt;John Niroula&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Plimpton_S/0/1/0/all/0/1&quot;&gt;Steven J. Plimpton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ipek_E/0/1/0/all/0/1&quot;&gt;Engin Ipek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+James_C/0/1/0/all/0/1&quot;&gt;Conrad D. James&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.10304">
<title>Few-shot Autoregressive Density Estimation: Towards Learning to Learn Distributions. (arXiv:1710.10304v3 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1710.10304</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep autoregressive models have shown state-of-the-art performance in density
estimation for natural images on large-scale datasets such as ImageNet.
However, such models require many thousands of gradient-based weight updates
and unique image examples for training. Ideally, the models would rapidly learn
visual concepts from only a handful of examples, similar to the manner in which
humans learns across many vision tasks. In this paper, we show how 1) neural
attention and 2) meta learning techniques can be used in combination with
autoregressive models to enable effective few-shot density estimation. Our
proposed modifications to PixelCNN result in state-of-the art few-shot density
estimation on the Omniglot dataset. Furthermore, we visualize the learned
attention policy and find that it learns intuitive algorithms for simple tasks
such as image mirroring on ImageNet and handwriting on Omniglot without
supervision. Finally, we extend the model to natural images and demonstrate
few-shot image generation on the Stanford Online Products dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Reed_S/0/1/0/all/0/1&quot;&gt;Scott Reed&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yutian Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Paine_T/0/1/0/all/0/1&quot;&gt;Thomas Paine&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oord_A/0/1/0/all/0/1&quot;&gt;A&amp;#xe4;ron van den Oord&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Eslami_S/0/1/0/all/0/1&quot;&gt;S. M. Ali Eslami&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rezende_D/0/1/0/all/0/1&quot;&gt;Danilo Rezende&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vinyals_O/0/1/0/all/0/1&quot;&gt;Oriol Vinyals&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Freitas_N/0/1/0/all/0/1&quot;&gt;Nando de Freitas&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.09206">
<title>Chaos-guided Input Structuring for Improved Learning in Recurrent Neural Networks. (arXiv:1712.09206v3 [q-bio.NC] UPDATED)</title>
<link>http://arxiv.org/abs/1712.09206</link>
<description rdf:parseType="Literal">&lt;p&gt;Anatomical studies demonstrate that brain reformats input information to
generate reliable responses for performing computations. However, it remains
unclear how neural circuits encode complex spatio-temporal patterns. We show
that neural dynamics are strongly influenced by the phase alignment between the
input and the spontaneous chaotic activity. Input structuring along the
dominant chaotic projections causes the chaotic trajectories to become stable
channels (or attractors), hence, improving the computational capability of a
recurrent network. Using mean field analysis, we derive the impact of input
structuring on the overall stability of attractors formed. Our results indicate
that input alignment determines the extent of intrinsic noise suppression and
hence, alters the attractor state stability, thereby controlling the network&apos;s
inference ability.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Panda_P/0/1/0/all/0/1&quot;&gt;Priyadarshini Panda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Roy_K/0/1/0/all/0/1&quot;&gt;Kaushik Roy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04657">
<title>Analyzing and Mitigating the Impact of Permanent Faults on a Systolic Array Based Neural Network Accelerator. (arXiv:1802.04657v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1802.04657</link>
<description rdf:parseType="Literal">&lt;p&gt;Due to their growing popularity and computational cost, deep neural networks
(DNNs) are being targeted for hardware acceleration. A popular architecture for
DNN acceleration, adopted by the Google Tensor Processing Unit (TPU), utilizes
a systolic array based matrix multiplication unit at its core. This paper deals
with the design of fault-tolerant, systolic array based DNN accelerators for
high defect rate technologies. To this end, we empirically show that the
classification accuracy of a baseline TPU drops significantly even at extremely
low fault rates (as low as $0.006\%$). We then propose two novel strategies,
fault-aware pruning (FAP) and fault-aware pruning+retraining (FAP+T), that
enable the TPU to operate at fault rates of up to $50\%$, with negligible drop
in classification accuracy (as low as $0.1\%$) and no run-time performance
overhead. The FAP+T does introduce a one-time retraining penalty per TPU chip
before it is deployed, but we propose optimizations that reduce this one-time
penalty to under 12 minutes. The penalty is then amortized over the entire
lifetime of the TPU&apos;s operation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Jeff Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gu_T/0/1/0/all/0/1&quot;&gt;Tianyu Gu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Basu_K/0/1/0/all/0/1&quot;&gt;Kanad Basu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garg_S/0/1/0/all/0/1&quot;&gt;Siddharth Garg&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06108">
<title>Modeling the Formation of Social Conventions in Multi-Agent Populations. (arXiv:1802.06108v1 [cs.MA])</title>
<link>http://arxiv.org/abs/1802.06108</link>
<description rdf:parseType="Literal">&lt;p&gt;In order to understand the formation of social conventions we need to know
the specific role of control and learning in multi-agent systems. To advance in
this direction, we propose, within the framework of the Distributed Adaptive
Control (DAC) theory, a novel Control-based Reinforcement Learning architecture
(CRL) that can account for the acquisition of social conventions in multi-agent
populations that are solving a benchmark social decision-making problem. Our
new CRL architecture, as a concrete realization of DAC multi-agent theory,
implements a low-level sensorimotor control loop handling the agent&apos;s reactive
behaviors (pre-wired reflexes), along with a layer based on model-free
reinforcement learning that maximizes long-term reward. We apply CRL in a
multi-agent game-theoretic task in which coordination must be achieved in order
to find an optimal solution. We show that our CRL architecture is able to both
find optimal solutions in discrete and continuous time and reproduce human
experimental data on standard game-theoretic metrics such as efficiency in
acquiring rewards, fairness in reward distribution and stability of convention
formation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Freire_I/0/1/0/all/0/1&quot;&gt;Ismael T. Freire&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moulin_Frier_C/0/1/0/all/0/1&quot;&gt;Clement Moulin-Frier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sanchez_Fibla_M/0/1/0/all/0/1&quot;&gt;Marti Sanchez-Fibla&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Arsiwalla_X/0/1/0/all/0/1&quot;&gt;Xerxes D. Arsiwalla&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Verschure_P/0/1/0/all/0/1&quot;&gt;Paul Verschure&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06137">
<title>Implicit Robot-Human Communication in Adversarial and Collaborative Environments. (arXiv:1802.06137v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.06137</link>
<description rdf:parseType="Literal">&lt;p&gt;Users of AI systems may rely upon them to produce plans for achieving desired
objectives. Such AI systems should be able to compute obfuscated plans whose
execution in adversarial situations protects privacy as well as legible plans
which are easy for team-members to understand in collaborative situations. We
develop a unified framework that addresses these dual problems by computing
plans with a desired level of comprehensibility from the point of view of a
partially informed observer. Our approach produces obfuscated plans with
observations that are consistent with at least &apos;k&apos; goals from a given set of
decoy goals. In addition, when the goal is known to the observer, our approach
generates obfuscated plans with observations that are diverse with at least &apos;l&apos;
candidate plans. Our approach for plan legibility produces plans that achieve a
goal while being consistent with at most &apos;j&apos; goals in a given set of
confounding goals. We provide an empirical evaluation to show the feasibility
and usefulness of our approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kulkarni_A/0/1/0/all/0/1&quot;&gt;Anagha Kulkarni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Srivastava_S/0/1/0/all/0/1&quot;&gt;Siddharth Srivastava&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kambhampati_S/0/1/0/all/0/1&quot;&gt;Subbarao Kambhampati&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06139">
<title>Reactive Reinforcement Learning in Asynchronous Environments. (arXiv:1802.06139v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.06139</link>
<description rdf:parseType="Literal">&lt;p&gt;The relationship between a reinforcement learning (RL) agent and an
asynchronous environment is often ignored. Frequently used models of the
interaction between an agent and its environment, such as Markov Decision
Processes (MDP) or Semi-Markov Decision Processes (SMDP), do not capture the
fact that, in an asynchronous environment, the state of the environment may
change during computation performed by the agent. In an asynchronous
environment, minimizing reaction time---the time it takes for an agent to react
to an observation---also minimizes the time in which the state of the
environment may change following observation. In many environments, the
reaction time of an agent directly impacts task performance by permitting the
environment to transition into either an undesirable terminal state or a state
where performing the chosen action is inappropriate. We propose a class of
reactive reinforcement learning algorithms that address this problem of
asynchronous environments by immediately acting after observing new state
information. We compare a reactive SARSA learning algorithm with the
conventional SARSA learning algorithm on two asynchronous robotic tasks
(emergency stopping and impact prevention), and show that the reactive RL
algorithm reduces the reaction time of the agent by approximately the duration
of the algorithm&apos;s learning update. This new class of reactive algorithms may
facilitate safer control and faster decision making without any change to
standard learning guarantees.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Travnik_J/0/1/0/all/0/1&quot;&gt;Jaden B. Travnik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mathewson_K/0/1/0/all/0/1&quot;&gt;Kory W. Mathewson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sutton_R/0/1/0/all/0/1&quot;&gt;Richard S. Sutton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pilarski_P/0/1/0/all/0/1&quot;&gt;Patrick M. Pilarski&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06259">
<title>Exact and Consistent Interpretation for Piecewise Linear Neural Networks: A Closed Form Solution. (arXiv:1802.06259v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1802.06259</link>
<description rdf:parseType="Literal">&lt;p&gt;Strong intelligent machines powered by deep neural networks are increasingly
deployed as black boxes to make decisions in risk-sensitive domains, such as
finance and medical. To reduce potential risk and build trust with users, it is
critical to interpret how such machines make their decisions. Existing works
interpret a pre-trained neural network by analyzing hidden neurons, mimicking
pre-trained models or approximating local predictions. However, these methods
do not provide a guarantee on the exactness and consistency of their
interpretation. In this paper, we propose an elegant closed form solution named
$OpenBox$ to compute exact and consistent interpretations for the family of
Piecewise Linear Neural Networks (PLNN). The major idea is to first transform a
PLNN into a mathematically equivalent set of linear classifiers, then interpret
each linear classifier by the features that dominate its prediction. We further
apply $OpenBox$ to demonstrate the effectiveness of non-negative and sparse
constraints on improving the interpretability of PLNNs. The extensive
experiments on both synthetic and real world data sets clearly demonstrate the
exactness and consistency of our interpretation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chu_L/0/1/0/all/0/1&quot;&gt;Lingyang Chu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_X/0/1/0/all/0/1&quot;&gt;Xia Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_J/0/1/0/all/0/1&quot;&gt;Juhua Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1&quot;&gt;Lanjun Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pei_J/0/1/0/all/0/1&quot;&gt;Jian Pei&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06306">
<title>Optimizing Interactive Systems with Data-Driven Objectives. (arXiv:1802.06306v1 [cs.HC])</title>
<link>http://arxiv.org/abs/1802.06306</link>
<description rdf:parseType="Literal">&lt;p&gt;Effective optimization is essential for \iss to provide a satisfactory user
experience. However, it is often challenging to find an objective to optimize
for. Generally, such objectives are manually crafted and rarely capture complex
user needs accurately. Conversely, we propose an approach that infers the
objective directly from observed user interactions. These inferences can be
made regardless of prior knowledge and across different types of user behavior.
Then we introduce: Interactive System Optimizer (ISO), a novel algorithm that
uses these inferred objectives for optimization. Our main contribution is a new
general principled approach to optimizing \iss using data-driven objectives. We
demonstrate the high effectiveness of ISO over several GridWorld simulations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Ziming Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grotov_A/0/1/0/all/0/1&quot;&gt;Artem Grotov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kiseleva_J/0/1/0/all/0/1&quot;&gt;Julia Kiseleva&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rijke_M/0/1/0/all/0/1&quot;&gt;Maarten de Rijke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oosterhuis_H/0/1/0/all/0/1&quot;&gt;Harrie Oosterhuis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06314">
<title>Autonomous Vehicle Speed Control for Safe Navigation of Occluded Pedestrian Crosswalk. (arXiv:1802.06314v1 [cs.RO])</title>
<link>http://arxiv.org/abs/1802.06314</link>
<description rdf:parseType="Literal">&lt;p&gt;Both humans and the sensors on an autonomous vehicle have limited sensing
capabilities. When these limitations coincide with scenarios involving
vulnerable road users, it becomes important to account for these limitations in
the motion planner. For the scenario of an occluded pedestrian crosswalk, the
speed of the approaching vehicle should be a function of the amount of
uncertainty on the roadway. In this work, the longitudinal controller is
formulated as a partially observable Markov decision process and dynamic
programming is used to compute the control policy. The control policy scales
the speed profile to be used by a model predictive steering controller.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Thornton_S/0/1/0/all/0/1&quot;&gt;Sarah Thornton&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06318">
<title>Large Neighborhood-Based Metaheuristic and Branch-and-Price for the Pickup and Delivery Problem with Split Loads. (arXiv:1802.06318v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.06318</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the multi-vehicle one-to-one pickup and delivery problem with
split loads, a NP-hard problem linked with a variety of applications for bulk
product transportation, bike-sharing systems and inventory re-balancing. This
problem is notoriously difficult due to the interaction of two challenging
vehicle routing attributes, &quot;pickups and deliveries&quot; and &quot;split deliveries&quot;.
This possibly leads to optimal solutions of a size that grows exponentially
with the instance size, containing multiple visits per customer pair, even in
the same route. To solve this problem, we propose an iterated local search
metaheuristic as well as a branch-and-price algorithm. The core of the
metaheuristic consists of a new large neighborhood search, which reduces the
problem of finding the best insertion combination of a pickup and delivery pair
into a route (with possible splits) to a resource-constrained shortest path and
knapsack problem. Similarly, the branch-and-price algorithm uses sophisticated
labeling techniques, route relaxations, pre-processing and branching rules for
an efficient resolution. Our computational experiments on classical
single-vehicle instances demonstrate the excellent performance of the
metaheuristic, which produces new best known solutions for 92 out of 93 test
instances, and outperforms all previous algorithms. Experimental results on new
multi-vehicle instances with distance constraints are also reported. The
branch-and-price algorithm produces optimal solutions for instances with up to
20 pickup-and-delivery pairs, and very accurate solutions are found by the
metaheuristic.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Haddad_M/0/1/0/all/0/1&quot;&gt;Matheus Nohra Haddad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Martinelli_R/0/1/0/all/0/1&quot;&gt;Rafael Martinelli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vidal_T/0/1/0/all/0/1&quot;&gt;Thibaut Vidal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ochi_L/0/1/0/all/0/1&quot;&gt;Luiz Satoru Ochi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Martins_S/0/1/0/all/0/1&quot;&gt;Simone Martins&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Souza_M/0/1/0/all/0/1&quot;&gt;Marcone Jamilson Freitas Souza&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hartl_R/0/1/0/all/0/1&quot;&gt;Richard Hartl&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06357">
<title>Convergence of Online Mirror Descent Algorithms. (arXiv:1802.06357v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.06357</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper we consider online mirror descent (OMD) algorithms, a class of
scalable online learning algorithms exploiting data geometric structures
through mirror maps. Necessary and sufficient conditions are presented in terms
of the step size sequence $\{\eta_t\}_{t}$ for the convergence of an OMD
algorithm with respect to the expected Bregman distance induced by the mirror
map. The condition is $\lim_{t\to\infty}\eta_t=0,
\sum_{t=1}^{\infty}\eta_t=\infty$ in the case of positive variances. It is
reduced to $\sum_{t=1}^{\infty}\eta_t=\infty$ in the case of zero variances for
which the linear convergence may be achieved by taking a constant step size
sequence. A sufficient condition on the almost sure convergence is also given.
We establish tight error bounds under mild conditions on the mirror map, the
loss function, and the regularizer. Our results are achieved by some novel
analysis on the one-step progress of the OMD algorithm using smoothness and
strong convexity of the mirror map and the loss function.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lei_Y/0/1/0/all/0/1&quot;&gt;Yunwen Lei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_D/0/1/0/all/0/1&quot;&gt;Ding-Xuan Zhou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06382">
<title>Scalable Alignment Kernels via Space-Efficient Feature Maps. (arXiv:1802.06382v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.06382</link>
<description rdf:parseType="Literal">&lt;p&gt;String kernels are attractive data analysis tools for analyzing string data.
Among them, alignment kernels are known for their high prediction accuracies in
string classifications when tested in combination with SVMs in various
applications. However, alignment kernels have a crucial drawback in that they
scale poorly due to their quadratic computation complexity in the number of
input strings, which limits large-scale applications in practice. We present
the first approximation named ESP+SFM for alignment kernels by leveraging a
metric embedding named edit-sensitive parsing (ESP) and space-efficient feature
maps (SFM) for random Fourier features (RFF) for large-scale string analyses.
Input strings are projected into vectors of RFF by leveraging ESP and SFM.
Then, SVMs are trained on the projected vectors, which enables to significantly
improve the scalability of alignment kernels while preserving their prediction
accuracies. We experimentally test ESP+ SFM on its ability to learn SVMs for
large-scale string classifications with various massive string data, and we
demonstrate the superior performance of ESP+SFM with respect to prediction
accuracy, scalability and computation efficiency.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tabei_Y/0/1/0/all/0/1&quot;&gt;Yasuo Tabei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yamanishi_Y/0/1/0/all/0/1&quot;&gt;Yoshihiro Yamanishi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pagh_R/0/1/0/all/0/1&quot;&gt;Rasmus Pagh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06416">
<title>Sim-To-Real Optimization Of Complex Real World Mobile Network with Imperfect Information via Deep Reinforcement Learning from Self-play. (arXiv:1802.06416v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.06416</link>
<description rdf:parseType="Literal">&lt;p&gt;Mobile network that millions of people use every day is one of the most
complex systems in real world. Optimization of mobile network to meet exploding
customer demand and reduce CAPEX/OPEX poses greater challenges than in prior
works. Learning to solve complex problems in real world to benefit everyone and
make the world better has long been ultimate goal of AI. However, it still
remains an unsolved problem for deep reinforcement learning (DRL), given
imperfect information in real world, huge state/action space, lots of data
needed for training, associated time/cost, multi-agent interactions, potential
negative impact to real world, etc. To bridge this reality gap, we proposed a
DRL framework to direct transfer optimal policy learned from multi-tasks in
source domain to unseen similar tasks in target domain without any further
training in both domains. First, we distilled temporal-spatial relationships
between cells and mobile users to scalable 3D image-like tensor to best
characterize partially observed mobile network. Second, inspired by AlphaGo, we
used a novel self-play mechanism to empower DRL agent to gradually improve its
intelligence by competing for best record on multiple tasks. Third, a
decentralized DRL method is proposed to coordinate multi-agents to compete and
cooperate as a team to maximize global reward and minimize potential negative
impact. Using 7693 unseen test tasks over 160 unseen simulated mobile networks
and 6 field trials over 4 commercial mobile networks in real world, we
demonstrated the capability of our approach to direct transfer the learning
from one simulator to another simulator, and from simulation to real world.
This is the first time that a DRL agent successfully transfers its learning
directly from simulation to very complex real world problems with incomplete
and imperfect information, huge state/action space and multi-agent
interactions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tan_Y/0/1/0/all/0/1&quot;&gt;Yongxi Tan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_J/0/1/0/all/0/1&quot;&gt;Jin Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1&quot;&gt;Xin Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_Q/0/1/0/all/0/1&quot;&gt;Qitao Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yunjun Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ye_Z/0/1/0/all/0/1&quot;&gt;Zhangxiang Ye&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Su_Z/0/1/0/all/0/1&quot;&gt;Zhenqiang Su&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06426">
<title>Estimating scale-invariant future in continuous time. (arXiv:1802.06426v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.06426</link>
<description rdf:parseType="Literal">&lt;p&gt;Natural learners must compute an estimate of future outcomes that follow from
a stimulus in continuous time. Critically, the learner cannot in general know a
priori the relevant time scale over which meaningful relationships will be
observed. Widely used reinforcement learning algorithms discretize continuous
time and use the Bellman equation to estimate exponentially-discounted future
reward. However, exponential discounting introduces a time scale to the
computation of value. Scaling is a serious problem in continuous time:
efficient learning with scaled algorithms requires prior knowledge of the
relevant scale. That is, with scaled algorithms one must know at least part of
the solution to a problem prior to attempting a solution. We present a
computational mechanism, developed based on work in psychology and
neuroscience, for computing a scale-invariant timeline of future events. This
mechanism efficiently computes a model for future time on a
logarithmically-compressed scale, and can be used to generate a scale-invariant
power-law-discounted estimate of expected future reward. Moreover, the
representation of future time retains information about what will happen when,
enabling flexible decision making based on future events. The entire timeline
can be constructed in a single parallel operation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tiganj_Z/0/1/0/all/0/1&quot;&gt;Zoran Tiganj&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gershman_S/0/1/0/all/0/1&quot;&gt;Samuel J. Gershman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sederberg_P/0/1/0/all/0/1&quot;&gt;Per B. Sederberg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Howard_M/0/1/0/all/0/1&quot;&gt;Marc W. Howard&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06444">
<title>Efficient Large-Scale Fleet Management via Multi-Agent Deep Reinforcement Learning. (arXiv:1802.06444v1 [cs.MA])</title>
<link>http://arxiv.org/abs/1802.06444</link>
<description rdf:parseType="Literal">&lt;p&gt;Large-scale online ride-sharing platforms have substantially transformed our
lives by reallocating transportation resources to alleviate traffic congestion
and promote transportation efficiency. An efficient fleet management strategy
not only can significantly improve the utilization of transportation resources
but also increase the revenue and customer satisfaction. It is a challenging
task to design an effective fleet management strategy that can adapt to an
environment involving complex dynamics between demand and supply. Existing
studies usually work on a simplified problem setting that can hardly capture
the complicated stochastic demand-supply variations in high-dimensional space.
In this paper we propose to tackle the large-scale fleet management problem
using reinforcement learning, and propose a contextual multi-agent
reinforcement learning framework including two concrete algorithms, namely
contextual deep Q-learning and contextual multi-agent actor-critic, to achieve
explicit coordination among a large number of agents adaptive to different
contexts. We show significant improvements of the proposed framework over
state-of-the-art approaches through extensive empirical studies.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_K/0/1/0/all/0/1&quot;&gt;Kaixiang Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_R/0/1/0/all/0/1&quot;&gt;Renyu Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Z/0/1/0/all/0/1&quot;&gt;Zhe Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1&quot;&gt;Jiayu Zhou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06476">
<title>Simultaneous Modeling of Multiple Complications for Risk Profiling in Diabetes Care. (arXiv:1802.06476v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.06476</link>
<description rdf:parseType="Literal">&lt;p&gt;Type 2 diabetes mellitus (T2DM) is a chronic disease that often results in
multiple complications. Risk prediction and profiling of T2DM complications is
critical for healthcare professionals to design personalized treatment plans
for patients in diabetes care for improved outcomes. In this paper, we study
the risk of developing complications after the initial T2DM diagnosis from
longitudinal patient records. We propose a novel multi-task learning approach
to simultaneously model multiple complications where each task corresponds to
the risk modeling of one complication. Specifically, the proposed method
strategically captures the relationships (1) between the risks of multiple T2DM
complications, (2) between the different risk factors, and (3) between the risk
factor selection patterns. The method uses coefficient shrinkage to identify an
informative subset of risk factors from high-dimensional data, and uses a
hierarchical Bayesian framework to allow domain knowledge to be incorporated as
priors. The proposed method is favorable for healthcare applications because in
additional to improved prediction performance, relationships among the
different risks and risk factors are also identified. Extensive experimental
results on a large electronic medical claims database show that the proposed
method outperforms state-of-the-art models by a significant margin.
Furthermore, we show that the risk associations learned and the risk factors
identified lead to meaningful clinical insights.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1&quot;&gt;Bin Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Ying Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghosh_S/0/1/0/all/0/1&quot;&gt;Soumya Ghosh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_Z/0/1/0/all/0/1&quot;&gt;Zhaonan Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ng_K/0/1/0/all/0/1&quot;&gt;Kenney Ng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_J/0/1/0/all/0/1&quot;&gt;Jianying Hu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06480">
<title>Accelerated Primal-Dual Policy Optimization for Safe Reinforcement Learning. (arXiv:1802.06480v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.06480</link>
<description rdf:parseType="Literal">&lt;p&gt;Constrained Markov Decision Process (CMDP) is a natural framework for
reinforcement learning tasks with safety constraints, where agents learn a
policy that maximizes the long-term reward while satisfying the constraints on
the long-term cost. A canonical approach for solving CMDPs is the primal-dual
method which updates parameters in primal and dual spaces in turn. Existing
methods for CMDPs only use on-policy data for dual updates, which results in
sample inefficiency and slow convergence. In this paper, we propose a policy
search method for CMDPs called Accelerated Primal-Dual Optimization (APDO),
which incorporates an off-policy trained dual variable in the dual update
procedure while updating the policy in primal space with on-policy likelihood
ratio gradient. Experimental results on a simulated robot locomotion task show
that APDO achieves better sample efficiency and faster convergence than
state-of-the-art approaches for CMDPs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_Q/0/1/0/all/0/1&quot;&gt;Qingkai Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Que_F/0/1/0/all/0/1&quot;&gt;Fanyu Que&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Modiano_E/0/1/0/all/0/1&quot;&gt;Eytan Modiano&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06485">
<title>Robust Estimation via Robust Gradient Estimation. (arXiv:1802.06485v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.06485</link>
<description rdf:parseType="Literal">&lt;p&gt;We provide a new computationally-efficient class of estimators for risk
minimization. We show that these estimators are robust for general statistical
models: in the classical Huber epsilon-contamination model and in heavy-tailed
settings. Our workhorse is a novel robust variant of gradient descent, and we
provide conditions under which our gradient descent variant provides accurate
estimators in a general convex risk minimization problem. We provide specific
consequences of our theory for linear regression, logistic regression and for
estimation of the canonical parameters in an exponential family. These results
provide some of the first computationally tractable and provably robust
estimators for these canonical statistical models. Finally, we study the
empirical performance of our proposed methods on synthetic and real datasets,
and find that our methods convincingly outperform a variety of baselines.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Prasad_A/0/1/0/all/0/1&quot;&gt;Adarsh Prasad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Suggala_A/0/1/0/all/0/1&quot;&gt;Arun Sai Suggala&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Balakrishnan_S/0/1/0/all/0/1&quot;&gt;Sivaraman Balakrishnan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ravikumar_P/0/1/0/all/0/1&quot;&gt;Pradeep Ravikumar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06516">
<title>Subspace Network: Deep Multi-Task Censored Regression for Modeling Neurodegenerative Diseases. (arXiv:1802.06516v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.06516</link>
<description rdf:parseType="Literal">&lt;p&gt;Over the past decade a wide spectrum of machine learning models have been
developed to model the neurodegenerative diseases, associating biomarkers,
especially non-intrusive neuroimaging markers, with key clinical scores
measuring the cognitive status of patients. Multi-task learning (MTL) has been
commonly utilized by these studies to address high dimensionality and small
cohort size challenges. However, most existing MTL approaches are based on
linear models and suffer from two major limitations: 1) they cannot explicitly
consider upper/lower bounds in these clinical scores; 2) they lack the
capability to capture complicated non-linear interactions among the variables.
In this paper, we propose Subspace Network, an efficient deep modeling approach
for non-linear multi-task censored regression. Each layer of the subspace
network performs a multi-task censored regression to improve upon the
predictions from the last layer via sketching a low-dimensional subspace to
perform knowledge transfer among learning tasks. Under mild assumptions, for
each layer the parametric subspace can be recovered using only one pass of
training data. Empirical results demonstrate that the proposed subspace network
quickly picks up the correct parameter subspaces, and outperforms
state-of-the-arts in predicting neurodegenerative clinical scores using
information in brain imaging.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_M/0/1/0/all/0/1&quot;&gt;Mengying Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Baytas_I/0/1/0/all/0/1&quot;&gt;Inci M. Baytas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhan_L/0/1/0/all/0/1&quot;&gt;Liang Zhan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zhangyang Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1&quot;&gt;Jiayu Zhou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06588">
<title>A Machine Learning Approach to Air Traffic Route Choice Modelling. (arXiv:1802.06588v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.06588</link>
<description rdf:parseType="Literal">&lt;p&gt;Air Traffic Flow and Capacity Management (ATFCM) is one of the constituent
parts of Air Traffic Management (ATM). The goal of ATFCM is to make airport and
airspace capacity meet traffic demand and, when capacity opportunities are
exhausted, optimise traffic flows to meet the available capacity. One of the
key enablers of ATFCM is the accurate estimation of future traffic demand. The
available information (schedules, flight plans, etc.) and its associated level
of uncertainty differ across the different ATFCM planning phases, leading to
qualitative differences between the types of forecasting that are feasible at
each time horizon. While abundant research has been conducted on tactical
trajectory prediction (i.e., during the day of operations), trajectory
prediction in the pre-tactical phase, when few or no flight plans are
available, has received much less attention. As a consequence, the methods
currently in use for pre-tactical traffic forecast are still rather
rudimentary, often resulting in suboptimal ATFCM decision making. This paper
proposes a machine learning approach for the prediction of airlines route
choices between two airports as a function of route characteristics, such as
flight efficiency, air navigation charges and expected level of congestion.
Different predictive models based on multinomial logistic regression and
decision trees are formulated and calibrated with historical traffic data, and
a critical evaluation of each model is conducted. We analyse the predictive
power of each model in terms of its ability to forecast traffic volumes at the
level of charging zones, proving significant potential to enhance pre-tactical
traffic forecast. We conclude by discussing the limitations and room for
improvement of the proposed approach, as well as the future developments
required to produce reliable traffic forecasts at a higher spatial and temporal
resolution.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Marcos_R/0/1/0/all/0/1&quot;&gt;Rodrigo Marcos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garcia_Cantu_O/0/1/0/all/0/1&quot;&gt;Oliva Garc&amp;#xed;a-Cant&amp;#xfa;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Herranz_R/0/1/0/all/0/1&quot;&gt;Ricardo Herranz&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06604">
<title>Learning High-level Representations from Demonstrations. (arXiv:1802.06604v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.06604</link>
<description rdf:parseType="Literal">&lt;p&gt;Hierarchical learning (HL) is key to solving complex sequential decision
problems with long horizons and sparse rewards. It allows learning agents to
break-up large problems into smaller, more manageable subtasks. A common
approach to HL, is to provide the agent with a number of high-level skills that
solve small parts of the overall problem. A major open question, however, is
how to identify a suitable set of reusable skills. We propose a principled
approach that uses human demonstrations to infer a set of subgoals based on
changes in the demonstration dynamics. Using these subgoals, we decompose the
learning problem into an abstract high-level representation and a set of
low-level subtasks. The abstract description captures the overall problem
structure, while subtasks capture desired skills. We demonstrate that we can
jointly optimize over both levels of learning. We show that the resulting
method significantly outperforms previous baselines on two challenging
problems: the Atari 2600 game Montezuma&apos;s Revenge, and a simulated robotics
problem moving the ant robot through a maze.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Andersen_G/0/1/0/all/0/1&quot;&gt;Garrett Andersen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vrancx_P/0/1/0/all/0/1&quot;&gt;Peter Vrancx&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bou_Ammar_H/0/1/0/all/0/1&quot;&gt;Haitham Bou-Ammar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06698">
<title>Analysis of Cause-Effect Inference via Regression Errors. (arXiv:1802.06698v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.06698</link>
<description rdf:parseType="Literal">&lt;p&gt;We address the problem of inferring the causal relation between two variables
by comparing the least-squares errors of the predictions in both possible
causal directions. Under the assumption of an independence between the function
relating cause and effect, the conditional noise distribution, and the
distribution of the cause, we show that the errors are smaller in causal
direction if both variables are equally scaled and the causal relation is close
to deterministic. Based on this, we provide an easily applicable algorithm that
only requires a regression in both possible causal directions and a comparison
of the errors. The performance of the algorithm is compared with different
related causal inference methods in various artificial and real-world data
sets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Blobaum_P/0/1/0/all/0/1&quot;&gt;Patrick Bl&amp;#xf6;baum&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Janzing_D/0/1/0/all/0/1&quot;&gt;Dominik Janzing&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Washio_T/0/1/0/all/0/1&quot;&gt;Takashi Washio&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shimizu_S/0/1/0/all/0/1&quot;&gt;Shohei Shimizu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Scholkopf_B/0/1/0/all/0/1&quot;&gt;Bernhard Sch&amp;#xf6;lkopf&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06739">
<title>Differentially Private Generative Adversarial Network. (arXiv:1802.06739v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.06739</link>
<description rdf:parseType="Literal">&lt;p&gt;Generative Adversarial Network (GAN) and its variants have recently attracted
intensive research interests due to their elegant theoretical foundation and
excellent empirical performance as generative models. These tools provide a
promising direction in the studies where data availability is limited. One
common issue in GANs is that the density of the learned generative distribution
could concentrate on the training data points, meaning that they can easily
remember training samples due to the high model complexity of deep networks.
This becomes a major concern when GANs are applied to private or sensitive data
such as patient medical records, and the concentration of distribution may
divulge critical patient information. To address this issue, in this paper we
propose a differentially private GAN (DPGAN) model, in which we achieve
differential privacy in GANs by adding carefully designed noise to gradients
during the learning procedure. We provide rigorous proof for the privacy
guarantee, as well as comprehensive empirical evidence to support our analysis,
where we demonstrate that our method can generate high quality data points at a
reasonable privacy level.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_L/0/1/0/all/0/1&quot;&gt;Liyang Xie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_K/0/1/0/all/0/1&quot;&gt;Kaixiang Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1&quot;&gt;Shu Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_F/0/1/0/all/0/1&quot;&gt;Fei Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1&quot;&gt;Jiayu Zhou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1507.07045">
<title>A Truth Serum for Large-Scale Evaluations. (arXiv:1507.07045v4 [cs.GT] UPDATED)</title>
<link>http://arxiv.org/abs/1507.07045</link>
<description rdf:parseType="Literal">&lt;p&gt;A major challenge in obtaining large-scale evaluations, e.g., product or
service reviews on online platforms, labeling images, grading in online
courses, etc., is that of eliciting honest responses from agents in the absence
of verifiability. We propose a new reward mechanism with strong incentive
properties applicable in a wide variety of such settings. This mechanism has a
simple and intuitive output agreement structure: an agent gets a reward only if
her response for an evaluation matches that of her peer. But instead of the
reward being the same across different answers, it is inversely proportional to
a popularity index of each answer. This index is a second order population
statistic that captures how frequently two agents performing the same
evaluation agree on the particular answer. Rare agreements thus earn a higher
reward than agreements that are relatively more common.
&lt;/p&gt;
&lt;p&gt;In the regime where there are a large number of evaluation tasks, we show
that truthful behavior is a strict Bayes-Nash equilibrium of the game induced
by the mechanism. Further, we show that the truthful equilibrium is
approximately optimal in terms of expected payoffs to the agents across all
symmetric equilibria, where the approximation error vanishes in the number of
evaluation tasks. Moreover, under a mild condition on strategy space, we show
that any symmetric equilibrium that gives a higher expected payoff than the
truthful equilibrium must be close to being fully informative if the number of
evaluations is large. These last two results are driven by a new notion of an
agreement measure that is shown to be monotonic in information loss. This
notion and its properties are of independent interest.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kamble_V/0/1/0/all/0/1&quot;&gt;Vijay Kamble&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Marn_D/0/1/0/all/0/1&quot;&gt;David Marn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shah_N/0/1/0/all/0/1&quot;&gt;Nihar Shah&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Parekh_A/0/1/0/all/0/1&quot;&gt;Abhay Parekh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ramachandran_K/0/1/0/all/0/1&quot;&gt;Kannan Ramachandran&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1603.01182">
<title>Network Unfolding Map by Edge Dynamics Modeling. (arXiv:1603.01182v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1603.01182</link>
<description rdf:parseType="Literal">&lt;p&gt;The emergence of collective dynamics in neural networks is a mechanism of the
animal and human brain for information processing. In this paper, we develop a
computational technique using distributed processing elements in a complex
network, which are called particles, to solve semi-supervised learning
problems. Three actions govern the particles&apos; dynamics: generation, walking,
and absorption. Labeled vertices generate new particles that compete against
rival particles for edge domination. Active particles randomly walk in the
network until they are absorbed by either a rival vertex or an edge currently
dominated by rival particles. The result from the model evolution consists of
sets of edges arranged by the label dominance. Each set tends to form a
connected subnetwork to represent a data class. Although the intrinsic dynamics
of the model is a stochastic one, we prove there exists a deterministic version
with largely reduced computational complexity; specifically, with linear
growth. Furthermore, the edge domination process corresponds to an unfolding
map in such way that edges &quot;stretch&quot; and &quot;shrink&quot; according to the vertex-edge
dynamics. Consequently, the unfolding effect summarizes the relevant
relationships between vertices and the uncovered data classes. The proposed
model captures important details of connectivity patterns over the vertex-edge
dynamics evolution, in contrast to previous approaches which focused on only
vertex or only edge dynamics. Computer simulations reveal that the new model
can identify nonlinear features in both real and artificial data, including
boundaries between distinct classes and overlapping structures of data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Verri_F/0/1/0/all/0/1&quot;&gt;Filipe Alves Neto Verri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Urio_P/0/1/0/all/0/1&quot;&gt;Paulo Roberto Urio&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_L/0/1/0/all/0/1&quot;&gt;Liang Zhao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1708.01425">
<title>The Argument Reasoning Comprehension Task: Identification and Reconstruction of Implicit Warrants. (arXiv:1708.01425v3 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1708.01425</link>
<description rdf:parseType="Literal">&lt;p&gt;Reasoning is a crucial part of natural language argumentation. To comprehend
an argument, one must analyze its warrant, which explains why its claim follows
from its premises. As arguments are highly contextualized, warrants are usually
presupposed and left implicit. Thus, the comprehension does not only require
language understanding and logic skills, but also depends on common sense. In
this paper we develop a methodology for reconstructing warrants systematically.
We operationalize it in a scalable crowdsourcing process, resulting in a freely
licensed dataset with warrants for 2k authentic arguments from news comments.
On this basis, we present a new challenging task, the argument reasoning
comprehension task. Given an argument with a claim and a premise, the goal is
to choose the correct implicit warrant from two options. Both warrants are
plausible and lexically close, but lead to contradicting claims. A solution to
this task will define a substantial step towards automatic warrant
reconstruction. However, experiments with several neural attention and language
models reveal that current approaches do not suffice.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Habernal_I/0/1/0/all/0/1&quot;&gt;Ivan Habernal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wachsmuth_H/0/1/0/all/0/1&quot;&gt;Henning Wachsmuth&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gurevych_I/0/1/0/all/0/1&quot;&gt;Iryna Gurevych&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stein_B/0/1/0/all/0/1&quot;&gt;Benno Stein&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1708.08722">
<title>Unifying DAGs and UGs. (arXiv:1708.08722v7 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1708.08722</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce a new class of graphical models that generalizes
Lauritzen-Wermuth-Frydenberg chain graphs by relaxing the semi-directed
acyclity constraint so that only directed cycles are forbidden. Moreover, up to
two edges are allowed between any pair of nodes. Specifically, we present
local, pairwise and global Markov properties for the new graphical models and
prove their equivalence. We also present an equivalent factorization property.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pena_J/0/1/0/all/0/1&quot;&gt;Jose M. Pe&amp;#xf1;a&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.02169">
<title>Bayesian Optimisation for Safe Navigation under Localisation Uncertainty. (arXiv:1709.02169v2 [cs.RO] UPDATED)</title>
<link>http://arxiv.org/abs/1709.02169</link>
<description rdf:parseType="Literal">&lt;p&gt;In outdoor environments, mobile robots are required to navigate through
terrain with varying characteristics, some of which might significantly affect
the integrity of the platform. Ideally, the robot should be able to identify
areas that are safe for navigation based on its own percepts about the
environment while avoiding damage to itself. Bayesian optimisation (BO) has
been successfully applied to the task of learning a model of terrain
traversability while guiding the robot through more traversable areas. An
issue, however, is that localisation uncertainty can end up guiding the robot
to unsafe areas and distort the model being learnt. In this paper, we address
this problem and present a novel method that allows BO to consider localisation
uncertainty by applying a Gaussian process model for uncertain inputs as a
prior. We evaluate the proposed method in simulation and in experiments with a
real robot navigating over rough terrain and compare it against standard BO
methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oliveira_R/0/1/0/all/0/1&quot;&gt;Rafael Oliveira&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ott_L/0/1/0/all/0/1&quot;&gt;Lionel Ott&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guizilini_V/0/1/0/all/0/1&quot;&gt;Vitor Guizilini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ramos_F/0/1/0/all/0/1&quot;&gt;Fabio Ramos&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.05199">
<title>Community Aware Random Walk for Network Embedding. (arXiv:1710.05199v2 [cs.SI] UPDATED)</title>
<link>http://arxiv.org/abs/1710.05199</link>
<description rdf:parseType="Literal">&lt;p&gt;Social network analysis provides meaningful information about behavior of
network members that can be used for diverse applications such as
classification, link prediction. However, network analysis is computationally
expensive because of feature learning for different applications. In recent
years, many researches have focused on feature learning methods in social
networks. Network embedding represents the network in a lower dimensional
representation space with the same properties which presents a compressed
representation of the network. In this paper, we introduce a novel algorithm
named &quot;CARE&quot; for network embedding that can be used for different types of
networks including weighted, directed and complex. Current methods try to
preserve local neighborhood information of nodes, whereas the proposed method
utilizes local neighborhood and community information of network nodes to cover
both local and global structure of social networks. CARE builds customized
paths, which are consisted of local and global structure of network nodes, as a
basis for network embedding and uses the Skip-gram model to learn
representation vector of nodes. Subsequently, stochastic gradient descent is
applied to optimize our objective function and learn the final representation
of nodes. Our method can be scalable when new nodes are appended to network
without information loss. Parallelize generation of customized random walks is
also used for speeding up CARE. We evaluate the performance of CARE on multi
label classification and link prediction tasks. Experimental results on various
networks indicate that the proposed method outperforms others in both Micro and
Macro-f1 measures for different size of training data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Keikha_M/0/1/0/all/0/1&quot;&gt;Mohammad Mehdi Keikha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rahgozar_M/0/1/0/all/0/1&quot;&gt;Maseud Rahgozar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Asadpour_M/0/1/0/all/0/1&quot;&gt;Masoud Asadpour&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.08875">
<title>Predicting Rich Drug-Drug Interactions via Biomedical Knowledge Graphs and Text Jointly Embedding. (arXiv:1712.08875v3 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1712.08875</link>
<description rdf:parseType="Literal">&lt;p&gt;Minimizing adverse reactions caused by drug-drug interactions has always been
a momentous research topic in clinical pharmacology. Detecting all possible
interactions through clinical studies before a drug is released to the market
is a demanding task. The power of big data is opening up new approaches to
discover various drug-drug interactions. However, these discoveries contain a
huge amount of noise and provide knowledge bases far from complete and
trustworthy ones to be utilized. Most existing studies focus on predicting
binary drug-drug interactions between drug pairs but ignore other interactions.
In this paper, we propose a novel framework, called PRD, to predict drug-drug
interactions. The framework uses the graph embedding that can overcome data
incompleteness and sparsity issues to achieve multiple DDI label prediction.
First, a large-scale drug knowledge graph is generated from different sources.
Then, the knowledge graph is embedded with comprehensive biomedical text into a
common low dimensional space. Finally, the learned embeddings are used to
efficiently compute rich DDI information through a link prediction process. To
validate the effectiveness of the proposed framework, extensive experiments
were conducted on real-world datasets. The results demonstrate that our model
outperforms several state-of-the-art baseline methods in terms of capability
and accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1&quot;&gt;Meng Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.01933">
<title>A Survey Of Methods For Explaining Black Box Models. (arXiv:1802.01933v2 [cs.CY] UPDATED)</title>
<link>http://arxiv.org/abs/1802.01933</link>
<description rdf:parseType="Literal">&lt;p&gt;In the last years many accurate decision support systems have been
constructed as black boxes, that is as systems that hide their internal logic
to the user. This lack of explanation constitutes both a practical and an
ethical issue. The literature reports many approaches aimed at overcoming this
crucial weakness sometimes at the cost of scarifying accuracy for
interpretability. The applications in which black box decision systems can be
used are various, and each approach is typically developed to provide a
solution for a specific problem and, as a consequence, delineating explicitly
or implicitly its own definition of interpretability and explanation. The aim
of this paper is to provide a classification of the main problems addressed in
the literature with respect to the notion of explanation and the type of black
box system. Given a problem definition, a black box type, and a desired
explanation this survey should help the researcher to find the proposals more
useful for his own work. The proposed classification of approaches to open
black box models should also be useful for putting the many research open
questions in perspective.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guidotti_R/0/1/0/all/0/1&quot;&gt;Riccardo Guidotti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Monreale_A/0/1/0/all/0/1&quot;&gt;Anna Monreale&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Turini_F/0/1/0/all/0/1&quot;&gt;Franco Turini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pedreschi_D/0/1/0/all/0/1&quot;&gt;Dino Pedreschi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Giannotti_F/0/1/0/all/0/1&quot;&gt;Fosca Giannotti&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06095">
<title>Mining Sub-Interval Relationships In Time Series Data. (arXiv:1802.06095v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.06095</link>
<description rdf:parseType="Literal">&lt;p&gt;Time-series data is being increasingly collected and stud- ied in several
areas such as neuroscience, climate science, transportation, and social media.
Discovery of complex patterns of relationships between individual time-series,
using data-driven approaches can improve our understanding of real-world
systems. While traditional approaches typically study relationships between two
entire time series, many interesting relationships in real-world applications
exist in small sub-intervals of time while remaining absent or feeble during
other sub-intervals. In this paper, we define the notion of a sub-interval
relationship (SIR) to capture inter- actions between two time series that are
prominent only in certain sub-intervals of time. We propose a novel and
efficient approach to find most interesting SIR in a pair of time series. We
evaluate our proposed approach on two real-world datasets from climate science
and neuroscience domain and demonstrated the scalability and computational
efficiency of our proposed approach. We further evaluated our discovered SIRs
based on a randomization based procedure. Our results indicated the existence
of several such relationships that are statistically significant, some of which
were also found to have physical interpretation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Agrawal_S/0/1/0/all/0/1&quot;&gt;Saurabh Agrawal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Verma_S/0/1/0/all/0/1&quot;&gt;Saurabh Verma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Atluri_G/0/1/0/all/0/1&quot;&gt;Gowtham Atluri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Karpatne_A/0/1/0/all/0/1&quot;&gt;Anuj Karpatne&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Liess_S/0/1/0/all/0/1&quot;&gt;Stefan Liess&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Macdonald_A/0/1/0/all/0/1&quot;&gt;Angus Macdonald III&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chatterjee_S/0/1/0/all/0/1&quot;&gt;Snigdhansu Chatterjee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kumar_V/0/1/0/all/0/1&quot;&gt;Vipin Kumar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06132">
<title>Interaction Matters: A Note on Non-asymptotic Local Convergence of Generative Adversarial Networks. (arXiv:1802.06132v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.06132</link>
<description rdf:parseType="Literal">&lt;p&gt;Motivated by the pursuit of a systematic computational and algorithmic
understanding of Generative Adversarial Networks (GANs), we present a simple
yet unified non-asymptotic local convergence theory for smooth two-player
games, which subsumes several discrete-time gradient-based saddle point
dynamics. The analysis reveals the surprising nature of the off-diagonal
interaction term as both a blessing and a curse. On the one hand, this
interaction term explains the origin of the slow-down effect in the convergence
of Simultaneous Gradient Ascent (SGA) to stable Nash equilibria. On the other
hand, for the unstable equilibria, exponential convergence can be proved thanks
to the interaction term, for three modified dynamics which have been proposed
to stabilize GAN training: Optimistic Mirror Descent (OMD), Consensus
Optimization (CO) and Predictive Method (PM). The analysis uncovers the
intimate connections among these stabilizing techniques, and provides detailed
characterization on the choice of learning rate.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Liang_T/0/1/0/all/0/1&quot;&gt;Tengyuan Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Stokes_J/0/1/0/all/0/1&quot;&gt;James Stokes&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06182">
<title>CREPE: A Convolutional Representation for Pitch Estimation. (arXiv:1802.06182v1 [eess.AS])</title>
<link>http://arxiv.org/abs/1802.06182</link>
<description rdf:parseType="Literal">&lt;p&gt;The task of estimating the fundamental frequency of a monophonic sound
recording, also known as pitch tracking, is fundamental to audio processing
with multiple applications in speech processing and music information
retrieval. To date, the best performing techniques, such as the pYIN algorithm,
are based on a combination of DSP pipelines and heuristics. While such
techniques perform very well on average, there remain many cases in which they
fail to correctly estimate the pitch. In this paper, we propose a data-driven
pitch tracking algorithm, CREPE, which is based on a deep convolutional neural
network that operates directly on the time-domain waveform. We show that the
proposed model produces state-of-the-art results, performing equally or better
than pYIN. Furthermore, we evaluate the model&apos;s generalizability in terms of
noise robustness. A pre-trained version of CREPE is made freely available as an
open-source Python module for easy application.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Kim_J/0/1/0/all/0/1&quot;&gt;Jong Wook Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Salamon_J/0/1/0/all/0/1&quot;&gt;Justin Salamon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Li_P/0/1/0/all/0/1&quot;&gt;Peter Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Bello_J/0/1/0/all/0/1&quot;&gt;Juan Pablo Bello&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06226">
<title>Post Selection Inference with Incomplete Maximum Mean Discrepancy Estimator. (arXiv:1802.06226v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.06226</link>
<description rdf:parseType="Literal">&lt;p&gt;Measuring divergence between two distributions is essential in machine
learning and statistics and has various applications including binary
classification, change point detection, and two-sample test. Furthermore, in
the era of big data, designing divergence measure that is interpretable and can
handle high-dimensional and complex data becomes extremely important. In the
paper, we propose a post selection inference (PSI) framework for divergence
measure, which can select a set of statistically significant features that
discriminate two distributions. Specifically, we employ an additive variant of
maximum mean discrepancy (MMD) for features and introduce a general hypothesis
test for PSI. A novel MMD estimator using the incomplete U-statistics, which
has an asymptotically Normal distribution (under mild assumptions) and gives
high detection power in PSI, is also proposed and analyzed theoretically.
Through synthetic and real-world feature selection experiments, we show that
the proposed framework can successfully detect statistically significant
features. Last, we propose a sample selection framework for analyzing different
members in the Generative Adversarial Networks (GANs) family.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yamada_M/0/1/0/all/0/1&quot;&gt;Makoto Yamada&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wu_D/0/1/0/all/0/1&quot;&gt;Denny Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tsai_Y/0/1/0/all/0/1&quot;&gt;Yao-Hung Hubert Tsai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Takeuchi_I/0/1/0/all/0/1&quot;&gt;Ichiro Takeuchi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Salakhutdinov_R/0/1/0/all/0/1&quot;&gt;Ruslan Salakhutdinov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Fukumizu_K/0/1/0/all/0/1&quot;&gt;Kenji Fukumizu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06286">
<title>Nonconvex Matrix Factorization from Rank-One Measurements. (arXiv:1802.06286v1 [cs.IT])</title>
<link>http://arxiv.org/abs/1802.06286</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the problem of recovering low-rank matrices from random rank-one
measurements, which spans numerous applications including covariance sketching,
phase retrieval, quantum state tomography, and learning shallow polynomial
neural networks, among others. Our approach is to directly estimate the
low-rank factor by minimizing a nonconvex quadratic loss function via vanilla
gradient descent, following a tailored spectral initialization. When the true
rank is small, this algorithm is guaranteed to converge to the ground truth (up
to global ambiguity) with near-optimal sample complexity and computational
complexity. To the best of our knowledge, this is the first guarantee that
achieves near-optimality in both metrics. In particular, the key enabler of
near-optimal computational guarantees is an implicit regularization phenomenon:
without explicit regularization, both spectral initialization and the gradient
descent iterates automatically stay within a region incoherent with the
measurement vectors. This feature allows one to employ much more aggressive
step sizes compared with the ones suggested in prior literature, without the
need of sample splitting.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yuanxin Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_C/0/1/0/all/0/1&quot;&gt;Cong Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yuxin Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chi_Y/0/1/0/all/0/1&quot;&gt;Yuejie Chi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06292">
<title>Nonparametric estimation of low rank matrix valued function. (arXiv:1802.06292v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.06292</link>
<description rdf:parseType="Literal">&lt;p&gt;Let $A:[0,1]\rightarrow\mathbb{H}_m$ (the space of Hermitian matrices) be a
matrix valued function which is low rank with entries in H\&quot;{o}lder class
$\Sigma(\beta,L)$. The goal of this paper is to study statistical estimation of
$A$ based on the regression model $\mathbb{E}(Y_j|\tau_j,X_j) = \langle
A(\tau_j), X_j \rangle,$ where $\tau_j$ are i.i.d. uniformly distributed in
$[0,1]$, $X_j$ are i.i.d. matrix completion sampling matrices, $Y_j$ are
independent bounded responses. We propose an innovative nuclear norm penalized
local polynomial estimator and establish an upper bound on its point-wise risk
measured by Frobenius norm. Then we extend this estimator globally and prove an
upper bound on its integrated risk measured by $L_2$-norm. We also propose
another new estimator based on bias-reducing kernels to study the case when $A$
is not necessarily low rank and establish an upper bound on its risk measured
by $L_{\infty}$-norm. We show that the obtained rates are all optimal up to
some logarithmic factor in minimax sense. Finally, we propose an adaptive
estimation procedure based on Lepski&apos;s method and the penalized data splitting
technique which is computationally efficient and can be easily implemented and
parallelized.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhou_F/0/1/0/all/0/1&quot;&gt;Fan Zhou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06293">
<title>Black-Box Reductions for Parameter-free Online Learning in Banach Spaces. (arXiv:1802.06293v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.06293</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce several new black-box reductions that significantly improve the
design of adaptive and parameter-free online learning algorithms by simplifying
analysis, improving regret guarantees, and sometimes even improving runtime. We
reduce parameter-free online learning to online exp-concave optimization, we
reduce optimization in a Banach space to one-dimensional optimization, and we
reduce optimization over a constrained domain to unconstrained optimization.
All of our reductions run as fast as online gradient descent. We use our new
techniques to improve upon the previously best regret bounds for parameter-free
learning, and do so for arbitrary norms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cutkosky_A/0/1/0/all/0/1&quot;&gt;Ashok Cutkosky&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Orabona_F/0/1/0/all/0/1&quot;&gt;Francesco Orabona&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06300">
<title>Exact and Robust Conformal Inference Methods for Predictive Machine Learning With Dependent Data. (arXiv:1802.06300v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.06300</link>
<description rdf:parseType="Literal">&lt;p&gt;We extend conformal inference to general settings that allow for time series
data. Our proposal is developed as a randomization method and accounts for
potential serial dependence by including block structures in the permutation
scheme. As a result, the proposed method retains the exact, model-free validity
when the data are i.i.d. or more generally exchangeable, similar to usual
conformal inference methods. When exchangeability fails, as is the case for
common time series data, the proposed approach is approximately valid under
weak assumptions on the conformity score.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chernozhukov_V/0/1/0/all/0/1&quot;&gt;Victor Chernozhukov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wuthrich_K/0/1/0/all/0/1&quot;&gt;Kaspar Wuthrich&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhu_Y/0/1/0/all/0/1&quot;&gt;Yinchu Zhu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06307">
<title>Out-of-sample extension of graph adjacency spectral embedding. (arXiv:1802.06307v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.06307</link>
<description rdf:parseType="Literal">&lt;p&gt;Many popular dimensionality reduction procedures have out-of-sample
extensions, which allow a practitioner to apply a learned embedding to
observations not seen in the initial training sample. In this work, we consider
the problem of obtaining an out-of-sample extension for the adjacency spectral
embedding, a procedure for embedding the vertices of a graph into Euclidean
space. We present two different approaches to this problem, one based on a
least-squares objective and the other based on a maximum-likelihood
formulation. We show that if the graph of interest is drawn according to a
certain latent position model called a random dot product graph, then both of
these out-of-sample extensions estimate the true latent position of the
out-of-sample vertex with the same error rate. Further, we prove a central
limit theorem for the least-squares-based extension, showing that the estimate
is asymptotically normal about the truth in the large-graph limit.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Levin_K/0/1/0/all/0/1&quot;&gt;Keith Levin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Roosta_Khorasani_F/0/1/0/all/0/1&quot;&gt;Farbod Roosta-Khorasani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mahoney_M/0/1/0/all/0/1&quot;&gt;Michael W. Mahoney&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Priebe_C/0/1/0/all/0/1&quot;&gt;Carey E. Priebe&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06308">
<title>Nonparametric Testing under Random Projection. (arXiv:1802.06308v1 [math.ST])</title>
<link>http://arxiv.org/abs/1802.06308</link>
<description rdf:parseType="Literal">&lt;p&gt;A common challenge in nonparametric inference is its high computational
complexity when data volume is large. In this paper, we develop computationally
efficient nonparametric testing by employing a random projection strategy. In
the specific kernel ridge regression setup, a simple distance-based test
statistic is proposed. Notably, we derive the minimum number of random
projections that is sufficient for achieving testing optimality in terms of the
minimax rate. An adaptive testing procedure is further established without
prior knowledge of regularity. One technical contribution is to establish upper
bounds for a range of tail sums of empirical kernel eigenvalues. Simulations
and real data analysis are conducted to support our theory.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Liu_M/0/1/0/all/0/1&quot;&gt;Meimei Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Shang_Z/0/1/0/all/0/1&quot;&gt;Zuofeng Shang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Cheng_G/0/1/0/all/0/1&quot;&gt;Guang Cheng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06355">
<title>Optimizing Spectral Sums using Randomized Chebyshev Expansions. (arXiv:1802.06355v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.06355</link>
<description rdf:parseType="Literal">&lt;p&gt;The trace of matrix functions, often called spectral sums, e.g., rank,
log-determinant and nuclear norm, appear in many machine learning tasks.
However, optimizing or computing such (parameterized) spectral sums typically
involves the matrix decomposition at the cost cubic in the matrix dimension,
which is expensive for large-scale applications. Several recent works were
proposed to approximate large-scale spectral sums utilizing polynomial function
approximations and stochastic trace estimators. However, all prior works on
this line have studied biased estimators, and their direct adaptions to an
optimization task under stochastic gradient descent (SGD) frameworks often do
not work as accumulated biased errors prevent stable convergence to the
optimum. To address the issue, we propose the provable optimal unbiased
estimator by randomizing Chebyshev polynomial degrees. We further introduce two
additional techniques for accelerating SGD, where key ideas are on sharing
randomness among many estimations during the iterative procedure. Finally, we
showcase two applications of the proposed SGD schemes: matrix completion and
learning Gaussian process, under the real-world datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Han_I/0/1/0/all/0/1&quot;&gt;Insu Han&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Avron_H/0/1/0/all/0/1&quot;&gt;Haim Avron&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shin_J/0/1/0/all/0/1&quot;&gt;Jinwoo Shin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06394">
<title>Training Big Random Forests with Little Resources. (arXiv:1802.06394v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.06394</link>
<description rdf:parseType="Literal">&lt;p&gt;Without access to large compute clusters, building random forests on large
datasets is still a challenging problem. This is, in particular, the case if
fully-grown trees are desired. We propose a simple yet effective framework that
allows to efficiently construct ensembles of huge trees for hundreds of
millions or even billions of training instances using a cheap desktop computer
with commodity hardware. The basic idea is to consider a multi-level
construction scheme, which builds top trees for small random subsets of the
available data and which subsequently distributes all training instances to the
top trees&apos; leaves for further processing. While being conceptually simple, the
overall efficiency crucially depends on the particular implementation of the
different phases. The practical merits of our approach are demonstrated using
dense datasets with hundreds of millions of training instances.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gieseke_F/0/1/0/all/0/1&quot;&gt;Fabian Gieseke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Igel_C/0/1/0/all/0/1&quot;&gt;Christian Igel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06398">
<title>HybridSVD: When Collaborative Information is Not Enough. (arXiv:1802.06398v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.06398</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a hybrid algorithm for top-$n$ recommendation task that allows to
incorporate both user and item side information within the standard
collaborative filtering approach. The algorithm extends PureSVD -- one of the
state-of-the-art latent factor models -- by exploiting a generalized
formulation of the singular value decomposition. This allows to inherit key
advantages of the classical algorithm such as highly efficient Lanczos-based
optimization procedure, minimal parameter tuning during a model selection phase
and a quick folding-in computation to generate recommendations instantly even
in a highly dynamic online environment. Within the generalized formulation
itself we provide an efficient scheme for side information fusion which avoids
undesirable computational overhead and addresses the scalability question.
Evaluation of the model is performed in both standard and cold-start scenarios
using the datasets with different sparsity levels. We demonstrate in which
cases our approach outperforms conventional methods and also provide some
intuition on when it may give no significant improvement.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Frolov_E/0/1/0/all/0/1&quot;&gt;Evgeny Frolov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oseledets_I/0/1/0/all/0/1&quot;&gt;Ivan Oseledets&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06402">
<title>Towards Ultra-High Performance and Energy Efficiency of Deep Learning Systems: An Algorithm-Hardware Co-Optimization Framework. (arXiv:1802.06402v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.06402</link>
<description rdf:parseType="Literal">&lt;p&gt;Hardware accelerations of deep learning systems have been extensively
investigated in industry and academia. The aim of this paper is to achieve
ultra-high energy efficiency and performance for hardware implementations of
deep neural networks (DNNs). An algorithm-hardware co-optimization framework is
developed, which is applicable to different DNN types, sizes, and application
scenarios. The algorithm part adopts the general block-circulant matrices to
achieve a fine-grained tradeoff between accuracy and compression ratio. It
applies to both fully-connected and convolutional layers and contains a
mathematically rigorous proof of the effectiveness of the method. The proposed
algorithm reduces computational complexity per layer from O($n^2$) to O($n\log
n$) and storage complexity from O($n^2$) to O($n$), both for training and
inference. The hardware part consists of highly efficient Field Programmable
Gate Array (FPGA)-based implementations using effective reconfiguration, batch
processing, deep pipelining, resource re-using, and hierarchical control.
Experimental results demonstrate that the proposed framework achieves at least
152X speedup and 71X energy efficiency gain compared with IBM TrueNorth
processor under the same test accuracy. It achieves at least 31X energy
efficiency gain compared with the reference FPGA-based work.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yanzhi Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ding_C/0/1/0/all/0/1&quot;&gt;Caiwen Ding&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Zhe Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yuan_G/0/1/0/all/0/1&quot;&gt;Geng Yuan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liao_S/0/1/0/all/0/1&quot;&gt;Siyu Liao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1&quot;&gt;Xiaolong Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yuan_B/0/1/0/all/0/1&quot;&gt;Bo Yuan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qian_X/0/1/0/all/0/1&quot;&gt;Xuehai Qian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1&quot;&gt;Jian Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qiu_Q/0/1/0/all/0/1&quot;&gt;Qinru Qiu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_X/0/1/0/all/0/1&quot;&gt;Xue Lin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06428">
<title>Improving Mild Cognitive Impairment Prediction via Reinforcement Learning and Dialogue Simulation. (arXiv:1802.06428v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.06428</link>
<description rdf:parseType="Literal">&lt;p&gt;Mild cognitive impairment (MCI) is a prodromal phase in the progression from
normal aging to dementia, especially Alzheimers disease. Even though there is
mild cognitive decline in MCI patients, they have normal overall cognition and
thus is challenging to distinguish from normal aging. Using transcribed data
obtained from recorded conversational interactions between participants and
trained interviewers, and applying supervised learning models to these data, a
recent clinical trial has shown a promising result in differentiating MCI from
normal aging. However, the substantial amount of interactions with medical
staff can still incur significant medical care expenses in practice. In this
paper, we propose a novel reinforcement learning (RL) framework to train an
efficient dialogue agent on existing transcripts from clinical trials.
Specifically, the agent is trained to sketch disease-specific lexical
probability distribution, and thus to converse in a way that maximizes the
diagnosis accuracy and minimizes the number of conversation turns. We evaluate
the performance of the proposed reinforcement learning framework on the MCI
diagnosis from a real clinical trial. The results show that while using only a
few turns of conversation, our framework can significantly outperform
state-of-the-art supervised learning approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_F/0/1/0/all/0/1&quot;&gt;Fengyi Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_K/0/1/0/all/0/1&quot;&gt;Kaixiang Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Uchendu_I/0/1/0/all/0/1&quot;&gt;Ikechukwu Uchendu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dodge_H/0/1/0/all/0/1&quot;&gt;Hiroko H. Dodge&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_J/0/1/0/all/0/1&quot;&gt;Jiayu Zhou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06439">
<title>Local Optimality and Generalization Guarantees for the Langevin Algorithm via Empirical Metastability. (arXiv:1802.06439v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.06439</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the detailed path-wise behavior of the discrete-time Langevin
algorithm for non-convex Empirical Risk Minimization (ERM) through the lens of
metastability, adopting some techniques from Berglund and Gentz.
&lt;/p&gt;
&lt;p&gt;For a particular local optimum of the empirical risk, with an arbitrary
initialization, we show that, with high probability, one of the two mutually
exclusive events will occur: either the Langevin trajectory ends up somewhere
outside the $\varepsilon$-neighborhood of this particular optimum within a
short recurrence time; or it enters this $\varepsilon$-neighborhood by the
recurrence time and stays there until an exponentially long escape time. We
call this phenomenon empirical metastability.
&lt;/p&gt;
&lt;p&gt;This two-timescale characterization aligns nicely with the existing
literature in the following two senses. First, the recurrence time is
dimension-independent, and resembles the convergence time of deterministic
Gradient Descent (GD). However unlike GD, the Langevin algorithm does not
require strong conditions on local initialization, and has the possibility of
eventually visiting all optima. Second, the scaling of the escape time is
consistent with the Eyring-Kramers law, which states that the Langevin scheme
will eventually visit all local minima, but it will take an exponentially long
time to transit among them. We apply this path-wise concentration result in the
context of statistical learning to examine local notions of generalization and
optimality.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tzen_B/0/1/0/all/0/1&quot;&gt;Belinda Tzen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_T/0/1/0/all/0/1&quot;&gt;Tengyuan Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Raginsky_M/0/1/0/all/0/1&quot;&gt;Maxim Raginsky&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06455">
<title>Bayesian Uncertainty Estimation for Batch Normalized Deep Networks. (arXiv:1802.06455v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.06455</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep neural networks have led to a series of breakthroughs, dramatically
improving the state-of-the-art in many domains. The techniques driving these
advances, however, lack a formal method to account for model uncertainty. While
the Bayesian approach to learning provides a solid theoretical framework to
handle uncertainty, inference in Bayesian-inspired deep neural networks is
difficult. In this paper, we provide a practical approach to Bayesian learning
that relies on a regularization technique found in nearly every modern network,
\textit{batch normalization}. We show that training a deep network using batch
normalization is equivalent to approximate inference in Bayesian models, and we
demonstrate how this finding allows us to make useful estimates of the model
uncertainty. With our approach, it is possible to make meaningful uncertainty
estimates using conventional architectures without modifying the network or the
training procedure. Our approach is thoroughly validated in a series of
empirical experiments on different tasks and using various measures,
outperforming baselines with strong statistical significance and displaying
competitive performance with other recent Bayesian approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Teye_M/0/1/0/all/0/1&quot;&gt;Mattias Teye&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Azizpour_H/0/1/0/all/0/1&quot;&gt;Hossein Azizpour&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Smith_K/0/1/0/all/0/1&quot;&gt;Kevin Smith&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06458">
<title>A Generative Modeling Approach to Limited Channel ECG Classification. (arXiv:1802.06458v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.06458</link>
<description rdf:parseType="Literal">&lt;p&gt;Processing temporal sequences is central to a variety of applications in
health care, and in particular multi-channel Electrocardiogram (ECG) is a
highly prevalent diagnostic modality that relies on robust sequence modeling.
While Recurrent Neural Networks (RNNs) have led to significant advances in
automated diagnosis with time-series data, they perform poorly when models are
trained using a limited set of channels. A crucial limitation of existing
solutions is that they rely solely on discriminative models, which tend to
generalize poorly in such scenarios. In order to combat this limitation, we
develop a generative modeling approach to limited channel ECG classification.
This approach first uses a \textit{Seq2Seq} model to implicitly generate the
missing channel information, and then uses the latent representation to perform
the actual supervisory task. This decoupling enables the use of unsupervised
data and also provides highly robust metric spaces for subsequent
discriminative learning. Our experiments with the Physionet dataset clearly
evidence the effectiveness of our approach over standard RNNs in disease
prediction.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rajan_D/0/1/0/all/0/1&quot;&gt;Deepta Rajan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Thiagarajan_J/0/1/0/all/0/1&quot;&gt;Jayaraman J. Thiagarajan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06501">
<title>Recommendations with Negative Feedback via Pairwise Deep Reinforcement Learning. (arXiv:1802.06501v1 [cs.IR])</title>
<link>http://arxiv.org/abs/1802.06501</link>
<description rdf:parseType="Literal">&lt;p&gt;Recommender systems play a crucial role in mitigating the problem of
information overload by suggesting users&apos; personalized items or services. The
vast majority of traditional recommender systems consider the recommendation
procedure as a static process and make recommendations following a fixed
strategy. In this paper, we propose a novel recommender system with the
capability of continuously improving its strategies during the interactions
with users. We model the sequential interactions between users and a
recommender system as a Markov Decision Process (MDP) and leverage
Reinforcement Learning (RL) to automatically learn the optimal strategies via
recommending trial-and-error items and receiving reinforcements of these items
from users&apos; feedback. Users&apos; feedback can be positive and negative and both
types of feedback have great potentials to boost recommendations. However, the
number of negative feedback is much larger than that of positive one; thus
incorporating them simultaneously is challenging since positive feedback could
be buried by negative one. In this paper, we develop a novel approach to
incorporate them into the proposed deep recommender system (DEERS) framework.
The experimental results based on real-world e-commerce data demonstrate the
effectiveness of the proposed framework. Further experiments have been
conducted to understand the importance of both positive and negative feedback
in recommendations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_X/0/1/0/all/0/1&quot;&gt;Xiangyu Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1&quot;&gt;Liang Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ding_Z/0/1/0/all/0/1&quot;&gt;Zhuoye Ding&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xia_L/0/1/0/all/0/1&quot;&gt;Long Xia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1&quot;&gt;Jiliang Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yin_D/0/1/0/all/0/1&quot;&gt;Dawei Yin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06526">
<title>Heron Inference for Bayesian Graphical Models. (arXiv:1802.06526v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.06526</link>
<description rdf:parseType="Literal">&lt;p&gt;Bayesian graphical models have been shown to be a powerful tool for
discovering uncertainty and causal structure from real-world data in many
application fields. Current inference methods primarily follow different kinds
of trade-offs between computational complexity and predictive accuracy. At one
end of the spectrum, variational inference approaches perform well in
computational efficiency, while at the other end, Gibbs sampling approaches are
known to be relatively accurate for prediction in practice. In this paper, we
extend an existing Gibbs sampling method, and propose a new deterministic Heron
inference (Heron) for a family of Bayesian graphical models. In addition to the
support for nontrivial distributability, one more benefit of Heron is that it
is able to not only allow us to easily assess the convergence status but also
largely improve the running efficiency. We evaluate Heron against the standard
collapsed Gibbs sampler and state-of-the-art state augmentation method in
inference for well-known graphical models. Experimental results using publicly
available real-life data have demonstrated that Heron significantly outperforms
the baseline methods for inferring Bayesian graphical models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rugeles_D/0/1/0/all/0/1&quot;&gt;Daniel Rugeles&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hai_Z/0/1/0/all/0/1&quot;&gt;Zhen Hai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cong_G/0/1/0/all/0/1&quot;&gt;Gao Cong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dash_M/0/1/0/all/0/1&quot;&gt;Manoranjan Dash&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06678">
<title>Large Scale Automated Forecasting for Monitoring Network Safety and Security. (arXiv:1802.06678v1 [stat.AP])</title>
<link>http://arxiv.org/abs/1802.06678</link>
<description rdf:parseType="Literal">&lt;p&gt;Real time large scale streaming data pose major challenges to forecasting, in
particular defying the presence of human experts to perform the corresponding
analysis. We present here a class of models and methods used to develop an
automated, scalable and versatile system for large scale forecasting oriented
towards safety and security monitoring. Our system provides short and long term
forecasts and uses them to detect safety and security issues in relation with
multiple internet connected devices well in advance they might take place.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Naveiro_R/0/1/0/all/0/1&quot;&gt;Roi Naveiro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rodriguez_S/0/1/0/all/0/1&quot;&gt;Sim&amp;#xf3;n Rodr&amp;#xed;guez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Insua_D/0/1/0/all/0/1&quot;&gt;David R&amp;#xed;os Insua&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1601.06207">
<title>Rectified Gaussian Scale Mixtures and the Sparse Non-Negative Least Squares Problem. (arXiv:1601.06207v5 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1601.06207</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we develop a Bayesian evidence maximization framework to solve
the sparse non-negative least squares problem (S-NNLS). We introduce a family
of probability densities referred to as the Rectified Gaussian Scale Mixture
(R-GSM), to model the sparsity enforcing prior distribution for the signal of
interest. The R-GSM prior encompasses a variety of heavy-tailed distributions
such as the rectified Laplacian and rectified Student-t distributions with a
proper choice of the mixing density. We utilize the hierarchical representation
induced by the R-GSM prior and develop an evidence maximization framework based
on the Expectation-Maximization (EM) algorithm. Using the EM-based method, we
estimate the hyper-parameters and obtain a point estimate for the solution of
interest. We refer to this proposed method as rectified Sparse Bayesian
Learning (R-SBL). We provide four EM-based R-SBL variants that offer a range of
options to trade-off computational complexity to the quality of the E-step
computation. These methods include the Markov Chain Monte Carlo EM, linear
minimum mean square estimation, approximate message passing and a diagonal
approximation. Using numerical experiments, we show that the proposed R-SBL
method outperforms existing S-NNLS solvers in terms of both signal and support
recovery, and is very robust against the structure of the design matrix.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nalci_A/0/1/0/all/0/1&quot;&gt;Alican Nalci&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fedorov_I/0/1/0/all/0/1&quot;&gt;Igor Fedorov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Al_Shoukairi_M/0/1/0/all/0/1&quot;&gt;Maher Al-Shoukairi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1&quot;&gt;Thomas T. Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rao_B/0/1/0/all/0/1&quot;&gt;Bhaskar D. Rao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1603.06038">
<title>Tensor Methods and Recommender Systems. (arXiv:1603.06038v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1603.06038</link>
<description rdf:parseType="Literal">&lt;p&gt;A substantial progress in development of new and efficient tensor
factorization techniques has led to an extensive research of their
applicability in recommender systems field. Tensor-based recommender models
push the boundaries of traditional collaborative filtering techniques by taking
into account a multifaceted nature of real environments, which allows to
produce more accurate, situational (e.g. context-aware, criteria-driven)
recommendations. Despite the promising results, tensor-based methods are poorly
covered in existing recommender systems surveys. This survey aims to complement
previous works and provide a comprehensive overview on the subject. To the best
of our knowledge, this is the first attempt to consolidate studies from various
application domains in an easily readable, digestible format, which helps to
get a notion of the current state of the field. We also provide a high level
discussion of the future perspectives and directions for further improvement of
tensor-based recommendation systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Frolov_E/0/1/0/all/0/1&quot;&gt;Evgeny Frolov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oseledets_I/0/1/0/all/0/1&quot;&gt;Ivan Oseledets&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1705.02436">
<title>Nonlinear Information Bottleneck. (arXiv:1705.02436v3 [cs.IT] UPDATED)</title>
<link>http://arxiv.org/abs/1705.02436</link>
<description rdf:parseType="Literal">&lt;p&gt;Information bottleneck [IB] is a technique for extracting information in some
`input&apos; random variable that is relevant for predicting some different &apos;output&apos;
random variable. IB works by encoding the input in a compressed &apos;bottleneck
variable&apos; from which the output can then be accurately decoded. IB can be
difficult to compute in practice, and has been mainly developed for two limited
cases: (1) discrete random variables with small state spaces, and (2)
continuous random variables that are jointly Gaussian distributed (in which
case the encoding and decoding maps are linear). We propose a method to perform
IB in more general domains. Our approach can be applied to discrete or
continuous inputs and outputs, and allows for nonlinear encoding and decoding
maps. The method uses a novel upper bound on the IB objective, derived using a
non-parametric estimator of mutual information and a variational approximation.
We show how to implement the method using neural networks and gradient-based
optimization, and demonstrate its performance on the MNIST dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kolchinsky_A/0/1/0/all/0/1&quot;&gt;Artemy Kolchinsky&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tracey_B/0/1/0/all/0/1&quot;&gt;Brendan D. Tracey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wolpert_D/0/1/0/all/0/1&quot;&gt;David H. Wolpert&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1705.02737">
<title>MIDA: Multiple Imputation using Denoising Autoencoders. (arXiv:1705.02737v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1705.02737</link>
<description rdf:parseType="Literal">&lt;p&gt;Missing data is a significant problem impacting all domains. State-of-the-art
framework for minimizing missing data bias is multiple imputation, for which
the choice of an imputation model remains nontrivial. We propose a multiple
imputation model based on overcomplete deep denoising autoencoders. Our
proposed model is capable of handling different data types, missingness
patterns, missingness proportions and distributions. Evaluation on several real
life datasets show our proposed model significantly outperforms current
state-of-the-art methods under varying conditions while simultaneously
improving end of the line analytics.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gondara_L/0/1/0/all/0/1&quot;&gt;Lovedeep Gondara&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_K/0/1/0/all/0/1&quot;&gt;Ke Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1705.07107">
<title>Gradient Estimators for Implicit Models. (arXiv:1705.07107v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1705.07107</link>
<description rdf:parseType="Literal">&lt;p&gt;Implicit models, which allow for the generation of samples but not for
point-wise evaluation of probabilities, are omnipresent in real-world problems
tackled by machine learning and a hot topic of current research. Some examples
include data simulators that are widely used in engineering and scientific
research, generative adversarial networks (GANs) for image synthesis, and
hot-off-the-press approximate inference techniques relying on implicit
distributions. The majority of existing approaches to learning implicit models
rely on approximating the intractable distribution or optimisation objective
for gradient-based optimisation, which is liable to produce inaccurate updates
and thus poor models. This paper alleviates the need for such approximations by
proposing the Stein gradient estimator, which directly estimates the score
function of the implicitly defined distribution. The efficacy of the proposed
estimator is empirically demonstrated by examples that include meta-learning
for approximate inference, and entropy regularised GANs that provide improved
sample diversity.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yingzhen Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Turner_R/0/1/0/all/0/1&quot;&gt;Richard E. Turner&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1705.08435">
<title>Personalized and Private Peer-to-Peer Machine Learning. (arXiv:1705.08435v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1705.08435</link>
<description rdf:parseType="Literal">&lt;p&gt;The rise of connected personal devices together with privacy concerns call
for machine learning algorithms capable of leveraging the data of a large
number of agents to learn personalized models under strong privacy
requirements. In this paper, we introduce an efficient algorithm to address the
above problem in a fully decentralized (peer-to-peer) and asynchronous fashion,
with provable convergence rate. We show how to make the algorithm
differentially private to protect against the disclosure of information about
the personal datasets, and formally analyze the trade-off between utility and
privacy. Our experiments show that our approach dramatically outperforms
previous work in the non-private case, and that under privacy constraints, we
can significantly improve over models learned in isolation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bellet_A/0/1/0/all/0/1&quot;&gt;Aur&amp;#xe9;lien Bellet&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guerraoui_R/0/1/0/all/0/1&quot;&gt;Rachid Guerraoui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Taziki_M/0/1/0/all/0/1&quot;&gt;Mahsa Taziki&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tommasi_M/0/1/0/all/0/1&quot;&gt;Marc Tommasi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1705.09869">
<title>Dimensionality reduction for acoustic vehicle classification with spectral embedding. (arXiv:1705.09869v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1705.09869</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a method for recognizing moving vehicles, using data from roadside
audio sensors. This problem has applications ranging widely, from traffic
analysis to surveillance. We extract a frequency signature from the audio
signal using a short-time Fourier transform, and treat each time window as an
individual data point to be classified. By applying a spectral embedding, we
decrease the dimensionality of the data sufficiently for K-nearest neighbors to
provide accurate vehicle identification.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sunu_J/0/1/0/all/0/1&quot;&gt;Justin Sunu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Percus_A/0/1/0/all/0/1&quot;&gt;Allon G. Percus&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1707.06618">
<title>Global Convergence of Langevin Dynamics Based Algorithms for Nonconvex Optimization. (arXiv:1707.06618v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1707.06618</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a unified framework to analyze the global convergence of Langevin
dynamics based algorithms for nonconvex finite-sum optimization with $n$
component functions. At the core of our analysis is a direct analysis of the
ergodicity of the numerical approximations to Langevin dynamics, which leads to
faster convergence rates. Specifically, we show that gradient Langevin dynamics
(GLD) and stochastic gradient Langevin dynamics (SGLD) converge to the almost
minimizer within $\tilde O\big(nd/(\lambda\epsilon) \big)$ and $\tilde
O\big(d^7/(\lambda^5\epsilon^5) \big)$ stochastic gradient evaluations
respectively, where $d$ is the problem dimension, and $\lambda$ is the spectral
gap of the Markov chain generated by GLD. Both of the results improve upon the
best known gradient complexity results. Furthermore, for the first time we
prove the global convergence guarantee for variance reduced stochastic gradient
Langevin dynamics (VR-SGLD) to the almost minimizer after $\tilde
O\big(\sqrt{n}d^5/(\lambda^4\epsilon^{5/2})\big)$ stochastic gradient
evaluations, which outperforms the gradient complexities of GLD and SGLD in a
wide regime. Our theoretical analyses shed some light on using Langevin
dynamics based algorithms for nonconvex optimization with provable guarantees.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Xu_P/0/1/0/all/0/1&quot;&gt;Pan Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chen_J/0/1/0/all/0/1&quot;&gt;Jinghui Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zou_D/0/1/0/all/0/1&quot;&gt;Difan Zou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gu_Q/0/1/0/all/0/1&quot;&gt;Quanquan Gu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1707.08092">
<title>Restricted Eigenvalue from Stable Rank with Applications to Sparse Linear Regression. (arXiv:1707.08092v4 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1707.08092</link>
<description rdf:parseType="Literal">&lt;p&gt;High-dimensional settings, where the data dimension ($d$) far exceeds the
number of observations ($n$), are common in many statistical and machine
learning applications. Methods based on $\ell_1$-relaxation, such as Lasso, are
very popular for sparse recovery in these settings. Restricted Eigenvalue (RE)
condition is among the weakest, and hence the most general, condition in
literature imposed on the Gram matrix that guarantees nice statistical
properties for the Lasso estimator. It is natural to ask: what families of
matrices satisfy the RE condition? Following a line of work in this area, we
construct a new broad ensemble of dependent random design matrices that have an
explicit RE bound. Our construction starts with a fixed (deterministic) matrix
$X \in \mathbb{R}^{n \times d}$ satisfying a simple stable rank condition, and
we show that a matrix drawn from the distribution $X \Phi^\top \Phi$, where
$\Phi \in \mathbb{R}^{m \times d}$ is a subgaussian random matrix, with high
probability, satisfies the RE condition. This construction allows incorporating
a fixed matrix that has an easily {\em verifiable} condition into the design
process, and allows for generation of {\em compressed} design matrices that
have a lower storage requirement than a standard design matrix. We give two
applications of this construction to sparse linear regression problems,
including one to a compressed sparse regression setting where the regression
algorithm only has access to a compressed representation of a fixed design
matrix $X$.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kasiviswanathan_S/0/1/0/all/0/1&quot;&gt;Shiva Prasad Kasiviswanathan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rudelson_M/0/1/0/all/0/1&quot;&gt;Mark Rudelson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.07804">
<title>Zeroth-Order Online Alternating Direction Method of Multipliers: Convergence Analysis and Applications. (arXiv:1710.07804v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1710.07804</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we design and analyze a new zeroth-order online algorithm,
namely, the zeroth-order online alternating direction method of multipliers
(ZOO-ADMM), which enjoys dual advantages of being gradient-free operation and
employing the ADMM to accommodate complex structured regularizers. Compared to
the first-order gradient-based online algorithm, we show that ZOO-ADMM requires
$\sqrt{m}$ times more iterations, leading to a convergence rate of
$O(\sqrt{m}/\sqrt{T})$, where $m$ is the number of optimization variables, and
$T$ is the number of iterations. To accelerate ZOO-ADMM, we propose two
minibatch strategies: gradient sample averaging and observation averaging,
resulting in an improved convergence rate of $O(\sqrt{1+q^{-1}m}/\sqrt{T})$,
where $q$ is the minibatch size. In addition to convergence analysis, we also
demonstrate ZOO-ADMM to applications in signal processing, statistics, and
machine learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Liu_S/0/1/0/all/0/1&quot;&gt;Sijia Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chen_J/0/1/0/all/0/1&quot;&gt;Jie Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chen_P/0/1/0/all/0/1&quot;&gt;Pin-Yu Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hero_A/0/1/0/all/0/1&quot;&gt;Alfred O. Hero&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.00382">
<title>A Large Dimensional Study of Regularized Discriminant Analysis Classifiers. (arXiv:1711.00382v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1711.00382</link>
<description rdf:parseType="Literal">&lt;p&gt;This article carries out a large dimensional analysis of standard regularized
discriminant analysis classifiers designed on the assumption that data arise
from a Gaussian mixture model with different means and covariances. The
analysis relies on fundamental results from random matrix theory (RMT) when
both the number of features and the cardinality of the training data within
each class grow large at the same pace. Under mild assumptions, we show that
the asymptotic classification error approaches a deterministic quantity that
depends only on the means and covariances associated with each class as well as
the problem dimensions. Such a result permits a better understanding of the
performance of regularized discriminant analsysis, in practical large but
finite dimensions, and can be used to determine and pre-estimate the optimal
regularization parameter that minimizes the misclassification error
probability. Despite being theoretically valid only for Gaussian data, our
findings are shown to yield a high accuracy in predicting the performances
achieved with real data sets drawn from the popular USPS data base, thereby
making an interesting connection between theory and practice.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Elkhalil_K/0/1/0/all/0/1&quot;&gt;Khalil Elkhalil&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kammoun_A/0/1/0/all/0/1&quot;&gt;Abla Kammoun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Couillet_R/0/1/0/all/0/1&quot;&gt;Romain Couillet&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Al_Naffouri_T/0/1/0/all/0/1&quot;&gt;Tareq Y. Al-Naffouri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Alouini_M/0/1/0/all/0/1&quot;&gt;Mohamed-Slim Alouini&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.01921">
<title>$A^{4}NT$: Author Attribute Anonymity by Adversarial Training of Neural Machine Translation. (arXiv:1711.01921v3 [cs.CR] UPDATED)</title>
<link>http://arxiv.org/abs/1711.01921</link>
<description rdf:parseType="Literal">&lt;p&gt;Text-based analysis methods allow to reveal privacy relevant author
attributes such as gender, age and identify of the text&apos;s author. Such methods
can compromise the privacy of an anonymous author even when the author tries to
remove privacy sensitive content. In this paper, we propose an automatic
method, called Adversarial Author Attribute Anonymity Neural Translation
($A^4NT$), to combat such text-based adversaries. We combine
sequence-to-sequence language models used in machine translation and generative
adversarial networks to obfuscate author attributes. Unlike machine translation
techniques which need paired data, our method can be trained on unpaired
corpora of text containing different authors. Importantly, we propose and
evaluate techniques to impose constraints on our $A^4NT$ to preserve the
semantics of the input text. $A^4NT$ learns to make minimal changes to the
input text to successfully fool author attribute classifiers, while aiming to
maintain the meaning of the input. We show through experiments on two different
datasets and three settings that our proposed method is effective in fooling
the author attribute classifiers and thereby improving the anonymity of
authors.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shetty_R/0/1/0/all/0/1&quot;&gt;Rakshith Shetty&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schiele_B/0/1/0/all/0/1&quot;&gt;Bernt Schiele&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fritz_M/0/1/0/all/0/1&quot;&gt;Mario Fritz&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.02795">
<title>Approximate message passing for nonconvex sparse regularization with stability and asymptotic analysis. (arXiv:1711.02795v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1711.02795</link>
<description rdf:parseType="Literal">&lt;p&gt;We analyse a linear regression problem with nonconvex regularization called
smoothly clipped absolute deviation (SCAD) under an overcomplete Gaussian basis
for Gaussian random data. We propose an approximate message passing (AMP)
algorithm considering nonconvex regularization, namely SCAD-AMP, and
analytically show that the stability condition corresponds to the de
Almeida--Thouless condition in spin glass literature. Through asymptotic
analysis, we show the correspondence between the density evolution of SCAD-AMP
and the replica symmetric solution. Numerical experiments confirm that for a
sufficiently large system size, SCAD-AMP achieves the optimal performance
predicted by the replica method. Through replica analysis, a phase transition
between replica symmetric (RS) and replica symmetry breaking (RSB) region is
found in the parameter space of SCAD. The appearance of the RS region for a
nonconvex penalty is a significant advantage that indicates the region of
smooth landscape of the optimization problem. Furthermore, we analytically show
that the statistical representation performance of the SCAD penalty is better
than that of L1-based methods, and the minimum representation error under RS
assumption is obtained at the edge of the RS/RSB phase. The correspondence
between the convergence of the existing coordinate descent algorithm and RS/RSB
transition is also indicated.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sakata_A/0/1/0/all/0/1&quot;&gt;Ayaka Sakata&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Xu_Y/0/1/0/all/0/1&quot;&gt;Yingying Xu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.07168">
<title>Stein Variational Message Passing for Continuous Graphical Models. (arXiv:1711.07168v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1711.07168</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a novel distributed inference algorithm for continuous graphical
models, by extending Stein variational gradient descent (SVGD) to leverage the
Markov dependency structure of the distribution of interest. Our approach
combines SVGD with a set of structured local kernel functions defined on the
Markov blanket of each node, which alleviates the curse of high dimensionality
and simultaneously yields a distributed algorithm for decentralized inference
tasks. We justify our method with theoretical analysis and show that the use of
local kernels can be viewed as a new type of localized approximation that
matches the target distribution on the conditional distributions of each node
over its Markov blanket. Our empirical results show that our method outperforms
a variety of baselines including standard MCMC and particle message passing
methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wang_D/0/1/0/all/0/1&quot;&gt;Dilin Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zeng_Z/0/1/0/all/0/1&quot;&gt;Zhe Zeng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Liu_Q/0/1/0/all/0/1&quot;&gt;Qiang Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.08244">
<title>How Well Can Generative Adversarial Networks Learn Densities: A Nonparametric View. (arXiv:1712.08244v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1712.08244</link>
<description rdf:parseType="Literal">&lt;p&gt;We study in this paper the rate of convergence for learning densities under
the Generative Adversarial Networks (GAN) framework, borrowing insights from
nonparametric statistics. We introduce an improved GAN estimator that achieves
a faster rate, through simultaneously leveraging the level of smoothness in the
target density and the evaluation metric, which in theory remedies the mode
collapse problem reported in the literature. A minimax lower bound is
constructed to show that when the dimension is large, the exponent in the rate
for the new GAN estimator is near optimal. One can view our results as
answering in a quantitative way how well GAN learns a wide range of densities
with different smoothness properties, under a hierarchy of evaluation metrics.
As a byproduct, we also obtain improved generalization bounds for GAN with
deeper ReLU discriminator network.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Liang_T/0/1/0/all/0/1&quot;&gt;Tengyuan Liang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.06818">
<title>Recovering a Hidden Community in a Preferential Attachment Graph. (arXiv:1801.06818v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1801.06818</link>
<description rdf:parseType="Literal">&lt;p&gt;A message passing algorithm is derived for recovering a dense subgraph within
a graph generated by a variation of the Barab\&apos;asi-Albert preferential
attachment model. The estimator is assumed to know the arrival times, or order
of attachment, of the vertices. The derivation of the algorithm is based on
belief propagation under an independence assumption. Two precursors to the
message passing algorithm are analyzed: the first is a degree thresholding (DT)
algorithm and the second is an algorithm based on the arrival times of the
children (C) of a given vertex, where the children of a given vertex are the
vertices that attached to it. Algorithm C significantly outperforms DT, showing
it is beneficial to know the arrival times of the children, beyond simply
knowing the number of them. For fixed fraction of vertices in the community,
fixed number of new edges per arriving vertex, and fixed affinity between
vertices in the community, the probability of error for recovering the label of
a vertex is found as a function of the time of attachment, for either algorithm
DT or C, in the large graph limit. By averaging over the time of attachment,
the limit in probability of the fraction of label errors made over all vertices
is identified, for either of the algorithms DT or C.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hajek_B/0/1/0/all/0/1&quot;&gt;Bruce Hajek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sankagiri_S/0/1/0/all/0/1&quot;&gt;Suryanarayana Sankagiri&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.03532">
<title>Bayesian Optimization Using Monotonicity Information and Its Application in Machine Learning Hyperparameter. (arXiv:1802.03532v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1802.03532</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose an algorithm for a family of optimization problems where the
objective can be decomposed as a sum of functions with monotonicity properties.
The motivating problem is optimization of hyperparameters of machine learning
algorithms, where we argue that the objective, validation error, can be
decomposed as monotonic functions of the hyperparameters. Our proposed
algorithm adapts Bayesian optimization methods to incorporate the monotonicity
constraints. We illustrate the advantages of exploiting monotonicity using
illustrative examples and demonstrate the improvements in optimization
efficiency for some machine learning hyperparameter tuning applications.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1&quot;&gt;Wenyi Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Welch_W/0/1/0/all/0/1&quot;&gt;William J. Welch&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.03692">
<title>Nearly Optimal Adaptive Procedure for Piecewise-Stationary Bandit: a Change-Point Detection Approach. (arXiv:1802.03692v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1802.03692</link>
<description rdf:parseType="Literal">&lt;p&gt;Multi-armed bandit (MAB) is a class of online learning problems where a
learning agent aims to maximize its expected cumulative reward while repeatedly
selecting to pull arms with unknown reward distributions. In this paper, we
consider a scenario in which the arms&apos; reward distributions may change in a
piecewise-stationary fashion at unknown time steps. By connecting
change-detection techniques with classic UCB algorithms, we motivate and
propose a learning algorithm called M-UCB, which can detect and adapt to
changes, for the considered scenario. We also establish an $O(\sqrt{MKT\log
T})$ regret bound for M-UCB, where $T$ is the number of time steps, $K$ is the
number of arms, and $M$ is the number of stationary segments. Comparison with
the best available lower bound shows that M-UCB is nearly optimal in $T$ up to
a logarithmic factor. We also compare M-UCB with state-of-the-art algorithms in
a numerical experiment based on a public Yahoo! dataset. In this experiment,
M-UCB achieves about $50 \%$ regret reduction with respect to the best
performing state-of-the-art algorithm.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Cao_Y/0/1/0/all/0/1&quot;&gt;Yang Cao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wen_Z/0/1/0/all/0/1&quot;&gt;Zheng Wen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kveton_B/0/1/0/all/0/1&quot;&gt;Branislav Kveton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Xie_Y/0/1/0/all/0/1&quot;&gt;Yao Xie&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04826">
<title>Leveraging the Exact Likelihood of Deep Latent Variable Models. (arXiv:1802.04826v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1802.04826</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep latent variable models combine the approximation abilities of deep
neural networks and the statistical foundations of generative models. The
induced data distribution is an infinite mixture model whose density is
extremely delicate to compute. Variational methods are consequently used for
inference, following the seminal work of Rezende et al. (2014) and Kingma and
Welling (2014). We study the well-posedness of the exact problem (maximum
likelihood) these techniques approximatively solve. In particular, we show that
most unconstrained models used for continuous data have an unbounded
likelihood. This ill-posedness and the problems it causes are illustrated on
real data. We also show how to insure the existence of maximum likelihood
estimates, and draw useful connections with nonparametric mixture models.
Furthermore, we describe an algorithm that allows to perform missing data
imputation using the exact conditional likelihood of a deep latent variable
model. On several real data sets, our algorithm consistently and significantly
outperforms the usual imputation scheme used within deep latent variable
models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mattei_P/0/1/0/all/0/1&quot;&gt;Pierre-Alexandre Mattei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Frellsen_J/0/1/0/all/0/1&quot;&gt;Jes Frellsen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05910">
<title>Pattern Localization in Time Series through Signal-To-Model Alignment in Latent Space. (arXiv:1802.05910v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1802.05910</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we study the problem of locating a predefined sequence of
patterns in a time series. In particular, the studied scenario assumes a
theoretical model is available that contains the expected locations of the
patterns. This problem is found in several contexts, and it is commonly solved
by first synthesizing a time series from the model, and then aligning it to the
true time series through dynamic time warping. We propose a technique that
increases the similarity of both time series before aligning them, by mapping
them into a latent correlation space. The mapping is learned from the data
through a machine-learning setup. Experiments on data from non-destructive
testing demonstrate that the proposed approach shows significant improvements
over the state of the art.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vaerenbergh_S/0/1/0/all/0/1&quot;&gt;Steven Van Vaerenbergh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Santamaria_I/0/1/0/all/0/1&quot;&gt;Ignacio Santamaria&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Elvira_V/0/1/0/all/0/1&quot;&gt;Victor Elvira&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Salvatori_M/0/1/0/all/0/1&quot;&gt;Matteo Salvatori&lt;/a&gt;</dc:creator>
</item></rdf:RDF>