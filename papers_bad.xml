<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Boring papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Bad Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-05-08T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.03033"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.03180"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05991"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.01929"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.01937"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.01941"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.01942"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.02682"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.02754"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.02785"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.02856"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.02859"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.02861"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.02867"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.02874"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.02895"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.02896"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.02912"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.02921"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.02971"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.03090"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.03094"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.03141"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.08893"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06306"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.00983"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.02408"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.02677"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.02840"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.02848"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.02908"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.02991"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.03006"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.03096"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1703.04599"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1708.07581"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.08511"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.11469"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06939"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.07891"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.08603"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.02627"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1805.03033">
<title>Efficient Design of Hardware-Enabled Recurrent Neural Networks. (arXiv:1805.03033v1 [cs.ET])</title>
<link>http://arxiv.org/abs/1805.03033</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work, we propose a new approach towards the efficient design of
reservoir computing hardware. First, we adapt the reservoir input mask to the
structure of the data via linear autoencoders. We therefore incorporate the
advantages of dimensionality reduction and dimensionality expansion achieved by
conventional and efficient linear algebra procedures of principal component
analysis. Second, we employ evolutionary-inspired genetic algorithm techniques
resulting in a highly efficient optimization of reservoir dynamics. We
illustrate the method on the so-called single-node reservoir computing
architecture, especially suitable for implementation in ultrahigh-speed
hardware. The combination of both methods and the resulting reduction of time
required for performance optimization of a hardware system establish a strategy
towards machine learning hardware capable of self-adaption to optimally solve
specific problems. We confirm the validity of those principles building RC
hardware based on a field-programmable gate array.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Penkovsky_B/0/1/0/all/0/1&quot;&gt;Bogdan Penkovsky&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Larger_L/0/1/0/all/0/1&quot;&gt;Laurent Larger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brunner_D/0/1/0/all/0/1&quot;&gt;Daniel Brunner&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.03180">
<title>Deep D-bar: Real time Electrical Impedance Tomography Imaging with Deep Neural Networks. (arXiv:1711.03180v2 [math.NA] UPDATED)</title>
<link>http://arxiv.org/abs/1711.03180</link>
<description rdf:parseType="Literal">&lt;p&gt;The mathematical problem for Electrical Impedance Tomography (EIT) is a
highly nonlinear ill-posed inverse problem requiring carefully designed
reconstruction procedures to ensure reliable image generation. D-bar methods
are based on a rigorous mathematical analysis and provide robust direct
reconstructions by using a low-pass filtering of the associated nonlinear
Fourier data. Similarly to low-pass filtering of linear Fourier data, only
using low frequencies in the image recovery process results in blurred images
lacking sharp features such as clear organ boundaries. Convolutional Neural
Networks provide a powerful framework for post-processing such convolved direct
reconstructions. In this study, we demonstrate that these CNN techniques lead
to sharp and reliable reconstructions even for the highly nonlinear inverse
problem of EIT. The network is trained on data sets of simulated examples and
then applied to experimental data without the need to perform an additional
transfer training. Results for absolute EIT images are presented using
experimental EIT data from the ACT4 and KIT4 EIT systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Hamilton_S/0/1/0/all/0/1&quot;&gt;Sarah Jane Hamilton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Hauptmann_A/0/1/0/all/0/1&quot;&gt;Andreas Hauptmann&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05991">
<title>The N-Tuple Bandit Evolutionary Algorithm for Game Agent Optimisation. (arXiv:1802.05991v2 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1802.05991</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper describes the N-Tuple Bandit Evolutionary Algorithm (NTBEA), an
optimisation algorithm developed for noisy and expensive discrete
(combinatorial) optimisation problems. The algorithm is applied to two
game-based hyper-parameter optimisation problems. The N-Tuple system directly
models the statistics, approximating the fitness and number of evaluations of
each modelled combination of parameters. The model is simple, efficient and
informative. Results show that the NTBEA significantly outperforms grid search
and an estimation of distribution algorithm.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lucas_S/0/1/0/all/0/1&quot;&gt;Simon M Lucas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Jialin Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Perez_Liebana_D/0/1/0/all/0/1&quot;&gt;Diego Perez-Liebana&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.01929">
<title>Superconducting Optoelectronic Neurons I: General Principles. (arXiv:1805.01929v2 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1805.01929</link>
<description rdf:parseType="Literal">&lt;p&gt;The design of neural hardware is informed by the prominence of differentiated
processing and information integration in cognitive systems. The central role
of communication leads to the principal assumption of the hardware platform:
signals between neurons should be optical to enable fanout and communication
with minimal delay. The requirement of energy efficiency leads to the
utilization of superconducting detectors to receive single-photon signals. We
discuss the potential of superconducting optoelectronic hardware to achieve the
spatial and temporal information integration advantageous for cognitive
processing, and we consider physical scaling limits based on light-speed
communication. We introduce the superconducting optoelectronic neurons and
networks that are the subject of the subsequent papers in this series.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shainline_J/0/1/0/all/0/1&quot;&gt;Jeffrey M. Shainline&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Buckley_S/0/1/0/all/0/1&quot;&gt;Sonia M. Buckley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+McCaughan_A/0/1/0/all/0/1&quot;&gt;Adam N. McCaughan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chiles_J/0/1/0/all/0/1&quot;&gt;Jeff Chiles&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mirin_R/0/1/0/all/0/1&quot;&gt;Richard P. Mirin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nam_S/0/1/0/all/0/1&quot;&gt;Sae Woo Nam&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.01937">
<title>Superconducting Optoelectronic Neurons III: Synaptic Plasticity. (arXiv:1805.01937v2 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1805.01937</link>
<description rdf:parseType="Literal">&lt;p&gt;As a means of dynamically reconfiguring the synaptic weight of a
superconducting optoelectronic loop neuron, a superconducting flux storage loop
is inductively coupled to the synaptic current bias of the neuron. A standard
flux memory cell is used to achieve a binary synapse, and loops capable of
storing many flux quanta are used to enact multi-stable synapses. Circuits are
designed to implement supervised learning wherein current pulses add or remove
flux from the loop to strengthen or weaken the synaptic weight. Designs are
presented for circuits with hundreds of intermediate synaptic weights between
minimum and maximum strengths. Circuits for implementing unsupervised learning
are modeled using two photons to strengthen and two photons to weaken the
synaptic weight via Hebbian and anti-Hebbian learning rules, and techniques are
proposed to control the learning rate. Implementation of short-term plasticity,
homeostatic plasticity, and metaplasticity in loop neurons is discussed.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shainline_J/0/1/0/all/0/1&quot;&gt;Jeffrey M. Shainline&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+McCaughan_A/0/1/0/all/0/1&quot;&gt;Adam N. McCaughan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Buckley_S/0/1/0/all/0/1&quot;&gt;Sonia M. Buckley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Donnelly_C/0/1/0/all/0/1&quot;&gt;Christine A. Donnelly&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Castellanos_Beltran_M/0/1/0/all/0/1&quot;&gt;Manuel Castellanos-Beltran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schneider_M/0/1/0/all/0/1&quot;&gt;Michael L. Schneider&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mirin_R/0/1/0/all/0/1&quot;&gt;Richard P. Mirin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nam_S/0/1/0/all/0/1&quot;&gt;Sae Woo Nam&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.01941">
<title>Superconducting Optoelectronic Neurons IV: Transmitter Circuits. (arXiv:1805.01941v2 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1805.01941</link>
<description rdf:parseType="Literal">&lt;p&gt;A superconducting optoelectronic neuron will produce a small current pulse
upon reaching threshold. We present an amplifier chain that converts this small
current pulse to a voltage pulse sufficient to produce light from a
semiconductor diode. This light is the signal used to communicate between
neurons in the network. The amplifier chain comprises a thresholding Josephson
junction, a relaxation oscillator Josephson junction, a superconducting
thin-film current-gated current amplifier, and a superconducting thin-film
current-gated voltage amplifier. We analyze the performance of the elements in
the amplifier chain in the time domain to calculate the energy consumption per
photon created for several values of light-emitting diode capacitance and
efficiency. The speed of the amplification sequence allows neuronal firing up
to at least 20\,MHz with power density low enough to be cooled easily with
standard $^4$He cryogenic systems operating at 4.2\,K.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shainline_J/0/1/0/all/0/1&quot;&gt;Jeffrey M. Shainline&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+McCaughan_A/0/1/0/all/0/1&quot;&gt;Adam N. McCaughan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Buckley_S/0/1/0/all/0/1&quot;&gt;Sonia M. Buckley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mirin_R/0/1/0/all/0/1&quot;&gt;Richard P. Mirin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nam_S/0/1/0/all/0/1&quot;&gt;Sae Woo Nam&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.01942">
<title>Superconducting Optoelectronic Neurons V: Networks and Scaling. (arXiv:1805.01942v2 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1805.01942</link>
<description rdf:parseType="Literal">&lt;p&gt;Networks of superconducting optoelectronic neurons are investigated for their
near-term technological potential and long-term physical limitations. Networks
with short average path length, high clustering coefficient, and power-law
degree distribution are designed using a growth model that assigns connections
between new and existing nodes based on spatial distance as well as degree of
existing nodes. The network construction algorithm is scalable to arbitrary
levels of network hierarchy and achieves systems with fractal spatial
properties and efficient wiring. By modeling the physical size of
superconducting optoelectronic neurons, we calculate the area of these
networks. A system with 8100 neurons and 330,430 total synapses will fit on a
1\,cm $\times$ 1\,cm die. Systems of millions of neurons with hundreds of
millions of synapses will fit on a 300\,mm wafer. For multi-wafer assemblies,
communication at light speed enables a neuronal pool the size of a large data
center comprising 100 trillion neurons with coherent oscillations at 1\,MHz.
Assuming a power law frequency distribution, as is necessary for self-organized
criticality, we calculate the power consumption of the networks. We find the
use of single photons for communication and superconducting circuits for
computation leads to power density low enough to be cooled by liquid $^4$He for
networks of any scale.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shainline_J/0/1/0/all/0/1&quot;&gt;Jeffrey M. Shainline&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chiles_J/0/1/0/all/0/1&quot;&gt;Jeff Chiles&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Buckley_S/0/1/0/all/0/1&quot;&gt;Sonia M. Buckley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+McCaughan_A/0/1/0/all/0/1&quot;&gt;Adam N. McCaughan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mirin_R/0/1/0/all/0/1&quot;&gt;Richard P. Mirin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nam_S/0/1/0/all/0/1&quot;&gt;Sae Woo Nam&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.02682">
<title>Predicting Graph Categories from Structural Properties. (arXiv:1805.02682v1 [cs.SI])</title>
<link>http://arxiv.org/abs/1805.02682</link>
<description rdf:parseType="Literal">&lt;p&gt;Complex networks are often categorized according to the underlying phenomena
that they represent such as molecular interactions, re-tweets, and brain
activity. In this work, we investigate the problem of predicting the category
(domain) of arbitrary networks. This includes complex networks from different
domains as well as synthetically generated graphs from five different network
models. A classification accuracy of $96.6\%$ is achieved using a random forest
classifier with both real and synthetic networks. This work makes two important
findings. First, our results indicate that complex networks from various
domains have distinct structural properties that allow us to predict with high
accuracy the category of a new previously unseen network. Second, synthetic
graphs are trivial to classify as the classification model can predict with
near-certainty the network model used to generate it. Overall, the results
demonstrate that networks drawn from different domains (and network models) are
trivial to distinguish using only a handful of simple structural properties.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Canning_J/0/1/0/all/0/1&quot;&gt;James P. Canning&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ingram_E/0/1/0/all/0/1&quot;&gt;Emma E. Ingram&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nowak_Wolff_S/0/1/0/all/0/1&quot;&gt;Sammantha Nowak-Wolff&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ortiz_A/0/1/0/all/0/1&quot;&gt;Adriana M. Ortiz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ahmed_N/0/1/0/all/0/1&quot;&gt;Nesreen K. Ahmed&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rossi_R/0/1/0/all/0/1&quot;&gt;Ryan A. Rossi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schmitt_K/0/1/0/all/0/1&quot;&gt;Karl R. B. Schmitt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Soundarajan_S/0/1/0/all/0/1&quot;&gt;Sucheta Soundarajan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.02754">
<title>Verisimilar Percept Sequences Tests for Autonomous Driving Intelligent Agent Assessment. (arXiv:1805.02754v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1805.02754</link>
<description rdf:parseType="Literal">&lt;p&gt;The autonomous car technology promises to replace human drivers with safer
driving systems. But although autonomous cars can become safer than human
drivers this is a long process that is going to be refined over time. Before
these vehicles are deployed on urban roads a minimum safety level must be
assured. Since the autonomous car technology is still under development there
is no standard methodology to evaluate such systems. It is important to
completely understand the technology that is being developed to design
efficient means to evaluate it. In this paper we assume safety-critical systems
reliability as a safety measure. We model an autonomous road vehicle as an
intelligent agent and we approach its evaluation from an artificial
intelligence perspective. Our focus is the evaluation of perception and
decision making systems and also to propose a systematic method to evaluate
their integration in the vehicle. We identify critical aspects of the data
dependency from the artificial intelligence state of the art models and we also
propose procedures to reproduce them.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Watanabe_T/0/1/0/all/0/1&quot;&gt;Thomio Watanabe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wolf_D/0/1/0/all/0/1&quot;&gt;Denis Wolf&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.02785">
<title>Fast Online Exact Solutions for Deterministic MDPs with Sparse Rewards. (arXiv:1805.02785v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.02785</link>
<description rdf:parseType="Literal">&lt;p&gt;Markov Decision Processes (MDPs) are a mathematical framework for modeling
sequential decision making under uncertainty. The classical approaches for
solving MDPs are well known and have been widely studied, some of which rely on
approximation techniques to solve MDPs with large state space and/or action
space. However, most of these classical solution approaches and their
approximation techniques still take much computation time to converge and
usually must be re-computed if the reward function is changed. This paper
introduces a novel alternative approach for exactly and efficiently solving
deterministic, continuous MDPs with sparse reward sources. When the environment
is such that the &quot;distance&quot; between states can be determined in constant time,
e.g. grid world, our algorithm offers $O( |R|^2 \times |A|^2 \times |S|)$,
where $|R|$ is the number of reward sources, $|A|$ is the number of actions,
and $|S|$ is the number of states. Memory complexity for the algorithm is $O(
|S| + |R| \times |A|)$. This new approach opens new avenues for boosting
computational performance for certain classes of MDPs and is of tremendous
value for MDP applications such as robotics and unmanned systems. This paper
describes the algorithm and presents numerical experiment results to
demonstrate its powerful computational performance. We also provide rigorous
mathematical description of the approach.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bertram_J/0/1/0/all/0/1&quot;&gt;Joshua R. Bertram&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_X/0/1/0/all/0/1&quot;&gt;Xuxi Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wei_P/0/1/0/all/0/1&quot;&gt;Peng Wei&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.02856">
<title>Reasoning with Sarcasm by Reading In-between. (arXiv:1805.02856v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1805.02856</link>
<description rdf:parseType="Literal">&lt;p&gt;Sarcasm is a sophisticated speech act which commonly manifests on social
communities such as Twitter and Reddit. The prevalence of sarcasm on the social
web is highly disruptive to opinion mining systems due to not only its tendency
of polarity flipping but also usage of figurative language. Sarcasm commonly
manifests with a contrastive theme either between positive-negative sentiments
or between literal-figurative scenarios. In this paper, we revisit the notion
of modeling contrast in order to reason with sarcasm. More specifically, we
propose an attention-based neural model that looks in-between instead of
across, enabling it to explicitly model contrast and incongruity. We conduct
extensive experiments on six benchmark datasets from Twitter, Reddit and the
Internet Argument Corpus. Our proposed model not only achieves state-of-the-art
performance on all datasets but also enjoys improved interpretability.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tay_Y/0/1/0/all/0/1&quot;&gt;Yi Tay&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tuan_L/0/1/0/all/0/1&quot;&gt;Luu Anh Tuan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hui_S/0/1/0/all/0/1&quot;&gt;Siu Cheung Hui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Su_J/0/1/0/all/0/1&quot;&gt;Jian Su&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.02859">
<title>On the Conditional Logic of Simulation Models. (arXiv:1805.02859v1 [cs.LO])</title>
<link>http://arxiv.org/abs/1805.02859</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose analyzing conditional reasoning by appeal to a notion of
intervention on a simulation program, formalizing and subsuming a number of
approaches to conditional thinking in the recent AI literature. Our main
results include a series of axiomatizations, allowing comparison between this
framework and existing frameworks (normality-ordering models, causal structural
equation models), and a complexity result establishing NP-completeness of the
satisfiability problem. Perhaps surprisingly, some of the basic logical
principles common to all existing approaches are invalidated in our causal
simulation approach. We suggest that this additional flexibility is important
in modeling some intuitive examples.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ibeling_D/0/1/0/all/0/1&quot;&gt;Duligur Ibeling&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Icard_T/0/1/0/all/0/1&quot;&gt;Thomas Icard&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.02861">
<title>Synthesizing Efficient Solutions for Patrolling Problems in the Internet Environment. (arXiv:1805.02861v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1805.02861</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose an algorithm for constructing efficient patrolling strategies in
the Internet environment, where the protected targets are nodes connected to
the network and the patrollers are software agents capable of
detecting/preventing undesirable activities on the nodes. The algorithm is
based on a novel compositional principle designed for a special class of
strategies, and it can quickly construct (sub)optimal solutions even if the
number of targets reaches hundreds of millions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brazdil_T/0/1/0/all/0/1&quot;&gt;Tom&amp;#xe1;&amp;#x161; Br&amp;#xe1;zdil&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kucera_A/0/1/0/all/0/1&quot;&gt;Anton&amp;#xed;n Ku&amp;#x10d;era&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rehak_V/0/1/0/all/0/1&quot;&gt;Vojt&amp;#x11b;ch &amp;#x158;eh&amp;#xe1;k&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.02867">
<title>Online normalizer calculation for softmax. (arXiv:1805.02867v1 [cs.PF])</title>
<link>http://arxiv.org/abs/1805.02867</link>
<description rdf:parseType="Literal">&lt;p&gt;The Softmax function is ubiquitous in machine learning, multiple previous
works suggested faster alternatives for it. In this paper we propose a way to
compute classical Softmax with fewer memory accesses and hypothesize that this
reduction in memory accesses should improve Softmax performance on actual
hardware. The benchmarks confirm this hypothesis: Softmax accelerates by up to
1.3x and Softmax+TopK combined by up to 5x.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Milakov_M/0/1/0/all/0/1&quot;&gt;Maxim Milakov&lt;/a&gt; (NVIDIA), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gimelshein_N/0/1/0/all/0/1&quot;&gt;Natalia Gimelshein&lt;/a&gt; (NVIDIA)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.02874">
<title>Finding Frequent Entities in Continuous Data. (arXiv:1805.02874v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1805.02874</link>
<description rdf:parseType="Literal">&lt;p&gt;In many applications that involve processing high-dimensional data, it is
important to identify a small set of entities that account for a significant
fraction of detections. Rather than formalize this as a clustering problem, in
which all detections must be grouped into hard or soft categories, we formalize
it as an instance of the frequent items or heavy hitters problem, which finds
groups of tightly clustered objects that have a high density in the feature
space. We show that the heavy hitters formulation generates solutions that are
more accurate and effective than the clustering formulation. In addition, we
present a novel online algorithm for heavy hitters, called HAC, which addresses
problems in continuous space, and demonstrate its effectiveness on real video
and household domains.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alet_F/0/1/0/all/0/1&quot;&gt;Ferran Alet&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chitnis_R/0/1/0/all/0/1&quot;&gt;Rohan Chitnis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kaelbling_L/0/1/0/all/0/1&quot;&gt;Leslie P. Kaelbling&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lozano_Perez_T/0/1/0/all/0/1&quot;&gt;Tomas Lozano-Perez&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.02895">
<title>Driving maneuvers prediction based on cognition-driven and data-driven method. (arXiv:1805.02895v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1805.02895</link>
<description rdf:parseType="Literal">&lt;p&gt;Advanced Driver Assistance Systems (ADAS) improve driving safety
significantly. They alert drivers from unsafe traffic conditions when a
dangerous maneuver appears. Traditional methods to predict driving maneuvers
are mostly based on data-driven models alone. However, existing methods to
understand the driver&apos;s intention remain an ongoing challenge due to a lack of
intersection of human cognition and data analysis. To overcome this challenge,
we propose a novel method that combines both the cognition-driven model and the
data-driven model. We introduce a model named Cognitive Fusion-RNN (CF-RNN)
which fuses the data inside the vehicle and the data outside the vehicle in a
cognitive way. The CF-RNN model consists of two Long Short-Term Memory (LSTM)
branches regulated by human reaction time. Experiments on the Brain4Cars
benchmark dataset demonstrate that the proposed method outperforms previous
methods and achieves state-of-the-art performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_D/0/1/0/all/0/1&quot;&gt;Dong Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_H/0/1/0/all/0/1&quot;&gt;Huimin Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dong_Y/0/1/0/all/0/1&quot;&gt;Yuhan Dong&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.02896">
<title>Survey and cross-benchmark comparison of remaining time prediction methods in business process monitoring. (arXiv:1805.02896v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1805.02896</link>
<description rdf:parseType="Literal">&lt;p&gt;Predictive business process monitoring methods exploit historical process
execution logs to generate predictions about running instances of a process,
including predictions of the remaining cycle time of running cases of a
process. A number of approaches to tackle this latter prediction problem have
been proposed in the literature. However, due to differences in the
experimental setups, choice of datasets, evaluation measures and baselines, the
relative performance of various methods remains unclear. This article presents
a systematic review and taxonomy of methods for remaining time prediction in
the context of business processes, as well as a cross-benchmark comparison of
16 methods based on 16 real-life datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Verenich_I/0/1/0/all/0/1&quot;&gt;Ilya Verenich&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dumas_M/0/1/0/all/0/1&quot;&gt;Marlon Dumas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rosa_M/0/1/0/all/0/1&quot;&gt;Marcello La Rosa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Maggi_F/0/1/0/all/0/1&quot;&gt;Fabrizio Maggi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Teinemaa_I/0/1/0/all/0/1&quot;&gt;Irene Teinemaa&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.02912">
<title>The Complexity of Limited Belief Reasoning -- The Quantifier-Free Case. (arXiv:1805.02912v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1805.02912</link>
<description rdf:parseType="Literal">&lt;p&gt;The classical view of epistemic logic is that an agent knows all the logical
consequences of their knowledge base. This assumption of logical omniscience is
often unrealistic and makes reasoning computationally intractable. One approach
to avoid logical omniscience is to limit reasoning to a certain belief level,
which intuitively measures the reasoning &quot;depth.&quot; This paper investigates the
computational complexity of reasoning with belief levels. First we show that
while reasoning remains tractable if the level is constant, the complexity
jumps to PSPACE-complete -- that is, beyond classical reasoning -- when the
belief level is part of the input. Then we further refine the picture using
parameterized complexity theory to investigate how the belief level and the
number of non-logical symbols affect the complexity.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yijia Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saffidine_A/0/1/0/all/0/1&quot;&gt;Abdallah Saffidine&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schwering_C/0/1/0/all/0/1&quot;&gt;Christoph Schwering&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.02921">
<title>Hierarchical Temporal Memory using Memristor Networks: A Survey. (arXiv:1805.02921v1 [cs.AR])</title>
<link>http://arxiv.org/abs/1805.02921</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents a survey of the currently available hardware designs for
implementation of the human cortex inspired algorithm, Hierarchical Temporal
Memory (HTM). In this review, we focus on the state of the art advances of
memristive HTM implementation and related HTM applications. With the advent of
edge computing, HTM can be a potential algorithm to implement on-chip near
sensor data processing. The comparison of analog memristive circuit
implementations with the digital and mixed-signal solutions are provided. The
advantages of memristive HTM over digital implementations against performance
metrics such as processing speed, reduced on-chip area and power dissipation
are discussed. The limitations and open problems concerning the memristive HTM,
such as the design scalability, sneak currents, leakage, parasitic effects,
lack of the analog learning circuits implementations and unreliability of the
memristive devices integrated with CMOS circuits are also discussed.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Krestinskaya_O/0/1/0/all/0/1&quot;&gt;Olga Krestinskaya&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dolzhikova_I/0/1/0/all/0/1&quot;&gt;Irina Dolzhikova&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+James_A/0/1/0/all/0/1&quot;&gt;Alex Pappachen James&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.02971">
<title>Multinomial Logit Bandit with Linear Utility Functions. (arXiv:1805.02971v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.02971</link>
<description rdf:parseType="Literal">&lt;p&gt;Multinomial logit bandit is a sequential subset selection problem which
arises in many applications. In each round, the player selects a
$K$-cardinality subset from $N$ candidate items, and receives a reward which is
governed by a {\it multinomial logit} (MNL) choice model considering both item
utility and substitution property among items. The player&apos;s objective is to
dynamically learn the parameters of MNL model and maximize cumulative reward
over a finite horizon $T$. This problem faces the exploration-exploitation
dilemma, and the involved combinatorial nature makes it non-trivial. In recent
years, there have developed some algorithms by exploiting specific
characteristics of the MNL model, but all of them estimate the parameters of
MNL model separately and incur a regret no better than
$\tilde{O}\big(\sqrt{NT}\big)$ which is not preferred for large candidate set
size $N$. In this paper, we consider the {\it linear utility} MNL choice model
whose item utilities are represented as linear functions of $d$-dimension item
features, and propose an algorithm, titled {\bf LUMB}, to exploit the
underlying structure. It is proven that the proposed algorithm achieves
$\tilde{O}\big(dK\sqrt{T}\big)$ regret which is free of candidate set size.
Experiments show the superiority of the proposed algorithm.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ou_M/0/1/0/all/0/1&quot;&gt;Mingdong Ou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_N/0/1/0/all/0/1&quot;&gt;Nan Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_S/0/1/0/all/0/1&quot;&gt;Shenghuo Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jin_R/0/1/0/all/0/1&quot;&gt;Rong Jin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.03090">
<title>Deception in Optimal Control. (arXiv:1805.03090v1 [math.OC])</title>
<link>http://arxiv.org/abs/1805.03090</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we consider an adversarial scenario where one agent seeks to
achieve an objective and its adversary seeks to learn the agent&apos;s intentions
and prevent the agent from achieving its objective. The agent has an incentive
to try to deceive the adversary about its intentions, while at the same time
working to achieve its objective. The primary contribution of this paper is to
introduce a mathematically rigorous framework for the notion of deception
within the context of optimal control. The central notion introduced in the
paper is that of a belief-induced reward: a reward dependent not only on the
agent&apos;s state and action, but also adversary&apos;s beliefs. Design of an optimal
deceptive strategy then becomes a question of optimal control design on the
product of the agent&apos;s state space and the adversary&apos;s belief space. The
proposed framework allows for deception to be defined in an arbitrary control
system endowed with a reward function, as well as with additional
specifications limiting the agent&apos;s control policy. In addition to defining
deception, we discuss design of optimally deceptive strategies under
uncertainties in agent&apos;s knowledge about the adversary&apos;s learning process. In
the latter part of the paper, we focus on a setting where the agent&apos;s behavior
is governed by a Markov decision process, and show that the design of optimally
deceptive strategies under lack of knowledge about the adversary naturally
reduces to previously discussed problems in control design on partially
observable or uncertain Markov decision processes. Finally, we present two
examples of deceptive strategies: a &quot;cops and robbers&quot; scenario and an example
where an agent may use camouflage while moving. We show that optimally
deceptive strategies in such examples follow the intuitive idea of how to
deceive an adversary in the above settings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Ornik_M/0/1/0/all/0/1&quot;&gt;Melkior Ornik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Topcu_U/0/1/0/all/0/1&quot;&gt;Ufuk Topcu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.03094">
<title>Using Simpson&apos;s Paradox to Discover Interesting Patterns in Behavioral Data. (arXiv:1805.03094v1 [cs.CY])</title>
<link>http://arxiv.org/abs/1805.03094</link>
<description rdf:parseType="Literal">&lt;p&gt;We describe a data-driven discovery method that leverages Simpson&apos;s paradox
to uncover interesting patterns in behavioral data. Our method systematically
disaggregates data to identify subgroups within a population whose behavior
deviates significantly from the rest of the population. Given an outcome of
interest and a set of covariates, the method follows three steps. First, it
disaggregates data into subgroups, by conditioning on a particular covariate,
so as minimize the variation of the outcome within the subgroups. Next, it
models the outcome as a linear function of another covariate, both in the
subgroups and in the aggregate data. Finally, it compares trends to identify
disaggregations that produce subgroups with different behaviors from the
aggregate. We illustrate the method by applying it to three real-world
behavioral datasets, including Q\&amp;amp;A site Stack Exchange and online learning
platforms Khan Academy and Duolingo.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alipourfard_N/0/1/0/all/0/1&quot;&gt;Nazanin Alipourfard&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fennell_P/0/1/0/all/0/1&quot;&gt;Peter G. Fennell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lerman_K/0/1/0/all/0/1&quot;&gt;Kristina Lerman&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.03141">
<title>Parallel Computation of PDFs on Big Spatial Data Using Spark. (arXiv:1805.03141v1 [cs.DC])</title>
<link>http://arxiv.org/abs/1805.03141</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider big spatial data, which is typically produced in scientific areas
such as geological or seismic interpretation. The spatial data can be produced
by observation (e.g. using sensors or soil instrument) or numerical simulation
programs and correspond to points that represent a 3D soil cube area. However,
errors in signal processing and modeling create some uncertainty, and thus a
lack of accuracy in identifying geological or seismic phenomenons. Such
uncertainty must be carefully analyzed. To analyze uncertainty, the main
solution is to compute a Probability Density Function (PDF) of each point in
the spatial cube area. However, computing PDFs on big spatial data can be very
time consuming (from several hours to even months on a parallel computer). In
this paper, we propose a new solution to efficiently compute such PDFs in
parallel using Spark, with three methods: data grouping, machine learning
prediction and sampling. We evaluate our solution by extensive experiments on
different computer clusters using big data ranging from hundreds of GB to
several TB. The experimental results show that our solution scales up very well
and can reduce the execution time by a factor of 33 (in the order of seconds or
minutes) compared with a baseline method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Ji Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lemus_N/0/1/0/all/0/1&quot;&gt;Noel Moreno Lemus&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pacitti_E/0/1/0/all/0/1&quot;&gt;Esther Pacitti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Porto_F/0/1/0/all/0/1&quot;&gt;Fabio Porto&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Valduriez_P/0/1/0/all/0/1&quot;&gt;Patrick Valduriez&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.08893">
<title>Fast Model Identification via Physics Engines for Data-Efficient Policy Search. (arXiv:1710.08893v2 [cs.RO] UPDATED)</title>
<link>http://arxiv.org/abs/1710.08893</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents a method for identifying mechanical parameters of robots
or objects, such as their mass and friction coefficients. Key features are the
use of off-the-shelf physics engines and the adaptation of a Bayesian
optimization technique towards minimizing the number of real-world experiments
needed for model-based reinforcement learning. The proposed framework
reproduces in a physics engine experiments performed on a real robot and
optimizes the model&apos;s mechanical parameters so as to match real-world
trajectories. The optimized model is then used for learning a policy in
simulation, before real-world deployment. It is well understood, however, that
it is hard to exactly reproduce real trajectories in simulation. Moreover, a
near-optimal policy can be frequently found with an imperfect model. Therefore,
this work proposes a strategy for identifying a model that is just good enough
to approximate the value of a locally optimal policy with a certain confidence,
instead of wasting effort on identifying the most accurate model. Evaluations,
performed both in simulation and on a real robotic manipulation task, indicate
that the proposed strategy results in an overall time-efficient, integrated
model identification and learning solution, which significantly improves the
data-efficiency of existing policy search algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_S/0/1/0/all/0/1&quot;&gt;Shaojun Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kimmel_A/0/1/0/all/0/1&quot;&gt;Andrew Kimmel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bekris_K/0/1/0/all/0/1&quot;&gt;Kostas E. Bekris&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Boularias_A/0/1/0/all/0/1&quot;&gt;Abdeslam Boularias&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06306">
<title>Optimizing Interactive Systems with Data-Driven Objectives. (arXiv:1802.06306v5 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1802.06306</link>
<description rdf:parseType="Literal">&lt;p&gt;Effective optimization is essential for interactive systems to provide a
satisfactory user experience. However, it is often challenging to find an
objective to optimize for. Generally, such objectives are manually crafted and
rarely capture complex user needs accurately. Conversely, we propose an
approach that infers the objective directly from observed user interactions.
These inferences can be made regardless of prior knowledge and across different
types of user behavior. Then we introduce: Interactive System Optimizer (ISO),
a novel algorithm that uses these inferred objectives for optimization. Our
main contribution is a new general principled approach to optimizing
interactive systems using data-driven objectives. We demonstrate the high
effectiveness of ISO over several GridWorld simulations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Ziming Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grotov_A/0/1/0/all/0/1&quot;&gt;Artem Grotov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kiseleva_J/0/1/0/all/0/1&quot;&gt;Julia Kiseleva&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rijke_M/0/1/0/all/0/1&quot;&gt;Maarten de Rijke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oosterhuis_H/0/1/0/all/0/1&quot;&gt;Harrie Oosterhuis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.00983">
<title>Robust Deep Reinforcement Learning for Security and Safety in Autonomous Vehicle Systems. (arXiv:1805.00983v2 [cs.SY] UPDATED)</title>
<link>http://arxiv.org/abs/1805.00983</link>
<description rdf:parseType="Literal">&lt;p&gt;To operate effectively in tomorrow&apos;s smart cities, autonomous vehicles (AVs)
must rely on intra-vehicle sensors such as camera and radar as well as
inter-vehicle communication. Such dependence on sensors and communication links
exposes AVs to cyber-physical (CP) attacks by adversaries that seek to take
control of the AVs by manipulating their data. Thus, to ensure safe and optimal
AV dynamics control, the data processing functions at AVs must be robust to
such CP attacks. To this end, in this paper, the state estimation process for
monitoring AV dynamics, in presence of CP attacks, is analyzed and a novel
adversarial deep reinforcement learning (RL) algorithm is proposed to maximize
the robustness of AV dynamics control to CP attacks. The attacker&apos;s action and
the AV&apos;s reaction to CP attacks are studied in a game-theoretic framework. In
the formulated game, the attacker seeks to inject faulty data to AV sensor
readings so as to manipulate the inter-vehicle optimal safe spacing and
potentially increase the risk of AV accidents or reduce the vehicle flow on the
roads. Meanwhile, the AV, acting as a defender, seeks to minimize the
deviations of spacing so as to ensure robustness to the attacker&apos;s actions.
Since the AV has no information about the attacker&apos;s action and due to the
infinite possibilities for data value manipulations, the outcome of the
players&apos; past interactions are fed to long-short term memory (LSTM) blocks.
Each player&apos;s LSTM block learns the expected spacing deviation resulting from
its own action and feeds it to its RL algorithm. Then, the the attacker&apos;s RL
algorithm chooses the action which maximizes the spacing deviation, while the
AV&apos;s RL algorithm tries to find the optimal action that minimizes such
deviation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ferdowsi_A/0/1/0/all/0/1&quot;&gt;Aidin Ferdowsi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Challita_U/0/1/0/all/0/1&quot;&gt;Ursula Challita&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saad_W/0/1/0/all/0/1&quot;&gt;Walid Saad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mandayam_N/0/1/0/all/0/1&quot;&gt;Narayan B. Mandayam&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.02408">
<title>Improving Knowledge Graph Embedding Using Simple Constraints. (arXiv:1805.02408v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1805.02408</link>
<description rdf:parseType="Literal">&lt;p&gt;Embedding knowledge graphs (KGs) into continuous vector spaces is a focus of
current research. Early works performed this task via simple models developed
over KG triples. Recent attempts focused on either designing more complicated
triple scoring models, or incorporating extra information beyond triples. This
paper, by contrast, investigates the potential of using very simple constraints
to improve KG embedding. We examine non-negativity constraints on entity
representations and approximate entailment constraints on relation
representations. The former help to learn compact and interpretable
representations for entities. The latter further encode regularities of logical
entailment between relations into their distributed representations. These
constraints impose prior beliefs upon the structure of the embedding space,
without negative impacts on efficiency or scalability. Evaluation on WordNet,
Freebase, and DBpedia shows that our approach is simple yet surprisingly
effective, significantly and consistently outperforming competitive baselines.
The constraints imposed indeed improve model interpretability, leading to a
substantially increased structuring of the embedding space. Code and data are
available at https://github.com/iieir-km/ComplEx-NNE_AER.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ding_B/0/1/0/all/0/1&quot;&gt;Boyang Ding&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Q/0/1/0/all/0/1&quot;&gt;Quan Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1&quot;&gt;Bin Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_L/0/1/0/all/0/1&quot;&gt;Li Guo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.02677">
<title>Polynomial Convergence of Gradient Descent for Training One-Hidden-Layer Neural Networks. (arXiv:1805.02677v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.02677</link>
<description rdf:parseType="Literal">&lt;p&gt;We analyze Gradient Descent applied to learning a bounded target function on
$n$ real-valued inputs by training a neural network with a single hidden layer
of nonlinear gates. Our main finding is that GD starting from a randomly
initialized network converges in mean squared loss to the minimum error (in
2-norm) of the best approximation of the target function using a polynomial of
degree at most $k$. Moreover, the size of the network and number of iterations
needed are both bounded by $n^{O(k)}$. The core of our analysis is the
following existence theorem, which is of independent interest: for any
$\epsilon &amp;gt; 0$, any bounded function that has a degree-$k$ polynomial
approximation with error $\epsilon_0$ (in 2-norm), can be approximated to
within error $\epsilon_0 + \epsilon$ as a linear combination of $n^{O(k)}
\mbox{poly}(1/\epsilon)$ randomly chosen gates from any class of gates whose
corresponding activation function has nonzero coefficients in its harmonic
expansion for degrees up to $k$. In particular, this applies to training
networks of unbiased sigmoids and ReLUs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vempala_S/0/1/0/all/0/1&quot;&gt;Santosh Vempala&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wilmes_J/0/1/0/all/0/1&quot;&gt;John Wilmes&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.02840">
<title>Fighting Accounting Fraud Through Forensic Data Analytics. (arXiv:1805.02840v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.02840</link>
<description rdf:parseType="Literal">&lt;p&gt;Accounting fraud is a global concern representing a significant threat to the
financial system stability due to the resulting diminishing of the market
confidence and trust of regulatory authorities. Several tricks can be used to
commit accounting fraud, hence the need for non-static regulatory interventions
that take into account different fraudulent patterns. Accordingly, this study
aims to improve the detection of accounting fraud via the implementation of
several machine learning methods to better differentiate between fraud and
non-fraud companies, and to further assist the task of examination within the
riskier firms by evaluating relevant financial indicators. Out-of-sample
results suggest there is a great potential in detecting falsified financial
statements through statistical modelling and analysis of publicly available
accounting information. The proposed methodology can be of assistance to public
auditors and regulatory agencies as it facilitates auditing processes, and
supports more targeted and effective examinations of accounting reports.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Jofre_M/0/1/0/all/0/1&quot;&gt;Maria Jofre&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gerlach_R/0/1/0/all/0/1&quot;&gt;Richard Gerlach&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.02848">
<title>Learning Generalized Hypergeometric Distribution (GHD) DAG models. (arXiv:1805.02848v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.02848</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce a new class of identifiable DAG models, where each node has a
conditional distribution given its parents belongs to a family of generalized
hypergeometric distributions (GHD). a family of generalized hypergeometric
distributions (GHD) includes a lot of discrete distributions such as Binomial,
Beta-binomial, Poisson, Poisson type, displaced Poisson, hyper-Poisson,
logarithmic, and many more. We prove that if the data drawn from the new class
of DAG models, one can fully identify the graph. We further provide a reliable
and tractable algorithm that recovers the directed graph from finitely many
data. We show through theoretical results and simulations that our algorithm is
statistically consistent even in high-dimensional settings ($n &amp;gt;p$) if the
degree of the graph is bounded, and performs well compared to state-of-the-art
DAG-learning algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Park_G/0/1/0/all/0/1&quot;&gt;Gunwoong Park&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.02908">
<title>Profitable Bandits. (arXiv:1805.02908v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.02908</link>
<description rdf:parseType="Literal">&lt;p&gt;Originally motivated by default risk management applications, this paper
investigates a novel problem, referred to as the profitable bandit problem
here. At each step, an agent chooses a subset of the K possible actions. For
each action chosen, she then receives the sum of a random number of rewards.
Her objective is to maximize her cumulated earnings. We adapt and study three
well-known strategies in this purpose, that were proved to be most efficient in
other settings: kl-UCB, Bayes-UCB and Thompson Sampling. For each of them, we
prove a finite time regret bound which, together with a lower bound we obtain
as well, establishes asymptotic optimality. Our goal is also to compare these
three strategies from a theoretical and empirical perspective both at the same
time. We give simple, self-contained proofs that emphasize their similarities,
as well as their differences. While both Bayesian strategies are automatically
adapted to the geometry of information, the numerical experiments carried out
show a slight advantage for Thompson Sampling in practice.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Achab_M/0/1/0/all/0/1&quot;&gt;Mastane Achab&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Clemencon_S/0/1/0/all/0/1&quot;&gt;Stephan Cl&amp;#xe9;men&amp;#xe7;on&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Garivier_A/0/1/0/all/0/1&quot;&gt;Aur&amp;#xe9;lien Garivier&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.02991">
<title>Differential Equations for Modeling Asynchronous Algorithms. (arXiv:1805.02991v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.02991</link>
<description rdf:parseType="Literal">&lt;p&gt;Asynchronous stochastic gradient descent (ASGD) is a popular parallel
optimization algorithm in machine learning. Most theoretical analysis on ASGD
take a discrete view and prove upper bounds for their convergence rates.
However, the discrete view has its intrinsic limitations: there is no
characterization of the optimization path and the proof techniques are
induction-based and thus usually complicated. Inspired by the recent successful
adoptions of stochastic differential equations (SDE) to the theoretical
analysis of SGD, in this paper, we study the continuous approximation of ASGD
by using stochastic differential delay equations (SDDE). We introduce the
approximation method and study the approximation error. Then we conduct
theoretical analysis on the convergence rates of ASGD algorithm based on the
continuous approximation. There are two methods: moment estimation and energy
function minimization can be used to analyze the convergence rates. Moment
estimation depends on the specific form of the loss function, while energy
function minimization only leverages the convex property of the loss function,
and does not depend on its specific form. In addition to the convergence
analysis, the continuous view also helps us derive better convergence rates.
All of this clearly shows the advantage of taking the continuous view in
gradient descent algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+He_L/0/1/0/all/0/1&quot;&gt;Li He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Meng_Q/0/1/0/all/0/1&quot;&gt;Qi Meng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chen_W/0/1/0/all/0/1&quot;&gt;Wei Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ma_Z/0/1/0/all/0/1&quot;&gt;Zhi-Ming Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Liu_T/0/1/0/all/0/1&quot;&gt;Tie-Yan Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.03006">
<title>Efficient online learning for large-scale peptide identification. (arXiv:1805.03006v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.03006</link>
<description rdf:parseType="Literal">&lt;p&gt;Motivation: Post-database searching is a key procedure in peptide
dentification with tandem mass spectrometry (MS/MS) strategies for refining
peptide-spectrum matches (PSMs) generated by database search engines. Although
many statistical and machine learning-based methods have been developed to
improve the accuracy of peptide identification, the challenge remains on
large-scale datasets and datasets with an extremely large proportion of false
positives (hard datasets). A more efficient learning strategy is required for
improving the performance of peptide identification on challenging datasets.
&lt;/p&gt;
&lt;p&gt;Results: In this work, we present an online learning method to conquer the
challenges remained for exiting peptide identification algorithms. We propose a
cost-sensitive learning model by using different loss functions for decoy and
target PSMs respectively. A larger penalty for wrongly selecting decoy PSMs
than that for target PSMs, and thus the new model can reduce its false
discovery rate on hard datasets. Also, we design an online learning algorithm,
OLCS-Ranker, to solve the proposed learning model. Rather than taking all
training data samples all at once, OLCS-Ranker iteratively feeds in only one
training sample into the learning model at each round. As a result, the memory
requirement is significantly reduced for large-scale problems. Experimental
studies show that OLCS-Ranker outperforms benchmark methods, such as CRanker
and Batch-CS-Ranker, in terms of accuracy and stability. Furthermore,
OLCS-Ranker is 15--85 times faster than CRanker method on large datasets.
&lt;/p&gt;
&lt;p&gt;Availability and implementation: OLCS-Ranker software is available at no
charge for non-commercial use at https://github.com/Isaac-QiXing/CRanker.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Liang_X/0/1/0/all/0/1&quot;&gt;Xijun Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Xia_Z/0/1/0/all/0/1&quot;&gt;Zhonghang Xia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yongxiang Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Jian_L/0/1/0/all/0/1&quot;&gt;Ling Jian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Niu_X/0/1/0/all/0/1&quot;&gt;Xinnan Niu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Link_A/0/1/0/all/0/1&quot;&gt;Andrew Link&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.03096">
<title>Fast Feature Extraction with CNNs with Pooling Layers. (arXiv:1805.03096v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1805.03096</link>
<description rdf:parseType="Literal">&lt;p&gt;In recent years, many publications showed that convolutional neural network
based features can have a superior performance to engineered features. However,
not much effort was taken so far to extract local features efficiently for a
whole image. In this paper, we present an approach to compute patch-based local
feature descriptors efficiently in presence of pooling and striding layers for
whole images at once. Our approach is generic and can be applied to nearly all
existing network architectures. This includes networks for all local feature
extraction tasks like camera calibration, Patchmatching, optical flow
estimation and stereo matching. In addition, our approach can be applied to
other patch-based approaches like sliding window object detection and
recognition. We complete our paper with a speed benchmark of popular CNN based
feature extraction approaches applied on a whole image, with and without our
speedup, and example code (for Torch) that shows how an arbitrary CNN
architecture can be easily converted by our approach.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bailer_C/0/1/0/all/0/1&quot;&gt;Christian Bailer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Habtegebrial_T/0/1/0/all/0/1&quot;&gt;Tewodros Habtegebrial&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+varanasi_K/0/1/0/all/0/1&quot;&gt;Kiran varanasi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stricker_D/0/1/0/all/0/1&quot;&gt;Didier Stricker&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1703.04599">
<title>Generalized Self-Concordant Functions: A Recipe for Newton-Type Methods. (arXiv:1703.04599v3 [math.OC] UPDATED)</title>
<link>http://arxiv.org/abs/1703.04599</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the smooth structure of convex functions by generalizing a powerful
concept so-called self-concordance introduced by Nesterov and Nemirovskii in
the early 1990s to a broader class of convex functions, which we call
generalized self-concordant functions. This notion allows us to develop a
unified framework for designing Newton-type methods to solve convex optimiza-
tion problems. The proposed theory provides a mathematical tool to analyze both
local and global convergence of Newton-type methods without imposing
unverifiable assumptions as long as the un- derlying functionals fall into our
generalized self-concordant function class. First, we introduce the class of
generalized self-concordant functions, which covers standard self-concordant
functions as a special case. Next, we establish several properties and key
estimates of this function class, which can be used to design numerical
methods. Then, we apply this theory to develop several Newton-type methods for
solving a class of smooth convex optimization problems involving the
generalized self- concordant functions. We provide an explicit step-size for
the damped-step Newton-type scheme which can guarantee a global convergence
without performing any globalization strategy. We also prove a local quadratic
convergence of this method and its full-step variant without requiring the
Lipschitz continuity of the objective Hessian. Then, we extend our result to
develop proximal Newton-type methods for a class of composite convex
minimization problems involving generalized self-concordant functions. We also
achieve both global and local convergence without additional assumption.
Finally, we verify our theoretical results via several numerical examples, and
compare them with existing methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Sun_T/0/1/0/all/0/1&quot;&gt;Tianxiao Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Tran_Dinh_Q/0/1/0/all/0/1&quot;&gt;Quoc Tran-Dinh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1708.07581">
<title>Accurate parameter estimation for Bayesian Network Classifiers using Hierarchical Dirichlet Processes. (arXiv:1708.07581v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1708.07581</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper introduces a novel parameter estimation method for the probability
tables of Bayesian network classifiers (BNCs), using hierarchical Dirichlet
processes (HDPs). The main result of this paper is to show that improved
parameter estimation allows BNCs to outperform leading learning methods such as
Random Forest for both 0-1 loss and RMSE, albeit just on categorical datasets.
&lt;/p&gt;
&lt;p&gt;As data assets become larger, entering the hyped world of &quot;big&quot;, efficient
accurate classification requires three main elements: (1) classifiers with
low-bias that can capture the fine-detail of large datasets (2) out-of-core
learners that can learn from data without having to hold it all in main memory
and (3) models that can classify new data very efficiently.
&lt;/p&gt;
&lt;p&gt;The latest Bayesian network classifiers (BNCs) satisfy these requirements.
Their bias can be controlled easily by increasing the number of parents of the
nodes in the graph. Their structure can be learned out of core with a limited
number of passes over the data. However, as the bias is made lower to
accurately model classification tasks, so is the accuracy of their parameters&apos;
estimates, as each parameter is estimated from ever decreasing quantities of
data. In this paper, we introduce the use of Hierarchical Dirichlet Processes
for accurate BNC parameter estimation.
&lt;/p&gt;
&lt;p&gt;We conduct an extensive set of experiments on 68 standard datasets and
demonstrate that our resulting classifiers perform very competitively with
Random Forest in terms of prediction, while keeping the out-of-core capability
and superior classification time.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Petitjean_F/0/1/0/all/0/1&quot;&gt;Francois Petitjean&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Buntine_W/0/1/0/all/0/1&quot;&gt;Wray Buntine&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Webb_G/0/1/0/all/0/1&quot;&gt;Geoffrey I. Webb&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zaidi_N/0/1/0/all/0/1&quot;&gt;Nayyar Zaidi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.08511">
<title>An Expectation Maximization Framework for Preferential Attachment Models. (arXiv:1710.08511v2 [stat.CO] UPDATED)</title>
<link>http://arxiv.org/abs/1710.08511</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper we develop an Expectation Maximization(EM) algorithm to
estimate the parameter of a Yule-Simon distribution. The Yule-Simon
distribution exhibits the &quot;rich get richer&quot; effect whereby an 80-20 type of
rule tends to dominate. These distributions are ubiquitous in industrial
settings. The EM algorithm presented provides both frequentist and Bayesian
estimates of the $\lambda$ parameter. By placing the estimation method within
the EM framework we are able to derive Standard errors of the resulting
estimate. Additionally, we prove convergence of the Yule-Simon EM algorithm and
study the rate of convergence. An explicit, closed form solution for the rate
of convergence of the algorithm is given.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Roberts_L/0/1/0/all/0/1&quot;&gt;Lucas Roberts&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Roberts_D/0/1/0/all/0/1&quot;&gt;Denisa Roberts&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.11469">
<title>Conditional Variance Penalties and Domain Shift Robustness. (arXiv:1710.11469v4 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1710.11469</link>
<description rdf:parseType="Literal">&lt;p&gt;When training a deep network for image classification, one can broadly
distinguish between two types of latent features of images that will drive the
classification. Following the notation of Gong et al. (2016), we can divide
latent features into (i) &quot;core&quot; features $X^\text{core}$ whose distribution
$X^\text{core}\vert Y$ does not change substantially across domains and (ii)
&quot;style&quot; features $X^{\text{style}}$ whose distribution $X^{\text{style}}\vert
Y$ can change substantially across domains. These latter orthogonal features
would generally include features such as rotation, image quality or brightness
but also more complex ones like hair color or posture for images of persons.
Guarding against future adversarial domain shifts implies that the influence of
the second type of style features in the prediction has to be limited. We
assume that the domain itself is not observed and hence a latent variable. We
do assume, however, that we can sometimes observe a typically discrete
identifier or $\mathrm{ID}$ variable. We know in some applications, for
example, that two images show the same person, and $\mathrm{ID}$ then refers to
the identity of the person. The method requires only a small fraction of images
to have an $\mathrm{ID}$ variable. We group data samples if they share the same
class and identifier $(Y,\mathrm{ID})=(y,\mathrm{id})$ and penalize the
conditional variance of the prediction if we condition on $(Y,\mathrm{ID})$.
Using this approach is shown to protect against shifts in the distribution of
the style variables for both regression and classification models.
Specifically, the conditional variance penalty CoRe is shown to be equivalent
to minimizing the risk under noise interventions in a regression setting and is
shown to lead to adversarial risk consistency in a partially linear
classification setting.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Heinze_Deml_C/0/1/0/all/0/1&quot;&gt;Christina Heinze-Deml&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Meinshausen_N/0/1/0/all/0/1&quot;&gt;Nicolai Meinshausen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06939">
<title>Estimator of Prediction Error Based on Approximate Message Passing for Penalized Linear Regression. (arXiv:1802.06939v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1802.06939</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose an estimator of prediction error using an approximate message
passing (AMP) algorithm that can be applied to a broad range of sparse
penalties. Following Stein&apos;s lemma, the estimator of the generalized degrees of
freedom, which is a key quantity for the construction of the estimator of the
prediction error, is calculated at the AMP fixed point. The resulting form of
the AMP-based estimator does not depend on the penalty function, and its value
can be further improved by considering the correlation between predictors. The
proposed estimator is asymptotically unbiased when the components of the
predictors and response variables are independently generated according to a
Gaussian distribution. We examine the behaviour of the estimator for real data
under nonconvex sparse penalties, where Akaike&apos;s information criterion does not
correspond to an unbiased estimator of the prediction error. The model selected
by the proposed estimator is close to that which minimizes the true prediction
error.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sakata_A/0/1/0/all/0/1&quot;&gt;Ayaka Sakata&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.07891">
<title>A Deep Learning Approach for Forecasting Air Pollution in South Korea Using LSTM. (arXiv:1804.07891v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1804.07891</link>
<description rdf:parseType="Literal">&lt;p&gt;Tackling air pollution is an imperative problem in South Korea, especially in
urban areas, over the last few years. More specially, South Korea has joined
the ranks of the world&apos;s most polluted countries alongside with other Asian
capitals, such as Beijing or Delhi. Much research is being conducted in
environmental science to evaluate the dangerous impact of particulate matters
on public health. Besides that, deterministic models of air pollutant behavior
are also generated; however, this is both complex and often inaccurate. On the
contrary, deep recurrent neural network reveals potent potential on forecasting
out-comes of time-series data and has become more prevalent. This paper uses
Recurrent Neural Network (RNN) with Long Short-Term Memory units as a framework
for leveraging knowledge from time-series data of air pollution and
meteorological information in Daegu, Seoul, Beijing, and Shenyang.
Additionally, we use encoder-decoder model, which is similar to machine
comprehension problems, as a crucial part of our prediction machine. Finally,
we investigate the prediction accuracy of various configurations. Our
experiments prevent the efficiency of integrating multiple layers of RNN on
prediction model when forecasting far timesteps ahead. This research is a
significant motivation for not only continuing researching on urban air quality
but also help the government leverage that insight to enact beneficial policies
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bui_T/0/1/0/all/0/1&quot;&gt;Tien-Cuong Bui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Le_V/0/1/0/all/0/1&quot;&gt;Van-Duc Le&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cha_S/0/1/0/all/0/1&quot;&gt;Sang-Kyun Cha&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.08603">
<title>Towards Learning Sparsely Used Dictionaries with Arbitrary Supports. (arXiv:1804.08603v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1804.08603</link>
<description rdf:parseType="Literal">&lt;p&gt;Dictionary learning is a popular approach for inferring a hidden basis or
dictionary in which data has a sparse representation. Data generated from the
dictionary A (an n by m matrix, with m &amp;gt; n in the over-complete setting) is
given by Y = AX where X is a matrix whose columns have supports chosen from a
distribution over k-sparse vectors, and the non-zero values chosen from a
symmetric distribution. Given Y, the goal is to recover A and X in polynomial
time. Existing algorithms give polytime guarantees for recovering incoherent
dictionaries, under strong distributional assumptions both on the supports of
the columns of X, and on the values of the non-zero entries. In this work, we
study the following question: Can we design efficient algorithms for recovering
dictionaries when the supports of the columns of X are arbitrary?
&lt;/p&gt;
&lt;p&gt;To address this question while circumventing the issue of
non-identifiability, we study a natural semirandom model for dictionary
learning where there are a large number of samples $y=Ax$ with arbitrary
k-sparse supports for x, along with a few samples where the sparse supports are
chosen uniformly at random. While the few samples with random supports ensures
identifiability, the support distribution can look almost arbitrary in
aggregate. Hence existing algorithmic techniques seem to break down as they
make strong assumptions on the supports.
&lt;/p&gt;
&lt;p&gt;Our main contribution is a new polynomial time algorithm for learning
incoherent over-complete dictionaries that works under the semirandom model.
Additionally the same algorithm provides polynomial time guarantees in new
parameter regimes when the supports are fully random. Finally using these
techniques, we also identify a minimal set of conditions on the supports under
which the dictionary can be (information theoretically) recovered from
polynomial samples for almost linear sparsity, i.e., $k=\tilde{O}(n)$.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Awasthi_P/0/1/0/all/0/1&quot;&gt;Pranjal Awasthi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vijayaraghavan_A/0/1/0/all/0/1&quot;&gt;Aravindan Vijayaraghavan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.02627">
<title>Computing the Shattering Coefficient of Supervised Learning Algorithms. (arXiv:1805.02627v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.02627</link>
<description rdf:parseType="Literal">&lt;p&gt;The Statistical Learning Theory (SLT) provides the theoretical guarantees for
supervised machine learning based on the Empirical Risk Minimization Principle
(ERMP). Such principle defines an upper bound to ensure the uniform convergence
of the empirical risk Remp(f), i.e., the error measured on a given data sample,
to the expected value of risk R(f) (a.k.a. actual risk), which depends on the
Joint Probability Distribution P(X x Y) mapping input examples x in X to class
labels y in Y. The uniform convergence is only ensured when the Shattering
coefficient N(F,2n) has a polynomial growing behavior. This paper proves the
Shattering coefficient for any Hilbert space H containing the input space X and
discusses its effects in terms of learning guarantees for supervised machine
algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mello_R/0/1/0/all/0/1&quot;&gt;Rodrigo Fernandes de Mello&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ponti_M/0/1/0/all/0/1&quot;&gt;Moacir Antonelli Ponti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ferreira_C/0/1/0/all/0/1&quot;&gt;Carlos Henrique Grossi Ferreira&lt;/a&gt;</dc:creator>
</item></rdf:RDF>