<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Boring papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Bad Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-08-09T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.02997"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.10205"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.00447"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05794"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.01521"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.03043"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.03090"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.03096"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.03130"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.03147"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.03233"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.01290"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.05250"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.02636"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.02838"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.02932"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.02933"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.02941"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.02956"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.03001"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.03030"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.03064"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.03216"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.03230"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.03253"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.03258"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.03162"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.03163"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.08968"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.04339"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.05062"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.04189"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.11258"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.01069"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.04119"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.09386"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1808.01975"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1808.02997">
<title>Sample size estimation for power and accuracy in the experimental comparison of algorithms. (arXiv:1808.02997v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1808.02997</link>
<description rdf:parseType="Literal">&lt;p&gt;Experimental comparisons of performance represent an important aspect of
research on optimization algorithms. In this work we present a methodology for
defining the required sample sizes for designing experiments with desired
statistical properties for the comparison of two methods on a given problem
class. The proposed approach allows the experimenter to define desired levels
of accuracy for estimates of mean performance differences on individual problem
instances, as well as the desired statistical power for comparing mean
performances over a problem class of interest. The method calculates the
required number of problem instances, and runs the algorithms on each test
instance so that the accuracy of the estimated differences in performance is
controlled at the predefined level. Two examples illustrate the application of
the proposed method, and its ability to achieve the desired statistical
properties with a methodologically sound definition of the relevant sample
sizes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Campelo_F/0/1/0/all/0/1&quot;&gt;Felipe Campelo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Takahashi_F/0/1/0/all/0/1&quot;&gt;Fernanda Takahashi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.10205">
<title>Neural and Synaptic Array Transceiver: A Brain-Inspired Computing Framework for Embedded Learning. (arXiv:1709.10205v3 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1709.10205</link>
<description rdf:parseType="Literal">&lt;p&gt;Embedded, continual learning for autonomous and adaptive behavior is a key
application of neuromorphic hardware. However, neuromorphic implementations of
embedded learning at large scales that are both flexible and efficient have
been hindered by a lack of a suitable algorithmic framework. As a result, the
most neuromorphic hardware is trained off-line on large clusters of dedicated
processors or GPUs and transferred post hoc to the device. We address this by
introducing the neural and synaptic array transceiver (NSAT), a neuromorphic
computational framework facilitating flexible and efficient embedded learning
by matching algorithmic requirements and neural and synaptic dynamics. NSAT
supports event-driven supervised, unsupervised and reinforcement learning
algorithms including deep learning. We demonstrate the NSAT in a wide range of
tasks, including the simulation of Mihalas-Niebur neuron, dynamic neural
fields, event-driven random back-propagation for event-based deep learning,
event-based contrastive divergence for unsupervised learning, and voltage-based
learning rules for sequence learning. We anticipate that this contribution will
establish the foundation for a new generation of devices enabling adaptive
mobile systems, wearable devices, and robots with data-driven autonomy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Detorakis_G/0/1/0/all/0/1&quot;&gt;Georgios Detorakis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sheik_S/0/1/0/all/0/1&quot;&gt;Sadique Sheik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Augustine_C/0/1/0/all/0/1&quot;&gt;Charles Augustine&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Paul_S/0/1/0/all/0/1&quot;&gt;Somnath Paul&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pedroni_B/0/1/0/all/0/1&quot;&gt;Bruno U. Pedroni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dutt_N/0/1/0/all/0/1&quot;&gt;Nikil Dutt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Krichmar_J/0/1/0/all/0/1&quot;&gt;Jeffrey Krichmar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cauwenberghs_G/0/1/0/all/0/1&quot;&gt;Gert Cauwenberghs&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Neftci_E/0/1/0/all/0/1&quot;&gt;Emre Neftci&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.00447">
<title>Optimal localist and distributed coding of spatiotemporal spike patterns through STDP and coincidence detection. (arXiv:1803.00447v3 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1803.00447</link>
<description rdf:parseType="Literal">&lt;p&gt;Repeating spatiotemporal spike patterns exist and carry information. Here we
investigated how a single spiking neuron can optimally respond to one given
pattern (localist coding), or to either one of several patterns (distributed
coding, i.e. the neuron&apos;s response is ambiguous but the identity of the pattern
could be inferred from the response of multiple neurons), but not to random
inputs. To do so, we extended a theory developed in a previous paper
[Masquelier, 2017], which was limited to localist coding. More specifically, we
computed analytically the signal-to-noise ratio (SNR) of a
multi-pattern-detector neuron, using a threshold-free leaky integrate-and-fire
(LIF) neuron model with non-plastic unitary synapses and homogeneous Poisson
inputs. Surprisingly, when increasing the number of patterns, the SNR decreases
slowly, and remains acceptable for several tens of independent patterns.
&lt;/p&gt;
&lt;p&gt;In addition, we investigated whether spike-timing-dependent plasticity (STDP)
could enable a neuron to reach the theoretical optimal SNR. To this aim, we
simulated a LIF equipped with STDP, and repeatedly exposed it to multiple input
spike patterns, embedded in equally dense Poisson spike trains. The LIF
progressively became selective to every repeating pattern with no supervision,
and stopped discharging during the Poisson spike trains. Furthermore, using
certain STDP parameters, the resulting pattern detectors were optimal. Tens of
independent patterns could be learned by a single neuron using a low adaptive
threshold, in contrast with previous studies, in which higher thresholds led to
localist coding only.
&lt;/p&gt;
&lt;p&gt;Taken together these results suggest that coincidence detection and STDP are
powerful mechanisms, fully compatible with distributed coding. Yet we
acknowledge that our theory is limited to single neurons, and thus also applies
to feed-forward networks, but not to recurrent ones.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Masquelier_T/0/1/0/all/0/1&quot;&gt;Timoth&amp;#xe9;e Masquelier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kheradpisheh_S/0/1/0/all/0/1&quot;&gt;Saeed Reza Kheradpisheh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05794">
<title>RAPIDNN: In-Memory Deep Neural Network Acceleration Framework. (arXiv:1806.05794v3 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1806.05794</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep neural networks (DNN) have demonstrated effectiveness for various
applications such as image processing, video segmentation, and speech
recognition. Running state-of-theart DNNs on current systems mostly relies on
either generalpurpose processors, ASIC designs, or FPGA accelerators, all of
which suffer from data movements due to the limited onchip memory and data
transfer bandwidth. In this work, we propose a novel framework, called RAPIDNN,
which processes all DNN operations within the memory to minimize the cost of
data movement. To enable in-memory processing, RAPIDNN reinterprets a DNN model
and maps it into a specialized accelerator, which is designed using
non-volatile memory blocks that model four fundamental DNN operations, i.e.,
multiplication, addition, activation functions, and pooling. The framework
extracts representative operands of a DNN model, e.g., weights and input
values, using clustering methods to optimize the model for in-memory
processing. Then, it maps the extracted operands and their precomputed results
into the accelerator memory blocks. At runtime, the accelerator identifies
computation results based on efficient in-memory search capability which also
provides tunability of approximation to further improve computation efficiency.
Our evaluation shows that RAPIDNN achieves 68.4x, 49.5x energy efficiency
improvement and 48.1x, 10.9x speedup as compared to ISAAC and PipeLayer, the
state-of-the-art DNN accelerators, while ensuring less than 0.3% of quality
loss.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Imani_M/0/1/0/all/0/1&quot;&gt;Mohsen Imani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Samragh_M/0/1/0/all/0/1&quot;&gt;Mohammad Samragh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_Y/0/1/0/all/0/1&quot;&gt;Yeseong Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gupta_S/0/1/0/all/0/1&quot;&gt;Saransh Gupta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koushanfar_F/0/1/0/all/0/1&quot;&gt;Farinaz Koushanfar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rosing_T/0/1/0/all/0/1&quot;&gt;Tajana Rosing&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.01521">
<title>Curiosity Driven Exploration of Learned Disentangled Goal Spaces. (arXiv:1807.01521v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1807.01521</link>
<description rdf:parseType="Literal">&lt;p&gt;Intrinsically motivated goal exploration processes enable agents to
autonomously sample goals to explore efficiently complex environments with
high-dimensional continuous actions. They have been applied successfully to
real world robots to discover repertoires of policies producing a wide
diversity of effects. Often these algorithms relied on engineered goal spaces
but it was recently shown that one can use deep representation learning
algorithms to learn an adequate goal space in simple environments. However, in
the case of more complex environments containing multiple objects or
distractors, an efficient exploration requires that the structure of the goal
space reflects the one of the environment. In this paper we show that using a
disentangled goal space leads to better exploration performances than an
entangled goal space. We further show that when the representation is
disentangled, one can leverage it by sampling goals that maximize learning
progress in a modular manner. Finally, we show that the measure of learning
progress, used to drive curiosity-driven exploration, can be used
simultaneously to discover abstract independently controllable features of the
environment.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Laversanne_Finot_A/0/1/0/all/0/1&quot;&gt;Adrien Laversanne-Finot&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pere_A/0/1/0/all/0/1&quot;&gt;Alexandre P&amp;#xe9;r&amp;#xe9;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oudeyer_P/0/1/0/all/0/1&quot;&gt;Pierre-Yves Oudeyer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.03043">
<title>Hunting for Tractable Languages for Judgment Aggregation. (arXiv:1808.03043v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1808.03043</link>
<description rdf:parseType="Literal">&lt;p&gt;Judgment aggregation is a general framework for collective decision making
that can be used to model many different settings. Due to its general nature,
the worst case complexity of essentially all relevant problems in this
framework is very high. However, these intractability results are mainly due to
the fact that the language to represent the aggregation domain is overly
expressive. We initiate an investigation of representation languages for
judgment aggregation that strike a balance between (1) being limited enough to
yield computational tractability results and (2) being expressive enough to
model relevant applications. In particular, we consider the languages of Krom
formulas, (definite) Horn formulas, and Boolean circuits in decomposable
negation normal form (DNNF). We illustrate the use of the positive complexity
results that we obtain for these languages with a concrete application: voting
on how to spend a budget (i.e., participatory budgeting).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Haan_R/0/1/0/all/0/1&quot;&gt;Ronald de Haan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.03090">
<title>Image Inspired Poetry Generation in XiaoIce. (arXiv:1808.03090v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1808.03090</link>
<description rdf:parseType="Literal">&lt;p&gt;Vision is a common source of inspiration for poetry. The objects and the
sentimental imprints that one perceives from an image may lead to various
feelings depending on the reader. In this paper, we present a system of poetry
generation from images to mimic the process. Given an image, we first extract a
few keywords representing objects and sentiments perceived from the image.
These keywords are then expanded to related ones based on their associations in
human written poems. Finally, verses are generated gradually from the keywords
using recurrent neural networks trained on existing poems. Our approach is
evaluated by human assessors and compared to other generation baselines. The
results show that our method can generate poems that are more artistic than the
baseline methods. This is one of the few attempts to generate poetry from
images. By deploying our proposed approach, XiaoIce has already generated more
than 12 million poems for users since its release in July 2017. A book of its
poems has been published by Cheers Publishing, which claimed that the book is
the first-ever poetry collection written by an AI in human history.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_W/0/1/0/all/0/1&quot;&gt;Wen-Feng Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1&quot;&gt;Chao-Chung Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_R/0/1/0/all/0/1&quot;&gt;Ruihua Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fu_J/0/1/0/all/0/1&quot;&gt;Jianlong Fu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_X/0/1/0/all/0/1&quot;&gt;Xing Xie&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nie_J/0/1/0/all/0/1&quot;&gt;Jian-Yun Nie&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.03096">
<title>On feature selection and evaluation of transportation mode prediction strategies. (arXiv:1808.03096v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1808.03096</link>
<description rdf:parseType="Literal">&lt;p&gt;Transportation modes prediction is a fundamental task for decision making in
smart cities and traffic management systems. Traffic policies designed based on
trajectory mining can save money and time for authorities and the public. It
may reduce the fuel consumption and commute time and moreover, may provide more
pleasant moments for residents and tourists. Since the number of features that
may be used to predict a user transportation mode can be substantial, finding a
subset of features that maximizes a performance measure is worth investigating.
In this work, we explore wrapper and information retrieval methods to find the
best subset of trajectory features. After finding the best classifier and the
best feature subset, our results were compared with two related papers that
applied deep learning methods and the results showed that our framework
achieved better performance. Furthermore, two types of cross-validation
approaches were investigated, and the performance results show that the random
cross-validation method provides optimistic results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Etemad_M/0/1/0/all/0/1&quot;&gt;Mohammad Etemad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Junior_A/0/1/0/all/0/1&quot;&gt;Amilcar Soares Junior&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Matwin_S/0/1/0/all/0/1&quot;&gt;Stan Matwin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.03130">
<title>Finite Query Answering in Expressive Description Logics with Transitive Roles. (arXiv:1808.03130v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1808.03130</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the problem of finite ontology mediated query answering (FOMQA), the
variant of OMQA where the represented world is assumed to be finite, and thus
only finite models of the ontology are considered. We adopt the most typical
setting with unions of conjunctive queries and ontologies expressed in
description logics (DLs). The study of FOMQA is relevant in settings that are
not finitely controllable. This is the case not only for DLs without the finite
model property, but also for those allowing transitive role declarations. When
transitive roles are allowed, evaluating queries is challenging: FOMQA is
undecidable for SHOIF and only known to be decidable for the Horn fragment of
ALCIF. We show decidability of FOMQA for three proper fragments of SOIF: SOI,
SOF, and SIF. Our approach is to characterise models relevant for deciding
finite query entailment. Relying on a certain regularity of these models, we
develop automata-based decision procedures with optimal complexity bounds.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gogacz_T/0/1/0/all/0/1&quot;&gt;Tomasz Gogacz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ibanez_Garcia_Y/0/1/0/all/0/1&quot;&gt;Yazmin Ib&amp;#xe1;&amp;#xf1;ez-Garc&amp;#xed;a&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Murlak_F/0/1/0/all/0/1&quot;&gt;Filip Murlak&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.03147">
<title>A New Optimization Layer for Real-Time Bidding Advertising Campaigns. (arXiv:1808.03147v1 [cs.GT])</title>
<link>http://arxiv.org/abs/1808.03147</link>
<description rdf:parseType="Literal">&lt;p&gt;While it is relatively easy to start an online advertising campaign,
obtaining a high Key Performance Indicator (KPI) can be challenging. A large
body of work on this subject has already been performed and platforms known as
DSPs are available on the market that deal with such an optimization. From the
advertiser&apos;s point of view, each DSP is a different black box, with its pros
and cons, that needs to be configured. In order to take advantage of the pros
of every DSP, advertisers are well-advised to use a combination of them when
setting up their campaigns. In this paper, we propose an algorithm for
advertisers to add an optimization layer on top of DSPs. The algorithm we
introduce, called SKOTT, maximizes the chosen KPI by optimally configuring the
DSPs and putting them in competition with each other. SKOTT is a highly
specialized iterative algorithm loosely based on gradient descent that is made
up of three independent sub-routines, each dealing with a different problem:
partitioning the budget, setting the desired average bid, and preventing
under-delivery. In particular, one of the novelties of our approach lies in our
taking the perspective of the advertisers rather than the DSPs. Synthetic
market data is used to evaluate the efficiency of SKOTT against other
state-of-the-art approaches adapted from similar problems. The results
illustrate the benefits of our proposals, which greatly outperforms the other
methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Micchi_G/0/1/0/all/0/1&quot;&gt;Gianluca Micchi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Soheily_Khah_S/0/1/0/all/0/1&quot;&gt;Saeid Soheily-Khah&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Turner_J/0/1/0/all/0/1&quot;&gt;Jacob Turner&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.03233">
<title>OBOE: Collaborative Filtering for AutoML Initialization. (arXiv:1808.03233v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1808.03233</link>
<description rdf:parseType="Literal">&lt;p&gt;Algorithm selection and hyperparameter tuning remain two of the most
challenging tasks in machine learning. The number of machine learning
applications is growing much faster than the number of machine learning
experts, hence we see an increasing demand for efficient automation of learning
processes. Here, we introduce OBOE, an algorithm for time-constrained model
selection and hyperparameter tuning. Taking advantage of similarity between
datasets, OBOE finds promising algorithm and hyperparameter configurations
through collaborative filtering. Our system explores these models under time
constraints, so that rapid initializations can be provided to warm-start more
fine-grained optimization methods. One novel aspect of our approach is a new
heuristic for active learning in time-constrained matrix completion based on
optimal experiment design. Our experiments demonstrate that OBOE delivers
state-of-the-art performance faster than competing approaches on a test bed of
supervised learning problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_C/0/1/0/all/0/1&quot;&gt;Chengrun Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Akimoto_Y/0/1/0/all/0/1&quot;&gt;Yuji Akimoto&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1&quot;&gt;Dae Won Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Udell_M/0/1/0/all/0/1&quot;&gt;Madeleine Udell&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.01290">
<title>Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor. (arXiv:1801.01290v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1801.01290</link>
<description rdf:parseType="Literal">&lt;p&gt;Model-free deep reinforcement learning (RL) algorithms have been demonstrated
on a range of challenging decision making and control tasks. However, these
methods typically suffer from two major challenges: very high sample complexity
and brittle convergence properties, which necessitate meticulous hyperparameter
tuning. Both of these challenges severely limit the applicability of such
methods to complex, real-world domains. In this paper, we propose soft
actor-critic, an off-policy actor-critic deep RL algorithm based on the maximum
entropy reinforcement learning framework. In this framework, the actor aims to
maximize expected reward while also maximizing entropy. That is, to succeed at
the task while acting as randomly as possible. Prior deep RL methods based on
this framework have been formulated as Q-learning methods. By combining
off-policy updates with a stable stochastic actor-critic formulation, our
method achieves state-of-the-art performance on a range of continuous control
benchmark tasks, outperforming prior on-policy and off-policy methods.
Furthermore, we demonstrate that, in contrast to other off-policy algorithms,
our approach is very stable, achieving very similar performance across
different random seeds.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Haarnoja_T/0/1/0/all/0/1&quot;&gt;Tuomas Haarnoja&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_A/0/1/0/all/0/1&quot;&gt;Aurick Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1&quot;&gt;Pieter Abbeel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1&quot;&gt;Sergey Levine&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.05250">
<title>Blockchain to Improve Security, Knowledge and Collaboration Inter-Agent Communication over Restrict Domains of the Internet Infrastructure. (arXiv:1805.05250v4 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1805.05250</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper describes the deployment and implementation of a blockchain to
improve the security, knowledge, intelligence and collaboration during the
inter-agent communication processes in restrict domains of the Internet
Infrastructure. It is a work that proposes the application of a blockchain,
platform independent, on a particular model of agents, but that can be used in
similar proposals, once the results on the specific model were satisfactory.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Braga_J/0/1/0/all/0/1&quot;&gt;Juliao Braga&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Silva_J/0/1/0/all/0/1&quot;&gt;Joao Nuno Silva&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Endo_P/0/1/0/all/0/1&quot;&gt;Patricia Takako Endo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ribas_J/0/1/0/all/0/1&quot;&gt;Jessica Ribas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Omar_N/0/1/0/all/0/1&quot;&gt;Nizam Omar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.02636">
<title>Cognitive system to achieve human-level accuracy in automated assignment of helpdesk email tickets. (arXiv:1808.02636v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1808.02636</link>
<description rdf:parseType="Literal">&lt;p&gt;Ticket assignment/dispatch is a crucial part of service delivery business
with lot of scope for automation and optimization. In this paper, we present an
end-to-end automated helpdesk email ticket assignment system, which is also
offered as a service. The objective of the system is to determine the nature of
the problem mentioned in an incoming email ticket and then automatically
dispatch it to an appropriate resolver group (or team) for resolution.
&lt;/p&gt;
&lt;p&gt;The proposed system uses an ensemble classifier augmented with a configurable
rule engine. While design of classifier that is accurate is one of the main
challenges, we also need to address the need of designing a system that is
robust and adaptive to changing business needs. We discuss some of the main
design challenges associated with email ticket assignment automation and how we
solve them. The design decisions for our system are driven by high accuracy,
coverage, business continuity, scalability and optimal usage of computational
resources.
&lt;/p&gt;
&lt;p&gt;Our system has been deployed in production of three major service providers
and currently assigning over 40,000 emails per month, on an average, with an
accuracy close to 90% and covering at least 90% of email tickets. This
translates to achieving human-level accuracy and results in a net saving of
about 23000 man-hours of effort per annum.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mandal_A/0/1/0/all/0/1&quot;&gt;Atri Mandal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Malhotra_N/0/1/0/all/0/1&quot;&gt;Nikhil Malhotra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Agarwal_S/0/1/0/all/0/1&quot;&gt;Shivali Agarwal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ray_A/0/1/0/all/0/1&quot;&gt;Anupama Ray&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sridhara_G/0/1/0/all/0/1&quot;&gt;Giriprasad Sridhara&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.02838">
<title>On the Effect of Task-to-Worker Assignment in Distributed Computing Systems with Stragglers. (arXiv:1808.02838v1 [cs.DC] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1808.02838</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the expected completion time of some recently proposed algorithms
for distributed computing which redundantly assign computing tasks to multiple
machines in order to tolerate a certain number of machine failures. We
analytically show that not only the amount of redundancy but also the
task-to-machine assignments affect the latency in a distributed system. We
study systems with a fixed number of computing tasks that are split in possibly
overlapping batches, and independent exponentially distributed machine service
times. We show that, for such systems, the uniform replication of non-
overlapping (disjoint) batches of computing tasks achieves the minimum expected
computing time.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Behrouzi_Far_A/0/1/0/all/0/1&quot;&gt;Amir Behrouzi-Far&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Soljanin_E/0/1/0/all/0/1&quot;&gt;Emina Soljanin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.02932">
<title>Nonparametric Gaussian mixture models for the multi-armed contextual bandit. (arXiv:1808.02932v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1808.02932</link>
<description rdf:parseType="Literal">&lt;p&gt;The multi-armed bandit is a sequential allocation task where an agent must
learn a policy that maximizes long term payoff, where only the reward of the
played arm is observed at each iteration. In the stochastic setting, the reward
for each action is generated from an unknown distribution, which depends on a
given &apos;context&apos;, available at each interaction with the world. Thompson
sampling is a generative, interpretable multi-armed bandit algorithm that has
been shown both to perform well in practice, and to enjoy optimality properties
for certain reward functions. Nevertheless, Thompson sampling requires sampling
from parameter posteriors and calculation of expected rewards, which are
possible for a very limited choice of distributions. We here extend Thompson
sampling to more complex scenarios by adopting a very flexible set of reward
distributions: nonparametric Gaussian mixture models. The generative process of
Bayesian nonparametric mixtures naturally aligns with the Bayesian modeling of
multi-armed bandits. This allows for the implementation of an efficient and
flexible Thompson sampling algorithm: the nonparametric model autonomously
determines its complexity in an online fashion, as it observes new rewards for
the played arms. We show how the proposed method sequentially learns the
nonparametric mixture model that best approximates the true underlying reward
distribution. Our contribution is valuable for practical scenarios, as it
avoids stringent model specifications, and yet attains reduced regret.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Urteaga_I/0/1/0/all/0/1&quot;&gt;I&amp;#xf1;igo Urteaga&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wiggins_C/0/1/0/all/0/1&quot;&gt;Chris H. Wiggins&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.02933">
<title>(Sequential) Importance Sampling Bandits. (arXiv:1808.02933v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1808.02933</link>
<description rdf:parseType="Literal">&lt;p&gt;The multi-armed bandit (MAB) problem is a sequential allocation task where
the goal is to learn a policy that maximizes long term payoff, where only the
reward of the executed action is observed; i.e., sequential optimal decisions
are made, while simultaneously learning how the world operates. In the
stochastic setting, the reward for each action is generated from an unknown
distribution. To decide the next optimal action to take, one must compute
sufficient statistics of this unknown reward distribution, e.g.
upper-confidence bounds (UCB), or expectations in Thompson sampling.
Closed-form expressions for these statistics of interest are analytically
intractable except for simple cases. We here propose to leverage Monte Carlo
estimation and, in particular, the flexibility of (sequential) importance
sampling (IS) to allow for accurate estimation of the statistics of interest
within the MAB problem. IS methods estimate posterior densities or expectations
in probabilistic models that are analytically intractable. We first show how IS
can be combined with state-of-the-art MAB algorithms (Thompson sampling and
Bayes-UCB) for classic (Bernoulli and contextual linear-Gaussian) bandit
problems. Furthermore, we leverage the power of sequential IS to extend the
applicability of these algorithms beyond the classic settings, and tackle
additional useful cases. Specifically, we study the dynamic linear-Gaussian
bandit, and both the static and dynamic logistic cases too. The flexibility of
(sequential) importance sampling is shown to be fundamental for obtaining
efficient estimates of the key sufficient statistics in these challenging
scenarios.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Urteaga_I/0/1/0/all/0/1&quot;&gt;I&amp;#xf1;igo Urteaga&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wiggins_C/0/1/0/all/0/1&quot;&gt;Chris H. Wiggins&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.02941">
<title>On the Convergence of A Class of Adam-Type Algorithms for Non-Convex Optimization. (arXiv:1808.02941v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1808.02941</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper studies a class of adaptive gradient based momentum algorithms
that update the search directions and learning rates simultaneously using past
gradients. This class, which we refer to as the &quot;Adam-type&quot;, includes the
popular algorithms such as the Adam, AMSGrad and AdaGrad. Despite their
popularity in training deep neural networks, the convergence of these
algorithms for solving nonconvex problems remains an open question. This paper
provides a set of mild sufficient conditions that guarantee the convergence for
the Adam-type methods. We prove that under our derived conditions, these
methods can achieve the convergence rate of order $O(\log{T}/\sqrt{T})$ for
nonconvex stochastic optimization. We show the conditions are essential in the
sense that violating them may make the algorithm diverge. Moreover, we propose
and analyze a class of (deterministic) incremental adaptive gradient
algorithms, which has the same $O(\log{T}/\sqrt{T})$ convergence rate. Our
study could also be extended to a broader class of adaptive gradient methods in
machine learning and optimization.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1&quot;&gt;Xiangyi Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1&quot;&gt;Sijia Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_R/0/1/0/all/0/1&quot;&gt;Ruoyu Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hong_M/0/1/0/all/0/1&quot;&gt;Mingyi Hong&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.02956">
<title>Feature Dimensionality Reduction for Video Affect Classification: A Comparative Study. (arXiv:1808.02956v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1808.02956</link>
<description rdf:parseType="Literal">&lt;p&gt;Affective computing has become a very important research area in
human-machine interaction. However, affects are subjective, subtle, and
uncertain. So, it is very difficult to obtain a large number of labeled
training samples, compared with the number of possible features we could
extract. Thus, dimensionality reduction is critical in affective computing.
This paper presents our preliminary study on dimensionality reduction for
affect classification. Five popular dimensionality reduction approaches are
introduced and compared. Experiments on the DEAP dataset showed that no
approach can universally outperform others, and performing classification using
the raw features directly may not always be a bad choice.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_C/0/1/0/all/0/1&quot;&gt;Chenfeng Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_D/0/1/0/all/0/1&quot;&gt;Dongrui Wu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.03001">
<title>Compressed Sensing Using Binary Matrices of Nearly Optimal Dimensions. (arXiv:1808.03001v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1808.03001</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we study the problem of compressed sensing using binary
measurement matrices, and $\ell_1$-norm minimization (basis pursuit) as the
recovery algorithm. We derive new upper and lower bounds on the number of
measurements to achieve robust sparse recovery with binary matrices. We
establish sufficient conditions for a column-regular binary matrix to satisfy
the robust null space property (RNSP), and show that the sparsity bounds for
robust sparse recovery obtained using the RNSP are better by a factor of $(3
\sqrt{3})/2 \approx 2.6$ compared to the restricted isometry property (RIP).
Next we derive universal lower bounds on the number of measurements that any
binary matrix needs to have in order to satisfy the weaker sufficient condition
based on the RNSP, and show that bipartite graphs of girth six are optimal.
Then we display two classes of binary matrices, namely parity check matrices of
array codes, and Euler squares, that have girth six and are nearly optimal in
the sense of almost satisfying the lower bound. In principle randomly generated
Gaussian measurement matrices are &quot;order-optimal.&quot; So we compare the phase
transition behavior of the basis pursuit formulation using binary array code
and Gaussian matrices, and show that (i) there is essentially no difference
between the phase transition boundaries in the two cases, and (ii) the CPU time
of basis pursuit with binary matrices is hundreds of times faster than with
Gaussian matrices, and the storage requirements are less. Therefore it is
suggested that binary matrices are a viable alternative to Gaussian matrices
for compressed sensing using basis pursuit.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lotfi_M/0/1/0/all/0/1&quot;&gt;Mahsa Lotfi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Vidyasagar_M/0/1/0/all/0/1&quot;&gt;Mathukumalli Vidyasagar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.03030">
<title>Policy Optimization as Wasserstein Gradient Flows. (arXiv:1808.03030v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1808.03030</link>
<description rdf:parseType="Literal">&lt;p&gt;Policy optimization is a core component of reinforcement learning (RL), and
most existing RL methods directly optimize parameters of a policy based on
maximizing the expected total reward, or its surrogate. Though often achieving
encouraging empirical success, its underlying mathematical principle on {\em
policy-distribution} optimization is unclear. We place policy optimization into
the space of probability measures, and interpret it as Wasserstein gradient
flows. On the probability-measure space, under specified circumstances, policy
optimization becomes a convex problem in terms of distribution optimization. To
make optimization feasible, we develop efficient algorithms by numerically
solving the corresponding discrete gradient flows. Our technique is applicable
to several RL settings, and is related to many state-of-the-art
policy-optimization algorithms. Empirical results verify the effectiveness of
our framework, often obtaining better performance compared to related
algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_R/0/1/0/all/0/1&quot;&gt;Ruiyi Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_C/0/1/0/all/0/1&quot;&gt;Changyou Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1&quot;&gt;Chunyuan Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Carin_L/0/1/0/all/0/1&quot;&gt;Lawrence Carin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.03064">
<title>Gradient and Newton Boosting for Classification and Regression. (arXiv:1808.03064v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1808.03064</link>
<description rdf:parseType="Literal">&lt;p&gt;Boosting algorithms enjoy large popularity due to their high predictive
accuracy on a wide array of datasets. In this article, we argue that it is
important to distinguish between three types of statistical boosting
algorithms: gradient and Newton boosting as well as a hybrid variant of the
two. To date, both researchers and practitioners often do not discriminate
between these boosting variants. We compare the different boosting algorithms
on a wide range of real and simulated datasets for various choices of loss
functions using trees as base learners. In addition, we introduce a novel
tuning parameter for Newton boosting. We find that Newton boosting performs
substantially better than the other boosting variants for classification, and
that the novel tuning parameter is important for predictive accuracy
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sigrist_F/0/1/0/all/0/1&quot;&gt;Fabio Sigrist&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.03216">
<title>Data-driven polynomial chaos expansion for machine learning regression. (arXiv:1808.03216v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1808.03216</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a regression technique for data driven problems based on
polynomial chaos expansion (PCE). PCE is a popular technique in the field of
uncertainty quantification (UQ), where it is typically used to replace a
runnable but expensive computational model subject to random inputs with an
inexpensive-to-evaluate polynomial function. The metamodel obtained enables a
reliable estimation of the statistics of the output, provided that a suitable
probabilistic model of the input is available.
&lt;/p&gt;
&lt;p&gt;In classical machine learning (ML) regression settings, however, the system
is only known through observations of its inputs and output, and the interest
lies in obtaining accurate pointwise predictions of the latter. Here, we show
that a PCE metamodel purely trained on data can yield pointwise predictions
whose accuracy is comparable to that of other ML regression models, such as
neural networks and support vector machines. The comparisons are performed on
benchmark datasets available from the literature. The methodology also enables
the quantification of the output uncertainties and is robust to noise.
Furthermore, it enjoys additional desirable properties, such as good
performance for small training sets and simplicity of construction, with only
little parameter tuning required. In the presence of statistically dependent
inputs, we investigate two ways to build the PCE, and show through simulations
that one approach is superior to the other in the stated settings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Torre_E/0/1/0/all/0/1&quot;&gt;E. Torre&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Marelli_S/0/1/0/all/0/1&quot;&gt;S. Marelli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Embrechts_P/0/1/0/all/0/1&quot;&gt;P. Embrechts&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sudret_B/0/1/0/all/0/1&quot;&gt;B. Sudret&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.03230">
<title>Does Hamiltonian Monte Carlo mix faster than a random walk on multimodal densities?. (arXiv:1808.03230v1 [math.PR])</title>
<link>http://arxiv.org/abs/1808.03230</link>
<description rdf:parseType="Literal">&lt;p&gt;Hamiltonian Monte Carlo (HMC) is a very popular and generic collection of
Markov chain Monte Carlo (MCMC) algorithms. One explanation for the popularity
of HMC algorithms is their excellent performance as the dimension $d$ of the
target becomes large: under conditions that are satisfied for many common
statistical models, optimally-tuned HMC algorithms have a running time that
scales like $d^{0.25}$. In stark contrast, the running time of the usual
Random-Walk Metropolis (RWM) algorithm, optimally tuned, scales like $d$. This
superior scaling of the HMC algorithm with dimension is attributed to the fact
that it, unlike RWM, incorporates the gradient information in the proposal
distribution. In this paper, we investigate a different scaling question: does
HMC beat RWM for highly $\textit{multimodal}$ targets? We find that the answer
is often $\textit{no}$. We compute the spectral gaps for both the algorithms
for a specific class of multimodal target densities, and show that they are
identical. The key reason is that, within one mode, the gradient is effectively
ignorant about other modes, thus negating the advantage the HMC algorithm
enjoys in unimodal targets. We also give heuristic arguments suggesting that
the above observation may hold quite generally. Our main tool for answering
this question is a novel simple formula for the conductance of HMC using
Liouville&apos;s theorem. This result allows us to compute the spectral gap of HMC
algorithms, for both the classical HMC with isotropic momentum and the recent
Riemannian HMC, for multimodal targets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Mangoubi_O/0/1/0/all/0/1&quot;&gt;Oren Mangoubi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Pillai_N/0/1/0/all/0/1&quot;&gt;Natesh S. Pillai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Smith_A/0/1/0/all/0/1&quot;&gt;Aaron Smith&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.03253">
<title>Counterfactual Normalization: Proactively Addressing Dataset Shift and Improving Reliability Using Causal Mechanisms. (arXiv:1808.03253v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1808.03253</link>
<description rdf:parseType="Literal">&lt;p&gt;Predictive models can fail to generalize from training to deployment
environments because of dataset shift, posing a threat to model reliability and
the safety of downstream decisions made in practice. Instead of using samples
from the target distribution to reactively correct dataset shift, we use
graphical knowledge of the causal mechanisms relating variables in a prediction
problem to proactively remove relationships that do not generalize across
environments, even when these relationships may depend on unobserved variables
(violations of the &quot;no unobserved confounders&quot; assumption). To accomplish this,
we identify variables with unstable paths of statistical influence and remove
them from the model. We also augment the causal graph with latent
counterfactual variables that isolate unstable paths of statistical influence,
allowing us to retain stable paths that would otherwise be removed. Our
experiments demonstrate that models that remove vulnerable variables and use
estimates of the latent variables transfer better, often outperforming in the
target domain despite some accuracy loss in the training domain.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Subbaswamy_A/0/1/0/all/0/1&quot;&gt;Adarsh Subbaswamy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Saria_S/0/1/0/all/0/1&quot;&gt;Suchi Saria&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.03258">
<title>Application of Bounded Total Variation Denoising in Urban Traffic Analysis. (arXiv:1808.03258v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1808.03258</link>
<description rdf:parseType="Literal">&lt;p&gt;While it is believed that denoising is not always necessary in many big data
applications, we show in this paper that denoising is helpful in urban traffic
analysis by applying the method of bounded total variation denoising to the
urban road traffic prediction and clustering problem. We propose two
easy-to-implement methods to estimate the noise strength parameter in the
denoising algorithm, and apply the denoising algorithm to GPS-based traffic
data from Beijing taxi system. For the traffic prediction problem, we combine
neural network and history matching method for roads randomly chosen from an
urban area of Beijing. Numerical experiments show that the predicting accuracy
is improved significantly by applying the proposed bounded total variation
denoising algorithm. We also test the algorithm on clustering problem, where a
recently developed clustering analysis method is applied to more than one
hundred urban road segments in Beijing based on their velocity profiles. Better
clustering result is obtained after denoising.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_S/0/1/0/all/0/1&quot;&gt;Shanshan Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1&quot;&gt;Haijun Yu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.03162">
<title>Bayesian bandits: balancing the exploration-exploitation tradeoff via double sampling. (arXiv:1709.03162v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1709.03162</link>
<description rdf:parseType="Literal">&lt;p&gt;Reinforcement learning studies how to balance exploration and exploitation in
real-world systems, optimizing interactions with the world while simultaneously
learning how the world operates. One general class of algorithms for such
learning is the multi-armed bandit setting. Randomized probability matching,
based upon the Thompson sampling approach introduced in the 1930s, has recently
been shown to perform well and to enjoy provable optimality properties. It
permits generative, interpretable modeling in a Bayesian setting, where prior
knowledge is incorporated, and the computed posteriors naturally capture the
full state of knowledge. In this work, we harness the information contained in
the Bayesian posterior and estimate its sufficient statistics via sampling. In
several application domains, for example in health and medicine, each
interaction with the world can be expensive and invasive, whereas drawing
samples from the model is relatively inexpensive. Exploiting this viewpoint, we
develop a double sampling technique driven by the uncertainty in the learning
process: it favors exploitation when certain about the properties of each arm,
exploring otherwise. The proposed algorithm does not make any distributional
assumption and it is applicable to complex reward distributions, as long as
Bayesian posterior updates are computable. Utilizing the estimated posterior
sufficient statistics, double sampling autonomously balances the
exploration-exploitation tradeoff to make better informed decisions. We
empirically show its reduced cumulative regret when compared to
state-of-the-art alternatives in representative bandit settings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Urteaga_I/0/1/0/all/0/1&quot;&gt;I&amp;#xf1;igo Urteaga&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wiggins_C/0/1/0/all/0/1&quot;&gt;Chris H. Wiggins&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.03163">
<title>Variational inference for the multi-armed contextual bandit. (arXiv:1709.03163v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1709.03163</link>
<description rdf:parseType="Literal">&lt;p&gt;In many biomedical, science, and engineering problems, one must sequentially
decide which action to take next so as to maximize rewards. One general class
of algorithms for optimizing interactions with the world, while simultaneously
learning how the world operates, is the multi-armed bandit setting and, in
particular, the contextual bandit case. In this setting, for each executed
action, one observes rewards that are dependent on a given &apos;context&apos;, available
at each interaction with the world. The Thompson sampling algorithm has
recently been shown to enjoy provable optimality properties for this set of
problems, and to perform well in real-world settings. It facilitates generative
and interpretable modeling of the problem at hand. Nevertheless, the design and
complexity of the model limit its application, since one must both sample from
the distributions modeled and calculate their expected rewards. We here show
how these limitations can be overcome using variational inference to
approximate complex models, applying to the reinforcement learning case
advances developed for the inference case in the machine learning community
over the past two decades. We consider contextual multi-armed bandit
applications where the true reward distribution is unknown and complex, which
we approximate with a mixture model whose parameters are inferred via
variational inference. We show how the proposed variational Thompson sampling
approach is accurate in approximating the true distribution, and attains
reduced regrets even with complex reward distributions. The proposed algorithm
is valuable for practical scenarios where restrictive modeling assumptions are
undesirable.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Urteaga_I/0/1/0/all/0/1&quot;&gt;I&amp;#xf1;igo Urteaga&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wiggins_C/0/1/0/all/0/1&quot;&gt;Chris H. Wiggins&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.08968">
<title>Spurious Local Minima are Common in Two-Layer ReLU Neural Networks. (arXiv:1712.08968v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1712.08968</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the optimization problem associated with training simple ReLU
neural networks of the form $\mathbf{x}\mapsto
\sum_{i=1}^{k}\max\{0,\mathbf{w}_i^\top \mathbf{x}\}$ with respect to the
squared loss. We provide a computer-assisted proof that even if the input
distribution is standard Gaussian, even if the dimension is arbitrarily large,
and even if the target values are generated by such a network, with orthonormal
parameter vectors, the problem can still have spurious local minima once $6\le
k\le 20$. By a concentration of measure argument, this implies that in high
input dimensions, \emph{nearly all} target networks of the relevant sizes lead
to spurious local minima. Moreover, we conduct experiments which show that the
probability of hitting such local minima is quite high, and increasing with the
network size. On the positive side, mild over-parameterization appears to
drastically reduce such local minima, indicating that an over-parameterization
assumption is necessary to get a positive result in this setting.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Safran_I/0/1/0/all/0/1&quot;&gt;Itay Safran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shamir_O/0/1/0/all/0/1&quot;&gt;Ohad Shamir&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.04339">
<title>Estimating the Number of Connected Components in a Graph via Subgraph Sampling. (arXiv:1801.04339v2 [math.ST] UPDATED)</title>
<link>http://arxiv.org/abs/1801.04339</link>
<description rdf:parseType="Literal">&lt;p&gt;Learning properties of large graphs from samples has been an important
problem in statistical network analysis since the early work of Goodman
\cite{Goodman1949} and Frank \cite{Frank1978}. We revisit a problem formulated
by Frank \cite{Frank1978} of estimating the number of connected components in a
large graph based on the subgraph sampling model, in which we randomly sample a
subset of the vertices and observe the induced subgraph. The key question is
whether accurate estimation is achievable in the \emph{sublinear} regime where
only a vanishing fraction of the vertices are sampled. We show that it is
impossible if the parent graph is allowed to contain high-degree vertices or
long induced cycles. For the class of chordal graphs, where induced cycles of
length four or above are forbidden, we characterize the optimal sample
complexity within constant factors and construct linear-time estimators that
provably achieve these bounds. This significantly expands the scope of previous
results which have focused on unbiased estimators and special classes of graphs
such as forests or cliques.
&lt;/p&gt;
&lt;p&gt;Both the construction and the analysis of the proposed methodology rely on
combinatorial properties of chordal graphs and identities of induced subgraph
counts. They, in turn, also play a key role in proving minimax lower bounds
based on construction of random instances of graphs with matching structures of
small subgraphs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Klusowski_J/0/1/0/all/0/1&quot;&gt;Jason M. Klusowski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Wu_Y/0/1/0/all/0/1&quot;&gt;Yihong Wu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.05062">
<title>Multi-Label Learning from Medical Plain Text with Convolutional Residual Models. (arXiv:1801.05062v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1801.05062</link>
<description rdf:parseType="Literal">&lt;p&gt;Predicting diagnoses from Electronic Health Records (EHRs) is an important
medical application of multi-label learning. We propose a convolutional
residual model for multi-label classification from doctor notes in EHR data. A
given patient may have multiple diagnoses, and therefore multi-label learning
is required. We employ a Convolutional Neural Network (CNN) to encode plain
text into a fixed-length sentence embedding vector. Since diagnoses are
typically correlated, a deep residual network is employed on top of the CNN
encoder, to capture label (diagnosis) dependencies and incorporate information
directly from the encoded sentence vector. A real EHR dataset is considered,
and we compare the proposed model with several well-known baselines, to predict
diagnoses based on doctor notes. Experimental results demonstrate the
superiority of the proposed convolutional residual model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xinyuan Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Henao_R/0/1/0/all/0/1&quot;&gt;Ricardo Henao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gan_Z/0/1/0/all/0/1&quot;&gt;Zhe Gan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yitong Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Carin_L/0/1/0/all/0/1&quot;&gt;Lawrence Carin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.04189">
<title>Noise2Noise: Learning Image Restoration without Clean Data. (arXiv:1803.04189v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1803.04189</link>
<description rdf:parseType="Literal">&lt;p&gt;We apply basic statistical reasoning to signal reconstruction by machine
learning -- learning to map corrupted observations to clean signals -- with a
simple and powerful conclusion: it is possible to learn to restore images by
only looking at corrupted examples, at performance at and sometimes exceeding
training using clean data, without explicit image priors or likelihood models
of the corruption. In practice, we show that a single model learns photographic
noise removal, denoising synthetic Monte Carlo images, and reconstruction of
undersampled MRI scans -- all corrupted by different processes -- based on
noisy data only.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lehtinen_J/0/1/0/all/0/1&quot;&gt;Jaakko Lehtinen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Munkberg_J/0/1/0/all/0/1&quot;&gt;Jacob Munkberg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hasselgren_J/0/1/0/all/0/1&quot;&gt;Jon Hasselgren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Laine_S/0/1/0/all/0/1&quot;&gt;Samuli Laine&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Karras_T/0/1/0/all/0/1&quot;&gt;Tero Karras&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aittala_M/0/1/0/all/0/1&quot;&gt;Miika Aittala&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aila_T/0/1/0/all/0/1&quot;&gt;Timo Aila&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.11258">
<title>Hierarchical Dirichlet Process-based Open Set Recognition. (arXiv:1806.11258v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1806.11258</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we propose a novel hierarchical dirichlet process-based
classification framework for open set recognition (HDP-OSR) where new
categories&apos; samples unseen in training appear during testing. Unlike the
existing methods which deal with this problem from the perspective of
discriminative model, we reconsider this problem from the perspective of
generative model. We model each known class data in training set as a group in
hierarchical dirichlet process (HDP) while the testing set as a whole is
treated in the same way, then co-clustering all the groups under the HDP
framework. Based on the properties of HDP, our HDP-OSR does not overly depend
on training samples and can achieve adaptive change as the data changes. More
precisely, HDP-OSR can automatically reserve space for unknown categories while
it can also discover new categories, meaning it naturally adapts to the open
set recognition scenario. Furthermore, treating the testing set as a whole
makes our framework take the correlations among the testing samples into
account whereas the existing methods obviously ignore this information.
Experimental results on a set of benchmark data sets indicate the validity of
our learning framework.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Geng_C/0/1/0/all/0/1&quot;&gt;Chuanxing Geng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_S/0/1/0/all/0/1&quot;&gt;Songcan Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.01069">
<title>Adversarial Robustness Toolbox v0.3.0. (arXiv:1807.01069v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1807.01069</link>
<description rdf:parseType="Literal">&lt;p&gt;Adversarial examples have become an indisputable threat to the security of
modern AI systems based on deep neural networks (DNNs). The Adversarial
Robustness Toolbox (ART) is a Python library designed to support researchers
and developers in creating novel defence techniques, as well as in deploying
practical defences of real-world AI systems. Researchers can use ART to
benchmark novel defences against the state-of-the-art. For developers, the
library provides interfaces which support the composition of comprehensive
defence systems using individual methods as building blocks. The Adversarial
Robustness Toolbox supports machine learning models (and deep neural networks
(DNNs) specifically) implemented in any of the most popular deep learning
frameworks (TensorFlow, Keras, PyTorch and MXNet). Currently, the library is
primarily intended to improve the adversarial robustness of visual recognition
systems, however, future releases that will comprise adaptations to other data
modes (such as speech, text or time series) are envisioned. The ART source code
is released (https://github.com/IBM/adversarial-robustness-toolbox) under an
MIT license. The release includes code examples and extensive documentation
(&lt;a href=&quot;http://adversarial-robustness-toolbox.readthedocs.io&quot;&gt;this http URL&lt;/a&gt;) to help researchers and
developers get quickly started.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nicolae_M/0/1/0/all/0/1&quot;&gt;Maria-Irina Nicolae&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sinn_M/0/1/0/all/0/1&quot;&gt;Mathieu Sinn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tran_M/0/1/0/all/0/1&quot;&gt;Minh Ngoc Tran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rawat_A/0/1/0/all/0/1&quot;&gt;Ambrish Rawat&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wistuba_M/0/1/0/all/0/1&quot;&gt;Martin Wistuba&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zantedeschi_V/0/1/0/all/0/1&quot;&gt;Valentina Zantedeschi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Baracaldo_N/0/1/0/all/0/1&quot;&gt;Nathalie Baracaldo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_B/0/1/0/all/0/1&quot;&gt;Bryant Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ludwig_H/0/1/0/all/0/1&quot;&gt;Heiko Ludwig&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Molloy_I/0/1/0/all/0/1&quot;&gt;Ian M. Molloy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Edwards_B/0/1/0/all/0/1&quot;&gt;Ben Edwards&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.04119">
<title>Exploiting statistical dependencies of time series with hierarchical correlation reconstruction. (arXiv:1807.04119v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1807.04119</link>
<description rdf:parseType="Literal">&lt;p&gt;While we are usually focused on forecasting future values of time series, it
is often valuable to additionally predict their entire probability
distributions, e.g. to evaluate risk, Monte Carlo simulations. On example of
time series of $\approx$ 30000 Dow Jones Industrial Averages, there will be
presented application of hierarchical correlation reconstruction for this
purpose: mean-square estimating polynomial as joint density for (current value,
context), where context is for example a few previous values. Then substituting
the currently observed context and normalizing density to 1, we get predicted
probability distribution for the current value. In contrast to standard machine
learning approaches like neural networks, optimal polynomial coefficients here
can be inexpensively directly calculated, have controllable accuracy, are
unique and independent, each has a specific cumulant-like interpretation, and
such approximation using can approach complete description of any real joint
distribution - providing a perfect tool to quantitatively describe and exploit
statistical dependencies in time series. There is also discussed application
for non-stationary time series: adapting coefficients to local statistical
behavior.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Duda_J/0/1/0/all/0/1&quot;&gt;Jarek Duda&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.09386">
<title>On the Randomized Complexity of Minimizing a Convex Quadratic Function. (arXiv:1807.09386v5 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1807.09386</link>
<description rdf:parseType="Literal">&lt;p&gt;Minimizing a convex, quadratic objective is a fundamental problem in machine
learning and optimization. In this work, we study prove information-theoretic,
gradient query complexity lower bounds for minimizing convex quadratic
functions, which, unlike prior works, apply even for randomized algorithms.
Specifically, we construct a distribution over quadratic functions that
witnesses lower bounds which match those known for deterministic algorithms, up
to multiplicative constants. The distribution which witnesses our lower bound
is in fact quite benign: it is both closed form, and derived from classical
ensembles in random matrix theory. We believe that our construction constitutes
a plausible &quot;average case&quot; setting, and thus provides compelling evidence that
the worst case and average case complexity of convex-quadratic optimization are
essentially identical.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Simchowitz_M/0/1/0/all/0/1&quot;&gt;Max Simchowitz&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1808.01975">
<title>A Survey on Surrogate Approaches to Non-negative Matrix Factorization. (arXiv:1808.01975v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1808.01975</link>
<description rdf:parseType="Literal">&lt;p&gt;Motivated by applications in hyperspectral imaging we investigate methods for
approximating a high-dimensional non-negative matrix $\mathbf{\mathit{Y}}$ by a
product of two lower-dimensional, non-negative matrices $\mathbf{\mathit{K}}$
and $\mathbf{\mathit{X}}.$ This so-called non-negative matrix factorization is
based on defining suitable Tikhonov functionals, which combine a discrepancy
measure for $\mathbf{\mathit{Y}}\approx\mathbf{\mathit{KX}}$ with penalty terms
for enforcing additional properties of $\mathbf{\mathit{K}}$ and
$\mathbf{\mathit{X}}$. The minimization is based on alternating minimization
with respect to $\mathbf{\mathit{K}}$ or $\mathbf{\mathit{X}}$, where in each
iteration step one replaces the original Tikhonov functional by a locally
defined surrogate functional. The choice of surrogate functionals is crucial:
It should allow a comparatively simple minimization and simultaneously its
first order optimality condition should lead to multiplicative update rules,
which automatically preserve non-negativity of the iterates. We review the most
standard construction principles for surrogate functionals for Frobenius-norm
and Kullback-Leibler discrepancy measures. We extend the known surrogate
constructions by a general framework, which allows to add a large variety of
penalty terms. The paper finishes by deriving the corresponding alternating
minimization schemes explicitely and by applying these methods to MALDI imaging
data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fernsel_P/0/1/0/all/0/1&quot;&gt;Pascal Fernsel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Maass_P/0/1/0/all/0/1&quot;&gt;Peter Maass&lt;/a&gt;</dc:creator>
</item></rdf:RDF>