<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Boring papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Bad Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-05-21T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07507"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07866"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07891"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07917"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08034"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08060"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08154"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.08314"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.07209"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.01374"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07398"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07429"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07431"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07505"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07535"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07547"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07563"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07592"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07683"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07708"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07732"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07733"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07780"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07805"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07830"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07871"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07874"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07932"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07935"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07956"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1702.08887"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1705.09026"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1707.08234"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.10082"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.11311"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.00129"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04007"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04592"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04799"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.09010"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.00846"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.01486"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.10969"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.00909"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.05250"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07376"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07405"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07410"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07412"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07416"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07430"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07438"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07445"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07451"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07454"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07458"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07460"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07474"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07482"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07489"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07516"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07561"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07574"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07588"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07601"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07616"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07624"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07633"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07645"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07654"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07684"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07687"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07702"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07725"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07737"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07746"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07777"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07785"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07808"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07810"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07820"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07833"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07836"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07844"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07880"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07909"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07912"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07914"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07938"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07943"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07960"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07978"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07979"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07997"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08010"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08045"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08052"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08058"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08061"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08102"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08114"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08140"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08166"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08193"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08196"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08206"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1512.08064"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1707.09049"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1708.08826"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.02893"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.03528"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.08862"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.09953"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.01682"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.02613"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.02294"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.07691"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.03497"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.03644"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04477"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04944"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05811"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.07024"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08407"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09064"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.10501"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.00195"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.07612"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.05862"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.06872"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.07045"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.09893"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.00521"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.01045"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.02257"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.05052"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1702.08159"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1805.07507">
<title>Reconciled Polynomial Machine: A Unified Representation of Shallow and Deep Learning Models. (arXiv:1805.07507v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.07507</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we aim at introducing a new machine learning model, namely
reconciled polynomial machine, which can provide a unified representation of
existing shallow and deep machine learning models. Reconciled polynomial
machine predicts the output by computing the inner product of the feature
kernel function and variable reconciling function. Analysis of several concrete
models, including Linear Models, FM, MVM, Perceptron, MLP and Deep Neural
Networks, will be provided in this paper, which can all be reduced to the
reconciled polynomial machine representations. Detailed analysis of the
learning error by these models will also be illustrated in this paper based on
their reduced representations from the function approximation perspective.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Jiawei Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cui_L/0/1/0/all/0/1&quot;&gt;Limeng Cui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gouza_F/0/1/0/all/0/1&quot;&gt;Fisher B. Gouza&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07866">
<title>Hybrid Macro/Micro Level Backpropagation for Training Deep Spiking Neural Networks. (arXiv:1805.07866v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1805.07866</link>
<description rdf:parseType="Literal">&lt;p&gt;Spiking neural networks (SNNs) are positioned to enable spatio-temporal
information processing and ultra-low power event-driven neuromorphic hardware.
However, SNNs are yet to reach the same performances of conventional deep
artificial neural networks (ANNs), a long-standing challenge due to complex
dynamics and non-differentiable spike events encountered in training. The
existing SNN error backpropagation (BP) methods are limited in terms of
scalability, lack of proper handling of spiking discontinuities, and/or
mismatch between the rate-coded loss function and computed gradient. We present
a hybrid macro/micro level backpropagation algorithm (HM2-BP) for training
multi-layer SNNs. The temporal effects are precisely captured by the proposed
spike-train level post-synaptic potential (S-PSP) at the microscopic level. The
rate-coded errors are defined at the macroscopic level, computed and
back-propagated across both macroscopic and microscopic levels. Different from
existing BP methods, HM2-BP directly computes the gradient of the rate-coded
loss function w.r.t tunable parameters. We evaluate the proposed HM2-BP
algorithm by training deep fully connected and convolutional SNNs based on the
static MNIST [13] and dynamic neuromorphic N-MNIST [22] datasets. HM2-BP
achieves an accuracy level of 99.49% and $98.88% for MNIST and N-MNIST,
respectively, outperforming the best reported performances obtained from the
existing SNN BP algorithms. It also achieves competitive performances
surpassing those of conventional deep learning models when dealing with
asynchronous spiking streams.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jin_Y/0/1/0/all/0/1&quot;&gt;Yingyezhe Jin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_P/0/1/0/all/0/1&quot;&gt;Peng Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1&quot;&gt;Wenrui Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07891">
<title>Parameter Hub: a Rack-Scale Parameter Server for Distributed Deep Neural Network Training. (arXiv:1805.07891v1 [cs.DC])</title>
<link>http://arxiv.org/abs/1805.07891</link>
<description rdf:parseType="Literal">&lt;p&gt;Distributed deep neural network (DDNN) training constitutes an increasingly
important workload that frequently runs in the cloud. Larger DNN models and
faster compute engines are shifting DDNN training bottlenecks from computation
to communication. This paper characterizes DDNN training to precisely pinpoint
these bottlenecks. We found that timely training requires high performance
parameter servers (PSs) with optimized network stacks and gradient processing
pipelines, as well as server and network hardware with balanced computation and
communication resources. We therefore propose PHub, a high performance
multi-tenant, rack-scale PS design. PHub co-designs the PS software and
hardware to accelerate rack-level and hierarchical cross-rack parameter
exchange, with an API compatible with many DDNN training frameworks. PHub
provides a performance improvement of up to 2.7x compared to state-of-the-art
distributed training techniques for cloud-based ImageNet workloads, with 25%
better throughput per dollar.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_L/0/1/0/all/0/1&quot;&gt;Liang Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nelson_J/0/1/0/all/0/1&quot;&gt;Jacob Nelson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ceze_L/0/1/0/all/0/1&quot;&gt;Luis Ceze&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Phanishayee_A/0/1/0/all/0/1&quot;&gt;Amar Phanishayee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Krishnamurthy_A/0/1/0/all/0/1&quot;&gt;Arvind Krishnamurthy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07917">
<title>Evolutionary Reinforcement Learning. (arXiv:1805.07917v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.07917</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep Reinforcement Learning (DRL) algorithms have been successfully applied
to a range of challenging control tasks. However, these methods typically
suffer from three core difficulties: temporal credit assignment with sparse
rewards, lack of effective exploration, and brittle convergence properties that
are extremely sensitive to hyperparameters. Collectively, these challenges
severely limit the applicability of these approaches to real world problems.
Evolutionary Algorithms (EAs), a class of black box optimization techniques
inspired by natural evolution, are well suited to address each of these three
challenges. However, EAs typically suffer with high sample complexity and
struggle to solve problems that require optimization of a large number of
parameters. In this paper, we introduce Evolutionary Reinforcement Learning
(ERL), a hybrid algorithm that leverages the population of an EA to provide
diversified data to train an RL agent, and reinserts the RL agent into the EA
population periodically to inject gradient information into the EA. ERL
inherits EA&apos;s ability of temporal credit assignment with a fitness metric,
effective exploration with a diverse set of policies, and stability of a
population-based approach and complements it with off-policy DRL&apos;s ability to
leverage gradients for higher sample efficiency and faster learning.
Experiments in a range of challenging continuous control benchmark tasks
demonstrate that ERL significantly outperforms prior DRL and EA methods,
achieving state-of-the-art performances.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khadka_S/0/1/0/all/0/1&quot;&gt;Shauharda Khadka&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tumer_K/0/1/0/all/0/1&quot;&gt;Kagan Tumer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08034">
<title>Never look back - The EnKF method and its application to the training of neural networks without back propagation. (arXiv:1805.08034v1 [math.NA])</title>
<link>http://arxiv.org/abs/1805.08034</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work, we present a new derivative-free optimization method and
investigate its use for training neural networks. Our method is motivated by
the Ensemble Kalman Filter (EnKF), which has been used successfully for solving
optimization problems that involve large-scale, highly nonlinear dynamical
systems. A key benefit of the EnKF method is that it requires only the
evaluation of the forward propagation but not its derivatives. Hence, in the
context of neural networks it alleviates the need for back propagation and
reduces the memory consumption dramatically. However, the method is not a pure
&quot;black-box&quot; global optimization heuristic as it efficiently utilizes the
structure of typical learning problems. We propose an important modification of
the EnKF that enables us to prove convergence of our method to the minimizer of
a strongly convex function. Our method also bears similarity with implicit
filtering and we demonstrate its potential for minimizing highly oscillatory
functions using a simple example. Further, we provide numerical examples that
demonstrate the potential of our method for training deep neural networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Haber_E/0/1/0/all/0/1&quot;&gt;Eldad Haber&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Lucka_F/0/1/0/all/0/1&quot;&gt;Felix Lucka&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Ruthotto_L/0/1/0/all/0/1&quot;&gt;Lars Ruthotto&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08060">
<title>Channel Estimation for Visible Light Communications Using Neural Networks. (arXiv:1805.08060v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1805.08060</link>
<description rdf:parseType="Literal">&lt;p&gt;Visible light communications (VLC) is an emerging field in technology and
research. Estimating the channel taps is a major requirement for designing
reliable communication systems. Due to the nonlinear characteristics of the VLC
channel those parameters cannot be derived easily. They can be calculated by
means of software simulation. In this work, a novel methodology is proposed for
the prediction of channel parameters using neural networks. Measurements
conducted in a controlled experimental setup are used to train neural networks
for channel tap prediction. Our experiment results indicate that neural
networks can be effectively trained to predict channel taps under different
environmental conditions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yesilkaya_A/0/1/0/all/0/1&quot;&gt;Anil Yesilkaya&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Karatalay_O/0/1/0/all/0/1&quot;&gt;Onur Karatalay&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ogrenci_A/0/1/0/all/0/1&quot;&gt;Arif Selcuk Ogrenci&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Panayirci_E/0/1/0/all/0/1&quot;&gt;Erdal Panayirci&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08154">
<title>Numeracy for Language Models: Evaluating and Improving their Ability to Predict Numbers. (arXiv:1805.08154v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1805.08154</link>
<description rdf:parseType="Literal">&lt;p&gt;Numeracy is the ability to understand and work with numbers. It is a
necessary skill for composing and understanding documents in clinical,
scientific, and other technical domains. In this paper, we explore different
strategies for modelling numerals with language models, such as memorisation
and digit-by-digit composition, and propose a novel neural architecture that
uses a continuous probability density function to model numerals from an open
vocabulary. Our evaluation on clinical and scientific datasets shows that using
hierarchical models to distinguish numerals from words improves a perplexity
metric on the subset of numerals by 2 and 4 orders of magnitude, respectively,
over non-hierarchical models. A combination of strategies can further improve
perplexity. Our continuous probability density function model reduces mean
absolute percentage errors by 18% and 54% in comparison to the second best
strategy for each dataset, respectively.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Spithourakis_G/0/1/0/all/0/1&quot;&gt;Georgios P. Spithourakis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Riedel_S/0/1/0/all/0/1&quot;&gt;Sebastian Riedel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.08314">
<title>Benchmarking Decoupled Neural Interfaces with Synthetic Gradients. (arXiv:1712.08314v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1712.08314</link>
<description rdf:parseType="Literal">&lt;p&gt;Artifical Neural Networks are a particular class of learning systems modeled
after biological neural functions with an interesting penchant for Hebbian
learning, that is &quot;neurons that wire together, fire together&quot;. However, unlike
their natural counterparts, artificial neural networks have a close and
stringent coupling between the modules of neurons in the network. This coupling
or locking imposes upon the network a strict and inflexible structure that
prevent layers in the network from updating their weights until a full
feed-forward and backward pass has occurred. Such a constraint though may have
sufficed for a while, is now no longer feasible in the era of very-large-scale
machine learning, coupled with the increased desire for parallelization of the
learning process across multiple computing infrastructures. To solve this
problem, synthetic gradients (SG) with decoupled neural interfaces (DNI) are
introduced as a viable alternative to the backpropagation algorithm. This paper
performs a speed benchmark to compare the speed and accuracy capabilities of
SG-DNI as opposed to a standard neural interface using multilayer perceptron
MLP. SG-DNI shows good promise, in that it not only captures the learning
problem, it is also over 3-fold faster due to it asynchronous learning
capabilities.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bisong_E/0/1/0/all/0/1&quot;&gt;Ekaba Bisong&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.07209">
<title>NAIS-Net: Stable Deep Networks from Non-Autonomous Differential Equations. (arXiv:1804.07209v2 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1804.07209</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper introduces Non-Autonomous Input-Output Stable Network (NAIS-Net),
a very deep architecture where each stacked processing block is derived from a
time-invariant non-autonomous dynamical system. Non-autonomy is implemented by
skip connections from the block input to each of the unrolled processing stages
and allows stability to be enforced so that blocks can be unrolled adaptively
to a pattern-dependent processing depth. NAIS-Net induces non-trivial,
Lipschitz input-output maps, even for an infinite unroll length. We prove that
the network is globally asymptotically stable so that for every initial
condition there is exactly one input-dependent equilibrium assuming tanh units,
and multiple stable equilibria for ReL units. An efficient implementation that
enforces the stability under derived conditions for both fully-connected and
convolutional layers is also presented. Experimental results show how NAIS-Net
exhibits stability in practice, yielding a significant reduction in
generalization gap compared to ResNets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ciccone_M/0/1/0/all/0/1&quot;&gt;Marco Ciccone&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gallieri_M/0/1/0/all/0/1&quot;&gt;Marco Gallieri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Masci_J/0/1/0/all/0/1&quot;&gt;Jonathan Masci&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Osendorfer_C/0/1/0/all/0/1&quot;&gt;Christian Osendorfer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gomez_F/0/1/0/all/0/1&quot;&gt;Faustino Gomez&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.01374">
<title>RF-PUF: Enhancing IoT Security through Authentication of Wireless Nodes using In-situ Machine Learning. (arXiv:1805.01374v2 [cs.CR] UPDATED)</title>
<link>http://arxiv.org/abs/1805.01374</link>
<description rdf:parseType="Literal">&lt;p&gt;Traditional authentication in radio-frequency (RF) systems enable secure data
transmission within a network through techniques such as digital signatures and
hash-based message authentication codes (HMAC). However, these techniques may
not prevent a malicious attacker from stealing the secret encryption keys using
invasive, modeling or side channel attacks. Physically unclonable functions
(PUF), on the other hand, can exploit manufacturing process variations to
uniquely identify silicon chips which makes a PUF-based system extremely robust
and secure at low cost, as it is practically impossible to replicate the same
silicon characteristics across dies. In this paper, we present RF- PUF: a deep
neural network based framework that allows real-time authentication of wireless
nodes, using the effects of inherent process variation on RF properties of the
wireless transmitters (Tx), detected through in-situ machine learning at the
receiver (Rx) end. The proposed method utilizes the already-existing asymmetric
RF communication framework and does not require any additional circuitry for
PUF generation or feature extraction. Simulation results involving the process
variations in a standard 65 nm technology node, and features such as LO offset
and I-Q imbalance detected with a neural network having 50 neurons in the
hidden layer indicate that the framework can distinguish up to 4800
transmitters with an accuracy of 99.9% (~ 99% for 10,000 transmitters) under
varying channel conditions, and without the need for traditional preambles.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chatterjee_B/0/1/0/all/0/1&quot;&gt;Baibhab Chatterjee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Das_D/0/1/0/all/0/1&quot;&gt;Debayan Das&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Maity_S/0/1/0/all/0/1&quot;&gt;Shovan Maity&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sen_S/0/1/0/all/0/1&quot;&gt;Shreyas Sen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07398">
<title>Robust Handling of Polysemy via Sparse Representations. (arXiv:1805.07398v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1805.07398</link>
<description rdf:parseType="Literal">&lt;p&gt;Words are polysemous and multi-faceted, with many shades of meanings. We
suggest that sparse distributed representations are more suitable than other,
commonly used, (dense) representations to express these multiple facets, and
present Category Builder, a working system that, as we show, makes use of
sparse representations to support multi-faceted lexical representations. We
argue that the set expansion task is well suited to study these meaning
distinctions since a word may belong to multiple sets with a different reason
for membership in each. We therefore exhibit the performance of Category
Builder on this task, while showing that our representation captures at the
same time analogy problems such as &quot;the Ganga of Egypt&quot; or &quot;the Voldemort of
Tolkien&quot;. Category Builder is shown to be a more expressive lexical
representation and to outperform dense representations such as Word2Vec in some
analogy classes despite being shown only two of the three input terms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mahabal_A/0/1/0/all/0/1&quot;&gt;Abhijit Mahabal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roth_D/0/1/0/all/0/1&quot;&gt;Dan Roth&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mittal_S/0/1/0/all/0/1&quot;&gt;Sid Mittal&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07429">
<title>Designing communication systems via iterative improvement: error correction coding with Bayes decoder and codebook optimized for source symbol error. (arXiv:1805.07429v1 [eess.SP])</title>
<link>http://arxiv.org/abs/1805.07429</link>
<description rdf:parseType="Literal">&lt;p&gt;In error correction coding (ECC), the typical error metric is the bit error
rate (BER) which measures the number of bit errors. For this metric, the
positions of the bits are not relevant to the decoding, and in many noise
models, not relevant to the BER either. In many applications this is
unsatisfactory as typically all bits are not equal and have different
significance. We look at ECC from a Bayesian perspective and introduce Bayes
estimators with general loss functions to take into account the bit
significance. We propose ECC schemes that optimize this error metric. As the
problem is highly nonlinear, traditional ECC construction techniques are not
applicable and we use iterative improvement search techniques to find good
codebooks. We provide numerical experiments to show that they can be superior
to classical linear block codes such as Hamming codes and decoding methods such
as minimum distance decoding.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Wu_C/0/1/0/all/0/1&quot;&gt;Chai Wah Wu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07431">
<title>Can machine learning identify interesting mathematics? An exploration using empirically observed laws. (arXiv:1805.07431v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.07431</link>
<description rdf:parseType="Literal">&lt;p&gt;We explore the possibility of using machine learning to identify interesting
mathematical structures by using certain quantities that serve as fingerprints.
In particular, we extract features from integer sequences using two empirical
laws: Benford&apos;s law and Taylor&apos;s law and experiment with various classifiers to
identify whether a sequence is nice, important, multiplicative, easy to compute
or related to primes or palindromes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_C/0/1/0/all/0/1&quot;&gt;Chai Wah Wu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07505">
<title>Free-rider Episode Screening via Dual Partition Model. (arXiv:1805.07505v1 [cs.DB])</title>
<link>http://arxiv.org/abs/1805.07505</link>
<description rdf:parseType="Literal">&lt;p&gt;One of the drawbacks of frequent episode mining is that overwhelmingly many
of the discovered patterns are redundant. Free-rider episode, as a typical
example, consists of a real pattern doped with some additional noise events.
Because of the possible high support of the inside noise events, such
free-rider episodes may have abnormally high support that they cannot be
filtered by frequency based framework. An effective technique for filtering
free-rider episodes is using a partition model to divide an episode into two
consecutive subepisodes and comparing the observed support of such episode with
its expected support under the assumption that these two subepisodes occur
independently. In this paper, we take more complex subepisodes into
consideration and develop a novel partition model named EDP for free-rider
episode filtering from a given set of episodes. It combines (1) a dual
partition strategy which divides an episode to an underlying real pattern and
potential noises; (2) a novel definition of the expected support of a
free-rider episode based on the proposed partition strategy. We can deem the
episode interesting if the observed support is substantially higher than the
expected support estimated by our model. The experiments on synthetic and
real-world datasets demonstrate EDP can effectively filter free-rider episodes
compared with existing state-of-the-arts.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ao_X/0/1/0/all/0/1&quot;&gt;Xiang Ao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yang Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_Z/0/1/0/all/0/1&quot;&gt;Zhen Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zuo_L/0/1/0/all/0/1&quot;&gt;Luo Zuo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_Q/0/1/0/all/0/1&quot;&gt;Qing He&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07535">
<title>An optimal approximation of discrete random variables with respect to the Kolmogorov distance. (arXiv:1805.07535v1 [cs.DS])</title>
<link>http://arxiv.org/abs/1805.07535</link>
<description rdf:parseType="Literal">&lt;p&gt;We present an algorithm that takes a discrete random variable $X$ and a
number $m$ and computes a random variable whose support (set of possible
outcomes) is of size at most $m$ and whose Kolmogorov distance from $X$ is
minimal. In addition to a formal theoretical analysis of the correctness and of
the computational complexity of the algorithm, we present a detailed empirical
evaluation that shows how the proposed approach performs in practice in
different applications and domains.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cohen_L/0/1/0/all/0/1&quot;&gt;Liat Cohen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fried_D/0/1/0/all/0/1&quot;&gt;Dror Fried&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Weiss_G/0/1/0/all/0/1&quot;&gt;Gera Weiss&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07547">
<title>Autonomous discovery of the goal space to learn a parameterized skill. (arXiv:1805.07547v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1805.07547</link>
<description rdf:parseType="Literal">&lt;p&gt;A parameterized skill is a mapping from multiple goals/task parameters to the
policy parameters to accomplish them. Existing works in the literature show how
a parameterized skill can be learned given a task space that defines all the
possible achievable goals. In this work, we focus on tasks defined in terms of
final states (goals), and we face on the challenge where the agent aims to
autonomously acquire a parameterized skill to manipulate an initially unknown
environment. In this case, the task space is not known a priori and the agent
has to autonomously discover it. The agent may posit as a task space its whole
sensory space (i.e. the space of all possible sensor readings) as the
achievable goals will certainly be a subset of this space. However, the space
of achievable goals may be a very tiny subspace in relation to the whole
sensory space, thus directly using the sensor space as task space exposes the
agent to the curse of dimensionality and makes existing autonomous skill
acquisition algorithms inefficient. In this work we present an algorithm that
actively discovers the manifold of the achievable goals within the sensor
space. We validate the algorithm by employing it in multiple different
simulated scenarios where the agent actions achieve different types of goals:
moving a redundant arm, pushing an object, and changing the color of an object.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cartoni_E/0/1/0/all/0/1&quot;&gt;Emilio Cartoni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Baldassarre_G/0/1/0/all/0/1&quot;&gt;Gianluca Baldassarre&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07563">
<title>Reinforcement Learning of Theorem Proving. (arXiv:1805.07563v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1805.07563</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce a theorem proving algorithm that uses practically no domain
heuristics for guiding its connection-style proof search. Instead, it runs many
Monte-Carlo simulations guided by reinforcement learning from previous proof
attempts. We produce several versions of the prover, parameterized by different
learning and guiding algorithms. The strongest version of the system is trained
on a large corpus of mathematical problems and evaluated on previously unseen
problems. The trained system solves within the same number of inferences over
40% more problems than a baseline prover, which is an unusually high
improvement in this hard AI domain. To our knowledge this is the first time
reinforcement learning has been convincingly applied to solving general
mathematical problems on a large scale.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kaliszyk_C/0/1/0/all/0/1&quot;&gt;Cezary Kaliszyk&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Urban_J/0/1/0/all/0/1&quot;&gt;Josef Urban&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Michalewski_H/0/1/0/all/0/1&quot;&gt;Henryk Michalewski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Olsak_M/0/1/0/all/0/1&quot;&gt;Mirek Ol&amp;#x161;&amp;#xe1;k&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07592">
<title>Adaptively Pruning Features for Boosted Decision Trees. (arXiv:1805.07592v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.07592</link>
<description rdf:parseType="Literal">&lt;p&gt;Boosted decision trees enjoy popularity in a variety of applications;
however, for large-scale datasets, the cost of training a decision tree in each
round can be prohibitively expensive. Inspired by ideas from the multi-arm
bandit literature, we develop a highly efficient algorithm for computing exact
greedy-optimal decision trees, outperforming the state-of-the-art Quick Boost
method. We further develop a framework for deriving lower bounds on the problem
that applies to a wide family of conceivable algorithms for the task (including
our algorithm and Quick Boost), and we demonstrate empirically on a wide
variety of data sets that our algorithm is near-optimal within this family of
algorithms. We also derive a lower bound applicable to any algorithm solving
the task, and we demonstrate that our algorithm empirically achieves
performance close to this best-achievable lower bound.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aziz_M/0/1/0/all/0/1&quot;&gt;Maryam Aziz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Anderton_J/0/1/0/all/0/1&quot;&gt;Jesse Anderton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aslam_J/0/1/0/all/0/1&quot;&gt;Javed Aslam&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07683">
<title>Learning Graph-Level Representations with Gated Recurrent Neural Networks. (arXiv:1805.07683v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.07683</link>
<description rdf:parseType="Literal">&lt;p&gt;Recently a variety of methods have been developed to encode graphs into
low-dimensional vectors that can be easily exploited by machine learning
algorithms. The majority of these methods start by embedding the graph nodes
into a low-dimensional vector space, followed by using some scheme to aggregate
the node embeddings. In this work, we develop a new approach to learn
graph-level representations, which includes a combination of unsupervised and
supervised learning components. We start by learning a set of global node
representations in an unsupervised fashion, followed by a strategy to map the
graph nodes into sequences of node-neighbor pairs. Gated recurrent neural
network (RNN) units are modified to accommodate both the node representations
as well as their neighborhood information. Experiments on standard graph
classification benchmarks demonstrate that our proposed approach achieves
superior or comparable performance relative to the state-of-the-art algorithms
in terms of convergence speed and classification accuracy. We further
illustrate the effectiveness of the different components used by our approach.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jin_Y/0/1/0/all/0/1&quot;&gt;Yu Jin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+JaJa_J/0/1/0/all/0/1&quot;&gt;Joseph F. JaJa&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07708">
<title>A Lyapunov-based Approach to Safe Reinforcement Learning. (arXiv:1805.07708v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.07708</link>
<description rdf:parseType="Literal">&lt;p&gt;In many real-world reinforcement learning (RL) problems, besides optimizing
the main objective function, an agent must concurrently avoid violating a
number of constraints. In particular, besides optimizing performance it is
crucial to guarantee the safety of an agent during training as well as
deployment (e.g. a robot should avoid taking actions - exploratory or not -
which irrevocably harm its hardware). To incorporate safety in RL, we derive
algorithms under the framework of constrained Markov decision problems (CMDPs),
an extension of the standard Markov decision problems (MDPs) augmented with
constraints on expected cumulative costs. Our approach hinges on a novel
\emph{Lyapunov} method. We define and present a method for constructing
Lyapunov functions, which provide an effective way to guarantee the global
safety of a behavior policy during training via a set of local, linear
constraints. Leveraging these theoretical underpinnings, we show how to use the
Lyapunov approach to systematically transform dynamic programming (DP) and RL
algorithms into their safe counterparts. To illustrate their effectiveness, we
evaluate these algorithms in several CMDP planning and decision-making tasks on
a safety benchmark domain. Our results show that our proposed method
significantly outperforms existing baselines in balancing constraint
satisfaction and performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chow_Y/0/1/0/all/0/1&quot;&gt;Yinlam Chow&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nachum_O/0/1/0/all/0/1&quot;&gt;Ofir Nachum&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Duenez_Guzman_E/0/1/0/all/0/1&quot;&gt;Edgar Duenez-Guzman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghavamzadeh_M/0/1/0/all/0/1&quot;&gt;Mohammad Ghavamzadeh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07732">
<title>Nonlinear Distributional Gradient Temporal-Difference Learning. (arXiv:1805.07732v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.07732</link>
<description rdf:parseType="Literal">&lt;p&gt;We devise a distributional variant of gradient temporal-difference (TD)
learning. Distributional reinforcement learning has been demonstrated to
outperform the regular one in the recent study
\citep{bellemare2017distributional}. In our paper, we design two new algorithms
called distributional GTD2 and distributional TDC using the Cram{\&apos;e}r distance
on the distributional version of the Bellman error objective function, which
inherits advantages of both the nonlinear gradient TD algorithms and the
distributional RL approach. We prove the asymptotic almost-sure convergence to
a local optimal solution for general smooth function approximators, which
includes neural networks that have been widely used in recent study to solve
the real-life RL problems. In each step, the computational complexity is linear
w.r.t.\ the number of the parameters of the function approximator, thus can be
implemented efficiently for neural networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qu_C/0/1/0/all/0/1&quot;&gt;Chao Qu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mannor_S/0/1/0/all/0/1&quot;&gt;Shie Mannor&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_H/0/1/0/all/0/1&quot;&gt;Huan Xu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07733">
<title>Learning Attentional Communication for Multi-Agent Cooperation. (arXiv:1805.07733v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1805.07733</link>
<description rdf:parseType="Literal">&lt;p&gt;Communication could potentially be an effective way for multi-agent
cooperation. However, information sharing among all agents or in predefined
communication architectures that existing methods adopt can be problematic.
When there is a large number of agents, agents hardly differentiate valuable
information that helps cooperative decision making from globally shared
information. Therefore, communication barely help, and could even impair the
learning of multi-agent cooperation. Predefined communication architectures, on
the other hand, restrict communication among agents and thus restrain potential
cooperation. To tackle these difficulties, in this paper, we propose an
attentional communication model that learns when communication is needed and
how to integrates shared information for cooperative decision making. Our model
leads to efficient and effective communication for large-scale multi-agent
cooperation. Empirically, we show the strength of our model in various
cooperative scenarios, where agents are able to develop more coordinated and
sophisticated strategies than existing methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_J/0/1/0/all/0/1&quot;&gt;Jiechuan Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_Z/0/1/0/all/0/1&quot;&gt;Zongqing Lu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07780">
<title>Unsupervised Video Object Segmentation for Deep Reinforcement Learning. (arXiv:1805.07780v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1805.07780</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a new technique for deep reinforcement learning that automatically
detects moving objects and uses the relevant information for action selection.
The detection of moving objects is done in an unsupervised way by exploiting
structure from motion. Instead of directly learning a policy from raw images,
the agent first learns to detect and segment moving objects by exploiting flow
information in video sequences. The learned representation is then used to
focus the policy of the agent on the moving objects. Over time, the agent
identifies which objects are critical for decision making and gradually builds
a policy based on relevant moving objects. This approach, which we call
Motion-Oriented REinforcement Learning (MOREL), is demonstrated on a suite of
Atari games where the ability to detect moving objects reduces the amount of
interaction needed with the environment to obtain a good policy. Furthermore,
the resulting policy is more interpretable than policies that directly map
images to actions or values with a black box neural network. We can gain
insight into the policy by inspecting the segmentation and motion of each
object detected by the agent. This allows practitioners to confirm whether a
policy is making decisions based on sensible information.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goel_V/0/1/0/all/0/1&quot;&gt;Vik Goel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Weng_J/0/1/0/all/0/1&quot;&gt;Jameson Weng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Poupart_P/0/1/0/all/0/1&quot;&gt;Pascal Poupart&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07805">
<title>Safe Policy Learning from Observations. (arXiv:1805.07805v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.07805</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we consider the problem of learning a policy by observing
numerous non-expert agents. Our goal is to extract a policy that, with
high-confidence, acts better than the average agents&apos; performance. Such a
setting is important for real-world problems where expert data is scarce but
non-expert data can easily be obtained, e.g. by crowdsourcing. Our approach is
to pose this problem as safe policy improvement in Reinforcement Learning.
First, we evaluate an average behavior policy and approximate its value
function. Then, we develop a stochastic policy improvement algorithm, termed
Rerouted Behavior Improvement (RBI), that safely improves the average behavior.
The primary advantages of RBI over current safe learning methods are its
stability in the presence of value estimation errors and the elimination of a
policy search process. We demonstrate these advantages in a Taxi grid-world
domain and in four games from the Atari learning environment.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sarafian_E/0/1/0/all/0/1&quot;&gt;Elad Sarafian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tamar_A/0/1/0/all/0/1&quot;&gt;Aviv Tamar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kraus_S/0/1/0/all/0/1&quot;&gt;Sarit Kraus&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07830">
<title>Learning to Teach in Cooperative Multiagent Reinforcement Learning. (arXiv:1805.07830v1 [cs.MA])</title>
<link>http://arxiv.org/abs/1805.07830</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a framework and algorithm for peer-to-peer teaching in cooperative
multiagent reinforcement learning. Our algorithm, Learning to Coordinate and
Teach Reinforcement (LeCTR), trains advising policies by using students&apos;
learning progress as a teaching reward. Agents using LeCTR learn to assume the
role of a teacher or student at the appropriate moments, exchanging action
advice to accelerate the entire learning process. Our algorithm supports
teaching heterogeneous teammates, advising under communication constraints, and
learns both what and when to advise. LeCTR is demonstrated to outperform the
final performance and rate of learning of prior teaching methods on multiple
benchmark domains. To our knowledge, this is the first approach for learning to
teach in a multiagent setting.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Omidshafiei_S/0/1/0/all/0/1&quot;&gt;Shayegan Omidshafiei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_D/0/1/0/all/0/1&quot;&gt;Dong-Ki Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_M/0/1/0/all/0/1&quot;&gt;Miao Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tesauro_G/0/1/0/all/0/1&quot;&gt;Gerald Tesauro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Riemer_M/0/1/0/all/0/1&quot;&gt;Matthew Riemer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Amato_C/0/1/0/all/0/1&quot;&gt;Christopher Amato&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Campbell_M/0/1/0/all/0/1&quot;&gt;Murray Campbell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+How_J/0/1/0/all/0/1&quot;&gt;Jonathan P. How&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07871">
<title>A Framework and Method for Online Inverse Reinforcement Learning. (arXiv:1805.07871v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.07871</link>
<description rdf:parseType="Literal">&lt;p&gt;Inverse reinforcement learning (IRL) is the problem of learning the
preferences of an agent from the observations of its behavior on a task. While
this problem has been well investigated, the related problem of {\em online}
IRL---where the observations are incrementally accrued, yet the demands of the
application often prohibit a full rerun of an IRL method---has received
relatively less attention. We introduce the first formal framework for online
IRL, called incremental IRL (I2RL), and a new method that advances maximum
entropy IRL with hidden variables, to this setting. Our formal analysis shows
that the new method has a monotonically improving performance with more
demonstration data, as well as probabilistically bounded error, both under full
and partial observability. Experiments in a simulated robotic application of
penetrating a continuous patrol under occlusion shows the relatively improved
performance and speed up of the new method and validates the utility of online
IRL.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Arora_S/0/1/0/all/0/1&quot;&gt;Saurabh Arora&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Doshi_P/0/1/0/all/0/1&quot;&gt;Prashant Doshi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Banerjee_B/0/1/0/all/0/1&quot;&gt;Bikramjit Banerjee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07874">
<title>GSAE: an autoencoder with embedded gene-set nodes for genomics functional characterization. (arXiv:1805.07874v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.07874</link>
<description rdf:parseType="Literal">&lt;p&gt;Bioinformatics tools have been developed to interpret gene expression data at
the gene set level, and these gene set based analyses improve the biologists&apos;
capability to discover functional relevance of their experiment design. While
elucidating gene set individually, inter gene sets association is rarely taken
into consideration. Deep learning, an emerging machine learning technique in
computational biology, can be used to generate an unbiased combination of gene
set, and to determine the biological relevance and analysis consistency of
these combining gene sets by leveraging large genomic data sets. In this study,
we proposed a gene superset autoencoder (GSAE), a multi-layer autoencoder model
with the incorporation of a priori defined gene sets that retain the crucial
biological features in the latent layer. We introduced the concept of the gene
superset, an unbiased combination of gene sets with weights trained by the
autoencoder, where each node in the latent layer is a superset. Trained with
genomic data from TCGA and evaluated with their accompanying clinical
parameters, we showed gene supersets&apos; ability of discriminating tumor subtypes
and their prognostic capability. We further demonstrated the biological
relevance of the top component gene sets in the significant supersets. Using
autoencoder model and gene superset at its latent layer, we demonstrated that
gene supersets retain sufficient biological information with respect to tumor
subtypes and clinical prognostic significance. Superset also provides high
reproducibility on survival analysis and accurate prediction for cancer
subtypes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chen_H/0/1/0/all/0/1&quot;&gt;Hung-I Harry Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chiu_Y/0/1/0/all/0/1&quot;&gt;Yu-Chiao Chiu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhang_T/0/1/0/all/0/1&quot;&gt;Tinghe Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhang_S/0/1/0/all/0/1&quot;&gt;Songyao Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Huang_Y/0/1/0/all/0/1&quot;&gt;Yufei Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yidong Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07932">
<title>Bilinear Attention Networks. (arXiv:1805.07932v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1805.07932</link>
<description rdf:parseType="Literal">&lt;p&gt;Attention networks in multimodal learning provide an efficient way to utilize
given visual information selectively. However, the computational cost to learn
attention distributions for every pair of multimodal input channels is
prohibitively expensive. To solve this problem, co-attention builds two
separate attention distributions for each modality neglecting the interaction
between multimodal inputs. In this paper, we propose bilinear attention
networks (BAN) that find bilinear attention distributions to utilize given
vision-language information seamlessly. BAN considers bilinear interactions
among two groups of input channels, while low-rank bilinear pooling extracts
the joint representations for each pair of channels. Furthermore, we propose a
variant of multimodal residual networks to exploit eight-attention maps of the
BAN efficiently. We quantitatively and qualitatively evaluate our model on
visual question answering (VQA 2.0) and Flickr30k Entities datasets, showing
that BAN significantly outperforms previous methods and achieves new
state-of-the-arts on both datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_J/0/1/0/all/0/1&quot;&gt;Jin-Hwa Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jun_J/0/1/0/all/0/1&quot;&gt;Jaehyun Jun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_B/0/1/0/all/0/1&quot;&gt;Byoung-Tak Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07935">
<title>DEEPEYE: A Compact and Accurate Video Comprehension at Terminal Devices Compressed with Quantization and Tensorization. (arXiv:1805.07935v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1805.07935</link>
<description rdf:parseType="Literal">&lt;p&gt;As it requires a huge number of parameters when exposed to high dimensional
inputs in video detection and classification, there is a grand challenge to
develop a compact yet accurate video comprehension at terminal devices. Current
works focus on optimizations of video detection and classification in a
separated fashion. In this paper, we introduce a video comprehension (object
detection and action recognition) system for terminal devices, namely DEEPEYE.
Based on You Only Look Once (YOLO), we have developed an 8-bit quantization
method when training YOLO; and also developed a tensorized-compression method
of Recurrent Neural Network (RNN) composed of features extracted from YOLO. The
developed quantization and tensorization can significantly compress the
original network model yet with maintained accuracy. Using the challenging
video datasets: MOMENTS and UCF11 as benchmarks, the results show that the
proposed DEEPEYE achieves 3.994x model compression rate with only 0.47% mAP
decreased; and 15,047x parameter reduction and 2.87x speed-up with 16.58%
accuracy improvement.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1&quot;&gt;Yuan Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1&quot;&gt;Guangya Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1&quot;&gt;Hai-Bao Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tan_S/0/1/0/all/0/1&quot;&gt;Sheldon X.-D. Tan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1&quot;&gt;Hao Yu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07956">
<title>Multiple-Step Greedy Policies in Online and Approximate Reinforcement Learning. (arXiv:1805.07956v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.07956</link>
<description rdf:parseType="Literal">&lt;p&gt;Multiple-step lookahead policies have demonstrated high empirical competence
in Reinforcement Learning, via the use of Monte Carlo Tree Search or Model
Predictive Control. In a recent work \cite{efroni2018beyond}, multiple-step
greedy policies and their use in vanilla Policy Iteration algorithms were
proposed and analyzed. In this work, we study multiple-step greedy algorithms
in more practical setups. We begin by highlighting a counter-intuitive
difficulty, arising with soft-policy updates: even in the absence of
approximations, and contrary to the 1-step-greedy case, monotonic policy
improvement is not guaranteed unless the update stepsize is sufficiently large.
Taking particular care about this difficulty, we formulate and analyze online
and approximate algorithms that use such a multi-step greedy operator.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Efroni_Y/0/1/0/all/0/1&quot;&gt;Yonathan Efroni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dalal_G/0/1/0/all/0/1&quot;&gt;Gal Dalal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Scherrer_B/0/1/0/all/0/1&quot;&gt;Bruno Scherrer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mannor_S/0/1/0/all/0/1&quot;&gt;Shie Mannor&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1702.08887">
<title>Stabilising Experience Replay for Deep Multi-Agent Reinforcement Learning. (arXiv:1702.08887v3 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1702.08887</link>
<description rdf:parseType="Literal">&lt;p&gt;Many real-world problems, such as network packet routing and urban traffic
control, are naturally modeled as multi-agent reinforcement learning (RL)
problems. However, existing multi-agent RL methods typically scale poorly in
the problem size. Therefore, a key challenge is to translate the success of
deep learning on single-agent RL to the multi-agent setting. A major stumbling
block is that independent Q-learning, the most popular multi-agent RL method,
introduces nonstationarity that makes it incompatible with the experience
replay memory on which deep Q-learning relies. This paper proposes two methods
that address this problem: 1) using a multi-agent variant of importance
sampling to naturally decay obsolete data and 2) conditioning each agent&apos;s
value function on a fingerprint that disambiguates the age of the data sampled
from the replay memory. Results on a challenging decentralised variant of
StarCraft unit micromanagement confirm that these methods enable the successful
combination of experience replay with multi-agent RL.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Foerster_J/0/1/0/all/0/1&quot;&gt;Jakob Foerster&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nardelli_N/0/1/0/all/0/1&quot;&gt;Nantas Nardelli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Farquhar_G/0/1/0/all/0/1&quot;&gt;Gregory Farquhar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Afouras_T/0/1/0/all/0/1&quot;&gt;Triantafyllos Afouras&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Torr_P/0/1/0/all/0/1&quot;&gt;Philip H. S. Torr&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kohli_P/0/1/0/all/0/1&quot;&gt;Pushmeet Kohli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Whiteson_S/0/1/0/all/0/1&quot;&gt;Shimon Whiteson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1705.09026">
<title>Best-Choice Edge Grafting for Efficient Structure Learning of Markov Random Fields. (arXiv:1705.09026v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1705.09026</link>
<description rdf:parseType="Literal">&lt;p&gt;Incremental methods for structure learning of pairwise Markov random fields
(MRFs), such as grafting, improve scalability by avoiding inference over the
entire feature space in each optimization step. Instead, inference is performed
over an incrementally grown active set of features. In this paper, we address
key computational bottlenecks that current incremental techniques still suffer
by introducing best-choice edge grafting, an incremental, structured method
that activates edges as groups of features in a streaming setting. The method
uses a reservoir of edges that satisfy an activation condition, approximating
the search for the optimal edge to activate. It also reorganizes the search
space using search-history and structure heuristics. Experiments show a
significant speedup for structure learning and a controllable trade-off between
the speed and quality of learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chaabene_W/0/1/0/all/0/1&quot;&gt;Walid Chaabene&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_B/0/1/0/all/0/1&quot;&gt;Bert Huang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1707.08234">
<title>Closed-Loop Policies for Operational Tests of Safety-Critical Systems. (arXiv:1707.08234v3 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1707.08234</link>
<description rdf:parseType="Literal">&lt;p&gt;Manufacturers of safety-critical systems must make the case that their
product is sufficiently safe for public deployment. Much of this case often
relies upon critical event outcomes from real-world testing, requiring
manufacturers to be strategic about how they allocate testing resources in
order to maximize their chances of demonstrating system safety. This work
frames the partially observable and belief-dependent problem of test scheduling
as a Markov decision process, which can be solved efficiently to yield
closed-loop manufacturer testing policies. By solving for policies over a wide
range of problem formulations, we are able to provide high-level guidance for
manufacturers and regulators on issues relating to the testing of
safety-critical systems. This guidance spans an array of topics, including
circumstances under which manufacturers should continue testing despite
observed incidents, when manufacturers should test aggressively, and when
regulators should increase or reduce the real-world testing requirements for an
autonomous vehicle.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Morton_J/0/1/0/all/0/1&quot;&gt;Jeremy Morton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wheeler_T/0/1/0/all/0/1&quot;&gt;Tim A. Wheeler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kochenderfer_M/0/1/0/all/0/1&quot;&gt;Mykel J. Kochenderfer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.10082">
<title>Towards Optimally Decentralized Multi-Robot Collision Avoidance via Deep Reinforcement Learning. (arXiv:1709.10082v3 [cs.RO] UPDATED)</title>
<link>http://arxiv.org/abs/1709.10082</link>
<description rdf:parseType="Literal">&lt;p&gt;Developing a safe and efficient collision avoidance policy for multiple
robots is challenging in the decentralized scenarios where each robot generate
its paths without observing other robots&apos; states and intents. While other
distributed multi-robot collision avoidance systems exist, they often require
extracting agent-level features to plan a local collision-free action, which
can be computationally prohibitive and not robust. More importantly, in
practice the performance of these methods are much lower than their centralized
counterparts.
&lt;/p&gt;
&lt;p&gt;We present a decentralized sensor-level collision avoidance policy for
multi-robot systems, which directly maps raw sensor measurements to an agent&apos;s
steering commands in terms of movement velocity. As a first step toward
reducing the performance gap between decentralized and centralized methods, we
present a multi-scenario multi-stage training framework to find an optimal
policy which is trained over a large number of robots on rich, complex
environments simultaneously using a policy gradient based reinforcement
learning algorithm. We validate the learned sensor-level collision avoidance
policy in a variety of simulated scenarios with thorough performance
evaluations and show that the final learned policy is able to find time
efficient, collision-free paths for a large-scale robot system. We also
demonstrate that the learned policy can be well generalized to new scenarios
that do not appear in the entire training period, including navigating a
heterogeneous group of robots and a large-scale scenario with 100 robots.
Videos are available at https://sites.google.com/view/drlmaca
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Long_P/0/1/0/all/0/1&quot;&gt;Pinxin Long&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fan_T/0/1/0/all/0/1&quot;&gt;Tingxiang Fan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liao_X/0/1/0/all/0/1&quot;&gt;Xinyi Liao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1&quot;&gt;Wenxi Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_H/0/1/0/all/0/1&quot;&gt;Hao Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pan_J/0/1/0/all/0/1&quot;&gt;Jia Pan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.11311">
<title>Deep Forward and Inverse Perceptual Models for Tracking and Prediction. (arXiv:1710.11311v2 [cs.RO] UPDATED)</title>
<link>http://arxiv.org/abs/1710.11311</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the problems of learning forward models that map state to
high-dimensional images and inverse models that map high-dimensional images to
state in robotics. Specifically, we present a perceptual model for generating
video frames from state with deep networks, and provide a framework for its use
in tracking and prediction tasks. We show that our proposed model greatly
outperforms standard deconvolutional methods and GANs for image generation,
producing clear, photo-realistic images. We also develop a convolutional neural
network model for state estimation and compare the result to an Extended Kalman
Filter to estimate robot trajectories. We validate all models on a real robotic
system.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lambert_A/0/1/0/all/0/1&quot;&gt;Alexander Lambert&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shaban_A/0/1/0/all/0/1&quot;&gt;Amirreza Shaban&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Raj_A/0/1/0/all/0/1&quot;&gt;Amit Raj&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1&quot;&gt;Zhen Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Boots_B/0/1/0/all/0/1&quot;&gt;Byron Boots&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.00129">
<title>Automata-Guided Hierarchical Reinforcement Learning for Skill Composition. (arXiv:1711.00129v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1711.00129</link>
<description rdf:parseType="Literal">&lt;p&gt;Skills learned through (deep) reinforcement learning often generalizes poorly
across domains and re-training is necessary when presented with a new task. We
present a framework that combines techniques in \textit{formal methods} with
\textit{reinforcement learning} (RL). The methods we provide allows for
convenient specification of tasks with logical expressions, learns hierarchical
policies (meta-controller and low-level controllers) with well-defined
intrinsic rewards, and construct new skills from existing ones with little to
no additional exploration. We evaluate the proposed methods in a simple grid
world simulation as well as a more complicated kitchen environment in AI2Thor
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xiao Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1&quot;&gt;Yao Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Belta_C/0/1/0/all/0/1&quot;&gt;Calin Belta&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04007">
<title>ProofWatch: Watchlist Guidance for Large Theories in E. (arXiv:1802.04007v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1802.04007</link>
<description rdf:parseType="Literal">&lt;p&gt;Watchlist (also hint list) is a mechanism that allows related proofs to guide
a proof search for a new conjecture. This mechanism has been used with the
Otter and Prover9 theorem provers, both for interactive formalizations and for
human-assisted proving of open conjectures in small theories. In this work we
explore the use of watchlists in large theories coming from first-order
translations of large ITP libraries, aiming at improving hammer-style
automation by smarter internal guidance of the ATP systems. In particular, we
(i) design watchlist-based clause evaluation heuristics inside the E ATP
system, and (ii) develop new proof guiding algorithms that load many previous
proofs inside the ATP and focus the proof search using a dynamically updated
notion of proof matching. The methods are evaluated on a large set of problems
coming from the Mizar library, showing significant improvement of E&apos;s standard
portfolio of strategies, and also of the previous best set of strategies
invented for Mizar by evolutionary methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goertzel_Z/0/1/0/all/0/1&quot;&gt;Zarathustra Goertzel&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jakub%5Cr%7Bu%7Dv_J/0/1/0/all/0/1&quot;&gt;Jan Jakub&amp;#x16f;v&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schulz_S/0/1/0/all/0/1&quot;&gt;Stephan Schulz&lt;/a&gt; (2), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Urban_J/0/1/0/all/0/1&quot;&gt;Josef Urban&lt;/a&gt; (1) ((1) Czech Technical University in Prague, (2) DHBW Stuttgart)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04592">
<title>Rebalancing Dockless Bike Sharing Systems. (arXiv:1802.04592v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1802.04592</link>
<description rdf:parseType="Literal">&lt;p&gt;Bike sharing provides an environment-friendly way for traveling and is
booming worldwide. Yet, due to the high similarity of user travel patterns, the
bike imbalance problem constantly occurs, especially for dockless bike sharing
systems, causing significant impact on service quality and company revenue.
Thus, it has become a critical task for bike sharing systems to resolve such
imbalance efficiently. In this paper, we propose a novel deep reinforcement
learning framework for incentivizing users to rebalance such sys- tems. We
model this problem as a Markov decision process and take both spatial and
temporal features into consideration. We develop a novel deep reinforcement
learning algorithm called Hierarchical Reinforcement Pricing (HRP), which
builds upon the Deep Deterministic Policy Gradient algorithm. Different from
existing methods that often ignore spatial information and rely heavily on
accurate prediction, HRP can capture both spatial and temporal dependencies
using a divide-and-conquer structure with an embedded localized module. We
conduct extensive experiments to evaluate HRP, based on a dataset from Mobike,
a major Chinese dockless bike sharing company. Results show that HRP performs
close to the 24-timeslot look-ahead optimization, and outperforms
state-of-the-art methods in both service level and bike distribution. It also
transfers well when applied to unseen areas.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pan_L/0/1/0/all/0/1&quot;&gt;Ling Pan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cai_Q/0/1/0/all/0/1&quot;&gt;Qingpeng Cai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fang_Z/0/1/0/all/0/1&quot;&gt;Zhixuan Fang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_P/0/1/0/all/0/1&quot;&gt;Pingzhong Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_L/0/1/0/all/0/1&quot;&gt;Longbo Huang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04799">
<title>TVM: An Automated End-to-End Optimizing Compiler for Deep Learning. (arXiv:1802.04799v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1802.04799</link>
<description rdf:parseType="Literal">&lt;p&gt;There is an increasing need to bring machine learning to a wide diversity of
hardware devices. Current frameworks rely on vendor-specific operator libraries
and optimize for a narrow range of server-class GPUs. Deploying workloads to
new platforms such as mobile phones, embedded devices, and accelerators (e.g.,
FPGAs, ASICs) requires significant manual effort. We propose TVM, a compiler
that exposes graph-level and operator-level optimizations to provide
performance portability to deep learning workloads across diverse hardware
back-ends. TVM solves optimization challenges specific to deep learning such as
high-level operator fusion, mapping to arbitrary hardware primitives, and
memory latency hiding. TVM also offers automated optimization of low-level
programs to hardware characteristics by employing a novel learning-based cost
modeling method for rapid exploration of code optimizations. Experimental
results demonstrate that TVM delivers performance across hardware back-ends
that are competitive with state-of-the-art hand-tuned libraries for low-power
CPU, mobile GPU, and server-class GPUs. We also demonstrate TVM&apos;s ability to
target new accelerator back-ends by targeting an FPGA-based generic deep
learning accelerator. The system is open sourced and in production use inside
several major companies.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1&quot;&gt;Tianqi Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moreau_T/0/1/0/all/0/1&quot;&gt;Thierry Moreau&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_Z/0/1/0/all/0/1&quot;&gt;Ziheng Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_L/0/1/0/all/0/1&quot;&gt;Lianmin Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yan_E/0/1/0/all/0/1&quot;&gt;Eddie Yan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cowan_M/0/1/0/all/0/1&quot;&gt;Meghan Cowan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_H/0/1/0/all/0/1&quot;&gt;Haichen Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1&quot;&gt;Leyuan Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1&quot;&gt;Yuwei Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ceze_L/0/1/0/all/0/1&quot;&gt;Luis Ceze&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guestrin_C/0/1/0/all/0/1&quot;&gt;Carlos Guestrin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Krishnamurthy_A/0/1/0/all/0/1&quot;&gt;Arvind Krishnamurthy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.09010">
<title>Datasheets for Datasets. (arXiv:1803.09010v2 [cs.DB] UPDATED)</title>
<link>http://arxiv.org/abs/1803.09010</link>
<description rdf:parseType="Literal">&lt;p&gt;Currently there is no standard way to identify how a dataset was created, and
what characteristics, motivations, and potential skews it represents. To begin
to address this issue, we propose the concept of a datasheet for datasets, a
short document to accompany public datasets, commercial APIs, and pretrained
models. The goal of this proposal is to enable better communication between
dataset creators and users, and help the AI community move toward greater
transparency and accountability. By analogy, in computer hardware, it has
become industry standard to accompany everything from the simplest components
(e.g., resistors), to the most complex microprocessor chips, with datasheets
detailing standard operating characteristics, test results, recommended usage,
and other information. We outline some of the questions a datasheet for
datasets should answer. These questions focus on when, where, and how the
training data was gathered, its recommended use cases, and, in the case of
human-centric datasets, information regarding the subjects&apos; demographics and
consent as applicable. We develop prototypes of datasheets for two well-known
datasets: Labeled Faces in The Wild~\cite{lfw} and the Pang \&amp;amp; Lee Polarity
Dataset~\cite{polarity}.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gebru_T/0/1/0/all/0/1&quot;&gt;Timnit Gebru&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Morgenstern_J/0/1/0/all/0/1&quot;&gt;Jamie Morgenstern&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vecchione_B/0/1/0/all/0/1&quot;&gt;Briana Vecchione&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vaughan_J/0/1/0/all/0/1&quot;&gt;Jennifer Wortman Vaughan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wallach_H/0/1/0/all/0/1&quot;&gt;Hanna Wallach&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Daumee_H/0/1/0/all/0/1&quot;&gt;Hal Daume&amp;#xe9; III&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Crawford_K/0/1/0/all/0/1&quot;&gt;Kate Crawford&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.00846">
<title>Learning to Search via Retrospective Imitation. (arXiv:1804.00846v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1804.00846</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the problem of learning a good search policy from demonstrations for
combinatorial search spaces. We propose retrospective imitation learning,
which, after initial training by an expert, improves itself by learning from
its own retrospective solutions. That is, when the policy eventually reaches a
feasible solution in a search tree after making mistakes and backtracks, it
retrospectively constructs an improved search trace to the solution by removing
backtracks, which is then used to further train the policy. A key feature of
our approach is that it can iteratively scale up, or transfer, to larger
problem sizes than the initial expert demonstrations. We showcase the
effectiveness of our approach on a synthetic maze solving task and the problem
of risk-aware path planning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_J/0/1/0/all/0/1&quot;&gt;Jialin Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lanka_R/0/1/0/all/0/1&quot;&gt;Ravi Lanka&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_A/0/1/0/all/0/1&quot;&gt;Albert Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yue_Y/0/1/0/all/0/1&quot;&gt;Yisong Yue&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ono_M/0/1/0/all/0/1&quot;&gt;Masahiro Ono&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.01486">
<title>Clinical Concept Embeddings Learned from Massive Sources of Multimodal Medical Data. (arXiv:1804.01486v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1804.01486</link>
<description rdf:parseType="Literal">&lt;p&gt;Word embeddings are a popular approach to unsupervised learning of word
relationships that are widely used in natural language processing. In this
article, we present a new set of embeddings for medical concepts learned using
an extremely large collection of multimodal medical data. Leaning on recent
theoretical insights, we demonstrate how an insurance claims database of 60
million members, a collection of 20 million clinical notes, and 1.7 million
full text biomedical journal articles can be combined to embed concepts into a
common space, resulting in the largest ever set of embeddings for 108,477
medical concepts. To evaluate our approach, we present a new benchmark
methodology based on statistical power specifically designed to test embeddings
of medical concepts. Our approach, called cui2vec, attains state of the art
performance relative to previous methods in most instances. Finally, we provide
a downloadable set of pre-trained embeddings for other researchers to use, as
well as an online tool for interactive exploration of the cui2vec embeddings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Beam_A/0/1/0/all/0/1&quot;&gt;Andrew L. Beam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kompa_B/0/1/0/all/0/1&quot;&gt;Benjamin Kompa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fried_I/0/1/0/all/0/1&quot;&gt;Inbar Fried&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Palmer_N/0/1/0/all/0/1&quot;&gt;Nathan P. Palmer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shi_X/0/1/0/all/0/1&quot;&gt;Xu Shi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cai_T/0/1/0/all/0/1&quot;&gt;Tianxi Cai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kohane_I/0/1/0/all/0/1&quot;&gt;Isaac S. Kohane&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.10969">
<title>UNIQ: Uniform Noise Injection for non-uniform Quantization of neural networks. (arXiv:1804.10969v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1804.10969</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a novel method for training a neural network amenable to inference
in low-precision arithmetic with quantized weights and activations. The
training is performed in full precision with random noise injection emulating
quantization noise. In order to circumvent the need to simulate realistic
quantization noise distributions, the weight distributions are uniformized by a
non-linear transformation, and uniform noise is injected. This procedure
emulates a non-uniform k-quantile quantizer at inference time, which adapts to
the specific distribution of the quantized parameters. As a by-product of
injecting noise to weights, we find that activations can also be quantized to
as low as 8-bit with only a minor accuracy degradation. The method achieves
state-of-the-art results for training low-precision networks on ImageNet. In
particular, we observe no degradation in accuracy for MobileNet and
ResNet-18/34/50 on ImageNet with as low as 4-bit quantization of weights. Our
solution achieves the state-of-the-art results in accuracy, in the low
computational budget regime, compared to similar models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Baskin_C/0/1/0/all/0/1&quot;&gt;Chaim Baskin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schwartz_E/0/1/0/all/0/1&quot;&gt;Eli Schwartz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheltonozhskii_E/0/1/0/all/0/1&quot;&gt;Evgenii Zheltonozhskii&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liss_N/0/1/0/all/0/1&quot;&gt;Natan Liss&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Giryes_R/0/1/0/all/0/1&quot;&gt;Raja Giryes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bronstein_A/0/1/0/all/0/1&quot;&gt;Alex M. Bronstein&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mendelson_A/0/1/0/all/0/1&quot;&gt;Avi Mendelson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.00909">
<title>Reinforcement Learning and Control as Probabilistic Inference: Tutorial and Review. (arXiv:1805.00909v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.00909</link>
<description rdf:parseType="Literal">&lt;p&gt;The framework of reinforcement learning or optimal control provides a
mathematical formalization of intelligent decision making that is powerful and
broadly applicable. While the general form of the reinforcement learning
problem enables effective reasoning about uncertainty, the connection between
reinforcement learning and inference in probabilistic models is not immediately
obvious. However, such a connection has considerable value when it comes to
algorithm design: formalizing a problem as probabilistic inference in principle
allows us to bring to bear a wide array of approximate inference tools, extend
the model in flexible and powerful ways, and reason about compositionality and
partial observability. In this article, we will discuss how a generalization of
the reinforcement learning or optimal control problem, which is sometimes
termed maximum entropy reinforcement learning, is equivalent to exact
probabilistic inference in the case of deterministic dynamics, and variational
inference in the case of stochastic dynamics. We will present a detailed
derivation of this framework, overview prior work that has drawn on this and
related ideas to propose new reinforcement learning and control algorithms, and
describe perspectives on future research.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1&quot;&gt;Sergey Levine&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.05250">
<title>Blockchain to Improve Security and Knowledge in Inter-Agent Communication and Collaboration over Restrict Domains of the Internet Infrastructure. (arXiv:1805.05250v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1805.05250</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper describes the deployment and implementation of a blockchain to
improve the security, knowledge and intelligence during the inter-agent
communication and collaboration processes in restrict domains of the Internet
Infrastructure. It is a work that proposes the application of a blockchain,
platform independent, on a particular model of agents, but that can be used in
similar proposals, once the results on the specific model were satisfactory.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Braga_J/0/1/0/all/0/1&quot;&gt;Juliao Braga&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Silva_J/0/1/0/all/0/1&quot;&gt;Joao Nuno Silva&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Endo_P/0/1/0/all/0/1&quot;&gt;Patricia Takako Endo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ribas_J/0/1/0/all/0/1&quot;&gt;Jessica Ribas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Omar_N/0/1/0/all/0/1&quot;&gt;Nizam Omar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07376">
<title>Modeling trend in temperature volatility using generalized LASSO. (arXiv:1805.07376v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.07376</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we present methodology for estimating trends in
spatio-temporal volatility. We give two algorithms for computing our estimator
which are tailored for dense, gridded observations over both space and time,
though these can be easily extended to other structures (time-varying network
flows, neuroimaging). We motivate our methodology by applying it to a massive
climate dataset and discuss the implications for climate analysis.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Khodadadi_A/0/1/0/all/0/1&quot;&gt;Arash Khodadadi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+McDonald_D/0/1/0/all/0/1&quot;&gt;Daniel J McDonald&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07405">
<title>Processing of missing data by neural networks. (arXiv:1805.07405v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.07405</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a general, theoretically justified mechanism for processing
missing data by neural networks. Our idea is to replace typical neuron response
in the first hidden layer by its expected value. This approach can be applied
for various types of networks at minimal cost in their modification. Moreover,
in contrast to recent approaches, it does not require complete data for
training. Experimental results performed on different types of architectures
show that our method gives better results than typical imputation strategies
and other methods dedicated for incomplete data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Smieja_M/0/1/0/all/0/1&quot;&gt;Marek Smieja&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Struski_L/0/1/0/all/0/1&quot;&gt;&amp;#x141;ukasz Struski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tabor_J/0/1/0/all/0/1&quot;&gt;Jacek Tabor&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zielinski_B/0/1/0/all/0/1&quot;&gt;Bartosz Zieli&amp;#x144;ski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Spurek_P/0/1/0/all/0/1&quot;&gt;Przemys&amp;#x142;aw Spurek&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07410">
<title>Learning to Collaborate for User-Controlled Privacy. (arXiv:1805.07410v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.07410</link>
<description rdf:parseType="Literal">&lt;p&gt;It is becoming increasingly clear that users should own and control their
data. Utility providers are also becoming more interested in guaranteeing data
privacy. As such, users and utility providers should collaborate in data
privacy, a paradigm that has not yet been developed in the privacy research
community. We introduce this concept and present explicit architectures where
the user controls what characteristics of the data she/he wants to share and
what she/he wants to keep private. This is achieved by collaborative learning a
sensitization function, either a deterministic or a stochastic one, that
retains valuable information for the utility tasks but it also eliminates
necessary information for the privacy ones. As illustration examples, we
implement them using a plug-and-play approach, where no algorithm is changed at
the system provider end, and an adversarial approach, where minor re-training
of the privacy inferring engine is allowed. In both cases the learned
sanitization function keeps the data in the original domain, thereby allowing
the system to use the same algorithms it was using before for both original and
privatized data. We show how we can maintain utility while fully protecting
private information if the user chooses to do so, even when the first is harder
than the second, as in the case here illustrated of identity detection while
hiding gender.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bertran_M/0/1/0/all/0/1&quot;&gt;Martin Bertran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Martinez_N/0/1/0/all/0/1&quot;&gt;Natalia Martinez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Papadaki_A/0/1/0/all/0/1&quot;&gt;Afroditi Papadaki&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Qiu_Q/0/1/0/all/0/1&quot;&gt;Qiang Qiu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rodrigues_M/0/1/0/all/0/1&quot;&gt;Miguel Rodrigues&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sapiro_G/0/1/0/all/0/1&quot;&gt;Guillermo Sapiro&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07412">
<title>Wasserstein Coresets for Lipschitz Costs. (arXiv:1805.07412v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.07412</link>
<description rdf:parseType="Literal">&lt;p&gt;Sparsification is becoming more and more relevant with the proliferation of
huge data sets. Coresets are a principled way to construct representative
weighted subsets of a data set that have matching performance with the full
data set for specific problems. However, coreset language neglects the nature
of the underlying data distribution, which is often continuous. In this paper,
we address this oversight by introducing a notion of measure coresets that
generalizes coreset language to arbitrary probability measures. Our definition
reveals a surprising connection to optimal transport theory which we leverage
to design a coreset for problems with Lipschitz costs. We validate our
construction on support vector machine (SVM) training, k-means clustering,
k-median clustering, and linear regression and show that we are competitive
with previous coreset constructions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Claici_S/0/1/0/all/0/1&quot;&gt;Sebastian Claici&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Solomon_J/0/1/0/all/0/1&quot;&gt;Justin Solomon&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07416">
<title>Computing Kantorovich-Wasserstein Distances on $d$-dimensional histograms using $(d+1)$-partite graphs. (arXiv:1805.07416v1 [math.OC])</title>
<link>http://arxiv.org/abs/1805.07416</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents a novel method to compute the exact
Kantorovich-Wasserstein distance between a pair of $d$-dimensional histograms
having $n$ bins each. We prove that this problem is equivalent to an
uncapacitated minimum cost flow problem on a $(d+1)$-partite graph with
$(d+1)n$ nodes and $dn^{\frac{d+1}{d}}$ arcs, whenever the cost is separable
along the principal $d$-dimensional directions. We show numerically the
benefits of our approach by computing the Kantorovich-Wasserstein distance of
order 2 among two sets of instances: gray scale images and $d$-dimensional
biomedical histograms. On these types of instances, our approach is competitive
with state-of-the-art optimal transport algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Auricchio_G/0/1/0/all/0/1&quot;&gt;Gennaro Auricchio&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Bassetti_F/0/1/0/all/0/1&quot;&gt;Federico Bassetti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Gualandi_S/0/1/0/all/0/1&quot;&gt;Stefano Gualandi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Veneroni_M/0/1/0/all/0/1&quot;&gt;Marco Veneroni&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07430">
<title>Efficient Online Portfolio with Logarithmic Regret. (arXiv:1805.07430v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.07430</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the decades-old problem of online portfolio management and propose
the first algorithm with logarithmic regret that is not based on Cover&apos;s
Universal Portfolio algorithm and admits much faster implementation.
Specifically Universal Portfolio enjoys optimal regret $\mathcal{O}(N\ln T)$
for $N$ financial instruments over $T$ rounds, but requires log-concave
sampling and has a large polynomial running time. Our algorithm, on the other
hand, ensures a slightly larger but still logarithmic regret of
$\mathcal{O}(N^2(\ln T)^4)$, and is based on the well-studied Online Mirror
Descent framework with a novel regularizer that can be implemented via standard
optimization methods in time $\mathcal{O}(TN^{2.5})$ per round. The regret of
all other existing works is either polynomial in $T$ or has a potentially
unbounded factor such as the inverse of the smallest price relative.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_H/0/1/0/all/0/1&quot;&gt;Haipeng Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wei_C/0/1/0/all/0/1&quot;&gt;Chen-Yu Wei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_K/0/1/0/all/0/1&quot;&gt;Kai Zheng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07438">
<title>Region-Based Classification of PolSAR Data Using Radial Basis Kernel Functions With Stochastic Distances. (arXiv:1805.07438v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.07438</link>
<description rdf:parseType="Literal">&lt;p&gt;Region-based classification of PolSAR data can be effectively performed by
seeking for the assignment that minimizes a distance between prototypes and
segments. Silva et al (2013) used stochastic distances between complex
multivariate Wishart models which, differently from other measures, are
computationally tractable. In this work we assess the robustness of such
approach with respect to errors in the training stage, and propose an extension
that alleviates such problems. We introduce robustness in the process by
incorporating a combination of radial basis kernel functions and stochastic
distances with Support Vector Machines (SVM). We consider several stochastic
distances between Wishart: Bhatacharyya, Kullback-Leibler, Chi-Square,
R\&apos;{e}nyi, and Hellinger. We perform two case studies with PolSAR images, both
simulated and from actual sensors, and different classification scenarios to
compare the performance of Minimum Distance and SVM classification frameworks.
With this, we model the situation of imperfect training samples. We show that
SVM with the proposed kernel functions achieves better performance with respect
to Minimum Distance, at the expense of more computational resources and the
need of parameter tuning. Code and data are provided for reproducibility.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Negri_R/0/1/0/all/0/1&quot;&gt;R. G. Negri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Frery_A/0/1/0/all/0/1&quot;&gt;A. C. Frery&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Silva_W/0/1/0/all/0/1&quot;&gt;W. B. Silva&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mendes_T/0/1/0/all/0/1&quot;&gt;T. S. G. Mendes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Dutra_L/0/1/0/all/0/1&quot;&gt;L. V. Dutra&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07445">
<title>DVAE#: Discrete Variational Autoencoders with Relaxed Boltzmann Priors. (arXiv:1805.07445v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.07445</link>
<description rdf:parseType="Literal">&lt;p&gt;Boltzmann machines are powerful distributions that have been shown to be an
effective prior over binary latent variables in variational autoencoders
(VAEs). However, previous methods for training discrete VAEs have used the
evidence lower bound and not the tighter importance-weighted bound. We propose
two approaches for relaxing Boltzmann machines to continuous distributions that
permit training with importance-weighted bounds. These relaxations are based on
generalized overlapping transformations and the Gaussian integral trick.
Experiments on the MNIST and OMNIGLOT datasets show that these relaxations
outperform previous discrete VAEs with Boltzmann priors.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Vahdat_A/0/1/0/all/0/1&quot;&gt;Arash Vahdat&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Andriyash_E/0/1/0/all/0/1&quot;&gt;Evgeny Andriyash&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Macready_W/0/1/0/all/0/1&quot;&gt;William G. Macready&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07451">
<title>Butterfly-Net: Optimal Function Representation Based on Convolutional Neural Networks. (arXiv:1805.07451v1 [math.NA])</title>
<link>http://arxiv.org/abs/1805.07451</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep networks, especially Convolutional Neural Networks (CNNs), have been
successfully applied in various areas of machine learning as well as to
challenging problems in other scientific and engineering fields. This paper
introduces Butterfly-Net, a low-complexity CNN with structured hard-coded
weights and sparse across-channel connections, which aims at an optimal
hierarchical function representation of the input signal. Theoretical analysis
of the approximation power of Butterfly-Net to the Fourier representation of
input data shows that the error decays exponentially as the depth increases.
Due to the ability of Butterfly-Net to approximate Fourier and local Fourier
transforms, the result can be used for approximation upper bound for CNNs in a
large class of problems. The analysis results are validated in numerical
experiments on the approximation of a 1D Fourier kernel and of solving a 2D
Poisson&apos;s equation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yingzhou Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Cheng_X/0/1/0/all/0/1&quot;&gt;Xiuyuan Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Lu_J/0/1/0/all/0/1&quot;&gt;Jianfeng Lu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07454">
<title>Model Inference with Stein Density Ratio Estimation. (arXiv:1805.07454v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.07454</link>
<description rdf:parseType="Literal">&lt;p&gt;The Kullback-Leilber divergence from model to data is a classic goodness of
fit measure but can be intractable in many cases. In this paper, we estimate
the ratio function between a data density and a model density with the help of
Stein operator. The estimated density ratio allows us to compute the likelihood
ratio function which is a surrogate to the actual Kullback-Leibler divergence
from model to data. By minimizing this surrogate, we can perform model fitting
and inference from either frequentist or Bayesian point of view. This paper
discusses methods, theories and algorithms for performing such tasks. Our
theoretical claims are verified by experiments and examples are given
demonstrating the usefulness of our methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Liu_S/0/1/0/all/0/1&quot;&gt;Song Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Jitkrittum_W/0/1/0/all/0/1&quot;&gt;Wittawat Jitkrittum&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ek_C/0/1/0/all/0/1&quot;&gt;Carl Henrik Ek&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07458">
<title>PG-TS: Improved Thompson Sampling for Logistic Contextual Bandits. (arXiv:1805.07458v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.07458</link>
<description rdf:parseType="Literal">&lt;p&gt;We address the problem of regret minimization in logistic contextual bandits,
where a learner decides among sequential actions or arms given their respective
contexts to maximize binary rewards. Using a fast inference procedure with
Polya-Gamma distributed augmentation variables, we propose an improved version
of Thompson Sampling, a Bayesian formulation of contextual bandits with
near-optimal performance. Our approach, Polya-Gamma augmented Thompson Sampling
(PG-TS), achieves state-of-the-art performance on simulated and real data.
PG-TS explores the action space efficiently and exploits high-reward arms,
quickly converging to solutions of low regret. Its explicit estimation of the
posterior distribution of the context feature covariance leads to substantial
empirical gains over approximate approaches. PG-TS is the first approach to
demonstrate the benefits of Polya-Gamma augmentation in bandits and to propose
an efficient Gibbs sampler for approximating the analytically unsolvable
integral of logistic contextual bandits.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Dumitrascu_B/0/1/0/all/0/1&quot;&gt;Bianca Dumitrascu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Feng_K/0/1/0/all/0/1&quot;&gt;Karen Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Engelhardt_B/0/1/0/all/0/1&quot;&gt;Barbara E Engelhardt&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07460">
<title>Fast Kernel Approximations for Latent Force Models and Convolved Multiple-Output Gaussian processes. (arXiv:1805.07460v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.07460</link>
<description rdf:parseType="Literal">&lt;p&gt;A latent force model is a Gaussian process with a covariance function
inspired by a differential operator. Such covariance function is obtained by
performing convolution integrals between Green&apos;s functions associated to the
differential operators, and covariance functions associated to latent
functions. In the classical formulation of latent force models, the covariance
functions are obtained analytically by solving a double integral, leading to
expressions that involve numerical solutions of different types of error
functions. In consequence, the covariance matrix calculation is considerably
expensive, because it requires the evaluation of one or more of these error
functions. In this paper, we use random Fourier features to approximate the
solution of these double integrals obtaining simpler analytical expressions for
such covariance functions. We show experimental results using ordinary
differential operators and provide an extension to build general kernel
functions for convolved multiple output Gaussian processes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Guarnizo_C/0/1/0/all/0/1&quot;&gt;Cristian Guarnizo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Alvarez_M/0/1/0/all/0/1&quot;&gt;Mauricio A. &amp;#xc1;lvarez&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07474">
<title>Projection-Free Bandit Convex Optimization. (arXiv:1805.07474v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.07474</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we propose the first computationally efficient projection-free
algorithm for the bandit convex optimization (BCO). We show that our algorithm
achieves a sublinear regret of $ O(nT^{4/5}) $ (where $ T $ is the horizon and
$ n $ is the dimension) for any bounded convex functions with uniformly bounded
gradients. We also evaluate the performance of our algorithm against prior art
on both synthetic and real data sets for portfolio selection and multiclass
classification problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chen_L/0/1/0/all/0/1&quot;&gt;Lin Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhang_M/0/1/0/all/0/1&quot;&gt;Mingrui Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Karbasi_A/0/1/0/all/0/1&quot;&gt;Amin Karbasi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07482">
<title>Optimal DR-Submodular Maximization and Applications to Provable Mean Field Inference. (arXiv:1805.07482v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.07482</link>
<description rdf:parseType="Literal">&lt;p&gt;Mean field inference in probabilistic models is generally a highly nonconvex
problem. Existing optimization methods, e.g., coordinate ascent algorithms, can
only generate local optima.
&lt;/p&gt;
&lt;p&gt;In this work we propose provable mean filed methods for probabilistic
log-submodular models and its posterior agreement (PA) with strong
approximation guarantees. The main algorithmic technique is a new Double Greedy
scheme, termed DR-DoubleGreedy, for continuous DR-submodular maximization with
box-constraints. It is a one-pass algorithm with linear time complexity,
reaching the optimal 1/2 approximation ratio, which may be of independent
interest. We validate the superior performance of our algorithms against
baseline algorithms on both synthetic and real-world datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bian_A/0/1/0/all/0/1&quot;&gt;An Bian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Buhmann_J/0/1/0/all/0/1&quot;&gt;Joachim M. Buhmann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Krause_A/0/1/0/all/0/1&quot;&gt;Andreas Krause&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07489">
<title>Contour location via entropy reduction leveraging multiple information sources. (arXiv:1805.07489v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.07489</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce an algorithm to locate contours of functions that are expensive
to evaluate. The problem of locating contours arise in many applications,
including classification, constrained optimization, and analysis of performance
of mechanical and dynamical systems (reliability, probability of failure,
stability, etc.). Our algorithm locates contours using information from
multiple sources, which are available in the form of relatively inexpensive,
biased, and possibly noisy approximations to the original function. Considering
multiple information sources can lead to significant cost savings. We also
introduce the concept of contour entropy, a formal measure of uncertainty about
the location of the zero contour of a function approximated by a statistical
surrogate model. Our algorithm locates contours efficiently by maximizing the
reduction of contour entropy per unit cost.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Marques_A/0/1/0/all/0/1&quot;&gt;Alexandre N. Marques&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lam_R/0/1/0/all/0/1&quot;&gt;Remi R. Lam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Willcox_K/0/1/0/all/0/1&quot;&gt;Karen E. Willcox&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07516">
<title>Estimation of Non-Normalized Mixture Models and Clustering Using Deep Representation. (arXiv:1805.07516v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.07516</link>
<description rdf:parseType="Literal">&lt;p&gt;We develop a general method for estimating a finite mixture of non-normalized
models. Here, a non-normalized model is defined to be a parametric distribution
with an intractable normalization constant. Existing methods for estimating
non-normalized models without computing the normalization constant are not
applicable to mixture models because they contain more than one intractable
normalization constant. The proposed method is derived by extending noise
contrastive estimation (NCE), which estimates non-normalized models by
discriminating between the observed data and some artificially generated noise.
We also propose an extension of NCE with multiple noise distributions. Then,
based on the observation that conventional classification learning with neural
networks is implicitly assuming an exponential family as a generative model, we
introduce a method for clustering unlabeled data by estimating a finite mixture
of distributions in an exponential family. Estimation of this mixture model is
attained by the proposed extensions of NCE where the training data of neural
networks are used as noise. Thus, the proposed method provides a
probabilistically principled clustering method that is able to utilize a deep
representation. Application to image clustering using a deep neural network
gives promising results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Matsuda_T/0/1/0/all/0/1&quot;&gt;Takeru Matsuda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hyvarinen_A/0/1/0/all/0/1&quot;&gt;Aapo Hyvarinen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07561">
<title>Transduction with Matrix Completion Using Smoothed Rank Function. (arXiv:1805.07561v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.07561</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we propose two new algorithms for transduction with Matrix
Completion (MC) problem. The joint MC and prediction tasks are addressed
simultaneously to enhance the accuracy, i.e., the label matrix is concatenated
to the data matrix forming a stacked matrix. Assuming the data matrix is of low
rank, we propose new recommendation methods by posing the problem as a
constrained minimization of the Smoothed Rank Function (SRF). We provide
convergence analysis for the proposed algorithms. The simulations are conducted
on real datasets in two different scenarios of randomly missing pattern with
and without block loss. The results confirm that the accuracy of our proposed
methods outperforms those of state-of-the-art methods even up to 10% in low
observation rates for the scenario without block loss. Our accuracy in the
latter scenario, is comparable to state-of-the-art methods while the complexity
of the proposed algorithms are reduced up to 4 times.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Esmaeili_A/0/1/0/all/0/1&quot;&gt;Ashkan Esmaeili&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Behdin_K/0/1/0/all/0/1&quot;&gt;Kayhan Behdin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fakharian_M/0/1/0/all/0/1&quot;&gt;Mohammad Amin Fakharian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Marvasti_F/0/1/0/all/0/1&quot;&gt;Farokh Marvasti&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07574">
<title>Chief complaint classification with recurrent neural networks. (arXiv:1805.07574v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.07574</link>
<description rdf:parseType="Literal">&lt;p&gt;Syndromic surveillance detects and monitors individual and population health
indicators through sources such as emergency department records. Automated
classification of these records can improve outbreak detection speed and
diagnosis accuracy. Current syndromic systems rely on hand-coded keyword-based
methods to parse written fields and may benefit from the use of modern
supervised-learning classifier models. In this paper we implement two recurrent
neural network models based on long short-term memory (LSTM) and gated
recurrent unit (GRU) cells and compare them to two traditional bag-of-words
classifiers: multinomial naive Bayes (MNB) and a support vector machine (SVM).
All four models are trained to predict diagnostic code groups as defined by
Clinical Classification Software, first to predict from discharge diagnosis,
then from chief complaint fields. The classifiers are trained on 3.6 million
de-identified emergency department records from a single United States
jurisdiction. We compare performance of these models primarily using the F1
score. We measure absolute model performance to determine which conditions are
the most amenable to surveillance based on chief complaint alone. Using
discharge diagnoses, the LSTM classifier performs best, though all models
exhibit an F1 score above 0.96. GRU performs best on chief complaints
(F1=0.4859) and MNB with bigrams performs worst (F1=0.3998). Certain syndrome
types are easier to detect than others. For examples, the GRU predicts
alcohol-related disorders well (F1=0.8084) but predicts influenza poorly
(F1=0.1363). In all instances the RNN models outperformed the bag-of-word
classifiers, suggesting deep learning models could substantially improve the
automatic classification of unstructured text for syndromic surveillance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lee_S/0/1/0/all/0/1&quot;&gt;Scott H Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Levin_D/0/1/0/all/0/1&quot;&gt;Drew Levin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Finley_P/0/1/0/all/0/1&quot;&gt;Pat Finley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Heilig_C/0/1/0/all/0/1&quot;&gt;Charles M Heilig&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07588">
<title>Robust Optimization over Multiple Domains. (arXiv:1805.07588v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.07588</link>
<description rdf:parseType="Literal">&lt;p&gt;Recently, machine learning becomes important for the cloud computing service.
Users of cloud computing can benefit from the sophisticated machine learning
models provided by the service. Considering that users can come from different
domains with the same problem, an ideal model has to be applicable over
multiple domains. In this work, we propose to address this challenge by
developing a framework of robust optimization. In lieu of minimizing the
empirical risk, we aim to learn a model optimized with an adversarial
distribution over multiple domains. Besides the convex model, we analyze the
convergence rate of learning a robust non-convex model due to its dominating
performance on many real-word applications. Furthermore, we demonstrate that
both the robustness of the framework and the convergence rate can be enhanced
by introducing appropriate regularizers for the adversarial distribution. The
empirical study on real-world fine-grained visual categorization and digits
recognition tasks verifies the effectiveness and efficiency of the proposed
framework.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qian_Q/0/1/0/all/0/1&quot;&gt;Qi Qian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_S/0/1/0/all/0/1&quot;&gt;Shenghuo Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1&quot;&gt;Jiasheng Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jin_R/0/1/0/all/0/1&quot;&gt;Rong Jin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_B/0/1/0/all/0/1&quot;&gt;Baigui Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1&quot;&gt;Hao Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07601">
<title>Deep Generative Markov State Models. (arXiv:1805.07601v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.07601</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a deep generative Markov State Model (DeepGenMSM) learning
framework for inference of metastable dynamical systems and prediction of
trajectories. After unsupervised training on time series data, the model
contains (i) a probabilistic encoder that maps from high-dimensional
configuration space to a small-sized vector indicating the membership to
metastable (long-lived) states, (ii) a Markov chain that governs the
transitions between metastable states and facilitates analysis of the long-time
dynamics, and (iii) a generative part that samples the conditional distribution
of configurations in the next time step. The model can be operated in a
recursive fashion to generate trajectories to predict the system evolution from
a defined starting state and propose new configurations. The DeepGenMSM is
demonstrated to provide accurate estimates of the long-time kinetics and
generate valid distributions for molecular dynamics (MD) benchmark systems.
Remarkably, we show that DeepGenMSMs are able to make long time-steps in
molecular configuration space and generate physically realistic structures in
regions that were not seen in training data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wu_H/0/1/0/all/0/1&quot;&gt;Hao Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mardt_A/0/1/0/all/0/1&quot;&gt;Andreas Mardt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pasquali_L/0/1/0/all/0/1&quot;&gt;Luca Pasquali&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Noe_F/0/1/0/all/0/1&quot;&gt;Frank Noe&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07616">
<title>Do Neural Network Cross-Modal Mappings Really Bridge Modalities?. (arXiv:1805.07616v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.07616</link>
<description rdf:parseType="Literal">&lt;p&gt;Feed-forward networks are widely used in cross-modal applications to bridge
modalities by mapping distributed vectors of one modality to the other, or to a
shared space. The predicted vectors are then used to perform e.g., retrieval or
labeling. Thus, the success of the whole system relies on the ability of the
mapping to make the neighborhood structure (i.e., the pairwise similarities) of
the predicted vectors akin to that of the target vectors. However, whether this
is achieved has not been investigated yet. Here, we propose a new similarity
measure and two ad hoc experiments to shed light on this issue. In three
cross-modal benchmarks we learn a large number of language-to-vision and
vision-to-language neural network mappings (up to five layers) using a rich
diversity of image and text features and loss functions. Our results reveal
that, surprisingly, the neighborhood structure of the predicted vectors
consistently resembles more that of the input vectors than that of the target
vectors. In a second experiment, we further show that untrained nets do not
significantly disrupt the neighborhood (i.e., semantic) structure of the input
vectors.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Collell_G/0/1/0/all/0/1&quot;&gt;Guillem Collell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Moens_M/0/1/0/all/0/1&quot;&gt;Marie-Francine Moens&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07624">
<title>Nonparametric Bayesian Deep Networks with Local Competition. (arXiv:1805.07624v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.07624</link>
<description rdf:parseType="Literal">&lt;p&gt;Local competition among neighboring neurons is a common procedure taking
place in biological systems. This finding has inspired research on more
biologically plausible deep networks that comprise competing linear units; such
models can be effectively trained by means of gradient-based backpropagation.
This is in contrast to traditional deep networks, built of nonlinear units that
do not entail any form of (local) competition. However, for the case of
competition-based networks, the problem of data-driven inference of their most
appropriate configuration, including the needed number of connections or
locally competing sets of units, has not been touched upon by the research
community. This work constitutes the first attempt to address this shortcoming;
to this end, we leverage solid arguments from the field of Bayesian
nonparametrics. Specifically, we introduce auxiliary discrete latent variables
of model component utility, and perform Bayesian inference over them. We impose
appropriate stick-breaking priors over the introduced discrete latent
variables; these give rise to an well-established sparsity-inducing mechanism.
We devise efficient inference algorithms for our model by resorting to
stochastic gradient variational Bayes. We perform an extensive experimental
evaluation of our approach using benchmark data. Our results verify that we
obtain state-of-the-art accuracy albeit via networks of much smaller memory and
computational footprint than the competition.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Panousis_K/0/1/0/all/0/1&quot;&gt;Konstantinos P. Panousis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chatzis_S/0/1/0/all/0/1&quot;&gt;Sotirios Chatzis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Theodoridis_S/0/1/0/all/0/1&quot;&gt;Sergios Theodoridis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07633">
<title>Heterogeneous Multi-output Gaussian Process Prediction. (arXiv:1805.07633v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.07633</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a novel extension of multi-output Gaussian processes for handling
heterogeneous outputs. We assume that each output has its own likelihood
function and use a vector-valued Gaussian process prior to jointly model the
parameters in all likelihoods as latent functions. Our multi-output Gaussian
process uses a covariance function with a linear model of coregionalisation
form. Assuming conditional independence across the underlying latent functions
together with an inducing variable framework, we are able to obtain tractable
variational bounds amenable to stochastic variational inference. We illustrate
the performance of the model on synthetic data and two real datasets: a human
behavioral study and a demographic high-dimensional dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Moreno_Munoz_P/0/1/0/all/0/1&quot;&gt;Pablo Moreno-Mu&amp;#xf1;oz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Artes_Rodriguez_A/0/1/0/all/0/1&quot;&gt;Antonio Art&amp;#xe9;s-Rodr&amp;#xed;guez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Alvarez_M/0/1/0/all/0/1&quot;&gt;Mauricio A. &amp;#xc1;lvarez&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07645">
<title>Regularized Loss Minimizers with Local Data Obfuscation. (arXiv:1805.07645v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.07645</link>
<description rdf:parseType="Literal">&lt;p&gt;While data privacy has been studied for more than a decade, it is still
unclear how data privacy will counter data utility. We focus on the balance of
data privacy and data utility in this paper. We show that there are several
\emph{regularized loss minimization} problems that can use locally perturbed
data with theoretical guarantees for loss consistency. Our result
quantitatively connects the convergence rate of the learning problems to the
impossibility of any adversary for recovering the original data from perturbed
observations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Zitao Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Honorio_J/0/1/0/all/0/1&quot;&gt;Jean Honorio&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07654">
<title>Sampling-Free Variational Inference of Bayesian Neural Nets. (arXiv:1805.07654v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.07654</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a new Bayesian Neural Net (BNN) formulation that affords
variational inference for which the evidence lower bound (ELBO) is analytically
tractable subject to a tight approximation. We achieve this tractability by
decomposing ReLU nonlinearities into an identity function and a Kronecker delta
function. We demonstrate formally that assigning the outputs of these functions
to separate latent variables allows representing the neural network likelihood
as the composition of a chain of linear operations. Performing variational
inference on this construction enables closed-form computation of the evidence
lower bound. It can thus be maximized without requiring Monte Carlo sampling to
approximate the problematic expected log-likelihood term. The resultant
formulation boils down to stochastic gradient descent, where the gradients are
not distorted by any factor besides minibatch selection. This amends a
long-standing disadvantage of BNNs relative to deterministic nets. Experiments
on four benchmark data sets show that the cleaner gradients provided by our
construction yield a steeper learning curve, achieving higher prediction
accuracies for a fixed epoch budget.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kandemir_M/0/1/0/all/0/1&quot;&gt;Melih Kandemir&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Haussmann_M/0/1/0/all/0/1&quot;&gt;Manuel Haussmann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hamprecht_F/0/1/0/all/0/1&quot;&gt;Fred A. Hamprecht&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07684">
<title>Stacked Propensity Score Functions for Observational Cohorts with Oversampled Exposed Subjects. (arXiv:1805.07684v1 [stat.ME])</title>
<link>http://arxiv.org/abs/1805.07684</link>
<description rdf:parseType="Literal">&lt;p&gt;Observational cohort studies with oversampled exposed subjects are typically
implemented to understand the causal effect of a rare exposure. Because the
distribution of exposed subjects in the sample differs from the source
population, estimation of a propensity score function (i.e., probability of
exposure given baseline covariates) targets a nonparametrically nonidentifiable
parameter. Consistent estimation of propensity score functions is an important
component of various causal inference estimators, including double robust
machine learning and inverse probability weighted estimators. We propose the
use of the probability of exposure from the source population in
observation-weighted stacking algorithms to produce consistent estimators of
propensity score functions. Simulation studies and a hypothetical health policy
intervention data analysis demonstrate low empirical bias and variance for
these stacked propensity score functions with observation weights.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rose_S/0/1/0/all/0/1&quot;&gt;Sherri Rose&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07687">
<title>Machine Teaching for Inverse Reinforcement Learning: Algorithms and Applications. (arXiv:1805.07687v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.07687</link>
<description rdf:parseType="Literal">&lt;p&gt;Inverse reinforcement learning (IRL) infers a reward function from
demonstrations, allowing for policy improvement and generalization. However,
despite much recent interest in IRL, little work has been done to understand of
the minimum set of demonstrations needed to teach a specific sequential
decision-making task. We formalize the problem of finding optimal
demonstrations for IRL as a machine teaching problem where the goal is to find
the minimum number of demonstrations needed to specify the reward equivalence
class of the demonstrator. We extend previous work on algorithmic teaching for
sequential decision-making tasks by showing an equivalence to the set cover
problem, and use this equivalence to develop an efficient algorithm for
determining the set of maximally-informative demonstrations. We apply our
proposed machine teaching algorithm to two novel applications: benchmarking
active learning IRL algorithms and developing an IRL algorithm that, rather
than assuming demonstrations are i.i.d., uses counterfactual reasoning over
informative demonstrations to learn more efficiently.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brown_D/0/1/0/all/0/1&quot;&gt;Daniel S. Brown&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Niekum_S/0/1/0/all/0/1&quot;&gt;Scott Niekum&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07702">
<title>Predicting drug response of tumors from integrated genomic profiles by deep neural networks. (arXiv:1805.07702v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.07702</link>
<description rdf:parseType="Literal">&lt;p&gt;The study of high-throughput genomic profiles from a pharmacogenomics
viewpoint has provided unprecedented insights into the oncogenic features
modulating drug response. A recent screening of ~1,000 cancer cell lines to a
collection of anti-cancer drugs illuminated the link between genotypes and
vulnerability. However, due to essential differences between cell lines and
tumors, the translation into predicting drug response in tumors remains
challenging. Here we proposed a DNN model to predict drug response based on
mutation and expression profiles of a cancer cell or a tumor. The model
contains a mutation and an expression encoders pre-trained using a large
pan-cancer dataset to abstract core representations of high-dimension data,
followed by a drug response predictor network. Given a pair of mutation and
expression profiles, the model predicts IC50 values of 265 drugs. We trained
and tested the model on a dataset of 622 cancer cell lines and achieved an
overall prediction performance of mean squared error at 1.96 (log-scale IC50
values). The performance was superior in prediction error or stability than two
classical methods and four analog DNNs of our model. We then applied the model
to predict drug response of 9,059 tumors of 33 cancer types. The model
predicted both known, including EGFR inhibitors in non-small cell lung cancer
and tamoxifen in ER+ breast cancer, and novel drug targets. The comprehensive
analysis further revealed the molecular mechanisms underlying the resistance to
a chemotherapeutic drug docetaxel in a pan-cancer setting and the anti-cancer
potential of a novel agent, CX-5461, in treating gliomas and hematopoietic
malignancies. Overall, our model and findings improve the prediction of drug
response and the identification of novel therapeutic options.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chiu_Y/0/1/0/all/0/1&quot;&gt;Yu-Chiao Chiu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chen_H/0/1/0/all/0/1&quot;&gt;Hung-I Harry Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhang_T/0/1/0/all/0/1&quot;&gt;Tinghe Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhang_S/0/1/0/all/0/1&quot;&gt;Songyao Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gorthi_A/0/1/0/all/0/1&quot;&gt;Aparna Gorthi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wang_L/0/1/0/all/0/1&quot;&gt;Li-Ju Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Huang_Y/0/1/0/all/0/1&quot;&gt;Yufei Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yidong Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07725">
<title>Human-guided data exploration using randomisation. (arXiv:1805.07725v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.07725</link>
<description rdf:parseType="Literal">&lt;p&gt;An explorative data analysis system should be aware of what the user already
knows and what the user wants to know of the data: otherwise the system cannot
provide the user with the most informative and useful views of the data. We
propose a principled way to do explorative data analysis, where the user&apos;s
background knowledge is modeled by a distribution parametrised by subsets of
rows and columns in the data, called tiles. The user can also use tiles to
describe his or her interests concerning relations in the data. We provide a
computationally efficient implementation of this concept based on constrained
randomisation. This is used to model both the background knowledge and the
user&apos;s information request and is a necessary prerequisite for any interactive
system. Furthermore, we describe a novel linear projection pursuit method to
find and show the views most informative to the user, which at the limit of no
background knowledge and with generic objective reduces to PCA. We show that
our method is robust under noise and fast enough for interactive use. We also
show that the method gives understandable and useful results when analysing
real-world data sets. We will release, under an open source license, a software
library implementing the idea, including the experiments presented in this
paper. We show that our method can outperform standard projection pursuit
visualisation methods in exploration tasks. Our framework makes it possible to
construct human-guided data exploration systems which are fast, powerful, and
give results that are easy to comprehend.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Puolamaki_K/0/1/0/all/0/1&quot;&gt;Kai Puolam&amp;#xe4;ki&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Oikarinen_E/0/1/0/all/0/1&quot;&gt;Emilia Oikarinen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Atli_B/0/1/0/all/0/1&quot;&gt;Buse Gul Atli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Henelius_A/0/1/0/all/0/1&quot;&gt;Andreas Henelius&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07737">
<title>Exp-Concavity of Proper Composite Losses. (arXiv:1805.07737v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.07737</link>
<description rdf:parseType="Literal">&lt;p&gt;The goal of online prediction with expert advice is to find a decision
strategy which will perform almost as well as the best expert in a given pool
of experts, on any sequence of outcomes. This problem has been widely studied
and $O(\sqrt{T})$ and $O(\log{T})$ regret bounds can be achieved for convex
losses (\cite{zinkevich2003online}) and strictly convex losses with bounded
first and second derivatives (\cite{hazan2007logarithmic}) respectively. In
special cases like the Aggregating Algorithm (\cite{vovk1995game}) with mixable
losses and the Weighted Average Algorithm (\cite{kivinen1999averaging}) with
exp-concave losses, it is possible to achieve $O(1)$ regret bounds.
\cite{van2012exp} has argued that mixability and exp-concavity are roughly
equivalent under certain conditions. Thus by understanding the underlying
relationship between these two notions we can gain the best of both algorithms
(strong theoretical performance guarantees of the Aggregating Algorithm and the
computational efficiency of the Weighted Average Algorithm). In this paper we
provide a complete characterization of the exp-concavity of any proper
composite loss. Using this characterization and the mixability condition of
proper losses (\cite{van2012mixability}), we show that it is possible to
transform (re-parameterize) any $\beta$-mixable binary proper loss into a
$\beta$-exp-concave composite loss with the same $\beta$. In the multi-class
case, we propose an approximation approach for this transformation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kamalaruban_P/0/1/0/all/0/1&quot;&gt;Parameswaran Kamalaruban&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Williamson_R/0/1/0/all/0/1&quot;&gt;Robert C. Williamson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xinhua Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07746">
<title>Structural Regularity Exploring and Controlling: A Network Reconstruction Perspective. (arXiv:1805.07746v1 [cs.SI])</title>
<link>http://arxiv.org/abs/1805.07746</link>
<description rdf:parseType="Literal">&lt;p&gt;The ubiquitous complex networks are often composed of regular and irregular
components, which makes uncovering the complexity of network structure into a
fundamental challenge in network science. Exploring the regular information and
identifying the roles of microscopic elements in network organization can help
practitioners to recognize the universal principles of network formation and
facilitate network data mining.Despite many algorithms having been proposed for
link prediction and network reconstruction, estimating and regulating the
reconstructability of complex networks remains an inadequately explored
problem. With the practical assumption that there has consistence between local
structures of networks and the corresponding adjacency matrices are
approximately low rank, we obtain a self-representation network model in which
the organization principles of networks are captured by representation matrix.
According to the model, original networks can be reconstructed based on
observed structure. What&apos;s more, the model enables us to estimate to what
extent networks are regulable, in other words, measure the reconstructability
of complex networks. In addition, the model enables us to measure the
importance of network links for network regularity thereby allowing us to
regulate the reconstructability of networks. The extensive experiments on
disparate networks demonstrate the effectiveness of the proposed algorithm and
measure. Specifically, the structural regularity reflects the
reconstructability of networks, and the reconstruction accuracy can be promoted
via the deleting of irregular network links independent of specific algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_T/0/1/0/all/0/1&quot;&gt;Tao Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qiao_S/0/1/0/all/0/1&quot;&gt;Shaojie Qiao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_W/0/1/0/all/0/1&quot;&gt;Wei Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xian_X/0/1/0/all/0/1&quot;&gt;Xingping Xian&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07777">
<title>DLBI: Deep learning guided Bayesian inference for structure reconstruction of super-resolution fluorescence microscopy. (arXiv:1805.07777v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1805.07777</link>
<description rdf:parseType="Literal">&lt;p&gt;Super-resolution fluorescence microscopy, with a resolution beyond the
diffraction limit of light, has become an indispensable tool to directly
visualize biological structures in living cells at a nanometer-scale
resolution. Despite advances in high-density super-resolution fluorescent
techniques, existing methods still have bottlenecks, including extremely long
execution time, artificial thinning and thickening of structures, and lack of
ability to capture latent structures. Here we propose a novel deep learning
guided Bayesian inference approach, DLBI, for the time-series analysis of
high-density fluorescent images. Our method combines the strength of deep
learning and statistical inference, where deep learning captures the underlying
distribution of the fluorophores that are consistent with the observed
time-series fluorescent images by exploring local features and correlation
along time-axis, and statistical inference further refines the ultrastructure
extracted by deep learning and endues physical meaning to the final image.
Comprehensive experimental results on both real and simulated datasets
demonstrate that our method provides more accurate and realistic local patch
and large-field reconstruction than the state-of-the-art method, the 3B
analysis, while our method is more than two orders of magnitude faster. The
main program is available at https://github.com/lykaust15/DLBI.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yu Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_F/0/1/0/all/0/1&quot;&gt;Fan Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_F/0/1/0/all/0/1&quot;&gt;Fa Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_P/0/1/0/all/0/1&quot;&gt;Pingyong Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_M/0/1/0/all/0/1&quot;&gt;Mingshu Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fan_M/0/1/0/all/0/1&quot;&gt;Ming Fan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1&quot;&gt;Lihua Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gao_X/0/1/0/all/0/1&quot;&gt;Xin Gao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Han_R/0/1/0/all/0/1&quot;&gt;Renmin Han&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07785">
<title>Conditional Inference in Pre-trained Variational Autoencoders via Cross-coding. (arXiv:1805.07785v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.07785</link>
<description rdf:parseType="Literal">&lt;p&gt;Variational Autoencoders (VAEs) are a popular generative model, but one in
which conditional inference can be challenging. If the decomposition into query
and evidence variables is fixed, conditional VAEs provide an attractive
solution. To support arbitrary queries, one is generally reduced to Markov
Chain Monte Carlo sampling methods that can suffer from long mixing times. In
this paper, we propose an idea we term cross-coding to approximate the
distribution over the latent variables after conditioning on an evidence
assignment to some subset of the variables. This allows generating query
samples without retraining the full VAE. We experimentally evaluate three
variations of cross-coding showing that (i) two can be quickly trained for
different decompositions of evidence and query and (ii) they quantitatively and
qualitatively outperform Hamiltonian Monte Carlo.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wu_G/0/1/0/all/0/1&quot;&gt;Ga Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Domke_J/0/1/0/all/0/1&quot;&gt;Justin Domke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sanner_S/0/1/0/all/0/1&quot;&gt;Scott Sanner&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07808">
<title>Multi-layer Kernel Ridge Regression for One-class Classification. (arXiv:1805.07808v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.07808</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, a multi-layer architecture (in a hierarchical fashion) by
stacking various Kernel Ridge Regression (KRR) based Auto-Encoder for one-class
classification is proposed and is referred as MKOC. MKOC has many layers of
Auto-Encoders to project the input features into new feature space and the last
layer was regression based one class classifier. The Auto-Encoders use an
unsupervised approach of learning and the final layer uses semi-supervised
(trained by only positive samples) approach of learning. The proposed MKOC is
experimentally evaluated on 15 publicly available benchmark datasets.
Experimental results verify the effectiveness of the proposed approach over 11
existing state-of-the-art kernel-based one-class classifiers. Friedman test is
also performed to verify the statistical significance of the claim of the
superiority of the proposed one-class classifiers over the existing
state-of-the-art methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gautam_C/0/1/0/all/0/1&quot;&gt;Chandan Gautam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tiwari_A/0/1/0/all/0/1&quot;&gt;Aruna Tiwari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Suresh_S/0/1/0/all/0/1&quot;&gt;Sundaram Suresh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Iosifidis_A/0/1/0/all/0/1&quot;&gt;Alexandros Iosifidis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07810">
<title>Online Structured Laplace Approximations For Overcoming Catastrophic Forgetting. (arXiv:1805.07810v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.07810</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce the Kronecker factored online Laplace approximation for
overcoming catastrophic forgetting in neural networks. The method is grounded
in a Bayesian online learning framework, where we recursively approximate the
posterior after every task with a Gaussian, leading to a quadratic penalty on
changes to the weights. The Laplace approximation requires calculating the
Hessian around a mode, which is typically intractable for modern architectures.
In order to make our method scalable, we leverage recent block-diagonal
Kronecker factored approximations to the curvature. Our algorithm achieves over
90% test accuracy across a sequence of 50 instantiations of the permuted MNIST
dataset, substantially outperforming related methods for overcoming
catastrophic forgetting.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ritter_H/0/1/0/all/0/1&quot;&gt;Hippolyt Ritter&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Botev_A/0/1/0/all/0/1&quot;&gt;Aleksandar Botev&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Barber_D/0/1/0/all/0/1&quot;&gt;David Barber&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07820">
<title>Targeted Adversarial Examples for Black Box Audio Systems. (arXiv:1805.07820v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.07820</link>
<description rdf:parseType="Literal">&lt;p&gt;The application of deep recurrent networks to audio transcription has led to
impressive gains in automatic speech recognition (ASR) systems. Many have
demonstrated that small adversarial perturbations can fool deep neural networks
into incorrectly predicting a specified target with high confidence. Current
work on fooling ASR systems have focused on white-box attacks, in which the
model architecture and parameters are known. In this paper, we adopt a
black-box approach to adversarial generation, combining the approaches of both
genetic algorithms and gradient estimation to solve the task. We achieve a
89.25% targeted attack similarity after 3000 generations while maintaining
94.6% audio file similarity.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Taori_R/0/1/0/all/0/1&quot;&gt;Rohan Taori&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kamsetty_A/0/1/0/all/0/1&quot;&gt;Amog Kamsetty&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chu_B/0/1/0/all/0/1&quot;&gt;Brenton Chu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vemuri_N/0/1/0/all/0/1&quot;&gt;Nikita Vemuri&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07833">
<title>Wasserstein regularization for sparse multi-task regression. (arXiv:1805.07833v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.07833</link>
<description rdf:parseType="Literal">&lt;p&gt;Two important elements have driven recent innovation in the field of
regression: sparsity-inducing regularization, to cope with high-dimensional
problems; multi-task learning through joint parameter estimation, to augment
the number of training samples. Both approaches complement each other in the
sense that a joint estimation results in more samples, which are needed to
estimate sparse models accurately, whereas sparsity promotes models that act on
subsets of related variables. This idea has driven the proposal of block
regularizers such as L1/Lq norms, which however effective, require that active
regressors strictly overlap. In this paper, we propose a more flexible convex
regularizer based on unbalanced optimal transport (OT) theory. That regularizer
promotes parameters that are close, according to the OT geometry, which takes
into account a prior geometric knowledge on the regressor variables. We derive
an efficient algorithm based on a regularized formulation of optimal transport,
which iterates through applications of Sinkhorn&apos;s algorithm along with
coordinate descent iterations. The performance of our model is demonstrated on
regular grids and complex triangulated geometries of the cortex with an
application in neuroimaging.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Janati_H/0/1/0/all/0/1&quot;&gt;Hicham Janati&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Cuturi_M/0/1/0/all/0/1&quot;&gt;Marco Cuturi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gramfort_A/0/1/0/all/0/1&quot;&gt;Alexandre Gramfort&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07836">
<title>Generalized Cross Entropy Loss for Training Deep Neural Networks with Noisy Labels. (arXiv:1805.07836v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.07836</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep neural networks (DNNs) have achieved tremendous success in a variety of
applications across many disciplines. Yet, their superior performance comes
with the expensive cost of requiring correctly annotated large-scale datasets.
Moreover, due to DNNs&apos; rich capacity, errors in training labels can hamper
performance. To combat this problem, mean absolute error (MAE) has recently
been proposed as a noise-robust alternative to the commonly-used categorical
cross entropy (CCE) loss. However, as we show in this paper, MAE can perform
poorly with DNNs and challenging datasets. Here, we present a theoretically
grounded set of noise-robust loss functions that can be seen as a
generalization of MAE and CCE. Proposed loss functions can be readily applied
with any existing DNN architecture and algorithm, while yielding good
performance in a wide range of noisy label scenarios. We report results from
experiments conducted with CIFAR-10, CIFAR-100 and FASHION-MNIST datasets and
synthetically generated noisy labels.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1&quot;&gt;Zhilu Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sabuncu_M/0/1/0/all/0/1&quot;&gt;Mert R. Sabuncu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07844">
<title>Projection-Free Algorithms in Statistical Estimation. (arXiv:1805.07844v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.07844</link>
<description rdf:parseType="Literal">&lt;p&gt;Frank-Wolfe algorithm (FW) and its variants have gained a surge of interests
in machine learning community due to its projection-free property. Recently
people have reduced the gradient evaluation complexity of FW algorithm to
$\log(\frac{1}{\epsilon})$ for the smooth and strongly convex objective. This
complexity result is especially significant in learning problem, as the
overwhelming data size makes a single evluation of gradient computational
expensive. However, in high-dimensional statistical estimation problems, the
objective is typically not strongly convex, and sometimes even non-convex. In
this paper, we extend the state-of-the-art FW type algorithms for the
large-scale, high-dimensional estimation problem. We show that as long as the
objective satisfies {\em restricted strong convexity}, and we are not
optimizing over statistical limit of the model, the $\log(\frac{1}{\epsilon})$
gradient evaluation complexity could still be attained.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yan Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Qu_C/0/1/0/all/0/1&quot;&gt;Chao Qu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Xu_H/0/1/0/all/0/1&quot;&gt;Huan Xu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07880">
<title>Learning with Non-Convex Truncated Losses by SGD. (arXiv:1805.07880v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.07880</link>
<description rdf:parseType="Literal">&lt;p&gt;Learning with a {\it convex loss} function has been a dominating paradigm for
many years. It remains an interesting question how non-convex loss functions
help improve the generalization of learning with broad applicability. In this
paper, we study a family of objective functions formed by truncating
traditional loss functions, which is applicable to both shallow learning and
deep learning. Truncating loss functions has potential to be less vulnerable
and more robust to large noise in observations that could be adversarial. More
importantly, it is a generic technique without assuming the knowledge of noise
distribution. To justify non-convex learning with truncated losses, we
establish excess risk bounds of empirical risk minimization based on truncated
losses for heavy-tailed output, and statistical error of an approximate
stationary point found by stochastic gradient descent (SGD) method. Our
experiments for shallow and deep learning for regression with outliers,
corrupted data and heavy-tailed noise further justify the proposed method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_Y/0/1/0/all/0/1&quot;&gt;Yi Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_S/0/1/0/all/0/1&quot;&gt;Shenghuo Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1&quot;&gt;Sen Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1&quot;&gt;Chi Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jin_R/0/1/0/all/0/1&quot;&gt;Rong Jin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_T/0/1/0/all/0/1&quot;&gt;Tianbao Yang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07909">
<title>Quickshift++: Provably Good Initializations for Sample-Based Mean Shift. (arXiv:1805.07909v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.07909</link>
<description rdf:parseType="Literal">&lt;p&gt;We provide initial seedings to the Quick Shift clustering algorithm, which
approximate the locally high-density regions of the data. Such seedings act as
more stable and expressive cluster-cores than the singleton modes found by
Quick Shift. We establish statistical consistency guarantees for this
modification. We then show strong clustering performance on real datasets as
well as promising applications to image segmentation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1&quot;&gt;Heinrich Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jang_J/0/1/0/all/0/1&quot;&gt;Jennifer Jang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kpotufe_S/0/1/0/all/0/1&quot;&gt;Samory Kpotufe&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07912">
<title>Frank-Wolfe Stein Sampling. (arXiv:1805.07912v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.07912</link>
<description rdf:parseType="Literal">&lt;p&gt;In Bayesian inference, the posterior distributions are difficult to obtain
analytically for complex models such as neural networks. Variational inference
usually uses a parametric distribution to approximate, from which we can easily
draw samples. Recently discrete approximation by particles has attracted
attention because of its expressive ability. An example is Stein variational
gradient descent (SVGD), which iteratively optimizes particles. Although SVGD
has been shown to be computationally efficient empirically, its theoretical
properties have not been clarified yet and no finite sample bound of a
convergence rate is known. Another example is Stein points (SP), which
minimizes kernelized Stein discrepancy directly. The finite sample bound of SP
is $\mathcal{O}(\sqrt{\log{N}/N})$ for $N$ particles, which is computationally
inefficient empirically, especially in high-dimensional problems. In this
paper, we propose a novel method named \emph{Frank-Wolfe Stein sampling}, which
minimizes the maximum mean discrepancy in a greedy way. Our method is
computationally efficient empirically and theoretically achieves a faster
convergence rate, $\mathcal{O}(e^{-N})$. Numerical experiments show the
superiority of our method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Futami_F/0/1/0/all/0/1&quot;&gt;Futoshi Futami&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Cui_Z/0/1/0/all/0/1&quot;&gt;Zhenghang Cui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sato_I/0/1/0/all/0/1&quot;&gt;Issei Sato&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sugiyama_M/0/1/0/all/0/1&quot;&gt;Masashi Sugiyama&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07914">
<title>Imitating Latent Policies from Observation. (arXiv:1805.07914v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.07914</link>
<description rdf:parseType="Literal">&lt;p&gt;We describe a novel approach to imitation learning that infers latent
policies directly from state observations. We introduce a method that
characterizes the causal effects of unknown actions on observations while
simultaneously predicting their likelihood. We then outline an action alignment
procedure that leverages a small amount of environment interactions to
determine a mapping between latent and real-world actions. We show that this
corrected labeling can be used for imitating the observed behavior, even though
no expert actions are given. We evaluate our approach within classic control
and photo-realistic visual environments and demonstrate that it performs well
when compared to standard approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Edwards_A/0/1/0/all/0/1&quot;&gt;Ashley D. Edwards&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sahni_H/0/1/0/all/0/1&quot;&gt;Himanshu Sahni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schroeker_Y/0/1/0/all/0/1&quot;&gt;Yannick Schroeker&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Isbell_C/0/1/0/all/0/1&quot;&gt;Charles L. Isbell&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07938">
<title>Transductive Boltzmann Machines. (arXiv:1805.07938v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.07938</link>
<description rdf:parseType="Literal">&lt;p&gt;We present transductive Boltzmann machines (TBMs), which firstly achieve
transductive learning of the Gibbs distribution. While exact learning of the
Gibbs distribution is impossible by the family of existing Boltzmann machines
due to combinatorial explosion of the sample space, TBMs overcome the problem
by adaptively constructing the minimum required sample space from data to avoid
unnecessary generalization. We theoretically provide bias-variance
decomposition of the KL divergence in TBMs to analyze its learnability, and
empirically demonstrate that TBMs are superior to the fully visible Boltzmann
machines and popularly used restricted Boltzmann machines in terms of
efficiency and effectiveness.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sugiyama_M/0/1/0/all/0/1&quot;&gt;Mahito Sugiyama&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tsuda_K/0/1/0/all/0/1&quot;&gt;Koji Tsuda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Nakahara_H/0/1/0/all/0/1&quot;&gt;Hiroyuki Nakahara&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07943">
<title>Relating Leverage Scores and Density using Regularized Christoffel Functions. (arXiv:1805.07943v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.07943</link>
<description rdf:parseType="Literal">&lt;p&gt;Statistical leverage scores emerged as a fundamental tool for matrix
sketching and column sampling with applications to low rank approximation,
regression, random feature learning and quadrature. Yet, the very nature of
this quantity is barely understood. Borrowing ideas from the orthogonal
polynomial literature, we introduce the regularized Christoffel function
associated to a positive definite kernel. This uncovers a variational
formulation for leverage scores for kernel methods and allows to elucidate
their relationships with the chosen kernel as well as population density. Our
main result quantitatively describes a decreasing relation between leverage
score and population density for a broad class of kernels on Euclidean spaces.
Numerical simulations support our findings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pauwels_E/0/1/0/all/0/1&quot;&gt;Edouard Pauwels&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bach_F/0/1/0/all/0/1&quot;&gt;Francis Bach&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vert_J/0/1/0/all/0/1&quot;&gt;Jean-Philippe Vert&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07960">
<title>Stochastic Gradient Descent for Stochastic Doubly-Nonconvex Composite Optimization. (arXiv:1805.07960v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.07960</link>
<description rdf:parseType="Literal">&lt;p&gt;The stochastic gradient descent has been widely used for solving composite
optimization problems in big data analyses. Many algorithms and convergence
properties have been developed. The composite functions were convex primarily
and gradually nonconvex composite functions have been adopted to obtain more
desirable properties. The convergence properties have been investigated, but
only when either of composite functions is nonconvex. There is no convergence
property when both composite functions are nonconvex, which is named the
\textit{doubly-nonconvex} case.To overcome this difficulty, we assume a simple
and weak condition that the penalty function is \textit{quasiconvex} and then
we obtain convergence properties for the stochastic doubly-nonconvex composite
optimization problem.The convergence rate obtained here is of the same order as
the existing work.We deeply analyze the convergence rate with the constant step
size and mini-batch size and give the optimal convergence rate with appropriate
sizes, which is superior to the existing work. Experimental results illustrate
that our method is superior to existing methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kawashima_T/0/1/0/all/0/1&quot;&gt;Takayuki Kawashima&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Fujisawa_H/0/1/0/all/0/1&quot;&gt;Hironori Fujisawa&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07978">
<title>Streaming MANN: A Streaming-Based Inference for Energy-Efficient Memory-Augmented Neural Networks. (arXiv:1805.07978v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.07978</link>
<description rdf:parseType="Literal">&lt;p&gt;With the successful development of artificial intelligence using deep
learning, there has been growing interest in its deployment. The mobile
environment is the closest hardware platform to real life, and it has become an
important platform for the success or failure of artificial intelligence.
Memory-augmented neural networks (MANNs) are neural networks proposed to
efficiently handle question-and-answer (Q&amp;amp;A) tasks, well-suited for mobile
devices. As a MANN requires various types of operations and recurrent data
paths, it is difficult to accelerate the inference in the structure designed
for other conventional neural network models, which is one of the biggest
obstacles to deploying MANNs in mobile environments. To address the
aforementioned issues, we propose Streaming MANN. This is the first attempt to
implement and demonstrate the architecture for energy-efficient inference of
MANNs with the concept of streaming processing. To achieve the full potential
of the streaming process, we propose a novel approach, called inference
thresholding, using Bayesian approach considering the characteristics of
natural language processing (NLP) tasks. To evaluate our proposed approaches,
we implemented the architecture and method in a field-programmable gate array
(FPGA) which is suitable for streaming processing. We measured the execution
time and power consumption of the inference for the bAbI dataset. The
experimental results showed that the performance efficiency per energy
(FLOPS/kJ) of the Streaming MANN increased by a factor of up to about 126
compared to the results of NVIDIA TITAN V, and up to 140 if inference
thresholding is applied.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Park_S/0/1/0/all/0/1&quot;&gt;Seongsik Park&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jang_J/0/1/0/all/0/1&quot;&gt;Jaehee Jang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1&quot;&gt;Seijoon Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yoon_S/0/1/0/all/0/1&quot;&gt;Sungroh Yoon&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07979">
<title>A Tensor-Based Sub-Mode Coordinate Algorithm for Stock Prediction. (arXiv:1805.07979v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.07979</link>
<description rdf:parseType="Literal">&lt;p&gt;The investment on the stock market is prone to be affected by the Internet.
For the purpose of improving the prediction accuracy, we propose a multi-task
stock prediction model that not only considers the stock correlations but also
supports multi-source data fusion. Our proposed model first utilizes tensor to
integrate the multi-sourced data, including financial Web news, investors&apos;
sentiments extracted from the social network and some quantitative data on
stocks. In this way, the intrinsic relationships among different information
sources can be captured, and meanwhile, multi-sourced information can be
complemented to solve the data sparsity problem. Secondly, we propose an
improved sub-mode coordinate algorithm (SMC). SMC is based on the stock
similarity, aiming to reduce the variance of their subspace in each dimension
produced by the tensor decomposition. The algorithm is able to improve the
quality of the input features, and thus improves the prediction accuracy. And
the paper utilizes the Long Short-Term Memory (LSTM) neural network model to
predict the stock fluctuation trends. Finally, the experiments on 78 A-share
stocks in CSI 100 and thirteen popular HK stocks in the year 2015 and 2016 are
conducted. The results demonstrate the improvement on the prediction accuracy
and the effectiveness of the proposed model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1&quot;&gt;Jieyun Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yunjia Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Jialai Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xi Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07997">
<title>Anime Style Space Exploration Using Metric Learning and Generative Adversarial Networks. (arXiv:1805.07997v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1805.07997</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep learning-based style transfer between images has recently become a
popular area of research. A common way of encoding &quot;style&quot; is through a feature
representation based on the Gram matrix of features extracted by some
pre-trained neural network or some other form of feature statistics. Such a
definition is based on an arbitrary human decision and may not best capture
what a style really is. In trying to gain a better understanding of &quot;style&quot;, we
propose a metric learning-based method to explicitly encode the style of an
artwork. In particular, our definition of style captures the differences
between artists, as shown by classification performances, and such that the
style representation can be interpreted, manipulated and visualized through
style-conditioned image generation through a Generative Adversarial Network. We
employ this method to explore the style space of anime portrait illustrations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiang_S/0/1/0/all/0/1&quot;&gt;Sitao Xiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_H/0/1/0/all/0/1&quot;&gt;Hao Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08010">
<title>Where Do You Think You&apos;re Going?: Inferring Beliefs about Dynamics from Behavior. (arXiv:1805.08010v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.08010</link>
<description rdf:parseType="Literal">&lt;p&gt;Inferring intent from observed behavior has been studied extensively within
the frameworks of Bayesian inverse planning and inverse reinforcement learning.
These methods infer a goal or reward function that best explains the actions of
the observed agent, typically a human demonstrator. Another agent can use this
inferred intent to predict, imitate, or assist the human user. However, a
central assumption in inverse reinforcement learning is that the demonstrator
is close to optimal. While models of suboptimal behavior exist, they typically
assume that suboptimal actions are the result of some type of random noise or a
known cognitive bias, like temporal inconsistency. In this paper, we take an
alternative approach, and model suboptimal behavior as the result of internal
model misspecification: the reason that user actions might deviate from
near-optimal actions is that the user has an incorrect set of beliefs about the
rules -- the dynamics -- governing how actions affect the environment. Our
insight is that while demonstrated actions may be suboptimal in the real world,
they may actually be near-optimal with respect to the user&apos;s internal model of
the dynamics. By estimating these internal beliefs from observed behavior, we
arrive at a new method for inferring intent. We demonstrate in simulation and
in a user study with 12 participants that this approach enables us to more
accurately model human intent, and can be used in a variety of applications,
including offering assistance in a shared autonomy framework and inferring
human preferences.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Reddy_S/0/1/0/all/0/1&quot;&gt;Siddharth Reddy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dragan_A/0/1/0/all/0/1&quot;&gt;Anca D. Dragan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1&quot;&gt;Sergey Levine&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08045">
<title>A universal framework for learning based on the elliptical mixture model (EMM). (arXiv:1805.08045v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.08045</link>
<description rdf:parseType="Literal">&lt;p&gt;An increasing prominence of unbalanced and noisy data highlights the
importance of elliptical mixture models (EMMs), which exhibit enhanced
robustness, flexibility and stability over the widely applied Gaussian mixture
model (GMM). However, existing studies of the EMM are typically of \textit{ad
hoc} nature, without a universal analysis framework or existence and uniqueness
considerations. To this end, we propose a general framework for estimating the
EMM, which makes use of the Riemannian manifold optimisation to convert the
original constrained optimisation paradigms into an un-constrained one. We
first revisit the statistics of elliptical distributions, to give a rationale
for the use of Riemannian metrics as well as the reformulation of the problem
in the Riemannian space. We then derive the EMM learning framework, based on
Riemannian gradient descent, which ensures the same optimum as the original
problem but accelerates the convergence speed. We also unify the treatment of
the existing elliptical distributions to build a universal EMM, providing a
simple and intuitive way to deal with the non-convex nature of this
optimisation problem. Numerical results demonstrate the ability of the proposed
framework to accommodate EMMs with different properties of individual
functions, and also verify the robustness and flexibility of the proposed
framework over the standard GMM.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_S/0/1/0/all/0/1&quot;&gt;Shengxi Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mandic_D/0/1/0/all/0/1&quot;&gt;Danilo P. Mandic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_Z/0/1/0/all/0/1&quot;&gt;Zeyang Yu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08052">
<title>Online Learning in Kernelized Markov Decision Processes. (arXiv:1805.08052v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.08052</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider online learning for minimizing regret in unknown, episodic Markov
decision processes (MDPs) with continuous states and actions. We develop
variants of the UCRL and posterior sampling algorithms that employ
nonparametric Gaussian process priors to generalize across the state and action
spaces. When the transition and reward functions of the true MDP are either
sampled from Gaussian process priors (fully Bayesian setting) or are members of
the associated Reproducing Kernel Hilbert Spaces of functions induced by
symmetric psd kernels (frequentist setting), we show that the algorithms enjoy
sublinear regret bounds. The bounds are in terms of explicit structural
parameters of the kernels, namely a novel generalization of the information
gain metric from kernelized bandit, and highlight the influence of transition
and reward function structure on the learning performance. Our results are
applicable to multi-dimensional state and action spaces with composite kernel
structures, and generalize results from the literature on kernelized bandits,
and the adaptive control of parametric linear dynamical systems with quadratic
costs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chowdhury_S/0/1/0/all/0/1&quot;&gt;Sayak Ray Chowdhury&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gopalan_A/0/1/0/all/0/1&quot;&gt;Aditya Gopalan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08058">
<title>Super Learning in the SAS system. (arXiv:1805.08058v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.08058</link>
<description rdf:parseType="Literal">&lt;p&gt;Background and objective: Stacking is an ensemble machine learning method
that averages predictions from multiple other algorithms, such as generalized
linear models and regression trees. A recent iteration of stacking, called
super learning, has been developed as a general approach to black box learning
and has seen frequent usage, in part due to the availability of an R package. I
develop super learning in the SAS software system using a new macro, and
demonstrate its performance relative to the R package.
&lt;/p&gt;
&lt;p&gt;Methods: I follow closely previous work using the R SuperLearner package and
assess the performance of super learning in a number of domains. I compare the
R package with the new SAS macro in a small set of simulations assessing curve
fitting in a prediction model, a set of 14 publicly available datasets to
assess cross-validated, expected loss, and data from a randomized trial of job
seekers&apos; training to assess the utility of super learning in causal inference
using inverse probability weighting.
&lt;/p&gt;
&lt;p&gt;Results: Across the simulated data and the publicly available data, the macro
performed similarly to the R package, even with a different set of potential
algorithms available natively in R and SAS. The example with inverse
probability weighting demonstrated the ability of the SAS macro to include
algorithms developed in R.
&lt;/p&gt;
&lt;p&gt;Conclusions: The super learner macro performs as well as the R package at a
number of tasks. Further, by extending the macro to include the use of R
packages, the macro can leverage both the the robust, enterprise oriented
procedures in SAS and the nimble, cutting edge packages in R. In the spirit of
ensemble learning, this macro extends the potential library of algorithms
beyond a single software system and provides a simple avenue into machine
learning in SAS.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Keil_A/0/1/0/all/0/1&quot;&gt;Alexander P Keil&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08061">
<title>NEWMA: a new method for scalable model-free online change-point detection. (arXiv:1805.08061v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.08061</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the problem of detecting abrupt changes in the distribution of a
multi-dimensional time series, with limited computing power and memory. In this
paper, we propose a new method for model-free online change-point detection
that relies only on fast and light recursive statistics, inspired by the
classical Exponential Weighted Moving Average algorithm (EWMA). The proposed
idea is to compute two EWMA statistics on the stream of data with different
forgetting factors, and to compare them. By doing so, we show that we
implicitly compare recent samples with older ones, without the need to
explicitly store them. Additionally, we leverage Random Features to efficiently
use the Maximum Mean Discrepancy as a distance between distributions. We show
that our method is orders of magnitude faster than usual non-parametric methods
for a given accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Keriven_N/0/1/0/all/0/1&quot;&gt;Nicolas Keriven&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garreau_D/0/1/0/all/0/1&quot;&gt;Damien Garreau&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Poli_I/0/1/0/all/0/1&quot;&gt;Iacopo Poli&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08102">
<title>Non-Oscillatory Pattern Learning for Non-Stationary Signals. (arXiv:1805.08102v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.08102</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper proposes a novel non-oscillatory pattern (NOP) learning scheme for
several oscillatory data analysis problems including signal decomposition,
super-resolution, and signal sub-sampling. To the best of our knowledge, the
proposed NOP is the first algorithm for these problems with fully
non-stationary oscillatory data with close and crossover frequencies, and
general oscillatory patterns. Even in stationary cases with trigonometric
patterns, numerical examples show that NOP admits competitive or better
performance in terms of accuracy and robustness than several state-of-the-art
algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Xu_J/0/1/0/all/0/1&quot;&gt;Jieren Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yitong Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Dunson_D/0/1/0/all/0/1&quot;&gt;David Dunson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Daubechies_I/0/1/0/all/0/1&quot;&gt;Ingrid Daubechies&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yang_H/0/1/0/all/0/1&quot;&gt;Haizhao Yang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08114">
<title>On the Convergence of Stochastic Gradient Descent with Adaptive Stepsizes. (arXiv:1805.08114v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1805.08114</link>
<description rdf:parseType="Literal">&lt;p&gt;Stochastic gradient descent is the method of choice for large scale
optimization of machine learning objective functions. Yet, its performance is
greatly variable and heavily depends on the choice of the stepsizes. This has
motivated a large body of research on adaptive stepsizes. However, there is
currently a gap in our theoretical understanding of these methods, especially
in the non-convex setting. In this paper, we start closing this gap: we
theoretically analyze the use of adaptive stepsizes, like the ones in AdaGrad,
in the non-convex setting. We show sufficient conditions for almost sure
convergence to a stationary point when the adaptive stepsizes are used, proving
the first guarantee for AdaGrad in the non-convex setting. Moreover, we show
explicit rates of convergence that automatically interpolates between $O(1/T)$
and $O(1/\sqrt{T})$ depending on the noise of the stochastic gradients, in both
the convex and non-convex setting.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xiaoyu Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Orabona_F/0/1/0/all/0/1&quot;&gt;Francesco Orabona&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08140">
<title>A New Lower Bound for Agnostic Learning with Sample Compression Schemes. (arXiv:1805.08140v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.08140</link>
<description rdf:parseType="Literal">&lt;p&gt;We establish a tight characterization of the worst-case rates for the excess
risk of agnostic learning with sample compression schemes and for uniform
convergence for agnostic sample compression schemes. In particular, we find
that the optimal rates of convergence for size-$k$ agnostic sample compression
schemes are of the form $\sqrt{\frac{k \log(n/k)}{n}}$, which contrasts with
agnostic learning with classes of VC dimension $k$, where the optimal rates are
of the form $\sqrt{\frac{k}{n}}$.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hanneke_S/0/1/0/all/0/1&quot;&gt;Steve Hanneke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kontorovich_A/0/1/0/all/0/1&quot;&gt;Aryeh Kontorovich&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08166">
<title>Learning to Optimize Tensor Programs. (arXiv:1805.08166v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.08166</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce a learning-based framework to optimize tensor programs for deep
learning workloads. Efficient implementations of tensor operators, such as
matrix multiplication and high dimensional convolution, are key enablers of
effective deep learning systems. However, existing systems rely on manually
optimized libraries such as cuDNN where only a narrow range of server class
GPUs are well-supported. The reliance on hardware-specific operator libraries
limits the applicability of high-level graph optimizations and incurs
significant engineering costs when deploying to new hardware targets. We use
learning to remove this engineering burden. We learn domain-specific
statistical cost models to guide the search of tensor operator implementations
over billions of possible program variants. We further accelerate the search by
effective model transfer across workloads. Experimental results show that our
framework delivers performance competitive with state-of-the-art hand-tuned
libraries for low-power CPU, mobile GPU, and server-class GPU.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1&quot;&gt;Tianqi Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_L/0/1/0/all/0/1&quot;&gt;Lianmin Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yan_E/0/1/0/all/0/1&quot;&gt;Eddie Yan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_Z/0/1/0/all/0/1&quot;&gt;Ziheng Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moreau_T/0/1/0/all/0/1&quot;&gt;Thierry Moreau&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ceze_L/0/1/0/all/0/1&quot;&gt;Luis Ceze&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guestrin_C/0/1/0/all/0/1&quot;&gt;Carlos Guestrin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Krishnamurthy_A/0/1/0/all/0/1&quot;&gt;Arvind Krishnamurthy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08193">
<title>Masking: A New Perspective of Noisy Supervision. (arXiv:1805.08193v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.08193</link>
<description rdf:parseType="Literal">&lt;p&gt;It is important to learn classifiers under noisy labels due to their
ubiquities. As noisy labels are corrupted from ground-truth labels by an
unknown noise transition matrix, the accuracy of classifiers can be improved by
estimating this matrix, without introducing either sample-selection or
regularization biases. However, such estimation is often inexact, which
inevitably degenerates the accuracy of classifiers. The inexact estimation is
due to either a heuristic trick, or the brutal-force learning by deep networks
under a finite dataset. In this paper, we present a human-assisted approach
called &quot;\textit{masking}&quot;. The masking conveys human cognition of invalid class
transitions, and naturally speculates the structure of the noise transition
matrix. Given the structure information, we only learn the noise transition
probability to reduce the estimation burden. To instantiate this approach, we
derive a structure-aware probabilistic model, which incorporates a structure
prior. During the model realization, we solve the challenges from structure
extraction and alignment in principle. Empirical results on benchmark datasets
with three noise structures show that, our approach can improve the robustness
of classifiers significantly.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Han_B/0/1/0/all/0/1&quot;&gt;Bo Han&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yao_J/0/1/0/all/0/1&quot;&gt;Jiangchao Yao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Niu_G/0/1/0/all/0/1&quot;&gt;Gang Niu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_M/0/1/0/all/0/1&quot;&gt;Mingyuan Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tsang_I/0/1/0/all/0/1&quot;&gt;Ivor Tsang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Ya Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sugiyama_M/0/1/0/all/0/1&quot;&gt;Masashi Sugiyama&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08196">
<title>Learning Maximum-A-Posteriori Perturbation Models for Structured Prediction in Polynomial Time. (arXiv:1805.08196v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.08196</link>
<description rdf:parseType="Literal">&lt;p&gt;MAP perturbation models have emerged as a powerful framework for inference in
structured prediction. Such models provide a way to efficiently sample from the
Gibbs distribution and facilitate predictions that are robust to random noise.
In this paper, we propose a provably polynomial time randomized algorithm for
learning the parameters of perturbed MAP predictors. Our approach is based on
minimizing a novel Rademacher-based generalization bound on the expected loss
of a perturbed MAP predictor, which can be computed in polynomial time. We
obtain conditions under which our randomized learning algorithm can guarantee
generalization to unseen examples.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ghoshal_A/0/1/0/all/0/1&quot;&gt;Asish Ghoshal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Honorio_J/0/1/0/all/0/1&quot;&gt;Jean Honorio&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08206">
<title>Boosting Uncertainty Estimation for Deep Neural Classifiers. (arXiv:1805.08206v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1805.08206</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the problem of uncertainty estimation in the context of
(non-Bayesian) deep neural classification. All current methods are based on
extracting uncertainty signals from a trained network optimized to solve the
classification problem at hand. We demonstrate that such techniques tend to
misestimate instances whose predictions are supposed to be highly confident.
This deficiency is an artifact of the training process with SGD-like
optimizers. Based on this observation, we develop an uncertainty estimation
algorithm that &quot;peels away&quot; highly confident points sequentially and estimates
their confidence using earlier snapshots of the trained model, before their
uncertainty estimates are jittered. We present extensive experiments indicating
that the proposed algorithm provides uncertainty estimates that are
consistently better than the best known methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Geifman_Y/0/1/0/all/0/1&quot;&gt;Yonatan Geifman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Uziel_G/0/1/0/all/0/1&quot;&gt;Guy Uziel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+El_Yaniv_R/0/1/0/all/0/1&quot;&gt;Ran El-Yaniv&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1512.08064">
<title>Statistical Learning under Nonstationary Mixing Processes. (arXiv:1512.08064v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1512.08064</link>
<description rdf:parseType="Literal">&lt;p&gt;We study a special case of the problem of statistical learning without the
i.i.d. assumption. Specifically, we suppose a learning method is presented with
a sequence of data points, and required to make a prediction (e.g., a
classification) for each one, and can then observe the loss incurred by this
prediction. We go beyond traditional analyses, which have focused on stationary
mixing processes or nonstationary product processes, by combining these two
relaxations to allow nonstationary mixing processes. We are particularly
interested in the case of $\beta$-mixing processes, with the sum of changes in
marginal distributions growing sublinearly in the number of samples. Under
these conditions, we propose a learning method, and establish that for bounded
VC subgraph classes, the cumulative excess risk grows sublinearly in the number
of predictions, at a quantified rate.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hanneke_S/0/1/0/all/0/1&quot;&gt;Steve Hanneke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1&quot;&gt;Liu Yang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1707.09049">
<title>Variational Joint Filtering. (arXiv:1707.09049v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1707.09049</link>
<description rdf:parseType="Literal">&lt;p&gt;State space models provide an interpretable framework for complex time series
by combining an intuitive dynamical system model with a probabilistic
observation model. We developed a flexible online learning framework for latent
nonlinear state dynamics and filtered latent states. Our method utilizes the
stochastic gradient variational Bayes method to jointly optimize the parameters
of the nonlinear dynamics, observation model, and the black-box recognition
model. Unlike previous approaches, our framework can incorporate non-trivial
observation noise models and has potential of inferring in real-time. We test
our method on point process and Gaussian observations driven by continuous
attractor dynamics and nonstationary systems, demonstrating its ability to
recover the phase portrait, filtered trajectory, and produce long-term
predictions for online machine learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhao_Y/0/1/0/all/0/1&quot;&gt;Yuan Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Park_I/0/1/0/all/0/1&quot;&gt;Il Memming Park&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1708.08826">
<title>Improved Support Recovery Guarantees for the Group Lasso With Applications to Structural Health Monitoring. (arXiv:1708.08826v2 [cs.IT] UPDATED)</title>
<link>http://arxiv.org/abs/1708.08826</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper considers the problem of estimating an unknown high dimensional
signal from noisy linear measurements, {when} the signal is assumed to possess
a \emph{group-sparse} structure in a {known,} fixed dictionary. We consider
signals generated according to a natural probabilistic model, and establish new
conditions under which the set of indices of the non-zero groups of the signal
(called the group-level support) may be accurately estimated via the group
Lasso. Our results strengthen existing coherence-based analyses that exhibit
the well-known &quot;square root&quot; bottleneck, allowing for the number of recoverable
nonzero groups to be nearly as large as the total number of groups. We also
establish a sufficient recovery condition relating the number of nonzero groups
and the signal to noise ratio (quantified in terms of the ratio of the squared
Euclidean norms of nonzero groups and the variance of the random additive
{measurement} noise), and validate this trend empirically. Finally, we examine
the implications of our results in the context of a structural health
monitoring application, where the group Lasso approach facilitates demixing of
a propagating acoustic wavefield, acquired on the material surface by a
scanning laser Doppler vibrometer, into antithetical components, one of which
indicates the locations of internal material defects.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Elyaderani_M/0/1/0/all/0/1&quot;&gt;Mojtaba Kadkhodaie Elyaderani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jain_S/0/1/0/all/0/1&quot;&gt;Swayambhoo Jain&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Druce_J/0/1/0/all/0/1&quot;&gt;Jeffrey Druce&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gonella_S/0/1/0/all/0/1&quot;&gt;Stefano Gonella&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Haupt_J/0/1/0/all/0/1&quot;&gt;Jarvis Haupt&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.02893">
<title>Convolutional Dictionary Learning: A Comparative Review and New Algorithms. (arXiv:1709.02893v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1709.02893</link>
<description rdf:parseType="Literal">&lt;p&gt;Convolutional sparse representations are a form of sparse representation with
a dictionary that has a structure that is equivalent to convolution with a set
of linear filters. While effective algorithms have recently been developed for
the convolutional sparse coding problem, the corresponding dictionary learning
problem is substantially more challenging. Furthermore, although a number of
different approaches have been proposed, the absence of thorough comparisons
between them makes it difficult to determine which of them represents the
current state of the art. The present work both addresses this deficiency and
proposes some new approaches that outperform existing ones in certain contexts.
A thorough set of performance comparisons indicates a very wide range of
performance differences among the existing and proposed methods, and clearly
identifies those that are the most effective.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garcia_Cardona_C/0/1/0/all/0/1&quot;&gt;Cristina Garcia-Cardona&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wohlberg_B/0/1/0/all/0/1&quot;&gt;Brendt Wohlberg&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.03528">
<title>GIANT: Globally Improved Approximate Newton Method for Distributed Optimization. (arXiv:1709.03528v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1709.03528</link>
<description rdf:parseType="Literal">&lt;p&gt;For distributed computing environment, we consider the empirical risk
minimization problem and propose a distributed and communication-efficient
Newton-type optimization method. At every iteration, each worker locally finds
an Approximate NewTon (ANT) direction, which is sent to the main driver. The
main driver, then, averages all the ANT directions received from workers to
form a {\it Globally Improved ANT} (GIANT) direction. GIANT is highly
communication efficient and naturally exploits the trade-offs between local
computations and global communications in that more local computations result
in fewer overall rounds of communications. Theoretically, we show that GIANT
enjoys an improved convergence rate as compared with first-order methods and
existing distributed Newton-type methods. Further, and in sharp contrast with
many existing distributed Newton-type methods, as well as popular first-order
methods, a highly advantageous practical feature of GIANT is that it only
involves one tuning parameter. We conduct large-scale experiments on a computer
cluster and, empirically, demonstrate the superior performance of GIANT.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_S/0/1/0/all/0/1&quot;&gt;Shusen Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roosta_Khorasani_F/0/1/0/all/0/1&quot;&gt;Farbod Roosta-Khorasani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_P/0/1/0/all/0/1&quot;&gt;Peng Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mahoney_M/0/1/0/all/0/1&quot;&gt;Michael W. Mahoney&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.08862">
<title>Bayesian Inference of Spreading Processes on Networks. (arXiv:1709.08862v3 [stat.AP] UPDATED)</title>
<link>http://arxiv.org/abs/1709.08862</link>
<description rdf:parseType="Literal">&lt;p&gt;Infectious diseases are studied to understand their spreading mechanisms, to
evaluate control strategies and to predict the risk and course of future
outbreaks. Because people only interact with a small number of individuals, and
because the structure of these interactions matters for spreading processes,
the pairwise relationships between individuals in a population can be usefully
represented by a network. Although the underlying processes of transmission are
different, the network approach can be used to study the spread of pathogens in
a contact network or the spread of rumors in an online social network. We study
simulated simple and complex epidemics on synthetic networks and on two
empirical networks, a social / contact network in an Indian village and an
online social network in the U.S. Our goal is to learn simultaneously about the
spreading process parameters and the source node (first infected node) of the
epidemic, given a fixed and known network structure, and observations about
state of nodes at several points in time. Our inference scheme is based on
approximate Bayesian computation (ABC), an inference technique for complex
models with likelihood functions that are either expensive to evaluate or
analytically intractable. ABC enables us to adopt a Bayesian approach to the
problem despite the posterior distribution being very complex. Our method is
agnostic about the topology of the network and the nature of the spreading
process. It generally performs well and, somewhat counter-intuitively, the
inference problem appears to be easier on more heterogeneous network
topologies, which enhances its future applicability to real-world settings
where few networks have homogeneous topologies.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Dutta_R/0/1/0/all/0/1&quot;&gt;Ritabrata Dutta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mira_A/0/1/0/all/0/1&quot;&gt;Antonietta Mira&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Onnela_J/0/1/0/all/0/1&quot;&gt;Jukka-Pekka Onnela&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.09953">
<title>The Error Probability of Random Fourier Features is Dimensionality Independent. (arXiv:1710.09953v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1710.09953</link>
<description rdf:parseType="Literal">&lt;p&gt;We show that the error probability of reconstructing kernel matrices from
Random Fourier Features for the Gaussian kernel function is at most
$\mathcal{O}(R^{2/3} \exp(-D))$, where $D$ is the number of random features and
$R$ is the diameter of the data domain. We also provide an
information-theoretic method-independent lower bound of $\Omega((1-\exp(-R^2))
\exp(-D))$. Compared to prior work, we are the first to show that the error
probability for random Fourier features is independent of the dimensionality of
data points. As applications of our theory, we obtain dimension-independent
bounds for kernel ridge regression and support vector machines.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Honorio_J/0/1/0/all/0/1&quot;&gt;Jean Honorio&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yu-Jun Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.01682">
<title>Estimation of Low-Rank Matrices via Approximate Message Passing. (arXiv:1711.01682v3 [math.ST] UPDATED)</title>
<link>http://arxiv.org/abs/1711.01682</link>
<description rdf:parseType="Literal">&lt;p&gt;Consider the problem of estimating a low-rank symmetric matrix when its
entries are perturbed by Gaussian noise, a setting that is known as `spiked
model&apos; or `deformed Wigner matrix&apos;. If the empirical distribution of the
entries of the spikes is known, optimal estimators that exploit this knowledge
can substantially outperform spectral approaches. Recent work characterizes the
accuracy of Bayes-optimal estimators in the high-dimensional limit. In this
paper we present a practical algorithm that can achieve Bayes-optimal accuracy
above the spectral threshold. A bold conjecture from statistical physics posits
that no polynomial-time algorithm achieves optimal error below the same
threshold (unless the best estimator is trivial). Our approach uses Approximate
Message Passing (AMP) in conjunction with a spectral initialization. AMP has
proven successful in a variety of statistical problem, and are amenable to
exact asymptotic analysis via state evolution. Unfortunately, state evolution
is uninformative when the algorithm is initialized near an unstable fixed
point, as it often happens in matrix estimation. We develop a new analysis of
AMP that allows for spectral initializations, and builds on a decoupling
between the outlier eigenvectors and the bulk in the spiked random matrix
model. Our main theorem is general and applies beyond matrix estimation.
However, we use it to derive detailed predictions for the problem of estimating
a rank-one matrix in noise. Special cases of these problem are closely related
-via universality arguments- to the network community detection problem for two
asymmetric communities. For general rank-one models, we show that AMP can be
used to construct asymptotically valid confidence intervals. As a further
illustration, we consider the example of a block-constant low-rank matrix with
symmetric blocks, which we refer to as `Gaussian Block Model&apos;.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Montanari_A/0/1/0/all/0/1&quot;&gt;Andrea Montanari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Venkataramanan_R/0/1/0/all/0/1&quot;&gt;Ramji Venkataramanan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.02613">
<title>Moonshine: Distilling with Cheap Convolutions. (arXiv:1711.02613v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1711.02613</link>
<description rdf:parseType="Literal">&lt;p&gt;Many engineers wish to deploy modern neural networks in memory-limited
settings; but the development of flexible methods for reducing memory use is in
its infancy, and there is little knowledge of the resulting cost-benefit. We
propose structural model distillation for memory reduction using a strategy
that produces a student architecture that is a simple transformation of the
teacher architecture: no redesign is needed, and the same hyperparameters can
be used. Using attention transfer, we provide Pareto curves/tables for
distillation of residual networks with four benchmark datasets, indicating the
memory versus accuracy payoff. We show that substantial memory savings are
possible with very little loss of accuracy, and confirm that distillation
provides student network performance that is better than training that student
architecture directly on data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Crowley_E/0/1/0/all/0/1&quot;&gt;Elliot J. Crowley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gray_G/0/1/0/all/0/1&quot;&gt;Gavin Gray&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Storkey_A/0/1/0/all/0/1&quot;&gt;Amos Storkey&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.02294">
<title>Learning Tree-based Deep Model for Recommender Systems. (arXiv:1801.02294v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1801.02294</link>
<description rdf:parseType="Literal">&lt;p&gt;Model-based methods for recommender systems have been studied extensively in
recent years. In systems with large corpus, however, the calculation cost for
the learnt model to predict all user-item preferences is tremendous, which
makes full corpus retrieval extremely difficult. To overcome the calculation
barriers, models such as matrix factorization resort to inner product form
(i.e., model user-item preference as the inner product of user, item latent
factors) and indexes to facilitate efficient approximate k-nearest neighbor
searches. However, it still remains challenging to incorporate more expressive
interaction forms between user and item features, e.g., interactions through
deep neural networks, because of the calculation cost.
&lt;/p&gt;
&lt;p&gt;In this paper, we focus on the problem of introducing arbitrary advanced
models to recommender systems with large corpus. We propose a novel tree-based
method which can provide logarithmic complexity w.r.t. corpus size even with
more expressive models such as deep neural networks. Our main idea is to
predict user interests from coarse to fine by traversing tree nodes in a
top-down fashion and making decisions for each user-node pair. We also show
that the tree structure can be jointly learnt towards better compatibility with
users&apos; interest distribution and hence facilitate both training and prediction.
Experimental evaluations with two large-scale real-world datasets show that the
proposed method significantly outperforms traditional methods. Online A/B test
results in Taobao display advertising platform also demonstrate the
effectiveness of the proposed method in production environments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhu_H/0/1/0/all/0/1&quot;&gt;Han Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xiang Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhang_P/0/1/0/all/0/1&quot;&gt;Pengye Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Li_G/0/1/0/all/0/1&quot;&gt;Guozheng Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+He_J/0/1/0/all/0/1&quot;&gt;Jie He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Li_H/0/1/0/all/0/1&quot;&gt;Han Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gai_K/0/1/0/all/0/1&quot;&gt;Kun Gai&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.07691">
<title>Drug Selection via Joint Push and Learning to Rank. (arXiv:1801.07691v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1801.07691</link>
<description rdf:parseType="Literal">&lt;p&gt;Selecting the right drugs for the right patients is a primary goal of
precision medicine. In this manuscript, we consider the problem of cancer drug
selection in a learning-to-rank framework. We have formulated the cancer drug
selection problem as to accurately predicting 1). the ranking positions of
sensitive drugs and 2). the ranking orders among sensitive drugs in cancer cell
lines based on their responses to cancer drugs. We have developed a new
learning-to-rank method, denoted as pLETORg , that predicts drug ranking
structures in each cell line via using drug latent vectors and cell line latent
vectors. The pLETORg method learns such latent vectors through explicitly
enforcing that, in the drug ranking list of each cell line, the sensitive drugs
are pushed above insensitive drugs, and meanwhile the ranking orders among
sensitive drugs are correct. Genomics information on cell lines is leveraged in
learning the latent vectors. Our experimental results on a benchmark cell
line-drug response dataset demonstrate that the new pLETORg significantly
outperforms the state-of-the-art method in prioritizing new sensitive drugs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_Y/0/1/0/all/0/1&quot;&gt;Yicheng He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Junfeng Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ning_X/0/1/0/all/0/1&quot;&gt;Xia Ning&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.03497">
<title>Modeling Dynamics with Deep Transition-Learning Networks. (arXiv:1802.03497v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1802.03497</link>
<description rdf:parseType="Literal">&lt;p&gt;We present an approach to learning Markovian dynamics, specifically the
transition (next-state) vector field of a stochastic dynamic system, using a
neural network model that we call the transcoder. Focusing on the stochastic
transition has several advantages in biology including next-state prediction
from current measurements (when history is not available), generation of
stochastic trajectories, and a model of transitions that allows us to predict
interactions. In addition, here we propose to utilize the neural network itself
as a white-box model to examine features of the dynamic process such as
identifying features that most control transitions in parts of the data space.
We validate our method on systems such as a single and a double pendulum, Frey
faces trajectories, and MCMC sampling of a Gaussian Mixture Model. We then
apply it to single-cell data of T-cell development and neuronal calcium imaging
data of mice presented with a visual stimulus.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dijk_D/0/1/0/all/0/1&quot;&gt;David van Dijk&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gigante_S/0/1/0/all/0/1&quot;&gt;Scott Gigante&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moon_K/0/1/0/all/0/1&quot;&gt;Kevin Moon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Strzalkowski_A/0/1/0/all/0/1&quot;&gt;Alexander Strzalkowski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ferguson_K/0/1/0/all/0/1&quot;&gt;Katie Ferguson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cardin_J/0/1/0/all/0/1&quot;&gt;Jess Cardin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wolf_G/0/1/0/all/0/1&quot;&gt;Guy Wolf&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Krishnaswamy_S/0/1/0/all/0/1&quot;&gt;Smita Krishnaswamy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.03644">
<title>Learning to Match via Inverse Optimal Transport. (arXiv:1802.03644v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1802.03644</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a unified data-driven framework based on inverse optimal transport
that can learn adaptive, nonlinear interaction cost function from noisy and
incomplete empirical matching matrix and predict new matching in various
matching contexts. We emphasize that the discrete optimal transport plays the
role of a variational principle which gives rise to an optimization based
framework for modeling the observed empirical matching data. Our formulation
leads to a non-convex optimiza- tion problem which can be solved efficiently by
an alternating optimization method. A key novel aspect of our formulation is
the incorporation of marginal relaxation via regularized Wasserstein distance,
significantly improving the robustness of the method in the face of noisy or
missing empirical matching data. Our model has wide applicability including
predicting matching in online dating, labor market, college application and
crowdsourcing. We back up our claims with numerical experiments on both
synthetic data and real world datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Li_R/0/1/0/all/0/1&quot;&gt;Ruilin Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ye_X/0/1/0/all/0/1&quot;&gt;Xiaojing Ye&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhou_H/0/1/0/all/0/1&quot;&gt;Haomin Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zha_H/0/1/0/all/0/1&quot;&gt;Hongyuan Zha&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04477">
<title>A Simple Proximal Stochastic Gradient Method for Nonsmooth Nonconvex Optimization. (arXiv:1802.04477v2 [math.OC] UPDATED)</title>
<link>http://arxiv.org/abs/1802.04477</link>
<description rdf:parseType="Literal">&lt;p&gt;We analyze stochastic gradient algorithms for optimizing nonconvex, nonsmooth
finite-sum problems. In particular, the objective function is given by the
summation of a differentiable (possibly nonconvex) component, together with a
possibly non-differentiable but convex component. We propose a proximal
stochastic gradient algorithm based on variance reduction, called ProxSVRG+.
Our main contribution lies in the analysis of ProxSVRG+. It recovers several
existing convergence results (in terms of the number of stochastic gradient
oracle calls and proximal operations), and improves/generalizes them. In
particular, ProxSVRG+ generalizes the best results given by the SCSG
(stochastically controlled stochastic gradient) algorithm, recently proposed by
[Lei et al., NIPS&apos;17] for the smooth nonconvex case. ProxSVRG+ is more
straightforward than SCSG and yields simpler analysis. Moreover, ProxSVRG+
outperforms the deterministic proximal gradient descent (ProxGD) for a wide
range of minibatch sizes, which partially solves an open problem proposed in
[Reddi et al., NIPS&apos;16]. Also, ProxSVRG+ uses much less proximal oracle calls
than ProxSVRG [Reddi et al., NIPS&apos;16] if the minibatch size $b&amp;lt;n^{2/3}$.
Besides, for nonconvex functions satisfied Polyak-\L{}ojasiewicz condition, we
show that ProxSVRG+ achieves a global linear convergence rate without restart
unlike ProxSVRG. ProxSVRG+ also improves ProxGD and ProxSVRG/SAGA, and
generalizes the results of SCSG in this case. Finally, we conduct several
numerical experiments and the experimental results are consistent with the
theoretical results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Zhize Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jian Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04944">
<title>Edge Attention-based Multi-Relational Graph Convolutional Networks. (arXiv:1802.04944v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1802.04944</link>
<description rdf:parseType="Literal">&lt;p&gt;Graph convolutional network (GCN) is generalization of convolutional neural
network (CNN) to work with arbitrarily structured graphs. A binary adjacency
matrix is commonly used in training a GCN. Recently, the attention mechanism
allows the network to learn a dynamic and adaptive aggregation of the
neighborhood. We propose a new GCN model on the graphs where edges are
characterized in multiple views or precisely in terms of multiple
relationships. For instance, in chemical graph theory, compound structures are
often represented by the hydrogen-depleted molecular graph where nodes
correspond to atoms and edges correspond to chemical bonds. Multiple attributes
can be important to characterize chemical bonds, such as atom pair (the types
of atoms that a bond connects), aromaticity, and whether a bond is in a ring.
The different attributes lead to different graph representations for the same
molecule. There is growing interests in both chemistry and machine learning
fields to directly learn molecular properties of compounds from the molecular
graph, instead of from fingerprints predefined by chemists. The proposed GCN
model, which we call edge attention-based multi-relational GCN (EAGCN), jointly
learns attention weights and node features in graph convolution. For each bond
attribute, a real-valued attention matrix is used to replace the binary
adjacency matrix. By designing a dictionary for the edge attention, and forming
the attention matrix of each molecule by looking up the dictionary, the EAGCN
exploits correspondence between bonds in different molecules. The prediction of
compound properties is based on the aggregated node features, which is
independent of the varying molecule (graph) size. We demonstrate the efficacy
of the EAGCN on multiple chemical datasets: Tox21, HIV, Freesolv, and
Lipophilicity, and interpret the resultant attention weights.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Shang_C/0/1/0/all/0/1&quot;&gt;Chao Shang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Liu_Q/0/1/0/all/0/1&quot;&gt;Qinqing Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chen_K/0/1/0/all/0/1&quot;&gt;Ko-Shin Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sun_J/0/1/0/all/0/1&quot;&gt;Jiangwen Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lu_J/0/1/0/all/0/1&quot;&gt;Jin Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yi_J/0/1/0/all/0/1&quot;&gt;Jinfeng Yi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bi_J/0/1/0/all/0/1&quot;&gt;Jinbo Bi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05811">
<title>Distributed Stochastic Optimization via Adaptive Stochastic Gradient Descent. (arXiv:1802.05811v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1802.05811</link>
<description rdf:parseType="Literal">&lt;p&gt;Stochastic convex optimization algorithms are the most popular way to train
machine learning models on large-scale data. Scaling up the training process of
these models is crucial in many applications, but the most popular algorithm,
Stochastic Gradient Descent (SGD), is a serial algorithm that is surprisingly
hard to parallelize. In this paper, we propose an efficient distributed
stochastic optimization method based on adaptive step sizes and variance
reduction techniques. We achieve a linear speedup in the number of machines,
small memory footprint, and only a small number of synchronization rounds --
logarithmic in dataset size -- in which the computation nodes communicate with
each other. Critically, our approach is a general reduction than parallelizes
any serial SGD algorithm, allowing us to leverage the significant progress that
has been made in designing adaptive SGD algorithms. We conclude by implementing
our algorithm in the Spark distributed framework and exhibit dramatic
performance gains on large-scale logistic regression problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Cutkosky_A/0/1/0/all/0/1&quot;&gt;Ashok Cutkosky&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Busa_Fekete_R/0/1/0/all/0/1&quot;&gt;Robert Busa-Fekete&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.07024">
<title>Selective Classification via Curve Optimization. (arXiv:1802.07024v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1802.07024</link>
<description rdf:parseType="Literal">&lt;p&gt;In practical applications of machine learning, it is often desirable to
identify and abstain on examples where the model&apos;s predictions are likely to be
incorrect. We consider the problem of selecting a budget-constrained subset of
test examples to abstain on, with the goal of maximizing performance on the
remaining examples. We develop a novel approach to this problem by analytically
optimizing the expected marginal improvement in a desired performance metric,
such as the area under the ROC curve or Precision-Recall curve. We compare our
approach to other abstention techniques for deep learning models based on
posterior probability and uncertainty estimates obtained using test-time
dropout. On various tasks in computer vision, natural language processing, and
bioinformatics, we demonstrate the consistent effectiveness of our approach
over other techniques.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Alexandari_A/0/1/0/all/0/1&quot;&gt;Amr Alexandari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Shrikumar_A/0/1/0/all/0/1&quot;&gt;Avanti Shrikumar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kundaje_A/0/1/0/all/0/1&quot;&gt;Anshul Kundaje&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08407">
<title>Exponentially Consistent Kernel Two-Sample Tests. (arXiv:1802.08407v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1802.08407</link>
<description rdf:parseType="Literal">&lt;p&gt;Given two sets of independent samples from unknown distributions $P$ and $Q$,
a two-sample test decides whether to reject the null hypothesis that $P=Q$.
Recent attention has focused on kernel two-sample tests as the test statistics
are easy to compute, converge fast, and have low bias with their finite sample
estimates. However, there still lacks an exact characterization on the
asymptotic performance of such tests, and in particular, the rate at which the
type-II error probability decays to zero in the large sample limit. In this
work, we establish that a class of kernel two-sample tests are exponentially
consistent with Polish, locally compact Hausdorff sample space, e.g., $\mathbb
R^d$. The obtained exponential decay rate is further shown to be optimal among
all two-sample tests satisfying the level constraint, and is independent of
particular kernels provided that they are bounded continuous and
characteristic. Our results gain new insights into related issues such as fair
alternative for testing and kernel selection strategy. Finally, as an
application, we show that a kernel based test achieves the optimal detection
for off-line change detection in the nonparametric setting.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhu_S/0/1/0/all/0/1&quot;&gt;Shengyu Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chen_B/0/1/0/all/0/1&quot;&gt;Biao Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chen_Z/0/1/0/all/0/1&quot;&gt;Zhitang Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09064">
<title>Model Agnostic Time Series Analysis via Matrix Estimation. (arXiv:1802.09064v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1802.09064</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose an algorithm to interpolate and forecast a time series by
transforming the observed time series into a matrix, utilizing matrix
estimation to recover missing values and de-noise observed entries, and
performing linear regression to make pre- dictions. This algorithm is a
consequence of a surprising and powerful link that we establish between (a
single) time series data and matrix estimation. Subsequently, our algorithm is
model agnostic with respect to the time dynamics and noise in the observations
(similar to the recent matrix estimation literature). In particular, our method
simultaneously provides meaningful imputation and prediction for a large class
of models: finite sum of harmonics (which approximate stationary processes),
non-stationary sublinear trends, Linear Time-Invariant (LTI) systems, and their
additive mixtures. It is noteworthy that this simple linear forecaster coupled
with matrix estimation comes with strong theoretical and experimental results.
Due to the noise agnostic nature, our algorithm recovers the hidden state of
sequential dynamics in settings where Expectation Maximization (EM) like
approaches are often used, but have little or no theoretical guarantees.
Through synthetic and real- world datasets, we demonstrate that our algorithm
outperforms standard software packages (including R libraries) in the presence
of missing data as well as high levels of noise. Moreover, when the packages -
but not our algorithm - are given the underlying model, our algorithm still
outperforms the standard packages.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Agarwal_A/0/1/0/all/0/1&quot;&gt;Anish Agarwal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Amjad_M/0/1/0/all/0/1&quot;&gt;Muhammad Jehangir Amjad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shah_D/0/1/0/all/0/1&quot;&gt;Devavrat Shah&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_D/0/1/0/all/0/1&quot;&gt;Dennis Shen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.10501">
<title>Predictive Uncertainty Estimation via Prior Networks. (arXiv:1802.10501v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1802.10501</link>
<description rdf:parseType="Literal">&lt;p&gt;Estimating how uncertain an AI system is in its predictions is important to
improve the safety of such systems. Uncertainty in predictive can result from
uncertainty in model parameters, irreducible data uncertainty and uncertainty
due to distributional mismatch between the test and training data
distributions. Different actions might be taken depending on the source of the
uncertainty so it is important to be able to distinguish between them.
Recently, baseline tasks and metrics have been defined and several practical
methods to estimate uncertainty developed. These methods, however, attempt to
model uncertainty due to distributional mismatch either implicitly through
model uncertainty or as data uncertainty. This work proposes a new framework
for modeling predictive uncertainty called Prior Networks (PNs) which
explicitly models distributional uncertainty. PNs do this by parameterizing a
prior distribution over predictive distributions. This work focuses on
uncertainty for classification and evaluates PNs on the tasks of identifying
out-of-distribution (OOD) samples and detecting misclassification on the MNIST
dataset, where they are found to outperform previous methods. Experiments on
synthetic and MNIST data show that unlike previous non-Bayesian methods PNs are
able to distinguish between data and distributional uncertainty.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Malinin_A/0/1/0/all/0/1&quot;&gt;Andrey Malinin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gales_M/0/1/0/all/0/1&quot;&gt;Mark Gales&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.00195">
<title>The Anisotropic Noise in Stochastic Gradient Descent: Its Behavior of Escaping from Minima and Regularization Effects. (arXiv:1803.00195v4 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1803.00195</link>
<description rdf:parseType="Literal">&lt;p&gt;Understanding the behavior of stochastic gradient descent (SGD) in the
context of deep neural networks has raised lots of concerns recently. Along
this line, we theoretically study a general form of gradient based optimization
dynamics with unbiased noise, which unifies SGD and standard Langevin dynamics.
Through investigating this general optimization dynamics, we analyze the
behavior of SGD on escaping from minima and its regularization effects. A novel
indicator is derived to characterize the efficiency of escaping from minima
through measuring the alignment of noise covariance and the curvature of loss
function. Based on this indicator, two conditions are established to show which
type of noise structure is superior to isotropic noise in term of escaping
efficiency. We further show that the anisotropic noise in SGD satisfies the two
conditions, and thus helps to escape from sharp and poor minima effectively,
towards more stable and flat minima that typically generalize well. We verify
our understanding through comparing this anisotropic diffusion with full
gradient descent plus isotropic diffusion (i.e. Langevin dynamics) and other
types of position-dependent noise.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhu_Z/0/1/0/all/0/1&quot;&gt;Zhanxing Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wu_J/0/1/0/all/0/1&quot;&gt;Jingfeng Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yu_B/0/1/0/all/0/1&quot;&gt;Bing Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wu_L/0/1/0/all/0/1&quot;&gt;Lei Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ma_J/0/1/0/all/0/1&quot;&gt;Jinwen Ma&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.07612">
<title>Generative Multi-Agent Behavioral Cloning. (arXiv:1803.07612v5 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1803.07612</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose and study the problem of generative multi-agent behavioral
cloning, where the goal is to learn a generative, i.e., non-deterministic,
multi-agent policy from pre-collected demonstration data. Building upon
advances in deep generative models, we present a hierarchical policy framework
that can tractably learn complex mappings from input states to distributions
over multi-agent action spaces by introducing a hierarchy with macro-intent
variables that encode long-term intent. In addition to synthetic settings, we
show how to instantiate our framework to effectively model complex interactions
between basketball players and generate realistic multi-agent trajectories of
basketball gameplay over long time periods. We validate our approach using both
quantitative and qualitative evaluations, including a user study comparison
conducted with professional sports analysts.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhan_E/0/1/0/all/0/1&quot;&gt;Eric Zhan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_S/0/1/0/all/0/1&quot;&gt;Stephan Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yue_Y/0/1/0/all/0/1&quot;&gt;Yisong Yue&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sha_L/0/1/0/all/0/1&quot;&gt;Long Sha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lucey_P/0/1/0/all/0/1&quot;&gt;Patrick Lucey&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.05862">
<title>Compressibility and Generalization in Large-Scale Deep Learning. (arXiv:1804.05862v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1804.05862</link>
<description rdf:parseType="Literal">&lt;p&gt;Modern neural networks are highly overparameterized, with capacity to
substantially overfit to training data. Nevertheless, these networks often
generalize well in practice. It has also been observed that trained networks
can often be &quot;compressed&quot; to much smaller representations. The purpose of this
paper is to connect these two empirical observations. Our main technical result
is a generalization bound for compressed networks based on the compressed size.
Combined with off-the-shelf compression algorithms, the bound leads to state of
the art generalization guarantees; in particular, we provide the first
non-vacuous generalization guarantees for realistic architectures applied to
the ImageNet classification problem. As additional evidence connecting
compression and generalization, we show that compressibility of models that
tend to overfit is limited: We establish an absolute limit on expected
compressibility as a function of expected generalization error, where the
expectations are over the random choice of training examples. The bounds are
complemented by empirical results that show an increase in overfitting implies
an increase in the number of bits required to describe a trained network.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhou_W/0/1/0/all/0/1&quot;&gt;Wenda Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Veitch_V/0/1/0/all/0/1&quot;&gt;Victor Veitch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Austern_M/0/1/0/all/0/1&quot;&gt;Morgane Austern&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Adams_R/0/1/0/all/0/1&quot;&gt;Ryan P. Adams&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Orbanz_P/0/1/0/all/0/1&quot;&gt;Peter Orbanz&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.06872">
<title>Co-teaching: Robust Training Deep Neural Networks with Extremely Noisy Labels. (arXiv:1804.06872v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1804.06872</link>
<description rdf:parseType="Literal">&lt;p&gt;It is challenging to train deep neural networks robustly with noisy labels,
as the capacity of deep neural networks is so high that they can totally
over-fit on these noisy labels. In this paper, motivated by the memorization
effects of deep networks, which shows networks fit clean instances first and
then noisy ones, we present a new paradigm called &quot;\textit{Co-teaching}&quot;
combating with noisy labels. We train two networks simultaneously. First, in
each mini-batch data, each network filters noisy instances based on
memorization effects. Then, it teaches the remained instances to its peer
network for updating the parameters. Empirical results on benchmark datasets
demonstrate that, the robustness of deep learning models trained by Co-teaching
approach is much superior than that of state-of-the-art methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Han_B/0/1/0/all/0/1&quot;&gt;Bo Han&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yao_Q/0/1/0/all/0/1&quot;&gt;Quanming Yao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_X/0/1/0/all/0/1&quot;&gt;Xingrui Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Niu_G/0/1/0/all/0/1&quot;&gt;Gang Niu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_M/0/1/0/all/0/1&quot;&gt;Miao Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_W/0/1/0/all/0/1&quot;&gt;Weihua Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tsang_I/0/1/0/all/0/1&quot;&gt;Ivor Tsang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sugiyama_M/0/1/0/all/0/1&quot;&gt;Masashi Sugiyama&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.07045">
<title>Semantic Adversarial Deep Learning. (arXiv:1804.07045v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1804.07045</link>
<description rdf:parseType="Literal">&lt;p&gt;Fueled by massive amounts of data, models produced by machine-learning (ML)
algorithms, especially deep neural networks, are being used in diverse domains
where trustworthiness is a concern, including automotive systems, finance,
health care, natural language processing, and malware detection. Of particular
concern is the use of ML algorithms in cyber-physical systems (CPS), such as
self-driving cars and aviation, where an adversary can cause serious
consequences. However, existing approaches to generating adversarial examples
and devising robust ML algorithms mostly ignore the semantics and context of
the overall system containing the ML component. For example, in an autonomous
vehicle using deep learning for perception, not every adversarial example for
the neural network might lead to a harmful consequence. Moreover, one may want
to prioritize the search for adversarial examples towards those that
significantly modify the desired semantics of the overall system. Along the
same lines, existing algorithms for constructing robust ML algorithms ignore
the specification of the overall system. In this paper, we argue that the
semantics and specification of the overall system has a crucial role to play in
this line of research. We present preliminary research results that support
this claim.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dreossi_T/0/1/0/all/0/1&quot;&gt;Tommaso Dreossi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jha_S/0/1/0/all/0/1&quot;&gt;Somesh Jha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Seshia_S/0/1/0/all/0/1&quot;&gt;Sanjit A. Seshia&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.09893">
<title>Random Fourier Features for Kernel Ridge Regression: Approximation Bounds and Statistical Guarantees. (arXiv:1804.09893v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1804.09893</link>
<description rdf:parseType="Literal">&lt;p&gt;Random Fourier features is one of the most popular techniques for scaling up
kernel methods, such as kernel ridge regression. However, despite impressive
empirical results, the statistical properties of random Fourier features are
still not well understood. In this paper we take steps toward filling this gap.
Specifically, we approach random Fourier features from a spectral matrix
approximation point of view, give tight bounds on the number of Fourier
features required to achieve a spectral approximation, and show how spectral
matrix approximation bounds imply statistical guarantees for kernel ridge
regression.
&lt;/p&gt;
&lt;p&gt;Qualitatively, our results are twofold: on the one hand, we show that random
Fourier feature approximation can provably speed up kernel ridge regression
under reasonable assumptions. At the same time, we show that the method is
suboptimal, and sampling from a modified distribution in Fourier space, given
by the leverage function of the kernel, yields provably better performance. We
study this optimal sampling distribution for the Gaussian kernel, achieving a
nearly complete characterization for the case of low-dimensional bounded
datasets. Based on this characterization, we propose an efficient sampling
scheme with guarantees superior to random Fourier features in this regime.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Avron_H/0/1/0/all/0/1&quot;&gt;Haim Avron&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kapralov_M/0/1/0/all/0/1&quot;&gt;Michael Kapralov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Musco_C/0/1/0/all/0/1&quot;&gt;Cameron Musco&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Musco_C/0/1/0/all/0/1&quot;&gt;Christopher Musco&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Velingker_A/0/1/0/all/0/1&quot;&gt;Ameya Velingker&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zandieh_A/0/1/0/all/0/1&quot;&gt;Amir Zandieh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.00521">
<title>Direct Runge-Kutta Discretization Achieves Acceleration. (arXiv:1805.00521v3 [math.OC] UPDATED)</title>
<link>http://arxiv.org/abs/1805.00521</link>
<description rdf:parseType="Literal">&lt;p&gt;We study gradient-based optimization methods obtained by directly
discretizing a second-order ordinary differential equation (ODE) related to the
continuous limit of Nesterov&apos;s accelerated gradient method. When the function
is smooth enough, we show that acceleration can be achieved by a stable
discretization of this ODE using standard Runge-Kutta integrators.
Specifically, we prove that under Lipschitz-gradient, convexity and
order-$(s+2)$ differentiability assumptions, the sequence of iterates generated
by discretizing the proposed second-order ODE converges to the optimal solution
at a rate of $\mathcal{O}({N^{-2\frac{s}{s+1}}})$, where $s$ is the order of
the Runge-Kutta numerical integrator. Furthermore, we introduce a new local
flatness condition on the objective, under which rates even faster than
$\mathcal{O}(N^{-2})$ can be achieved with low-order integrators and only
gradient information. Notably, this flatness condition is satisfied by several
standard loss functions used in machine learning. We provide numerical
experiments that verify the theoretical rates predicted by our results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Jingzhao Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Mokhtari_A/0/1/0/all/0/1&quot;&gt;Aryan Mokhtari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Sra_S/0/1/0/all/0/1&quot;&gt;Suvrit Sra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Jadbabaie_A/0/1/0/all/0/1&quot;&gt;Ali Jadbabaie&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.01045">
<title>Alpha-Beta Divergence For Variational Inference. (arXiv:1805.01045v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1805.01045</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper introduces a variational approximation framework using direct
optimization of what is known as the {\it scale invariant Alpha-Beta
divergence} (sAB divergence). This new objective encompasses most variational
objectives that use the Kullback-Leibler, the R{\&apos;e}nyi or the gamma
divergences. It also gives access to objective functions never exploited before
in the context of variational inference. This is achieved via two easy to
interpret control parameters, which allow for a smooth interpolation over the
divergence space while trading-off properties such as mass-covering of a target
distribution and robustness to outliers in the data. Furthermore, the sAB
variational objective can be optimized directly by repurposing existing methods
for Monte Carlo computation of complex variational objectives, leading to
estimates of the divergence instead of variational lower bounds. We show the
advantages of this objective on Bayesian models for regression problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Regli_J/0/1/0/all/0/1&quot;&gt;Jean-Baptiste Regli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Silva_R/0/1/0/all/0/1&quot;&gt;Ricardo Silva&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.02257">
<title>Bayesian Regularization for Graphical Models with Unequal Shrinkage. (arXiv:1805.02257v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1805.02257</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider a Bayesian framework for estimating a high-dimensional sparse
precision matrix, in which adaptive shrinkage and sparsity are induced by a
mixture of Laplace priors. Besides discussing our formulation from the Bayesian
standpoint, we investigate the MAP (maximum a posteriori) estimator from a
penalized likelihood perspective that gives rise to a new non-convex penalty
approximating the $\ell_0$ penalty. Optimal error rates for estimation
consistency in terms of various matrix norms along with selection consistency
for sparse structure recovery are shown for the unique MAP estimator under mild
conditions. For fast and efficient computation, an EM algorithm is proposed to
compute the MAP estimator of the precision matrix and (approximate) posterior
probabilities on the edges of the underlying sparse structure. Through
extensive simulation studies and a real application to a call center data, we
have demonstrated the fine performance of our method compared with existing
alternatives.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gan_L/0/1/0/all/0/1&quot;&gt;Lingrui Gan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Narisetty_N/0/1/0/all/0/1&quot;&gt;Naveen N. Narisetty&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Liang_F/0/1/0/all/0/1&quot;&gt;Feng Liang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.05052">
<title>A Gentle Introduction to Supervised Machine Learning. (arXiv:1805.05052v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.05052</link>
<description rdf:parseType="Literal">&lt;p&gt;This tutorial is based on the lecture notes for the courses &quot;Machine
Learning: Basic Principles&quot; and &quot;Artificial Intelligence&quot;, which I have taught
during fall 2017 and spring 2018 at Aalto university. The aim is to provide an
accessible introduction to some of the main concepts and methods within
supervised machine learning. Most of the current systems which are con- sidered
as (artificially) intelligent are based on some form of supervised machine
learning. After discussing the main building blocks of a formal machine
learning problem, some of the most popular algorithmic design patterns for
machine learning methods are presented.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jung_A/0/1/0/all/0/1&quot;&gt;Alexander Jung&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1702.08159">
<title>McKernel: A Library for Approximate Kernel Expansions in Log-linear Time. (arXiv:1702.08159v6 [cs.LG] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1702.08159</link>
<description rdf:parseType="Literal">&lt;p&gt;Kernel Methods Next Generation (KMNG) introduces a framework to use kernel
approximates in the mini-batch setting with SGD Optimizer as an alternative to
Deep Learning. McKernel is a C++ library for KMNG ML Large-scale. It contains a
CPU optimized implementation of the Fastfood algorithm that allows the
computation of approximated kernel expansions in log-linear time. The algorithm
requires to compute the product of Walsh Hadamard Transform (WHT) matrices. A
cache friendly SIMD Fast Walsh Hadamard Transform (FWHT) that achieves
compelling speed and outperforms current state-of-the-art methods has been
developed. McKernel allows to obtain non-linear classification combining
Fastfood and a linear classifier.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Curto_J/0/1/0/all/0/1&quot;&gt;Joachim D. Curt&amp;#xf3;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zarza_I/0/1/0/all/0/1&quot;&gt;Irene C. Zarza&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_F/0/1/0/all/0/1&quot;&gt;Feng Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Smola_A/0/1/0/all/0/1&quot;&gt;Alexander J. Smola&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Torre_F/0/1/0/all/0/1&quot;&gt;Fernando De La Torre&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ngo_C/0/1/0/all/0/1&quot;&gt;Chong-Wah Ngo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gool_L/0/1/0/all/0/1&quot;&gt;Luc Van Gool&lt;/a&gt;</dc:creator>
</item></rdf:RDF>