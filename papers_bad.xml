<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Boring papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Bad Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-07-29T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.10470"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.10562"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1708.06525"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.00456"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.10299"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.10303"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.10399"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.10413"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.10580"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.10615"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.10680"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1611.01553"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.03043"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06426"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.10081"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.11556"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.02717"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.07193"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.09388"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.10119"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.10278"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.10328"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.10363"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.10375"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.10455"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.10458"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.10494"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.10565"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.10571"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.10573"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.10584"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.10588"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.10600"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.10602"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.10623"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.10693"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.10707"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.10728"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.00205"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.00559"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06398"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.00013"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.00020"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11085"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.09780"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.03513"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.04193"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1807.10470">
<title>BSAS: Beetle Swarm Antennae Search Algorithm for Optimization Problems. (arXiv:1807.10470v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1807.10470</link>
<description rdf:parseType="Literal">&lt;p&gt;Beetle antennae search (BAS) is an efficient meta-heuristic algorithm.
However, the convergent results of BAS rely heavily on the random beetle
direction in every iterations. More specifically, different random seeds may
cause different optimized results. Besides, the step-size update algorithm of
BAS cannot guarantee objective become smaller in iterative process. In order to
solve these problems, this paper proposes Beetle Swarm Antennae Search
Algorithm (BSAS) which combines swarm intelligence algorithm with
feedback-based step-size update strategy. BSAS employs k beetles to find more
optimal position in each moving rather than one beetle. The step-size updates
only when k beetles return without better choices. Experiments are carried out
on building system identification. The results reveal the efficacy of the BSAS
algorithm to avoid influence of random direction of Beetle. In addition, the
estimation errors decrease as the beetles number goes up.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jiangyu Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1&quot;&gt;Huanxin Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.10562">
<title>Contributions to the development of the CRO-SL algorithm: Engineering applications problems. (arXiv:1807.10562v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1807.10562</link>
<description rdf:parseType="Literal">&lt;p&gt;This Ph.D. thesis discusses advanced design issues of the evolutionary-based
algorithm \textit{&quot;Coral Reef Optimization&quot;}, in its Substrate-Layer (CRO-SL)
version, for optimization problems in Engineering Applications. The problems
that can be tackled with meta-heuristic approaches is very wide and varied, and
it is not exclusive of engineering. However we focus the Thesis on it area, one
of the most prominent in our time. One of the proposed application is battery
scheduling problem in Micro-Grids (MGs). Specifically, we consider an MG that
includes renewable distributed generation and different loads, defined by its
power profiles, and is equipped with an energy storage device (battery) to
address its programming (duration of loading / discharging and occurrence) in a
real scenario with variable electricity prices. Also, we discuss a problem of
vibration cancellation over structures of two and four floors, using Tuned Mass
Dampers (TMD&apos;s). The optimization algorithm will try to find the best solution
by obtaining three physical parameters and the TMD location. As another related
application, CRO-SL is used to design Multi-Input-Multi-Output Active Vibration
Control (MIMO-AVC) via inertial-mass actuators, for structures subjected to
human induced vibration. In this problem, we will optimize the location of each
actuator and tune control gains. Finally, we tackle the optimization of a
textile modified meander-line Inverted-F Antenna (IFA) with variable width and
spacing meander, for RFID systems. Specifically, the CRO-SL is used to obtain
an optimal antenna design, with a good bandwidth and radiation pattern, ideal
for RFID readers. Radio Frequency Identification (RFID) has become one of the
most numerous manufactured devices worldwide due to a reliable and inexpensive
means of locating people. They are used in access and money cards and product
labels and many other applications.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Camacho_Gomez_C/0/1/0/all/0/1&quot;&gt;Carlos Camacho-G&amp;#xf3;mez&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1708.06525">
<title>Neural Network-based Graph Embedding for Cross-Platform Binary Code Similarity Detection. (arXiv:1708.06525v4 [cs.CR] UPDATED)</title>
<link>http://arxiv.org/abs/1708.06525</link>
<description rdf:parseType="Literal">&lt;p&gt;The problem of cross-platform binary code similarity detection aims at
detecting whether two binary functions coming from different platforms are
similar or not. It has many security applications, including plagiarism
detection, malware detection, vulnerability search, etc. Existing approaches
rely on approximate graph matching algorithms, which are inevitably slow and
sometimes inaccurate, and hard to adapt to a new task. To address these issues,
in this work, we propose a novel neural network-based approach to compute the
embedding, i.e., a numeric vector, based on the control flow graph of each
binary function, then the similarity detection can be done efficiently by
measuring the distance between the embeddings for two functions. We implement a
prototype called Gemini. Our extensive evaluation shows that Gemini outperforms
the state-of-the-art approaches by large margins with respect to similarity
detection accuracy. Further, Gemini can speed up prior art&apos;s embedding
generation time by 3 to 4 orders of magnitude and reduce the required training
time from more than 1 week down to 30 minutes to 10 hours. Our real world case
studies demonstrate that Gemini can identify significantly more vulnerable
firmware images than the state-of-the-art, i.e., Genius. Our research showcases
a successful application of deep learning on computer security problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_X/0/1/0/all/0/1&quot;&gt;Xiaojun Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1&quot;&gt;Chang Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feng_Q/0/1/0/all/0/1&quot;&gt;Qian Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yin_H/0/1/0/all/0/1&quot;&gt;Heng Yin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_L/0/1/0/all/0/1&quot;&gt;Le Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_D/0/1/0/all/0/1&quot;&gt;Dawn Song&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.00456">
<title>Evenly Cascaded Convolutional Networks. (arXiv:1807.00456v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1807.00456</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce Evenly Cascaded convolutional Network (ECN), a neural network
taking inspiration from the cascade algorithm of wavelet analysis. ECN employs
two feature streams - a low-level and high-level steam. At each layer these
streams interact, such that low-level features are modulated using advanced
perspectives from the high-level stream. ECN is evenly structured through
resizing feature map dimensions by a consistent ratio, which removes the burden
of ad-hoc specification of feature map dimensions. ECN produces easily
interpretable features maps, a result whose intuition can be understood in the
context of scale-space theory. We demonstrate that ECN&apos;s design facilitates the
training process through providing easily trainable shortcuts. We report new
state-of-the-art results for small networks, without the need for additional
treatment such as pruning or compression - a consequence of ECN&apos;s simple
structure and direct training. A 6-layered ECN design with under 500k
parameters achieves 95.24% and 78.99% accuracy on CIFAR-10 and CIFAR-100
datasets, respectively, outperforming the current state-of-the-art on small
parameter networks, and a 3 million parameter ECN produces results competitive
to the state-of-the-art.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ye_C/0/1/0/all/0/1&quot;&gt;Chengxi Ye&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Devaraj_C/0/1/0/all/0/1&quot;&gt;Chinmaya Devaraj&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Maynord_M/0/1/0/all/0/1&quot;&gt;Michael Maynord&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fermuller_C/0/1/0/all/0/1&quot;&gt;Cornelia Ferm&amp;#xfc;ller&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aloimonos_Y/0/1/0/all/0/1&quot;&gt;Yiannis Aloimonos&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.10299">
<title>Variational Option Discovery Algorithms. (arXiv:1807.10299v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1807.10299</link>
<description rdf:parseType="Literal">&lt;p&gt;We explore methods for option discovery based on variational inference and
make two algorithmic contributions. First: we highlight a tight connection
between variational option discovery methods and variational autoencoders, and
introduce Variational Autoencoding Learning of Options by Reinforcement
(VALOR), a new method derived from the connection. In VALOR, the policy encodes
contexts from a noise distribution into trajectories, and the decoder recovers
the contexts from the complete trajectories. Second: we propose a curriculum
learning approach where the number of contexts seen by the agent increases
whenever the agent&apos;s performance is strong enough (as measured by the decoder)
on the current set of contexts. We show that this simple trick stabilizes
training for VALOR and prior variational option discovery methods, allowing a
single agent to learn many more modes of behavior than it could with a fixed
context distribution. Finally, we investigate other topics related to
variational option discovery, including fundamental limitations of the general
approach and the applicability of learned options to downstream tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Achiam_J/0/1/0/all/0/1&quot;&gt;Joshua Achiam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Edwards_H/0/1/0/all/0/1&quot;&gt;Harrison Edwards&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Amodei_D/0/1/0/all/0/1&quot;&gt;Dario Amodei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1&quot;&gt;Pieter Abbeel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.10303">
<title>Semantically Meaningful View Selection. (arXiv:1807.10303v1 [cs.RO])</title>
<link>http://arxiv.org/abs/1807.10303</link>
<description rdf:parseType="Literal">&lt;p&gt;An understanding of the nature of objects could help robots to solve both
high-level abstract tasks and improve performance at lower-level concrete
tasks. Although deep learning has facilitated progress in image understanding,
a robot&apos;s performance in problems like object recognition often depends on the
angle from which the object is observed. Traditionally, robot sorting tasks
rely on a fixed top-down view of an object. By changing its viewing angle, a
robot can select a more semantically informative view leading to better
performance for object recognition. In this paper, we introduce the problem of
semantic view selection, which seeks to find good camera poses to gain semantic
knowledge about an observed object. We propose a conceptual formulation of the
problem, together with a solvable relaxation based on clustering. We then
present a new image dataset consisting of around 10k images representing
various views of 144 objects under different poses. Finally we use this dataset
to propose a first solution to the problem by training a neural network to
predict a &quot;semantic score&quot; from a top view image and camera pose. The views
predicted to have higher scores are then shown to provide better clustering
results than fixed top-down views.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guerin_J/0/1/0/all/0/1&quot;&gt;Joris Gu&amp;#xe9;rin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gibaru_O/0/1/0/all/0/1&quot;&gt;Olivier Gibaru&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nyiri_E/0/1/0/all/0/1&quot;&gt;Eric Nyiri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Thiery_S/0/1/0/all/0/1&quot;&gt;St&amp;#xe9;phane Thiery&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Boots_B/0/1/0/all/0/1&quot;&gt;Byron Boots&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.10399">
<title>Entropic Latent Variable Discovery. (arXiv:1807.10399v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1807.10399</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the problem of discovering the simplest latent variable that can
make two observed discrete variables conditionally independent. This problem
has appeared in the literature as probabilistic latent semantic analysis
(pLSA), and has connections to non-negative matrix factorization. When the
simplicity of the variable is measured through its cardinality, we show that a
solution to this latent variable discovery problem can be used to distinguish
direct causal relations from spurious correlations among almost all joint
distributions on simple causal graphs with two observed variables. Conjecturing
a similar identifiability result holds with Shannon entropy, we study a loss
function that trades-off between entropy of the latent variable and the
conditional mutual information of the observed variables. We then propose a
latent variable discovery algorithm -- LatentSearch -- and show that its
stationary points are the stationary points of our loss function. We
experimentally show that LatentSearch can indeed be used to distinguish direct
causal relations from spurious correlations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kocaoglu_M/0/1/0/all/0/1&quot;&gt;Murat Kocaoglu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Shakkottai_S/0/1/0/all/0/1&quot;&gt;Sanjay Shakkottai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Dimakis_A/0/1/0/all/0/1&quot;&gt;Alexandros G. Dimakis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Caramanis_C/0/1/0/all/0/1&quot;&gt;Constantine Caramanis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Vishwanath_S/0/1/0/all/0/1&quot;&gt;Sriram Vishwanath&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.10413">
<title>Adapting control policies from simulation to reality using a pairwise loss. (arXiv:1807.10413v1 [cs.RO])</title>
<link>http://arxiv.org/abs/1807.10413</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper proposes an approach to domain transfer based on a pairwise loss
function that helps transfer control policies learned in simulation onto a real
robot. We explore the idea in the context of a &apos;category level&apos; manipulation
task where a control policy is learned that enables a robot to perform a mating
task involving novel objects. We explore the case where depth images are used
as the main form of sensor input. Our experimental results demonstrate that
proposed method consistently outperforms baseline methods that train only in
simulation or that combine real and simulated data in a naive way.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Viereck_U/0/1/0/all/0/1&quot;&gt;Ulrich Viereck&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saenko_K/0/1/0/all/0/1&quot;&gt;Kate Saenko&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Platt_R/0/1/0/all/0/1&quot;&gt;Robert Platt&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.10580">
<title>Is the Pedestrian going to Cross? Answering by 2D Pose Estimation. (arXiv:1807.10580v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1807.10580</link>
<description rdf:parseType="Literal">&lt;p&gt;Our recent work suggests that, thanks to nowadays powerful CNNs, image-based
2D pose estimation is a promising cue for determining pedestrian intentions
such as crossing the road in the path of the ego-vehicle, stopping before
entering the road, and starting to walk or bending towards the road. This
statement is based on the results obtained on non-naturalistic sequences
(Daimler dataset), i.e. in sequences choreographed specifically for performing
the study. Fortunately, a new publicly available dataset (JAAD) has appeared
recently to allow developing methods for detecting pedestrian intentions in
naturalistic driving conditions; more specifically, for addressing the relevant
question is the pedestrian going to cross? Accordingly, in this paper we use
JAAD to assess the usefulness of 2D pose estimation for answering such a
question. We combine CNN-based pedestrian detection, tracking and pose
estimation to predict the crossing action from monocular images. Overall, the
proposed pipeline provides new state-of-the-art results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fang_Z/0/1/0/all/0/1&quot;&gt;Zhijie Fang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lopez_A/0/1/0/all/0/1&quot;&gt;Antonio M. L&amp;#xf3;pez&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.10615">
<title>Judging a Book by its Description : Analyzing Gender Stereotypes in the Man Bookers Prize Winning Fiction. (arXiv:1807.10615v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1807.10615</link>
<description rdf:parseType="Literal">&lt;p&gt;The presence of gender stereotypes in many aspects of society is a well-known
phenomenon. In this paper, we focus on studying and quantifying such
stereotypes and bias in the Man Bookers Prize winning fiction. We consider 275
books shortlisted for Man Bookers Prize between 1969 and 2017. The gender bias
is analyzed by semantic modeling of book descriptions on Goodreads. This
reveals the pervasiveness of gender bias and stereotype in the books on
different features like occupation, introductions and actions associated to the
characters in the book.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Madaan_N/0/1/0/all/0/1&quot;&gt;Nishtha Madaan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mehta_S/0/1/0/all/0/1&quot;&gt;Sameep Mehta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mittal_S/0/1/0/all/0/1&quot;&gt;Shravika Mittal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Suvarna_A/0/1/0/all/0/1&quot;&gt;Ashima Suvarna&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.10680">
<title>Combining Restricted Boltzmann Machines with Neural Networks for Latent Truth Discovery. (arXiv:1807.10680v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.10680</link>
<description rdf:parseType="Literal">&lt;p&gt;Latent truth discovery, LTD for short, refers to the problem of aggregating
ltiple claims from various sources in order to estimate the plausibility of
atements about entities. In the absence of a ground truth, this problem is
highly challenging, when some sources provide conflicting claims and others no
claims at all. In this work we provide an unsupervised stochastic inference
procedure on top of a model that combines restricted Boltzmann machines with
feed-forward neural networks to accurately infer the reliability of sources as
well as the plausibility of statements about entities. In comparison to prior
work our approach stands out (1) by allowing the incorporation of arbitrary
features about sources and claims, (2) by generalizing from reliability per
source towards a reliability function, and thus (3) enabling the estimation of
source reliability even for sources that have provided no or very few claims,
(4) by building on efficient and scalable stochastic inference algorithms, and
(5) by outperforming the state-of-the-art by a considerable margin.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Broelemann_K/0/1/0/all/0/1&quot;&gt;Klaus Broelemann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kasneci_G/0/1/0/all/0/1&quot;&gt;Gjergji Kasneci&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1611.01553">
<title>QBF Solving by Counterexample-guided Expansion. (arXiv:1611.01553v4 [cs.LO] UPDATED)</title>
<link>http://arxiv.org/abs/1611.01553</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce a novel generalization of Counterexample-Guided Inductive
Synthesis (CEGIS) and instantiate it to yield a novel, competitive algorithm
for solving Quantified Boolean Formulas (QBF). Current QBF solvers based on
counterexample-guided expansion use a recursive approach which scales poorly
with the number of quantifier alternations. Our generalization of CEGIS removes
the need for this recursive approach, and we instantiate it to yield a simple
and efficient algorithm for QBF solving. Lastly, this research is supported by
a competitive, though straightforward, implementation of the algorithm, making
it possible to study the practical impact of our algorithm design decisions,
along with various optimizations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bloem_R/0/1/0/all/0/1&quot;&gt;Roderick Bloem&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Braud_Santoni_N/0/1/0/all/0/1&quot;&gt;Nicolas Braud-Santoni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hadzic_V/0/1/0/all/0/1&quot;&gt;Vedad Hadzic&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.03043">
<title>A Heuristic Search Algorithm Using the Stability of Learning Algorithms in Certain Scenarios as the Fitness Function: An Artificial General Intelligence Engineering Approach. (arXiv:1712.03043v3 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1712.03043</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents a non-manual design engineering method based on heuristic
search algorithm to search for candidate agents in the solution space which
formed by artificial intelligence agents modeled on the base of
bionics.Compared with the artificial design method represented by meta-learning
and the bionics method represented by the neural architecture chip,this method
is more feasible for realizing artificial general intelligence,and it has a
much better interaction with cognitive neuroscience;at the same time,the
engineering method is based on the theoretical hypothesis that the final
learning algorithm is stable in certain scenarios,and has generalization
ability in various scenarios.The paper discusses the theory preliminarily and
proposes the possible correlation between the theory and the fixed-point
theorem in the field of mathematics.Limited by the author&apos;s knowledge
level,this correlation is proposed only as a kind of conjecture.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Z/0/1/0/all/0/1&quot;&gt;Zengkun Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06426">
<title>Estimating scale-invariant future in continuous time. (arXiv:1802.06426v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1802.06426</link>
<description rdf:parseType="Literal">&lt;p&gt;Natural learners must compute an estimate of future outcomes that follow from
a stimulus in continuous time. Critically, the learner cannot in general know a
priori the relevant time scale over which meaningful relationships will be
observed. Widely used reinforcement learning algorithms discretize continuous
time and use the Bellman equation to estimate exponentially-discounted future
reward. However, exponential discounting introduces a time scale to the
computation of value. Scaling is a serious problem in continuous time:
efficient learning with scaled algorithms requires prior knowledge of the
relevant scale. That is, with scaled algorithms one must know at least part of
the solution to a problem prior to attempting a solution. We present a
computational mechanism, developed based on work in psychology and
neuroscience, for computing a scale-invariant timeline of future events. This
mechanism efficiently computes a model for future time on a
logarithmically-compressed scale, and can be used to generate a scale-invariant
power-law-discounted estimate of expected future reward. Moreover, the
representation of future time retains information about what will happen when,
enabling flexible decision making based on future events. The entire timeline
can be constructed in a single parallel operation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tiganj_Z/0/1/0/all/0/1&quot;&gt;Zoran Tiganj&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gershman_S/0/1/0/all/0/1&quot;&gt;Samuel J. Gershman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sederberg_P/0/1/0/all/0/1&quot;&gt;Per B. Sederberg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Howard_M/0/1/0/all/0/1&quot;&gt;Marc W. Howard&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.10081">
<title>DeepJDOT: Deep Joint Distribution Optimal Transport for Unsupervised Domain Adaptation. (arXiv:1803.10081v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1803.10081</link>
<description rdf:parseType="Literal">&lt;p&gt;In computer vision, one is often confronted with problems of domain shifts,
which occur when one applies a classifier trained on a source dataset to target
data sharing similar characteristics (e.g. same classes), but also different
latent data structures (e.g. different acquisition conditions). In such a
situation, the model will perform poorly on the new data, since the classifier
is specialized to recognize visual cues specific to the source domain. In this
work we explore a solution, named DeepJDOT, to tackle this problem: through a
measure of discrepancy on joint deep representations/labels based on optimal
transport, we not only learn new data representations aligned between the
source and target domain, but also simultaneously preserve the discriminative
information used by the classifier. We applied DeepJDOT to a series of visual
recognition tasks, where it compares favorably against state-of-the-art deep
domain adaptation methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Damodaran_B/0/1/0/all/0/1&quot;&gt;Bharath Bhushan Damodaran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kellenberger_B/0/1/0/all/0/1&quot;&gt;Benjamin Kellenberger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Flamary_R/0/1/0/all/0/1&quot;&gt;R&amp;#xe9;mi Flamary&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tuia_D/0/1/0/all/0/1&quot;&gt;Devis Tuia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Courty_N/0/1/0/all/0/1&quot;&gt;Nicolas Courty&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.11556">
<title>Learning to Anonymize Faces for Privacy Preserving Action Detection. (arXiv:1803.11556v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1803.11556</link>
<description rdf:parseType="Literal">&lt;p&gt;There is an increasing concern in computer vision devices invading users&apos;
privacy by recording unwanted videos. On the one hand, we want the camera
systems to recognize important events and assist human daily lives by
understanding its videos, but on the other hand we want to ensure that they do
not intrude people&apos;s privacy. In this paper, we propose a new principled
approach for learning a video \emph{face anonymizer}. We use an adversarial
training setting in which two competing systems fight: (1) a video anonymizer
that modifies the original video to remove privacy-sensitive information while
still trying to maximize spatial action detection performance, and (2) a
discriminator that tries to extract privacy-sensitive information from the
anonymized videos. The end result is a video anonymizer that performs
pixel-level modifications to anonymize each person&apos;s face, with minimal effect
on action detection performance. We experimentally confirm the benefits of our
approach compared to conventional hand-crafted anonymization methods including
masking, blurring, and noise adding. Code, demo, and more results can be found
on our project page https://jason718.github.io/project/privacy/main.html.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ren_Z/0/1/0/all/0/1&quot;&gt;Zhongzheng Ren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_Y/0/1/0/all/0/1&quot;&gt;Yong Jae Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ryoo_M/0/1/0/all/0/1&quot;&gt;Michael S. Ryoo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.02717">
<title>DeepMimic: Example-Guided Deep Reinforcement Learning of Physics-Based Character Skills. (arXiv:1804.02717v3 [cs.GR] UPDATED)</title>
<link>http://arxiv.org/abs/1804.02717</link>
<description rdf:parseType="Literal">&lt;p&gt;A longstanding goal in character animation is to combine data-driven
specification of behavior with a system that can execute a similar behavior in
a physical simulation, thus enabling realistic responses to perturbations and
environmental variation. We show that well-known reinforcement learning (RL)
methods can be adapted to learn robust control policies capable of imitating a
broad range of example motion clips, while also learning complex recoveries,
adapting to changes in morphology, and accomplishing user-specified goals. Our
method handles keyframed motions, highly-dynamic actions such as
motion-captured flips and spins, and retargeted motions. By combining a
motion-imitation objective with a task objective, we can train characters that
react intelligently in interactive settings, e.g., by walking in a desired
direction or throwing a ball at a user-specified target. This approach thus
combines the convenience and motion quality of using motion clips to define the
desired style and appearance, with the flexibility and generality afforded by
RL methods and physics-based animation. We further explore a number of methods
for integrating multiple clips into the learning process to develop
multi-skilled agents capable of performing a rich repertoire of diverse skills.
We demonstrate results using multiple characters (human, Atlas robot, bipedal
dinosaur, dragon) and a large variety of skills, including locomotion,
acrobatics, and martial arts.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peng_X/0/1/0/all/0/1&quot;&gt;Xue Bin Peng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1&quot;&gt;Pieter Abbeel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1&quot;&gt;Sergey Levine&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Panne_M/0/1/0/all/0/1&quot;&gt;Michiel van de Panne&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.07193">
<title>Lipschitz Continuity in Model-based Reinforcement Learning. (arXiv:1804.07193v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1804.07193</link>
<description rdf:parseType="Literal">&lt;p&gt;We examine the impact of learning Lipschitz continuous models in the context
of model-based reinforcement learning. We provide a novel bound on multi-step
prediction error of Lipschitz models where we quantify the error using the
Wasserstein metric. We go on to prove an error bound for the value-function
estimate arising from Lipschitz models and show that the estimated value
function is itself Lipschitz. We conclude with empirical results that show the
benefits of controlling the Lipschitz constant of neural-network models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Asadi_K/0/1/0/all/0/1&quot;&gt;Kavosh Asadi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Misra_D/0/1/0/all/0/1&quot;&gt;Dipendra Misra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Littman_M/0/1/0/all/0/1&quot;&gt;Michael L. Littman&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.09388">
<title>LAPRAN: A Scalable Laplacian Pyramid Reconstructive Adversarial Network for Flexible Compressive Sensing Reconstruction. (arXiv:1807.09388v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1807.09388</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper addresses the single-image compressive sensing (CS) and
reconstruction problem. We propose a scalable Laplacian pyramid reconstructive
adversarial network (LAPRAN) that enables high-fidelity, flexible and fast CS
images reconstruction. LAPRAN progressively reconstructs an image following the
concept of Laplacian pyramid through multiple stages of reconstructive
adversarial networks (RANs). At each pyramid level, CS measurements are fused
with a contextual latent vector to generate a high-frequency image residual.
Consequently, LAPRAN can produce hierarchies of reconstructed images and each
with an incremental resolution and improved quality. The scalable pyramid
structure of LAPRAN enables high-fidelity CS reconstruction with a flexible
resolution that is adaptive to a wide range of compression ratios (CRs), which
is infeasible with existing methods. Experimental results on multiple public
datasets show that LAPRAN offers an average 7.47dB and 5.98dB PSNR, and an
average 57.93% and 33.20% SSIM improvement compared to model-based and
data-driven baselines, respectively.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_K/0/1/0/all/0/1&quot;&gt;Kai Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Z/0/1/0/all/0/1&quot;&gt;Zhikang Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ren_F/0/1/0/all/0/1&quot;&gt;Fengbo Ren&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.10119">
<title>A Unified Approximation Framework for Deep Neural Networks. (arXiv:1807.10119v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1807.10119</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep neural networks (DNNs) have achieved significant success in a variety of
real world applications. However, tons of parameters in the networks restrict
the efficiency of neural networks due to the large model size and the intensive
computation. To address this issue, various compression and acceleration
techniques have been investigated, among which low-rank filters and sparse
filters are heavily studied. In this paper we propose a unified framework to
compress the convolutional neural networks by combining these two strategies,
while taking the nonlinear activation into consideration. The filer of a layer
is approximated by the sum of a sparse component and a low-rank component, both
of which are in favor of model compression. Especially, we constrain the sparse
component to be structured sparse which facilitates acceleration. The
performance of the network is retained by minimizing the reconstruction error
of the feature maps after activation of each layer, using the alternating
direction method of multipliers (ADMM). The experimental results show that our
proposed approach can compress VGG-16 and AlexNet by over 4X. In addition, 2.2X
and 1.1X speedup are achieved on VGG-16 and AlexNet, respectively, at a cost of
less increase on error rate.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_Y/0/1/0/all/0/1&quot;&gt;Yuzhe Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_R/0/1/0/all/0/1&quot;&gt;Ran Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1&quot;&gt;Wei Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shang_F/0/1/0/all/0/1&quot;&gt;Fanhua Shang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_W/0/1/0/all/0/1&quot;&gt;Wenjian Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cho_M/0/1/0/all/0/1&quot;&gt;Minsik Cho&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_B/0/1/0/all/0/1&quot;&gt;Bei Yu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.10278">
<title>Structured Point Cloud Data Analysis via Regularized Tensor Regression for Process Modeling and Optimization. (arXiv:1807.10278v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1807.10278</link>
<description rdf:parseType="Literal">&lt;p&gt;Advanced 3D metrology technologies such as Coordinate Measuring Machine (CMM)
and laser 3D scanners have facilitated the collection of massive point cloud
data, beneficial for process monitoring, control and optimization. However, due
to their high dimensionality and structure complexity, modeling and analysis of
point clouds are still a challenge. In this paper, we utilize multilinear
algebra techniques and propose a set of tensor regression approaches to model
the variational patterns of point clouds and to link them to process variables.
The performance of the proposed methods is evaluated through simulations and a
real case study of turning process optimization.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yan_H/0/1/0/all/0/1&quot;&gt;Hao Yan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Paynabar_K/0/1/0/all/0/1&quot;&gt;Kamran Paynabar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pacel_M/0/1/0/all/0/1&quot;&gt;Massimo Pacel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.10328">
<title>Selective Clustering Annotated using Modes of Projections. (arXiv:1807.10328v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1807.10328</link>
<description rdf:parseType="Literal">&lt;p&gt;Selective clustering annotated using modes of projections (SCAMP) is a new
clustering algorithm for data in $\mathbb{R}^p$. SCAMP is motivated from the
point of view of non-parametric mixture modeling. Rather than maximizing a
classification likelihood to determine cluster assignments, SCAMP casts
clustering as a search and selection problem. One consequence of this problem
formulation is that the number of clusters is $\textbf{not}$ a SCAMP tuning
parameter. The search phase of SCAMP consists of finding sub-collections of the
data matrix, called candidate clusters, that obey shape constraints along each
coordinate projection. An extension of the dip test of Hartigan and Hartigan
(1985) is developed to assist the search. Selection occurs by scoring each
candidate cluster with a preference function that quantifies prior belief about
the mixture composition. Clustering proceeds by selecting candidates to
maximize their total preference score. SCAMP concludes by annotating each
selected cluster with labels that describe how cluster-level statistics compare
to certain dataset-level quantities. SCAMP can be run multiple times on a
single data matrix. Comparison of annotations obtained across iterations
provides a measure of clustering uncertainty. Simulation studies and
applications to real data are considered. A C++ implementation with R interface
is $\href{https://github.com/RGLab/scamp}{available\ online}$.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Greene_E/0/1/0/all/0/1&quot;&gt;Evan Greene&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Finak_G/0/1/0/all/0/1&quot;&gt;Greg Finak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gottardo_R/0/1/0/all/0/1&quot;&gt;Raphael Gottardo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.10363">
<title>Message-passing neural networks for high-throughput polymer screening. (arXiv:1807.10363v1 [physics.comp-ph])</title>
<link>http://arxiv.org/abs/1807.10363</link>
<description rdf:parseType="Literal">&lt;p&gt;Machine learning methods have shown promise in predicting molecular
properties, and given sufficient training data ML may surpass density
functional theory in computational speed and chemical accuracy. However, the
most accurate machine learning methods require optimized 3D molecular
geometries, limiting their applicability for high-throughput screening. We show
that near-optimal results for large polymeric molecules can be obtained without
optimized 3D geometry, and that trained model weights can be used to improve
performance on related tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+John_P/0/1/0/all/0/1&quot;&gt;Peter C. St. John&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Phillips_C/0/1/0/all/0/1&quot;&gt;Caleb Phillips&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Kemper_T/0/1/0/all/0/1&quot;&gt;Travis W. Kemper&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Wilson_A/0/1/0/all/0/1&quot;&gt;A. Nolan Wilson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Crowley_M/0/1/0/all/0/1&quot;&gt;Michael F. Crowley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Nimlos_M/0/1/0/all/0/1&quot;&gt;Mark R. Nimlos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Larsen_R/0/1/0/all/0/1&quot;&gt;Ross E. Larsen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.10375">
<title>Integrative Multi-View Reduced-Rank Regression: Bridging Group-Sparse and Low-Rank Models. (arXiv:1807.10375v1 [stat.ME])</title>
<link>http://arxiv.org/abs/1807.10375</link>
<description rdf:parseType="Literal">&lt;p&gt;Multi-view data have been routinely collected in various fields of science
and engineering. A general problem is to study the predictive association
between multivariate responses and multi-view predictor sets, all of which can
be of high dimensionality. It is likely that only a few views are relevant to
prediction, and the predictors within each relevant view contribute to the
prediction collectively rather than sparsely. We cast this new problem under
the familiar multivariate regression framework and propose an integrative
reduced-rank regression (iRRR), where each view has its own low-rank
coefficient matrix. As such, latent features are extracted from each view in a
supervised fashion. For model estimation, we develop a convex composite nuclear
norm penalization approach, which admits an efficient algorithm via alternating
direction method of multipliers. Extensions to non-Gaussian and incomplete data
are discussed. Theoretically, we derive non-asymptotic oracle bounds of iRRR
under a restricted eigenvalue condition. Our results recover oracle bounds of
several special cases of iRRR including Lasso, group Lasso and nuclear norm
penalized regression. Therefore, iRRR seamlessly bridges group-sparse and
low-rank methods and can achieve substantially faster convergence rate under
realistic settings of multi-view learning. Simulation studies and an
application in the Longitudinal Studies of Aging further showcase the efficacy
of the proposed methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Li_G/0/1/0/all/0/1&quot;&gt;Gen Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Liu_X/0/1/0/all/0/1&quot;&gt;Xiaokang Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chen_K/0/1/0/all/0/1&quot;&gt;Kun Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.10455">
<title>Acceleration through Optimistic No-Regret Dynamics. (arXiv:1807.10455v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.10455</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the problem of minimizing a smooth convex function by reducing
the optimization to computing the Nash equilibrium of a particular zero-sum
convex-concave game. Zero-sum games can be solved using no-regret learning
dynamics, and the standard approach leads to a rate of $O(1/T)$. But we are
able to show that the game can be solved at a rate of $O(1/T^2)$, extending
recent works of \cite{RS13,SALS15} by using \textit{optimistic learning} to
speed up equilibrium computation. The optimization algorithm that we can
extract from this equilibrium reduction coincides \textit{exactly} with the
well-known \NA \cite{N83a} method, and indeed the same story allows us to
recover several variants of the Nesterov&apos;s algorithm via small tweaks. This
methodology unifies a number of different iterative optimization methods: we
show that the \HB algorithm is precisely the non-optimistic variant of \NA, and
recent prior work already established a similar perspective on \FW
\cite{AW17,ALLW18}.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jun-Kun Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abernethy_J/0/1/0/all/0/1&quot;&gt;Jacob Abernethy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.10458">
<title>AXNet: ApproXimate computing using an end-to-end trainable neural network. (arXiv:1807.10458v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.10458</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural network based approximate computing is a universal architecture
promising to gain tremendous energy-efficiency for many error resilient
applications. To guarantee the approximation quality, existing works deploy two
neural networks (NNs), e.g., an approximator and a predictor. The approximator
provides the approximate results, while the predictor predicts whether the
input data is safe to approximate with the given quality requirement. However,
it is non-trivial and time-consuming to make these two neural network
coordinate---they have different optimization objectives---by training them
separately. This paper proposes a novel neural network structure---AXNet---to
fuse two NNs to a holistic end-to-end trainable NN. Leveraging the philosophy
of multi-task learning, AXNet can tremendously improve the invocation
(proportion of safe-to-approximate samples) and reduce the approximation error.
The training effort also decrease significantly. Experiment results show 50.7%
more invocation and substantial cuts of training time when compared to existing
neural network based approximate computing framework.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peng_Z/0/1/0/all/0/1&quot;&gt;Zhenghao Peng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_X/0/1/0/all/0/1&quot;&gt;Xuyang Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_C/0/1/0/all/0/1&quot;&gt;Chengwen Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jing_N/0/1/0/all/0/1&quot;&gt;Naifeng Jing&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_X/0/1/0/all/0/1&quot;&gt;Xiaoyao Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_C/0/1/0/all/0/1&quot;&gt;Cewu Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_L/0/1/0/all/0/1&quot;&gt;Li Jiang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.10494">
<title>DeepLink: A Novel Link Prediction Framework based on Deep Learning. (arXiv:1807.10494v1 [cs.SI])</title>
<link>http://arxiv.org/abs/1807.10494</link>
<description rdf:parseType="Literal">&lt;p&gt;Recently, link prediction has attracted more attentions from various
disciplines such as computer science, bioinformatics and economics. In this
problem, unknown links between nodes are discovered based on numerous
information such as network topology, profile information and user generated
contents. Most of the previous researchers have focused on the structural
features of the networks. While the recent researches indicate that contextual
information can change the network topology. Although, there are number of
valuable researches which combine structural and content information, but they
face with the scalability issue due to feature engineering. Because, majority
of the extracted features are obtained by a supervised or semi supervised
algorithm. Moreover, the existing features are not general enough to indicate
good performance on different networks with heterogeneous structures. Besides,
most of the previous researches are presented for undirected and unweighted
networks. In this paper, a novel link prediction framework called &quot;DeepLink&quot; is
presented based on deep learning techniques. In contrast to the previous
researches which fail to automatically extract best features for the link
prediction, deep learning reduces the manual feature engineering. In this
framework, both the structural and content information of the nodes are
employed. The framework can use different structural feature vectors, which are
prepared by various link prediction methods. It considers all proximity orders
that are presented in a network during the structural feature learning. We have
evaluated the performance of DeepLink on two real social network datasets
including Telegram and irBlogs. On both datasets, the proposed framework
outperforms several structural and hybrid approaches for link prediction
problem.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Keikha_M/0/1/0/all/0/1&quot;&gt;Mohammad Mehdi Keikha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rahgozar_M/0/1/0/all/0/1&quot;&gt;Maseud Rahgozar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Asadpour_M/0/1/0/all/0/1&quot;&gt;Masoud Asadpour&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.10565">
<title>DeepPhase: Surgical Phase Recognition in CATARACTS Videos. (arXiv:1807.10565v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1807.10565</link>
<description rdf:parseType="Literal">&lt;p&gt;Automated surgical workflow analysis and understanding can assist surgeons to
standardize procedures and enhance post-surgical assessment and indexing, as
well as, interventional monitoring. Computer-assisted interventional (CAI)
systems based on video can perform workflow estimation through surgical
instruments&apos; recognition while linking them to an ontology of procedural
phases. In this work, we adopt a deep learning paradigm to detect surgical
instruments in cataract surgery videos which in turn feed a surgical phase
inference recurrent network that encodes temporal aspects of phase steps within
the phase classification. Our models present comparable to state-of-the-art
results for surgical tool detection and phase recognition with accuracies of 99
and 78% respectively.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zisimopoulos_O/0/1/0/all/0/1&quot;&gt;Odysseas Zisimopoulos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Flouty_E/0/1/0/all/0/1&quot;&gt;Evangello Flouty&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luengo_I/0/1/0/all/0/1&quot;&gt;Imanol Luengo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Giataganas_P/0/1/0/all/0/1&quot;&gt;Petros Giataganas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nehme_J/0/1/0/all/0/1&quot;&gt;Jean Nehme&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chow_A/0/1/0/all/0/1&quot;&gt;Andre Chow&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stoyanov_D/0/1/0/all/0/1&quot;&gt;Danail Stoyanov&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.10571">
<title>Sparse Range-constrained Learning and Its Application for Medical Image Grading. (arXiv:1807.10571v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1807.10571</link>
<description rdf:parseType="Literal">&lt;p&gt;Sparse learning has been shown to be effective in solving many real-world
problems. Finding sparse representations is a fundamentally important topic in
many fields of science including signal processing, computer vision, genome
study and medical imaging. One important issue in applying sparse
representation is to find the basis to represent the data,especially in
computer vision and medical imaging where the data is not necessary incoherent.
In medical imaging, clinicians often grade the severity or measure the risk
score of a disease based on images. This process is referred to as medical
image grading. Manual grading of the disease severity or risk score is often
used. However, it is tedious, subjective and expensive. Sparse learning has
been used for automatic grading of medical images for different diseases. In
the grading, we usually begin with one step to find a sparse representation of
the testing image using a set of reference images or atoms from the dictionary.
Then in the second step, the selected atoms are used as references to compute
the grades of the testing images. Since the two steps are conducted
sequentially, the objective function in the first step is not necessarily
optimized for the second step. In this paper, we propose a novel sparse
range-constrained learning(SRCL)algorithm for medical image grading.Different
from most of existing sparse learning algorithms, SRCL integrates the objective
of finding a sparse representation and that of grading the image into one
function. It aims to find a sparse representation of the testing image based on
atoms that are most similar in both the data or feature representation and the
medical grading scores. We apply the new proposed SRCL to CDR computation and
cataract grading. Experimental results show that the proposed method is able to
improve the accuracy in cup-to-disc ratio computation and cataract grading.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_J/0/1/0/all/0/1&quot;&gt;Jun Cheng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.10573">
<title>LiDAR and Camera Detection Fusion in a Real Time Industrial Multi-Sensor Collision Avoidance System. (arXiv:1807.10573v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1807.10573</link>
<description rdf:parseType="Literal">&lt;p&gt;Collision avoidance is a critical task in many applications, such as ADAS
(advanced driver-assistance systems), industrial automation and robotics. In an
industrial automation setting, certain areas should be off limits to an
automated vehicle for protection of people and high-valued assets. These areas
can be quarantined by mapping (e.g., GPS) or via beacons that delineate a
no-entry area. We propose a delineation method where the industrial vehicle
utilizes a LiDAR {(Light Detection and Ranging)} and a single color camera to
detect passive beacons and model-predictive control to stop the vehicle from
entering a restricted space. The beacons are standard orange traffic cones with
a highly reflective vertical pole attached. The LiDAR can readily detect these
beacons, but suffers from false positives due to other reflective surfaces such
as worker safety vests. Herein, we put forth a method for reducing false
positive detection from the LiDAR by projecting the beacons in the camera
imagery via a deep learning method and validating the detection using a neural
network-learned projection from the camera to the LiDAR space. Experimental
data collected at Mississippi State University&apos;s Center for Advanced Vehicular
Systems (CAVS) shows the effectiveness of the proposed system in keeping the
true detection while mitigating false positives.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wei_P/0/1/0/all/0/1&quot;&gt;Pan Wei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cagle_L/0/1/0/all/0/1&quot;&gt;Lucas Cagle&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Reza_T/0/1/0/all/0/1&quot;&gt;Tasmia Reza&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ball_J/0/1/0/all/0/1&quot;&gt;John Ball&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gafford_J/0/1/0/all/0/1&quot;&gt;James Gafford&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.10584">
<title>Uncertainty and Interpretability in Convolutional Neural Networks for Semantic Segmentation of Colorectal Polyps. (arXiv:1807.10584v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1807.10584</link>
<description rdf:parseType="Literal">&lt;p&gt;Convolutional Neural Networks (CNNs) are propelling advances in a range of
different computer vision tasks such as object detection and object
segmentation. Their success has motivated research in applications of such
models for medical image analysis. If CNN-based models are to be helpful in a
medical context, they need to be precise, interpretable, and uncertainty in
predictions must be well understood. In this paper, we develop and evaluate
recent advances in uncertainty estimation and model interpretability in the
context of semantic segmentation of polyps from colonoscopy images. We evaluate
and enhance several architectures of Fully Convolutional Networks (FCNs) for
semantic segmentation of colorectal polyps and provide a comparison between
these models. Our highest performing model achieves a 76.06\% mean IOU accuracy
on the EndoScene dataset, a considerable improvement over the previous
state-of-the-art.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wickstrom_K/0/1/0/all/0/1&quot;&gt;Kristoffer Wickstr&amp;#xf8;m&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kampffmeyer_M/0/1/0/all/0/1&quot;&gt;Michael Kampffmeyer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jenssen_R/0/1/0/all/0/1&quot;&gt;Robert Jenssen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.10588">
<title>A Modality-Adaptive Method for Segmenting Brain Tumors and Organs-at-Risk in Radiation Therapy Planning. (arXiv:1807.10588v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1807.10588</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper we present a method for simultaneously segmenting brain tumors
and an extensive set of organs-at-risk for radiation therapy planning of
glioblastomas. The method combines a contrast-adaptive generative model for
whole-brain segmentation with a new spatial regularization model of tumor shape
using convolutional restricted Boltzmann machines. We demonstrate
experimentally that the method is able to adapt to image acquisitions that
differ substantially from any available training data, ensuring its
applicability across treatment sites; that its tumor segmentation accuracy is
comparable to that of the current state of the art; and that it captures most
organs-at-risk sufficiently well for radiation therapy planning purposes. The
proposed method may be a valuable step towards automating the delineation of
brain tumors and organs-at-risk in glioblastoma patients undergoing radiation
therapy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Agn_M/0/1/0/all/0/1&quot;&gt;Mikael Agn&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rosenschold_P/0/1/0/all/0/1&quot;&gt;Per Munck af Rosensch&amp;#xf6;ld&lt;/a&gt; (2), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Puonti_O/0/1/0/all/0/1&quot;&gt;Oula Puonti&lt;/a&gt; (3), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lundemann_M/0/1/0/all/0/1&quot;&gt;Michael J. Lundemann&lt;/a&gt; (4), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mancini_L/0/1/0/all/0/1&quot;&gt;Laura Mancini&lt;/a&gt; (5 and 6), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Papadaki_A/0/1/0/all/0/1&quot;&gt;Anastasia Papadaki&lt;/a&gt; (5 and 6), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Thust_S/0/1/0/all/0/1&quot;&gt;Steffi Thust&lt;/a&gt; (5 and 6), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ashburner_J/0/1/0/all/0/1&quot;&gt;John Ashburner&lt;/a&gt; (7), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Law_I/0/1/0/all/0/1&quot;&gt;Ian Law&lt;/a&gt; (8), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leemput_K/0/1/0/all/0/1&quot;&gt;Koen Van Leemput&lt;/a&gt; (1 and 9) ((1) Department of Applied Mathematics and Computer Science, Technical University of Denmark, Denmark, (2) Radiation Physics, Department of Hematology, Oncology and Radiation Physics, Sk&amp;#xe5;ne University Hospital, Lund, Sweden, (3) Danish Research Centre for Magnetic Resonance, Copenhagen University Hospital Hvidovre, Denmark, (4) Department of Oncology, Copenhagen University Hospital Rigshospitalet, Denmark, (5) Neuroradiological Academic Unit, Department of Brain Repair and Rehabilitation, UCL Institute of Neurology, University College London, UK, (6) Lysholm Department of Neuroradiology, National Hospital for Neurology and Neurosurgery, UCLH NHS Foundation Trust, UK, (7) Wellcome Centre for Human Neuroimaging, UCL Institute of Neurology, University College London, UK, (8) Department of Clinical Physiology, Nuclear Medicine and PET, Copenhagen University Hospital Rigshospitalet, Denmark, (9) Athinoula A. Martinos Center for Biomedical Imaging, Massachusetts General Hospital, Harvard Medical School, USA)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.10600">
<title>A post-processing method to improve the white matter hyperintensity segmentation accuracy for randomly-initialized U-net. (arXiv:1807.10600v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1807.10600</link>
<description rdf:parseType="Literal">&lt;p&gt;White matter hyperintensity (WMH) is commonly found in elder individuals and
appears to be associated with brain diseases. U-net is a convolutional network
that has been widely used for biomedical image segmentation. Recently, U-net
has been successfully applied to WMH segmentation. Random initialization is
usally used to initialize the model weights in the U-net. However, the model
may coverage to different local optima with different randomly initialized
weights. We find a combination of thresholding and averaging the outputs of
U-nets with different random initializations can largely improve the WMH
segmentation accuracy. Based on this observation, we propose a post-processing
technique concerning the way how averaging and thresholding are conducted.
Specifically, we first transfer the score maps from three U-nets to binary
masks via thresholding and then average those binary masks to obtain the final
WMH segmentation. Both quantitative analysis (via the Dice similarity
coefficient) and qualitative analysis (via visual examinations) reveal the
superior performance of the proposed method. This post-processing technique is
independent of the model used. As such, it can also be applied to situations
where other deep learning models are employed, especially when random
initialization is adopted and pre-training is unavailable.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yue Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_W/0/1/0/all/0/1&quot;&gt;Wanli Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yifan Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_X/0/1/0/all/0/1&quot;&gt;Xiaoying Tang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.10602">
<title>A Trace Lasso Regularized L1-norm Graph Cut for Highly Correlated Noisy Hyperspectral Image. (arXiv:1807.10602v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1807.10602</link>
<description rdf:parseType="Literal">&lt;p&gt;This work proposes an adaptive trace lasso regularized L1-norm based graph
cut method for dimensionality reduction of Hyperspectral images, called as
`Trace Lasso-L1 Graph Cut&apos; (TL-L1GC). The underlying idea of this method is to
generate the optimal projection matrix by considering both the sparsity as well
as the correlation of the data samples. The conventional L2-norm used in the
objective function is sensitive to noise and outliers. Therefore, in this work
L1-norm is utilized as a robust alternative to L2-norm. Besides, for further
improvement of the results, we use a penalty function of trace lasso with the
L1GC method. It adaptively balances the L2-norm and L1-norm simultaneously by
considering the data correlation along with the sparsity. We obtain the optimal
projection matrix by maximizing the ratio of between-class dispersion to
within-class dispersion using L1-norm with trace lasso as the penalty.
Furthermore, an iterative procedure for this TL-L1GC method is proposed to
solve the optimization function. The effectiveness of this proposed method is
evaluated on two benchmark HSI datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mohanty_R/0/1/0/all/0/1&quot;&gt;Ramanarayan Mohanty&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Happy_S/0/1/0/all/0/1&quot;&gt;S L Happy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Suthar_N/0/1/0/all/0/1&quot;&gt;Nilesh Suthar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Routray_A/0/1/0/all/0/1&quot;&gt;Aurobinda Routray&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.10623">
<title>Learning low dimensional word based linear classifiers using Data Shared Adaptive Bootstrap Aggregated Lasso with application to IMDb data. (arXiv:1807.10623v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1807.10623</link>
<description rdf:parseType="Literal">&lt;p&gt;In this article we propose a new supervised ensemble learning method called
Data Shared Adaptive Bootstrap Aggregated (AdaBag) Lasso for capturing low
dimensional useful features for word based sentiment analysis and mining
problems. The literature on ensemble methods is very rich in both statistics
and machine learning. The algorithm is a substantial upgrade of the Data Shared
Lasso uplift algorithm. The most significant conceptual addition to the
existing literature lies in the final selection of bag of predictors through a
special bootstrap aggregation scheme. We apply the algorithm to one simulated
data and perform dimension reduction in grouped IMDb data (drama, comedy and
horror) to extract reduced set of word features for predicting sentiment
ratings of movie reviews demonstrating different aspects. We also compare the
performance of the present method with the classical Principal Components with
associated Linear Discrimination (PCA-LD) as baseline. There are few
limitations in the algorithm. Firstly, the algorithm workflow does not
incorporate online sequential data acquisition and it does not use sentence
based models which are common in ANN algorithms . Our results produce slightly
higher error rate compare to the reported state-of-the-art as a consequence.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Maurya_A/0/1/0/all/0/1&quot;&gt;Ashutosh K. Maurya&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.10693">
<title>Infinite Mixture of Inverted Dirichlet Distributions. (arXiv:1807.10693v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.10693</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work, we develop a novel Bayesian estimation method for the Dirichlet
process (DP) mixture of the inverted Dirichlet distributions, which has been
shown to be very flexible for modeling vectors with positive elements. The
recently proposed extended variational inference (EVI) framework is adopted to
derive an analytically tractable solution. The convergency of the proposed
algorithm is theoretically guaranteed by introducing single lower bound
approximation to the original objective function in the VI framework. In
principle, the proposed model can be viewed as an infinite inverted Dirichelt
mixture model (InIDMM) that allows the automatic determination of the number of
mixture components from data. Therefore, the problem of pre-determining the
optimal number of mixing components has been overcome. Moreover, the problems
of over-fitting and under-fitting are avoided by the Bayesian estimation
approach. Comparing with several recently proposed DP-related methods, the good
performance and effectiveness of the proposed method have been demonstrated
with both synthesized data and real data evaluations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_Z/0/1/0/all/0/1&quot;&gt;Zhanyu Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lai_Y/0/1/0/all/0/1&quot;&gt;Yuping Lai&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.10707">
<title>End-to-end Deep Learning from Raw Sensor Data: Atrial Fibrillation Detection using Wearables. (arXiv:1807.10707v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1807.10707</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a convolutional-recurrent neural network architecture with long
short-term memory for real-time processing and classification of digital sensor
data. The network implicitly performs typical signal processing tasks such as
filtering and peak detection, and learns time-resolved embeddings of the input
signal. We use a prototype multi-sensor wearable device to collect over 180h of
photoplethysmography (PPG) data sampled at 20Hz, of which 36h are during atrial
fibrillation (AFib). We use end-to-end learning to achieve state-of-the-art
results in detecting AFib from raw PPG data. For classification labels output
every 0.8s, we demonstrate an area under ROC curve of 0.9999, with false
positive and false negative rates both below $2\times 10^{-3}$. This
constitutes a significant improvement on previous results utilising
domain-specific feature engineering, such as heart rate extraction, and brings
large-scale atrial fibrillation screenings within imminent reach.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gotlibovych_I/0/1/0/all/0/1&quot;&gt;Igor Gotlibovych&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Crawford_S/0/1/0/all/0/1&quot;&gt;Stuart Crawford&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Goyal_D/0/1/0/all/0/1&quot;&gt;Dileep Goyal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Jiaqi Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kerem_Y/0/1/0/all/0/1&quot;&gt;Yaniv Kerem&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Benaron_D/0/1/0/all/0/1&quot;&gt;David Benaron&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yilmaz_D/0/1/0/all/0/1&quot;&gt;Defne Yilmaz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Marcus_G/0/1/0/all/0/1&quot;&gt;Gregory Marcus&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yihan/0/1/0/all/0/1&quot;&gt;Yihan&lt;/a&gt; (Jessie)Li</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.10728">
<title>Deep PDF: Probabilistic Surface Optimization and Density Estimation. (arXiv:1807.10728v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.10728</link>
<description rdf:parseType="Literal">&lt;p&gt;A probability density function (pdf) encodes the entire stochastic knowledge
about data distribution, where data may represent stochastic observations in
robotics, transition state pairs in reinforcement learning or any other
empirically acquired modality. Inferring data pdf is of prime importance,
allowing to analyze various model hypotheses and perform smart decision making.
However, most density estimation techniques are limited in their representation
expressiveness to specific kernel type or predetermined distribution family,
and have other restrictions. For example, kernel density estimation (KDE)
methods require meticulous parameter search and are extremely slow at querying
new points. In this paper we present a novel non-parametric density estimation
approach, DeepPDF, that uses a neural network to approximate a target pdf given
samples from thereof. Such a representation provides high inference accuracy
for a wide range of target pdfs using a relatively simple network structure,
making our method highly statistically robust. This is done via a new
stochastic optimization algorithm, \emph{Probabilistic Surface Optimization}
(PSO), that turns to advantage the stochastic nature of sample points in order
to force network output to be identical to the output of a target pdf. Once
trained, query point evaluation can be efficiently done in DeepPDF by a simple
network forward pass, with linear complexity in the number of query points.
Moreover, the PSO algorithm is capable of inferring the frequency of data
samples and may also be used in other statistical tasks such as conditional
estimation and distribution transformation. We compare the derived approach
with KDE methods showing its superior performance and accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kopitkov_D/0/1/0/all/0/1&quot;&gt;Dmitry Kopitkov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Indelman_V/0/1/0/all/0/1&quot;&gt;Vadim Indelman&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.00205">
<title>Tensors, Learning, and &apos;Kolmogorov Extension&apos; for Finite-alphabet Random Vectors. (arXiv:1712.00205v2 [eess.SP] UPDATED)</title>
<link>http://arxiv.org/abs/1712.00205</link>
<description rdf:parseType="Literal">&lt;p&gt;Estimating the joint probability mass function (PMF) of a set of random
variables lies at the heart of statistical learning and signal processing.
Without structural assumptions, such as modeling the variables as a Markov
chain, tree, or other graphical model, joint PMF estimation is often considered
mission impossible - the number of unknowns grows exponentially with the number
of variables. But who gives us the structural model? Is there a generic,
`non-parametric&apos; way to control joint PMF complexity without relying on a
priori structural assumptions regarding the underlying probability model? Is it
possible to discover the operational structure without biasing the analysis up
front? What if we only observe random subsets of the variables, can we still
reliably estimate the joint PMF of all? This paper shows, perhaps surprisingly,
that if the joint PMF of any three variables can be estimated, then the joint
PMF of all the variables can be provably recovered under relatively mild
conditions. The result is reminiscent of Kolmogorov&apos;s extension theorem -
consistent specification of lower-dimensional distributions induces a unique
probability measure for the entire process. The difference is that for
processes of limited complexity (rank of the high-dimensional PMF) it is
possible to obtain complete characterization from only three-dimensional
distributions. In fact not all three-dimensional PMFs are needed; and under
more stringent conditions even two-dimensional will do. Exploiting multilinear
algebra, this paper proves that such higher-dimensional PMF completion can be
guaranteed - several pertinent identifiability results are derived. It also
provides a practical and efficient algorithm to carry out the recovery task.
Judiciously designed simulations and real-data experiments on movie
recommendation and data classification are presented to showcase the
effectiveness of the approach.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Kargas_N/0/1/0/all/0/1&quot;&gt;Nikos Kargas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Sidiropoulos_N/0/1/0/all/0/1&quot;&gt;Nicholas D. Sidiropoulos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Fu_X/0/1/0/all/0/1&quot;&gt;Xiao Fu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.00559">
<title>Progressive Neural Architecture Search. (arXiv:1712.00559v3 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1712.00559</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a new method for learning the structure of convolutional neural
networks (CNNs) that is more efficient than recent state-of-the-art methods
based on reinforcement learning and evolutionary algorithms. Our approach uses
a sequential model-based optimization (SMBO) strategy, in which we search for
structures in order of increasing complexity, while simultaneously learning a
surrogate model to guide the search through structure space. Direct comparison
under the same search space shows that our method is up to 5 times more
efficient than the RL method of Zoph et al. (2018) in terms of number of models
evaluated, and 8 times faster in terms of total compute. The structures we
discover in this way achieve state of the art classification accuracies on
CIFAR-10 and ImageNet.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1&quot;&gt;Chenxi Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zoph_B/0/1/0/all/0/1&quot;&gt;Barret Zoph&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Neumann_M/0/1/0/all/0/1&quot;&gt;Maxim Neumann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shlens_J/0/1/0/all/0/1&quot;&gt;Jonathon Shlens&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hua_W/0/1/0/all/0/1&quot;&gt;Wei Hua&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1&quot;&gt;Li-Jia Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fei_Fei_L/0/1/0/all/0/1&quot;&gt;Li Fei-Fei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yuille_A/0/1/0/all/0/1&quot;&gt;Alan Yuille&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_J/0/1/0/all/0/1&quot;&gt;Jonathan Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Murphy_K/0/1/0/all/0/1&quot;&gt;Kevin Murphy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06398">
<title>HybridSVD: When Collaborative Information is Not Enough. (arXiv:1802.06398v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1802.06398</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a hybrid algorithm for top-$n$ recommendation task that allows to
incorporate both user and item side information within the standard
collaborative filtering approach. The algorithm extends PureSVD -- one of the
state-of-the-art latent factor models -- by exploiting a generalized
formulation of the singular value decomposition. This allows to inherit key
advantages of the classical algorithm such as highly efficient Lanczos-based
optimization procedure, minimal parameter tuning during a model selection phase
and a quick folding-in computation to generate recommendations instantly even
in a highly dynamic online environment. Within the generalized formulation
itself we provide an efficient scheme for side information fusion which avoids
undesirable computational overhead and addresses the scalability question.
Evaluation of the model is performed in both standard and cold-start scenarios
using the datasets with different sparsity levels. We demonstrate in which
cases our approach outperforms conventional methods and also provide some
intuition on when it may give no significant improvement.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Frolov_E/0/1/0/all/0/1&quot;&gt;Evgeny Frolov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oseledets_I/0/1/0/all/0/1&quot;&gt;Ivan Oseledets&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.00013">
<title>Constraining Effective Field Theories with Machine Learning. (arXiv:1805.00013v4 [hep-ph] UPDATED)</title>
<link>http://arxiv.org/abs/1805.00013</link>
<description rdf:parseType="Literal">&lt;p&gt;We present powerful new analysis techniques to constrain effective field
theories at the LHC. By leveraging the structure of particle physics processes,
we extract extra information from Monte-Carlo simulations, which can be used to
train neural network models that estimate the likelihood ratio. These methods
scale well to processes with many observables and theory parameters, do not
require any approximations of the parton shower or detector response, and can
be evaluated in microseconds. We show that they allow us to put significantly
stronger bounds on dimension-six operators than existing methods, demonstrating
their potential to improve the precision of the LHC legacy constraints.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/hep-ph/1/au:+Brehmer_J/0/1/0/all/0/1&quot;&gt;Johann Brehmer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/hep-ph/1/au:+Cranmer_K/0/1/0/all/0/1&quot;&gt;Kyle Cranmer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/hep-ph/1/au:+Louppe_G/0/1/0/all/0/1&quot;&gt;Gilles Louppe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/hep-ph/1/au:+Pavez_J/0/1/0/all/0/1&quot;&gt;Juan Pavez&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.00020">
<title>A Guide to Constraining Effective Field Theories with Machine Learning. (arXiv:1805.00020v4 [hep-ph] UPDATED)</title>
<link>http://arxiv.org/abs/1805.00020</link>
<description rdf:parseType="Literal">&lt;p&gt;We develop, discuss, and compare several inference techniques to constrain
theory parameters in collider experiments. By harnessing the latent-space
structure of particle physics processes, we extract extra information from the
simulator. This augmented data can be used to train neural networks that
precisely estimate the likelihood ratio. The new methods scale well to many
observables and high-dimensional parameter spaces, do not require any
approximations of the parton shower and detector response, and can be evaluated
in microseconds. Using weak-boson-fusion Higgs production as an example
process, we compare the performance of several techniques. The best results are
found for likelihood ratio estimators trained with extra information about the
score, the gradient of the log likelihood function with respect to the theory
parameters. The score also provides sufficient statistics that contain all the
information needed for inference in the neighborhood of the Standard Model.
These methods enable us to put significantly stronger bounds on effective
dimension-six operators than the traditional approach based on histograms. They
also outperform generic machine learning methods that do not make use of the
particle physics structure, demonstrating their potential to substantially
improve the new physics reach of the LHC legacy results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/hep-ph/1/au:+Brehmer_J/0/1/0/all/0/1&quot;&gt;Johann Brehmer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/hep-ph/1/au:+Cranmer_K/0/1/0/all/0/1&quot;&gt;Kyle Cranmer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/hep-ph/1/au:+Louppe_G/0/1/0/all/0/1&quot;&gt;Gilles Louppe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/hep-ph/1/au:+Pavez_J/0/1/0/all/0/1&quot;&gt;Juan Pavez&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11085">
<title>More Than a Feeling: Learning to Grasp and Regrasp using Vision and Touch. (arXiv:1805.11085v2 [cs.RO] UPDATED)</title>
<link>http://arxiv.org/abs/1805.11085</link>
<description rdf:parseType="Literal">&lt;p&gt;For humans, the process of grasping an object relies heavily on rich tactile
feedback. Most recent robotic grasping work, however, has been based only on
visual input, and thus cannot easily benefit from feedback after initiating
contact. In this paper, we investigate how a robot can learn to use tactile
information to iteratively and efficiently adjust its grasp. To this end, we
propose an end-to-end action-conditional model that learns regrasping policies
from raw visuo-tactile data. This model -- a deep, multimodal convolutional
network -- predicts the outcome of a candidate grasp adjustment, and then
executes a grasp by iteratively selecting the most promising actions. Our
approach requires neither calibration of the tactile sensors, nor any
analytical modeling of contact forces, thus reducing the engineering effort
required to obtain efficient grasping policies. We train our model with data
from about 6,450 grasping trials on a two-finger gripper equipped with GelSight
high-resolution tactile sensors on each finger. Across extensive experiments,
our approach outperforms a variety of baselines at (i) estimating grasp
adjustment outcomes, (ii) selecting efficient grasp adjustments for quick
grasping, and (iii) reducing the amount of force applied at the fingers, while
maintaining competitive performance. Finally, we study the choices made by our
model and show that it has successfully acquired useful and interpretable
grasping behaviors.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Calandra_R/0/1/0/all/0/1&quot;&gt;Roberto Calandra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Owens_A/0/1/0/all/0/1&quot;&gt;Andrew Owens&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jayaraman_D/0/1/0/all/0/1&quot;&gt;Dinesh Jayaraman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_J/0/1/0/all/0/1&quot;&gt;Justin Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yuan_W/0/1/0/all/0/1&quot;&gt;Wenzhen Yuan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Malik_J/0/1/0/all/0/1&quot;&gt;Jitendra Malik&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Adelson_E/0/1/0/all/0/1&quot;&gt;Edward H. Adelson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1&quot;&gt;Sergey Levine&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.09780">
<title>Correlated pseudo-marginal Metropolis-Hastings using quasi-Newton proposals. (arXiv:1806.09780v2 [stat.CO] UPDATED)</title>
<link>http://arxiv.org/abs/1806.09780</link>
<description rdf:parseType="Literal">&lt;p&gt;Pseudo-marginal Metropolis-Hastings (pmMH) is a versatile algorithm for
sampling from target distributions which are not easy to evaluate point-wise.
However, pmMH requires good proposal distributions to sample efficiently from
the target, which can be problematic to construct in practice. This is
especially a problem for high-dimensional targets when the standard random-walk
proposal is inefficient. We extend pmMH to allow for constructing the proposal
based on information from multiple past iterations. As a consequence,
quasi-Newton (qN) methods can be employed to form proposals which utilize
gradient information to guide the Markov chain to areas of high probability and
to construct approximations of the local curvature to scale step sizes. The
proposed method is demonstrated on several problems which indicate that qN
proposals can perform better than other common Hessian-based proposals.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Dahlin_J/0/1/0/all/0/1&quot;&gt;Johan Dahlin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wills_A/0/1/0/all/0/1&quot;&gt;Adrian Wills&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ninness_B/0/1/0/all/0/1&quot;&gt;Brett Ninness&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.03513">
<title>Automatic trajectory recognition in Active Target Time Projection Chambers data by means of hierarchical clustering. (arXiv:1807.03513v2 [physics.ins-det] UPDATED)</title>
<link>http://arxiv.org/abs/1807.03513</link>
<description rdf:parseType="Literal">&lt;p&gt;The automatic reconstruction of three-dimensional particle tracks from Active
Target Time Projection Chambers data can be a challenging task, especially in
the presence of noise. In this article, we propose a non-parametric algorithm
that is based on the idea of clustering point triplets instead of the original
points. We define an appropriate distance measure on point triplets and then
apply a single-link hierarchical clustering on the triplets. Compared to
parametric approaches like RANSAC or the Hough transform, the new algorithm has
the advantage of potentially finding trajectories even of shapes that are not
known beforehand. This feature is particularly important in low-energy nuclear
physics experiments with Active Targets operating inside a magnetic field. The
algorithm has been validated using data from experiments performed with the
Active Target Time Projection Chamber developed at the National Superconducting
Cyclotron Laboratory (NSCL).The results demonstrate the capability of the
algorithm to identify and isolate particle tracks that describe non-analytical
trajectories. For curved tracks, the vertex detection recall was 86\% and the
precision 94\%. For straight tracks, the vertex detection recall was 96\% and
the precision 98\%. In the case of a test set containing only straight linear
tracks, the algorithm performed better than an iterative Hough transform.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Dalitz_C/0/1/0/all/0/1&quot;&gt;Christoph Dalitz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Ayyad_Y/0/1/0/all/0/1&quot;&gt;Yassid Ayyad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Wilberg_J/0/1/0/all/0/1&quot;&gt;Jens Wilberg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Aymans_L/0/1/0/all/0/1&quot;&gt;Lukas Aymans&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Bazin_D/0/1/0/all/0/1&quot;&gt;Daniel Bazin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Mittig_W/0/1/0/all/0/1&quot;&gt;Wolfgang Mittig&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.04193">
<title>Distributed Variational Representation Learning. (arXiv:1807.04193v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1807.04193</link>
<description rdf:parseType="Literal">&lt;p&gt;The problem of distributed representation learning is one in which multiple
sources of information $X_1,\ldots,X_K$ are processed separately so as to learn
as much information as possible about some ground truth $Y$. We investigate
this problem from information-theoretic grounds, through a generalization of
Tishby&apos;s centralized Information Bottleneck (IB) method to the distributed
setting. Specifically, $K$ encoders, $K \geq 2$, compress their observations
$X_1,\ldots,X_K$ separately in a manner such that, collectively, the produced
representations preserve as much information as possible about $Y$. We study
both discrete memoryless (DM) and memoryless vector Gaussian data models. For
the discrete model, we establish a single-letter characterization of the
optimal tradeoff between complexity (or rate) and relevance (or information)
for a class of memoryless sources (the observations $X_1,\ldots,X_K$ being
conditionally independent given $Y$). For the vector Gaussian model, we provide
an explicit characterization of the optimal complexity-relevance tradeoff.
Furthermore, we develop a variational bound on the complexity-relevance
tradeoff which generalizes the evidence lower bound (ELBO) to the distributed
setting. We also provide two algorithms that allow to compute this bound: i) a
Blahut-Arimoto type iterative algorithm which enables to compute optimal
complexity-relevance encoding mappings by iterating over a set of
self-consistent equations, and ii) a variational inference type algorithm in
which the encoding mappings are parametrized by neural networks and the bound
approximated by Markov sampling and optimized with stochastic gradient descent.
Numerical results on synthetic and real datasets are provided to support the
efficiency of the approaches and algorithms developed in this paper.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Aguerri_I/0/1/0/all/0/1&quot;&gt;Inaki Estella Aguerri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zaidi_A/0/1/0/all/0/1&quot;&gt;Abdellatif Zaidi&lt;/a&gt;</dc:creator>
</item></rdf:RDF>