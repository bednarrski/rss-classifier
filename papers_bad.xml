<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Boring papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Bad Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-06-07T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02502"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02654"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02679"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02706"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1704.00026"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.03620"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.05174"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.09331"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02373"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02380"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02415"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02421"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02457"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02473"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02501"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02510"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02623"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02664"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02711"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02739"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02813"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02814"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.03243"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.00420"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07935"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00952"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02027"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.05339"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07472"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02137"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02338"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02382"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02390"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02402"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02450"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02455"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02485"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02511"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02512"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02538"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02543"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02612"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02617"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02659"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02714"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02775"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02815"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1611.02041"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1611.04208"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1702.08248"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1706.01833"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1707.06792"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1708.01799"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.11279"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.03265"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04220"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04712"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04911"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05757"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.08089"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.11262"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.01882"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.06530"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.08527"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10367"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11640"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11811"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00701"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.01811"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.06454"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1806.02502">
<title>GP-RVM: Genetic Programing-based Symbolic Regression Using Relevance Vector Machine. (arXiv:1806.02502v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1806.02502</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper proposes a hybrid basis function construction method (GP-RVM) for
Symbolic Regression problem, which combines an extended version of Genetic
Programming called Kaizen Programming and Relevance Vector Machine to evolve an
optimal set of basis functions. Different from traditional evolutionary
algorithms where a single individual is a complete solution, our method
proposes a solution based on linear combination of basis functions built from
individuals during the evolving process. RVM which is a sparse Bayesian kernel
method selects suitable functions to constitute the basis. RVM determines the
posterior weight of a function by evaluating its quality and sparsity. The
solution produced by GP-RVM is a sparse Bayesian linear model of the
coefficients of many non-linear functions. Our hybrid approach is focused on
nonlinear white-box models selecting the right combination of functions to
build robust predictions without prior knowledge about data. Experimental
results show that GP-RVM outperforms conventional methods, which suggest that
it is an efficient and accurate technique for solving SR. The computational
complexity of GP-RVM scales in $O( M^{3})$, where $M$ is the number of
functions in the basis set and is typically much smaller than the number $N$ of
training patterns.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rad_H/0/1/0/all/0/1&quot;&gt;Hossein Izadi Rad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Feng_J/0/1/0/all/0/1&quot;&gt;Ji Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Iba_H/0/1/0/all/0/1&quot;&gt;Hitoshi Iba&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02654">
<title>New Hybrid Neuro-Evolutionary Algorithms for Renewable Energy and Facilities Management Problems. (arXiv:1806.02654v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.02654</link>
<description rdf:parseType="Literal">&lt;p&gt;This Ph.D. thesis deals with the optimization of several renewable energy
resources development as well as the improvement of facilities management in
oceanic engineering and airports, using computational hybrid methods belonging
to AI to this end. Energy is essential to our society in order to ensure a good
quality of life. This means that predictions over the characteristics on which
renewable energies depend are necessary, in order to know the amount of energy
that will be obtained at any time. The second topic tackled in this thesis is
related to the basic parameters that influence in different marine activities
and airports, whose knowledge is necessary to develop a proper facilities
management in these environments. Within this work, a study of the
state-of-the-art Machine Learning have been performed to solve the problems
associated with the topics above-mentioned, and several contributions have been
proposed: One of the pillars of this work is focused on the estimation of the
most important parameters in the exploitation of renewable resources. The
second contribution of this thesis is related to feature selection problems.
The proposed methodologies are applied to multiple problems: the prediction of
$H_s$, relevant for marine energy applications and marine activities, the
estimation of WPREs, undesirable variations in the electric power produced by a
wind farm, the prediction of global solar radiation in areas from Spain and
Australia, really important in terms of solar energy, and the prediction of
low-visibility events at airports. All of these practical issues are developed
with the consequent previous data analysis, normally, in terms of
meteorological variables.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Cornejo_Bueno_L/0/1/0/all/0/1&quot;&gt;L. Cornejo-Bueno&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02679">
<title>Semi-Supervised Learning via Compact Latent Space Clustering. (arXiv:1806.02679v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.02679</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a novel cost function for semi-supervised learning of neural
networks that encourages compact clustering of the latent space to facilitate
separation. The key idea is to dynamically create a graph over embeddings of
labeled and unlabeled samples of a training batch to capture underlying
structure in feature space, and use label propagation to estimate its high and
low density regions. We then devise a cost function based on Markov chains on
the graph that regularizes the latent space to form a single compact cluster
per class, while avoiding to disturb existing clusters during optimization. We
evaluate our approach on three benchmarks and compare to state-of-the art with
promising results. Our approach combines the benefits of graph-based
regularization with efficient, inductive inference, does not require
modifications to a network architecture, and can thus be easily applied to
existing networks to enable an effective use of unlabeled data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kamnitsas_K/0/1/0/all/0/1&quot;&gt;Konstantinos Kamnitsas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Castro_D/0/1/0/all/0/1&quot;&gt;Daniel C. Castro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Folgoc_L/0/1/0/all/0/1&quot;&gt;Loic Le Folgoc&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Walker_I/0/1/0/all/0/1&quot;&gt;Ian Walker&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tanno_R/0/1/0/all/0/1&quot;&gt;Ryutaro Tanno&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rueckert_D/0/1/0/all/0/1&quot;&gt;Daniel Rueckert&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Glocker_B/0/1/0/all/0/1&quot;&gt;Ben Glocker&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Criminisi_A/0/1/0/all/0/1&quot;&gt;Antonio Criminisi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nori_A/0/1/0/all/0/1&quot;&gt;Aditya Nori&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02706">
<title>Multiobjective Test Problems with Degenerate Pareto Fronts. (arXiv:1806.02706v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1806.02706</link>
<description rdf:parseType="Literal">&lt;p&gt;In multiobjective optimization, a set of scalable test problems with a
variety of features allows researchers to investigate and evaluate abilities of
different optimization algorithms, and thus can help them to design and develop
more effective and efficient approaches. Existing, commonly-used test problem
suites are mainly focused on the situations where all the objectives are
conflicting with each other. However, in some many-objective optimization
problems, there may be unexpected characteristics among objectives, e.g.,
redundancy. This leads to a degenerate problem. In this paper, we
systematically study degenerate problems. We abstract three generic
characteristics of degenerate problems, and on the basis of these
characteristics we present a set of test problems, in order to support the
investigation of multiobjective search algorithms on problems with redundant
objectives. To assess the proposed test problems, ten representative
multiobjective evolutionary algorithms are tested. The results indicate that
none of the tested algorithms is able to effectively solve these proposed
problems, calling for the need of developing new approaches to addressing
degenerate multi-objective problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhen_L/0/1/0/all/0/1&quot;&gt;Liangli Zhen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_M/0/1/0/all/0/1&quot;&gt;Miqing Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_R/0/1/0/all/0/1&quot;&gt;Ran Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peng_D/0/1/0/all/0/1&quot;&gt;Dezhong Peng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yao_X/0/1/0/all/0/1&quot;&gt;Xin Yao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1704.00026">
<title>Upper Bounds on the Runtime of the Univariate Marginal Distribution Algorithm on OneMax. (arXiv:1704.00026v4 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1704.00026</link>
<description rdf:parseType="Literal">&lt;p&gt;A runtime analysis of the Univariate Marginal Distribution Algorithm (UMDA)
is presented on the OneMax function for wide ranges of its parameters $\mu$ and
$\lambda$. If $\mu\ge c\log n$ for some constant $c&amp;gt;0$ and
$\lambda=(1+\Theta(1))\mu$, a general bound $O(\mu n)$ on the expected runtime
is obtained. This bound crucially assumes that all marginal probabilities of
the algorithm are confined to the interval $[1/n,1-1/n]$. If $\mu\ge c&apos;
\sqrt{n}\log n$ for a constant $c&apos;&amp;gt;0$ and $\lambda=(1+\Theta(1))\mu$, the
behavior of the algorithm changes and the bound on the expected runtime becomes
$O(\mu\sqrt{n})$, which typically even holds if the borders on the marginal
probabilities are omitted.
&lt;/p&gt;
&lt;p&gt;The results supplement the recently derived lower bound
$\Omega(\mu\sqrt{n}+n\log n)$ by Krejca and Witt (FOGA 2017) and turn out as
tight for the two very different values $\mu=c\log n$ and $\mu=c&apos;\sqrt{n}\log
n$. They also improve the previously best known upper bound $O(n\log n\log\log
n)$ by Dang and Lehre (GECCO 2015).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Witt_C/0/1/0/all/0/1&quot;&gt;Carsten Witt&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.03620">
<title>Optimal approximation of continuous functions by very deep ReLU networks. (arXiv:1802.03620v2 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1802.03620</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider approximations of general continuous functions on
finite-dimensional cubes by general deep ReLU neural networks and study the
approximation rates with respect to the modulus of continuity of the function
and the total number of weights $W$ in the network. We establish the complete
phase diagram of feasible approximation rates and show that it includes two
distinct phases. One phase corresponds to slower approximations that can be
achieved with constant-depth networks and continuous weight assignments. The
other phase provides faster approximations at the cost of depths necessarily
growing as a power law $L\sim W^{\alpha}, 0&amp;lt;\alpha\le 1,$ and with necessarily
discontinuous weight assignments. In particular, we prove that constant-width
fully-connected networks of depth $L\sim W$ provide the fastest possible
approximation rate $\|f-\widetilde f\|_\infty = O(\omega_f(O(W^{-2/\nu})))$
that cannot be achieved with less deep networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yarotsky_D/0/1/0/all/0/1&quot;&gt;Dmitry Yarotsky&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.05174">
<title>Multi-objective Analysis of MAP-Elites Performance. (arXiv:1803.05174v2 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1803.05174</link>
<description rdf:parseType="Literal">&lt;p&gt;In certain complex optimization tasks, it becomes necessary to use multiple
measures to characterize the performance of different algorithms. This paper
presents a method that combines ordinal effect sizes with Pareto dominance to
analyze such cases. Since the method is ordinal, it can also generalize across
different optimization tasks even when the performance measurements are
differently scaled. Through a case study, we show that this method can discover
and quantify relations that would be difficult to deduce using a conventional
measure-by-measure analysis. This case study applies the method to the
evolution of robot controller repertoires using the MAP-Elites algorithm. Here,
we analyze the search performance across a large set of parametrizations;
varying mutation size and operator type, as well as map resolution, across four
different robot morphologies. We show that the average magnitude of mutations
has a bigger effect on outcomes than their precise distributions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Samuelsen_E/0/1/0/all/0/1&quot;&gt;Eivind Samuelsen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Glette_K/0/1/0/all/0/1&quot;&gt;Kyrre Glette&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.09331">
<title>Where are we now? A large benchmark study of recent symbolic regression methods. (arXiv:1804.09331v2 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1804.09331</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper we provide a broad benchmarking of recent genetic programming
approaches to symbolic regression in the context of state of the art machine
learning approaches. We use a set of nearly 100 regression benchmark problems
culled from open source repositories across the web. We conduct a rigorous
benchmarking of four recent symbolic regression approaches as well as nine
machine learning approaches from scikit-learn. The results suggest that
symbolic regression performs strongly compared to state-of-the-art gradient
boosting algorithms, although in terms of running times is among the slowest of
the available methodologies. We discuss the results in detail and point to
future research directions that may allow symbolic regression to gain wider
adoption in the machine learning community.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Orzechowski_P/0/1/0/all/0/1&quot;&gt;Patryk Orzechowski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cava_W/0/1/0/all/0/1&quot;&gt;William La Cava&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moore_J/0/1/0/all/0/1&quot;&gt;Jason H. Moore&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02373">
<title>Dempsterian-Shaferian Belief Network From Data. (arXiv:1806.02373v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1806.02373</link>
<description rdf:parseType="Literal">&lt;p&gt;Shenoy and Shafer {Shenoy:90} demonstrated that both for Dempster-Shafer
Theory and probability theory there exists a possibility to calculate
efficiently marginals of joint belief distributions (by so-called local
computations) provided that the joint distribution can be decomposed
(factorized) into a belief network. A number of algorithms exists for
decomposition of probabilistic joint belief distribution into a bayesian
(belief) network from data. For example
&lt;/p&gt;
&lt;p&gt;Spirtes, Glymour and Schein{Spirtes:90b} formulated a Conjecture that a
direct dependence test and a head-to-head meeting test would suffice to
construe bayesian network from data in such a way that Pearl&apos;s concept of
d-separation {Geiger:90} applies.
&lt;/p&gt;
&lt;p&gt;This paper is intended to transfer Spirtes, Glymour and Scheines
{Spirtes:90b} approach onto the ground of the Dempster-Shafer Theory (DST). For
this purpose, a frequentionistic interpretation of the DST developed in
{Klopotek:93b} is exploited. A special notion of conditionality for DST is
introduced and demonstrated to behave with respect to Pearl&apos;s d-separation
{Geiger:90} much the same way as conditional probability (though some
differences like non-uniqueness are evident). Based on this, an algorithm
analogous to that from {Spirtes:90b} is developed.
&lt;/p&gt;
&lt;p&gt;The notion of a partially oriented graph (pog) is introduced and within this
graph the notion of p-d-separation is defined. If direct dependence test and
head-to-head meeting test are used to orient the pog then its p-d-separation is
shown to be equivalent to the Pearl&apos;s d-separation for any compatible dag.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Klopotek_M/0/1/0/all/0/1&quot;&gt;Mieczys&amp;#x142;aw A. K&amp;#x142;opotek&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02380">
<title>Causal Interventions for Fairness. (arXiv:1806.02380v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.02380</link>
<description rdf:parseType="Literal">&lt;p&gt;Most approaches in algorithmic fairness constrain machine learning methods so
the resulting predictions satisfy one of several intuitive notions of fairness.
While this may help private companies comply with non-discrimination laws or
avoid negative publicity, we believe it is often too little, too late. By the
time the training data is collected, individuals in disadvantaged groups have
already suffered from discrimination and lost opportunities due to factors out
of their control. In the present work we focus instead on interventions such as
a new public policy, and in particular, how to maximize their positive effects
while improving the fairness of the overall system. We use causal methods to
model the effects of interventions, allowing for potential interference--each
individual&apos;s outcome may depend on who else receives the intervention. We
demonstrate this with an example of allocating a budget of teaching resources
using a dataset of schools in New York City.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kusner_M/0/1/0/all/0/1&quot;&gt;Matt J. Kusner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Russell_C/0/1/0/all/0/1&quot;&gt;Chris Russell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Loftus_J/0/1/0/all/0/1&quot;&gt;Joshua R. Loftus&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Silva_R/0/1/0/all/0/1&quot;&gt;Ricardo Silva&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02415">
<title>Gaussian Mixture Reduction for Time-Constrained Approximate Inference in Hybrid Bayesian Networks. (arXiv:1806.02415v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1806.02415</link>
<description rdf:parseType="Literal">&lt;p&gt;Hybrid Bayesian Networks (HBNs), which contain both discrete and continuous
variables, arise naturally in many application areas (e.g., image
understanding, data fusion, medical diagnosis, fraud detection). This paper
concerns inference in an important subclass of HBNs, the conditional Gaussian
(CG) networks, in which all continuous random variables have Gaussian
distributions and all children of continuous random variables must be
continuous. Inference in CG networks can be NP-hard even for special-case
structures, such as poly-trees, where inference in discrete Bayesian networks
can be performed in polynomial time. Therefore, approximate inference is
required. In approximate inference, it is often necessary to trade off accuracy
against solution time. This paper presents an extension to the Hybrid Message
Passing inference algorithm for general CG networks and an algorithm for
optimizing its accuracy given a bound on computation time. The extended
algorithm uses Gaussian mixture reduction to prevent an exponential increase in
the number of Gaussian mixture components. The trade-off algorithm performs
pre-processing to find optimal run-time settings for the extended algorithm.
Experimental results for four CG networks compare performance of the extended
algorithm with existing algorithms and show the optimal settings for these CG
networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Park_C/0/1/0/all/0/1&quot;&gt;Cheol Young Park&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Laskey_K/0/1/0/all/0/1&quot;&gt;Kathryn Blackmond Laskey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Costa_P/0/1/0/all/0/1&quot;&gt;Paulo C. G. Costa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Matsumoto_S/0/1/0/all/0/1&quot;&gt;Shou Matsumoto&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02421">
<title>Human-aided Multi-Entity Bayesian Networks Learning from Relational Data. (arXiv:1806.02421v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.02421</link>
<description rdf:parseType="Literal">&lt;p&gt;An Artificial Intelligence (AI) system is an autonomous system which emulates
human mental and physical activities such as Observe, Orient, Decide, and Act,
called the OODA process. An AI system performing the OODA process requires a
semantically rich representation to handle a complex real world situation and
ability to reason under uncertainty about the situation. Multi-Entity Bayesian
Networks (MEBNs) combines First-Order Logic with Bayesian Networks for
representing and reasoning about uncertainty in complex, knowledge-rich
domains. MEBN goes beyond standard Bayesian networks to enable reasoning about
an unknown number of entities interacting with each other in various types of
relationships, a key requirement for the OODA process of an AI system. MEBN
models have heretofore been constructed manually by a domain expert. However,
manual MEBN modeling is labor-intensive and insufficiently agile. To address
these problems, an efficient method is needed for MEBN modeling. One of the
methods is to use machine learning to learn a MEBN model in whole or in part
from data. In the era of Big Data, data-rich environments, characterized by
uncertainty and complexity, have become ubiquitous. The larger the data sample
is, the more accurate the results of the machine learning approach can be.
Therefore, machine learning has potential to improve the quality of MEBN models
as well as the effectiveness for MEBN modeling. In this research, we study a
MEBN learning framework to develop a MEBN model from a combination of domain
expert&apos;s knowledge and data. To evaluate the MEBN learning framework, we
conduct an experiment to compare the MEBN learning framework and the existing
manual MEBN modeling in terms of development efficiency.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Park_C/0/1/0/all/0/1&quot;&gt;Cheol Young Park&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Laskey_K/0/1/0/all/0/1&quot;&gt;Kathryn Blackmond Laskey&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02457">
<title>Reference Model of Multi-Entity Bayesian Networks for Predictive Situation Awareness. (arXiv:1806.02457v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1806.02457</link>
<description rdf:parseType="Literal">&lt;p&gt;During the past quarter-century, situation awareness (SAW) has become a
critical research theme, because of its importance. Since the concept of SAW
was first introduced during World War I, various versions of SAW have been
researched and introduced. Predictive Situation Awareness (PSAW) focuses on the
ability to predict aspects of a temporally evolving situation over time. PSAW
requires a formal representation and a reasoning method using such a
representation. A Multi-Entity Bayesian Network (MEBN) is a knowledge
representation formalism combining Bayesian Networks (BN) with First-Order
Logic (FOL). MEBN can be used to represent uncertain situations (supported by
BN) as well as complex situations (supported by FOL). Also, efficient reasoning
algorithms for MEBN have been developed. MEBN can be a formal representation to
support PSAW and has been used for several PSAW systems. Although several MEBN
applications for PSAW exist, very little work can be found in the literature
that attempts to generalize a MEBN model to support PSAW. In this research, we
define a reference model for MEBN in PSAW, called a PSAW-MEBN reference model.
The PSAW-MEBN reference model enables us to easily develop a MEBN model for
PSAW by supporting the design of a MEBN model for PSAW. In this research, we
introduce two example use cases using the PSAW-MEBN reference model to develop
MEBN models to support PSAW: a Smart Manufacturing System and a Maritime Domain
Awareness System.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Parka_C/0/1/0/all/0/1&quot;&gt;Cheol Young Parka&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Laskey_K/0/1/0/all/0/1&quot;&gt;Kathryn Blackmond Laskey&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02473">
<title>Graph Convolutional Policy Network for Goal-Directed Molecular Graph Generation. (arXiv:1806.02473v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.02473</link>
<description rdf:parseType="Literal">&lt;p&gt;Generating novel graph structures that optimize given objectives while
obeying some given underlying rules is fundamental for chemistry, biology and
social science research. This is especially important in the task of molecular
graph generation, whose goal is to discover novel molecules with desired
properties such as drug-likeness and synthetic accessibility, while obeying
physical laws such as chemical valency. However, designing models to find
molecules that optimize desired properties while incorporating highly complex
and non-differentiable rules remains to be a challenging task. Here we propose
Graph Convolutional Policy Network (GCPN), a general graph convolutional
network based model for goal-directed graph generation through reinforcement
learning. The model is trained to optimize domain-specific rewards and
adversarial loss through policy gradient, and acts in an environment that
incorporates domain-specific rules. Experimental results show that GCPN can
achieve 61% improvement on chemical property optimization over state-of-the-art
baselines while resembling known molecules, and achieve 184% improvement on the
constrained property optimization task.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+You_J/0/1/0/all/0/1&quot;&gt;Jiaxuan You&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_B/0/1/0/all/0/1&quot;&gt;Bowen Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ying_R/0/1/0/all/0/1&quot;&gt;Rex Ying&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pande_V/0/1/0/all/0/1&quot;&gt;Vijay Pande&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leskovec_J/0/1/0/all/0/1&quot;&gt;Jure Leskovec&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02501">
<title>Simplifying Reward Design through Divide-and-Conquer. (arXiv:1806.02501v1 [cs.RO])</title>
<link>http://arxiv.org/abs/1806.02501</link>
<description rdf:parseType="Literal">&lt;p&gt;Designing a good reward function is essential to robot planning and
reinforcement learning, but it can also be challenging and frustrating. The
reward needs to work across multiple different environments, and that often
requires many iterations of tuning. We introduce a novel divide-and-conquer
approach that enables the designer to specify a reward separately for each
environment. By treating these separate reward functions as observations about
the underlying true reward, we derive an approach to infer a common reward
across all environments. We conduct user studies in an abstract grid world
domain and in a motion planning domain for a 7-DOF manipulator that measure
user effort and solution quality. We show that our method is faster, easier to
use, and produces a higher quality solution than the typical method of
designing a reward jointly across all environments. We additionally conduct a
series of experiments that measure the sensitivity of these results to
different properties of the reward design task, such as the number of
environments, the number of feasible solutions per environment, and the
fraction of the total features that vary within each environment. We find that
independent reward design outperforms the standard, joint, reward design
process but works best when the design problem can be divided into simpler
subproblems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ratner_E/0/1/0/all/0/1&quot;&gt;Ellis Ratner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hadfield_Menell_D/0/1/0/all/0/1&quot;&gt;Dylan Hadfield-Menell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dragan_A/0/1/0/all/0/1&quot;&gt;Anca D. Dragan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02510">
<title>Removing Algorithmic Discrimination (With Minimal Individual Error). (arXiv:1806.02510v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1806.02510</link>
<description rdf:parseType="Literal">&lt;p&gt;We address the problem of correcting group discriminations within a score
function, while minimizing the individual error. Each group is described by a
probability density function on the set of profiles. We first solve the problem
analytically in the case of two populations, with a uniform bonus-malus on the
zones where each population is a majority. We then address the general case of
n populations, where the entanglement of populations does not allow a similar
analytical solution. We show that an approximate solution with an arbitrarily
high level of precision can be computed with linear programming. Finally, we
address the inverse problem where the error should not go beyond a certain
value and we seek to minimize the discrimination.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mhamdi_E/0/1/0/all/0/1&quot;&gt;El Mahdi El Mhamdi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guerraoui_R/0/1/0/all/0/1&quot;&gt;Rachid Guerraoui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hoang_L/0/1/0/all/0/1&quot;&gt;L&amp;#xea; Nguy&amp;#xea;n Hoang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Maurer_A/0/1/0/all/0/1&quot;&gt;Alexandre Maurer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02623">
<title>Spectral Network Embedding: A Fast and Scalable Method via Sparsity. (arXiv:1806.02623v1 [cs.SI])</title>
<link>http://arxiv.org/abs/1806.02623</link>
<description rdf:parseType="Literal">&lt;p&gt;Network embedding aims to learn low-dimensional representations of nodes in a
network, while the network structure and inherent properties are preserved. It
has attracted tremendous attention recently due to significant progress in
downstream network learning tasks, such as node classification, link
prediction, and visualization. However, most existing network embedding methods
suffer from the expensive computations due to the large volume of networks. In
this paper, we propose a $10\times \sim 100\times$ faster network embedding
method, called Progle, by elegantly utilizing the sparsity property of online
networks and spectral analysis. In Progle, we first construct a \textit{sparse}
proximity matrix and train the network embedding efficiently via sparse matrix
decomposition. Then we introduce a network propagation pattern via spectral
analysis to incorporate local and global structure information into the
embedding. Besides, this model can be generalized to integrate network
information into other insufficiently trained embeddings at speed. Benefiting
from sparse spectral network embedding, our experiment on four different
datasets shows that Progle outperforms or is comparable to state-of-the-art
unsupervised comparison approaches---DeepWalk, LINE, node2vec, GraRep, and
HOPE, regarding accuracy, while is $10\times$ faster than the fastest
word2vec-based method. Finally, we validate the scalability of Progle both in
real large-scale networks and multiple scales of synthetic networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Jie Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yan Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1&quot;&gt;Jie Tang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02664">
<title>Probabilistic AND-OR Attribute Grouping for Zero-Shot Learning. (arXiv:1806.02664v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1806.02664</link>
<description rdf:parseType="Literal">&lt;p&gt;In zero-shot learning (ZSL), a classifier is trained to recognize visual
classes without any image samples. Instead, it is given semantic information
about the class, like a textual description or a set of attributes. Learning
from attributes could benefit from explicitly modeling structure of the
attribute space. Unfortunately, learning of general structure from empirical
samples is hard with typical dataset sizes.
&lt;/p&gt;
&lt;p&gt;Here we describe LAGO, a probabilistic model designed to capture natural soft
and-or relations across groups of attributes. We show how this model can be
learned end-to-end with a deep attribute-detection model. The soft group
structure can be learned from data jointly as part of the model, and can also
readily incorporate prior knowledge about groups if available. The soft and-or
structure succeeds to capture meaningful and predictive structures, improving
the accuracy of zero-shot learning on two of three benchmarks.
&lt;/p&gt;
&lt;p&gt;Finally, LAGO reveals a unified formulation over two ZSL approaches: DAP
(Lampert et al. 2009) and ESZSL (Romera-Paredes &amp;amp; Torr, 2015). Interestingly,
taking only one singleton group for each attribute, introduces a new
soft-relaxation of DAP, that outperforms DAP by ~40%.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Atzmon_Y/0/1/0/all/0/1&quot;&gt;Yuval Atzmon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chechik_G/0/1/0/all/0/1&quot;&gt;Gal Chechik&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02711">
<title>POTs: The revolution will not be optimized?. (arXiv:1806.02711v1 [cs.CY])</title>
<link>http://arxiv.org/abs/1806.02711</link>
<description rdf:parseType="Literal">&lt;p&gt;Optimization systems infer, induce, and shape events in the real world to
fulfill objective functions. Protective optimization technologies (POTs)
reconfigure these events as a response to the effects of optimization on a
group of users or local environment. POTs analyze how events (or lack thereof)
affect users and environments, then manipulate these events to influence system
outcomes, e.g., by altering the optimization constraints and poisoning system
inputs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gurses_S/0/1/0/all/0/1&quot;&gt;Seda Gurses&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Overdorf_R/0/1/0/all/0/1&quot;&gt;Rebekah Overdorf&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Balsa_E/0/1/0/all/0/1&quot;&gt;Ero Balsa&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02739">
<title>Discovering space - Grounding spatial topology and metric regularity in a naive agent&apos;s sensorimotor experience. (arXiv:1806.02739v1 [cs.RO])</title>
<link>http://arxiv.org/abs/1806.02739</link>
<description rdf:parseType="Literal">&lt;p&gt;In line with the sensorimotor contingency theory, we investigate the problem
of the perception of space from a fundamental sensorimotor perspective. Despite
its pervasive nature in our perception of the world, the origin of the concept
of space remains largely mysterious. For example in the context of artificial
perception, this issue is usually circumvented by having engineers pre-define
the spatial structure of the problem the agent has to face. We here show that
the structure of space can be autonomously discovered by a naive agent in the
form of sensorimotor regularities, that correspond to so called compensable
sensory experiences: these are experiences that can be generated either by the
agent or its environment. By detecting such compensable experiences the agent
can infer the topological and metric structure of the external space in which
its body is moving. We propose a theoretical description of the nature of these
regularities and illustrate the approach on a simulated robotic arm equipped
with an eye-like sensor, and which interacts with an object. Finally we show
how these regularities can be used to build an internal representation of the
sensor&apos;s external spatial configuration.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alban_A/0/1/0/all/0/1&quot;&gt;Alban Laflaquiere Alban&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+ORegan_J/0/1/0/all/0/1&quot;&gt;J.Kevin O&amp;#x27;Regan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gas_B/0/1/0/all/0/1&quot;&gt;Bruno Gas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Terekhov_A/0/1/0/all/0/1&quot;&gt;Alexander Terekhov&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02813">
<title>Self-Consistent Trajectory Autoencoder: Hierarchical Reinforcement Learning with Trajectory Embeddings. (arXiv:1806.02813v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.02813</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work, we take a representation learning perspective on hierarchical
reinforcement learning, where the problem of learning lower layers in a
hierarchy is transformed into the problem of learning trajectory-level
generative models. We show that we can learn continuous latent representations
of trajectories, which are effective in solving temporally extended and
multi-stage problems. Our proposed model, SeCTAR, draws inspiration from
variational autoencoders, and learns latent representations of trajectories. A
key component of this method is to learn both a latent-conditioned policy and a
latent-conditioned model which are consistent with each other. Given the same
latent, the policy generates a trajectory which should match the trajectory
predicted by the model. This model provides a built-in prediction mechanism, by
predicting the outcome of closed loop policy behavior. We propose a novel
algorithm for performing hierarchical RL with this model, combining model-based
planning in the learned latent space with an unsupervised exploration
objective. We show that our model is effective at reasoning over long horizons
with sparse rewards for several simulated tasks, outperforming standard
reinforcement learning methods and prior methods for hierarchical reasoning,
model-based planning, and exploration.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Co_Reyes_J/0/1/0/all/0/1&quot;&gt;John D. Co-Reyes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;YuXuan Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gupta_A/0/1/0/all/0/1&quot;&gt;Abhishek Gupta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Eysenbach_B/0/1/0/all/0/1&quot;&gt;Benjamin Eysenbach&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abbeel_P/0/1/0/all/0/1&quot;&gt;Pieter Abbeel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1&quot;&gt;Sergey Levine&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02814">
<title>Embedding Transfer for Low-Resource Medical Named Entity Recognition: A Case Study on Patient Mobility. (arXiv:1806.02814v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1806.02814</link>
<description rdf:parseType="Literal">&lt;p&gt;Functioning is gaining recognition as an important indicator of global
health, but remains under-studied in medical natural language processing
research. We present the first analysis of automatically extracting
descriptions of patient mobility, using a recently-developed dataset of free
text electronic health records. We frame the task as a named entity recognition
(NER) problem, and investigate the applicability of NER techniques to mobility
extraction. As text corpora focused on patient functioning are scarce, we
explore domain adaptation of word embeddings for use in a recurrent neural
network NER system. We find that embeddings trained on a small in-domain corpus
perform nearly as well as those learned from large out-of-domain corpora, and
that domain adaptation techniques yield additional improvements in both
precision and recall. Our analysis identifies several significant challenges in
extracting descriptions of patient mobility, including the length and
complexity of annotated entities and high linguistic variability in mobility
descriptions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Newman_Griffis_D/0/1/0/all/0/1&quot;&gt;Denis Newman-Griffis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zirikly_A/0/1/0/all/0/1&quot;&gt;Ayah Zirikly&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.03243">
<title>Selecting Representative Examples for Program Synthesis. (arXiv:1711.03243v3 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1711.03243</link>
<description rdf:parseType="Literal">&lt;p&gt;Program synthesis is a class of regression problems where one seeks a
solution, in the form of a source-code program, mapping the inputs to their
corresponding outputs exactly. Due to its precise and combinatorial nature,
program synthesis is commonly formulated as a constraint satisfaction problem,
where input-output examples are encoded as constraints and solved with a
constraint solver. A key challenge of this formulation is scalability: while
constraint solvers work well with a few well-chosen examples, a large set of
examples can incur significant overhead in both time and memory. We describe a
method to discover a subset of examples that is both small and representative:
the subset is constructed iteratively, using a neural network to predict the
probability of unchosen examples conditioned on the chosen examples in the
subset, and greedily adding the least probable example. We empirically evaluate
the representativeness of the subsets constructed by our method, and
demonstrate such subsets can significantly improve synthesis time and
stability.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pu_Y/0/1/0/all/0/1&quot;&gt;Yewen Pu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Miranda_Z/0/1/0/all/0/1&quot;&gt;Zachery Miranda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Solar_Lezama_A/0/1/0/all/0/1&quot;&gt;Armando Solar-Lezama&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kaelbling_L/0/1/0/all/0/1&quot;&gt;Leslie Pack Kaelbling&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.00420">
<title>Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples. (arXiv:1802.00420v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1802.00420</link>
<description rdf:parseType="Literal">&lt;p&gt;We identify obfuscated gradients, a kind of gradient masking, as a phenomenon
that leads to a false sense of security in defenses against adversarial
examples. While defenses that cause obfuscated gradients appear to defeat
iterative optimization-based attacks, we find defenses relying on this effect
can be circumvented. We describe characteristic behaviors of defenses
exhibiting the effect, and for each of the three types of obfuscated gradients
we discover, we develop attack techniques to overcome it. In a case study,
examining non-certified white-box-secure defenses at ICLR 2018, we find
obfuscated gradients are a common occurrence, with 7 of 9 defenses relying on
obfuscated gradients. Our new attacks successfully circumvent 6 completely, and
1 partially, in the original threat model each paper considers.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Athalye_A/0/1/0/all/0/1&quot;&gt;Anish Athalye&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Carlini_N/0/1/0/all/0/1&quot;&gt;Nicholas Carlini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wagner_D/0/1/0/all/0/1&quot;&gt;David Wagner&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07935">
<title>DEEPEYE: A Compact and Accurate Video Comprehension at Terminal Devices Compressed with Quantization and Tensorization. (arXiv:1805.07935v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1805.07935</link>
<description rdf:parseType="Literal">&lt;p&gt;As it requires a huge number of parameters when exposed to high dimensional
inputs in video detection and classification, there is a grand challenge to
develop a compact yet accurate video comprehension at terminal devices. Current
works focus on optimizations of video detection and classification in a
separated fashion. In this paper, we introduce a video comprehension (object
detection and action recognition) system for terminal devices, namely DEEPEYE.
Based on You Only Look Once (YOLO), we have developed an 8-bit quantization
method when training YOLO; and also developed a tensorized-compression method
of Recurrent Neural Network (RNN) composed of features extracted from YOLO. The
developed quantization and tensorization can significantly compress the
original network model yet with maintained accuracy. Using the challenging
video datasets: MOMENTS and UCF11 as benchmarks, the results show that the
proposed DEEPEYE achieves 3.994x model compression rate with only 0.47% mAP
decreased; and 15,047x parameter reduction and 2.87x speed-up with 16.58%
accuracy improvement.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_Y/0/1/0/all/0/1&quot;&gt;Yuan Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_G/0/1/0/all/0/1&quot;&gt;Guangya Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1&quot;&gt;Hai-Bao Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tan_S/0/1/0/all/0/1&quot;&gt;Sheldon X.-D. Tan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_H/0/1/0/all/0/1&quot;&gt;Hao Yu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00952">
<title>Stochastic Gradient/Mirror Descent: Minimax Optimality and Implicit Regularization. (arXiv:1806.00952v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1806.00952</link>
<description rdf:parseType="Literal">&lt;p&gt;Stochastic descent methods (of the gradient and mirror varieties) have become
increasingly popular in optimization. In fact, it is now widely recognized that
the success of deep learning is not only due to the special deep architecture
of the models, but also due to the behavior of the stochastic descent methods
used, which play a key role in reaching &quot;good&quot; solutions that generalize well
to unseen data. In an attempt to shed some light on why this is the case, we
revisit some minimax properties of stochastic gradient descent (SGD) on the
square loss of linear models---originally developed in the 1990&apos;s---and extend
them to generic stochastic mirror descent (SMD) algorithms on general loss
functions and nonlinear models. In particular, we show that there is a
fundamental identity which holds for SMD (and SGD) under very general
conditions, and that this identity implies the minimax optimality of SMD (and
SGD) with sufficiently small step size, for a general class of loss functions
and general nonlinear models. We further show that this identity can be used to
naturally establish other properties of SMD (and SGD), such as convergence and
&quot;implicit regularization&quot; for over-parameterized linear models, which have been
shown in certain cases in the literature. We also show how this identity can be
used in the so-called &quot;highly over-parameterized&quot; nonlinear setting to provide
insights into why SMD (and SGD) may have similar convergence and implicit
regularization properties for deep learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Azizan_N/0/1/0/all/0/1&quot;&gt;Navid Azizan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hassibi_B/0/1/0/all/0/1&quot;&gt;Babak Hassibi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02027">
<title>Discrete-Continuous Mixtures in Probabilistic Programming: Generalized Semantics and Inference Algorithms. (arXiv:1806.02027v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1806.02027</link>
<description rdf:parseType="Literal">&lt;p&gt;Despite the recent successes of probabilistic programming languages (PPLs) in
AI applications, PPLs offer only limited support for random variables whose
distributions combine discrete and continuous elements. We develop the notion
of measure-theoretic Bayesian networks (MTBNs) and use it to provide more
general semantics for PPLs with arbitrarily many random variables defined over
arbitrary measure spaces. We develop two new general sampling algorithms that
are provably correct under the MTBN framework: the lexicographic likelihood
weighting (LLW) for general MTBNs and the lexicographic particle filter (LPF),
a specialized algorithm for state-space models. We further integrate MTBNs into
a widely used PPL system, BLOG, and verify the effectiveness of the new
inference algorithms through representative examples.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Y/0/1/0/all/0/1&quot;&gt;Yi Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Srivastava_S/0/1/0/all/0/1&quot;&gt;Siddharth Srivastava&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hay_N/0/1/0/all/0/1&quot;&gt;Nicholas Hay&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Du_S/0/1/0/all/0/1&quot;&gt;Simon Du&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Russell_S/0/1/0/all/0/1&quot;&gt;Stuart Russell&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.05339">
<title>Predicting Oral Disintegrating Tablet Formulations by Neural Network Techniques. (arXiv:1803.05339v1 [stat.ML] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1803.05339</link>
<description rdf:parseType="Literal">&lt;p&gt;Oral Disintegrating Tablets (ODTs) is a novel dosage form that can be
dissolved on the tongue within 3min or less especially for geriatric and
pediatric patients. Current ODT formulation studies usually rely on the
personal experience of pharmaceutical experts and trial-and-error in the
laboratory, which is inefficient and time-consuming. The aim of current
research was to establish the prediction model of ODT formulations with direct
compression process by Artificial Neural Network (ANN) and Deep Neural Network
(DNN) techniques. 145 formulation data were extracted from Web of Science. All
data sets were divided into three parts: training set (105 data), validation
set (20) and testing set (20). ANN and DNN were compared for the prediction of
the disintegrating time. The accuracy of the ANN model has reached 85.60%,
80.00% and 75.00% on the training set, validation set and testing set
respectively, whereas that of the DNN model was 85.60%, 85.00% and 80.00%,
respectively. Compared with the ANN, DNN showed the better prediction for ODT
formulations. It is the first time that deep neural network with the improved
dataset selection algorithm is applied to formulation prediction on small data.
The proposed predictive approach could evaluate the critical parameters about
quality control of formulation, and guide research and process development. The
implementation of this prediction model could effectively reduce drug product
development timeline and material usage, and proactively facilitate the
development of a robust drug product.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Han_R/0/1/0/all/0/1&quot;&gt;Run Han&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yang_Y/0/1/0/all/0/1&quot;&gt;Yilong Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xiaoshan Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ouyang_D/0/1/0/all/0/1&quot;&gt;Defang Ouyang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07472">
<title>Deep Dynamical Modeling and Control of Unsteady Fluid Flows. (arXiv:1805.07472v1 [cs.CE] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1805.07472</link>
<description rdf:parseType="Literal">&lt;p&gt;The design of flow control systems remains a challenge due to the nonlinear
nature of the equations that govern fluid flow. However, recent advances in
computational fluid dynamics (CFD) have enabled the simulation of complex fluid
flows with high accuracy, opening the possibility of using learning-based
approaches to facilitate controller design. We present a method for learning
the forced and unforced dynamics of airflow over a cylinder directly from CFD
data. The proposed approach, grounded in Koopman theory, is shown to produce
stable dynamical models that can predict the time evolution of the cylinder
system over extended time horizons. Finally, by performing model predictive
control with the learned dynamical models, we are able to find a
straightforward, interpretable control law for suppressing vortex shedding in
the wake of the cylinder.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Morton_J/0/1/0/all/0/1&quot;&gt;Jeremy Morton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Witherden_F/0/1/0/all/0/1&quot;&gt;Freddie D. Witherden&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jameson_A/0/1/0/all/0/1&quot;&gt;Antony Jameson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kochenderfer_M/0/1/0/all/0/1&quot;&gt;Mykel J. Kochenderfer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02137">
<title>A New Framework for Machine Intelligence: Concepts and Prototype. (arXiv:1806.02137v1 [cs.AI] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1806.02137</link>
<description rdf:parseType="Literal">&lt;p&gt;Machine learning (ML) and artificial intelligence (AI) have become hot topics
in many information processing areas, from chatbots to scientific data
analysis. At the same time, there is uncertainty about the possibility of
extending predominant ML technologies to become general solutions with
continuous learning capabilities. Here, a simple, yet comprehensive,
theoretical framework for intelligent systems is presented. A combination of
Mirror Compositional Representations (MCR) and a Solution-Critic Loop (SCL) is
proposed as a generic approach for different types of problems. A prototype
implementation is presented for document comparison using English Wikipedia
corpus.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Montoya_A/0/1/0/all/0/1&quot;&gt;Abel Torres Montoya&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02338">
<title>Towards Dependability Metrics for Neural Networks. (arXiv:1806.02338v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.02338</link>
<description rdf:parseType="Literal">&lt;p&gt;Neural networks and other data engineered models are instrumental in
developing automated driving components such as perception or intention
prediction. The safety-critical aspect of such a domain makes dependability of
neural networks a central concern for long living systems. Hence, it is of
great importance to support the development team in evaluating important
dependability attributes of the machine learning artifacts during their
development process. So far, there is no systematic framework available in
which a neural network can be evaluated against these important attributes. In
this paper, we address this challenge by proposing eight metrics that
characterize the robustness, interpretability, completeness, and correctness of
machine learning artifacts, enabling the development team to efficiently
identify dependability issues.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_C/0/1/0/all/0/1&quot;&gt;Chih-Hong Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nuhrenberg_G/0/1/0/all/0/1&quot;&gt;Georg N&amp;#xfc;hrenberg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Huang_C/0/1/0/all/0/1&quot;&gt;Chung-Hao Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yasuoka_H/0/1/0/all/0/1&quot;&gt;Hirotoshi Yasuoka&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02382">
<title>Universal Conditional Machine. (arXiv:1806.02382v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.02382</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a single neural probabilistic model based on variational
autoencoder that can be conditioned on an arbitrary subset of observed features
and then sample the remaining features in &quot;one shot&quot;. The features may be both
real-valued and categorical. Training of the model is performed by stochastic
variational Bayes. The experimental evaluation on synthetic data, as well as
feature imputation and image inpainting problems, shows the effectiveness of
the proposed approach and diversity of the generated samples.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ivanov_O/0/1/0/all/0/1&quot;&gt;Oleg Ivanov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Figurnov_M/0/1/0/all/0/1&quot;&gt;Michael Figurnov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Vetrov_D/0/1/0/all/0/1&quot;&gt;Dmitry Vetrov&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02390">
<title>Variational Implicit Processes. (arXiv:1806.02390v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.02390</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper introduces the variational implicit processes (VIPs), a Bayesian
nonparametric method based on a class of highly flexible priors over functions.
Similar to Gaussian processes (GPs), in implicit processes (IPs), an implicit
multivariate prior (data simulators, Bayesian neural networks, etc.) is placed
over any finite collections of random variables. A novel and efficient
variational inference algorithm for IPs is derived using wake-sleep updates,
which gives analytic solutions and allows scalable hyper-parameter learning
with stochastic optimization. Experiments on real-world regression datasets
demonstrate that VIPs return better uncertainty estimates and superior
performance over existing inference methods for GPs and Bayesian neural
networks. With a Bayesian LSTM as the implicit prior, the proposed approach
achieves state-of-the-art results on predicting power conversion efficiency of
molecules based on raw chemical formulas.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ma_C/0/1/0/all/0/1&quot;&gt;Chao Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yingzhen Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hernandez_Lobato_J/0/1/0/all/0/1&quot;&gt;Jos&amp;#xe9; Miguel Hern&amp;#xe1;ndez-Lobato&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02402">
<title>Localized Structured Prediction. (arXiv:1806.02402v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.02402</link>
<description rdf:parseType="Literal">&lt;p&gt;Key to structured prediction is exploiting the problem structure to simplify
the learning process. A major challenge arises when data exhibit a local
structure (e.g., are made by &quot;parts&quot;) that can be leveraged to better
approximate the relation between (parts of) the input and (parts of) the
output. Recent literature on signal processing, and in particular computer
vision, has shown that capturing these aspects is indeed essential to achieve
state-of-the-art performance. While such algorithms are typically derived on a
case-by-case basis, in this work we propose the first theoretical framework to
deal with part-based data from a general perspective. We derive a novel
approach to deal with these problems and study its generalization properties
within the setting of statistical learning theory. Our analysis is novel in
that it explicitly quantifies the benefits of leveraging the part-based
structure of the problem with respect to the learning rates of the proposed
estimator.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ciliberto_C/0/1/0/all/0/1&quot;&gt;Carlo Ciliberto&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bach_F/0/1/0/all/0/1&quot;&gt;Francis Bach&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rudi_A/0/1/0/all/0/1&quot;&gt;Alessandro Rudi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02450">
<title>A Finite Time Analysis of Temporal Difference Learning With Linear Function Approximation. (arXiv:1806.02450v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.02450</link>
<description rdf:parseType="Literal">&lt;p&gt;Temporal difference learning (TD) is a simple iterative algorithm used to
estimate the value function corresponding to a given policy in a Markov
decision process. Although TD is one of the most widely used algorithms in
reinforcement learning, its theoretical analysis has proved challenging and few
guarantees on its statistical efficiency are available. In this work, we
provide a \emph{simple and explicit finite time analysis} of temporal
difference learning with linear function approximation. Except for a few key
insights, our analysis mirrors standard techniques for analyzing stochastic
gradient descent algorithms, and therefore inherits the simplicity and elegance
of that literature. A final section of the paper shows that all of our main
results extend to Q-learning applied to high dimensional optimal stopping
problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bhandari_J/0/1/0/all/0/1&quot;&gt;Jalaj Bhandari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Russo_D/0/1/0/all/0/1&quot;&gt;Daniel Russo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singal_R/0/1/0/all/0/1&quot;&gt;Raghav Singal&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02455">
<title>MEBN-RM: A Mapping between Multi-Entity Bayesian Network and Relational Model. (arXiv:1806.02455v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.02455</link>
<description rdf:parseType="Literal">&lt;p&gt;Multi-Entity Bayesian Network (MEBN) is a knowledge representation formalism
combining Bayesian Networks (BN) with First-Order Logic (FOL). MEBN has
sufficient expressive power for general-purpose knowledge representation and
reasoning. Developing a MEBN model to support a given application is a
challenge, requiring definition of entities, relationships, random variables,
conditional dependence relationships, and probability distributions. When
available, data can be invaluable both to improve performance and to streamline
development. By far the most common format for available data is the relational
database (RDB). Relational databases describe and organize data according to
the Relational Model (RM). Developing a MEBN model from data stored in an RDB
therefore requires mapping between the two formalisms. This paper presents
MEBN-RM, a set of mapping rules between key elements of MEBN and RM. We
identify links between the two languages (RM and MEBN) and define four levels
of mapping from elements of RM to elements of MEBN. These definitions are
implemented in the MEBN-RM algorithm, which converts a relational schema in RM
to a partial MEBN model. Through this research, the software has been released
as a MEBN-RM open-source software tool. The method is illustrated through two
example use cases using MEBN-RM to develop MEBN models: a Critical
Infrastructure Defense System and a Smart Manufacturing System.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Parka_C/0/1/0/all/0/1&quot;&gt;Cheol Young Parka&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Laskey_K/0/1/0/all/0/1&quot;&gt;Kathryn Blackmond Laskey&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02485">
<title>Stochastic Block Models are a Discrete Surface Tension. (arXiv:1806.02485v1 [cs.SI])</title>
<link>http://arxiv.org/abs/1806.02485</link>
<description rdf:parseType="Literal">&lt;p&gt;Networks, which represent agents and interactions between them, arise in
myriad applications throughout the sciences, engineering, and even the
humanities. To understand large-scale structure in a network, a common task is
to cluster a network&apos;s nodes into sets called &quot;communities&quot; such that there are
dense connections within communities but sparse connections between them. A
popular and statistically principled method to perform such clustering is to
use a family of generative models known as stochastic block models (SBMs). In
this paper, we show that maximum likelihood estimation in an SBM is a network
analog of a well-known continuum surface-tension problem that arises from an
application in metallurgy. To illustrate the utility of this bridge, we
implement network analogs of three surface-tension algorithms, with which we
successfully recover planted community structure in synthetic networks and
which yield fascinating insights on empirical networks from the field of
hyperspectral video segmentation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Boyd_Z/0/1/0/all/0/1&quot;&gt;Zachary M. Boyd&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Porter_M/0/1/0/all/0/1&quot;&gt;Mason A. Porter&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bertozzi_A/0/1/0/all/0/1&quot;&gt;Andrea L. Bertozzi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02511">
<title>Exact Low Tubal Rank Tensor Recovery from Gaussian Measurements. (arXiv:1806.02511v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.02511</link>
<description rdf:parseType="Literal">&lt;p&gt;The recent proposed Tensor Nuclear Norm (TNN) [Lu et al., 2016; 2018a] is an
interesting convex penalty induced by the tensor SVD [Kilmer and Martin, 2011].
It plays a similar role as the matrix nuclear norm which is the convex
surrogate of the matrix rank. Considering that the TNN based Tensor Robust PCA
[Lu et al., 2018a] is an elegant extension of Robust PCA with a similar tight
recovery bound, it is natural to solve other low rank tensor recovery problems
extended from the matrix cases. However, the extensions and proofs are
generally tedious. The general atomic norm provides a unified view of
low-complexity structures induced norms, e.g., the $\ell_1$-norm and nuclear
norm. The sharp estimates of the required number of generic measurements for
exact recovery based on the atomic norm are known in the literature. In this
work, with a careful choice of the atomic set, we prove that TNN is a special
atomic norm. Then by computing the Gaussian width of certain cone which is
necessary for the sharp estimate, we achieve a simple bound for guaranteed low
tubal rank tensor recovery from Gaussian measurements. Specifically, we show
that by solving a TNN minimization problem, the underlying tensor of size
$n_1\times n_2\times n_3$ with tubal rank $r$ can be exactly recovered when the
given number of Gaussian measurements is $O(r(n_1+n_2-r)n_3)$. It is order
optimal when comparing with the degrees of freedom $r(n_1+n_2-r)n_3$. Beyond
the Gaussian mapping, we also give the recovery guarantee of tensor completion
based on the uniform random mapping by TNN minimization. Numerical experiments
verify our theoretical results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lu_C/0/1/0/all/0/1&quot;&gt;Canyi Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Feng_J/0/1/0/all/0/1&quot;&gt;Jiashi Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lin_Z/0/1/0/all/0/1&quot;&gt;Zhouchen Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yan_S/0/1/0/all/0/1&quot;&gt;Shuicheng Yan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02512">
<title>Importance weighted generative networks. (arXiv:1806.02512v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.02512</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep generative networks can simulate from a complex target distribution, by
minimizing a loss with respect to samples from that distribution. However,
often we do not have direct access to our target distribution - our data may be
subject to sample selection bias, or may be from a different but related
distribution. We present methods based on importance weighting that can
estimate the loss with respect to a target distribution, even if we cannot
access that distribution directly, in a variety of settings. These estimators,
which differentially weight the contribution of data to the loss function,
offer both theoretical guarantees and impressive empirical performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Diesendruck_M/0/1/0/all/0/1&quot;&gt;Maurice Diesendruck&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Elenberg_E/0/1/0/all/0/1&quot;&gt;Ethan R. Elenberg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sen_R/0/1/0/all/0/1&quot;&gt;Rajat Sen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Cole_G/0/1/0/all/0/1&quot;&gt;Guy W. Cole&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Shakkottai_S/0/1/0/all/0/1&quot;&gt;Sanjay Shakkottai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Williamson_S/0/1/0/all/0/1&quot;&gt;Sinead A. Williamson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02538">
<title>Segment-Based Credit Scoring Using Latent Clusters in the Variational Autoencoder. (arXiv:1806.02538v1 [cs.CE])</title>
<link>http://arxiv.org/abs/1806.02538</link>
<description rdf:parseType="Literal">&lt;p&gt;Identifying customer segments in retail banking portfolios with different
risk profiles can improve the accuracy of credit scoring. The Variational
Autoencoder (VAE) has shown promising results in different research domains,
and it has been documented the powerful information embedded in the latent
space of the VAE. We use the VAE and show that transforming the input data into
a meaningful representation, it is possible to steer configurations in the
latent space of the VAE. Specifically, the Weight of Evidence (WoE)
transformation encapsulates the propensity to fall into financial distress and
the latent space in the VAE preserves this characteristic in a well-defined
clustering structure. These clusters have considerably different risk profiles
and therefore are suitable not only for credit scoring but also for marketing
and customer purposes. This new clustering methodology offers solutions to some
of the challenges in the existing clustering algorithms, e.g., suggests the
number of clusters, assigns cluster labels to new customers, enables cluster
visualization, scales to large datasets, captures non-linear relationships
among others. Finally, for portfolios with a large number of customers in each
cluster, developing one classifier model per cluster can improve the credit
scoring assessment.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mancisidor_R/0/1/0/all/0/1&quot;&gt;Rogelio Andrade Mancisidor&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kampffmeyer_M/0/1/0/all/0/1&quot;&gt;Michael Kampffmeyer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aas_K/0/1/0/all/0/1&quot;&gt;Kjersti Aas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jenssen_R/0/1/0/all/0/1&quot;&gt;Robert Jenssen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02543">
<title>Grouped Gaussian Processes for Solar Power Prediction. (arXiv:1806.02543v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.02543</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider multi-task regression models where the observations are assumed
to be a linear combination of several latent node functions and weight
functions, which are both drawn from Gaussian process priors. Driven by the
problem of developing scalable methods for distributed solar power forecasting,
we propose coupled priors over groups of (node or weight) processes to estimate
a forecast model for solar power production at multiple distributed sites,
exploiting spatial dependence between functions. Our results show that our
approach provides better quantification of predictive uncertainties than
competing benchmarks while maintaining high point-prediction accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Dahl_A/0/1/0/all/0/1&quot;&gt;Astrid Dahl&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bonilla_E/0/1/0/all/0/1&quot;&gt;Edwin V. Bonilla&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02612">
<title>Dimensionality-Driven Learning with Noisy Labels. (arXiv:1806.02612v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1806.02612</link>
<description rdf:parseType="Literal">&lt;p&gt;Datasets with significant proportions of noisy (incorrect) class labels
present challenges for training accurate Deep Neural Networks (DNNs). We
propose a new perspective for understanding DNN generalization for such
datasets, by investigating the dimensionality of the deep representation
subspace of training samples. We show that from a dimensionality perspective,
DNNs exhibit quite distinctive learning styles when trained with clean labels
versus when trained with a proportion of noisy labels. Based on this finding,
we develop a new dimensionality-driven learning strategy, which monitors the
dimensionality of subspaces during training and adapts the loss function
accordingly. We empirically demonstrate that our approach is highly tolerant to
significant proportions of noisy labels, and can effectively learn
low-dimensional local subspaces that capture the data distribution.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_X/0/1/0/all/0/1&quot;&gt;Xingjun Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yisen Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Houle_M/0/1/0/all/0/1&quot;&gt;Michael E. Houle&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_S/0/1/0/all/0/1&quot;&gt;Shuo Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Erfani_S/0/1/0/all/0/1&quot;&gt;Sarah M. Erfani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xia_S/0/1/0/all/0/1&quot;&gt;Shu-Tao Xia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wijewickrema_S/0/1/0/all/0/1&quot;&gt;Sudanthi Wijewickrema&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bailey_J/0/1/0/all/0/1&quot;&gt;James Bailey&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02617">
<title>Asynchronous Stochastic Quasi-Newton MCMC for Non-Convex Optimization. (arXiv:1806.02617v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.02617</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent studies have illustrated that stochastic gradient Markov Chain Monte
Carlo techniques have a strong potential in non-convex optimization, where
local and global convergence guarantees can be shown under certain conditions.
By building up on this recent theory, in this study, we develop an
asynchronous-parallel stochastic L-BFGS algorithm for non-convex optimization.
The proposed algorithm is suitable for both distributed and shared-memory
settings. We provide formal theoretical analysis and show that the proposed
method achieves an ergodic convergence rate of ${\cal O}(1/\sqrt{N})$ ($N$
being the total number of iterations) and it can achieve a linear speedup under
certain conditions. We perform several experiments on both synthetic and real
datasets. The results support our theory and show that the proposed algorithm
provides a significant speedup over the recently proposed synchronous
distributed L-BFGS algorithm.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Simsekli_U/0/1/0/all/0/1&quot;&gt;Umut &amp;#x15e;im&amp;#x15f;ekli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yildiz_C/0/1/0/all/0/1&quot;&gt;&amp;#xc7;a&amp;#x11f;atay Y&amp;#x131;ld&amp;#x131;z&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Nguyen_T/0/1/0/all/0/1&quot;&gt;Thanh Huy Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Richard_G/0/1/0/all/0/1&quot;&gt;Ga&amp;#xeb;l Richard&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Cemgil_A/0/1/0/all/0/1&quot;&gt;A. Taylan Cemgil&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02659">
<title>Scalable Multi-Class Bayesian Support Vector Machines for Structured and Unstructured Data. (arXiv:1806.02659v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.02659</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce a new Bayesian multi-class support vector machine by formulating
a pseudo-likelihood for a multi-class hinge loss in the form of a
location-scale mixture of Gaussians. We derive a variational-inference-based
training objective for gradient-based learning. Additionally, we employ an
inducing point approximation which scales inference to large data sets.
Furthermore, we develop hybrid Bayesian neural networks that combine standard
deep learning components with the proposed model to enable learning for
unstructured data. We provide empirical evidence that our model outperforms the
competitor methods with respect to both training time and accuracy in
classification experiments on 68 structured and two unstructured data sets.
Finally, we highlight the key capability of our model in yielding prediction
uncertainty for classification by demonstrating its effectiveness in the tasks
of large-scale active learning and detection of adversarial images.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wistuba_M/0/1/0/all/0/1&quot;&gt;Martin Wistuba&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rawat_A/0/1/0/all/0/1&quot;&gt;Ambrish Rawat&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02714">
<title>A Study of EV BMS Cyber Security Based on Neural Network SOC Prediction. (arXiv:1806.02714v1 [stat.AP])</title>
<link>http://arxiv.org/abs/1806.02714</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent changes to greenhouse gas emission policies are catalyzing the
electric vehicle (EV) market making it readily accessible to consumers. While
there are challenges that arise with dense deployment of EVs, one of the major
future concerns is cyber security threat. In this paper, cyber security threats
in the form of tampering with EV battery&apos;s State of Charge (SOC) was explored.
A Back Propagation (BP) Neural Network (NN) was trained and tested based on
experimental data to estimate SOC of battery under normal operation and
cyber-attack scenarios. NeuralWare software was used to run scenarios.
Different statistic metrics of the predicted values were compared against the
actual values of the specific battery tested to measure the stability and
accuracy of the proposed BP network under different operating conditions. The
results showed that BP NN was able to capture and detect the false entries due
to a cyber-attack on its network.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rahman_S/0/1/0/all/0/1&quot;&gt;Syed Rahman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Aburub_H/0/1/0/all/0/1&quot;&gt;Haneen Aburub&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mekonnen_Y/0/1/0/all/0/1&quot;&gt;Yemeserach Mekonnen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sarwat_A/0/1/0/all/0/1&quot;&gt;Arif I.Sarwat&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02775">
<title>Stein Variational Gradient Descent Without Gradient. (arXiv:1806.02775v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.02775</link>
<description rdf:parseType="Literal">&lt;p&gt;Stein variational gradient decent (SVGD) has been shown to be a powerful
approximate inference algorithm for complex distributions. However, the
standard SVGD requires calculating the gradient of the target density and
cannot be applied when the gradient is unavailable. In this work, we develop a
gradient-free variant of SVGD (GF-SVGD), which replaces the true gradient with
a surrogate gradient, and corrects the induced bias by re-weighting the
gradients in a proper form. We show that our GF-SVGD can be viewed as the
standard SVGD with a special choice of kernel, and hence directly inherits the
theoretical properties of SVGD. We shed insights on the empirical choice of the
surrogate gradient and propose an annealed GF-SVGD that leverages the idea of
simulated annealing to improve the performance on high dimensional complex
distributions. Empirical studies show that our method consistently outperforms
a number of recent advanced gradient-free MCMC methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Han_J/0/1/0/all/0/1&quot;&gt;Jun Han&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Liu_Q/0/1/0/all/0/1&quot;&gt;Qiang Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02815">
<title>Data Summarization at Scale: A Two-Stage Submodular Approach. (arXiv:1806.02815v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.02815</link>
<description rdf:parseType="Literal">&lt;p&gt;The sheer scale of modern datasets has resulted in a dire need for
summarization techniques that identify representative elements in a dataset.
Fortunately, the vast majority of data summarization tasks satisfy an intuitive
diminishing returns condition known as submodularity, which allows us to find
nearly-optimal solutions in linear time. We focus on a two-stage submodular
framework where the goal is to use some given training functions to reduce the
ground set so that optimizing new functions (drawn from the same distribution)
over the reduced set provides almost as much value as optimizing them over the
entire ground set. In this paper, we develop the first streaming and
distributed solutions to this problem. In addition to providing strong
theoretical guarantees, we demonstrate both the utility and efficiency of our
algorithms on real-world tasks including image summarization and ride-share
optimization.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mitrovic_M/0/1/0/all/0/1&quot;&gt;Marko Mitrovic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kazemi_E/0/1/0/all/0/1&quot;&gt;Ehsan Kazemi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zadimoghaddam_M/0/1/0/all/0/1&quot;&gt;Morteza Zadimoghaddam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Karbasi_A/0/1/0/all/0/1&quot;&gt;Amin Karbasi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1611.02041">
<title>Does Distributionally Robust Supervised Learning Give Robust Classifiers?. (arXiv:1611.02041v5 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1611.02041</link>
<description rdf:parseType="Literal">&lt;p&gt;Distributionally Robust Supervised Learning (DRSL) is necessary for building
reliable machine learning systems. When machine learning is deployed in the
real world, its performance can be significantly degraded because test data may
follow a different distribution from training data. DRSL with f-divergences
explicitly considers the worst-case distribution shift by minimizing the
adversarially reweighted training loss. In this paper, we analyze this DRSL,
focusing on the classification scenario. Since the DRSL is explicitly
formulated for a distribution shift scenario, we naturally expect it to give a
robust classifier that can aggressively handle shifted distributions. However,
surprisingly, we prove that the DRSL just ends up giving a classifier that
exactly fits the given training distribution, which is too pessimistic. This
pessimism comes from two sources: the particular losses used in classification
and the fact that the variety of distributions to which the DRSL tries to be
robust is too wide. Motivated by our analysis, we propose simple DRSL that
overcomes this pessimism and empirically demonstrate its effectiveness.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hu_W/0/1/0/all/0/1&quot;&gt;Weihua Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Niu_G/0/1/0/all/0/1&quot;&gt;Gang Niu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sato_I/0/1/0/all/0/1&quot;&gt;Issei Sato&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sugiyama_M/0/1/0/all/0/1&quot;&gt;Masashi Sugiyama&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1611.04208">
<title>Joint mean and covariance estimation with unreplicated matrix-variate data. (arXiv:1611.04208v4 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1611.04208</link>
<description rdf:parseType="Literal">&lt;p&gt;It has been proposed that complex populations, such as those that arise in
genomics studies, may exhibit dependencies among observations as well as among
variables. This gives rise to the challenging problem of analyzing unreplicated
high-dimensional data with unknown mean and dependence structures.
Matrix-variate approaches that impose various forms of (inverse) covariance
sparsity allow flexible dependence structures to be estimated, but cannot
directly be applied when the mean and covariance matrices are estimated
jointly. We present a practical method utilizing generalized least squares and
penalized (inverse) covariance estimation to address this challenge. We
establish consistency and obtain rates of convergence for estimating the mean
parameters and covariance matrices. The advantages of our approaches are: (i)
dependence graphs and covariance structures can be estimated in the presence of
unknown mean structure, (ii) the mean structure becomes more efficiently
estimated when accounting for the dependence structure among observations; and
(iii) inferences about the mean parameters become correctly calibrated. We use
simulation studies and analysis of genomic data from a twin study of ulcerative
colitis to illustrate the statistical convergence and the performance of our
methods in practical settings. Several lines of evidence show that the test
statistics for differential gene expression produced by our methods are
correctly calibrated and improve power over conventional methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hornstein_M/0/1/0/all/0/1&quot;&gt;Michael Hornstein&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Fan_R/0/1/0/all/0/1&quot;&gt;Roger Fan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Shedden_K/0/1/0/all/0/1&quot;&gt;Kerby Shedden&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhou_S/0/1/0/all/0/1&quot;&gt;Shuheng Zhou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1702.08248">
<title>Scalable k-Means Clustering via Lightweight Coresets. (arXiv:1702.08248v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1702.08248</link>
<description rdf:parseType="Literal">&lt;p&gt;Coresets are compact representations of data sets such that models trained on
a coreset are provably competitive with models trained on the full data set. As
such, they have been successfully used to scale up clustering models to massive
data sets. While existing approaches generally only allow for multiplicative
approximation errors, we propose a novel notion of lightweight coresets that
allows for both multiplicative and additive errors. We provide a single
algorithm to construct lightweight coresets for k-means clustering as well as
soft and hard Bregman clustering. The algorithm is substantially faster than
existing constructions, embarrassingly parallel, and the resulting coresets are
smaller. We further show that the proposed approach naturally generalizes to
statistical k-means clustering and that, compared to existing results, it can
be used to compute smaller summaries for empirical risk minimization. In
extensive experiments, we demonstrate that the proposed algorithm outperforms
existing data summarization strategies in practice.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bachem_O/0/1/0/all/0/1&quot;&gt;Olivier Bachem&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lucic_M/0/1/0/all/0/1&quot;&gt;Mario Lucic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Krause_A/0/1/0/all/0/1&quot;&gt;Andreas Krause&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1706.01833">
<title>Online Adaptive Machine Learning Based Algorithm for Implied Volatility Surface Modeling. (arXiv:1706.01833v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1706.01833</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work, we design a machine learning based method, online adaptive
primal support vector regression (SVR), to model the implied volatility surface
(IVS). The algorithm proposed is the first derivation and implementation of an
online primal kernel SVR. It features enhancements that allow efficient online
adaptive learning by embedding the idea of local fitness and budget maintenance
to dynamically update support vectors upon pattern drifts. For algorithm
acceleration, we implement its most computationally intensive parts in a Field
Programmable Gate Arrays hardware, where a 132x speedup over CPU is achieved
during online prediction. Using intraday tick data from the E-mini S&amp;amp;P 500
options market, we show that the Gaussian kernel outperforms the linear kernel
in regulating the size of support vectors, and that our empirical IVS algorithm
beats two competing online methods with regards to model complexity and
regression errors (the mean absolute percentage error of our algorithm is up to
13%). Best results are obtained at the center of the IVS grid due to its larger
number of adjacent support vectors than the edges of the grid. Sensitivity
analysis is also presented to demonstrate how hyper parameters affect the error
rates and model complexity.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zeng_Y/0/1/0/all/0/1&quot;&gt;Yaxiong Zeng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Klabjan_D/0/1/0/all/0/1&quot;&gt;Diego Klabjan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1707.06792">
<title>Graphical posterior predictive classifier: Bayesian model averaging with particle Gibbs. (arXiv:1707.06792v4 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1707.06792</link>
<description rdf:parseType="Literal">&lt;p&gt;In this study, we present a multi-class graphical Bayesian predictive
classifier that incorporates the uncertainty in the model selection into the
standard Bayesian formalism. For each class, the dependence structure
underlying the observed features is represented by a set of decomposable
Gaussian graphical models. Emphasis is then placed on the Bayesian model
averaging which takes full account of the class-specific model uncertainty by
averaging over the posterior graph model probabilities. An explicit evaluation
of the model probabilities is well known to be infeasible. To address this
issue, we consider the particle Gibbs strategy of Olsson et al. (2018b) for
posterior sampling from decomposable graphical models which utilizes the
Christmas tree algorithm of Olsson et al. (2018a) as proposal kernel. We also
derive a strong hyper Markov law which we call the hyper normal Wishart law
that allow to perform the resultant Bayesian calculations locally. The proposed
predictive graphical classifier reveals superior performance compared to the
ordinary Bayesian predictive rule that does not account for the model
uncertainty, as well as to a number of out-of-the-box classifiers.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pavlenko_T/0/1/0/all/0/1&quot;&gt;Tatjana Pavlenko&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rios_F/0/1/0/all/0/1&quot;&gt;Felix Leopoldo Rios&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1708.01799">
<title>Efficient Contextual Bandits in Non-stationary Worlds. (arXiv:1708.01799v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1708.01799</link>
<description rdf:parseType="Literal">&lt;p&gt;Most contextual bandit algorithms minimize regret against the best fixed
policy, a questionable benchmark for non-stationary environments that are
ubiquitous in applications. In this work, we develop several efficient
contextual bandit algorithms for non-stationary environments by equipping
existing methods for i.i.d. problems with sophisticated statistical tests so as
to dynamically adapt to a change in distribution.
&lt;/p&gt;
&lt;p&gt;We analyze various standard notions of regret suited to non-stationary
environments for these algorithms, including interval regret, switching regret,
and dynamic regret. When competing with the best policy at each time, one of
our algorithms achieves regret $\mathcal{O}(\sqrt{ST})$ if there are $T$ rounds
with $S$ stationary periods, or more generally
$\mathcal{O}(\Delta^{1/3}T^{2/3})$ where $\Delta$ is some non-stationarity
measure. These results almost match the optimal guarantees achieved by an
inefficient baseline that is a variant of the classic Exp4 algorithm. The
dynamic regret result is also the first one for efficient and fully adversarial
contextual bandit.
&lt;/p&gt;
&lt;p&gt;Furthermore, while the results above require tuning a parameter based on the
unknown quantity $S$ or $\Delta$, we also develop a parameter free algorithm
achieving regret $\min\{S^{1/4}T^{3/4}, \Delta^{1/5}T^{4/5}\}$. This improves
and generalizes the best existing result $\Delta^{0.18}T^{0.82}$ by Karnin and
Anava (2016) which only holds for the two-armed bandit problem.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_H/0/1/0/all/0/1&quot;&gt;Haipeng Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wei_C/0/1/0/all/0/1&quot;&gt;Chen-Yu Wei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Agarwal_A/0/1/0/all/0/1&quot;&gt;Alekh Agarwal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Langford_J/0/1/0/all/0/1&quot;&gt;John Langford&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.11279">
<title>Interpretability Beyond Feature Attribution: Quantitative Testing with Concept Activation Vectors (TCAV). (arXiv:1711.11279v5 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1711.11279</link>
<description rdf:parseType="Literal">&lt;p&gt;The interpretation of deep learning models is a challenge due to their size,
complexity, and often opaque internal state. In addition, many systems, such as
image classifiers, operate on low-level features rather than high-level
concepts. To address these challenges, we introduce Concept Activation Vectors
(CAVs), which provide an interpretation of a neural net&apos;s internal state in
terms of human-friendly concepts. The key idea is to view the high-dimensional
internal state of a neural net as an aid, not an obstacle. We show how to use
CAVs as part of a technique, Testing with CAVs (TCAV), that uses directional
derivatives to quantify the degree to which a user-defined concept is important
to a classification result--for example, how sensitive a prediction of &quot;zebra&quot;
is to the presence of stripes. Using the domain of image classification as a
testing ground, we describe how CAVs may be used to explore hypotheses and
generate insights for a standard image classification network as well as a
medical application.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kim_B/0/1/0/all/0/1&quot;&gt;Been Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wattenberg_M/0/1/0/all/0/1&quot;&gt;Martin Wattenberg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gilmer_J/0/1/0/all/0/1&quot;&gt;Justin Gilmer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Cai_C/0/1/0/all/0/1&quot;&gt;Carrie Cai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wexler_J/0/1/0/all/0/1&quot;&gt;James Wexler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Viegas_F/0/1/0/all/0/1&quot;&gt;Fernanda Viegas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sayres_R/0/1/0/all/0/1&quot;&gt;Rory Sayres&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.03265">
<title>More Adaptive Algorithms for Adversarial Bandits. (arXiv:1801.03265v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1801.03265</link>
<description rdf:parseType="Literal">&lt;p&gt;We develop a novel and generic algorithm for the adversarial multi-armed
bandit problem (or more generally the combinatorial semi-bandit problem). When
instantiated differently, our algorithm achieves various new data-dependent
regret bounds improving previous work. Examples include: 1) a regret bound
depending on the variance of only the best arm; 2) a regret bound depending on
the first-order path-length of only the best arm; 3) a regret bound depending
on the sum of first-order path-lengths of all arms as well as an important
negative term, which together lead to faster convergence rates for some normal
form games with partial feedback; 4) a regret bound that simultaneously implies
small regret when the best arm has small loss and logarithmic regret when there
exists an arm whose expected loss is always smaller than those of others by a
fixed gap (e.g. the classic i.i.d. setting). In some cases, such as the last
two results, our algorithm is completely parameter-free.
&lt;/p&gt;
&lt;p&gt;The main idea of our algorithm is to apply the optimism and adaptivity
techniques to the well-known Online Mirror Descent framework with a special
log-barrier regularizer. The challenges are to come up with appropriate
optimistic predictions and correction terms in this framework. Some of our
results also crucially rely on using a sophisticated increasing learning rate
schedule.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wei_C/0/1/0/all/0/1&quot;&gt;Chen-Yu Wei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_H/0/1/0/all/0/1&quot;&gt;Haipeng Luo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04220">
<title>Augment and Reduce: Stochastic Inference for Large Categorical Distributions. (arXiv:1802.04220v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1802.04220</link>
<description rdf:parseType="Literal">&lt;p&gt;Categorical distributions are ubiquitous in machine learning, e.g., in
classification, language models, and recommendation systems. However, when the
number of possible outcomes is very large, using categorical distributions
becomes computationally expensive, as the complexity scales linearly with the
number of outcomes. To address this problem, we propose augment and reduce
(A&amp;amp;R), a method to alleviate the computational complexity. A&amp;amp;R uses two ideas:
latent variable augmentation and stochastic variational inference. It maximizes
a lower bound on the marginal likelihood of the data. Unlike existing methods
which are specific to softmax, A&amp;amp;R is more general and is amenable to other
categorical models, such as multinomial probit. On several large-scale
classification problems, we show that A&amp;amp;R provides a tighter bound on the
marginal likelihood and has better predictive performance than existing
approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ruiz_F/0/1/0/all/0/1&quot;&gt;Francisco J. R. Ruiz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Titsias_M/0/1/0/all/0/1&quot;&gt;Michalis K. Titsias&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Dieng_A/0/1/0/all/0/1&quot;&gt;Adji B. Dieng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Blei_D/0/1/0/all/0/1&quot;&gt;David M. Blei&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04712">
<title>Attention-based Deep Multiple Instance Learning. (arXiv:1802.04712v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1802.04712</link>
<description rdf:parseType="Literal">&lt;p&gt;Multiple instance learning (MIL) is a variation of supervised learning where
a single class label is assigned to a bag of instances. In this paper, we state
the MIL problem as learning the Bernoulli distribution of the bag label where
the bag label probability is fully parameterized by neural networks.
Furthermore, we propose a neural network-based permutation-invariant
aggregation operator that corresponds to the attention mechanism. Notably, an
application of the proposed attention-based operator provides insight into the
contribution of each instance to the bag label. We show empirically that our
approach achieves comparable performance to the best MIL methods on benchmark
MIL datasets and it outperforms other methods on a MNIST-based MIL dataset and
two real-life histopathology datasets without sacrificing interpretability.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ilse_M/0/1/0/all/0/1&quot;&gt;Maximilian Ilse&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tomczak_J/0/1/0/all/0/1&quot;&gt;Jakub M. Tomczak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Welling_M/0/1/0/all/0/1&quot;&gt;Max Welling&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04911">
<title>Large-Scale Sparse Inverse Covariance Estimation via Thresholding and Max-Det Matrix Completion. (arXiv:1802.04911v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1802.04911</link>
<description rdf:parseType="Literal">&lt;p&gt;The sparse inverse covariance estimation problem is commonly solved using an
$\ell_{1}$-regularized Gaussian maximum likelihood estimator known as
&quot;graphical lasso&quot;, but its computational cost becomes prohibitive for large
data sets. A recent line of results showed--under mild assumptions--that the
graphical lasso estimator can be retrieved by soft-thresholding the sample
covariance matrix and solving a maximum determinant matrix completion (MDMC)
problem. This paper proves an extension of this result, and describes a
Newton-CG algorithm to efficiently solve the MDMC problem. Assuming that the
thresholded sample covariance matrix is sparse with a sparse Cholesky
factorization, we prove that the algorithm converges to an $\epsilon$-accurate
solution in $O(n\log(1/\epsilon))$ time and $O(n)$ memory. The algorithm is
highly efficient in practice: we solve the associated MDMC problems with as
many as 200,000 variables to 7-9 digits of accuracy in less than an hour on a
standard laptop computer running MATLAB.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhang_R/0/1/0/all/0/1&quot;&gt;Richard Y. Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Fattahi_S/0/1/0/all/0/1&quot;&gt;Salar Fattahi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sojoudi_S/0/1/0/all/0/1&quot;&gt;Somayeh Sojoudi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05757">
<title>Stochastic Wasserstein Barycenters. (arXiv:1802.05757v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1802.05757</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a stochastic algorithm to compute the barycenter of a set of
probability distributions under the Wasserstein metric from optimal transport.
Unlike previous approaches, our method extends to continuous input
distributions and allows the support of the barycenter to be adjusted in each
iteration. We tackle the problem without regularization, allowing us to recover
a sharp output whose support is contained within the support of the true
barycenter. We give examples where our algorithm recovers a more meaningful
barycenter than previous work. Our method is versatile and can be extended to
applications such as generating super samples from a given distribution and
recovering blue noise approximations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Claici_S/0/1/0/all/0/1&quot;&gt;Sebastian Claici&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chien_E/0/1/0/all/0/1&quot;&gt;Edward Chien&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Solomon_J/0/1/0/all/0/1&quot;&gt;Justin Solomon&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.08089">
<title>Sampling as optimization in the space of measures: The Langevin dynamics as a composite optimization problem. (arXiv:1802.08089v2 [math.OC] UPDATED)</title>
<link>http://arxiv.org/abs/1802.08089</link>
<description rdf:parseType="Literal">&lt;p&gt;We study sampling as optimization in the space of measures. We focus on
gradient flow-based optimization with the Langevin dynamics as a case study. We
investigate the source of the bias of the unadjusted Langevin algorithm (ULA)
in discrete time, and consider how to remove or reduce the bias. We point out
the difficulty is that the heat flow is exactly solvable, but neither its
forward nor backward method is implementable in general, except for Gaussian
data. We propose the symmetrized Langevin algorithm (SLA), which should have a
smaller bias than ULA, at the price of implementing a proximal gradient step in
space. We show SLA is in fact consistent for Gaussian target measure, whereas
ULA is not. We also illustrate various algorithms explicitly for Gaussian
target measure, including gradient descent, proximal gradient, and
Forward-Backward, and show they are all consistent.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Wibisono_A/0/1/0/all/0/1&quot;&gt;Andre Wibisono&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.11262">
<title>Efficient First-Order Algorithms for Adaptive Signal Denoising. (arXiv:1803.11262v2 [math.ST] UPDATED)</title>
<link>http://arxiv.org/abs/1803.11262</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the problem of discrete-time signal denoising, focusing on a
specific family of non-linear convolution-type estimators. Each such estimator
is associated with a time-invariant filter which is obtained adaptively, by
solving a certain convex optimization problem. Adaptive convolution-type
estimators were demonstrated to have favorable statistical properties. However,
the question of their computational complexity remains largely unexplored, and
in fact we are not aware of any publicly available implementation of these
estimators. Our first contribution is an efficient implementation of these
estimators via some known first-order proximal algorithms. Our second
contribution is a computational complexity analysis of the proposed procedures,
which takes into account their statistical nature and the related notion of
statistical accuracy. The proposed procedures and their analysis are
illustrated on a simulated data benchmark.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Ostrovskii_D/0/1/0/all/0/1&quot;&gt;Dmitrii Ostrovskii&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Harchaoui_Z/0/1/0/all/0/1&quot;&gt;Zaid Harchaoui&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.01882">
<title>Hyperbolic Entailment Cones for Learning Hierarchical Embeddings. (arXiv:1804.01882v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1804.01882</link>
<description rdf:parseType="Literal">&lt;p&gt;Learning graph representations via low-dimensional embeddings that preserve
relevant network properties is an important class of problems in machine
learning. We here present a novel method to embed directed acyclic graphs.
Following prior work, we first advocate for using hyperbolic spaces which
provably model tree-like structures better than Euclidean geometry. Second, we
view hierarchical relations as partial orders defined using a family of nested
geodesically convex cones. We prove that these entailment cones admit an
optimal shape with a closed form expression both in the Euclidean and
hyperbolic spaces, and they canonically define the embedding learning process.
Experiments show significant improvements of our method over strong recent
baselines both in terms of representational capacity and generalization.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ganea_O/0/1/0/all/0/1&quot;&gt;Octavian-Eugen Ganea&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Becigneul_G/0/1/0/all/0/1&quot;&gt;Gary B&amp;#xe9;cigneul&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hofmann_T/0/1/0/all/0/1&quot;&gt;Thomas Hofmann&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.06530">
<title>Improving the Gaussian Mechanism for Differential Privacy: Analytical Calibration and Optimal Denoising. (arXiv:1805.06530v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.06530</link>
<description rdf:parseType="Literal">&lt;p&gt;The Gaussian mechanism is an essential building block used in multitude of
differentially private data analysis algorithms. In this paper we revisit the
Gaussian mechanism and show that the original analysis has several important
limitations. Our analysis reveals that the variance formula for the original
mechanism is far from tight in the high privacy regime ($\varepsilon \to 0$)
and it cannot be extended to the low privacy regime ($\varepsilon \to \infty$).
We address these limitations by developing an optimal Gaussian mechanism whose
variance is calibrated directly using the Gaussian cumulative density function
instead of a tail bound approximation. We also propose to equip the Gaussian
mechanism with a post-processing step based on adaptive estimation techniques
by leveraging that the distribution of the perturbation is known. Our
experiments show that analytical calibration removes at least a third of the
variance of the noise compared to the classical Gaussian mechanism, and that
denoising dramatically improves the accuracy of the Gaussian mechanism in the
high-dimensional regime.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Balle_B/0/1/0/all/0/1&quot;&gt;Borja Balle&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yu-Xiang Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.08527">
<title>Safe Element Screening for Submodular Function Minimization. (arXiv:1805.08527v4 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1805.08527</link>
<description rdf:parseType="Literal">&lt;p&gt;Submodular functions are discrete analogs of convex functions, which have
applications in various fields, including machine learning and computer vision.
However, in large-scale applications, solving Submodular Function Minimization
(SFM) problems remains challenging. In this paper, we make the first attempt to
extend the emerging technique named screening in large-scale sparse learning to
SFM for accelerating its optimization process. We first conduct a careful
studying of the relationships between SFM and the corresponding convex proximal
problems, as well as the accurate primal optimum estimation of the proximal
problems. Relying on this study, we subsequently propose a novel safe screening
method to quickly identify the elements guaranteed to be included (we refer to
them as active) or excluded (inactive) in the final optimal solution of SFM
during the optimization process. By removing the inactive elements and fixing
the active ones, the problem size can be dramatically reduced, leading to great
savings in the computational cost without sacrificing any accuracy. To the best
of our knowledge, the proposed method is the first screening method in the
fields of SFM and even combinatorial optimization, thus pointing out a new
direction for accelerating SFM algorithms. Experiment results on both synthetic
and real datasets demonstrate the significant speedups gained by our approach.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhang_W/0/1/0/all/0/1&quot;&gt;Weizhong Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hong_B/0/1/0/all/0/1&quot;&gt;Bin Hong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ma_L/0/1/0/all/0/1&quot;&gt;Lin Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Liu_W/0/1/0/all/0/1&quot;&gt;Wei Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhang_T/0/1/0/all/0/1&quot;&gt;Tong Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.10367">
<title>Zeroth-Order Stochastic Variance Reduction for Nonconvex Optimization. (arXiv:1805.10367v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.10367</link>
<description rdf:parseType="Literal">&lt;p&gt;As application demands for zeroth-order (gradient-free) optimization
accelerate, the need for variance reduced and faster converging approaches is
also intensifying. This paper addresses these challenges by presenting: a) a
comprehensive theoretical analysis of variance reduced zeroth-order (ZO)
optimization, b) a novel variance reduced ZO algorithm, called ZO-SVRG, and c)
an experimental evaluation of our approach in the context of two compelling
applications, black-box chemical material classification and generation of
adversarial examples from black-box deep neural network models. Our theoretical
analysis uncovers an essential difficulty in the analysis of ZO-SVRG: the
unbiased assumption on gradient estimates no longer holds. We prove that
compared to its first-order counterpart, ZO-SVRG with a two-point random
gradient estimator could suffer an additional error of order $O(1/b)$, where
$b$ is the mini-batch size. To mitigate this error, we propose two accelerated
versions of ZO-SVRG utilizing variance reduced gradient estimators, which
achieve the best rate known for ZO stochastic optimization (in terms of
iterations). Our extensive experimental results show that our approaches
outperform other state-of-the-art ZO algorithms, and strike a balance between
the convergence rate and the function query complexity.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_S/0/1/0/all/0/1&quot;&gt;Sijia Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kailkhura_B/0/1/0/all/0/1&quot;&gt;Bhavya Kailkhura&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_P/0/1/0/all/0/1&quot;&gt;Pin-Yu Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ting_P/0/1/0/all/0/1&quot;&gt;Paishun Ting&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chang_S/0/1/0/all/0/1&quot;&gt;Shiyu Chang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Amini_L/0/1/0/all/0/1&quot;&gt;Lisa Amini&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11640">
<title>K-Beam Minimax: Efficient Optimization for Deep Adversarial Learning. (arXiv:1805.11640v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.11640</link>
<description rdf:parseType="Literal">&lt;p&gt;Minimax optimization plays a key role in adversarial training of machine
learning algorithms, such as learning generative models, domain adaptation,
privacy preservation, and robust learning. In this paper, we demonstrate the
failure of alternating gradient descent in minimax optimization problems due to
the discontinuity of solutions of the inner maximization. To address this, we
propose a new epsilon-subgradient descent algorithm that addresses this problem
by simultaneously tracking K candidate solutions. Practically, the algorithm
can find solutions that previous saddle-point algorithms cannot find, with only
a sublinear increase of complexity in K. We analyze the conditions under which
the algorithm converges to the true solution in detail. A significant
improvement in stability and convergence speed of the algorithm is observed in
simple representative problems, GAN training, and domain-adaptation problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hamm_J/0/1/0/all/0/1&quot;&gt;Jihun Hamm&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Noh_Y/0/1/0/all/0/1&quot;&gt;Yung-Kyun Noh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11811">
<title>Stochastic Zeroth-order Optimization via Variance Reduction method. (arXiv:1805.11811v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1805.11811</link>
<description rdf:parseType="Literal">&lt;p&gt;Derivative-free optimization has become an important technique used in
machine learning for optimizing black-box models. To conduct updates without
explicitly computing gradient, most current approaches iteratively sample a
random search direction from Gaussian distribution and compute the estimated
gradient along that direction. However, due to the variance in the search
direction, the convergence rates and query complexities of existing methods
suffer from a factor of $d$, where $d$ is the problem dimension. In this paper,
we introduce a novel Stochastic Zeroth-order method with Variance Reduction
under Gaussian smoothing (SZVR-G) and establish the complexity for optimizing
non-convex problems. With variance reduction on both sample space and search
space, the complexity of our algorithm is sublinear to $d$ and is strictly
better than current approaches, in both smooth and non-smooth cases. Moreover,
we extend the proposed method to the mini-batch version. Our experimental
results demonstrate the superior performance of the proposed method over
existing derivative-free optimization techniques. Furthermore, we successfully
apply our method to conduct a universal black-box attack to deep neural
networks and present some interesting results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Liu_L/0/1/0/all/0/1&quot;&gt;Liu Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Cheng_M/0/1/0/all/0/1&quot;&gt;Minhao Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hsieh_C/0/1/0/all/0/1&quot;&gt;Cho-Jui Hsieh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tao_D/0/1/0/all/0/1&quot;&gt;Dacheng Tao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00701">
<title>On Multi-Layer Basis Pursuit, Efficient Algorithms and Convolutional Neural Networks. (arXiv:1806.00701v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1806.00701</link>
<description rdf:parseType="Literal">&lt;p&gt;Parsimonious representations in data modeling are ubiquitous and central for
processing information. Motivated by the recent Multi-Layer Convolutional
Sparse Coding (ML-CSC) model, we herein generalize the traditional Basis
Pursuit regression problem to a multi-layer setting, introducing similar sparse
enforcing penalties at different representation layers in a symbiotic relation
between synthesis and analysis sparse priors. We propose and analyze different
iterative algorithms to solve this new problem in practice. We prove that the
presented multi-layer Iterative Soft Thresholding (ML-ISTA) and multi-layer
Fast ISTA (ML-FISTA) converge to the global optimum of our multi-layer
formulation at a rate of $\mathcal{O}(1/k)$ and $\mathcal{O}(1/k^2)$,
respectively. We further show how these algorithms effectively implement
particular recurrent neural networks that generalize feed-forward architectures
without any increase in the number of parameters. We demonstrate the different
architectures resulting from unfolding the iterations of the proposed
multi-layer pursuit algorithms, providing a principled way to construct deep
recurrent CNNs from feed-forward ones. We demonstrate the emerging
constructions by training them in an end-to-end manner, consistently improving
the performance of classical networks without introducing extra filters or
parameters.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sulam_J/0/1/0/all/0/1&quot;&gt;Jeremias Sulam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aberdam_A/0/1/0/all/0/1&quot;&gt;Aviad Aberdam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Elad_M/0/1/0/all/0/1&quot;&gt;Michael Elad&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.01811">
<title>AdaGrad stepsizes: Sharp convergence over nonconvex landscapes, from any initialization. (arXiv:1806.01811v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1806.01811</link>
<description rdf:parseType="Literal">&lt;p&gt;Adaptive gradient methods such as AdaGrad and its variants update the
stepsize in stochastic gradient descent on the fly according to the gradients
received along the way; such methods have gained widespread use in large-scale
optimization for their ability to converge robustly, without the need to fine
tune parameters such as the stepsize schedule. Yet, the theoretical guarantees
to date for AdaGrad are for online and convex optimization, which is quite
different from the offline and nonconvex setting where adaptive gradient
methods shine in practice. We bridge this gap by providing strong theoretical
guarantees in batch and stochastic setting, for the convergence of AdaGrad over
smooth, nonconvex landscapes, from any initialization of the stepsize, without
knowledge of Lipschitz constant of the gradient. We show in the stochastic
setting that AdaGrad converges to a stationary point at the optimal
$O(1/\sqrt{N})$ rate (up to a $\log(N)$ factor), and in the batch setting, at
the optimal $O(1/N)$ rate. Moreover, in both settings, the constant in the rate
matches the constant obtained as if the variance of the gradient noise and
Lipschitz constant of the gradient were known in advance and used to tune the
stepsize, up to a logarithmic factor of the mismatch between the optimal
stepsize and the stepsize used to initialize AdaGrad. In particular, our
results imply that AdaGrad is robust to both the unknown Lipschitz constant and
level of stochastic noise on the gradient, in a near-optimal sense. When there
is noise, AdaGrad converges at the rate of $O(1/\sqrt{N})$ with well-tuned
stepsize, and when there is not noise, the same algorithm converges at the rate
of $O(1/N)$ like well-tuned batch gradient descent.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ward_R/0/1/0/all/0/1&quot;&gt;Rachel Ward&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wu_X/0/1/0/all/0/1&quot;&gt;Xiaoxia Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bottou_L/0/1/0/all/0/1&quot;&gt;Leon Bottou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.06454">
<title>Unsupervised Machine Learning Based on Non-Negative Tensor Factorization for Analyzing Reactive-Mixing. (arXiv:1805.06454v1 [cs.CE] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1805.06454</link>
<description rdf:parseType="Literal">&lt;p&gt;Analysis of reactive-diffusion simulations requires a large number of
independent model runs. For each high-fidelity simulation, inputs are varied
and the predicted mixing behavior is represented by changes in species
concentration. It is then required to discern how the model inputs impact the
mixing process. This task is challenging and typically involves interpretation
of large model outputs. However, the task can be automated and substantially
simplified by applying Machine Learning (ML) methods. In this paper, we present
an application of an unsupervised ML method (called NTFk) using Non-negative
Tensor Factorization (NTF) coupled with a custom clustering procedure based on
k-means to reveal hidden features in product concentration. An attractive
aspect of the proposed ML method is that it ensures the extracted features are
non-negative, which are important to obtain a meaningful deconstruction of the
mixing processes. The ML method is applied to a large set of high-resolution
FEM simulations representing reaction-diffusion processes in perturbed
vortex-based velocity fields. The applied FEM ensures that species
concentration are always non-negative. The simulated reaction is a fast
irreversible bimolecular reaction. The reactive-diffusion model input
parameters that control mixing include properties of velocity field,
anisotropic dispersion, and molecular diffusion. We demonstrate the
applicability of the ML method to produce a meaningful deconstruction of model
outputs to discriminate between different physical processes impacting the
reactants, their mixing, and the spatial distribution of the product. The
presented ML analysis allowed us to identify additive features that
characterize mixing behavior.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vesselinov_V/0/1/0/all/0/1&quot;&gt;V. V. Vesselinov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mudunuru_M/0/1/0/all/0/1&quot;&gt;M. K. Mudunuru&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Karra_S/0/1/0/all/0/1&quot;&gt;S. Karra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Malley_D/0/1/0/all/0/1&quot;&gt;D. O. Malley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alexandrov_B/0/1/0/all/0/1&quot;&gt;B. S. Alexandrov&lt;/a&gt;</dc:creator>
</item></rdf:RDF>