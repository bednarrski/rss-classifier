<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Boring papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Bad Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-03-25T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.08660"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.08833"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1706.04332"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04899"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.08604"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.08706"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.08740"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.08784"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.08857"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.08874"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1705.10217"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.01711"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.08858"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.08533"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.08577"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.08586"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.08591"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.08600"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.08651"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.08661"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.08667"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.08680"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.08700"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.08823"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.08841"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.08917"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.00483"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.00699"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.02852"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.07079"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.06396"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.07200"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.08312"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1803.08660">
<title>Lifting Layers: Analysis and Applications. (arXiv:1803.08660v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1803.08660</link>
<description rdf:parseType="Literal">&lt;p&gt;The great advances of learning-based approaches in image processing and
computer vision are largely based on deeply nested networks that compose linear
transfer functions with suitable non-linearities. Interestingly, the most
frequently used non-linearities in imaging applications (variants of the
rectified linear unit) are uncommon in low dimensional approximation problems.
In this paper we propose a novel non-linear transfer function, called lifting,
which is motivated from a related technique in convex optimization. A lifting
layer increases the dimensionality of the input, naturally yields a linear
spline when combined with a fully connected layer, and therefore closes the gap
between low and high dimensional approximation problems. Moreover, applying the
lifting operation to the loss layer of the network allows us to handle
non-convex and flat (zero-gradient) cost functions. We analyze the proposed
lifting theoretically, exemplify interesting properties in synthetic
experiments and demonstrate its effectiveness in deep learning approaches to
image classification and denoising.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ochs_P/0/1/0/all/0/1&quot;&gt;Peter Ochs&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meinhardt_T/0/1/0/all/0/1&quot;&gt;Tim Meinhardt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leal_Taixe_L/0/1/0/all/0/1&quot;&gt;Laura Leal-Taixe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moeller_M/0/1/0/all/0/1&quot;&gt;Michael Moeller&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.08833">
<title>Gaussian and exponential lateral connectivity on distributed spiking neural network simulation. (arXiv:1803.08833v1 [cs.DC])</title>
<link>http://arxiv.org/abs/1803.08833</link>
<description rdf:parseType="Literal">&lt;p&gt;We measured the impact of long-range exponentially decaying intra-areal
lateral connectivity on the scaling and memory occupation of a distributed
spiking neural network simulator compared to that of short-range Gaussian
decays. While previous studies adopted short-range connectivity, recent
experimental neurosciences studies are pointing out the role of longer-range
intra-areal connectivity with implications on neural simulation platforms.
Two-dimensional grids of cortical columns composed by up to 11 M point-like
spiking neurons with spike frequency adaption were connected by up to 30 G
synapses using short- and long-range connectivity models. The MPI processes
composing the distributed simulator were run on up to 1024 hardware cores,
hosted on a 64 nodes server platform. The hardware platform was a cluster of
IBM NX360 M5 16-core compute nodes, each one containing two Intel Xeon Haswell
8-core E5-2630 v3 processors, with a clock of 2.40 G Hz, interconnected through
an InfiniBand network, equipped with 4x QDR switches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pastorelli_E/0/1/0/all/0/1&quot;&gt;Elena Pastorelli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Paolucci_P/0/1/0/all/0/1&quot;&gt;Pier Stanislao Paolucci&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Simula_F/0/1/0/all/0/1&quot;&gt;Francesco Simula&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Biagioni_A/0/1/0/all/0/1&quot;&gt;Andrea Biagioni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Capuani_F/0/1/0/all/0/1&quot;&gt;Fabrizio Capuani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cretaro_P/0/1/0/all/0/1&quot;&gt;Paolo Cretaro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bonis_G/0/1/0/all/0/1&quot;&gt;Giulia De Bonis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cicero_F/0/1/0/all/0/1&quot;&gt;Francesca Lo Cicero&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lonardo_A/0/1/0/all/0/1&quot;&gt;Alessandro Lonardo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Martinelli_M/0/1/0/all/0/1&quot;&gt;Michele Martinelli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pontisso_L/0/1/0/all/0/1&quot;&gt;Luca Pontisso&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vicini_P/0/1/0/all/0/1&quot;&gt;Piero Vicini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ammendola_R/0/1/0/all/0/1&quot;&gt;Roberto Ammendola&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1706.04332">
<title>MATIC: Learning Around Errors for Efficient Low-Voltage Neural Network Accelerators. (arXiv:1706.04332v3 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1706.04332</link>
<description rdf:parseType="Literal">&lt;p&gt;As a result of the increasing demand for deep neural network (DNN)-based
services, efforts to develop dedicated hardware accelerators for DNNs are
growing rapidly. However,while accelerators with high performance and
efficiency on convolutional deep neural networks (Conv-DNNs) have been
developed, less progress has been made with regards to fully-connected DNNs
(FC-DNNs). In this paper, we propose MATIC (Memory Adaptive Training with
In-situ Canaries), a methodology that enables aggressive voltage scaling of
accelerator weight memories to improve the energy-efficiency of DNN
accelerators. To enable accurate operation with voltage overscaling, MATIC
combines the characteristics of destructive SRAM reads with the error
resilience of neural networks in a memory-adaptive training process.
Furthermore, PVT-related voltage margins are eliminated using bit-cells from
synaptic weights as in-situ canaries to track runtime environmental variation.
Demonstrated on a low-power DNN accelerator that we fabricate in 65 nm CMOS,
MATIC enables up to 60-80 mV of voltage overscaling (3.3x total energy
reduction versus the nominal voltage), or 18.6x application error reduction.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_S/0/1/0/all/0/1&quot;&gt;Sung Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Howe_P/0/1/0/all/0/1&quot;&gt;Patrick Howe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moreau_T/0/1/0/all/0/1&quot;&gt;Thierry Moreau&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alaghi_A/0/1/0/all/0/1&quot;&gt;Armin Alaghi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ceze_L/0/1/0/all/0/1&quot;&gt;Luis Ceze&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sathe_V/0/1/0/all/0/1&quot;&gt;Visvesh Sathe&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04899">
<title>Field-Programmable Deep Neural Network (DNN) Learning and Inference accelerator: a concept. (arXiv:1802.04899v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1802.04899</link>
<description rdf:parseType="Literal">&lt;p&gt;An accelerator is a specialized integrated circuit designed to perform
specific computations faster than if those were performed by CPU or GPU. A
Field-Programmable DNN learning and inference accelerator (FProg-DNN) using
hybrid systolic and non-systolic techniques, distributed information-control
and deep pipelined structure is proposed and its microarchitecture and
operation presented here. Reconfigurability attends diverse DNN designs and
allows for different number of workers to be assigned to different layers as a
function of the relative difference in computational load among layers. The
computational delay per layer is made roughly the same along pipelined
accelerator structure. VGG-16 and recently proposed Inception Modules are used
for showing the flexibility of the FProg-DNN reconfigurability. Special
structures were also added for a combination of convolution layer, map
coincidence and feedback for state of the art learning with small set of
examples, which is the focus of a companion paper by the author (Franca-Neto,
2018). The accelerator described is able to reconfigure from (1) allocating all
a DNN computations to a single worker in one extreme of sub-optimal performance
to (2) optimally allocating workers per layer according to computational load
in each DNN layer to be realized. Due the pipelined architecture, more than 50x
speedup is achieved relative to GPUs or TPUs. This speed-up is consequence of
hiding the delay in transporting activation outputs from one layer to the next
in a DNN behind the computations in the receiving layer. This FProg-DNN concept
has been simulated and validated at behavioral-functional level.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Franca_Neto_L/0/1/0/all/0/1&quot;&gt;Luiz M Franca-Neto&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.08604">
<title>Learning State Representations for Query Optimization with Deep Reinforcement Learning. (arXiv:1803.08604v1 [cs.DB])</title>
<link>http://arxiv.org/abs/1803.08604</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep reinforcement learning is quickly changing the field of artificial
intelligence. These models are able to capture a high level understanding of
their environment, enabling them to learn difficult dynamic tasks in a variety
of domains. In the database field, query optimization remains a difficult
problem. Our goal in this work is to explore the capabilities of deep
reinforcement learning in the context of query optimization. At each state, we
build queries incrementally and encode properties of subqueries through a
learned representation. The challenge here lies in the formation of the state
transition function, which defines how the current subquery state combines with
the next query operation (action) to yield the next state. As a first step in
this direction, we focus the state representation problem and the formation of
the state transition function. We describe our approach and show preliminary
results. We further discuss how we can use the state representation to improve
query optimization using reinforcement learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ortiz_J/0/1/0/all/0/1&quot;&gt;Jennifer Ortiz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Balazinska_M/0/1/0/all/0/1&quot;&gt;Magdalena Balazinska&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gehrke_J/0/1/0/all/0/1&quot;&gt;Johannes Gehrke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Keerthi_S/0/1/0/all/0/1&quot;&gt;S. Sathiya Keerthi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.08706">
<title>Foundations of Prescriptive Process Monitoring. (arXiv:1803.08706v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1803.08706</link>
<description rdf:parseType="Literal">&lt;p&gt;Predictive process monitoring is concerned with the analysis of events
produced during the execution of a process in order to predict the future state
of ongoing cases thereof. Existing techniques in this field are able to
predict, at each step of a case, the likelihood that the case will end up in an
undesired outcome. These techniques, however, do not take into account what
process workers may do with the generated predictions in order to decrease the
likelihood of undesired outcomes. This paper proposes a framework for
prescriptive process monitoring, which extends predictive monitoring approaches
with concepts of alarms, interventions, compensations, and mitigation effects.
The framework incorporates a parameterized cost model to assess the
cost-benefit tradeoffs of applying prescriptive process monitoring in a given
setting. The paper also outlines an approach to optimize the generation of
alarms given a dataset and a set of cost model parameters. The proposed
approach is empirically evaluated using a range of real-life event logs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Teinemaa_I/0/1/0/all/0/1&quot;&gt;Irene Teinemaa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tax_N/0/1/0/all/0/1&quot;&gt;Niek Tax&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leoni_M/0/1/0/all/0/1&quot;&gt;Massimiliano de Leoni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dumas_M/0/1/0/all/0/1&quot;&gt;Marlon Dumas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Maggi_F/0/1/0/all/0/1&quot;&gt;Fabrizio Maria Maggi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.08740">
<title>Speeding-up Object Detection Training for Robotics with FALKON. (arXiv:1803.08740v1 [cs.RO])</title>
<link>http://arxiv.org/abs/1803.08740</link>
<description rdf:parseType="Literal">&lt;p&gt;Latest deep learning methods for object detection provided remarkable
performance boost, but have limits when used in robotic applications. One of
the most relevant issues is the long training time, which is due to the large
size and unbalance of the associated training sets, characterized by few
positive and tons of negative (i.e. background) examples. Proposed approaches,
either based on end-to-end learning by back-propagation [22], or standard
kernel methods trained with Hard Negatives Mining on top of deep features [8],
proved to be effective, but prohibitively slow for on-line applications. In
this paper we propose a novel pipeline for object detection that overcomes this
problem and provides comparable performance, with a 60x training speedup. Our
pipeline combines (i) the Region Proposal Network and the deep feature
extractor from [22] to efficiently select candidate RoIs and encode them into
powerful representations, with (ii) the recently proposed FALKON [23]
algorithm, a novel kernel-based method that allows to quickly train on millions
of points. We address the size and unbalance of training data by exploiting the
stochastic subsampling intrinsic into the method, combined with a novel, fast,
bootstrapping approach. We assess the effectiveness of the approach in a
standard computer vision setting (PASCAL VOC 2007 [5]) and demonstrate its
applicability to a real robotic scenario as represented by the iCubWorld
Transformations [18] dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Maiettini_E/0/1/0/all/0/1&quot;&gt;Elisa Maiettini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pasquale_G/0/1/0/all/0/1&quot;&gt;Giulia Pasquale&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rosasco_L/0/1/0/all/0/1&quot;&gt;Lorenzo Rosasco&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Natale_L/0/1/0/all/0/1&quot;&gt;Lorenzo Natale&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.08784">
<title>From Random Differential Equations to Structural Causal Models: the stochastic case. (arXiv:1803.08784v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1803.08784</link>
<description rdf:parseType="Literal">&lt;p&gt;Random Differential Equations provide a natural extension of Ordinary
Differential Equations to the stochastic setting. We show how, and under which
conditions, every equilibrium state of a Random Differential Equation (RDE) can
be described by a Structural Causal Model (SCM), while pertaining the causal
semantics. This provides an SCM that captures the stochastic and causal
behavior of the RDE, which can model both cycles and confounders. This enables
the study of the equilibrium states of the RDE by applying the theory and
statistical tools available for SCMs, for example, marginalizations and Markov
properties, as we illustrate by means of an example. Our work thus provides a
direct connection between two fields that so far have been developing in
isolation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bongers_S/0/1/0/all/0/1&quot;&gt;Stephan Bongers&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mooij_J/0/1/0/all/0/1&quot;&gt;Joris M. Mooij&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.08857">
<title>2CoBel : An Efficient Belief Function Extension for Two-dimensional Continuous Spaces. (arXiv:1803.08857v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1803.08857</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper introduces an innovative approach for handling 2D compound
hypotheses within the Belief Function Theory framework. We propose a
polygon-based generic rep- resentation which relies on polygon clipping
operators. This approach allows us to account in the computational cost for the
precision of the representation independently of the cardinality of the
discernment frame. For the BBA combination and decision making, we propose
efficient algorithms which rely on hashes for fast lookup, and on a topological
ordering of the focal elements within a directed acyclic graph encoding their
interconnections. Additionally, an implementation of the functionalities
proposed in this paper is provided as an open source library. Experimental
results on a pedestrian localization problem are reported. The experiments show
that the solution is accurate and that it fully benefits from the scalability
of the 2D search space granularity provided by our representation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pellicano_N/0/1/0/all/0/1&quot;&gt;Nicola Pellican&amp;#xf2;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hegarat_Mascle_S/0/1/0/all/0/1&quot;&gt;Sylvie Le H&amp;#xe9;garat-Mascle&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aldea_E/0/1/0/all/0/1&quot;&gt;Emanuel Aldea&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.08874">
<title>A mosaic of Chu spaces and Channel Theory with applications to Object Identification and Mereological Complexity. (arXiv:1803.08874v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1803.08874</link>
<description rdf:parseType="Literal">&lt;p&gt;Chu Spaces and Channel Theory are well established areas of investigation in
the general context of category theory. We review a range of examples and
applications of these methods in logic and computer science, including Formal
Concept Analysis, distributed systems and ontology development. We then employ
these methods to describe human object perception, beginning with the
construction of uncategorized object files and proceeding through
categorization, individual object identification and the tracking of object
identity through time. We investigate the relationship between abstraction and
mereological categorization, particularly as these affect object identity
tracking. This we accomplish in terms of information flow that is semantically
structured in terms of local logics, while at the same time this framework also
provides an inferential mechanism towards identification and perception. We
show how a mereotopology naturally emerges from the representation of
classifications by simplicial complexes, and briefly explore the emergence of
geometric relations and interactions between objects.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fields_C/0/1/0/all/0/1&quot;&gt;Chris Fields&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Glazebrook_J/0/1/0/all/0/1&quot;&gt;James F. Glazebrook&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1705.10217">
<title>Black-box Testing of First-Order Logic Ontologies Using WordNet. (arXiv:1705.10217v3 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1705.10217</link>
<description rdf:parseType="Literal">&lt;p&gt;Artificial Intelligence aims to provide computer programs with commonsense
knowledge to reason about our world. This paper offers a new practical approach
towards automated commonsense reasoning with first-order logic (FOL)
ontologies. We propose a new black-box testing methodology of FOL SUMO-based
ontologies by exploiting WordNet and its mapping into SUMO. Our proposal
includes a method for the (semi-)automatic creation of a very large benchmark
of competency questions and a procedure for its automated evaluation by using
automated theorem provers (ATPs). Applying different quality criteria, our
testing proposal enables a successful evaluation of a) the competency of
several translations of SUMO into FOL and b) the performance of various
automated ATPs. Finally, we also provide a fine-grained and complete analysis
of the commonsense reasoning competency of current FOL SUMO-based ontologies.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alvez_J/0/1/0/all/0/1&quot;&gt;Javier &amp;#xc1;lvez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lucio_P/0/1/0/all/0/1&quot;&gt;Paqui Lucio&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rigau_G/0/1/0/all/0/1&quot;&gt;German Rigau&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.01711">
<title>Coding-theorem Like Behaviour and Emergence of the Universal Distribution from Resource-bounded Algorithmic Probability. (arXiv:1711.01711v10 [cs.IT] UPDATED)</title>
<link>http://arxiv.org/abs/1711.01711</link>
<description rdf:parseType="Literal">&lt;p&gt;Previously referred to as `miraculous&apos; in the scientific literature because
of its powerful properties and its wide application as optimal solution to the
problem of induction/inference, (approximations to) Algorithmic Probability
(AP) and the associated Universal Distribution are (or should be) of the
greatest importance in science. Here we investigate the emergence, the rates of
emergence and convergence, and the Coding-theorem like behaviour of AP in
Turing-subuniversal models of computation. We investigate empirical
distributions of computing models in the Chomsky hierarchy. We introduce
measures of algorithmic probability and algorithmic complexity based upon
resource-bounded computation, in contrast to previously thoroughly investigated
distributions produced from the output distribution of Turing machines. This
approach allows for numerical approximations to algorithmic
(Kolmogorov-Chaitin) complexity-based estimations at each of the levels of a
computational hierarchy. We demonstrate that all these estimations are
correlated in rank and that they converge both in rank and values as a function
of computational power, despite fundamental differences between computational
models. In the context of natural processes that operate below the Turing
universal level because of finite resources and physical degradation, the
investigation of natural biases stemming from algorithmic rules may shed light
on the distribution of outcomes. We show that up to 60\% of the
simplicity/complexity bias in distributions produced even by the weakest of the
computational models can be accounted for by Algorithmic Probability in its
approximation to the Universal Distribution.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zenil_H/0/1/0/all/0/1&quot;&gt;Hector Zenil&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Badillo_L/0/1/0/all/0/1&quot;&gt;Liliana Badillo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hernandez_Orozco_S/0/1/0/all/0/1&quot;&gt;Santiago Hern&amp;#xe1;ndez-Orozco&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hernandez_Quiroz_F/0/1/0/all/0/1&quot;&gt;Francisco Hern&amp;#xe1;ndez-Quiroz&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.08858">
<title>Towards Collaborative Conceptual Exploration. (arXiv:1712.08858v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1712.08858</link>
<description rdf:parseType="Literal">&lt;p&gt;In domains with high knowledge distribution a natural objective is to create
principle foundations for collaborative interactive learning environments. We
present a first mathematical characterization of a collaborative learning
group, a consortium, based on closure systems of attribute sets and the
well-known attribute exploration algorithm from formal concept analysis. To
this end, we introduce (weak) local experts for subdomains of a given knowledge
domain. These entities are able to refute and potentially accept a given
(implicational) query for some closure system that is a restriction of the
whole domain. On this we build up a consortial expert and show first insights
about the ability of such an expert to answer queries. Furthermore, we depict
techniques on how to cope with falsely accepted implications and on combining
counterexamples. Using notions from combinatorial design theory we further
expand those insights as far as providing first results on the decidability
problem if a given consortium is able to explore some target domain.
Applications in conceptual knowledge acquisition as well as in collaborative
interactive ontology learning are at hand.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hanika_T/0/1/0/all/0/1&quot;&gt;Tom Hanika&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zumbragel_J/0/1/0/all/0/1&quot;&gt;Jens Zumbr&amp;#xe4;gel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.08533">
<title>Understanding Measures of Uncertainty for Adversarial Example Detection. (arXiv:1803.08533v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1803.08533</link>
<description rdf:parseType="Literal">&lt;p&gt;Measuring uncertainty is a promising technique for detecting adversarial
examples, crafted inputs on which the model predicts an incorrect class with
high confidence. But many measures of uncertainty exist, including predictive
en- tropy and mutual information, each capturing different types of
uncertainty. We study these measures, and shed light on why mutual information
seems to be effective at the task of adversarial example detection. We
highlight failure modes for MC dropout, a widely used approach for estimating
uncertainty in deep models. This leads to an improved understanding of the
drawbacks of current methods, and a proposal to improve the quality of
uncertainty estimates using probabilistic model ensembles. We give illustrative
experiments using MNIST to demonstrate the intuition underlying the different
measures of uncertainty, as well as experiments on a real world Kaggle dogs vs
cats classification dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Smith_L/0/1/0/all/0/1&quot;&gt;Lewis Smith&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gal_Y/0/1/0/all/0/1&quot;&gt;Yarin Gal&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.08577">
<title>Unbiased scalable softmax optimization. (arXiv:1803.08577v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1803.08577</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent neural network and language models rely on softmax distributions with
an extremely large number of categories. Since calculating the softmax
normalizing constant in this context is prohibitively expensive, there is a
growing literature of efficiently computable but biased estimates of the
softmax. In this paper we propose the first unbiased algorithms for maximizing
the softmax likelihood whose work per iteration is independent of the number of
classes and datapoints (and no extra work is required at the end of each
epoch). We show that our proposed unbiased methods comprehensively outperform
the state-of-the-art on seven real world datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Fagan_F/0/1/0/all/0/1&quot;&gt;Francois Fagan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Iyengar_G/0/1/0/all/0/1&quot;&gt;Garud Iyengar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.08586">
<title>Optimization of Smooth Functions with Noisy Observations: Local Minimax Rates. (arXiv:1803.08586v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1803.08586</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the problem of global optimization of an unknown non-convex
smooth function with zeroth-order feedback. In this setup, an algorithm is
allowed to adaptively query the underlying function at different locations and
receives noisy evaluations of function values at the queried points (i.e. the
algorithm has access to zeroth-order information). Optimization performance is
evaluated by the expected difference of function values at the estimated
optimum and the true optimum. In contrast to the classical optimization setup,
first-order information like gradients are not directly accessible to the
optimization algorithm. We show that the classical minimax framework of
analysis, which roughly characterizes the worst-case query complexity of an
optimization algorithm in this setting, leads to excessively pessimistic
results. We propose a local minimax framework to study the fundamental
difficulty of optimizing smooth functions with adaptive function evaluations,
which provides a refined picture of the intrinsic difficulty of zeroth-order
optimization. We show that for functions with fast level set growth around the
global minimum, carefully designed optimization algorithms can identify a near
global minimizer with many fewer queries. For the special case of strongly
convex and smooth functions, our implied convergence rates match the ones
developed for zeroth-order convex optimization problems. At the other end of
the spectrum, for worst-case smooth functions no algorithm can converge faster
than the minimax rate of estimating the entire unknown function in the
$\ell_\infty$-norm. We provide an intuitive and efficient algorithm that
attains the derived upper error bounds.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yining Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Balakrishnan_S/0/1/0/all/0/1&quot;&gt;Sivaraman Balakrishnan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Singh_A/0/1/0/all/0/1&quot;&gt;Aarti Singh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.08591">
<title>End-to-End Learning for the Deep Multivariate Probit Model. (arXiv:1803.08591v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1803.08591</link>
<description rdf:parseType="Literal">&lt;p&gt;The multivariate probit model (MVP) is a popular classic model for studying
binary responses of multiple entities. Nevertheless, the computational
challenge of learning the MVP model, given that its likelihood involves
integrating over a multidimensional constrained space of latent variables,
significantly limits its application in practice. We propose a flexible deep
generalization of the classic MVP, the Deep Multivariate Probit Model (DMVP),
which is an end-to-end learning scheme that uses an efficient parallel sampling
process of the multivariate probit model to exploit GPU-boosted deep neural
networks. We present both theoretical and empirical analysis of the convergence
behavior of DMVP&apos;s sampling process with respect to the resolution of the
correlation structure. We provide convergence guarantees for DMVP and our
empirical analysis demonstrates the advantages of DMVP&apos;s sampling compared with
standard MCMC-based methods. We also show that when applied to multi-entity
modelling problems, which are natural DMVP applications, DMVP trains faster
than classical MVP, by at least an order of magnitude, captures rich
correlations among entities, and further improves the joint likelihood of
entities compared with several competitive models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_D/0/1/0/all/0/1&quot;&gt;Di Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xue_Y/0/1/0/all/0/1&quot;&gt;Yexiang Xue&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gomes_C/0/1/0/all/0/1&quot;&gt;Carla P. Gomes&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.08600">
<title>Lower error bounds for the stochastic gradient descent optimization algorithm: Sharp convergence rates for slowly and fast decaying learning rates. (arXiv:1803.08600v1 [math.NA])</title>
<link>http://arxiv.org/abs/1803.08600</link>
<description rdf:parseType="Literal">&lt;p&gt;The stochastic gradient descent (SGD) optimization algorithm plays a central
role in a series of machine learning applications. The scientific literature
provides a vast amount of upper error bounds for the SGD method. Much less
attention as been paid to proving lower error bounds for the SGD method. It is
the key contribution of this paper to make a step in this direction. More
precisely, in this article we establish for every $\gamma, \nu \in (0,\infty)$
essentially matching lower and upper bounds for the mean square error of the
SGD process with learning rates $(\frac{\gamma}{n^\nu})_{n \in \mathbb{N}}$
associated to a simple quadratic stochastic optimization problem. This allows
us to precisely quantify the mean square convergence rate of the SGD method in
dependence on the asymptotic behavior of the learning rates.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Jentzen_A/0/1/0/all/0/1&quot;&gt;Arnulf Jentzen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Wurstemberger_P/0/1/0/all/0/1&quot;&gt;Philippe von Wurstemberger&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.08651">
<title>Learning Recommendations While Influencing Interests. (arXiv:1803.08651v1 [cs.IR])</title>
<link>http://arxiv.org/abs/1803.08651</link>
<description rdf:parseType="Literal">&lt;p&gt;Personalized recommendation systems (RS) are extensively used in many
services. Many of these are based on learning algorithms where the RS uses the
recommendation history and the user response to learn an optimal strategy.
Further, these algorithms are based on the assumption that the user interests
are rigid. Specifically, they do not account for the effect of learning
strategy on the evolution of the user interests. In this paper we develop
influence models for a learning algorithm that is used to optimally recommend
websites to web users. We adapt the model of \cite{Ioannidis10} to include an
item-dependent reward to the RS from the suggestions that are accepted by the
user. For this we first develop a static optimisation scheme when all the
parameters are known. Next we develop a stochastic approximation based learning
scheme for the RS to learn the optimal strategy when the user profiles are not
known. Finally, we describe several user-influence models for the learning
algorithm and analyze their effect on the steady user interests and on the
steady state optimal strategy as compared to that when the users are not
influenced.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meshram_R/0/1/0/all/0/1&quot;&gt;Rahul Meshram&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Manjunath_D/0/1/0/all/0/1&quot;&gt;D. Manjunath&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Karamchandani_N/0/1/0/all/0/1&quot;&gt;Nikhil Karamchandani&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.08661">
<title>Bayesian Optimization with Expensive Integrands. (arXiv:1803.08661v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1803.08661</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a Bayesian optimization algorithm for objective functions that are
sums or integrals of expensive-to-evaluate functions, allowing noisy
evaluations. These objective functions arise in multi-task Bayesian
optimization for tuning machine learning hyperparameters, optimization via
simulation, and sequential design of experiments with random environmental
conditions. Our method is average-case optimal by construction when a single
evaluation of the integrand remains within our evaluation budget. Achieving
this one-step optimality requires solving a challenging value of information
optimization problem, for which we provide a novel efficient
discretization-free computational method. We also provide consistency proofs
for our method in both continuum and discrete finite domains for objective
functions that are sums. In numerical experiments comparing against previous
state-of-the-art methods, including those that also leverage sum or integral
structure, our method performs as well or better across a wide range of
problems and offers significant improvements when evaluations are noisy or the
integrand varies smoothly in the integrated variables.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Toscano_Palmerin_S/0/1/0/all/0/1&quot;&gt;Saul Toscano-Palmerin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Frazier_P/0/1/0/all/0/1&quot;&gt;Peter I. Frazier&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.08667">
<title>On efficient global optimization via universal Kriging surrogate models. (arXiv:1803.08667v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1803.08667</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we investigate the capability of the universal Kriging (UK)
model for single-objective global optimization applied within an efficient
global optimization (EGO) framework. We implemented this combined UK-EGO
framework and studied four variants of the UK methods, that is, a UK with a
first-order polynomial, a UK with a second-order polynomial, a blind Kriging
(BK) implementation from the ooDACE toolbox, and a polynomial-chaos Kriging
(PCK) implementation. The UK-EGO framework with automatic trend function
selection derived from the BK and PCK models works by building a UK surrogate
model and then performing optimizations via expected improvement criteria on
the Kriging model with the lowest leave-one-out cross-validation error. Next,
we studied and compared the UK-EGO variants and standard EGO using five
synthetic test functions and one aerodynamic problem. Our results show that the
proper choice for the trend function through automatic feature selection can
improve the optimization performance of UK-EGO relative to EGO. From our
results, we found that PCK-EGO was the best variant, as it had more robust
performance as compared to the rest of the UK-EGO schemes; however, total-order
expansion should be used to generate the candidate trend function set for
high-dimensional problems. Note that, for some test functions, the UK with
predetermined polynomial trend functions performed better than that of BK and
PCK, indicating that the use of automatic trend function selection does not
always lead to the best quality solutions. We also found that although some
variants of UK are not as globally accurate as the ordinary Kriging (OK), they
can still identify better-optimized solutions due to the addition of the trend
function, which helps the optimizer locate the global optimum.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Palar_P/0/1/0/all/0/1&quot;&gt;Pramudita Satria Palar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Shimoyama_K/0/1/0/all/0/1&quot;&gt;Koji Shimoyama&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.08680">
<title>Improving DNN Robustness to Adversarial Attacks using Jacobian Regularization. (arXiv:1803.08680v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1803.08680</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep neural networks have lately shown tremendous performance in various
applications including vision and speech processing tasks. However, alongside
their ability to perform these tasks with such high accuracy, it has been shown
that they are highly susceptible to adversarial attacks: a small change of the
input would cause the network to err with high confidence. This phenomenon
exposes an inherent fault in these networks and their ability to generalize
well. For this reason, providing robustness to adversarial attacks is an
important challenge in networks training, which has led to an extensive
research. In this work, we suggest a theoretically inspired novel approach to
improve the networks&apos; robustness. Our method applies regularization using the
Frobenius norm of the Jacobian of the network, which is applied as
post-processing, after regular training has finished. We demonstrate
empirically that it leads to enhanced robustness results with a minimal change
in the original network&apos;s accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jakubovitz_D/0/1/0/all/0/1&quot;&gt;Daniel Jakubovitz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Giryes_R/0/1/0/all/0/1&quot;&gt;Raja Giryes&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.08700">
<title>Determinantal Point Processes for Coresets. (arXiv:1803.08700v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1803.08700</link>
<description rdf:parseType="Literal">&lt;p&gt;When one is faced with a dataset too large to be used all at once, an obvious
solution is to retain only part of it. In practice this takes a wide variety of
different forms, but among them &quot;coresets&quot; are especially appealing. A coreset
is a (small) weighted sample of the original data that comes with a guarantee:
that a cost function can be evaluated on the smaller set instead of the larger
one, with low relative error. For some classes of problems, and via a careful
choice of sampling distribution, iid random sampling has turned to be one of
the most successful methods to build coresets efficiently. However, independent
samples are sometimes overly redundant, and one could hope that enforcing
diversity would lead to better performance. The difficulty lies in proving
coreset properties in non-iid samples. We show that the coreset property holds
for samples formed with determinantal point processes (DPP). DPPs are
interesting because they are a rare example of repulsive point processes with
tractable theoretical properties, enabling us to construct general coreset
theorems. We apply our results to the $k$-means problem, and give empirical
evidence of the superior performance of DPP samples over state of the art
methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tremblay_N/0/1/0/all/0/1&quot;&gt;Nicolas Tremblay&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Barthelme_S/0/1/0/all/0/1&quot;&gt;Simon Barthelm&amp;#xe9;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Amblard_P/0/1/0/all/0/1&quot;&gt;Pierre-Olivier Amblard&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.08823">
<title>A high-bias, low-variance introduction to Machine Learning for physicists. (arXiv:1803.08823v1 [physics.comp-ph])</title>
<link>http://arxiv.org/abs/1803.08823</link>
<description rdf:parseType="Literal">&lt;p&gt;Machine Learning (ML) is one of the most exciting and dynamic areas of modern
research and application. The purpose of this review is to provide an
introduction to the core concepts and tools of machine learning in a manner
easily understood and intuitive to physicists. The review begins by covering
fundamental concepts in ML and modern statistics such as the bias-variance
tradeoff, overfitting, regularization, and generalization before moving on to
more advanced topics in both supervised and unsupervised learning. Topics
covered in the review include ensemble models, deep learning and neural
networks, clustering and data visualization, energy-based models (including
MaxEnt models and Restricted Boltzmann Machines), and variational methods.
Throughout, we emphasize the many natural connections between ML and
statistical physics. A notable aspect of the review is the use of Python
notebooks to introduce modern ML/statistical packages to readers using
physics-inspired datasets (the Ising Model and Monte-Carlo simulations of
supersymmetric decays of proton-proton collisions). We conclude with an
extended outlook discussing possible uses of machine learning for furthering
our understanding of the physical world as well as open problems in ML where
physicists maybe able to contribute. (Notebooks are available at
https://physics.bu.edu/~pankajm/MLnotebooks.html )
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Mehta_P/0/1/0/all/0/1&quot;&gt;Pankaj Mehta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Bukov_M/0/1/0/all/0/1&quot;&gt;Marin Bukov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Wang_C/0/1/0/all/0/1&quot;&gt;Ching-Hao Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Day_A/0/1/0/all/0/1&quot;&gt;Alexandre G.R. Day&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Richardson_C/0/1/0/all/0/1&quot;&gt;Clint Richardson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Fisher_C/0/1/0/all/0/1&quot;&gt;Charles K. Fisher&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Schwab_D/0/1/0/all/0/1&quot;&gt;David J. Schwab&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.08841">
<title>The Convergence of Stochastic Gradient Descent in Asynchronous Shared Memory. (arXiv:1803.08841v1 [cs.DC])</title>
<link>http://arxiv.org/abs/1803.08841</link>
<description rdf:parseType="Literal">&lt;p&gt;Stochastic Gradient Descent (SGD) is a fundamental algorithm in machine
learning, representing the optimization backbone for training several classic
models, from regression to neural networks. Given the recent practical focus on
distributed machine learning, significant work has been dedicated to the
convergence properties of this algorithm under the inconsistent and noisy
updates arising from execution in a distributed environment. However,
surprisingly, the convergence properties of this classic algorithm in the
standard shared-memory model are still not well-understood.
&lt;/p&gt;
&lt;p&gt;In this work, we address this gap, and provide new convergence bounds for
lock-free concurrent stochastic gradient descent, executing in the classic
asynchronous shared memory model, against a strong adaptive adversary. Our
results give improved upper and lower bounds on the &quot;price of asynchrony&quot; when
executing the fundamental SGD algorithm in a concurrent setting. They show that
this classic optimization tool can converge faster and with a wider range of
parameters than previously known under asynchronous iterations. At the same
time, we exhibit a fundamental trade-off between the maximum delay in the
system and the rate at which SGD can converge, which governs the set of
parameters under which this algorithm can still work efficiently.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alistarh_D/0/1/0/all/0/1&quot;&gt;Dan Alistarh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sa_C/0/1/0/all/0/1&quot;&gt;Christopher De Sa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Konstantinov_N/0/1/0/all/0/1&quot;&gt;Nikola Konstantinov&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.08917">
<title>Byzantine Stochastic Gradient Descent. (arXiv:1803.08917v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1803.08917</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper studies the problem of distributed stochastic optimization in an
adversarial setting where, out of the $m$ machines which allegedly compute
stochastic gradients every iteration, an $\alpha$-fraction are Byzantine, and
can behave arbitrarily and adversarially. Our main result is a variant of
stochastic gradient descent (SGD) which finds $\varepsilon$-approximate
minimizers of convex functions in $T = \tilde{O}\big( \frac{1}{\varepsilon^2 m}
+ \frac{\alpha^2}{\varepsilon^2} \big)$ iterations. In contrast, traditional
mini-batch SGD needs $T = O\big( \frac{1}{\varepsilon^2 m} \big)$ iterations,
but cannot tolerate Byzantine failures. Further, we provide a lower bound
showing that, up to logarithmic factors, our algorithm is
information-theoretically optimal both in terms of sampling complexity and time
complexity.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alistarh_D/0/1/0/all/0/1&quot;&gt;Dan Alistarh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Allen_Zhu_Z/0/1/0/all/0/1&quot;&gt;Zeyuan Allen-Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_J/0/1/0/all/0/1&quot;&gt;Jerry Li&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.00483">
<title>Iteratively Linearized Reweighted Alternating Direction Method of Multipliers for a Class of Nonconvex Problems. (arXiv:1709.00483v5 [cs.NA] UPDATED)</title>
<link>http://arxiv.org/abs/1709.00483</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we consider solving a class of nonconvex and nonsmooth
problems frequently appearing in signal processing and machine learning
research. The traditional alternating direction method of multipliers
encounters troubles in both mathematics and computations in solving the
nonconvex and nonsmooth subproblem. In view of this, we propose a reweighted
alternating direction method of multipliers. In this algorithm, all subproblems
are convex and easy to solve. We also provide several guarantees for the
convergence and prove that the algorithm globally converges to a critical point
of an auxiliary function with the help of the Kurdyka-{\L}ojasiewicz property.
Several numerical results are presented to demonstrate the efficiency of the
proposed algorithm.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sun_T/0/1/0/all/0/1&quot;&gt;Tao Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1&quot;&gt;Hao Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cheng_L/0/1/0/all/0/1&quot;&gt;Lizhi Cheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_W/0/1/0/all/0/1&quot;&gt;Wei Zhu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.00699">
<title>Improving Network Robustness against Adversarial Attacks with Compact Convolution. (arXiv:1712.00699v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1712.00699</link>
<description rdf:parseType="Literal">&lt;p&gt;Though Convolutional Neural Networks (CNNs) have surpassed human-level
performance on tasks such as object classification and face verification, they
can easily be fooled by adversarial attacks. These attacks add a small
perturbation to the input image that causes the network to misclassify the
sample. In this paper, we focus on neutralizing adversarial attacks by compact
feature learning. In particular, we show that learning features in a closed and
bounded space improves the robustness of the network. We explore the effect of
L2-Softmax Loss, that enforces compactness in the learned features, thus
resulting in enhanced robustness to adversarial perturbations. Additionally, we
propose compact convolution, a novel method of convolution that when
incorporated in conventional CNNs improves their robustness. Compact
convolution ensures feature compactness at every layer such that they are
bounded and close to each other. Extensive experiments show that Compact
Convolutional Networks (CCNs) neutralize multiple types of attacks, and perform
better than existing methods in defending adversarial attacks, without
incurring any additional training overhead compared to CNNs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ranjan_R/0/1/0/all/0/1&quot;&gt;Rajeev Ranjan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sankaranarayanan_S/0/1/0/all/0/1&quot;&gt;Swami Sankaranarayanan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Castillo_C/0/1/0/all/0/1&quot;&gt;Carlos D. Castillo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chellappa_R/0/1/0/all/0/1&quot;&gt;Rama Chellappa&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.02852">
<title>mGPfusion: Predicting protein stability changes with Gaussian process kernel learning and data fusion. (arXiv:1802.02852v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1802.02852</link>
<description rdf:parseType="Literal">&lt;p&gt;Proteins are commonly used by biochemical industry for numerous processes.
Refining these proteins&apos; properties via mutations causes stability effects as
well. Accurate computational method to predict how mutations affect protein
stability are necessary to facilitate efficient protein design. However,
accuracy of predictive models is ultimately constrained by the limited
availability of experimental data. We have developed mGPfusion, a novel
Gaussian process (GP) method for predicting protein&apos;s stability changes upon
single and multiple mutations. This method complements the limited experimental
data with large amounts of molecular simulation data. We introduce a Bayesian
data fusion model that re-calibrates the experimental and in silico data
sources and then learns a predictive GP model from the combined data. Our
protein-specific model requires experimental data only regarding the protein of
interest and performs well even with few experimental measurements. The
mGPfusion models proteins by contact maps and infers the stability effects
caused by mutations with a mixture of graph kernels. Our results show that
mGPfusion outperforms state-of-the-art methods in predicting protein stability
on a dataset of 15 different proteins and that incorporating molecular
simulation data improves the model learning and prediction accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Jokinen_E/0/1/0/all/0/1&quot;&gt;Emmi Jokinen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Heinonen_M/0/1/0/all/0/1&quot;&gt;Markus Heinonen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lahdesmaki_H/0/1/0/all/0/1&quot;&gt;Harri L&amp;#xe4;hdesm&amp;#xe4;ki&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.07079">
<title>Structured Uncertainty Prediction Networks. (arXiv:1802.07079v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1802.07079</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper is the first work to propose a network to predict a structured
uncertainty distribution for a synthesized image. Previous approaches have been
mostly limited to predicting diagonal covariance matrices. Our novel model
learns to predict a full Gaussian covariance matrix for each reconstruction,
which permits efficient sampling and likelihood evaluation.
&lt;/p&gt;
&lt;p&gt;We demonstrate that our model can accurately reconstruct ground truth
correlated residual distributions for synthetic datasets and generate plausible
high frequency samples for real face images. We also illustrate the use of
these predicted covariances for structure preserving image denoising.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Dorta_G/0/1/0/all/0/1&quot;&gt;Garoe Dorta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Vicente_S/0/1/0/all/0/1&quot;&gt;Sara Vicente&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Agapito_L/0/1/0/all/0/1&quot;&gt;Lourdes Agapito&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Campbell_N/0/1/0/all/0/1&quot;&gt;Neill D.F. Campbell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Simpson_I/0/1/0/all/0/1&quot;&gt;Ivor Simpson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.06396">
<title>Reviving and Improving Recurrent Back-Propagation. (arXiv:1803.06396v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1803.06396</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we revisit the recurrent back-propagation (RBP) algorithm,
discuss the conditions under which it applies as well as how to satisfy them in
deep neural networks. We show that RBP can be unstable and propose two variants
based on conjugate gradient on the normal equations (CG-RBP) and Neumann series
(Neumann-RBP). We further investigate the relationship between Neumann-RBP and
back propagation through time (BPTT) and its truncated version (TBPTT). Our
Neumann-RBP has the same time complexity as TBPTT but only requires constant
memory, whereas TBPTT&apos;s memory cost scales linearly with the number of
truncation steps. We examine all RBP variants along with BPTT and TBPTT in
three different application domains: associative memory with continuous
Hopfield networks, document classification in citation networks using graph
neural networks and hyperparameter optimization for fully connected networks.
All experiments demonstrate that RBPs, especially the Neumann-RBP variant, are
efficient and effective for optimizing convergent recurrent neural networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liao_R/0/1/0/all/0/1&quot;&gt;Renjie Liao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xiong_Y/0/1/0/all/0/1&quot;&gt;Yuwen Xiong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fetaya_E/0/1/0/all/0/1&quot;&gt;Ethan Fetaya&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1&quot;&gt;Lisa Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yoon_K/0/1/0/all/0/1&quot;&gt;KiJung Yoon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pitkow_X/0/1/0/all/0/1&quot;&gt;Xaq Pitkow&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Urtasun_R/0/1/0/all/0/1&quot;&gt;Raquel Urtasun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zemel_R/0/1/0/all/0/1&quot;&gt;Richard Zemel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.07200">
<title>Training Recurrent Neural Networks as a Constraint Satisfaction Problem. (arXiv:1803.07200v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1803.07200</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents a new approach for training artificial neural networks
using techniques for solving the constraint satisfaction problem (CSP). The
quotient gradient system (QGS) is a trajectory based method for solving the
CSP. This study converts the training set of a neural network into a CSP and
uses the QGS to find its solutions. The QGS finds the global minimum of the
optimization problem by tracking trajectories of a nonlinear dynamical system
and does not stop at a local minimum of the optimization problem. Lyapunov
theory is used to prove the asymptotic stability of the solutions with and
without the presence of measurement errors. Numerical examples illustrate the
effectiveness of the proposed methodology and compare it to a genetic algorithm
and error backpropagation
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khodabandehlou_H/0/1/0/all/0/1&quot;&gt;Hamid Khodabandehlou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fadali_M/0/1/0/all/0/1&quot;&gt;Mohammad Sami Fadali&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.08312">
<title>Learning Eligibility in Cancer Clinical Trials using Deep Neural Networks. (arXiv:1803.08312v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1803.08312</link>
<description rdf:parseType="Literal">&lt;p&gt;Interventional cancer clinical trials are generally too restrictive and
patients are often excluded from them on the basis of comorbidity, past or
concomitant treatments and the fact that they are over a certain age. The
efficacy and safety of new treatments for patients with these characteristics
are not, therefore, defined. In this work, we build a model with which to
automatically predict whether short clinical statements were considered
inclusion or exclusion criteria. We used clinical trials protocols on cancer
that have been available in public registries for the last 18 years to train
word embeddings, and constructed a dataset of 6M short free-texts labeled as
eligible or not eligible. We then trained and validated a text classifier,
using deep neural networks with pre-trained word-embedding as its inputs, to
predict whether or not short free-text statements describing clinical
information were considered eligible. The best model achieved an F-measure of
0.91 and an almost perfect agreement when employing a validation set of 800K
labeled statements. The trained model was also tested on an independent set of
clinical statements mimicking those used in routine clinical practice, yielding
a consistent performance. We additionally analyzed the semantic reasoning of
the word embedding representations obtained, and were able to identify
equivalent treatments for a type of tumor in an analogy with the drugs used to
treat other tumors. The present work shows that representation learning using
neural networks can be successfully leveraged to extract the medical knowledge
available on clinical trial protocols and potentially assist practitioners when
prescribing treatments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bustos_A/0/1/0/all/0/1&quot;&gt;Aurelia Bustos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pertusa_A/0/1/0/all/0/1&quot;&gt;Antonio Pertusa&lt;/a&gt;</dc:creator>
</item></rdf:RDF>