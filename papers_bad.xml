<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Boring papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Bad Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-06-13T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04932"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05034"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05141"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1703.01887"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.00656"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04854"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04959"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05049"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05085"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05108"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05112"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05117"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.00322"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.08893"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.06560"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.02998"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09045"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.02623"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04731"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04743"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04773"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04819"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04823"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04838"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04863"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04900"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04994"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05017"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05054"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05096"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05134"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05139"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.05151"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1609.05486"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1706.03922"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.02893"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.05515"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.08464"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04374"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06847"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.03234"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.06837"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09950"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.09994"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00530"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.03285"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04047"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.04209"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.03467"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1806.04932">
<title>Reservoir Computing Hardware with Cellular Automata. (arXiv:1806.04932v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1806.04932</link>
<description rdf:parseType="Literal">&lt;p&gt;Elementary cellular automata (ECA) is a widely studied one-dimensional
processing methodology where the successive iteration of the automaton may lead
to the recreation of a rich pattern dynamic. Recently, cellular automata have
been proposed as a feasible way to implement Reservoir Computing (RC) systems
in which the automata rule is fixed and the training is performed using a
linear regression. In this work we perform an exhaustive study of the
performance of the different ECA rules when applied to pattern recognition of
time-independent input signals using a RC scheme. Once the different ECA rules
have been tested, the most accurate one (rule 90) is selected to implement a
digital circuit. Rule 90 is easily reproduced using a reduced set of XOR gates
and shift-registers, thus representing a high-performance alternative for RC
hardware implementation in terms of processing time, circuit area, power
dissipation and system accuracy. The model (both in software and its hardware
implementation) has been tested using a pattern recognition task of handwritten
numbers (the MNIST database) for which we obtained competitive results in terms
of accuracy, speed and power dissipation. The proposed model can be considered
to be a low-cost method to implement fast pattern recognition digital circuits.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moran_A/0/1/0/all/0/1&quot;&gt;Alejandro Mor&amp;#xe1;n&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Frasser_C/0/1/0/all/0/1&quot;&gt;Christiam F. Frasser&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rossello_J/0/1/0/all/0/1&quot;&gt;Josep L. Rossell&amp;#xf3;&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05034">
<title>A Probabilistic U-Net for Segmentation of Ambiguous Images. (arXiv:1806.05034v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1806.05034</link>
<description rdf:parseType="Literal">&lt;p&gt;Many real-world vision problems suffer from inherent ambiguities. In clinical
applications for example, it might not be clear from a CT scan alone which
particular region is cancer tissue. Therefore a group of graders typically
produces a set of diverse but plausible segmentations. We consider the task of
learning a distribution over segmentations given an input. To this end we
propose a generative segmentation model based on a combination of a U-Net with
a conditional variational autoencoder that is capable of efficiently producing
an unlimited number of plausible hypotheses. We show on a lung abnormalities
segmentation task and on a Cityscapes segmentation task that our model
reproduces the possible segmentation variants as well as the frequencies with
which they occur, doing so significantly better than published approaches.
These models could have a high impact in real-world applications, such as being
used as clinical decision-making algorithms accounting for multiple plausible
semantic segmentation hypotheses to provide possible diagnoses and recommend
further actions to resolve the present ambiguities.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kohl_S/0/1/0/all/0/1&quot;&gt;Simon A. A. Kohl&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Romera_Paredes_B/0/1/0/all/0/1&quot;&gt;Bernardino Romera-Paredes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meyer_C/0/1/0/all/0/1&quot;&gt;Clemens Meyer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fauw_J/0/1/0/all/0/1&quot;&gt;Jeffrey De Fauw&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ledsam_J/0/1/0/all/0/1&quot;&gt;Joseph R. Ledsam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Maier_Hein_K/0/1/0/all/0/1&quot;&gt;Klaus H. Maier-Hein&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Eslami_S/0/1/0/all/0/1&quot;&gt;S. M. Ali Eslami&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rezende_D/0/1/0/all/0/1&quot;&gt;Danilo Jimenez Rezende&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ronneberger_O/0/1/0/all/0/1&quot;&gt;Olaf Ronneberger&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05141">
<title>Exploiting Inherent Error-Resiliency of Neuromorphic Computing to achieve Extreme Energy-Efficiency through Mixed-Signal Neurons. (arXiv:1806.05141v1 [cs.ET])</title>
<link>http://arxiv.org/abs/1806.05141</link>
<description rdf:parseType="Literal">&lt;p&gt;Neuromorphic computing, inspired by the brain, promises extreme efficiency
for certain classes of learning tasks, such as classification and pattern
recognition. The performance and power consumption of neuromorphic computing
depends heavily on the choice of the neuron architecture. Digital neurons
(Dig-N) are conventionally known to be accurate and efficient at high speed,
while suffering from high leakage currents from a large number of transistors
in a large design. On the other hand, analog/mixed-signal neurons are prone to
noise, variability and mismatch, but can lead to extremely low-power designs.
In this work, we will analyze, compare and contrast existing neuron
architectures with a proposed mixed-signal neuron (MS-N) in terms of
performance, power and noise, thereby demonstrating the applicability of the
proposed mixed-signal neuron for achieving extreme energy-efficiency in
neuromorphic computing. The proposed MS-N is implemented in 65 nm CMOS
technology and exhibits &amp;gt; 100X better energy-efficiency across all frequencies
over two traditional digital neurons synthesized in the same technology node.
We also demonstrate that the inherent error-resiliency of a fully connected or
even convolutional neural network (CNN) can handle the noise as well as the
manufacturing non-idealities of the MS-N up to certain degrees. Notably, a
system-level implementation on MNIST datasets exhibits a worst-case increase in
classification error by 2.1% when the integrated noise power in the bandwidth
is ~ 0.1 uV2, along with +-3{\sigma} amount of variation and mismatch
introduced in the transistor parameters for the proposed neuron with 8-bit
precision.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chatterjee_B/0/1/0/all/0/1&quot;&gt;Baibhab Chatterjee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Panda_P/0/1/0/all/0/1&quot;&gt;Priyadarshini Panda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Maity_S/0/1/0/all/0/1&quot;&gt;Shovan Maity&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Biswas_A/0/1/0/all/0/1&quot;&gt;Ayan Biswas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roy_K/0/1/0/all/0/1&quot;&gt;Kaushik Roy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sen_S/0/1/0/all/0/1&quot;&gt;Shreyas Sen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1703.01887">
<title>Co-evolutionary multi-task learning for dynamic time series prediction. (arXiv:1703.01887v2 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1703.01887</link>
<description rdf:parseType="Literal">&lt;p&gt;Time series prediction typically consists of a data reconstruction phase
where the time series is broken into overlapping windows known as the timespan.
The size of the timespan can be seen as a way of determining the extent of past
information required for an effective prediction. In certain applications such
as the prediction of wind-intensity of storms and cyclones, prediction models
need to be dynamic in accommodating different values of the timespan. These
applications require robust prediction as soon as the event takes place. We
identify a new category of problem called dynamic time series prediction that
requires a model to give prediction when presented with varying lengths of the
timespan. In this paper, we propose a co-evolutionary multi-task learning
method that provides a synergy between multi-task learning and co-evolutionary
algorithms to address dynamic time series prediction. The method features
effective use of building blocks of knowledge inspired by dynamic programming
and multi-task learning. It enables neural networks to retain modularity during
training for making a decision in situations even when certain inputs are
missing. The effectiveness of the method is demonstrated using one-step-ahead
chaotic time series and tropical cyclone wind-intensity prediction.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chandra_R/0/1/0/all/0/1&quot;&gt;Rohitash Chandra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ong_Y/0/1/0/all/0/1&quot;&gt;Yew-Soon Ong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goh_C/0/1/0/all/0/1&quot;&gt;Chi-Keong Goh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.00656">
<title>mQAPViz: A divide-and-conquer multi-objective optimization algorithm to compute large data visualizations. (arXiv:1804.00656v2 [cs.HC] UPDATED)</title>
<link>http://arxiv.org/abs/1804.00656</link>
<description rdf:parseType="Literal">&lt;p&gt;Algorithms for data visualizations are essential tools for transforming data
into useful narratives. Unfortunately, very few visualization algorithms can
handle the large datasets of many real-world scenarios. In this study, we
address the visualization of these datasets as a Multi-Objective Optimization
Problem. We propose mQAPViz, a divide-and-conquer multi-objective optimization
algorithm to compute large-scale data visualizations. Our method employs the
Multi-Objective Quadratic Assignment Problem (mQAP) as the mathematical
foundation to solve the visualization task at hand. The algorithm applies
advanced sampling techniques originating from the field of machine learning and
efficient data structures to scale to millions of data objects. The algorithm
allocates objects onto a 2D grid layout. Experimental results on real-world and
large datasets demonstrate that mQAPViz is a competitive alternative to
existing techniques.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sanhueza_C/0/1/0/all/0/1&quot;&gt;Claudio Sanhueza&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jimenez_F/0/1/0/all/0/1&quot;&gt;Francia Jim&amp;#xe9;nez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Berretta_R/0/1/0/all/0/1&quot;&gt;Regina Berretta&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moscato_P/0/1/0/all/0/1&quot;&gt;Pablo Moscato&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04854">
<title>Fast and Scalable Bayesian Deep Learning by Weight-Perturbation in Adam. (arXiv:1806.04854v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.04854</link>
<description rdf:parseType="Literal">&lt;p&gt;Uncertainty computation in deep learning is essential to design robust and
reliable systems. Variational inference (VI) is a promising approach for such
computation, but requires more effort to implement and execute compared to
maximum-likelihood methods. In this paper, we propose new natural-gradient
algorithms to reduce such efforts for Gaussian mean-field VI. Our algorithms
can be implemented within the Adam optimizer by perturbing the network weights
during gradient evaluations, and uncertainty estimates can be cheaply obtained
by using the vector that adapts the learning rate. This requires lower memory,
computation, and implementation effort than existing VI methods, while
obtaining uncertainty estimates of comparable quality. Our empirical results
confirm this and further suggest that the weight-perturbation in our algorithm
could be useful for exploration in reinforcement learning and stochastic
optimization.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Khan_M/0/1/0/all/0/1&quot;&gt;Mohammad Emtiyaz Khan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Nielsen_D/0/1/0/all/0/1&quot;&gt;Didrik Nielsen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tangkaratt_V/0/1/0/all/0/1&quot;&gt;Voot Tangkaratt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lin_W/0/1/0/all/0/1&quot;&gt;Wu Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gal_Y/0/1/0/all/0/1&quot;&gt;Yarin Gal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Srivastava_A/0/1/0/all/0/1&quot;&gt;Akash Srivastava&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04959">
<title>Fairness Behind a Veil of Ignorance: A Welfare Analysis for Automated Decision Making. (arXiv:1806.04959v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1806.04959</link>
<description rdf:parseType="Literal">&lt;p&gt;We draw attention to an important, yet largely overlooked aspect of
evaluating fairness for automated decision making systems---namely risk and
welfare considerations. Our proposed family of measures corresponds to the
long-established formulations of cardinal social welfare in economics. We come
to this proposal by taking the perspective of a rational, risk-averse
individual who is going to be subject to algorithmic decision making and is
faced with the task of choosing between several algorithmic alternatives behind
a Rawlsian veil of ignorance. The convex formulation of our measures allows us
to integrate them as a constraint into any convex loss minimization pipeline.
Our empirical analysis reveals interesting trade-offs between our proposal and
(a) prediction accuracy, (b) group discrimination, and (c) Dwork et al.&apos;s
notion of individual fairness. Furthermore and perhaps most importantly, our
work provides both theoretical and empirical evidence suggesting that a
lower-bound on our measures often leads to bounded inequality in algorithmic
outcomes; hence presenting the first computationally feasible mechanism for
bounding individual-level (un)fairness.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Heidari_H/0/1/0/all/0/1&quot;&gt;Hoda Heidari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ferrari_C/0/1/0/all/0/1&quot;&gt;Claudio Ferrari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gummadi_K/0/1/0/all/0/1&quot;&gt;Krishna P. Gummadi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Krause_A/0/1/0/all/0/1&quot;&gt;Andreas Krause&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05049">
<title>MAP inference via Block-Coordinate Frank-Wolfe Algorithm. (arXiv:1806.05049v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.05049</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a new proximal bundle method for Maximum-A-Posteriori (MAP)
inference in structured energy minimization problems. The method optimizes a
Lagrangean relaxation of the original energy minimization problem using a multi
plane block-coordinate Frank-Wolfe method that takes advantage of the specific
structure of the Lagrangean decomposition. We show empirically that our method
outperforms state-of-the-art Lagrangean decomposition based algorithms on some
challenging Markov Random Field, multi-label discrete tomography and graph
matching problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Swoboda_P/0/1/0/all/0/1&quot;&gt;Paul Swoboda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kolmogorov_V/0/1/0/all/0/1&quot;&gt;Vladimir Kolmogorov&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05085">
<title>Your 2 is My 1, Your 3 is My 9: Handling Arbitrary Miscalibrations in Ratings. (arXiv:1806.05085v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.05085</link>
<description rdf:parseType="Literal">&lt;p&gt;Cardinal scores (numeric ratings) collected from people are well known to
suffer from miscalibrations. A popular approach to address this issue is to
assume simplistic models of miscalibration (such as linear biases) to de-bias
the scores. This approach, however, often fares poorly because people&apos;s
miscalibrations are typically far more complex and not well understood. In the
absence of simplifying assumptions on the miscalibration, it is widely believed
that the only useful information in the cardinal scores is the induced ranking.
In this paper, inspired by the framework of Stein&apos;s shrinkage and empirical
Bayes, we contest this widespread belief. Specifically, we consider cardinal
scores with arbitrary (or even adversarially chosen) miscalibrations that is
only required to be consistent with the induced ranking. We design estimators
that despite making no assumptions on the miscalibration, surprisingly,
strictly and uniformly outperform all possible estimators that rely on only the
ranking. Our estimators are flexible in that they can be used as a plug-in for
a variety of applications. Our results thus provide novel insights in the
eternal debate between cardinal and ordinal data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jingyan Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Shah_N/0/1/0/all/0/1&quot;&gt;Nihar B. Shah&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05108">
<title>Holographic Automata for Ambient Immersive A. I. via Reservoir Computing. (arXiv:1806.05108v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1806.05108</link>
<description rdf:parseType="Literal">&lt;p&gt;We prove the existence of a semilinear representation of Cellular Automata
(CA) with the introduction of multiple convolution kernels. Examples of the
technique are presented for rules akin to the &quot;edge-of-chaos&quot; including the
Turing universal rule 110 for further utilization in the area of reservoir
computing. We also examine the significance of their dual representation on a
frequency or wavelength domain as a superposition of plane waves for
distributed computing applications including a new proposal for a &quot;Hologrid&quot;
that could be realized with present Wi-Fi,Li-Fi technologies.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Raptis_T/0/1/0/all/0/1&quot;&gt;Theophanes E. Raptis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05112">
<title>Comparing Fairness Criteria Based on Social Outcome. (arXiv:1806.05112v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1806.05112</link>
<description rdf:parseType="Literal">&lt;p&gt;Fairness in algorithmic decision-making processes is attracting increasing
concern. When an algorithm is applied to human-related decision-making an
estimator solely optimizing its predictive power can learn biases on the
existing data, which motivates us the notion of fairness in machine learning.
while several different notions are studied in the literature, little studies
are done on how these notions affect the individuals. We demonstrate such a
comparison between several policies induced by well-known fairness criteria,
including the color-blind (CB), the demographic parity (DP), and the equalized
odds (EO). We show that the EO is the only criterion among them that removes
group-level disparity. Empirical studies on the social welfare and disparity of
these policies are conducted.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Komiyama_J/0/1/0/all/0/1&quot;&gt;Junpei Komiyama&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shimao_H/0/1/0/all/0/1&quot;&gt;Hajime Shimao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05117">
<title>Learning to Shoot in First Person Shooter Games by Stabilizing Actions and Clustering Rewards for Reinforcement Learning. (arXiv:1806.05117v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1806.05117</link>
<description rdf:parseType="Literal">&lt;p&gt;While reinforcement learning (RL) has been applied to turn-based board games
for many years, more complex games involving decision-making in real-time are
beginning to receive more attention. A challenge in such environments is that
the time that elapses between deciding to take an action and receiving a reward
based on its outcome can be longer than the interval between successive
decisions. We explore this in the context of a non-player character (NPC) in a
modern first-person shooter game. Such games take place in 3D environments
where players, both human and computer-controlled, compete by engaging in
combat and completing task objectives. We investigate the use of RL to enable
NPCs to gather experience from game-play and improve their shooting skill over
time from a reward signal based on the damage caused to opponents. We propose a
new method for RL updates and reward calculations, in which the updates are
carried out periodically, after each shooting encounter has ended, and a new
weighted-reward mechanism is used which increases the reward applied to actions
that lead to damaging the opponent in successive hits in what we term &quot;hit
clusters&quot;.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Glavin_F/0/1/0/all/0/1&quot;&gt;Frank G. Glavin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Madden_M/0/1/0/all/0/1&quot;&gt;Michael G. Madden&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.00322">
<title>Disintegration and Bayesian Inversion via String Diagrams. (arXiv:1709.00322v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1709.00322</link>
<description rdf:parseType="Literal">&lt;p&gt;The notions of disintegration and Bayesian inversion are fundamental in
conditional probability theory. They produce channels, as conditional
probabilities, from a joint state, or from an already given channel (in
opposite direction). These notions exist in the literature, in concrete
situations, but are presented here in abstract graphical formulations. The
resulting abstract descriptions are used for proving basic results in
conditional probability theory. The existence of disintegration and Bayesian
inversion is discussed for discrete probability, and also for measure-theoretic
probability --- via standard Borel spaces and via likelihoods. Finally, the
usefulness of disintegration and Bayesian inversion is illustrated in several
examples.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cho_K/0/1/0/all/0/1&quot;&gt;Kenta Cho&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jacobs_B/0/1/0/all/0/1&quot;&gt;Bart Jacobs&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.08893">
<title>Fast Model Identification via Physics Engines for Data-Efficient Policy Search. (arXiv:1710.08893v3 [cs.RO] UPDATED)</title>
<link>http://arxiv.org/abs/1710.08893</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents a method for identifying mechanical parameters of robots
or objects, such as their mass and friction coefficients. Key features are the
use of off-the-shelf physics engines and the adaptation of a Bayesian
optimization technique towards minimizing the number of real-world experiments
needed for model-based reinforcement learning. The proposed framework
reproduces in a physics engine experiments performed on a real robot and
optimizes the model&apos;s mechanical parameters so as to match real-world
trajectories. The optimized model is then used for learning a policy in
simulation, before real-world deployment. It is well understood, however, that
it is hard to exactly reproduce real trajectories in simulation. Moreover, a
near-optimal policy can be frequently found with an imperfect model. Therefore,
this work proposes a strategy for identifying a model that is just good enough
to approximate the value of a locally optimal policy with a certain confidence,
instead of wasting effort on identifying the most accurate model. Evaluations,
performed both in simulation and on a real robotic manipulation task, indicate
that the proposed strategy results in an overall time-efficient, integrated
model identification and learning solution, which significantly improves the
data-efficiency of existing policy search algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_S/0/1/0/all/0/1&quot;&gt;Shaojun Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kimmel_A/0/1/0/all/0/1&quot;&gt;Andrew Kimmel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bekris_K/0/1/0/all/0/1&quot;&gt;Kostas E. Bekris&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Boularias_A/0/1/0/all/0/1&quot;&gt;Abdeslam Boularias&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.06560">
<title>Improving Exploration in Evolution Strategies for Deep Reinforcement Learning via a Population of Novelty-Seeking Agents. (arXiv:1712.06560v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1712.06560</link>
<description rdf:parseType="Literal">&lt;p&gt;Evolution strategies (ES) are a family of black-box optimization algorithms
able to train deep neural networks roughly as well as Q-learning and policy
gradient methods on challenging deep reinforcement learning (RL) problems, but
are much faster (e.g. hours vs. days) because they parallelize better. However,
many RL problems require directed exploration because they have reward
functions that are sparse or deceptive (i.e. contain local optima), and it is
unknown how to encourage such exploration with ES. Here we show that algorithms
that have been invented to promote directed exploration in small-scale evolved
neural networks via populations of exploring agents, specifically novelty
search (NS) and quality diversity (QD) algorithms, can be hybridized with ES to
improve its performance on sparse or deceptive deep RL tasks, while retaining
scalability. Our experiments confirm that the resultant new algorithms, NS-ES
and two QD algorithms, NSR-ES and NSRA-ES, avoid local optima encountered by ES
to achieve higher performance on Atari and simulated robots learning to walk
around a deceptive trap. This paper thus introduces a family of fast, scalable
algorithms for reinforcement learning that are capable of directed exploration.
It also adds this new family of exploration algorithms to the RL toolbox and
raises the interesting possibility that analogous algorithms with multiple
simultaneous paths of exploration might also combine well with existing RL
algorithms outside ES.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Conti_E/0/1/0/all/0/1&quot;&gt;Edoardo Conti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Madhavan_V/0/1/0/all/0/1&quot;&gt;Vashisht Madhavan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Such_F/0/1/0/all/0/1&quot;&gt;Felipe Petroski Such&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lehman_J/0/1/0/all/0/1&quot;&gt;Joel Lehman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stanley_K/0/1/0/all/0/1&quot;&gt;Kenneth O. Stanley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Clune_J/0/1/0/all/0/1&quot;&gt;Jeff Clune&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.02998">
<title>DeepCAS: A Deep Reinforcement Learning Algorithm for Control-Aware Scheduling. (arXiv:1803.02998v2 [cs.SY] UPDATED)</title>
<link>http://arxiv.org/abs/1803.02998</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider networked control systems consisting of multiple independent
controlled subsystems, operating over a shared communication network. Such
systems are ubiquitous in cyber-physical systems, Internet of Things, and
large-scale industrial systems. In many large-scale settings, the size of the
communication network is smaller than the size of the system. In consequence,
scheduling issues arise. The main contribution of this paper is to develop a
deep reinforcement learning-based \emph{control-aware} scheduling
(\textsc{DeepCAS}) algorithm to tackle these issues. We use the following
(optimal) design strategy: First, we synthesize an optimal controller for each
subsystem; next, we design a learning algorithm that adapts to the chosen
subsystems (plants) and controllers. As a consequence of this adaptation, our
algorithm finds a schedule that minimizes the \emph{control loss}. We present
empirical results to show that \textsc{DeepCAS} finds schedules with better
performance than periodic ones.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Demirel_B/0/1/0/all/0/1&quot;&gt;Burak Demirel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ramaswamy_A/0/1/0/all/0/1&quot;&gt;Arunselvan Ramaswamy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Quevedo_D/0/1/0/all/0/1&quot;&gt;Daniel E. Quevedo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Karl_H/0/1/0/all/0/1&quot;&gt;Holger Karl&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09045">
<title>When Simple Exploration is Sample Efficient: Identifying Sufficient Conditions for Random Exploration to Yield PAC RL Algorithms. (arXiv:1805.09045v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.09045</link>
<description rdf:parseType="Literal">&lt;p&gt;Efficient exploration is one of the key challenges for reinforcement learning
(RL) algorithms. Most traditional sample efficiency bounds require strategic
exploration. Recently many deep RL algorithm with simple heuristic exploration
strategies that have few formal guarantees, achieve surprising success in many
domains. These results pose an important question about understanding these
exploration strategies such as $e$-greedy, as well as understanding what
characterize the difficulty of exploration in MDPs. In this work we propose
problem specific sample complexity bounds of $Q$ learning with random walk
exploration that rely on several structural properties. We also link our
theoretical results to some empirical benchmark domains, to illustrate if our
bound gives polynomial sample complexity or not in these domains and how that
is related with the empirical performance in these domains.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yao Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brunskill_E/0/1/0/all/0/1&quot;&gt;Emma Brunskill&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.02623">
<title>Spectral Network Embedding: A Fast and Scalable Method via Sparsity. (arXiv:1806.02623v2 [cs.SI] UPDATED)</title>
<link>http://arxiv.org/abs/1806.02623</link>
<description rdf:parseType="Literal">&lt;p&gt;Network embedding aims to learn low-dimensional representations of nodes in a
network, while the network structure and inherent properties are preserved. It
has attracted tremendous attention recently due to significant progress in
downstream network learning tasks, such as node classification, link
prediction, and visualization. However, most existing network embedding methods
suffer from the expensive computations due to the large volume of networks. In
this paper, we propose a $10\times \sim 100\times$ faster network embedding
method, called Progle, by elegantly utilizing the sparsity property of online
networks and spectral analysis. In Progle, we first construct a \textit{sparse}
proximity matrix and train the network embedding efficiently via sparse matrix
decomposition. Then we introduce a network propagation pattern via spectral
analysis to incorporate local and global structure information into the
embedding. Besides, this model can be generalized to integrate network
information into other insufficiently trained embeddings at speed. Benefiting
from sparse spectral network embedding, our experiment on four different
datasets shows that Progle outperforms or is comparable to state-of-the-art
unsupervised comparison approaches---DeepWalk, LINE, node2vec, GraRep, and
HOPE, regarding accuracy, while is $10\times$ faster than the fastest
word2vec-based method. Finally, we validate the scalability of Progle both in
real large-scale networks and multiple scales of synthetic networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Jie Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yan Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1&quot;&gt;Jie Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ding_M/0/1/0/all/0/1&quot;&gt;Ming Ding&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04731">
<title>Deep learning to represent sub-grid processes in climate models. (arXiv:1806.04731v1 [physics.ao-ph])</title>
<link>http://arxiv.org/abs/1806.04731</link>
<description rdf:parseType="Literal">&lt;p&gt;The representation of nonlinear sub-grid processes, especially clouds, has
been a major source of uncertainty in climate models for decades.
Cloud-resolving models better represent many of these processes and can now be
run globally but only for short-term simulations of at most a few years because
of computational limitations. Here we demonstrate that deep learning can be
used to capture many advantages of cloud-resolving modeling at a fraction of
the computational cost. We train a deep neural network to represent all
atmospheric sub-grid processes in a climate model by learning from a
multi-scale model in which convection is treated explicitly. The trained neural
network then replaces the traditional sub-grid parameterizations in a global
general circulation model in which it freely interacts with the resolved
dynamics and the surface-flux scheme. The prognostic multi-year simulations are
stable and closely reproduce not only the mean climate of the cloud-resolving
simulation but also key aspects of variability, including precipitation
extremes and the equatorial wave spectrum. Furthermore, the neural network
approximately conserves energy despite not being explicitly instructed to.
Finally, we show that the neural network parameterization generalizes to new
surface forcing patterns but struggles to cope with temperatures far outside
its training manifold. Our results show the feasibility of using deep learning
for climate model parameterization. In a broader context, we anticipate that
data-driven Earth System Model development could play a key role in reducing
climate prediction uncertainty in the coming decade.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Rasp_S/0/1/0/all/0/1&quot;&gt;Stephan Rasp&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Pritchard_M/0/1/0/all/0/1&quot;&gt;Michael S. Pritchard&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/physics/1/au:+Gentine_P/0/1/0/all/0/1&quot;&gt;Pierre Gentine&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04743">
<title>INFERNO: Inference-Aware Neural Optimisation. (arXiv:1806.04743v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.04743</link>
<description rdf:parseType="Literal">&lt;p&gt;Complex computer simulations are commonly required for accurate data
modelling in many scientific disciplines, making statistical inference
challenging due to the intractability of the likelihood evaluation for the
observed data. Furthermore, sometimes one is interested on inference drawn over
a subset of the generative model parameters while taking into account model
uncertainty or misspecification on the remaining nuisance parameters. In this
work, we show how non-linear summary statistics can be constructed by
minimising inference-motivated losses via stochastic gradient descent.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Castro_P/0/1/0/all/0/1&quot;&gt;Pablo de Castro&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Dorigo_T/0/1/0/all/0/1&quot;&gt;Tommaso Dorigo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04773">
<title>Static Malware Detection &amp; Subterfuge: Quantifying the Robustness of Machine Learning and Current Anti-Virus. (arXiv:1806.04773v1 [cs.CR])</title>
<link>http://arxiv.org/abs/1806.04773</link>
<description rdf:parseType="Literal">&lt;p&gt;As machine-learning (ML) based systems for malware detection become more
prevalent, it becomes necessary to quantify the benefits compared to the more
traditional anti-virus (AV) systems widely used today. It is not practical to
build an agreed upon test set to benchmark malware detection systems on pure
classification performance. Instead we tackle the problem by creating a new
testing methodology, where we evaluate the change in performance on a set of
known benign &amp;amp; malicious files as adversarial modifications are performed. The
change in performance combined with the evasion techniques then quantifies a
system&apos;s robustness against that approach. Through these experiments we are
able to show in a quantifiable way how purely ML based systems can be more
robust than AV products at detecting malware that attempts evasion through
modification, but may be slower to adapt in the face of significantly novel
attacks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fleshman_W/0/1/0/all/0/1&quot;&gt;William Fleshman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Raff_E/0/1/0/all/0/1&quot;&gt;Edward Raff&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zak_R/0/1/0/all/0/1&quot;&gt;Richard Zak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+McLean_M/0/1/0/all/0/1&quot;&gt;Mark McLean&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nicholas_C/0/1/0/all/0/1&quot;&gt;Charles Nicholas&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04819">
<title>Integral Privacy for Density Estimation with Approximation Guarantees. (arXiv:1806.04819v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.04819</link>
<description rdf:parseType="Literal">&lt;p&gt;Density estimation is an old and central problem in statistics and machine
learning. There exists only few approaches to cast this problem in a
differential privacy framework and to our knowledge, while all provide proofs
of security, very little is still known about the approximation guarantees of
the \textit{unknown density} by the private one learned. In this paper, we
exploit the tools of boosting to show that, provided we have access to a weak
learner in the original boosting sense, there exists a way to learn a
\textit{private density} out of \textit{classifiers}, which can guarantee an
approximation of the true density that degrades gracefully as the privacy
budget $\epsilon$ decreases. There are three key formal features of our
results: (i) our approximation bound is, as we show, near optimal for our
technique at hand and (ii) the privacy guarantee holds \textit{even when} we
remove the famed adjacency condition of inputs in differential privacy, thereby
leading to a stronger privacy guarantee we relate to as \textit{integral
privacy}. Finally, (iii) we provide for the first time approximation guarantees
for the capture of fat regions of the density, a problem which is receiving a
lot of attention in the generative adversarial networks literature with the
mode capture problem. Experimental results against a state of the art
implementation of private kernel density estimation display that our technique
consistently obtains improved results, managing in particular to get similar
outputs for a privacy budget $\epsilon$ which is however orders of magnitude
smaller.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Husain_H/0/1/0/all/0/1&quot;&gt;Hisham Husain&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Cranko_Z/0/1/0/all/0/1&quot;&gt;Zac Cranko&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Nock_R/0/1/0/all/0/1&quot;&gt;Richard Nock&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04823">
<title>Plug-in Regularized Estimation of High-Dimensional Parameters in Nonlinear Semiparametric Models. (arXiv:1806.04823v1 [math.ST])</title>
<link>http://arxiv.org/abs/1806.04823</link>
<description rdf:parseType="Literal">&lt;p&gt;We develop a theory for estimation of a high-dimensional sparse parameter
$\theta$ defined as a minimizer of a population loss function $L_D(\theta,g_0)$
which, in addition to $\theta$, depends on a, potentially infinite dimensional,
nuisance parameter $g_0$. Our approach is based on estimating $\theta$ via an
$\ell_1$-regularized minimization of a sample analog of $L_S(\theta, \hat{g})$,
plugging in a first-stage estimate $\hat{g}$, computed on a hold-out sample. We
define a population loss to be (Neyman) orthogonal if the gradient of the loss
with respect to $\theta$, has pathwise derivative with respect to $g$ equal to
zero, when evaluated at the true parameter and nuisance component. We show that
orthogonality implies a second-order impact of the first stage nuisance error
on the second stage target parameter estimate. Our approach applies to both
convex and non-convex losses, albeit the latter case requires a small
adaptation of our method with a preliminary estimation step of the target
parameter. Our result enables oracle convergence rates for $\theta$ under
assumptions on the first stage rates, typically of the order of $n^{-1/4}$.
&lt;/p&gt;
&lt;p&gt;We show how such an orthogonal loss can be constructed via a novel
orthogonalization process for a general model defined by conditional moment
restrictions. We apply our theory to high-dimensional versions of standard
estimation problems in statistics and econometrics, such as: estimation of
conditional moment models with missing data, estimation of structural utilities
in games of incomplete information and estimation of treatment effects in
regression models with non-linear link functions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Chernozhukov_V/0/1/0/all/0/1&quot;&gt;Victor Chernozhukov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Nekipelov_D/0/1/0/all/0/1&quot;&gt;Denis Nekipelov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Semenova_V/0/1/0/all/0/1&quot;&gt;Vira Semenova&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Syrgkanis_V/0/1/0/all/0/1&quot;&gt;Vasilis Syrgkanis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04838">
<title>Partial AUC Maximization via Nonlinear Scoring Functions. (arXiv:1806.04838v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.04838</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a method for maximizing a partial area under a receiver operating
characteristic (ROC) curve (pAUC) for binary classification tasks. In binary
classification tasks, accuracy is the most commonly used as a measure of
classifier performance. In some applications such as anomaly detection and
diagnostic testing, accuracy is not an appropriate measure since prior
probabilties are often greatly biased. Although in such cases the pAUC has been
utilized as a performance measure, few methods have been proposed for directly
maximizing the pAUC. This optimization is achieved by using a scoring function.
The conventional approach utilizes a linear function as the scoring function.
In contrast we newly introduce nonlinear scoring functions for this purpose.
Specifically, we present two types of nonlinear scoring functions based on
generative models and deep neural networks. We show experimentally that
nonlinear scoring fucntions improve the conventional methods through the
application of a binary classification of real and bogus objects obtained with
the Hyper Suprime-Cam on the Subaru telescope.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ueda_N/0/1/0/all/0/1&quot;&gt;Naonori Ueda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Fujino_A/0/1/0/all/0/1&quot;&gt;Akinori Fujino&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04863">
<title>Cell Identity Codes: Understanding Cell Identity from Gene Expression Profiles using Deep Neural Networks. (arXiv:1806.04863v1 [q-bio.GN])</title>
<link>http://arxiv.org/abs/1806.04863</link>
<description rdf:parseType="Literal">&lt;p&gt;Understanding cell identity is an important task in many biomedical areas.
Expression patterns of specific marker genes have been used to characterize
some limited cell types, but exclusive markers are not available for many cell
types. A second approach is to use machine learning to discriminate cell types
based on the whole gene expression profiles (GEPs). The accuracies of simple
classification algorithms such as linear discriminators or support vector
machines are limited due to the complexity of biological systems. We used deep
neural networks to analyze 1040 GEPs from 16 different human tissues and cell
types. After comparing different architectures, we identified a specific
structure of deep autoencoders that can encode a GEP into a vector of 30
numeric values, which we call the cell identity code (CIC). The original GEP
can be reproduced from the CIC with an accuracy comparable to technical
replicates of the same experiment. Although we use an unsupervised approach to
train the autoencoder, we show different values of the CIC are connected to
different biological aspects of the cell, such as different pathways or
biological processes. This network can use CIC to reproduce the GEP of the cell
types it has never seen during the training. It also can resist some noise in
the measurement of the GEP. Furthermore, we introduce classifier autoencoder,
an architecture that can accurately identify cell type based on the GEP or the
CIC.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Abdolhosseini_F/0/1/0/all/0/1&quot;&gt;Farzad Abdolhosseini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Azarkhalili_B/0/1/0/all/0/1&quot;&gt;Behrooz Azarkhalili&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Maazallahi_A/0/1/0/all/0/1&quot;&gt;Abbas Maazallahi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Kamal_A/0/1/0/all/0/1&quot;&gt;Aryan Kamal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Motahari_S/0/1/0/all/0/1&quot;&gt;Seyed Abolfazl Motahari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Sharifi_Zarchi_A/0/1/0/all/0/1&quot;&gt;Ali Sharifi-Zarchi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Chitsaz_H/0/1/0/all/0/1&quot;&gt;Hamidreza Chitsaz&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04900">
<title>A Machine-Learning Item Recommendation System for Video Games. (arXiv:1806.04900v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.04900</link>
<description rdf:parseType="Literal">&lt;p&gt;Video-game players generate huge amounts of data, as everything they do
within a game is recorded. In particular, among all the stored actions and
behaviors, there is information on the in-game purchases of virtual products.
Such information is of critical importance in modern free-to-play titles, where
gamers can select or buy a profusion of items during the game in order to
progress and fully enjoy their experience.
&lt;/p&gt;
&lt;p&gt;To try to maximize these kind of purchases, one can use a recommendation
system so as to present players with items that might be interesting for them.
Such systems can better achieve their goal by employing machine learning
algorithms that are able to predict the rating of an item or product by a
particular user. In this paper we evaluate and compare two of these algorithms,
an ensemble-based model (extremely randomized trees) and a deep neural network,
both of which are promising candidates for operational video-game recommender
engines.
&lt;/p&gt;
&lt;p&gt;Item recommenders can help developers improve the game. But, more
importantly, it should be possible to integrate them into the game, so that
users automatically get personalized recommendations while playing. The
presented models are not only able to meet this challenge, providing accurate
predictions of the items that a particular player will find attractive, but
also sufficiently fast and robust to be used in operational settings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bertens_P/0/1/0/all/0/1&quot;&gt;Paul Bertens&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Guitart_A/0/1/0/all/0/1&quot;&gt;Anna Guitart&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chen_P/0/1/0/all/0/1&quot;&gt;Pei Pei Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Perianez_A/0/1/0/all/0/1&quot;&gt;&amp;#xc1;frica Peri&amp;#xe1;&amp;#xf1;ez&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04994">
<title>Only Bayes should learn a manifold (on the estimation of differential geometric structure from data). (arXiv:1806.04994v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.04994</link>
<description rdf:parseType="Literal">&lt;p&gt;We investigate learning of the differential geometric structure of a data
manifold embedded in a high-dimensional Euclidean space. We first analyze
kernel-based algorithms and show that under the usual regularizations,
non-probabilistic methods cannot recover the differential geometric structure,
but instead find mostly linear manifolds or spaces equipped with teleports. To
properly learn the differential geometric structure, non-probabilistic methods
must apply regularizations that enforce large gradients, which go against
common wisdom. We repeat the analysis for probabilistic methods and find that
under reasonable priors, the geometric structure can be recovered. Fully
exploiting the recovered structure, however, requires the development of
stochastic extensions to classic Riemannian geometry. We take early steps in
that regard. Finally, we partly extend the analysis to modern models based on
neural networks, thereby highlighting geometric and probabilistic shortcomings
of current deep generative models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hauberg_S/0/1/0/all/0/1&quot;&gt;S&amp;#xf8;ren Hauberg&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05017">
<title>Brain-Computer Interface with Corrupted EEG Data: A Tensor Completion Approach. (arXiv:1806.05017v1 [q-bio.QM])</title>
<link>http://arxiv.org/abs/1806.05017</link>
<description rdf:parseType="Literal">&lt;p&gt;One of the current issues in Brain-Computer Interface is how to deal with
noisy Electroencephalography measurements organized as multidimensional
datasets. On the other hand, recently, significant advances have been made in
multidimensional signal completion algorithms that exploit tensor decomposition
models to capture the intricate relationship among entries in a
multidimensional signal. We propose to use tensor completion applied to EEG
data for improving the classification performance in a motor imagery BCI system
with corrupted measurements. Noisy measurements are considered as unknowns that
are inferred from a tensor decomposition model. We evaluate the performance of
four recently proposed tensor completion algorithms plus a simple interpolation
strategy, first with random missing entries and then with missing samples
constrained to have a specific structure (random missing channels), which is a
more realistic assumption in BCI Applications. We measured the ability of these
algorithms to reconstruct the tensor from observed data. Then, we tested the
classification accuracy of imagined movement in a BCI experiment with missing
samples. We show that for random missing entries, all tensor completion
algorithms can recover missing samples increasing the classification
performance compared to a simple interpolation approach. For the random missing
channels case, we show that tensor completion algorithms help to reconstruct
missing channels, significantly improving the accuracy in the classification of
motor imagery, however, not at the same level as clean data. Tensor completion
algorithms are useful in real BCI applications. The proposed strategy could
allow using motor imagery BCI systems even when EEG data is highly affected by
missing channels and/or samples, avoiding the need of new acquisitions in the
calibration stage.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Sole_Casals_J/0/1/0/all/0/1&quot;&gt;Jordi Sole-Casals&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Caiafa_C/0/1/0/all/0/1&quot;&gt;Cesar F. Caiafa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Zhao_Q/0/1/0/all/0/1&quot;&gt;Qibin Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/q-bio/1/au:+Cichocki_A/0/1/0/all/0/1&quot;&gt;Adrzej Cichocki&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05054">
<title>Support Vector Machine Application for Multiphase Flow Pattern Prediction. (arXiv:1806.05054v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.05054</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper a data analytical approach featuring support vector machines
(SVM) is employed to train a predictive model over an experimentaldataset,
which consists of the most relevant studies for two-phase flow pattern
prediction. The database for this study consists of flow patterns or flow
regimes in gas-liquid two-phase flow. The term flow pattern refers to the
geometrical configuration of the gas and liquid phases in the pipe. When gas
and liquid flow simultaneously in a pipe, the two phases can distribute
themselves in a variety of flow configurations. Gas-liquid two-phase flow
occurs ubiquitously in various major industrial fields: petroleum, chemical,
nuclear, and geothermal industries. The flow configurations differ from each
other in the spatial distribution of the interface, resulting in different flow
characteristics. Experimental results obtained by applying the presented
methodology to different combinations of flow patterns demonstrate that the
proposed approach is state-of-the-art alternatives by achieving 97% correct
classification. The results suggest machine learning could be used as an
effective tool for automatic detection and classification of gas-liquid flow
patterns.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Guillen_Rondon_P/0/1/0/all/0/1&quot;&gt;Pablo Guillen-Rondon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Robinson_M/0/1/0/all/0/1&quot;&gt;Melvin D. Robinson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Torres_C/0/1/0/all/0/1&quot;&gt;Carlos Torres&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pereya_E/0/1/0/all/0/1&quot;&gt;Eduardo Pereya&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05096">
<title>Path-entropy maximized Markov chains for dimensionality reduction. (arXiv:1806.05096v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.05096</link>
<description rdf:parseType="Literal">&lt;p&gt;Stochastic kernel based dimensionality reduction methods have become popular
in the last decade. The central component of these methods is a symmetric
kernel that quantifies the vicinity of pairs of data points and a
kernel-induced Markov chain. Typically, the Markov chain is fully specified by
the kernel through row normalization. However, it may be desirable to impose
user-specified stationary-state and dynamical constraints on the Markov chain.
Notably, no systematic framework exists to prescribe user-defined constraints
on Markov chains. Here, we use a path entropy maximization based approach to
derive Markov chains on data using a kernel and additional user-defined
constraints. We illustrate the usefulness of the path entropy normalization
procedure with multiple real and artificial data sets.
&lt;/p&gt;
&lt;p&gt;All scripts are available at: https://github.com/dixitpd/maxcaldiffmap
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dixit_P/0/1/0/all/0/1&quot;&gt;Purushottam D. Dixit&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05134">
<title>Marginal Policy Gradients for Complex Control. (arXiv:1806.05134v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.05134</link>
<description rdf:parseType="Literal">&lt;p&gt;Many complex domains, such as robotics control and real-time strategy (RTS)
games, require an agent to learn a continuous control. In the former, an agent
learns a policy over $\mathbb{R}^d$ and in the latter, over a discrete set of
actions each of which is parametrized by a continuous parameter. Such problems
are naturally solved using policy based reinforcement learning (RL) methods,
but unfortunately these often suffer from high variance leading to instability
and slow convergence. We show that in many cases a substantial portion of the
variance in policy gradient estimators is completely unnecessary and can be
eliminated without introducing bias. Unnecessary variance is introduced
whenever policies over bounded action spaces are modeled using distributions
with unbounded support, by applying a transformation $T$ to the sampled action
before execution in the environment. Recent works have studied variance reduced
policy gradients for actions in bounded intervals, but to date no variance
reduced methods exist when the action is a direction -- constrained to the unit
sphere -- something often seen in RTS games. To address these challenges we:
(1) introduce a stochastic policy gradient method for directional control; (2)
introduce the marginal policy gradient framework, a powerful technique to
obtain variance reduced policy gradients for arbitrary $T$; (3) show that
marginal policy gradients are guaranteed to reduce variance, quantifying that
reduction exactly; (4) validate our framework by applying the methods to a
popular RTS game and a navigation task, demonstrating improvement over a policy
gradient baseline.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Eisenach_C/0/1/0/all/0/1&quot;&gt;Carson Eisenach&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1&quot;&gt;Haichuan Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Ji Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1&quot;&gt;Han Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05139">
<title>High-Dimensional Inference for Cluster-Based Graphical Models. (arXiv:1806.05139v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.05139</link>
<description rdf:parseType="Literal">&lt;p&gt;Motivated by modern applications in which one constructs graphical models
based on a very large number of features, this paper introduces a new class of
cluster-based graphical models. Unlike standard graphical models, variable
clustering is applied as an initial step for reducing the dimension of the
feature space. We employ model assisted clustering, in which the clusters
contain features that are similar to the same unobserved latent variable. Two
different cluster-based Gaussian graphical models are considered: the latent
variable graph, corresponding to the graphical model associated with the
unobserved latent variables, and the cluster-average graph, corresponding to
the vector of features averaged over clusters. We derive estimates tailored to
these graphs, with the goal of pattern recovery under false discovery rate
(FDR) control. Our study reveals that likelihood based inference for the latent
graph is analytically intractable, and we develop alternative estimation and
inference strategies. We replace the likelihood of the data by appropriate
empirical risk functions that allow for valid inference in both graphical
models under study. Our main results are Berry-Esseen central limit theorems
for the proposed estimators, which are proved under weaker assumptions than
those employed in the existing literature on Gaussian graphical model
inference. We make explicit the implications of the asymptotic approximations
on graph recovery under FDR control, and show when it can be controlled
asymptotically. Our analysis takes into account the uncertainty induced by the
initial clustering step. We find that the errors induced by clustering are
asymptotically ignorable in the follow-up analysis, under no further
restrictions on the parameter space for which inference is valid. The
theoretical properties of the proposed procedures are verified on simulated
data and an fMRI data analysis.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Eisenach_C/0/1/0/all/0/1&quot;&gt;Carson Eisenach&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bunea_F/0/1/0/all/0/1&quot;&gt;Florentina Bunea&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ning_Y/0/1/0/all/0/1&quot;&gt;Yang Ning&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Dinicu_C/0/1/0/all/0/1&quot;&gt;Claudiu Dinicu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.05151">
<title>On Landscape of Lagrangian Functions and Stochastic Search for Constrained Nonconvex Optimization. (arXiv:1806.05151v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.05151</link>
<description rdf:parseType="Literal">&lt;p&gt;We study constrained nonconvex optimization problems in machine learning,
signal processing, and stochastic control. It is well-known that these problems
can be rewritten to a minimax problem in a Lagrangian form. However, due to the
lack of convexity, their landscape is not well understood and how to find the
stable equilibria of the Lagrangian function is still unknown. To bridge the
gap, we study the landscape of the Lagrangian function. Further, we define a
special class of Lagrangian functions. They enjoy two properties: 1.Equilibria
are either stable or unstable (Formal definition in Section 2); 2.Stable
equilibria correspond to the global optima of the original problem. We show
that a generalized eigenvalue (GEV) problem, including canonical correlation
analysis and other problems, belongs to the class. Specifically, we
characterize its stable and unstable equilibria by leveraging an invariant
group and symmetric property (more details in Section 3). Motivated by these
neat geometric structures, we propose a simple, efficient, and stochastic
primal-dual algorithm solving the online GEV problem. Theoretically, we provide
sufficient conditions, based on which we establish an asymptotic convergence
rate and obtain the first sample complexity result for the online GEV problem
by diffusion approximations, which are widely used in applied probability and
stochastic control. Numerical results are provided to support our theory.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1&quot;&gt;Zhehui Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xingguo Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1&quot;&gt;Lin F. Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Haupt_J/0/1/0/all/0/1&quot;&gt;Jarvis Haupt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_T/0/1/0/all/0/1&quot;&gt;Tuo Zhao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1609.05486">
<title>Probabilistic Feature Selection and Classification Vector Machine. (arXiv:1609.05486v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1609.05486</link>
<description rdf:parseType="Literal">&lt;p&gt;Sparse Bayesian learning is a state-of-the-art supervised learning algorithm
that can choose a subset of relevant samples from the input data and make
reliable probabilistic predictions. However, in the presence of
high-dimensional data with irrelevant features, traditional sparse Bayesian
classifiers suffer from performance degradation and low efficiency by failing
to eliminate irrelevant features. To tackle this problem, we propose a novel
sparse Bayesian embedded feature selection method that adopts truncated
Gaussian distributions as both sample and feature priors. The proposed method,
called probabilistic feature selection and classification vector machine
(PFCVMLP ), is able to simultaneously select relevant features and samples for
classification tasks. In order to derive the analytical solutions, Laplace
approximation is applied to compute approximate posteriors and marginal
likelihoods. Finally, parameters and hyperparameters are optimized by the
type-II maximum likelihood method. Experiments on three datasets validate the
performance of PFCVMLP along two dimensions: classification performance and
effectiveness for feature selection. Finally, we analyze the generalization
performance and derive a generalization error bound for PFCVMLP . By tightening
the bound, the importance of feature selection is demonstrated.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_B/0/1/0/all/0/1&quot;&gt;Bingbing Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_C/0/1/0/all/0/1&quot;&gt;Chang Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rijke_M/0/1/0/all/0/1&quot;&gt;Maarten de Rijke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yao_X/0/1/0/all/0/1&quot;&gt;Xin Yao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_H/0/1/0/all/0/1&quot;&gt;Huanhuan Chen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1706.03922">
<title>Analyzing the Robustness of Nearest Neighbors to Adversarial Examples. (arXiv:1706.03922v4 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1706.03922</link>
<description rdf:parseType="Literal">&lt;p&gt;Motivated by safety-critical applications, test-time attacks on classifiers
via adversarial examples has recently received a great deal of attention.
However, there is a general lack of understanding on why adversarial examples
arise; whether they originate due to inherent properties of data or due to lack
of training samples remains ill-understood. In this work, we introduce a
theoretical framework analogous to bias-variance theory for understanding these
effects.
&lt;/p&gt;
&lt;p&gt;We use our framework to analyze the robustness of a canonical non-parametric
classifier - the k-nearest neighbors. Our analysis shows that its robustness
properties depend critically on the value of k - the classifier may be
inherently non-robust for small k, but its robustness approaches that of the
Bayes Optimal classifier for fast-growing k. We propose a novel modified
1-nearest neighbor classifier, and guarantee its robustness in the large sample
limit. Our experiments suggest that this classifier may have good robustness
properties even for reasonable data set sizes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yizhen Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Jha_S/0/1/0/all/0/1&quot;&gt;Somesh Jha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chaudhuri_K/0/1/0/all/0/1&quot;&gt;Kamalika Chaudhuri&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.02893">
<title>Convolutional Dictionary Learning: A Comparative Review and New Algorithms. (arXiv:1709.02893v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1709.02893</link>
<description rdf:parseType="Literal">&lt;p&gt;Convolutional sparse representations are a form of sparse representation with
a dictionary that has a structure that is equivalent to convolution with a set
of linear filters. While effective algorithms have recently been developed for
the convolutional sparse coding problem, the corresponding dictionary learning
problem is substantially more challenging. Furthermore, although a number of
different approaches have been proposed, the absence of thorough comparisons
between them makes it difficult to determine which of them represents the
current state of the art. The present work both addresses this deficiency and
proposes some new approaches that outperform existing ones in certain contexts.
A thorough set of performance comparisons indicates a very wide range of
performance differences among the existing and proposed methods, and clearly
identifies those that are the most effective.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garcia_Cardona_C/0/1/0/all/0/1&quot;&gt;Cristina Garcia-Cardona&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wohlberg_B/0/1/0/all/0/1&quot;&gt;Brendt Wohlberg&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.05515">
<title>Some variations on Ensembled Random Survival Forest with application to Cancer Research. (arXiv:1709.05515v2 [stat.ME] UPDATED)</title>
<link>http://arxiv.org/abs/1709.05515</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper we describe a novel implementation of adaboost for prediction
of survival function. We take different variations of the algorithm and compare
the algorithms based on system run time and root mean square error. Our
construction includes right censoring data and competing risk data too. We take
different data set to illustrate the performance of the algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Dey_A/0/1/0/all/0/1&quot;&gt;Arabin Kumar Dey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+N%2E_S/0/1/0/all/0/1&quot;&gt;Suhas N.&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Teja_T/0/1/0/all/0/1&quot;&gt;Talasila Sai Teja&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Juneja_A/0/1/0/all/0/1&quot;&gt;Anshul Juneja&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.08464">
<title>Interpretable Machine Learning for Privacy-Preserving Pervasive Systems. (arXiv:1710.08464v5 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1710.08464</link>
<description rdf:parseType="Literal">&lt;p&gt;The presence of pervasive systems in our everyday lives and the interaction
of users with connected devices such as smartphones or home appliances generate
increasing amounts of traces that reflect users&apos; behavior. A plethora of
machine learning techniques enable service providers to process these traces to
extract latent information about the users. While most of the existing projects
have focused on the accuracy of these techniques, little work has been done on
the interpretation of the inference and identification algorithms based on
them. In this paper, we propose a machine learning interpretability framework
for inference algorithms based on data collected through pervasive systems and
we outline the open challenges in this research area. Our interpretability
framework enable users to understand how the traces they generate could expose
their privacy, while allowing for usable and personalized services at the same
time.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Baron_B/0/1/0/all/0/1&quot;&gt;Benjamin Baron&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Musolesi_M/0/1/0/all/0/1&quot;&gt;Mirco Musolesi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04374">
<title>Tempered Adversarial Networks. (arXiv:1802.04374v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1802.04374</link>
<description rdf:parseType="Literal">&lt;p&gt;Generative adversarial networks (GANs) have been shown to produce realistic
samples from high-dimensional distributions, but training them is considered
hard. A possible explanation for training instabilities is the inherent
imbalance between the networks: While the discriminator is trained directly on
both real and fake samples, the generator only has control over the fake
samples it produces since the real data distribution is fixed by the choice of
a given dataset. We propose a simple modification that gives the generator
control over the real samples which leads to a tempered learning process for
both generator and discriminator. The real data distribution passes through a
lens before being revealed to the discriminator, balancing the generator and
discriminator by gradually revealing more detailed features necessary to
produce high-quality results. The proposed module automatically adjusts the
learning process to the current strength of the networks, yet is generic and
easy to add to any GAN variant. In a number of experiments, we show that this
can improve quality, stability and/or convergence speed across a range of
different GAN architectures (DCGAN, LSGAN, WGAN-GP).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sajjadi_M/0/1/0/all/0/1&quot;&gt;Mehdi S. M. Sajjadi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Parascandolo_G/0/1/0/all/0/1&quot;&gt;Giambattista Parascandolo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mehrjou_A/0/1/0/all/0/1&quot;&gt;Arash Mehrjou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Scholkopf_B/0/1/0/all/0/1&quot;&gt;Bernhard Sch&amp;#xf6;lkopf&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06847">
<title>Distribution Matching in Variational Inference. (arXiv:1802.06847v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1802.06847</link>
<description rdf:parseType="Literal">&lt;p&gt;We show that Variational Autoencoders consistently fail to learn marginal
distributions in latent and visible space. We ask whether this is a consequence
of matching conditional distributions, or a limitation of explicit model and
posterior distributions. We explore alternatives provided by marginal
distribution matching and implicit distributions through the use of Generative
Adversarial Networks in variational inference. We perform a large-scale
evaluation of several VAE-GAN hybrids and explore the implications of class
probability estimation for learning distributions. We conclude that at present
VAE-GAN hybrids have limited applicability: they are harder to scale, evaluate,
and use for inference compared to VAEs; and they do not improve over the
generation quality of GANs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rosca_M/0/1/0/all/0/1&quot;&gt;Mihaela Rosca&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lakshminarayanan_B/0/1/0/all/0/1&quot;&gt;Balaji Lakshminarayanan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mohamed_S/0/1/0/all/0/1&quot;&gt;Shakir Mohamed&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.03234">
<title>Improving Optimization in Models With Continuous Symmetry Breaking. (arXiv:1803.03234v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1803.03234</link>
<description rdf:parseType="Literal">&lt;p&gt;Many loss functions in representation learning are invariant under a
continuous symmetry transformation. For example, the loss function of word
embeddings (Mikolov et al., 2013) remains unchanged if we simultaneously rotate
all word and context embedding vectors. We show that representation learning
models for time series possess an approximate continuous symmetry that leads to
slow convergence of gradient descent. We propose a new optimization algorithm
that speeds up convergence using ideas from gauge theory in physics. Our
algorithm leads to orders of magnitude faster convergence and to more
interpretable representations, as we show for dynamic extensions of matrix
factorization and word embedding models. We further present an example
application of our proposed algorithm that translates modern words into their
historic equivalents.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bamler_R/0/1/0/all/0/1&quot;&gt;Robert Bamler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mandt_S/0/1/0/all/0/1&quot;&gt;Stephan Mandt&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.06837">
<title>A fast algorithm with minimax optimal guarantees for topic models with an unknown number of topics. (arXiv:1805.06837v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1805.06837</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a new method of estimation in topic models, that is not a
variation on the existing simplex finding algorithms, and that estimates the
number of topics K from the observed data. We derive new finite sample minimax
lower bounds for the estimation of A, as well as new upper bounds for our
proposed estimator. We describe the scenarios where our estimator is minimax
adaptive. Our finite sample analysis is valid for any number of documents (n),
individual document length (N_i), dictionary size (p) and number of topics (K),
and both p and K are allowed to increase with n, a situation not handled well
by previous analyses. We complement our theoretical results with a detailed
simulation study. We illustrate that the new algorithm is faster and more
accurate than the current ones, although we start out with a computational and
theoretical disadvantage of not knowing the correct number of topics K, while
we provide the competing methods with the correct value in our simulations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bing_X/0/1/0/all/0/1&quot;&gt;Xin Bing&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bunea_F/0/1/0/all/0/1&quot;&gt;Florentina Bunea&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wegkamp_M/0/1/0/all/0/1&quot;&gt;Marten Wegkamp&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09950">
<title>Early Stopping for Nonparametric Testing. (arXiv:1805.09950v2 [math.ST] UPDATED)</title>
<link>http://arxiv.org/abs/1805.09950</link>
<description rdf:parseType="Literal">&lt;p&gt;Early stopping of iterative algorithms is an algorithmic regularization
method to avoid over-fitting in estimation and classification. In this paper,
we show that early stopping can also be applied to obtain the minimax optimal
testing in a general non-parametric setup. Specifically, a Wald-type test
statistic is obtained based on an iterated estimate produced by functional
gradient descent algorithms in a reproducing kernel Hilbert space. A notable
contribution is to establish a &quot;sharp&quot; stopping rule: when the number of
iterations achieves an optimal order, testing optimality is achievable;
otherwise, testing optimality becomes impossible. As a by-product, a similar
sharpness result is also derived for minimax optimal estimation under early
stopping studied in [11] and [19]. All obtained results hold for various kernel
classes, including Sobolev smoothness classes and Gaussian kernel classes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Liu_M/0/1/0/all/0/1&quot;&gt;Meimei Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Cheng_G/0/1/0/all/0/1&quot;&gt;Guang Cheng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.09994">
<title>Safe learning-based optimal motion planning for automated driving. (arXiv:1805.09994v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.09994</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper presents preliminary work on learning the search heuristic for the
optimal motion planning for automated driving in urban traffic. Previous work
considered search-based optimal motion planning framework (SBOMP) that utilized
numerical or model-based heuristics that did not consider dynamic obstacles.
Optimal solution was still guaranteed since dynamic obstacles can only increase
the cost. However, significant variations in the search efficiency are observed
depending whether dynamic obstacles are present or not. This paper introduces
machine learning (ML) based heuristic that takes into account dynamic
obstacles, thus adding to the performance consistency for achieving real-time
implementation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ajanovic_Z/0/1/0/all/0/1&quot;&gt;Zlatan Ajanovic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lacevic_B/0/1/0/all/0/1&quot;&gt;Bakir Lacevic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stettinger_G/0/1/0/all/0/1&quot;&gt;Georg Stettinger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Watzenig_D/0/1/0/all/0/1&quot;&gt;Daniel Watzenig&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Horn_M/0/1/0/all/0/1&quot;&gt;Martin Horn&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00530">
<title>Efficient, Certifiably Optimal High-Dimensional Clustering. (arXiv:1806.00530v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1806.00530</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider SDP relaxation methods for data and variable clustering problems,
which have been shown in the literature to have good statistical properties in
a variety of settings, but remain intractable to solve in practice. In
particular, we propose FORCE, a new algorithm to solve the Peng-Wei $K$-means
SDP. Compared to the naive interior point method, our method reduces the
computational complexity of solving the SDP from
$\tilde{O}(d^7\log\epsilon^{-1})$ to $\tilde{O}(d^{6}K^{-2}\epsilon^{-1})$. Our
method combines a primal first-order method with a dual optimality certificate
search, which when successful, allows for early termination of the primal
method. We show under certain data generating distributions that, with high
probability, FORCE is guaranteed to find the optimal solution to the SDP
relaxation and provide a certificate of exact optimality. As verified by our
numerical experiments, this allows FORCE to solve the Peng-Wei SDP with
dimensions in the hundreds in only tens of seconds. We also consider a
variation of the Peng-Wei SDP for the case when $K$ is not known a priori and
show that a slight modification of FORCE reduces the computational complexity
of solving this problem as well: from $\tilde{O}(d^7\log\epsilon^{-1})$ using a
standard SDP solver to $\tilde{O}(d^{4}\epsilon^{-1})$.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Eisenach_C/0/1/0/all/0/1&quot;&gt;Carson Eisenach&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Liu_H/0/1/0/all/0/1&quot;&gt;Han Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.03285">
<title>Pricing Engine: Estimating Causal Impacts in Real World Business Settings. (arXiv:1806.03285v2 [econ.EM] UPDATED)</title>
<link>http://arxiv.org/abs/1806.03285</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce the Pricing Engine package to enable the use of Double ML
estimation techniques in general panel data settings. Customization allows the
user to specify first-stage models, first-stage featurization, second stage
treatment selection and second stage causal-modeling. We also introduce a
DynamicDML class that allows the user to generate dynamic treatment-aware
forecasts at a range of leads and to understand how the forecasts will vary as
a function of causally estimated treatment parameters. The Pricing Engine is
built on Python 3.5 and can be run on an Azure ML Workbench environment with
the addition of only a few Python packages. This note provides high-level
discussion of the Double ML method, describes the packages intended use and
includes an example Jupyter notebook demonstrating application to some publicly
available data. Installation of the package and additional technical
documentation is available at
$\href{https://github.com/bquistorff/pricingengine}{github.com/bquistorff/pricingengine}$.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/econ/1/au:+Goldman_M/0/1/0/all/0/1&quot;&gt;Matt Goldman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/econ/1/au:+Quistorff_B/0/1/0/all/0/1&quot;&gt;Brian Quistorff&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04047">
<title>High Dimensional Data Enrichment: Interpretable, Fast, and Data-Efficient. (arXiv:1806.04047v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1806.04047</link>
<description rdf:parseType="Literal">&lt;p&gt;High dimensional structured data enriched model describes groups of
observations by shared and per-group individual parameters, each with its own
structure such as sparsity or group sparsity. In this paper, we consider the
general form of data enrichment where data comes in a fixed but arbitrary
number of groups G. Any convex function, e.g., norms, can characterize the
structure of both shared and individual parameters. We propose an estimator for
high dimensional data enriched model and provide conditions under which it
consistently estimates both shared and individual parameters. We also delineate
sample complexity of the estimator and present high probability non-asymptotic
bound on estimation error of all parameters. Interestingly the sample
complexity of our estimator translates to conditions on both per-group sample
sizes and the total number of samples. We propose an iterative estimation
algorithm with linear convergence rate and supplement our theoretical analysis
with synthetic and real experimental results. Particularly, we show the
predictive power of data-enriched model along with its interpretable results in
anticancer drug sensitivity analysis.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+T%2E_A/0/1/0/all/0/1&quot;&gt;Amir Asiaee T.&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Oymak_S/0/1/0/all/0/1&quot;&gt;Samet Oymak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Coombes_K/0/1/0/all/0/1&quot;&gt;Kevin R. Coombes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Banerjee_A/0/1/0/all/0/1&quot;&gt;Arindam Banerjee&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.04209">
<title>3D Convolutional Neural Networks for Classification of Functional Connectomes. (arXiv:1806.04209v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1806.04209</link>
<description rdf:parseType="Literal">&lt;p&gt;Resting-state functional MRI (rs-fMRI) scans hold the potential to serve as a
diagnostic or prognostic tool for a wide variety of conditions, such as autism,
Alzheimer&apos;s disease, and stroke. While a growing number of studies have
demonstrated the promise of machine learning algorithms for rs-fMRI based
clinical or behavioral prediction, most prior models have been limited in their
capacity to exploit the richness of the data. For example, classification
techniques applied to rs-fMRI often rely on region-based summary statistics
and/or linear models. In this work, we propose a novel volumetric Convolutional
Neural Network (CNN) framework that takes advantage of the full-resolution 3D
spatial structure of rs-fMRI data and fits non-linear predictive models. We
showcase our approach on a challenging large-scale dataset (ABIDE, with N &amp;gt;
2,000) and report state-of-the-art accuracy results on rs-fMRI-based
discrimination of autism patients and healthy controls.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khosla_M/0/1/0/all/0/1&quot;&gt;Meenakshi Khosla&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jamison_K/0/1/0/all/0/1&quot;&gt;Keith Jamison&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kuceyeski_A/0/1/0/all/0/1&quot;&gt;Amy Kuceyeski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sabuncu_M/0/1/0/all/0/1&quot;&gt;Mert Sabuncu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.03467">
<title>Orthogonal Random Forest for Heterogeneous Treatment Effect Estimation. (arXiv:1806.03467v1 [cs.LG] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1806.03467</link>
<description rdf:parseType="Literal">&lt;p&gt;We study the problem of estimating heterogeneous treatment effects from
observational data, where the treatment policy on the collected data was
determined by potentially many confounding observable variables. We propose
orthogonal random forest1, an algorithm that combines orthogonalization, a
technique that effectively removes the confounding effect in two-stage
estimation, with generalized random forests [Athey et al., 2017], a flexible
method for estimating treatment effect heterogeneity. We prove a consistency
rate result of our estimator in the partially linear regression model, and en
route we provide a consistency analysis for a general framework of performing
generalized method of moments (GMM) estimation. We also provide a comprehensive
empirical evaluation of our algorithms, and show that they consistently
outperform baseline approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oprescu_M/0/1/0/all/0/1&quot;&gt;Miruna Oprescu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Syrgkanis_V/0/1/0/all/0/1&quot;&gt;Vasilis Syrgkanis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1&quot;&gt;Zhiwei Steven Wu&lt;/a&gt;</dc:creator>
</item></rdf:RDF>