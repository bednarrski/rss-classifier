<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Boring papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Bad Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-07-04T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.01521"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.01697"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.01937"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.01425"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.01442"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.01603"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.01670"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.05768"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.01267"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.00403"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.01332"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.01334"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.01337"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.01350"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.01356"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.01422"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.01473"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.01488"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.01514"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.01545"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.01604"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.01613"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.01622"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.01623"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.01647"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.01695"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1703.09528"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1706.00476"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1707.09971"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.02858"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.03764"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00556"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1807.01296"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1807.01521">
<title>Curiosity Driven Exploration of Learned Disentangled Goal Spaces. (arXiv:1807.01521v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.01521</link>
<description rdf:parseType="Literal">&lt;p&gt;Intrinsically motivated goal exploration processes enable agents to
autonomously sample goals to explore efficiently complex environments with
high-dimensional continuous actions. They have been applied successfully to
real world robots to discover repertoires of policies producing a wide
diversity of effects. Often these algorithms relied on engineered goal spaces
but it was recently shown that one can use deep representation learning
algorithms to learn an adequate goal space in simple environments. However, in
the case of more complex environments containing multiple objects or
distractors, an efficient exploration requires that the structure of the goal
space reflects the one of the environment. In this paper we show that using a
disentangled goal space leads to better exploration performances than an
entangled goal space. We further show that when the representation is
disentangled, one can leverage it by sampling goals that maximize learning
progress in a modular manner. Finally, we show that the measure of learning
progress, used to drive curiosity-driven exploration, can be used
simultaneously to discover abstract independently controllable features of the
environment.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Laversanne_Finot_A/0/1/0/all/0/1&quot;&gt;Adrien Laversanne-Finot&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pere_A/0/1/0/all/0/1&quot;&gt;Alexandre P&amp;#xe9;r&amp;#xe9;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oudeyer_P/0/1/0/all/0/1&quot;&gt;Pierre-Yves Oudeyer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.01697">
<title>Benchmarking Neural Network Robustness to Common Corruptions and Surface Variations. (arXiv:1807.01697v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.01697</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper we establish rigorous benchmarks for image classifier
robustness. Our first benchmark, ImageNet-C, standardizes and expands the
corruption robustness topic, while showing which classifiers are preferable in
safety-critical applications. Unlike recent robustness research, this benchmark
evaluates performance on commonplace corruptions not worst-case adversarial
corruptions. We find that there are negligible changes in relative corruption
robustness from AlexNet to ResNet classifiers, and we discover ways to enhance
corruption robustness. Then we propose a new dataset called Icons-50 which
opens research on a new kind of robustness, surface variation robustness. With
this dataset we evaluate the frailty of classifiers on new styles of known
objects and unexpected instances of known classes. We also demonstrate two
methods that improve surface variation robustness. Together our benchmarks may
aid future work toward networks that learn fundamental class structure and also
robustly generalize.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hendrycks_D/0/1/0/all/0/1&quot;&gt;Dan Hendrycks&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dietterich_T/0/1/0/all/0/1&quot;&gt;Thomas G. Dietterich&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.01937">
<title>Superconducting Optoelectronic Neurons III: Synaptic Plasticity. (arXiv:1805.01937v4 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1805.01937</link>
<description rdf:parseType="Literal">&lt;p&gt;As a means of dynamically reconfiguring the synaptic weight of a
superconducting optoelectronic loop neuron, a superconducting flux storage loop
is inductively coupled to the synaptic current bias of the neuron. A standard
flux memory cell is used to achieve a binary synapse, and loops capable of
storing many flux quanta are used to enact multi-stable synapses. Circuits are
designed to implement supervised learning wherein current pulses add or remove
flux from the loop to strengthen or weaken the synaptic weight. Designs are
presented for circuits with hundreds of intermediate synaptic weights between
minimum and maximum strengths. Circuits for implementing unsupervised learning
are modeled using two photons to strengthen and two photons to weaken the
synaptic weight via Hebbian and anti-Hebbian learning rules, and techniques are
proposed to control the learning rate. Implementation of short-term plasticity,
homeostatic plasticity, and metaplasticity in loop neurons is discussed.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shainline_J/0/1/0/all/0/1&quot;&gt;Jeffrey M. Shainline&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+McCaughan_A/0/1/0/all/0/1&quot;&gt;Adam N. McCaughan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Buckley_S/0/1/0/all/0/1&quot;&gt;Sonia M. Buckley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Donnelly_C/0/1/0/all/0/1&quot;&gt;Christine A. Donnelly&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Castellanos_Beltran_M/0/1/0/all/0/1&quot;&gt;Manuel Castellanos-Beltran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schneider_M/0/1/0/all/0/1&quot;&gt;Michael L. Schneider&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mirin_R/0/1/0/all/0/1&quot;&gt;Richard P. Mirin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nam_S/0/1/0/all/0/1&quot;&gt;Sae Woo Nam&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.01425">
<title>Region Growing Curriculum Generation for Reinforcement Learning. (arXiv:1807.01425v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1807.01425</link>
<description rdf:parseType="Literal">&lt;p&gt;Learning a policy capable of moving an agent between any two states in the
environment is important for many robotics problems involving navigation and
manipulation. Due to the sparsity of rewards in such tasks, applying
reinforcement learning in these scenarios can be challenging. Common approaches
for tackling this problem include reward engineering with auxiliary rewards,
requiring domain-specific knowledge or changing the objective.
&lt;/p&gt;
&lt;p&gt;In this work, we introduce a method based on region-growing that allows
learning in an environment with any pair of initial and goal states. Our
algorithm first learns how to move between nearby states and then increases the
difficulty of the start-goal transitions as the agent&apos;s performance improves.
This approach creates an efficient curriculum for learning the objective
behavior of reaching any goal from any initial state. In addition, we describe
a method to adaptively adjust expansion of the growing region that allows
automatic adjustment of the key exploration hyperparameter to environments with
different requirements. We evaluate our approach on a set of simulated
navigation and manipulation tasks, where we demonstrate that our algorithm can
efficiently learn a policy in the presence of sparse rewards.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Molchanov_A/0/1/0/all/0/1&quot;&gt;Artem Molchanov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hausman_K/0/1/0/all/0/1&quot;&gt;Karol Hausman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Birchfield_S/0/1/0/all/0/1&quot;&gt;Stan Birchfield&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sukhatme_G/0/1/0/all/0/1&quot;&gt;Gaurav Sukhatme&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.01442">
<title>Modeling Sparse Deviations for Compressed Sensing using Generative Models. (arXiv:1807.01442v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1807.01442</link>
<description rdf:parseType="Literal">&lt;p&gt;In compressed sensing, a small number of linear measurements can be used to
reconstruct an unknown signal. Existing approaches leverage assumptions on the
structure of these signals, such as sparsity or the availability of a
generative model. A domain-specific generative model can provide a stronger
prior and thus allow for recovery with far fewer measurements. However, unlike
sparsity-based approaches, existing methods based on generative models
guarantee exact recovery only over their support, which is typically only a
small subset of the space on which the signals are defined. We propose
Sparse-Gen, a framework that allows for sparse deviations from the support set,
thereby achieving the best of both worlds by using a domain specific prior and
allowing reconstruction over the full space of signals. Theoretically, our
framework provides a new class of signals that can be acquired using compressed
sensing, reducing classic sparse vector recovery to a special case and avoiding
the restrictive support due to a generative model prior. Empirically, we
observe consistent improvements in reconstruction accuracy over competing
approaches, especially in the more practical setting of transfer compressed
sensing where a generative model for a data-rich, source domain aids sensing on
a data-scarce, target domain.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Dhar_M/0/1/0/all/0/1&quot;&gt;Manik Dhar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Grover_A/0/1/0/all/0/1&quot;&gt;Aditya Grover&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ermon_S/0/1/0/all/0/1&quot;&gt;Stefano Ermon&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.01603">
<title>BIN-CT: Urban Waste Collection based in Predicting the Container Fill Level. (arXiv:1807.01603v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1807.01603</link>
<description rdf:parseType="Literal">&lt;p&gt;The fast demographic growth, together with the concentration of the
population in cities and the increasing amount of daily waste, are factors that
push to the limit the ability of waste assimilation by Nature. Therefore, we
need technological means to make an optimal management of the waste collection
process, which represents 70% of the operational cost in waste treatment. In
this article, we present a free intelligent software system, based on
computational learning algorithms, which plans the best routes for waste
collection supported by past (historical) and future (predictions) data.
&lt;/p&gt;
&lt;p&gt;The objective of the system is the cost reduction of the waste collection
service by means of the minimization in distance traveled by any truck to
collect a container, hence the fuel consumption. At the same time the quality
of service to the citizen is increased avoiding the annoying overflows of
containers thanks to the accurate fill level predictions performed by BIN-CT.
In this article we show the features of our software system, illustrating it
operation with a real case study of a Spanish city. We conclude that the use of
BIN-CT avoids unnecessary visits to containers, reduces the distance traveled
to collect a container and therefore we obtain a reduction of total costs and
harmful emissions thrown to the atmosphere.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ferrer_J/0/1/0/all/0/1&quot;&gt;Javier Ferrer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alba_E/0/1/0/all/0/1&quot;&gt;Enrique Alba&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.01670">
<title>Encoding Spatial Relations from Natural Language. (arXiv:1807.01670v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1807.01670</link>
<description rdf:parseType="Literal">&lt;p&gt;Natural language processing has made significant inroads into learning the
semantics of words through distributional approaches, however representations
learnt via these methods fail to capture certain kinds of information implicit
in the real world. In particular, spatial relations are encoded in a way that
is inconsistent with human spatial reasoning and lacking invariance to
viewpoint changes. We present a system capable of capturing the semantics of
spatial relations such as behind, left of, etc from natural language. Our key
contributions are a novel multi-modal objective based on generating images of
scenes from their textual descriptions, and a new dataset on which to train it.
We demonstrate that internal representations are robust to meaning preserving
transformations of descriptions (paraphrase invariance), while viewpoint
invariance is an emergent property of the system.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ramalho_T/0/1/0/all/0/1&quot;&gt;Tiago Ramalho&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kocisky_T/0/1/0/all/0/1&quot;&gt;Tom&amp;#xe1;&amp;#x161; Kocisk&amp;#xfd;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Besse_F/0/1/0/all/0/1&quot;&gt;Frederic Besse&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Eslami_S/0/1/0/all/0/1&quot;&gt;S. M. Ali Eslami&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Melis_G/0/1/0/all/0/1&quot;&gt;G&amp;#xe1;bor Melis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Viola_F/0/1/0/all/0/1&quot;&gt;Fabio Viola&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Blunsom_P/0/1/0/all/0/1&quot;&gt;Phil Blunsom&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hermann_K/0/1/0/all/0/1&quot;&gt;Karl Moritz Hermann&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.05768">
<title>PAC-Reasoning in Relational Domains. (arXiv:1803.05768v3 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1803.05768</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the problem of predicting plausible missing facts in relational
data, given a set of imperfect logical rules. In particular, our aim is to
provide bounds on the (expected) number of incorrect inferences that are made
in this way. Since for classical inference it is in general impossible to bound
this number in a non-trivial way, we consider two inference relations that
weaken, but remain close in spirit to classical inference.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kuzelka_O/0/1/0/all/0/1&quot;&gt;Ondrej Kuzelka&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yuyi Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Davis_J/0/1/0/all/0/1&quot;&gt;Jesse Davis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schockaert_S/0/1/0/all/0/1&quot;&gt;Steven Schockaert&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.01267">
<title>Internal Model from Observations for Reward Shaping. (arXiv:1806.01267v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1806.01267</link>
<description rdf:parseType="Literal">&lt;p&gt;Reinforcement learning methods require careful design involving a reward
function to obtain the desired action policy for a given task. In the absence
of hand-crafted reward functions, prior work on the topic has proposed several
methods for reward estimation by using expert state trajectories and action
pairs. However, there are cases where complete or good action information
cannot be obtained from expert demonstrations. We propose a novel reinforcement
learning method in which the agent learns an internal model of observation on
the basis of expert-demonstrated state trajectories to estimate rewards without
completely learning the dynamics of the external environment from state-action
pairs. The internal model is obtained in the form of a predictive model for the
given expert state distribution. During reinforcement learning, the agent
predicts the reward as a function of the difference between the actual state
and the state predicted by the internal model. We conducted multiple
experiments in environments of varying complexity, including the Super Mario
Bros and Flappy Bird games. We show our method successfully trains good
policies directly from expert game-play videos.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kimura_D/0/1/0/all/0/1&quot;&gt;Daiki Kimura&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chaudhury_S/0/1/0/all/0/1&quot;&gt;Subhajit Chaudhury&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tachibana_R/0/1/0/all/0/1&quot;&gt;Ryuki Tachibana&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dasgupta_S/0/1/0/all/0/1&quot;&gt;Sakyasingha Dasgupta&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.00403">
<title>Towards Mixed Optimization for Reinforcement Learning with Program Synthesis. (arXiv:1807.00403v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1807.00403</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep reinforcement learning has led to several recent breakthroughs, though
the learned policies are often based on black-box neural networks. This makes
them difficult to interpret and to impose desired specification constraints
during learning. We present an iterative framework, MORL, for improving the
learned policies using program synthesis. Concretely, we propose to use
synthesis techniques to obtain a symbolic representation of the learned policy,
which can then be debugged manually or automatically using program repair.
After the repair step, we use behavior cloning to obtain the policy
corresponding to the repaired program, which is then further improved using
gradient descent. This process continues until the learned policy satisfies
desired constraints. We instantiate MORL for the simple CartPole problem and
show that the programmatic representation allows for high-level modifications
that in turn lead to improved learning of the policies.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bhupatiraju_S/0/1/0/all/0/1&quot;&gt;Surya Bhupatiraju&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Agrawal_K/0/1/0/all/0/1&quot;&gt;Kumar Krishna Agrawal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singh_R/0/1/0/all/0/1&quot;&gt;Rishabh Singh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.01332">
<title>Multi-Level Feature Abstraction from Convolutional Neural Networks for Multimodal Biometric Identification. (arXiv:1807.01332v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.01332</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we propose a deep multimodal fusion network to fuse multiple
modalities (face, iris, and fingerprint) for person identification. The
proposed deep multimodal fusion algorithm consists of multiple streams of
modality-specific Convolutional Neural Networks (CNNs), which are jointly
optimized at multiple feature abstraction levels. Multiple features are
extracted at several different convolutional layers from each modality-specific
CNN for joint feature fusion, optimization, and classification. Features
extracted at different convolutional layers of a modality-specific CNN
represent the input at several different levels of abstract representations. We
demonstrate that an efficient multimodal classification can be accomplished
with a significant reduction in the number of network parameters by exploiting
these multi-level abstract representations extracted from all the
modality-specific CNNs. We demonstrate an increase in multimodal person
identification performance by utilizing the proposed multi-level feature
abstract representations in our multimodal fusion, rather than using only the
features from the last layer of each modality-specific CNNs. We show that our
deep multi-modal CNNs with multimodal fusion at several different feature level
abstraction can significantly outperform the unimodal representation accuracy.
We also demonstrate that the joint optimization of all the modality-specific
CNNs excels the score and decision level fusions of independently optimized
CNNs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Soleymani_S/0/1/0/all/0/1&quot;&gt;Sobhan Soleymani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dabouei_A/0/1/0/all/0/1&quot;&gt;Ali Dabouei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kazemi_H/0/1/0/all/0/1&quot;&gt;Hadi Kazemi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dawson_J/0/1/0/all/0/1&quot;&gt;Jeremy Dawson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nasrabadi_N/0/1/0/all/0/1&quot;&gt;Nasser M. Nasrabadi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.01334">
<title>Breast Cancer Diagnosis via Classification Algorithms. (arXiv:1807.01334v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1807.01334</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we analyze the Wisconsin Diagnostic Breast Cancer Data using
Machine Learning classification techniques, such as the SVM, Bayesian Logistic
Regression (Variational Approximation), and K-Nearest-Neighbors. We describe
each model, and compare their performance through different measures. We
conclude that SVM has the best performance among all other classifiers, while
it competes closely with the Bayesian Logistic Regression that is ranked second
best method for this dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Entezari_R/0/1/0/all/0/1&quot;&gt;Reihaneh Entezari&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.01337">
<title>COTA: Improving the Speed and Accuracy of Customer Support through Ranking and Deep Networks. (arXiv:1807.01337v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.01337</link>
<description rdf:parseType="Literal">&lt;p&gt;For a company looking to provide delightful user experiences, it is of
paramount importance to take care of any customer issues. This paper proposes
COTA, a system to improve speed and reliability of customer support for end
users through automated ticket classification and answers selection for support
representatives. Two machine learning and natural language processing
techniques are demonstrated: one relying on feature engineering (COTA v1) and
the other exploiting raw signals through deep learning architectures (COTA v2).
COTA v1 employs a new approach that converts the multi-classification task into
a ranking problem, demonstrating significantly better performance in the case
of thousands of classes. For COTA v2, we propose an Encoder-Combiner-Decoder, a
novel deep learning architecture that allows for heterogeneous input and output
feature types and injection of prior knowledge through network architecture
choices. This paper compares these models and their variants on the task of
ticket classification and answer selection, showing model COTA v2 outperforms
COTA v1, and analyzes their inner workings and shortcomings. Finally, an A/B
test is conducted in a production setting validating the real-world impact of
COTA in reducing issue resolution time by 10 percent without reducing customer
satisfaction.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Molino_P/0/1/0/all/0/1&quot;&gt;Piero Molino&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zheng_H/0/1/0/all/0/1&quot;&gt;Huaixiu Zheng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yi-Chia Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.01350">
<title>OCTen: Online Compression-based Tensor Decomposition. (arXiv:1807.01350v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.01350</link>
<description rdf:parseType="Literal">&lt;p&gt;Tensor decompositions are powerful tools for large data analytics as they
jointly model multiple aspects of data into one framework and enable the
discovery of the latent structures and higher-order correlations within the
data. One of the most widely studied and used decompositions, especially in
data mining and machine learning, is the Canonical Polyadic or CP
decomposition. However, today&apos;s datasets are not static and these datasets
often dynamically growing and changing with time. To operate on such large
data, we present OCTen the first ever compression-based online parallel
implementation for the CP decomposition. We conduct an extensive empirical
analysis of the algorithms in terms of fitness, memory used and CPU time, and
in order to demonstrate the compression and scalability of the method, we apply
OCTen to big tensor data. Indicatively, OCTen performs on-par or better than
state-of-the-art online and online methods in terms of decomposition accuracy
and efficiency, while saving up to 40-200 % memory space.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gujral_E/0/1/0/all/0/1&quot;&gt;Ekta Gujral&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pasricha_R/0/1/0/all/0/1&quot;&gt;Ravdeep Pasricha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_T/0/1/0/all/0/1&quot;&gt;Tianxiong Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Papalexakis_E/0/1/0/all/0/1&quot;&gt;Evangelos E. Papalexakis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.01356">
<title>Efficient ConvNets for Analog Arrays. (arXiv:1807.01356v1 [cs.ET])</title>
<link>http://arxiv.org/abs/1807.01356</link>
<description rdf:parseType="Literal">&lt;p&gt;Analog arrays are a promising upcoming hardware technology with the potential
to drastically speed up deep learning. Their main advantage is that they
compute matrix-vector products in constant time, irrespective of the size of
the matrix. However, early convolution layers in ConvNets map very unfavorably
onto analog arrays, because kernel matrices are typically small and the
constant time operation needs to be sequentially iterated a large number of
times, reducing the speed up advantage for ConvNets. Here, we propose to
replicate the kernel matrix of a convolution layer on distinct analog arrays,
and randomly divide parts of the compute among them, so that multiple kernel
matrices are trained in parallel. With this modification, analog arrays execute
ConvNets with an acceleration factor that is proportional to the number of
kernel matrices used per layer (here tested 16-128). Despite having more free
parameters, we show analytically and in numerical experiments that this
convolution architecture is self-regularizing and implicitly learns similar
filters across arrays. We also report superior performance on a number of
datasets and increased robustness to adversarial attacks. Our investigation
suggests to revise the notion that mixed analog-digital hardware is not
suitable for ConvNets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rasch_M/0/1/0/all/0/1&quot;&gt;Malte J. Rasch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gokmen_T/0/1/0/all/0/1&quot;&gt;Tayfun Gokmen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rigotti_M/0/1/0/all/0/1&quot;&gt;Mattia Rigotti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Haensch_W/0/1/0/all/0/1&quot;&gt;Wilfried Haensch&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.01422">
<title>Diagonal Discriminant Analysis with Feature Selection for High Dimensional Data. (arXiv:1807.01422v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1807.01422</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce a new method of performing high dimensional discriminant
analysis, which we call multiDA. We achieve this by constructing a hybrid model
that seamlessly integrates a multiclass diagonal discriminant analysis model
and feature selection components. Our feature selection component naturally
simplifies to weights which are simple functions of likelihood ratio statistics
allowing natural comparisons with traditional hypothesis testing methods. We
provide heuristic arguments suggesting desirable asymptotic properties of our
algorithm with regards to feature selection. We compare our method with several
other approaches, showing marked improvements in regard to prediction accuracy,
interpretability of chosen features, and algorithm run time. We demonstrate
such strengths of our model by showing strong classification performance on
publicly available high dimensional datasets, as well as through multiple
simulation studies. We make an R package available implementing our approach.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Romanes_S/0/1/0/all/0/1&quot;&gt;Sarah Elizabeth Romanes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ormerod_J/0/1/0/all/0/1&quot;&gt;John Thomas Ormerod&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yang_J/0/1/0/all/0/1&quot;&gt;Jean YH Yang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.01473">
<title>Supervised Reinforcement Learning with Recurrent Neural Network for Dynamic Treatment Recommendation. (arXiv:1807.01473v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.01473</link>
<description rdf:parseType="Literal">&lt;p&gt;Dynamic treatment recommendation systems based on large-scale electronic
health records (EHRs) become a key to successfully improve practical clinical
outcomes. Prior relevant studies recommend treatments either use supervised
learning (e.g. matching the indicator signal which denotes doctor
prescriptions), or reinforcement learning (e.g. maximizing evaluation signal
which indicates cumulative reward from survival rates). However, none of these
studies have considered to combine the benefits of supervised learning and
reinforcement learning. In this paper, we propose Supervised Reinforcement
Learning with Recurrent Neural Network (SRL-RNN), which fuses them into a
synergistic learning framework. Specifically, SRL-RNN applies an off-policy
actor-critic framework to handle complex relations among multiple medications,
diseases and individual characteristics. The &quot;actor&quot; in the framework is
adjusted by both the indicator signal and evaluation signal to ensure effective
prescription and low mortality. RNN is further utilized to solve the
Partially-Observed Markov Decision Process (POMDP) problem due to the lack of
fully observed states in real world applications. Experiments on the publicly
real-world dataset, i.e., MIMIC-3, illustrate that our model can reduce the
estimated mortality, while providing promising accuracy in matching doctors&apos;
prescriptions.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1&quot;&gt;Lu Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1&quot;&gt;Wei Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1&quot;&gt;Xiaofeng He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zha_H/0/1/0/all/0/1&quot;&gt;Hongyuan Zha&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.01488">
<title>Factored Bandits. (arXiv:1807.01488v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.01488</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce the factored bandits model, which is a framework for learning
with limited (bandit) feedback, where actions can be decomposed into a
Cartesian product of atomic actions. Factored bandits incorporate rank-1
bandits as a special case, but significantly relax the assumptions on the form
of the reward function. We provide an anytime algorithm for stochastic factored
bandits and up to constants matching upper and lower regret bounds for the
problem. Furthermore, we show that with a slight modification the proposed
algorithm can be applied to utility based dueling bandits. We obtain an
improvement in the additive terms of the regret bound compared to state of the
art algorithms (the additive terms are dominating up to time horizons which are
exponential in the number of arms).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zimmert_J/0/1/0/all/0/1&quot;&gt;Julian Zimmert&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Seldin_Y/0/1/0/all/0/1&quot;&gt;Yevgeny Seldin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.01514">
<title>Generating Synthetic but Plausible Healthcare Record Datasets. (arXiv:1807.01514v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1807.01514</link>
<description rdf:parseType="Literal">&lt;p&gt;Generating datasets that &quot;look like&quot; given real ones is an interesting tasks
for healthcare applications of ML and many other fields of science and
engineering. In this paper we propose a new method of general application to
binary datasets based on a method for learning the parameters of a latent
variable moment that we have previously used for clustering patient datasets.
We compare our method with a recent proposal (MedGan) based on generative
adversarial methods and find that the synthetic datasets we generate are
globally more realistic in at least two senses: real and synthetic instances
are harder to tell apart by Random Forests, and the MMD statistic. The most
likely explanation is that our method does not suffer from the &quot;mode collapse&quot;
which is an admitted problem of GANs. Additionally, the generative models we
generate are easy to interpret, unlike the rather obscure GANs. Our experiments
are performed on two patient datasets containing ICD-9 diagnostic codes: the
publicly available MIMIC-III dataset and a dataset containing admissions for
congestive heart failure during 7 years at Hospital de Sant Pau in Barcelona.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Avino_L/0/1/0/all/0/1&quot;&gt;Laura Avi&amp;#xf1;&amp;#xf3;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ruffini_M/0/1/0/all/0/1&quot;&gt;Matteo Ruffini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gavalda_R/0/1/0/all/0/1&quot;&gt;Ricard Gavald&amp;#xe0;&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.01545">
<title>Wideband Time-Domain Digital Backpropagation via Subband Processing and Deep Learning. (arXiv:1807.01545v1 [cs.IT])</title>
<link>http://arxiv.org/abs/1807.01545</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a low-complexity sub-banded DSP architecture for digital
backpropagation where the walk-off effect is compensated using simple delay
elements. For a simulated 96-Gbaud signal and 2500 km optical link, our method
achieves a 2.8 dB SNR improvement over linear equalization.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hager_C/0/1/0/all/0/1&quot;&gt;Christian H&amp;#xe4;ger&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pfister_H/0/1/0/all/0/1&quot;&gt;Henry D. Pfister&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.01604">
<title>Quasi-Monte Carlo Variational Inference. (arXiv:1807.01604v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1807.01604</link>
<description rdf:parseType="Literal">&lt;p&gt;Many machine learning problems involve Monte Carlo gradient estimators. As a
prominent example, we focus on Monte Carlo variational inference (MCVI) in this
paper. The performance of MCVI crucially depends on the variance of its
stochastic gradients. We propose variance reduction by means of Quasi-Monte
Carlo (QMC) sampling. QMC replaces N i.i.d. samples from a uniform probability
distribution by a deterministic sequence of samples of length N. This sequence
covers the underlying random variable space more evenly than i.i.d. draws,
reducing the variance of the gradient estimator. With our novel approach, both
the score function and the reparameterization gradient estimators lead to much
faster convergence. We also propose a new algorithm for Monte Carlo objectives,
where we operate with a constant learning rate and increase the number of QMC
samples per iteration. We prove that this way, our algorithm can converge
asymptotically at a faster rate than SGD. We furthermore provide theoretical
guarantees on QMC for Monte Carlo objectives that go beyond MCVI, and support
our findings by several experiments on large-scale data sets from various
domains.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Buchholz_A/0/1/0/all/0/1&quot;&gt;Alexander Buchholz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wenzel_F/0/1/0/all/0/1&quot;&gt;Florian Wenzel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mandt_S/0/1/0/all/0/1&quot;&gt;Stephan Mandt&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.01613">
<title>Conditional Neural Processes. (arXiv:1807.01613v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.01613</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep neural networks excel at function approximation, yet they are typically
trained from scratch for each new function. On the other hand, Bayesian
methods, such as Gaussian Processes (GPs), exploit prior knowledge to quickly
infer the shape of a new function at test time. Yet GPs are computationally
expensive, and it can be hard to design appropriate priors. In this paper we
propose a family of neural models, Conditional Neural Processes (CNPs), that
combine the benefits of both. CNPs are inspired by the flexibility of
stochastic processes such as GPs, but are structured as neural networks and
trained via gradient descent. CNPs make accurate predictions after observing
only a handful of training data points, yet scale to complex functions and
large datasets. We demonstrate the performance and versatility of the approach
on a range of canonical machine learning tasks, including regression,
classification and image completion.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garnelo_M/0/1/0/all/0/1&quot;&gt;Marta Garnelo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rosenbaum_D/0/1/0/all/0/1&quot;&gt;Dan Rosenbaum&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Maddison_C/0/1/0/all/0/1&quot;&gt;Chris J. Maddison&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ramalho_T/0/1/0/all/0/1&quot;&gt;Tiago Ramalho&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saxton_D/0/1/0/all/0/1&quot;&gt;David Saxton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shanahan_M/0/1/0/all/0/1&quot;&gt;Murray Shanahan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Teh_Y/0/1/0/all/0/1&quot;&gt;Yee Whye Teh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rezende_D/0/1/0/all/0/1&quot;&gt;Danilo J. Rezende&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Eslami_S/0/1/0/all/0/1&quot;&gt;S. M. Ali Eslami&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.01622">
<title>Neural Processes. (arXiv:1807.01622v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.01622</link>
<description rdf:parseType="Literal">&lt;p&gt;A neural network (NN) is a parameterised function that can be tuned via
gradient descent to approximate a labelled collection of data with high
precision. A Gaussian process (GP), on the other hand, is a probabilistic model
that defines a distribution over possible functions, and is updated in light of
data via the rules of probabilistic inference. GPs are probabilistic,
data-efficient and flexible, however they are also computationally intensive
and thus limited in their applicability. We introduce a class of neural latent
variable models which we call Neural Processes (NPs), combining the best of
both worlds. Like GPs, NPs define distributions over functions, are capable of
rapid adaptation to new observations, and can estimate the uncertainty in their
predictions. Like NNs, NPs are computationally efficient during training and
evaluation but also learn to adapt their priors to data. We demonstrate the
performance of NPs on a range of learning tasks, including regression and
optimisation, and compare and contrast with related models in the literature.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Garnelo_M/0/1/0/all/0/1&quot;&gt;Marta Garnelo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schwarz_J/0/1/0/all/0/1&quot;&gt;Jonathan Schwarz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rosenbaum_D/0/1/0/all/0/1&quot;&gt;Dan Rosenbaum&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Viola_F/0/1/0/all/0/1&quot;&gt;Fabio Viola&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rezende_D/0/1/0/all/0/1&quot;&gt;Danilo J. Rezende&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Eslami_S/0/1/0/all/0/1&quot;&gt;S.M. Ali Eslami&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Teh_Y/0/1/0/all/0/1&quot;&gt;Yee Whye Teh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.01623">
<title>Modeling outcomes of soccer matches. (arXiv:1807.01623v1 [stat.AP])</title>
<link>http://arxiv.org/abs/1807.01623</link>
<description rdf:parseType="Literal">&lt;p&gt;We compare various extensions of the Bradley-Terry model and a hierarchical
Poisson log-linear model in terms of their performance in predicting the
outcome of soccer matches (win, draw, or loss). The parameters of the
Bradley-Terry extensions are estimated by maximizing the log-likelihood, or an
appropriately penalized version of it, while the posterior densities of the
parameters of the hierarchical Poisson log-linear model are approximated using
integrated nested Laplace approximations. The prediction performance of the
various modeling approaches is assessed using a novel, context-specific
framework for temporal validation that is found to deliver accurate estimates
of the test error. The direct modeling of outcomes via the various
Bradley-Terry extensions and the modeling of match scores using the
hierarchical Poisson log-linear model demonstrate similar behavior in terms of
predictive performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tsokos_A/0/1/0/all/0/1&quot;&gt;Alkeos Tsokos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Narayanan_S/0/1/0/all/0/1&quot;&gt;Santhosh Narayanan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kosmidis_I/0/1/0/all/0/1&quot;&gt;Ioannis Kosmidis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Baio_G/0/1/0/all/0/1&quot;&gt;Gianluca Baio&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Cucuringu_M/0/1/0/all/0/1&quot;&gt;Mihai Cucuringu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Whitaker_G/0/1/0/all/0/1&quot;&gt;Gavin Whitaker&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kiraly_F/0/1/0/all/0/1&quot;&gt;Franz J. Kir&amp;#xe1;ly&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.01647">
<title>Privacy Amplification by Subsampling: Tight Analyses via Couplings and Divergences. (arXiv:1807.01647v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1807.01647</link>
<description rdf:parseType="Literal">&lt;p&gt;Differential privacy comes equipped with multiple analytical tools for the
design of private data analyses. One important tool is the so called &quot;privacy
amplification by subsampling&quot; principle, which ensures that a differentially
private mechanism run on a random subsample of a population provides higher
privacy guarantees than when run on the entire population. Several instances of
this principle have been studied for different random subsampling methods, each
with an ad-hoc analysis. In this paper we present a general method that
recovers and improves prior analyses, yields lower bounds and derives new
instances of privacy amplification by subsampling. Our method leverages a
characterization of differential privacy as a divergence which emerged in the
program verification community. Furthermore, it introduces new tools, including
advanced joint convexity and privacy profiles, which might be of independent
interest.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Balle_B/0/1/0/all/0/1&quot;&gt;Borja Balle&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barthe_G/0/1/0/all/0/1&quot;&gt;Gilles Barthe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gaboardi_M/0/1/0/all/0/1&quot;&gt;Marco Gaboardi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.01695">
<title>SPIDER: Near-Optimal Non-Convex Optimization via Stochastic Path Integrated Differential Estimator. (arXiv:1807.01695v1 [math.OC])</title>
<link>http://arxiv.org/abs/1807.01695</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we propose a new technique named Stochastic Path-Integrated
Differential EstimatoR (SPIDER), which can be used to track many deterministic
quantities of interest with significantly reduced computational cost. Combining
SPIDER with the method of normalized gradient descent, we propose two new
algorithms, namely SPIDER-SFO and SPIDER-SSO, that solve non-convex stochastic
optimization problems using stochastic gradients only. We provide sharp
error-bound results on their convergence rates. Specially, we prove that the
SPIDER-SFO and SPIDER-SSO algorithms achieve a record-breaking
$\tilde{O}(\epsilon^{-3})$ gradient computation cost to find an
$\epsilon$-approximate first-order and $(\epsilon,
O(\epsilon^{0.5}))$-approximate second-order stationary point, respectively. In
addition, we prove that SPIDER-SFO nearly matches the algorithmic lower bound
for finding stationary point under the gradient Lipschitz assumption in the
finite-sum setting.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Fang_C/0/1/0/all/0/1&quot;&gt;Cong Fang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Li_C/0/1/0/all/0/1&quot;&gt;Chris Junchi Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Lin_Z/0/1/0/all/0/1&quot;&gt;Zhouchen Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Zhang_T/0/1/0/all/0/1&quot;&gt;Tong Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1703.09528">
<title>Discovering Relational Covariance Structures for Explaining Multiple Time Series. (arXiv:1703.09528v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1703.09528</link>
<description rdf:parseType="Literal">&lt;p&gt;Analyzing time series data is important to predict future events and changes
in finance, manufacturing, and administrative decisions. In time series
analysis, Gaussian Process (GP) regression methods recently demonstrate
competitive performance by decomposing temporal covariance structures. The
covariance structure decomposition allows exploiting shared parameters over a
set of multiple, selected time series. In this paper, we present two novel GP
models which naturally handle multiple time series by placing an Indian Buffet
Process (IBP) prior on the presence of shared kernels. We also investigate the
well-definedness of the models when infinite latent components are introduced.
We present a pragmatic search algorithm which explores a larger structure space
efficiently than the existing search algorithm. Experiments are conducted on
both synthetic data sets and real-world data sets, showing improved results in
term of structure discoveries and predictive performances. We further provide a
promising application generating comparison reports from our model results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tong_A/0/1/0/all/0/1&quot;&gt;Anh Tong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Choi_J/0/1/0/all/0/1&quot;&gt;Jaesik Choi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1706.00476">
<title>The Mixing method: low-rank coordinate descent for semidefinite programming with diagonal constraints. (arXiv:1706.00476v3 [math.OC] UPDATED)</title>
<link>http://arxiv.org/abs/1706.00476</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we propose a low-rank coordinate descent approach to
structured semidefinite programming with diagonal constraints. The approach,
which we call the Mixing method, is extremely simple to implement, has no free
parameters, and typically attains an order of magnitude or better improvement
in optimization performance over the current state of the art. We show that the
method is strictly decreasing, converges to a critical point, and further that
for sufficient rank all non-optimal critical points are unstable. Moreover, we
prove that with a step size, the Mixing method converges to the global optimum
of the semidefinite program almost surely in a locally linear rate under random
initialization. This is the first low-rank semidefinite programming method that
has been shown to achieve a global optimum on the spherical manifold without
assumption. We apply our algorithm to two related domains: solving the maximum
cut semidefinite relaxation, and solving a maximum satisfiability relaxation
(we also briefly consider additional applications such as learning word
embeddings). In all settings, we demonstrate substantial improvement over the
existing state of the art along various dimensions, and in total, this work
expands the scope and scale of problems that can be solved using semidefinite
programming methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Wang_P/0/1/0/all/0/1&quot;&gt;Po-Wei Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Chang_W/0/1/0/all/0/1&quot;&gt;Wei-Cheng Chang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Kolter_J/0/1/0/all/0/1&quot;&gt;J. Zico Kolter&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1707.09971">
<title>Spectral Method and Regularized MLE Are Both Optimal for Top-$K$ Ranking. (arXiv:1707.09971v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1707.09971</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper is concerned with the problem of top-$K$ ranking from pairwise
comparisons. Given a collection of $n$ items and a few pairwise comparisons
across them, one wishes to identify the set of $K$ items that receive the
highest ranks. To tackle this problem, we adopt the logistic parametric model
--- the Bradley-Terry-Luce model, where each item is assigned a latent
preference score, and where the outcome of each pairwise comparison depends
solely on the relative scores of the two items involved. Recent works have made
significant progress towards characterizing the performance (e.g. the mean
square error for estimating the scores) of several classical methods, including
the spectral method and the maximum likelihood estimator (MLE). However, where
they stand regarding top-$K$ ranking remains unsettled.
&lt;/p&gt;
&lt;p&gt;We demonstrate that under a natural random sampling model, the spectral
method alone, or the regularized MLE alone, is minimax optimal in terms of the
sample complexity --- the number of paired comparisons needed to ensure exact
top-$K$ identification, for the fixed dynamic range regime. This is
accomplished via optimal control of the entrywise error of the score estimates.
We complement our theoretical studies by numerical experiments, confirming that
both methods yield low entrywise errors for estimating the underlying scores.
Our theory is established via a novel leave-one-out trick, which proves
effective for analyzing both iterative and non-iterative procedures. Along the
way, we derive an elementary eigenvector perturbation bound for probability
transition matrices, which parallels the Davis-Kahan $\sin\Theta$ theorem for
symmetric matrices. This also allows us to close the gap between the $\ell_2$
error upper bound for the spectral method and the minimax lower limit.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yuxin Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Fan_J/0/1/0/all/0/1&quot;&gt;Jianqing Fan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ma_C/0/1/0/all/0/1&quot;&gt;Cong Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wang_K/0/1/0/all/0/1&quot;&gt;Kaizheng Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.02858">
<title>Scalable high-resolution forecasting of sparse spatiotemporal events with kernel methods: a winning solution to the NIJ &quot;Real-Time Crime Forecasting Challenge&quot;. (arXiv:1801.02858v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1801.02858</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a generic spatiotemporal event forecasting method, which we
developed for the National Institute of Justice&apos;s (NIJ) Real-Time Crime
Forecasting Challenge. Our solution to the challenge is a spatiotemporal
forecasting model combining scalable randomized Reproducing Kernel Hilbert
Space (RKHS) methods for approximating Gaussian processes with autoregressive
smoothing kernels in a regularized supervised learning framework. While the
smoothing kernels capture the two main approaches in current use in the field
of crime forecasting, heatmap-based (kernel density estimation) and
self-exciting point process (SEPP) models, the RKHS component of the model can
be understood as an approximation to the popular log-Gaussian Cox Process
model. For inference, we discretize the spatiotemporal point pattern and learn
a log intensity function using the Poisson likelihood and highly efficient
gradient-based optimization methods. Model hyperparameters including quality of
RKHS approximation, spatial and temporal kernel lengthscales, number of
autoregressive lags, bandwidths for smoothing kernels, as well as cell shape,
size, and rotation, were learned using temporal crossvalidation. Resulting
predictions significantly exceeded baseline KDE estimates; we had winning
submissions to the competition in each of the different crime types and across
different timescales, suggesting that our method is generically applicable.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Flaxman_S/0/1/0/all/0/1&quot;&gt;Seth Flaxman&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chirico_M/0/1/0/all/0/1&quot;&gt;Michael Chirico&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pereira_P/0/1/0/all/0/1&quot;&gt;Pau Pereira&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Loeffler_C/0/1/0/all/0/1&quot;&gt;Charles Loeffler&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.03764">
<title>Variance Networks: When Expectation Does Not Meet Your Expectations. (arXiv:1803.03764v4 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1803.03764</link>
<description rdf:parseType="Literal">&lt;p&gt;Ordinary stochastic neural networks mostly rely on the expected values of
their weights to make predictions, whereas the induced noise is mostly used to
capture the uncertainty, prevent overfitting and slightly boost the performance
through test-time averaging. In this paper, we introduce variance layers, a
different kind of stochastic layers. Each weight of a variance layer follows a
zero-mean distribution and is only parameterized by its variance. We show that
such layers can learn surprisingly well, can serve as an efficient exploration
tool in reinforcement learning tasks and provide a decent defense against
adversarial attacks. We also show that a number of conventional Bayesian neural
networks naturally converge to such zero-mean posteriors. We observe that in
these cases such zero-mean parameterization leads to a much better training
objective than conventional parameterizations where the mean is being learned.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Neklyudov_K/0/1/0/all/0/1&quot;&gt;Kirill Neklyudov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Molchanov_D/0/1/0/all/0/1&quot;&gt;Dmitry Molchanov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ashukha_A/0/1/0/all/0/1&quot;&gt;Arsenii Ashukha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Vetrov_D/0/1/0/all/0/1&quot;&gt;Dmitry Vetrov&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00556">
<title>Intrinsic Isometric Manifold Learning with Application to Localization. (arXiv:1806.00556v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1806.00556</link>
<description rdf:parseType="Literal">&lt;p&gt;Data living on manifolds commonly appear in many applications. Often this
results from an inherently latent low-dimensional system being observed through
higher dimensional measurements. We show that under certain conditions, it is
possible to construct an intrinsic and isometric data representation, which
respects an underlying latent intrinsic geometry. Namely, we view the observed
data only as a proxy and learn the structure of a latent unobserved intrinsic
manifold, whereas common practice is to learn the manifold of the observed
data. For this purpose, we build a new metric and propose a method for its
robust estimation by assuming mild statistical priors and by using artificial
neural networks as a mechanism for metric regularization and parametrization.
We show successful application to unsupervised indoor localization in ad-hoc
sensor networks. Specifically, we show that our proposed method facilitates
accurate localization of a moving agent from imaging data it collects.
Importantly, our method is applied in the same way to two different imaging
modalities, thereby demonstrating its intrinsic and modality-invariant
capabilities.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Schwartz_A/0/1/0/all/0/1&quot;&gt;Ariel Schwartz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Talmon_R/0/1/0/all/0/1&quot;&gt;Ronen Talmon&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1807.01296">
<title>Approximate Survey Propagation for Statistical Inference. (arXiv:1807.01296v1 [cond-mat.dis-nn] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1807.01296</link>
<description rdf:parseType="Literal">&lt;p&gt;Approximate message passing algorithm enjoyed considerable attention in the
last decade. In this paper we introduce a variant of the AMP algorithm that
takes into account glassy nature of the system under consideration. We coin
this algorithm as the approximate survey propagation (ASP) and derive it for a
class of low-rank matrix estimation problems. We derive the state evolution for
the ASP algorithm and prove that it reproduces the one-step replica symmetry
breaking (1RSB) fixed-point equations, well-known in physics of disordered
systems. Our derivation thus gives a concrete algorithmic meaning to the 1RSB
equations that is of independent interest. We characterize the performance of
ASP in terms of convergence and mean-squared error as a function of the free
Parisi parameter s. We conclude that when there is a model mismatch between the
true generative model and the inference model, the performance of AMP rapidly
degrades both in terms of MSE and of convergence, while ASP converges in a
larger regime and can reach lower errors. Among other results, our analysis
leads us to a striking hypothesis that whenever s (or other parameters) can be
set in such a way that the Nishimori condition $M=Q&amp;gt;0$ is restored, then the
corresponding algorithm is able to reach mean-squared error as low as the
Bayes-optimal error obtained when the model and its parameters are known and
exactly matched in the inference procedure.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Antenucci_F/0/1/0/all/0/1&quot;&gt;Fabrizio Antenucci&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Krzakala_F/0/1/0/all/0/1&quot;&gt;Florent Krzakala&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Urbani_P/0/1/0/all/0/1&quot;&gt;Pierfrancesco Urbani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cond-mat/1/au:+Zdeborova_L/0/1/0/all/0/1&quot;&gt;Lenka Zdeborov&amp;#xe1;&lt;/a&gt;</dc:creator>
</item></rdf:RDF>