<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Boring papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Bad Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-06-04T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00730"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00797"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.01016"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.01107"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.01128"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.01224"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.00970"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.03304"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.00404"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00499"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00540"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00553"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00589"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00610"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00712"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00727"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00754"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00806"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00882"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00938"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00952"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00960"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00979"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00984"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.01044"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.01130"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.01151"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.01159"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.01175"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.01186"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.01235"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.01242"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.06275"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.11531"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.00377"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.03654"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.07946"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.10672"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11548"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00069"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00512"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00530"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00534"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00543"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00548"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00552"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00556"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00569"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00640"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00656"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00663"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00667"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00672"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00676"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00685"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00701"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00720"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00728"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00775"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00811"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00848"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00875"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00877"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00880"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00892"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00973"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.00981"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.01003"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.01047"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.01052"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.01059"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.01083"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.01094"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.01145"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.01240"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.01248"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.01259"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1806.01260"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1307.8371"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1610.09600"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1707.06792"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.09513"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.06719"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.08240"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.02557"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.02558"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.03065"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05693"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.00636"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.04503"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.06223"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.00616"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07281"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.07616"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11182"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11284"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.11845"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1805.12279"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1806.00730">
<title>Minnorm training: an algorithm for training overcomplete deep neural networks. (arXiv:1806.00730v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.00730</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work, we propose a new training method for finding minimum weight
norm solutions in over-parameterized neural networks (NNs). This method seeks
to improve training speed and generalization performance by framing NN training
as a constrained optimization problem wherein the sum of the norm of the
weights in each layer of the network is minimized, under the constraint of
exactly fitting training data. It draws inspiration from support vector
machines (SVMs), which are able to generalize well, despite often having an
infinite number of free parameters in their primal form, and from recent
theoretical generalization bounds on NNs which suggest that lower norm
solutions generalize better. To solve this constrained optimization problem,
our method employs Lagrange multipliers that act as integrators of error over
training and identify `support vector&apos;-like examples. The method can be
implemented as a wrapper around gradient based methods and uses standard
back-propagation of gradients from the NN for both regression and
classification versions of the algorithm. We provide theoretical justifications
for the effectiveness of this algorithm in comparison to early stopping and
$L_2$-regularization using simple, analytically tractable settings. In
particular, we show faster convergence to the max-margin hyperplane in a
shallow network (compared to vanilla gradient descent); faster convergence to
the minimum-norm solution in a linear chain (compared to $L_2$-regularization);
and initialization-independent generalization performance in a deep linear
network. Finally, using the MNIST dataset, we demonstrate that this algorithm
can boost test accuracy and identify difficult examples in real-world datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bansal_Y/0/1/0/all/0/1&quot;&gt;Yamini Bansal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Advani_M/0/1/0/all/0/1&quot;&gt;Madhu Advani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Cox_D/0/1/0/all/0/1&quot;&gt;David D Cox&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Saxe_A/0/1/0/all/0/1&quot;&gt;Andrew M Saxe&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00797">
<title>Echo state networks are universal. (arXiv:1806.00797v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1806.00797</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper shows that echo state networks are universal uniform approximants
in the context of discrete-time fading memory filters with uniformly bounded
inputs defined on negative infinite times. The proof uses newly introduced
internal approximation results for filters associated to reservoir computing
systems, as well as the external approximation properties of state affine
systems proved in a previous work.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grigoryeva_L/0/1/0/all/0/1&quot;&gt;Lyudmila Grigoryeva&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ortega_J/0/1/0/all/0/1&quot;&gt;Juan-Pablo Ortega&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.01016">
<title>Hierarchical Bi-level Multi-Objective Evolution of Single- and Multi-layer Echo State Network Autoencoders for Data Representations. (arXiv:1806.01016v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1806.01016</link>
<description rdf:parseType="Literal">&lt;p&gt;Echo State Network (ESN) presents a distinguished kind of recurrent neural
networks. It is built upon a sparse, random and large hidden infrastructure
called reservoir. ESNs have succeeded in dealing with several non-linear
problems such as prediction, classification, etc. Thanks to its rich dynamics,
ESN is used as an Autoencoder (AE) to extract features from original data
representations. ESN is not only used with its basic single layer form but also
with the recently proposed Multi-Layer (ML) architecture. The well setting of
ESN (basic and ML) architectures and training parameters is a crucial and hard
labor task. Generally, a number of parameters (hidden neurons, sparsity rates,
input scaling) is manually altered to achieve minimum learning error. However,
this randomly hand crafted task, on one hand, may not guarantee best training
results and on the other hand, it can raise the network&apos;s complexity. In this
paper, a hierarchical bi-level evolutionary optimization is proposed to deal
with these issues. The first level includes a multi-objective architecture
optimization providing maximum learning accuracy while sustaining the
complexity at a reduced standard. Multi-objective Particle Swarm Optimization
(MOPSO) is used to optimize ESN structure in a way to provide a trade-off
between the network complexity decreasing and the accuracy increasing. A
pareto-front of optimal solutions is generated by the end of the MOPSO process.
These solutions present the set of candidates that succeeded in providing a
compromise between different objectives (learning error and network
complexity). At the second level, each of the solutions already found undergo a
mono-objective weights optimization to enhance the obtained pareto-front.
Empirical results ensure the effectiveness of the evolved ESN recurrent AEs
(basic and ML) for noisy and noise free data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chouikhi_N/0/1/0/all/0/1&quot;&gt;Naima Chouikhi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ammar_B/0/1/0/all/0/1&quot;&gt;Boudour Ammar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alimi_A/0/1/0/all/0/1&quot;&gt;Adel M. Alimi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.01107">
<title>GANAX: A Unified MIMD-SIMD Acceleration for Generative Adversarial Networks. (arXiv:1806.01107v1 [cs.DC])</title>
<link>http://arxiv.org/abs/1806.01107</link>
<description rdf:parseType="Literal">&lt;p&gt;Generative Adversarial Networks (GANs) are one of the most recent deep
learning models that generate synthetic data from limited genuine datasets.
GANs are on the frontier as further extension of deep learning into many
domains (e.g., medicine, robotics, content synthesis) requires massive sets of
labeled data that is generally either unavailable or prohibitively costly to
collect. Although GANs are gaining prominence in various fields, there are no
accelerators for these new models. In fact, GANs leverage a new operator,
called transposed convolution, that exposes unique challenges for hardware
acceleration. This operator first inserts zeros within the multidimensional
input, then convolves a kernel over this expanded array to add information to
the embedded zeros. Even though there is a convolution stage in this operator,
the inserted zeros lead to underutilization of the compute resources when a
conventional convolution accelerator is employed. We propose the GANAX
architecture to alleviate the sources of inefficiency associated with the
acceleration of GANs using conventional convolution accelerators, making the
first GAN accelerator design possible. We propose a reorganization of the
output computations to allocate compute rows with similar patterns of zeros to
adjacent processing engines, which also avoids inconsequential multiply-adds on
the zeros. This compulsory adjacency reclaims data reuse across these
neighboring processing engines, which had otherwise diminished due to the
inserted zeros. The reordering breaks the full SIMD execution model, which is
prominent in convolution accelerators. Therefore, we propose a unified
MIMD-SIMD design for GANAX that leverages repeated patterns in the computation
to create distinct microprograms that execute concurrently in SIMD mode.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yazdanbakhsh_A/0/1/0/all/0/1&quot;&gt;Amir Yazdanbakhsh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Falahati_H/0/1/0/all/0/1&quot;&gt;Hajar Falahati&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wolfe_P/0/1/0/all/0/1&quot;&gt;Philip J. Wolfe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Samadi_K/0/1/0/all/0/1&quot;&gt;Kambiz Samadi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_N/0/1/0/all/0/1&quot;&gt;Nam Sung Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Esmaeilzadeh_H/0/1/0/all/0/1&quot;&gt;Hadi Esmaeilzadeh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.01128">
<title>Ring Migration Topology Helps Bypassing Local Optima. (arXiv:1806.01128v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1806.01128</link>
<description rdf:parseType="Literal">&lt;p&gt;Running several evolutionary algorithms in parallel and occasionally
exchanging good solutions is referred to as island models. The idea is that the
independence of the different islands leads to diversity, thus possibly
exploring the search space better. Many theoretical analyses so far have found
a complete (or sufficiently quickly expanding) topology as underlying migration
graph most efficient for optimization, even though a quick dissemination of
individuals leads to a loss of diversity. We suggest a simple fitness function
FORK with two local optima parametrized by $r \geq 2$ and a scheme for
composite fitness functions. We show that, while the (1+1) EA gets stuck in a
bad local optimum and incurs a run time of $\Theta(n^{2r})$ fitness evaluations
on FORK, island models with a complete topology can achieve a run time of
$\Theta(n^{1.5r})$ by making use of rare migrations in order to explore the
search space more effectively. Finally, the ring topology, making use of rare
migrations and a large diameter, can achieve a run time of
$\tilde{\Theta}(n^r)$, the black box complexity of FORK. This shows that the
ring topology can be preferable over the complete topology in order to maintain
diversity.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Frahnow_C/0/1/0/all/0/1&quot;&gt;Clemens Frahnow&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kotzing_T/0/1/0/all/0/1&quot;&gt;Timo K&amp;#xf6;tzing&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.01224">
<title>Challenges in High-dimensional Reinforcement Learning with Evolution Strategies. (arXiv:1806.01224v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1806.01224</link>
<description rdf:parseType="Literal">&lt;p&gt;Evolution Strategies (ESs) have recently become popular for training deep
neural networks, in particular on reinforcement learning tasks, a special form
of controller design. Compared to classic problems in continuous direct search,
deep networks pose extremely high-dimensional optimization problems, with many
thousands or even millions of variables. In addition, many control problems
give rise to a stochastic fitness function. Considering the relevance of the
application, we study the suitability of evolution strategies for
high-dimensional, stochastic problems. Our results give insights into which
algorithmic mechanisms of modern ES are of value for the class of problems at
hand, and they reveal principled limitations of the approach. They are in line
with our theoretical understanding of ESs. We show that combining ESs that
offer reduced internal algorithm cost with uncertainty handling techniques
yields promising methods for this class of problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Muller_N/0/1/0/all/0/1&quot;&gt;Nils M&amp;#xfc;ller&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Glasmachers_T/0/1/0/all/0/1&quot;&gt;Tobias Glasmachers&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.00970">
<title>A Classification-Based Study of Covariate Shift in GAN Distributions. (arXiv:1711.00970v6 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1711.00970</link>
<description rdf:parseType="Literal">&lt;p&gt;A basic, and still largely unanswered, question in the context of Generative
Adversarial Networks (GANs) is whether they are truly able to capture all the
fundamental characteristics of the distributions they are trained on. In
particular, evaluating the diversity of GAN distributions is challenging and
existing methods provide only a partial understanding of this issue. In this
paper, we develop quantitative and scalable tools for assessing the diversity
of GAN distributions. Specifically, we take a classification-based perspective
and view loss of diversity as a form of covariate shift introduced by GANs. We
examine two specific forms of such shift: mode collapse and boundary
distortion. In contrast to prior work, our methods need only minimal human
supervision and can be readily applied to state-of-the-art GANs on large,
canonical datasets. Examining popular GANs using our tools indicates that these
GANs have significant problems in reproducing the more distributional
properties of their training dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Santurkar_S/0/1/0/all/0/1&quot;&gt;Shibani Santurkar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schmidt_L/0/1/0/all/0/1&quot;&gt;Ludwig Schmidt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Madry_A/0/1/0/all/0/1&quot;&gt;Aleksander M&amp;#x105;dry&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.03304">
<title>Seeking Open-Ended Evolution in Swarm Chemistry II: Analyzing Long-Term Dynamics via Automated Object Harvesting. (arXiv:1804.03304v2 [nlin.AO] UPDATED)</title>
<link>http://arxiv.org/abs/1804.03304</link>
<description rdf:parseType="Literal">&lt;p&gt;We studied the long-term dynamics of evolutionary Swarm Chemistry by
extending the simulation length ten-fold compared to earlier work and by
developing and using a new automated object harvesting method. Both macroscopic
dynamics and microscopic object features were characterized and tracked using
several measures. Results showed that the evolutionary dynamics tended to
settle down into a stable state after the initial transient period, and that
the extent of environmental perturbations also affected the evolutionary trends
substantially. In the meantime, the automated harvesting method successfully
produced a huge collection of spontaneously evolved objects, revealing the
system&apos;s autonomous creativity at an unprecedented scale.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/nlin/1/au:+Sayama_H/0/1/0/all/0/1&quot;&gt;Hiroki Sayama&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.00404">
<title>Deep Defense: Training DNNs with Improved Adversarial Robustness. (arXiv:1803.00404v2 [cs.CV] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1803.00404</link>
<description rdf:parseType="Literal">&lt;p&gt;Despite the efficacy on a variety of computer vision tasks, deep neural
networks (DNNs) are vulnerable to adversarial attacks, limiting their
applications in security-critical systems. Recent works have shown the
possibility of generating imperceptibly perturbed image inputs (a.k.a.,
adversarial examples) to fool well-trained DNN classifiers into making
arbitrary predictions. To address this problem, we propose a training recipe
named &quot;deep defense&quot;. Our core idea is to integrate an adversarial
perturbation-based regularizer into the classification objective, such that the
obtained models learn to resist potential attacks, directly and precisely. The
whole optimization problem is solved just like training a recursive network.
Experimental results demonstrate that our method outperforms training with
adversarial/Parseval regularizations by large margins on various datasets
(including MNIST, CIFAR-10 and ImageNet) and different DNN architectures. Code
and models for reproducing our results will be made publicly available.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yan_Z/0/1/0/all/0/1&quot;&gt;Ziang Yan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guo_Y/0/1/0/all/0/1&quot;&gt;Yiwen Guo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_C/0/1/0/all/0/1&quot;&gt;Changshui Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00499">
<title>Backpropagation for Implicit Spectral Densities. (arXiv:1806.00499v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.00499</link>
<description rdf:parseType="Literal">&lt;p&gt;Most successful machine intelligence systems rely on gradient-based learning,
which is made possible by backpropagation. Some systems are designed to aid us
in interpreting data when explicit goals cannot be provided. These unsupervised
systems are commonly trained by backpropagating through a likelihood function.
We introduce a tool that allows us to do this even when the likelihood is not
explicitly set, by instead using the implicit likelihood of the model.
Explicitly defining the likelihood often entails making heavy-handed
assumptions that impede our ability to solve challenging tasks. On the other
hand, the implicit likelihood of the model is accessible without the need for
such assumptions. Our tool, which we call spectral backpropagation, allows us
to optimize it in much greater generality than what has been attempted before.
GANs can also be viewed as a technique for optimizing implicit likelihoods. We
study them using spectral backpropagation in order to demonstrate robustness
for high-dimensional problems, and identify two novel properties of the
generator G: (1) there exist aberrant, nonsensical outputs to which G assigns
very high likelihood, and (2) the eigenvectors of the metric induced by G over
latent space correspond to quasi-disentangled explanatory factors.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ramesh_A/0/1/0/all/0/1&quot;&gt;Aditya Ramesh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+LeCun_Y/0/1/0/all/0/1&quot;&gt;Yann LeCun&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00540">
<title>Integrating Episodic Memory into a Reinforcement Learning Agent using Reservoir Sampling. (arXiv:1806.00540v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.00540</link>
<description rdf:parseType="Literal">&lt;p&gt;Episodic memory is a psychology term which refers to the ability to recall
specific events from the past. We suggest one advantage of this particular type
of memory is the ability to easily assign credit to a specific state when
remembered information is found to be useful. Inspired by this idea, and the
increasing popularity of external memory mechanisms to handle long-term
dependencies in deep learning systems, we propose a novel algorithm which uses
a reservoir sampling procedure to maintain an external memory consisting of a
fixed number of past states. The algorithm allows a deep reinforcement learning
agent to learn online to preferentially remember those states which are found
to be useful to recall later on. Critically this method allows for efficient
online computation of gradient estimates with respect to the write process of
the external memory. Thus unlike most prior mechanisms for external memory it
is feasible to use in an online reinforcement learning setting.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Young_K/0/1/0/all/0/1&quot;&gt;Kenny J. Young&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sutton_R/0/1/0/all/0/1&quot;&gt;Richard S. Sutton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1&quot;&gt;Shuo Yang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00553">
<title>Deep Curiosity Search: Intra-Life Exploration Improves Performance on Challenging Deep Reinforcement Learning Problems. (arXiv:1806.00553v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1806.00553</link>
<description rdf:parseType="Literal">&lt;p&gt;Traditional exploration methods in RL require agents to perform random
actions to find rewards. But these approaches struggle on sparse-reward domains
like Montezuma&apos;s Revenge where the probability that any random action sequence
leads to reward is extremely low. Recent algorithms have performed well on such
tasks by encouraging agents to visit new states or perform new actions in
relation to all prior training episodes (which we call across-training
novelty). But such algorithms do not consider whether an agent exhibits
intra-life novelty: doing something new within the current episode, regardless
of whether those behaviors have been performed in previous episodes. We
hypothesize that across-training novelty might discourage agents from
revisiting initially non-rewarding states that could become important stepping
stones later in training. We introduce Deep Curiosity Search (DeepCS), which
encourages intra-life exploration by rewarding agents for visiting as many
different states as possible within each episode, and show that DeepCS matches
the performance of current state-of-the-art methods on Montezuma&apos;s Revenge. We
further show that DeepCS improves exploration on Gravitar (another difficult,
sparse-reward game) and performs well on the dense-reward game Amidar.
Surprisingly, DeepCS doubles A2C performance on Seaquest, a game we would not
have expected to benefit from intra-life exploration because the arena is small
and already easily navigated by naive exploration techniques. In one run,
DeepCS achieves a maximum training score of 80,000 points on Seaquest, higher
than any methods other than Ape-X. The strong performance of DeepCS on these
sparse- and dense-reward tasks suggests that encouraging intra-life novelty is
an interesting, new approach for improving performance in Deep RL and motivates
further research into hybridizing across-training and intra-life exploration
methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Stanton_C/0/1/0/all/0/1&quot;&gt;Christopher Stanton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Clune_J/0/1/0/all/0/1&quot;&gt;Jeff Clune&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00589">
<title>Efficient Entropy for Policy Gradient with Multidimensional Action Space. (arXiv:1806.00589v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.00589</link>
<description rdf:parseType="Literal">&lt;p&gt;In recent years, deep reinforcement learning has been shown to be adept at
solving sequential decision processes with high-dimensional state spaces such
as in the Atari games. Many reinforcement learning problems, however, involve
high-dimensional discrete action spaces as well as high-dimensional state
spaces. This paper considers entropy bonus, which is used to encourage
exploration in policy gradient. In the case of high-dimensional action spaces,
calculating the entropy and its gradient requires enumerating all the actions
in the action space and running forward and backpropagation for each action,
which may be computationally infeasible. We develop several novel unbiased
estimators for the entropy bonus and its gradient. We apply these estimators to
several models for the parameterized policies, including Independent Sampling,
CommNet, Autoregressive with Modified MDP, and Autoregressive with LSTM.
Finally, we test our algorithms on two environments: a multi-hunter
multi-rabbit grid game and a multi-agent multi-arm bandit problem. The results
show that our entropy estimators substantially improve performance with
marginal additional computational cost.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Y/0/1/0/all/0/1&quot;&gt;Yiming Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vuong_Q/0/1/0/all/0/1&quot;&gt;Quan Ho Vuong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Song_K/0/1/0/all/0/1&quot;&gt;Kenny Song&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gong_X/0/1/0/all/0/1&quot;&gt;Xiao-Yue Gong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ross_K/0/1/0/all/0/1&quot;&gt;Keith W. Ross&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00610">
<title>Accounting for the Neglected Dimensions of AI Progress. (arXiv:1806.00610v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1806.00610</link>
<description rdf:parseType="Literal">&lt;p&gt;We analyze and reframe AI progress. In addition to the prevailing metrics of
performance, we highlight the usually neglected costs paid in the development
and deployment of a system, including: data, expert knowledge, human oversight,
software resources, computing cycles, hardware and network facilities,
development time, etc. These costs are paid throughout the life cycle of an AI
system, fall differentially on different individuals, and vary in magnitude
depending on the replicability and generality of the AI solution. The
multidimensional performance and cost space can be collapsed to a single
utility metric for a user with transitive and complete preferences. Even absent
a single utility function, AI advances can be generically assessed by whether
they expand the Pareto (optimal) surface. We explore a subset of these
neglected dimensions using the two case studies of Alpha* and ALE. This
broadened conception of progress in AI should lead to novel ways of measuring
success in AI, and can help set milestones for future progress.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Martinez_Plumed_F/0/1/0/all/0/1&quot;&gt;Fernando Mart&amp;#xed;nez-Plumed&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Avin_S/0/1/0/all/0/1&quot;&gt;Shahar Avin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brundage_M/0/1/0/all/0/1&quot;&gt;Miles Brundage&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dafoe_A/0/1/0/all/0/1&quot;&gt;Allan Dafoe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+hEigeartaigh_S/0/1/0/all/0/1&quot;&gt;Sean &amp;#xd3; h&amp;#xc9;igeartaigh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hernandez_Orallo_J/0/1/0/all/0/1&quot;&gt;Jos&amp;#xe9; Hern&amp;#xe1;ndez-Orallo&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00712">
<title>An Interpretable Deep Hierarchical Semantic Convolutional Neural Network for Lung Nodule Malignancy Classification. (arXiv:1806.00712v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1806.00712</link>
<description rdf:parseType="Literal">&lt;p&gt;While deep learning methods are increasingly being applied to tasks such as
computer-aided diagnosis, these models are difficult to interpret, do not
incorporate prior domain knowledge, and are often considered as a &quot;black-box.&quot;
The lack of model interpretability hinders them from being fully understood by
target users such as radiologists. In this paper, we present a novel
interpretable deep hierarchical semantic convolutional neural network (HSCNN)
to predict whether a given pulmonary nodule observed on a computed tomography
(CT) scan is malignant. Our network provides two levels of output: 1) low-level
radiologist semantic features, and 2) a high-level malignancy prediction score.
The low-level semantic outputs quantify the diagnostic features used by
radiologists and serve to explain how the model interprets the images in an
expert-driven manner. The information from these low-level tasks, along with
the representations learned by the convolutional layers, are then combined and
used to infer the high-level task of predicting nodule malignancy. This unified
architecture is trained by optimizing a global loss function including both
low- and high-level tasks, thereby learning all the parameters within a joint
framework. Our experimental results using the Lung Image Database Consortium
(LIDC) show that the proposed method not only produces interpretable lung
cancer predictions but also achieves significantly better results compared to
common 3D CNN approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_S/0/1/0/all/0/1&quot;&gt;Shiwen Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Han_S/0/1/0/all/0/1&quot;&gt;Simon X. Han&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aberle_D/0/1/0/all/0/1&quot;&gt;Denise R. Aberle&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bui_A/0/1/0/all/0/1&quot;&gt;Alex A.T. Bui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hsu_W/0/1/0/all/0/1&quot;&gt;Willliam Hsu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00727">
<title>Closed-loop Bayesian Semantic Data Fusion for Collaborative Human-Autonomy Target Search. (arXiv:1806.00727v1 [cs.RO])</title>
<link>http://arxiv.org/abs/1806.00727</link>
<description rdf:parseType="Literal">&lt;p&gt;In search applications, autonomous unmanned vehicles must be able to
efficiently reacquire and localize mobile targets that can remain out of view
for long periods of time in large spaces. As such, all available information
sources must be actively leveraged -- including imprecise but readily available
semantic observations provided by humans. To achieve this, this work develops
and validates a novel collaborative human-machine sensing solution for dynamic
target search. Our approach uses continuous partially observable Markov
decision process (CPOMDP) planning to generate vehicle trajectories that
optimally exploit imperfect detection data from onboard sensors, as well as
semantic natural language observations that can be specifically requested from
human sensors. The key innovation is a scalable hierarchical Gaussian mixture
model formulation for efficiently solving CPOMDPs with semantic observations in
continuous dynamic state spaces. The approach is demonstrated and validated
with a real human-robot team engaged in dynamic indoor target search and
capture scenarios on a custom testbed.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Burks_L/0/1/0/all/0/1&quot;&gt;Luke Burks&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Loefgren_I/0/1/0/all/0/1&quot;&gt;Ian Loefgren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Barbier_L/0/1/0/all/0/1&quot;&gt;Luke Barbier&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Muesing_J/0/1/0/all/0/1&quot;&gt;Jeremy Muesing&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+McGinley_J/0/1/0/all/0/1&quot;&gt;Jamison McGinley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vunnam_S/0/1/0/all/0/1&quot;&gt;Sousheel Vunnam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ahmed_N/0/1/0/all/0/1&quot;&gt;Nisar Ahmed&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00754">
<title>Psychological State in Text: A Limitation of Sentiment Analysis. (arXiv:1806.00754v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1806.00754</link>
<description rdf:parseType="Literal">&lt;p&gt;Starting with the idea that sentiment analysis models should be able to
predict not only positive or negative but also other psychological states of a
person, we implement a sentiment analysis model to investigate the relationship
between the model and emotional state. We first examine psychological
measurements of 64 participants and ask them to write a book report about a
story. After that, we train our sentiment analysis model using crawled movie
review data. We finally evaluate participants&apos; writings, using the pretrained
model as a concept of transfer learning. The result shows that sentiment
analysis model performs good at predicting a score, but the score does not have
any correlation with human&apos;s self-checked sentiment.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jo_H/0/1/0/all/0/1&quot;&gt;Hwiyeol Jo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ryu_J/0/1/0/all/0/1&quot;&gt;Jeong Ryu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00806">
<title>k-Space Deep Learning for Parallel MRI: Application to Time-Resolved MR Angiography. (arXiv:1806.00806v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1806.00806</link>
<description rdf:parseType="Literal">&lt;p&gt;Time-resolved angiography with interleaved stochastic trajectories (TWIST)
has been widely used for dynamic contrast enhanced MRI (DCE-MRI). To achieve
highly accelerated acquisitions, TWIST combines the periphery of the k-space
data from several adjacent frames to reconstruct one temporal frame. However,
this view-sharing scheme limits the true temporal resolution of TWIST. In
addition, since the k-space sampling patterns have been specially designed for
a specific generalized autocalibrating partial parallel acquisition (GRAPPA)
factor, it is not possible to reduce the number of views in order to
reconstruct images with a better temporal resolution. To address these issues,
this paper proposes a novel k-space deep learning approach for parallel MRI. In
particular, inspired by the recent mathematical discovery that links Hankel
matrix decomposition to deep learning, we have implemented our neural network
so that accurate k-space interpolations are performed simultaneously for
multiple coils by exploiting the redundancies along the coils and images. In
addition, the proposed method can immediately generate reconstruction results
with different numbers of view-sharing, allowing us to exploit the trade-off
between spatial and temporal resolution. Reconstruction results using in vivo
TWIST data set confirm the accuracy and the flexibility of the proposed method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cha_E/0/1/0/all/0/1&quot;&gt;Eunju Cha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kim_E/0/1/0/all/0/1&quot;&gt;Eung Yeop Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1&quot;&gt;Jong Chul Ye&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00882">
<title>Structural Learning of Multivariate Regression Chain Graphs via Decomposition. (arXiv:1806.00882v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1806.00882</link>
<description rdf:parseType="Literal">&lt;p&gt;We extend the decomposition approach for learning Bayesian networks (BN)
proposed by (Xie et al., 2006) to learning multivariate regression chain graphs
(MVR CGs), which include BNs as a special case. The same advantages of this
decomposition approach hold in the more general setting: reduces complexity and
increased power of computational independence tests. Moreover, latent (hidden)
variables can be represented in MVR CGs by using bidirected edges, and our
algorithm correctly recovers any independence structure that is faithful to a
MVR CG, thus greatly extending the range of applications of decomposition-based
model selection techniques. While our new algorithm has the same complexity as
the one in (Xie et al., 2006) for BNs, it requires larger components for
general MVR CGs, to insure that sufficient data is present to estimate
parameters.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Javidian_M/0/1/0/all/0/1&quot;&gt;Mohammad Ali Javidian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Valtorta_M/0/1/0/all/0/1&quot;&gt;Marco Valtorta&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00938">
<title>Program Synthesis from Visual Specification. (arXiv:1806.00938v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1806.00938</link>
<description rdf:parseType="Literal">&lt;p&gt;Program synthesis is the process of automatically translating a specification
into computer code. Traditional synthesis settings require a formal, precise
specification. Motivated by computer education applications where a student
learns to code simple turtle-style drawing programs, we study a novel synthesis
setting where only a noisy user-intention drawing is specified. This allows
students to sketch their intended output, optionally together with their own
incomplete program, to automatically produce a completed program. We formulate
this synthesis problem as search in the space of programs, with the score of a
state being the Hausdorff distance between the program output and the user
drawing. We compare several search algorithms on a corpus consisting of real
user drawings and the corresponding programs, and demonstrate that our
algorithms can synthesize programs optimally satisfying the specification.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hernandez_E/0/1/0/all/0/1&quot;&gt;Evan Hernandez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vartanian_A/0/1/0/all/0/1&quot;&gt;Ara Vartanian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_X/0/1/0/all/0/1&quot;&gt;Xiaojin Zhu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00952">
<title>Stochastic Gradient/Mirror Descent: Minimax Optimality and Implicit Regularization. (arXiv:1806.00952v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.00952</link>
<description rdf:parseType="Literal">&lt;p&gt;Stochastic descent methods (of the gradient and mirror varieties) have become
increasingly popular in optimization. In fact, it is now widely recognized that
the success of deep learning is not only due to the special deep architecture
of the models, but also due to the behavior of the stochastic descent methods
used, which play a key role in reaching &quot;good&quot; solutions that generalize well
to unseen data. In an attempt to shed some light on why this is the case, we
revisit some minimax properties of stochastic gradient descent (SGD) on the
square loss of linear models---originally developed in the 1990&apos;s---and extend
them to \emph{generic} stochastic mirror descent (SMD) algorithms on
\emph{general} loss functions and \emph{nonlinear} models. In particular, we
show that there is a fundamental identity which holds for SMD (and SGD) under
very general conditions, and that this identity implies the minimax optimality
of SMD (and SGD) with sufficiently small step size, for a general class of loss
functions and general nonlinear models. We further show that this identity can
be used to naturally establish other properties of SMD (and SGD), such as
convergence and \emph{implicit regularization} for over-parameterized linear
models, which have been shown in certain cases in the literature. We also show
how this identity can be used in the so-called &quot;highly over-parameterized&quot;
nonlinear setting to provide insights into why SMD (and SGD) may have similar
convergence and implicit regularization properties for deep learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Azizan_N/0/1/0/all/0/1&quot;&gt;Navid Azizan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hassibi_B/0/1/0/all/0/1&quot;&gt;Babak Hassibi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00960">
<title>Mechanism Design without Money for Common Goods. (arXiv:1806.00960v1 [cs.GT])</title>
<link>http://arxiv.org/abs/1806.00960</link>
<description rdf:parseType="Literal">&lt;p&gt;We initiate the study of mechanism design without money for common goods. Our
model captures a variation of the well-known one-dimensional facility location
problem if the facility is assumed to have a capacity constraint $k&amp;lt;n$ where
$n$ is the population size. This new model introduces a richer game-theoretic
context compared to the classical facility location, or public goods, problem.
Our key result contributes a novel perspective relating to the &quot;major open
question&quot; (Barbar\`a et al., 1998) posed by Border and Jordan (1983) by showing
the equivalence of dominant strategy incentive compatible (DIC) mechanisms for
common goods and the family of Generalized Median Mechanisms (GMMs). This
equivalence does not hold in the public goods setting and, by situating GMMs in
this broader game-theoretic context, is the first complete characterization of
GMMs in terms of purely strategic properties. We then characterize lower bounds
of the welfare approximation ratio across all DIC mechanisms and identify a DIC
mechanism which attains this lower bound when $k&amp;lt;\lceil (n+1)/2\rceil$ and
$k=n$. Finally, we analyze the approximation ratio when the property of DIC is
weakened to ex post incentive compatibility.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aziz_H/0/1/0/all/0/1&quot;&gt;Haris Aziz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chan_H/0/1/0/all/0/1&quot;&gt;Hau Chan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_B/0/1/0/all/0/1&quot;&gt;Barton E. Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Parkes_D/0/1/0/all/0/1&quot;&gt;David. C. Parkes&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00979">
<title>Similarity encoding for learning with dirty categorical variables. (arXiv:1806.00979v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.00979</link>
<description rdf:parseType="Literal">&lt;p&gt;For statistical learning, categorical variables in a table are usually
considered as discrete entities and encoded separately to feature vectors,
e.g., with one-hot encoding. &quot;Dirty&quot; non-curated data gives rise to categorical
variables with a very high cardinality but redundancy: several categories
reflect the same entity. In databases, this issue is typically solved with a
deduplication step. We show that a simple approach that exposes the redundancy
to the learning algorithm brings significant gains. We study a generalization
of one-hot encoding, similarity encoding, that builds feature vectors from
similarities across categories. We perform a thorough empirical validation on
non-curated tables, a problem seldom studied in machine learning. Results on
seven real-world datasets show that similarity encoding brings significant
gains in prediction in comparison with known encoding methods for categories or
strings, notably one-hot encoding and bag of character n-grams. We draw
practical recommendations for encoding dirty categories: 3-gram similarity
appears to be a good choice to capture morphological resemblance. For very
high-cardinality, dimensionality reduction significantly reduces the
computational cost with little loss in performance: random projections or
choosing a subset of prototype categories still outperforms classic encoding
approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cerda_P/0/1/0/all/0/1&quot;&gt;Patricio Cerda&lt;/a&gt; (PARIETAL), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Varoquaux_G/0/1/0/all/0/1&quot;&gt;Ga&amp;#xeb;l Varoquaux&lt;/a&gt; (PARIETAL), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kegl_B/0/1/0/all/0/1&quot;&gt;Bal&amp;#xe1;zs K&amp;#xe9;gl&lt;/a&gt; (LAL, CNRS)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00984">
<title>DNN-HMM based Speaker Adaptive Emotion Recognition using Proposed Epoch and MFCC Features. (arXiv:1806.00984v1 [cs.SD])</title>
<link>http://arxiv.org/abs/1806.00984</link>
<description rdf:parseType="Literal">&lt;p&gt;Speech is produced when time varying vocal tract system is excited with time
varying excitation source. Therefore, the information present in a speech such
as message, emotion, language, speaker is due to the combined effect of both
excitation source and vocal tract system. However, there is very less
utilization of excitation source features to recognize emotion. In our earlier
work, we have proposed a novel method to extract glottal closure instants
(GCIs) known as epochs. In this paper, we have explored epoch features namely
instantaneous pitch, phase and strength of epochs for discriminating emotions.
We have combined the excitation source features and the well known
Male-frequency cepstral coefficient (MFCC) features to develop an emotion
recognition system with improved performance. DNN-HMM speaker adaptive models
have been developed using MFCC, epoch and combined features. IEMOCAP emotional
database has been used to evaluate the models. The average accuracy for emotion
recognition system when using MFCC and epoch features separately is 59.25% and
54.52% respectively. The recognition performance improves to 64.2% when MFCC
and epoch features are combined.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fahad_M/0/1/0/all/0/1&quot;&gt;Md. Shah Fahad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yadav_J/0/1/0/all/0/1&quot;&gt;Jainath Yadav&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pradhan_G/0/1/0/all/0/1&quot;&gt;Gyadhar Pradhan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Deepak_A/0/1/0/all/0/1&quot;&gt;Akshay Deepak&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.01044">
<title>A Desirability-Based Axiomatisation for Coherent Choice Functions. (arXiv:1806.01044v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1806.01044</link>
<description rdf:parseType="Literal">&lt;p&gt;Choice functions constitute a simple, direct and very general mathematical
framework for modelling choice under uncertainty. In particular, they are able
to represent the set-valued choices that typically arise from applying decision
rules to imprecise-probabilistic uncertainty models. We provide them with a
clear interpretation in terms of attitudes towards gambling, borrowing ideas
from the theory of sets of desirable gambles, and we use this interpretation to
derive a set of basic axioms. We show that these axioms lead to a full-fledged
theory of coherent choice functions, which includes a representation in terms
of sets of desirable gambles, and a conservative inference method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bock_J/0/1/0/all/0/1&quot;&gt;Jasper De Bock&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cooman_G/0/1/0/all/0/1&quot;&gt;Gert de Cooman&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.01130">
<title>Learning from Exemplars and Prototypes in Machine Learning and Psychology. (arXiv:1806.01130v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1806.01130</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper draws a parallel between similarity-based categorisation models
developed in cognitive psychology and the nearest neighbour classifier (1-NN)
in machine learning. Conceived as a result of the historical rivalry between
prototype theories (abstraction) and exemplar theories (memorisation), recent
models of human categorisation seek a compromise in-between. Regarding the
stimuli (entities to be categorised) as points in a metric space, machine
learning offers a large collection of methods to select a small, representative
and discriminative point set. These methods are known under various names:
instance selection, data editing, prototype selection, prototype generation or
prototype replacement. The nearest neighbour classifier is used with the
selected reference set. Such a set can be interpreted as a data-driven
categorisation model. We juxtapose the models from the two fields to enable
cross-referencing. We believe that both machine learning and cognitive
psychology can draw inspiration from the comparison and enrich their repertoire
of similarity-based models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zubek_J/0/1/0/all/0/1&quot;&gt;Julian Zubek&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kuncheva_L/0/1/0/all/0/1&quot;&gt;Ludmila Kuncheva&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.01151">
<title>Shallow decision-making analysis in General Video Game Playing. (arXiv:1806.01151v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1806.01151</link>
<description rdf:parseType="Literal">&lt;p&gt;The General Video Game AI competitions have been the testing ground for
several techniques for game playing, such as evolutionary computation
techniques, tree search algorithms, hyper heuristic based or knowledge based
algorithms. So far the metrics used to evaluate the performance of agents have
been win ratio, game score and length of games. In this paper we provide a
wider set of metrics and a comparison method for evaluating and comparing
agents. The metrics and the comparison method give shallow introspection into
the agent&apos;s decision making process and they can be applied to any agent
regardless of its algorithmic nature. In this work, the metrics and the
comparison method are used to measure the impact of the terms that compose a
tree policy of an MCTS based agent, comparing with several baseline agents. The
results clearly show how promising such general approach is and how it can be
useful to understand the behaviour of an AI agent, in particular, how the
comparison with baseline agents can help understanding the shape of the agent
decision landscape. The presented metrics and comparison method represent a
step toward to more descriptive ways of logging and analysing agent&apos;s
behaviours.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bravi_I/0/1/0/all/0/1&quot;&gt;Ivan Bravi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Jialin Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Perez_Liebana_D/0/1/0/all/0/1&quot;&gt;Diego Perez-Liebana&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lucas_S/0/1/0/all/0/1&quot;&gt;Simon Lucas&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.01159">
<title>Efficient and Scalable Batch Bayesian Optimization Using K-Means. (arXiv:1806.01159v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.01159</link>
<description rdf:parseType="Literal">&lt;p&gt;We present K-Means Batch Bayesian Optimization (KMBBO), a novel batch
sampling algorithm for Bayesian Optimization (BO). KMBBO uses unsupervised
learning to efficiently estimate peaks of the model acquisition function. We
show in empirical experiments that our method outperforms the current
state-of-the-art batch allocation algorithms on a variety of test problems
including tuning of algorithm hyper-parameters and a challenging drug discovery
problem. In order to accommodate the real-world problem of high dimensional
data, we propose a modification to KMBBO by combining it with compressed
sensing to project the optimization into a lower dimensional subspace. We
demonstrate empirically that this 2-step method is competitive with algorithms
where no dimensionality reduction has taken place.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Groves_M/0/1/0/all/0/1&quot;&gt;Matthew Groves&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pyzer_Knapp_E/0/1/0/all/0/1&quot;&gt;Edward O. Pyzer-Knapp&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.01175">
<title>TD or not TD: Analyzing the Role of Temporal Differencing in Deep Reinforcement Learning. (arXiv:1806.01175v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.01175</link>
<description rdf:parseType="Literal">&lt;p&gt;Our understanding of reinforcement learning (RL) has been shaped by
theoretical and empirical results that were obtained decades ago using tabular
representations and linear function approximators. These results suggest that
RL methods that use temporal differencing (TD) are superior to direct Monte
Carlo estimation (MC). How do these results hold up in deep RL, which deals
with perceptually complex environments and deep nonlinear models? In this
paper, we re-examine the role of TD in modern deep RL, using specially designed
environments that control for specific factors that affect performance, such as
reward sparsity, reward delay, and the perceptual complexity of the task. When
comparing TD with infinite-horizon MC, we are able to reproduce classic results
in modern settings. Yet we also find that finite-horizon MC is not inferior to
TD, even when rewards are sparse or delayed. This makes MC a viable alternative
to TD in deep RL.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Amiranashvili_A/0/1/0/all/0/1&quot;&gt;Artemij Amiranashvili&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dosovitskiy_A/0/1/0/all/0/1&quot;&gt;Alexey Dosovitskiy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koltun_V/0/1/0/all/0/1&quot;&gt;Vladlen Koltun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brox_T/0/1/0/all/0/1&quot;&gt;Thomas Brox&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.01186">
<title>Measuring and avoiding side effects using relative reachability. (arXiv:1806.01186v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.01186</link>
<description rdf:parseType="Literal">&lt;p&gt;How can we design reinforcement learning agents that avoid causing
unnecessary disruptions to their environment? We argue that current approaches
to penalizing side effects can introduce bad incentives in tasks that require
irreversible actions, and in environments that contain sources of change other
than the agent. For example, some approaches give the agent an incentive to
prevent any irreversible changes in the environment, including the actions of
other agents. We introduce a general definition of side effects, based on
relative reachability of states compared to a default state, that avoids these
undesirable incentives. Using a set of gridworld experiments illustrating
relevant scenarios, we empirically compare relative reachability to penalties
based on existing definitions and show that it is the only penalty among those
tested that produces the desired behavior in all the scenarios.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Krakovna_V/0/1/0/all/0/1&quot;&gt;Victoria Krakovna&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Orseau_L/0/1/0/all/0/1&quot;&gt;Laurent Orseau&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Martic_M/0/1/0/all/0/1&quot;&gt;Miljan Martic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Legg_S/0/1/0/all/0/1&quot;&gt;Shane Legg&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.01235">
<title>Deep Graphs. (arXiv:1806.01235v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.01235</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose an algorithm for deep learning on networks and graphs. It relies
on the notion that many graph algorithms, such as PageRank, Weisfeiler-Lehman,
or Message Passing can be expressed as iterative vertex updates. Unlike
previous methods which rely on the ingenuity of the designer, Deep Graphs are
adaptive to the estimation problem. Training and deployment are both efficient,
since the cost is $O(|E| + |V|)$, where $E$ and $V$ are the sets of edges and
vertices respectively. In short, we learn the recurrent update functions rather
than positing their specific functional form. This yields an algorithm that
achieves excellent accuracy on both graph labeling and regression tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Platanios_E/0/1/0/all/0/1&quot;&gt;Emmanouil Antonios Platanios&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Smola_A/0/1/0/all/0/1&quot;&gt;Alex Smola&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.01242">
<title>Graph networks as learnable physics engines for inference and control. (arXiv:1806.01242v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.01242</link>
<description rdf:parseType="Literal">&lt;p&gt;Understanding and interacting with everyday physical scenes requires rich
knowledge about the structure of the world, represented either implicitly in a
value or policy function, or explicitly in a transition model. Here we
introduce a new class of learnable models--based on graph networks--which
implement an inductive bias for object- and relation-centric representations of
complex, dynamical systems. Our results show that as a forward model, our
approach supports accurate predictions from real and simulated data, and
surprisingly strong and efficient generalization, across eight distinct
physical systems which we varied parametrically and structurally. We also found
that our inference model can perform system identification. Our models are also
differentiable, and support online planning via gradient-based trajectory
optimization, as well as offline policy optimization. Our framework offers new
opportunities for harnessing and exploiting rich knowledge about the world, and
takes a key step toward building machines with more human-like representations
of the world.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sanchez_Gonzalez_A/0/1/0/all/0/1&quot;&gt;Alvaro Sanchez-Gonzalez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Heess_N/0/1/0/all/0/1&quot;&gt;Nicolas Heess&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Springenberg_J/0/1/0/all/0/1&quot;&gt;Jost Tobias Springenberg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Merel_J/0/1/0/all/0/1&quot;&gt;Josh Merel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Riedmiller_M/0/1/0/all/0/1&quot;&gt;Martin Riedmiller&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hadsell_R/0/1/0/all/0/1&quot;&gt;Raia Hadsell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Battaglia_P/0/1/0/all/0/1&quot;&gt;Peter Battaglia&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.06275">
<title>Incorrigibility in the CIRL Framework. (arXiv:1709.06275v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1709.06275</link>
<description rdf:parseType="Literal">&lt;p&gt;A value learning system has incentives to follow shutdown instructions,
assuming the shutdown instruction provides information (in the technical sense)
about which actions lead to valuable outcomes. However, this assumption is not
robust to model mis-specification (e.g., in the case of programmer errors). We
demonstrate this by presenting some Supervised POMDP scenarios in which errors
in the parameterized reward function remove the incentive to follow shutdown
commands. These difficulties parallel those discussed by Soares et al. (2015)
in their paper on corrigibility. We argue that it is important to consider
systems that follow shutdown commands under some weaker set of assumptions
(e.g., that one small verified module is correctly implemented; as opposed to
an entire prior probability distribution and/or parameterized reward function).
We discuss some difficulties with simple ways to attempt to attain these sorts
of guarantees in a value learning framework.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Carey_R/0/1/0/all/0/1&quot;&gt;Ryan Carey&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.11531">
<title>SemTK: An Ontology-first, Open Source Semantic Toolkit for Managing and Querying Knowledge Graphs. (arXiv:1710.11531v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1710.11531</link>
<description rdf:parseType="Literal">&lt;p&gt;The relatively recent adoption of Knowledge Graphs as an enabling technology
in multiple high-profile artificial intelligence and cognitive applications has
led to growing interest in the Semantic Web technology stack. Many
semantics-related tools, however, are focused on serving experts with a deep
understanding of semantic technologies. For example, triplification of
relational data is available but there is no open source tool that allows a
user unfamiliar with OWL/RDF to import data into a semantic triple store in an
intuitive manner. Further, many tools require users to have a working
understanding of SPARQL to query data. Casual users interested in benefiting
from the power of Knowledge Graphs have few tools available for exploring,
querying, and managing semantic data. We present SemTK, the Semantics Toolkit,
a user-friendly suite of tools that allow both expert and non-expert semantics
users convenient ingestion of relational data, simplified query generation, and
more. The exploration of ontologies and instance data is performed through
SPARQLgraph, an intuitive web-based user interface in SemTK understandable and
navigable by a lay user. The open source version of SemTK is available at
&lt;a href=&quot;http://semtk.research.ge.com&quot;&gt;this http URL&lt;/a&gt;
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cuddihy_P/0/1/0/all/0/1&quot;&gt;Paul Cuddihy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+McHugh_J/0/1/0/all/0/1&quot;&gt;Justin McHugh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Williams_J/0/1/0/all/0/1&quot;&gt;Jenny Weisenberg Williams&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mulwad_V/0/1/0/all/0/1&quot;&gt;Varish Mulwad&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aggour_K/0/1/0/all/0/1&quot;&gt;Kareem S. Aggour&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.00377">
<title>Don&apos;t Just Assume; Look and Answer: Overcoming Priors for Visual Question Answering. (arXiv:1712.00377v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1712.00377</link>
<description rdf:parseType="Literal">&lt;p&gt;A number of studies have found that today&apos;s Visual Question Answering (VQA)
models are heavily driven by superficial correlations in the training data and
lack sufficient image grounding. To encourage development of models geared
towards the latter, we propose a new setting for VQA where for every question
type, train and test sets have different prior distributions of answers.
Specifically, we present new splits of the VQA v1 and VQA v2 datasets, which we
call Visual Question Answering under Changing Priors (VQA-CP v1 and VQA-CP v2
respectively). First, we evaluate several existing VQA models under this new
setting and show that their performance degrades significantly compared to the
original VQA setting. Second, we propose a novel Grounded Visual Question
Answering model (GVQA) that contains inductive biases and restrictions in the
architecture specifically designed to prevent the model from &apos;cheating&apos; by
primarily relying on priors in the training data. Specifically, GVQA explicitly
disentangles the recognition of visual concepts present in the image from the
identification of plausible answer space for a given question, enabling the
model to more robustly generalize across different distributions of answers.
GVQA is built off an existing VQA model -- Stacked Attention Networks (SAN).
Our experiments demonstrate that GVQA significantly outperforms SAN on both
VQA-CP v1 and VQA-CP v2 datasets. Interestingly, it also outperforms more
powerful VQA models such as Multimodal Compact Bilinear Pooling (MCB) in
several cases. GVQA offers strengths complementary to SAN when trained and
evaluated on the original VQA v1 and VQA v2 datasets. Finally, GVQA is more
transparent and interpretable than existing VQA models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Agrawal_A/0/1/0/all/0/1&quot;&gt;Aishwarya Agrawal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Batra_D/0/1/0/all/0/1&quot;&gt;Dhruv Batra&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Parikh_D/0/1/0/all/0/1&quot;&gt;Devi Parikh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kembhavi_A/0/1/0/all/0/1&quot;&gt;Aniruddha Kembhavi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.03654">
<title>Beyond the One Step Greedy Approach in Reinforcement Learning. (arXiv:1802.03654v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1802.03654</link>
<description rdf:parseType="Literal">&lt;p&gt;The famous Policy Iteration algorithm alternates between policy improvement
and policy evaluation. Implementations of this algorithm with several variants
of the latter evaluation stage, e.g, $n$-step and trace-based returns, have
been analyzed in previous works. However, the case of multiple-step lookahead
policy improvement, despite the recent increase in empirical evidence of its
strength, has to our knowledge not been carefully analyzed yet. In this work,
we introduce the first such analysis. Namely, we formulate variants of
multiple-step policy improvement, derive new algorithms using these definitions
and prove their convergence. Moreover, we show that recent prominent
Reinforcement Learning algorithms are, in fact, instances of our framework. We
thus shed light on their empirical success and give a recipe for deriving new
algorithms for future study.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Efroni_Y/0/1/0/all/0/1&quot;&gt;Yonathan Efroni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dalal_G/0/1/0/all/0/1&quot;&gt;Gal Dalal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Scherrer_B/0/1/0/all/0/1&quot;&gt;Bruno Scherrer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mannor_S/0/1/0/all/0/1&quot;&gt;Shie Mannor&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.07946">
<title>Extrofitting: Enriching Word Representation and its Vector Space with Semantic Lexicons. (arXiv:1804.07946v2 [cs.CL] UPDATED)</title>
<link>http://arxiv.org/abs/1804.07946</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose post-processing method for enriching not only word representation
but also its vector space using semantic lexicons, which we call extrofitting.
The method consists of 3 steps as follows: (i) Expanding 1 or more dimension(s)
on all the word vectors, filling with their representative value. (ii)
Transferring semantic knowledge by averaging each representative values of
synonyms and filling them in the expanded dimension(s). These two steps make
representations of the synonyms close together. (iii) Projecting the vector
space using Linear Discriminant Analysis, which eliminates the expanded
dimension(s) with semantic knowledge. When experimenting with GloVe, we find
that our method outperforms Faruqui&apos;s retrofitting on some of word similarity
task. We also report further analysis on our method in respect to word vector
dimensions, vocabulary size as well as other well-known pretrained word vectors
(e.g., Word2Vec, Fasttext).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jo_H/0/1/0/all/0/1&quot;&gt;Hwiyeol Jo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Choi_S/0/1/0/all/0/1&quot;&gt;Stanley Jungkyu Choi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.10672">
<title>A note on belief structures and S-approximation spaces. (arXiv:1805.10672v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1805.10672</link>
<description rdf:parseType="Literal">&lt;p&gt;We study relations between evidence theory and S-approximation spaces. Both
theories have their roots in the analysis of Dempster&apos;s multivalued mappings
and lower and upper probabilities and have close relations to rough sets. We
show that an S-approximation space, satisfying a monotonicity condition, can
induce a natural belief structure which is a fundamental block in evidence
theory. We also demonstrate that one can induce a natural belief structure on
one set, given a belief structure on another set if those sets are related by a
partial monotone S-approximation space.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shakiba_A/0/1/0/all/0/1&quot;&gt;Ali Shakiba&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goharshady_A/0/1/0/all/0/1&quot;&gt;Amir Kafshdar Goharshady&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hooshmandasl_M/0/1/0/all/0/1&quot;&gt;MohammadReza Hooshmandasl&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Meybodi_M/0/1/0/all/0/1&quot;&gt;Mohsen Alambardar Meybodi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11548">
<title>The Actor Search Tree Critic (ASTC) for Off-Policy POMDP Learning in Medical Decision Making. (arXiv:1805.11548v3 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1805.11548</link>
<description rdf:parseType="Literal">&lt;p&gt;Off-policy reinforcement learning enables near-optimal policy from suboptimal
experience, thereby provisions opportunity for artificial intelligence
applications in healthcare. Previous works have mainly framed patient-clinician
interactions as Markov decision processes, while true physiological states are
not necessarily fully observable from clinical data. We capture this situation
with partially observable Markov decision process, in which an agent optimises
its actions in a belief represented as a distribution of patient states
inferred from individual history trajectories. A Gaussian mixture model is
fitted for the observed data. Moreover, we take into account the fact that
nuance in pharmaceutical dosage could presumably result in significantly
different effect by modelling a continuous policy through a Gaussian
approximator directly in the policy space, i.e. the actor. To address the
challenge of infinite number of possible belief states which renders exact
value iteration intractable, we evaluate and plan for only every encountered
belief, through heuristic search tree by tightly maintaining lower and upper
bounds of the true value of belief. We further resort to function
approximations to update value bounds estimation, i.e. the critic, so that the
tree search can be improved through more compact bounds at the fringe nodes
that will be back-propagated to the root. Both actor and critic parameters are
learned via gradient-based approaches. Our proposed policy trained from real
intensive care unit data is capable of dictating dosing on vasopressors and
intravenous fluids for sepsis patients that lead to the best patient outcomes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_L/0/1/0/all/0/1&quot;&gt;Luchen Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Komorowski_M/0/1/0/all/0/1&quot;&gt;Matthieu Komorowski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Faisal_A/0/1/0/all/0/1&quot;&gt;Aldo A. Faisal&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00069">
<title>Explaining Explanations: An Approach to Evaluating Interpretability of Machine Learning. (arXiv:1806.00069v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1806.00069</link>
<description rdf:parseType="Literal">&lt;p&gt;There has recently been a surge of work in explanatory artificial
intelligence (XAI). This research area tackles the important problem that
complex machines and algorithms often cannot provide insights into their
behavior and thought processes. XAI allows users and parts of the internal
system to be more transparent, providing explanations of their decisions in
some level of detail. These explanations are important to ensure algorithmic
fairness, identify potential bias/problems in the training data, and to ensure
that the algorithms perform as expected. However, explanations produced by
these systems is neither standardized nor systematically assessed. In an effort
to create best practices and identify open challenges, we provide our
definition of explainability and show how it can be used to classify existing
literature. We discuss why current approaches to explanatory methods especially
for deep neural networks are insufficient. Finally, based on our survey, we
conclude with suggested future research directions for explanatory artificial
intelligence.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gilpin_L/0/1/0/all/0/1&quot;&gt;Leilani H. Gilpin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bau_D/0/1/0/all/0/1&quot;&gt;David Bau&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yuan_B/0/1/0/all/0/1&quot;&gt;Ben Z. Yuan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bajwa_A/0/1/0/all/0/1&quot;&gt;Ayesha Bajwa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Specter_M/0/1/0/all/0/1&quot;&gt;Michael Specter&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kagal_L/0/1/0/all/0/1&quot;&gt;Lalana Kagal&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00512">
<title>Structurally Sparsified Backward Propagation for Faster Long Short-Term Memory Training. (arXiv:1806.00512v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.00512</link>
<description rdf:parseType="Literal">&lt;p&gt;Exploiting sparsity enables hardware systems to run neural networks faster
and more energy-efficiently. However, most prior sparsity-centric optimization
techniques only accelerate the forward pass of neural networks and usually
require an even longer training process with iterative pruning and retraining.
We observe that artificially inducing sparsity in the gradients of the gates in
an LSTM cell has little impact on the training quality. Further, we can enforce
structured sparsity in the gate gradients to make the LSTM backward pass up to
45% faster than the state-of-the-art dense approach and 168% faster than the
state-of-the-art sparsifying method on modern GPUs. Though the structured
sparsifying method can impact the accuracy of a model, this performance gap can
be eliminated by mixing our sparse training method and the standard dense
training method. Experimental results show that the mixed method can achieve
comparable results in a shorter time span than using purely dense training.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_M/0/1/0/all/0/1&quot;&gt;Maohua Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Clemons_J/0/1/0/all/0/1&quot;&gt;Jason Clemons&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pool_J/0/1/0/all/0/1&quot;&gt;Jeff Pool&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rhu_M/0/1/0/all/0/1&quot;&gt;Minsoo Rhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Keckler_S/0/1/0/all/0/1&quot;&gt;Stephen W. Keckler&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xie_Y/0/1/0/all/0/1&quot;&gt;Yuan Xie&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00530">
<title>Efficient, Certifiably Optimal High-Dimensional Clustering. (arXiv:1806.00530v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.00530</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider SDP relaxation methods for data and variable clustering problems,
which have been shown in the literature to have good statistical properties in
a variety of settings, but remain intractable to solve in practice. In
particular, we propose FORCE, a new algorithm to solve the Peng-Wei $K$-means
SDP. Compared to the naive interior point method, our method reduces the
computational complexity of solving the SDP from
$\tilde{O}(d^7\log\epsilon^{-1})$ to $\tilde{O}(d^{6}K^{-2}\epsilon^{-1})$. Our
method combines a primal first-order method with a dual optimality certificate
search, which when successful, allows for early termination of the primal
method. We show under certain data generating distributions that, with high
probability, FORCE is guaranteed to find the optimal solution to the SDP
relaxation and provide a certificate of exact optimality. As verified by our
numerical experiments, this allows FORCE to solve the Peng-Wei SDP with
dimensions in the hundreds in only tens of seconds. We also consider a
variation of the Peng-Wei SDP for the case when $K$ is not known a priori and
show that a slight modification of FORCE reduces the computational complexity
of solving this problem as well: from $\tilde{O}(d^7\log\epsilon^{-1})$ using a
standard SDP solver to $\tilde{O}(d^{4}\epsilon^{-1})$.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Eisenach_C/0/1/0/all/0/1&quot;&gt;Carson Eisenach&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Liu_H/0/1/0/all/0/1&quot;&gt;Han Liu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00534">
<title>Run Procrustes, Run! On the convergence of accelerated Procrustes Flow. (arXiv:1806.00534v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.00534</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work, we present theoretical results on the convergence of non-convex
accelerated gradient descent in matrix factorization models. The technique is
applied to matrix sensing problems with squared loss, for the estimation of a
rank $r$ optimal solution $X^\star \in \mathbb{R}^{n \times n}$. We show that
the acceleration leads to linear convergence rate, even under non-convex
settings where the variable $X$ is represented as $U U^\top$ for $U \in
\mathbb{R}^{n \times r}$. Our result has the same dependence on the condition
number of the objective --and the optimal solution-- as that of the recent
results on non-accelerated algorithms. However, acceleration is observed in
practice, both in synthetic examples and in two real applications: neuronal
multi-unit activities recovery from single electrode recordings, and quantum
state tomography on quantum computing simulators.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kyrillidis_A/0/1/0/all/0/1&quot;&gt;Anastasios Kyrillidis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ubaru_S/0/1/0/all/0/1&quot;&gt;Shashanka Ubaru&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kollias_G/0/1/0/all/0/1&quot;&gt;Georgios Kollias&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bouchard_K/0/1/0/all/0/1&quot;&gt;Kristofer Bouchard&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00543">
<title>The Externalities of Exploration and How Data Diversity Helps Exploitation. (arXiv:1806.00543v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.00543</link>
<description rdf:parseType="Literal">&lt;p&gt;Online learning algorithms, widely used to power search and content
optimization on the web, must balance exploration and exploitation, potentially
sacrificing the experience of current users for information that will lead to
better decisions in the future. Recently, concerns have been raised about
whether the process of exploration could be viewed as unfair, placing too much
burden on certain individuals or groups. Motivated by these concerns, we
initiate the study of the externalities of exploration - the undesirable side
effects that the presence of one party may impose on another - under the linear
contextual bandits model. We introduce the notion of a group externality,
measuring the extent to which the presence of one population of users impacts
the rewards of another. We show that this impact can in some cases be negative,
and that, in a certain sense, no algorithm can avoid it. We then study
externalities at the individual level, interpreting the act of exploration as
an externality imposed on the current user of a system by future users. This
drives us to ask under what conditions inherent diversity in the data makes
explicit exploration unnecessary. We build on a recent line of work on the
smoothed analysis of the greedy algorithm that always chooses the action that
currently looks optimal, improving on prior results to show that a greedy
approach almost matches the best possible Bayesian regret rate of any other
algorithm on the same problem instance whenever the diversity conditions hold,
and that this regret is at most $\tilde{O}(T^{1/3})$. Returning to group-level
effects, we show that under the same conditions, negative group externalities
essentially vanish under the greedy algorithm. Together, our results uncover a
sharp contrast between the high externalities that exist in the worst case, and
the ability to remove all externalities if the data is sufficiently diverse.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Raghavan_M/0/1/0/all/0/1&quot;&gt;Manish Raghavan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Slivkins_A/0/1/0/all/0/1&quot;&gt;Aleksandrs Slivkins&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vaughan_J/0/1/0/all/0/1&quot;&gt;Jennifer Wortman Vaughan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_Z/0/1/0/all/0/1&quot;&gt;Zhiwei Steven Wu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00548">
<title>A Fast and Scalable Joint Estimator for Integrating Additional Knowledge in Learning Multiple Related Sparse Gaussian Graphical Models. (arXiv:1806.00548v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.00548</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the problem of including additional knowledge in estimating
sparse Gaussian graphical models (sGGMs) from aggregated samples, arising often
in bioinformatics and neuroimaging applications. Previous joint sGGM estimators
either fail to use existing knowledge or cannot scale-up to many tasks (large
$K$) under a high-dimensional (large $p$) situation. In this paper, we propose
a novel \underline{J}oint \underline{E}lementary \underline{E}stimator
incorporating additional \underline{K}nowledge (JEEK) to infer multiple related
sparse Gaussian Graphical models from large-scale heterogeneous data. Using
domain knowledge as weights, we design a novel hybrid norm as the minimization
objective to enforce the superposition of two weighted sparsity constraints,
one on the shared interactions and the other on the task-specific structural
patterns. This enables JEEK to elegantly consider various forms of existing
knowledge based on the domain at hand and avoid the need to design
knowledge-specific optimization. JEEK is solved through a fast and entry-wise
parallelizable solution that largely improves the computational efficiency of
the state-of-the-art $O(p^5K^4)$ to $O(p^2K^4)$. We conduct a rigorous
statistical analysis showing that JEEK achieves the same convergence rate
$O(\log(Kp)/n_{tot})$ as the state-of-the-art estimators that are much harder
to compute. Empirically, on multiple synthetic datasets and two real-world
data, JEEK outperforms the speed of the state-of-arts significantly while
achieving the same level of prediction accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_B/0/1/0/all/0/1&quot;&gt;Beilun Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sekhon_A/0/1/0/all/0/1&quot;&gt;Arshdeep Sekhon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qi_Y/0/1/0/all/0/1&quot;&gt;Yanjun Qi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00552">
<title>Bayesian approach to model-based extrapolation of nuclear observables. (arXiv:1806.00552v1 [nucl-th])</title>
<link>http://arxiv.org/abs/1806.00552</link>
<description rdf:parseType="Literal">&lt;p&gt;The mass, or binding energy, is the basis property of the atomic nucleus. It
determines its stability, and reaction and decay rates. Quantifying the nuclear
binding is important for understanding the origin of elements in the universe.
The astrophysical processes responsible for the nucleosynthesis in stars often
take place far from the valley of stability, where experimental masses are not
known. In such cases, missing nuclear information must be provided by
theoretical predictions using extreme extrapolations. Bayesian machine learning
techniques can be applied to improve predictions by taking full advantage of
the information contained in the deviations between experimental and calculated
masses. We consider 10 global models based on nuclear Density Functional Theory
as well as two more phenomenological mass models. The emulators of S2n
residuals and credibility intervals defining theoretical error bars are
constructed using Bayesian Gaussian processes and Bayesian neural networks. We
consider a large training dataset pertaining to nuclei whose masses were
measured before 2003. For the testing datasets, we considered those exotic
nuclei whose masses have been determined after 2003. We then carried out
extrapolations towards the 2n dripline. While both Gaussian processes and
Bayesian neural networks reduce the rms deviation from experiment
significantly, GP offers a better and much more stable performance. The
increase in the predictive power is quite astonishing: the resulting rms
deviations from experiment on the testing dataset are similar to those of more
phenomenological models. The empirical coverage probability curves we obtain
match very well the reference values which is highly desirable to ensure
honesty of uncertainty quantification, and the estimated credibility intervals
on predictions make it possible to evaluate predictive power of individual
models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/nucl-th/1/au:+Neufcourt_L/0/1/0/all/0/1&quot;&gt;L&amp;#xe9;o Neufcourt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/nucl-th/1/au:+Cao_Y/0/1/0/all/0/1&quot;&gt;Yuchen Cao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/nucl-th/1/au:+Nazarewicz_W/0/1/0/all/0/1&quot;&gt;Witold Nazarewicz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/nucl-th/1/au:+Viens_F/0/1/0/all/0/1&quot;&gt;Frederi Viens&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00556">
<title>Intrinsic Isometric Manifold Learning with Application to Localization. (arXiv:1806.00556v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.00556</link>
<description rdf:parseType="Literal">&lt;p&gt;Data living on manifolds commonly appear in many applications. We show that
under certain conditions, it is possible to construct an intrinsic and
isometric data representation, which respects an underlying latent intrinsic
manifold geometry. Namely, instead of learning the structure of the observed
manifold, we view the observed data only as a proxy and learn the structure of
a latent unobserved intrinsic manifold. For this purpose, we build a new metric
and propose a method for robust estimation by assuming mild statistical priors
and by using artificial neural networks as a mechanism for metric
regularization and parameterization. We show successful application to
unsupervised indoor localization in ad-hoc sensor networks. Specifically, we
show that our proposed method facilitates accurate localization of a moving
agent from imaging data it collects. Importantly, our method is applied in the
same way to two different imaging modalities, thereby demonstrating its
intrinsic capabilities.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Schwartz_A/0/1/0/all/0/1&quot;&gt;Ariel Schwartz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Talmon_R/0/1/0/all/0/1&quot;&gt;Ronen Talmon&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00569">
<title>Variable Selection for Nonparametric Learning with Power Series Kernels. (arXiv:1806.00569v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.00569</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we propose a variable selection method for general
nonparametric kernel-based estimation. The proposed method consists of
two-stage estimation: (1) construct a consistent estimator of the target
function, (2) approximate the estimator using a few variables by l1-type
penalized estimation. We see that the proposed method can be applied to various
kernel nonparametric estimation such as kernel ridge regression, kernel-based
density and density-ratio estimation. We prove that the proposed method has the
property of the variable selection consistency when the power series kernel is
used. This result is regarded as an extension of the variable selection
consistency for the non-negative garrote to the kernel-based estimators.
Several experiments including simulation studies and real data applications
show the effectiveness of the proposed method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Matsui_K/0/1/0/all/0/1&quot;&gt;Kota Matsui&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kumagai_W/0/1/0/all/0/1&quot;&gt;Wataru Kumagai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kanamori_K/0/1/0/all/0/1&quot;&gt;Kenta Kanamori&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Nishikimi_M/0/1/0/all/0/1&quot;&gt;Mitsuaki Nishikimi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kanamori_T/0/1/0/all/0/1&quot;&gt;Takafumi Kanamori&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00640">
<title>Binary Classification with Karmic, Threshold-Quasi-Concave Metrics. (arXiv:1806.00640v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.00640</link>
<description rdf:parseType="Literal">&lt;p&gt;Complex performance measures, beyond the popular measure of accuracy, are
increasingly being used in the context of binary classification. These complex
performance measures are typically not even decomposable, that is, the loss
evaluated on a batch of samples cannot typically be expressed as a sum or
average of losses evaluated at individual samples, which in turn requires new
theoretical and methodological developments beyond standard treatments of
supervised learning. In this paper, we advance this understanding of binary
classification for complex performance measures by identifying two key
properties: a so-called Karmic property, and a more technical
threshold-quasi-concavity property, which we show is milder than existing
structural assumptions imposed on performance measures. Under these properties,
we show that the Bayes optimal classifier is a threshold function of the
conditional probability of positive class. We then leverage this result to come
up with a computationally practical plug-in classifier, via a novel threshold
estimator, and further, provide a novel statistical analysis of classification
error with respect to complex performance measures.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yan_B/0/1/0/all/0/1&quot;&gt;Bowei Yan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Koyejo_O/0/1/0/all/0/1&quot;&gt;Oluwasanmi Koyejo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhong_K/0/1/0/all/0/1&quot;&gt;Kai Zhong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ravikumar_P/0/1/0/all/0/1&quot;&gt;Pradeep Ravikumar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00656">
<title>Scraping and Preprocessing Commercial Auction Data for Fraud Classification. (arXiv:1806.00656v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.00656</link>
<description rdf:parseType="Literal">&lt;p&gt;In the last three decades, we have seen a significant increase in trading
goods and services through online auctions. However, this business created an
attractive environment for malicious moneymakers who can commit different types
of fraud activities, such as Shill Bidding (SB). The latter is predominant
across many auctions but this type of fraud is difficult to detect due to its
similarity to normal bidding behaviour. The unavailability of SB datasets makes
the development of SB detection and classification models burdensome.
Furthermore, to implement efficient SB detection models, we should produce SB
data from actual auctions of commercial sites. In this study, we first scraped
a large number of eBay auctions of a popular product. After preprocessing the
raw auction data, we build a high-quality SB dataset based on the most reliable
SB strategies. The aim of our research is to share the preprocessed auction
dataset as well as the SB training (unlabelled) dataset, thereby researchers
can apply various machine learning techniques by using authentic data of
auctions and fraud.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alzahrani_A/0/1/0/all/0/1&quot;&gt;Ahmad Alzahrani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sadaoui_S/0/1/0/all/0/1&quot;&gt;Samira Sadaoui&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00663">
<title>Locally Interpretable Models and Effects based on Supervised Partitioning (LIME-SUP). (arXiv:1806.00663v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.00663</link>
<description rdf:parseType="Literal">&lt;p&gt;Supervised Machine Learning (SML) algorithms such as Gradient Boosting,
Random Forest, and Neural Networks have become popular in recent years due to
their increased predictive performance over traditional statistical methods.
This is especially true with large data sets (millions or more observations and
hundreds to thousands of predictors). However, the complexity of the SML models
makes them opaque and hard to interpret without additional tools. There has
been a lot of interest recently in developing global and local diagnostics for
interpreting and explaining SML models. In this paper, we propose locally
interpretable models and effects based on supervised partitioning (trees)
referred to as LIME-SUP. This is in contrast with the KLIME approach that is
based on clustering the predictor space. We describe LIME-SUP based on fitting
trees to the fitted response (LIM-SUP-R) as well as the derivatives of the
fitted response (LIME-SUP-D). We compare the results with KLIME and describe
its advantages using simulation and real data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hu_L/0/1/0/all/0/1&quot;&gt;Linwei Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chen_J/0/1/0/all/0/1&quot;&gt;Jie Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Nair_V/0/1/0/all/0/1&quot;&gt;Vijayan N. Nair&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sudjianto_A/0/1/0/all/0/1&quot;&gt;Agus Sudjianto&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00667">
<title>Idealised Bayesian Neural Networks Cannot Have Adversarial Examples: Theoretical and Empirical Study. (arXiv:1806.00667v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.00667</link>
<description rdf:parseType="Literal">&lt;p&gt;We prove that idealised discriminative Bayesian neural networks, capturing
perfect epistemic uncertainty, cannot have adversarial examples: Techniques for
crafting adversarial examples will necessarily fail to generate perturbed
images which fool the classifier. This suggests why MC dropout-based techniques
have been observed to be fairly robust to adversarial examples. We support our
claims mathematically and empirically. We experiment with HMC on synthetic data
derived from MNIST for which we know the ground truth image density, showing
that near-perfect epistemic uncertainty correlates to density under image
manifold, and that adversarial images lie off the manifold. Using our new-found
insights we suggest a new attack for MC dropout-based models by looking for
imperfections in uncertainty estimation, and also suggest a mitigation. Lastly,
we demonstrate our mitigation on a cats-vs-dogs image classification task with
a VGG13 variant.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gal_Y/0/1/0/all/0/1&quot;&gt;Yarin Gal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Smith_L/0/1/0/all/0/1&quot;&gt;Lewis Smith&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00672">
<title>Optimal Clustering under Uncertainty. (arXiv:1806.00672v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.00672</link>
<description rdf:parseType="Literal">&lt;p&gt;Classical clustering algorithms typically either lack an underlying
probability framework to make them predictive or focus on parameter estimation
rather than defining and minimizing a notion of error. Recent work addresses
these issues by developing a probabilistic framework based on the theory of
random labeled point processes and characterizing a Bayes clusterer that
minimizes the number of misclustered points. The Bayes clusterer is analogous
to the Bayes classifier. Whereas determining a Bayes classifier requires full
knowledge of the feature-label distribution, deriving a Bayes clusterer
requires full knowledge of the point process. When uncertain of the point
process, one would like to find a robust clusterer that is optimal over the
uncertainty, just as one may find optimal robust classifiers with uncertain
feature-label distributions. Herein, we derive an optimal robust clusterer by
first finding an effective random point process that incorporates all
randomness within its own probabilistic structure and from which a Bayes
clusterer can be derived that provides an optimal robust clusterer relative to
the uncertainty. This is analogous to the use of effective class-conditional
distributions in robust classification. After evaluating the performance of
robust clusterers in synthetic mixtures of Gaussians models, we apply the
framework to granular imaging, where we make use of the asymptotic
granulometric moment theory for granular images to relate robust clustering
theory to the application.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Dalton_L/0/1/0/all/0/1&quot;&gt;Lori A. Dalton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Benalcazar_M/0/1/0/all/0/1&quot;&gt;Marco E. Benalc&amp;#xe1;zar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Dougherty_E/0/1/0/all/0/1&quot;&gt;Edward R. Dougherty&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00676">
<title>A Geometric Approach for Real-time Monitoring of Dynamic Large Scale Graphs: AS-level graphs illustrated. (arXiv:1806.00676v1 [cs.NI])</title>
<link>http://arxiv.org/abs/1806.00676</link>
<description rdf:parseType="Literal">&lt;p&gt;The monitoring of large dynamic networks is a major chal- lenge for a wide
range of application. The complexity stems from properties of the underlying
graphs, in which slight local changes can lead to sizable variations of global
prop- erties, e.g., under certain conditions, a single link cut that may be
overlooked during monitoring can result in splitting the graph into two
disconnected components. Moreover, it is often difficult to determine whether a
change will propagate globally or remain local. Traditional graph theory
measure such as the centrality or the assortativity of the graph are not
satisfying to characterize global properties of the graph. In this paper, we
tackle the problem of real-time monitoring of dynamic large scale graphs by
developing a geometric approach that leverages notions of geometric curvature
and recent development in graph embeddings using Ollivier-Ricci curvature [47].
We illustrate the use of our method by consid- ering the practical case of
monitoring dynamic variations of global Internet using topology changes
information provided by combining several BGP feeds. In particular, we use our
method to detect major events and changes via the geometry of the embedding of
the graph.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Salamatian_L/0/1/0/all/0/1&quot;&gt;Loqman Salamatian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kaafar_D/0/1/0/all/0/1&quot;&gt;Dali Kaafar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Salamatian_K/0/1/0/all/0/1&quot;&gt;Kav&amp;#xe9; Salamatian&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00685">
<title>Hierarchical Attention-Based Recurrent Highway Networks for Time Series Prediction. (arXiv:1806.00685v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.00685</link>
<description rdf:parseType="Literal">&lt;p&gt;Time series prediction has been studied in a variety of domains. However, it
is still challenging to predict future series given historical observations and
past exogenous data. Existing methods either fail to consider the interactions
among different components of exogenous variables which may affect the
prediction accuracy, or cannot model the correlations between exogenous data
and target data. Besides, the inherent temporal dynamics of exogenous data are
also related to the target series prediction, and thus should be considered as
well. To address these issues, we propose an end-to-end deep learning model,
i.e., Hierarchical attention-based Recurrent Highway Network (HRHN), which
incorporates spatio-temporal feature extraction of exogenous variables and
temporal dynamics modeling of target variables into a single framework.
Moreover, by introducing the hierarchical attention mechanism, HRHN can
adaptively select the relevant exogenous features in different semantic levels.
We carry out comprehensive empirical evaluations with various methods over
several datasets, and show that HRHN outperforms the state of the arts in time
series prediction, especially in capturing sudden changes and sudden
oscillations of time series.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tao_Y/0/1/0/all/0/1&quot;&gt;Yunzhe Tao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ma_L/0/1/0/all/0/1&quot;&gt;Lin Ma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_W/0/1/0/all/0/1&quot;&gt;Weizhong Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Jian Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_W/0/1/0/all/0/1&quot;&gt;Wei Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Du_Q/0/1/0/all/0/1&quot;&gt;Qiang Du&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00701">
<title>On Multi-Layer Basis Pursuit, Efficient Algorithms and Convolutional Neural Networks. (arXiv:1806.00701v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.00701</link>
<description rdf:parseType="Literal">&lt;p&gt;Parsimonious representations in data modeling are ubiquitous and central for
processing information. Motivated by the recent Multi-Layer Convolutional
Sparse Coding (ML-CSC) model, we herein generalize the traditional Basis
Pursuit regression problem to a multi-layer setting, introducing similar sparse
enforcing penalties at different representation layers in a symbiotic relation
between synthesis and analysis sparse priors. We propose and analyze different
iterative algorithms to solve this new problem in practice. We prove that the
presented multi-layer Iterative Soft Thresholding (ML-ISTA) and multi-layer
Fast ISTA (ML-FISTA) converge to the global optimum of our multi-layer
formulation at a rate of $\mathcal{O}(1/k)$ and $\mathcal{O}(1/k^2)$,
respectively. We further show how these algorithms effectively implement
particular recurrent neural networks that generalize feed-forward architectures
without any increase in the number of parameters. We demonstrate the different
architectures resulting from unfolding the iterations of the proposed
multi-layer pursuit algorithms, providing a principled way to construct deep
recurrent CNNs from feed-forward ones. We demonstrate the emerging
constructions by training them in an end-to-end manner, consistently improving
the performance of classical networks without introducing extra filters or
parameters.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sulam_J/0/1/0/all/0/1&quot;&gt;Jeremias Sulam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aberdam_A/0/1/0/all/0/1&quot;&gt;Aviad Aberdam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Elad_M/0/1/0/all/0/1&quot;&gt;Michael Elad&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00720">
<title>Generalized Robust Bayesian Committee Machine for Large-scale Gaussian Process Regression. (arXiv:1806.00720v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.00720</link>
<description rdf:parseType="Literal">&lt;p&gt;In order to scale standard Gaussian process (GP) regression to large-scale
datasets, aggregation models employ factorized training process and then
combine predictions from distributed experts. The state-of-the-art aggregation
models, however, either provide inconsistent predictions or require
time-consuming aggregation process. We first prove the inconsistency of typical
aggregations using disjoint or random data partition, and then present a
consistent yet efficient aggregation model for large-scale GP. The proposed
model inherits the advantages of aggregations, e.g., closed-form inference and
aggregation, parallelization and distributed computing. Furthermore,
theoretical and empirical analyses reveal that the new aggregation model
performs better due to the consistent predictions that converge to the true
underlying function when the training size approaches infinity.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Liu_H/0/1/0/all/0/1&quot;&gt;Haitao Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Cai_J/0/1/0/all/0/1&quot;&gt;Jianfei Cai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yi Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ong_Y/0/1/0/all/0/1&quot;&gt;Yew-Soon Ong&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00728">
<title>Data-Free/Data-Sparse Softmax Parameter Estimation with Structured Class Geometries. (arXiv:1806.00728v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.00728</link>
<description rdf:parseType="Literal">&lt;p&gt;This note considers softmax parameter estimation when little/no labeled
training data is available, but a priori information about the relative
geometry of class label log-odds boundaries is available. It is shown that
`data-free&apos; softmax model synthesis corresponds to solving a linear system of
parameter equations, wherein desired dominant class log-odds boundaries are
encoded via convex polytopes that decompose the input feature space. When
solvable, the linear equations yield closed-form softmax parameter solution
families using class boundary polytope specifications only. This allows softmax
parameter learning to be implemented without expensive brute force data
sampling and numerical optimization. The linear equations can also be adapted
to constrained maximum likelihood estimation in data-sparse settings. Since
solutions may also fail to exist for the linear parameter equations derived
from certain polytope specifications, it is thus also shown that there exist
probabilistic classification problems over m convexly separable classes for
which the log-odds boundaries cannot be learned using an m-class softmax model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ahmed_N/0/1/0/all/0/1&quot;&gt;Nisar Ahmed&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00775">
<title>Exploration in Structured Reinforcement Learning. (arXiv:1806.00775v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.00775</link>
<description rdf:parseType="Literal">&lt;p&gt;We address reinforcement learning problems with finite state and action
spaces where the underlying MDP has some known structure that could be
potentially exploited to minimize the exploration of suboptimal (state, action)
pairs. For any arbitrary structure, we derive problem-specific regret lower
bounds satisfied by any learning algorithm. These lower bounds are made
explicit for unstructured MDPs and for those whose transition probabilities and
average reward function are Lipschitz continuous w.r.t. the state and action.
For Lipschitz MDPs, the bounds are shown not to scale with the sizes $S$ and
$A$ of the state and action spaces, i.e., they are smaller than $c \log T$
where $T$ is the time horizon and the constant $c$ only depends on the
Lipschitz structure, the span of the bias function, and the minimal action
sub-optimality gap. This contrasts with unstructured MDPs where the regret
lower bound typically scales as $SA \log T$ . We devise DEL (Directed
Exploration Learning), an algorithm that matches our regret lower bounds. We
further simplify the algorithm for Lipschitz MDPs, and show that the simplified
version is still able to efficiently exploit the structure.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ok_J/0/1/0/all/0/1&quot;&gt;Jungseul Ok&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Proutiere_A/0/1/0/all/0/1&quot;&gt;Alexandre Proutiere&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tranos_D/0/1/0/all/0/1&quot;&gt;Damianos Tranos&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00811">
<title>Causal Inference with Noisy and Missing Covariates via Matrix Factorization. (arXiv:1806.00811v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.00811</link>
<description rdf:parseType="Literal">&lt;p&gt;Valid causal inference in observational studies often requires controlling
for confounders. However, in practice measurements of confounders may be noisy,
and can lead to biased estimates of causal effects. We show that we can reduce
the bias caused by measurement noise using a large number of noisy measurements
of the underlying confounders. We propose the use of matrix factorization to
infer the confounders from noisy covariates, a flexible and principled
framework that adapts to missing values, accommodates a wide variety of data
types, and can augment many causal inference methods. We bound the error for
the induced average treatment effect estimator and show it is consistent in a
linear regression setting, using Exponential Family Matrix Completion
preprocessing. We demonstrate the effectiveness of the proposed procedure in
numerical experiments with both synthetic data and real clinical data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kallus_N/0/1/0/all/0/1&quot;&gt;Nathan Kallus&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mao_X/0/1/0/all/0/1&quot;&gt;Xiaojie Mao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Udell_M/0/1/0/all/0/1&quot;&gt;Madeleine Udell&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00848">
<title>Learning Graphs from Data: A Signal Representation Perspective. (arXiv:1806.00848v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.00848</link>
<description rdf:parseType="Literal">&lt;p&gt;The construction of a meaningful graph topology plays a crucial role in the
effective representation, processing, analysis and visualization of structured
data. When a natural choice of the graph is not readily available from the
datasets, it is thus desirable to infer or learn a graph topology from the
data. In this tutorial overview, we survey solutions to the problem of graph
learning, including classical viewpoints from statistics and physics, and more
recent approaches that adopt a graph signal processing (GSP) perspective. We
further emphasize the conceptual similarities and differences between classical
and GSP graph inference methods and highlight the potential advantage of the
latter in a number of theoretical and practical scenarios. We conclude with
several open issues and challenges that are keys to the design of future signal
processing and machine learning algorithms for learning graphs from data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dong_X/0/1/0/all/0/1&quot;&gt;Xiaowen Dong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Thanou_D/0/1/0/all/0/1&quot;&gt;Dorina Thanou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rabbat_M/0/1/0/all/0/1&quot;&gt;Michael Rabbat&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Frossard_P/0/1/0/all/0/1&quot;&gt;Pascal Frossard&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00875">
<title>Deploying Customized Data Representation and Approximate Computing in Machine Learning Applications. (arXiv:1806.00875v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.00875</link>
<description rdf:parseType="Literal">&lt;p&gt;Major advancements in building general-purpose and customized hardware have
been one of the key enablers of versatility and pervasiveness of machine
learning models such as deep neural networks. To sustain this ubiquitous
deployment of machine learning models and cope with their computational and
storage complexity, several solutions such as low-precision representation of
model parameters using fixed-point representation and deploying approximate
arithmetic operations have been employed. Studying the potency of such
solutions in different applications requires integrating them into existing
machine learning frameworks for high-level simulations as well as implementing
them in hardware to analyze their effects on power/energy dissipation,
throughput, and chip area. Lop is a library for design space exploration that
bridges the gap between machine learning and efficient hardware realization. It
comprises a Python module, which can be integrated with some of the existing
machine learning frameworks and implements various customizable data
representations including fixed-point and floating-point as well as approximate
arithmetic operations.Furthermore, it includes a highly-parameterized Scala
module, which allows synthesizing hardware based on the said data
representations and arithmetic operations. Lop allows researchers and designers
to quickly compare quality of their models using various data representations
and arithmetic operations in Python and contrast the hardware cost of viable
representations by synthesizing them on their target platforms (e.g., FPGA or
ASIC). To the best of our knowledge, Lop is the first library that allows both
software simulation and hardware realization using customized data
representations and approximate computing techniques.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nazemi_M/0/1/0/all/0/1&quot;&gt;Mahdi Nazemi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pedram_M/0/1/0/all/0/1&quot;&gt;Massoud Pedram&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00877">
<title>Multi-Agent Reinforcement Learning via Double Averaging Primal-Dual Optimization. (arXiv:1806.00877v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.00877</link>
<description rdf:parseType="Literal">&lt;p&gt;Despite the success of single-agent reinforcement learning, multi-agent
reinforcement learning (MARL) remains challenging due to complex interactions
between agents. Motivated by decentralized applications such as sensor
networks, swarm robotics, and power grids, we study policy evaluation in MARL,
where agents with jointly observed state-action pairs and private local rewards
collaborate to learn the value of a given policy.
&lt;/p&gt;
&lt;p&gt;In this paper, we propose a double averaging scheme, where each agent
iteratively performs averaging over both space and time to incorporate
neighboring gradient information and local reward information, respectively. We
prove that the proposed algorithm converges to the optimal solution at a global
geometric rate. In particular, such an algorithm is built upon a primal-dual
reformulation of the mean squared projected Bellman error minimization problem,
which gives rise to a decentralized convex-concave saddle-point problem. To the
best of our knowledge, the proposed double averaging primal-dual optimization
algorithm is the first to achieve fast finite-time convergence on decentralized
convex-concave saddle-point problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wai_H/0/1/0/all/0/1&quot;&gt;Hoi-To Wai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_Z/0/1/0/all/0/1&quot;&gt;Zhuoran Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zhaoran Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hong_M/0/1/0/all/0/1&quot;&gt;Mingyi Hong&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00880">
<title>Disconnected Manifold Learning for Generative Adversarial Networks. (arXiv:1806.00880v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.00880</link>
<description rdf:parseType="Literal">&lt;p&gt;Real images often lie on a union of disjoint manifolds rather than one
globally connected manifold, and this can cause several difficulties for the
training of common Generative Adversarial Networks (GANs). In this work, we
first show that single generator GANs are unable to correctly model a
distribution supported on a disconnected manifold, and investigate how sample
quality, mode collapse and local convergence are affected by this. Next, we
show how using a collection of generators can address this problem, providing
new insights into the success of such multi-generator GANs. Finally, we explain
the serious issues caused by considering a fixed prior over the collection of
generators and propose a novel approach for learning the prior and inferring
the necessary number of generators without any supervision. Our proposed
modifications can be applied on top of any other GAN model to enable learning
of distributions supported on disconnected manifolds. We conduct several
experiments to illustrate the aforementioned shortcoming of GANs, its
consequences in practice, and the effectiveness of our proposed modifications
in alleviating these issues.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khayatkhoei_M/0/1/0/all/0/1&quot;&gt;Mahyar Khayatkhoei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Singh_M/0/1/0/all/0/1&quot;&gt;Maneesh Singh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Elgammal_A/0/1/0/all/0/1&quot;&gt;Ahmed Elgammal&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00892">
<title>Conservative Exploration using Interleaving. (arXiv:1806.00892v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.00892</link>
<description rdf:parseType="Literal">&lt;p&gt;In many practical problems, a learning agent may want to learn the best
action in hindsight without ever taking a bad action, which is significantly
worse than the default production action. In general, this is impossible
because the agent has to explore unknown actions, some of which can be bad, to
learn better actions. However, when the actions are combinatorial, this may be
possible if the unknown action can be evaluated by interleaving it with the
production action. We formalize this concept as learning in stochastic
combinatorial semi-bandits with exchangeable actions. We design efficient
learning algorithms for this problem, bound their n-step regret, and evaluate
them on both synthetic and real-world problems. Our real-world experiments show
that our algorithms can learn to recommend K most attractive movies without
ever violating a strict production constraint, both overall and subject to a
diversity constraint.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Katariya_S/0/1/0/all/0/1&quot;&gt;Sumeet Katariya&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kveton_B/0/1/0/all/0/1&quot;&gt;Branislav Kveton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wen_Z/0/1/0/all/0/1&quot;&gt;Zheng Wen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Potluru_V/0/1/0/all/0/1&quot;&gt;Vamsi K. Potluru&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00973">
<title>Sequential Test for the Lowest Mean: From Thompson to Murphy Sampling. (arXiv:1806.00973v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.00973</link>
<description rdf:parseType="Literal">&lt;p&gt;Learning the minimum/maximum mean among a finite set of distributions is a
fundamental sub-task in planning, game tree search and reinforcement learning.
We formalize this learning task as the problem of sequentially testing how the
minimum mean among a finite set of distributions compares to a given threshold.
We develop refined non-asymptotic lower bounds, which show that optimality
mandates very different sampling behavior for a low vs high true minimum. We
show that Thompson Sampling and the intuitive Lower Confidence Bounds policy
each nail only one of these cases. We develop a novel approach that we call
Murphy Sampling. Even though it entertains exclusively low true minima, we
prove that MS is optimal for both possibilities. We then design advanced
self-normalized deviation inequalities, fueling more aggressive stopping rules.
We complement our theoretical guarantees by experiments showing that MS works
best in practice.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kaufmann_E/0/1/0/all/0/1&quot;&gt;Emilie Kaufmann&lt;/a&gt; (SEQUEL, CNRS, CRIStAL), &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Koolen_W/0/1/0/all/0/1&quot;&gt;Wouter Koolen&lt;/a&gt; (CWI), &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Garivier_A/0/1/0/all/0/1&quot;&gt;Aurelien Garivier&lt;/a&gt; (IMT)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.00981">
<title>Automatic Clustering of a Network Protocol with Weakly-Supervised Clustering. (arXiv:1806.00981v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.00981</link>
<description rdf:parseType="Literal">&lt;p&gt;Abstraction is a fundamental part when learning behavioral models of systems.
Usually the process of abstraction is manually defined by domain experts. This
paper presents a method to perform automatic abstraction for network protocols.
In particular a weakly supervised clustering algorithm is used to build an
abstraction with a small vocabulary size for the widely used TLS protocol. To
show the effectiveness of the proposed method we compare the resultant abstract
messages to a manually constructed (reference) abstraction. With a small amount
of side-information in the form of a few labeled examples this method finds an
abstraction that matches the reference abstraction perfectly.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schrank_T/0/1/0/all/0/1&quot;&gt;Tobias Schrank&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pernkopf_F/0/1/0/all/0/1&quot;&gt;Franz Pernkopf&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.01003">
<title>Distributed Learning from Interactions in Social Networks. (arXiv:1806.01003v1 [cs.SY])</title>
<link>http://arxiv.org/abs/1806.01003</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider a network scenario in which agents can evaluate each other
according to a score graph that models some interactions. The goal is to design
a distributed protocol, run by the agents, that allows them to learn their
unknown state among a finite set of possible values. We propose a Bayesian
framework in which scores and states are associated to probabilistic events
with unknown parameters and hyperparameters, respectively. We show that each
agent can learn its state by means of a local Bayesian classifier and a
(centralized) Maximum-Likelihood (ML) estimator of parameter-hyperparameter
that combines plain ML and Empirical Bayes approaches. By using tools from
graphical models, which allow us to gain insight on conditional dependencies of
scores and states, we provide a relaxed probabilistic model that ultimately
leads to a parameter-hyperparameter estimator amenable to distributed
computation. To highlight the appropriateness of the proposed relaxation, we
demonstrate the distributed estimators on a social interaction set-up for user
profiling.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sasso_F/0/1/0/all/0/1&quot;&gt;Francesco Sasso&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Coluccia_A/0/1/0/all/0/1&quot;&gt;Angelo Coluccia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Notarstefano_G/0/1/0/all/0/1&quot;&gt;Giuseppe Notarstefano&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.01047">
<title>Normative Modeling of Neuroimaging Data using Scalable Multi-Task Gaussian Processes. (arXiv:1806.01047v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.01047</link>
<description rdf:parseType="Literal">&lt;p&gt;Normative modeling has recently been proposed as an alternative for the
case-control approach in modeling heterogeneity within clinical cohorts.
Normative modeling is based on single-output Gaussian process regression that
provides coherent estimates of uncertainty required by the method but does not
consider spatial covariance structure. Here, we introduce a scalable multi-task
Gaussian process regression (S-MTGPR) approach to address this problem. To this
end, we exploit a combination of a low-rank approximation of the spatial
covariance matrix with algebraic properties of Kronecker product in order to
reduce the computational complexity of Gaussian process regression in
high-dimensional output spaces. On a public fMRI dataset, we show that S-MTGPR:
1) leads to substantial computational improvements that allow us to estimate
normative models for high-dimensional fMRI data whilst accounting for spatial
structure in data; 2) by modeling both spatial and across-sample variances, it
provides higher sensitivity in novelty detection scenarios.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kia_S/0/1/0/all/0/1&quot;&gt;Seyed Mostafa Kia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Marquand_A/0/1/0/all/0/1&quot;&gt;Andre Marquand&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.01052">
<title>Neural Network-Based Equations for Predicting PGA and PGV in Texas, Oklahoma, and Kansas. (arXiv:1806.01052v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.01052</link>
<description rdf:parseType="Literal">&lt;p&gt;Parts of Texas, Oklahoma, and Kansas have experienced increased rates of
seismicity in recent years, providing new datasets of earthquake recordings to
develop ground motion prediction models for this particular region of the
Central and Eastern North America (CENA). This paper outlines a framework for
using Artificial Neural Networks (ANNs) to develop attenuation models from the
ground motion recordings in this region. While attenuation models exist for the
CENA, concerns over the increased rate of seismicity in this region necessitate
investigation of ground motions prediction models particular to these states.
To do so, an ANN-based framework is proposed to predict peak ground
acceleration (PGA) and peak ground velocity (PGV) given magnitude, earthquake
source-to-site distance, and shear wave velocity. In this framework,
approximately 4,500 ground motions with magnitude greater than 3.0 recorded in
these three states (Texas, Oklahoma, and Kansas) since 2005 are considered.
Results from this study suggest that existing ground motion prediction models
developed for CENA do not accurately predict the ground motion intensity
measures for earthquakes in this region, especially for those with low
source-to-site distances or on very soft soil conditions. The proposed ANN
models provide much more accurate prediction of the ground motion intensity
measures at all distances and magnitudes. The proposed ANN models are also
converted to relatively simple mathematical equations so that engineers can
easily use them to predict the ground motion intensity measures for future
events. Finally, through a sensitivity analysis, the contributions of the
predictive parameters to the prediction of the considered intensity measures
are investigated.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Khosravikia_F/0/1/0/all/0/1&quot;&gt;Farid Khosravikia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zeinali_Y/0/1/0/all/0/1&quot;&gt;Yasaman Zeinali&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Nagy_Z/0/1/0/all/0/1&quot;&gt;Zoltan Nagy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Clayton_P/0/1/0/all/0/1&quot;&gt;Patricia Clayton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rathje_E/0/1/0/all/0/1&quot;&gt;Ellen M. Rathje&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.01059">
<title>iFair: Learning Individually Fair Data Representations for Algorithmic Decision Making. (arXiv:1806.01059v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.01059</link>
<description rdf:parseType="Literal">&lt;p&gt;People are rated and ranked, towards algorithmic decision making in an
increasing number of applications, typically based on machine learning.
Research on how to incorporate fairness into such tasks has prevalently pursued
the paradigm of group fairness: ensuring that each ethnic or social group
receives its fair share in the outcome of classifiers and rankings. In
contrast, the alternative paradigm of individual fairness has received
relatively little attention. This paper introduces a method for
probabilistically clustering user records into a low-rank representation that
captures individual fairness yet also achieves high accuracy in classification
and regression models. Our notion of individual fairness requires that users
who are similar in all task-relevant attributes such as job qualification, and
disregarding all potentially discriminating attributes such as gender, should
have similar outcomes. Since the case for fairness is ubiquitous across many
tasks, we aim to learn general representations that can be applied to arbitrary
downstream use-cases. We demonstrate the versatility of our method by applying
it to classification and learning-to-rank tasks on two real-world datasets. Our
experiments show substantial improvements over the best prior work for this
setting.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lahoti_P/0/1/0/all/0/1&quot;&gt;Preethi Lahoti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Weikum_G/0/1/0/all/0/1&quot;&gt;Gerhard Weikum&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gummadi_K/0/1/0/all/0/1&quot;&gt;Krishna P. Gummadi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.01083">
<title>Optimal Balancing of Time-Dependent Confounders for Marginal Structural Models. (arXiv:1806.01083v1 [stat.ME])</title>
<link>http://arxiv.org/abs/1806.01083</link>
<description rdf:parseType="Literal">&lt;p&gt;Marginal structural models (MSMs) estimate the causal effect of a
time-varying treatment in the presence of time-dependent confounding via
weighted regression. The standard approach of using inverse probability of
treatment weighting (IPTW) can lead to high-variance estimates due to extreme
weights and be sensitive to model misspecification. Various methods have been
proposed to partially address this, including truncation and stabilized-IPTW to
temper extreme weights and covariate balancing propensity score (CBPS) to
address treatment model misspecification. In this paper, we present Kernel
Optimal Weighting (KOW), a convex-optimization-based approach that finds
weights for fitting the MSM that optimally balance time-dependent confounders
while simultaneously controlling for precision, directly addressing the above
limitations. KOW directly minimizes the error in estimation due to
time-dependent confounding via a new decomposition as a functional. We further
extend KOW to control for informative censoring. We evaluate the performance of
KOW in a simulation study, comparing it with IPTW, stabilized-IPTW, and CBPS.
We demonstrate the use of KOW in studying the effect of treatment initiation on
time-to-death among people living with HIV and the effect of negative
advertising on elections in the United States.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kallus_N/0/1/0/all/0/1&quot;&gt;Nathan Kallus&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Santacatterina_M/0/1/0/all/0/1&quot;&gt;Michele Santacatterina&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.01094">
<title>groupICA: Independent component analysis for grouped data. (arXiv:1806.01094v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.01094</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce groupICA, a novel independent component analysis (ICA) algorithm
which decomposes linearly mixed multivariate observations into independent
components that are corrupted (and rendered dependent) by hidden group-wise
confounding. It extends the ordinary ICA model in a theoretically sound and
explicit way to incorporate group-wise (or environment-wise) structure in data
and hence provides a justified alternative to the use of ICA on data blindly
pooled across groups. In addition to our theoretical framework, we explain its
causal interpretation and motivation, provide an efficient estimation procedure
and prove identifiability of the unmixing matrix under mild assumptions.
Finally, we illustrate the performance and robustness of our method on
simulated data and run experiments on publicly available EEG datasets
demonstrating the applicability to real-world scenarios. We provide a
scikit-learn compatible pip-installable Python package groupICA as well as R
and Matlab implementations accompanied by a documentation and an audible
example at https://sweichwald.de/groupICA.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pfister_N/0/1/0/all/0/1&quot;&gt;Niklas Pfister&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Weichwald_S/0/1/0/all/0/1&quot;&gt;Sebastian Weichwald&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Buhlmann_P/0/1/0/all/0/1&quot;&gt;Peter B&amp;#xfc;hlmann&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Scholkopf_B/0/1/0/all/0/1&quot;&gt;Bernhard Sch&amp;#xf6;lkopf&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.01145">
<title>Machines hear better when they have ears. (arXiv:1806.01145v1 [cs.SD])</title>
<link>http://arxiv.org/abs/1806.01145</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep-neural-network (DNN) based noise suppression systems yield significant
improvements over conventional approaches such as spectral subtraction and
non-negative matrix factorization, but do not generalize well to noise
conditions they were not trained for. In comparison to DNNs, humans show
remarkable noise suppression capabilities that yield successful speech
intelligibility under various adverse listening conditions and negative
signal-to-noise ratios (SNRs). Motivated by the excellent human performance,
this paper explores whether numerical models that simulate human cochlear
signal processing can be combined with DNNs to improve the robustness of DNN
based noise suppression systems. Five cochlear models were coupled to
fully-connected and recurrent NN-based noise suppression systems and were
trained and evaluated for a variety of noise conditions using objective
metrics: perceptual speech quality (PESQ), segmental SNR and cepstral distance.
The simulations show that biophysically-inspired cochlear models improve the
generalizability of DNN-based noise suppression systems for unseen noise and
negative SNRs. This approach thus leads to robust noise suppression systems
that are less sensitive to the noise type and noise level. Because cochlear
models capture the intrinsic nonlinearities and dynamics of peripheral auditory
processing, it is shown here that accounting for their deterministic signal
processing improves machine hearing and avoids overtraining of multi-layer
DNNs. We hence conclude that machines hear better when realistic cochlear
models are used at the input of DNNs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Baby_D/0/1/0/all/0/1&quot;&gt;Deepak Baby&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Verhulst_S/0/1/0/all/0/1&quot;&gt;Sarah Verhulst&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.01240">
<title>Diffeomorphic Learning. (arXiv:1806.01240v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1806.01240</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce in this paper a learning paradigm in which the training data is
transformed by a diffeomorphic transformation before prediction. The learning
algorithm minimizes a cost function evaluating the prediction error on the
training set penalized by the distance between the diffeomorphism and the
identity. The approach borrows ideas from shape analysis, in the way
diffeomorphisms are estimated for shape and image alignment, and brings them in
a previously unexplored setting, estimating, in particular diffeomorphisms in
much larger dimensions. After introducing the concept and describing a learning
algorithm, we present diverse applications, mostly with synthetic examples,
demonstrating the potential of the approach, as well as some of its current
room for improvement.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Younes_L/0/1/0/all/0/1&quot;&gt;Laurent Younes&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.01248">
<title>Dynamically Hierarchy Revolution: DirNet for Compressing Recurrent Neural Network on Mobile Devices. (arXiv:1806.01248v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.01248</link>
<description rdf:parseType="Literal">&lt;p&gt;Recurrent neural networks (RNNs) achieve cutting-edge performance on a
variety of problems. However, due to their high computational and memory
demands, deploying RNNs on resource constrained mobile devices is a challenging
task. To guarantee minimum accuracy loss with higher compression rate and
driven by the mobile resource requirement, we introduce a novel model
compression approach DirNet based on an optimized fast dictionary learning
algorithm, which 1) dynamically mines the dictionary atoms of the projection
dictionary matrix within layer to adjust the compression rate 2) adaptively
changes the sparsity of sparse codes cross the hierarchical layers.
Experimental results on language model and an ASR model trained with a 1000h
speech dataset demonstrate that our method significantly outperforms prior
approaches. Evaluated on off-the-shelf mobile devices, we are able to reduce
the size of original model by eight times with real-time model inference and
negligible accuracy loss.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_J/0/1/0/all/0/1&quot;&gt;Jie Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;Xiaolong Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_D/0/1/0/all/0/1&quot;&gt;Dawei Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yalin Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.01259">
<title>Learning a Code: Machine Learning for Approximate Non-Linear Coded Computation. (arXiv:1806.01259v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1806.01259</link>
<description rdf:parseType="Literal">&lt;p&gt;Machine learning algorithms are typically run on large scale, distributed
compute infrastructure that routinely face a number of unavailabilities such as
failures and temporary slowdowns. Adding redundant computations using
coding-theoretic tools called &quot;codes&quot; is an emerging technique to alleviate the
adverse effects of such unavailabilities. A code consists of an encoding
function that proactively introduces redundant computation and a decoding
function that reconstructs unavailable outputs using the available ones. Past
work focuses on using codes to provide resilience for linear computations and
specific iterative optimization algorithms. However, computations performed for
a variety of applications including inference on state-of-the-art machine
learning algorithms, such as neural networks, typically fall outside this
realm. In this paper, we propose taking a learning-based approach to designing
codes that can handle non-linear computations. We present carefully designed
neural network architectures and a training methodology for learning encoding
and decoding functions that produce approximate reconstructions of unavailable
computation results. We present extensive experimental results demonstrating
the effectiveness of the proposed approach: we show that the our learned codes
can accurately reconstruct $64 - 98\%$ of the unavailable predictions from
neural-network based image classifiers on the MNIST, Fashion-MNIST, and
CIFAR-10 datasets. To the best of our knowledge, this work proposes the first
learning-based approach for designing codes, and also presents the first
coding-theoretic solution that can provide resilience for any non-linear
(differentiable) computation. Our results show that learning can be an
effective technique for designing codes, and that learned codes are a highly
promising approach for bringing the benefits of coding to non-linear
computations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kosaian_J/0/1/0/all/0/1&quot;&gt;Jack Kosaian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rashmi_K/0/1/0/all/0/1&quot;&gt;K.V. Rashmi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Venkataraman_S/0/1/0/all/0/1&quot;&gt;Shivaram Venkataraman&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1806.01260">
<title>Digging Into Self-Supervised Monocular Depth Estimation. (arXiv:1806.01260v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1806.01260</link>
<description rdf:parseType="Literal">&lt;p&gt;Depth-sensing is important for both navigation and scene understanding.
However, procuring RGB images with corresponding depth data for training deep
models is challenging; large-scale, varied, datasets with ground truth training
data are scarce. Consequently, several recent methods have proposed treating
the training of monocular color-to-depth estimation networks as an image
reconstruction problem, thus forgoing the need for ground truth depth.
&lt;/p&gt;
&lt;p&gt;There are multiple concepts and design decisions for these networks that seem
sensible, but give mixed or surprising results when tested. For example,
binocular stereo as the source of self-supervision seems cumbersome and hard to
scale, yet results are less blurry compared to training with monocular videos.
Such decisions also interplay with questions about architectures, loss
functions, image scales, and motion handling. In this paper, we propose a
simple yet effective model, with several general architectural and loss
innovations, that surpasses all other self-supervised depth estimation
approaches on KITTI.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Godard_C/0/1/0/all/0/1&quot;&gt;Cl&amp;#xe9;ment Godard&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aodha_O/0/1/0/all/0/1&quot;&gt;Oisin Mac Aodha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Brostow_G/0/1/0/all/0/1&quot;&gt;Gabriel Brostow&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1307.8371">
<title>The Power of Localization for Efficiently Learning Linear Separators with Noise. (arXiv:1307.8371v9 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1307.8371</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce a new approach for designing computationally efficient learning
algorithms that are tolerant to noise, and demonstrate its effectiveness by
designing algorithms with improved noise tolerance guarantees for learning
linear separators.
&lt;/p&gt;
&lt;p&gt;We consider both the malicious noise model and the adversarial label noise
model. For malicious noise, where the adversary can corrupt both the label and
the features, we provide a polynomial-time algorithm for learning linear
separators in $\Re^d$ under isotropic log-concave distributions that can
tolerate a nearly information-theoretically optimal noise rate of $\eta =
\Omega(\epsilon)$. For the adversarial label noise model, where the
distribution over the feature vectors is unchanged, and the overall probability
of a noisy label is constrained to be at most $\eta$, we also give a
polynomial-time algorithm for learning linear separators in $\Re^d$ under
isotropic log-concave distributions that can handle a noise rate of $\eta =
\Omega\left(\epsilon\right)$.
&lt;/p&gt;
&lt;p&gt;We show that, in the active learning model, our algorithms achieve a label
complexity whose dependence on the error parameter $\epsilon$ is
polylogarithmic. This provides the first polynomial-time active learning
algorithm for learning linear separators in the presence of malicious noise or
adversarial label noise.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Awasthi_P/0/1/0/all/0/1&quot;&gt;Pranjal Awasthi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Balcan_M/0/1/0/all/0/1&quot;&gt;Maria Florina Balcan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Long_P/0/1/0/all/0/1&quot;&gt;Philip M. Long&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1610.09600">
<title>Super-resolution estimation of cyclic arrival rates. (arXiv:1610.09600v5 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1610.09600</link>
<description rdf:parseType="Literal">&lt;p&gt;Exploiting the fact that most arrival processes exhibit cyclic behaviour, we
propose a simple procedure for estimating the intensity of a nonhomogeneous
Poisson process. The estimator is the super-resolution analogue to Shao 2010
and Shao &amp;amp; Lii 2011, which is a sum of $p$ sinusoids where $p$ and the
frequency, amplitude, and phase of each wave are not known and need to be
estimated. This results in an interpretable yet flexible specification that is
suitable for use in modelling as well as in high resolution simulations.
&lt;/p&gt;
&lt;p&gt;Our estimation procedure sits in between classic periodogram methods and
atomic/total variation norm thresholding. Through a novel use of window
functions in the point process domain, our approach attains super-resolution
without semidefinite programming. Under suitable conditions, finite sample
guarantees can be derived for our procedure. These resolve some open questions
and expand existing results in spectral estimation literature.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chen_N/0/1/0/all/0/1&quot;&gt;Ningyuan Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lee_D/0/1/0/all/0/1&quot;&gt;Donald K.K. Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Negahban_S/0/1/0/all/0/1&quot;&gt;Sahand Negahban&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1707.06792">
<title>Graphical posterior predictive classifier: Bayesian model averaging with particle Gibbs. (arXiv:1707.06792v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1707.06792</link>
<description rdf:parseType="Literal">&lt;p&gt;In this study, we present a multi-class graphical Bayesian predictive
classifier that incorporates the uncertainty in the model selection into the
standard Bayesian formalism. For each class, the dependence structure
underlying the observed features is represented by a set of decomposable
Gaussian graphical models. Emphasis is then placed on the Bayesian model
averaging which takes full account of the class-specific model uncertainty by
averaging over the posterior graph model probabilities. Even though the
decomposability assumption severely reduces the model space, the size of the
class of decomposable models is still immense, rendering the explicit Bayesian
averaging over all the models infeasible. To address this issue, we consider
the particle Gibbs strategy of Olsson et al. (2018) for posterior sampling from
decomposable graphical models which utilizes the Christmas tree algorithm of
Rios et al. (2016) as proposal kernel. We also derive the a strong hyper Markov
law which we call the hyper normal Wishart law that allow to perform the
resultant Bayesian calculations locally. The proposed predictive graphical
classifier reveals superior performance compared to the ordinary Bayesian
predictive rule that does not account for the model uncertainty, as well as to
a number of out-of-the-box classifiers.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pavlenko_T/0/1/0/all/0/1&quot;&gt;Tatjana Pavlenko&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rios_F/0/1/0/all/0/1&quot;&gt;Felix Leopoldo Rios&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.09513">
<title>Maximum Principle Based Algorithms for Deep Learning. (arXiv:1710.09513v4 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1710.09513</link>
<description rdf:parseType="Literal">&lt;p&gt;The continuous dynamical system approach to deep learning is explored in
order to devise alternative frameworks for training algorithms. Training is
recast as a control problem and this allows us to formulate necessary
optimality conditions in continuous time using the Pontryagin&apos;s maximum
principle (PMP). A modification of the method of successive approximations is
then used to solve the PMP, giving rise to an alternative training algorithm
for deep learning. This approach has the advantage that rigorous error
estimates and convergence results can be established. We also show that it may
avoid some pitfalls of gradient-based methods, such as slow convergence on flat
landscapes near saddle points. Furthermore, we demonstrate that it obtains
favorable initial convergence rate per-iteration, provided Hamiltonian
maximization can be efficiently carried out - a step which is still in need of
improvement. Overall, the approach opens up new avenues to attack problems
associated with deep learning, such as trapping in slow manifolds and
inapplicability of gradient-based methods for discrete trainable variables.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Q/0/1/0/all/0/1&quot;&gt;Qianxiao Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_L/0/1/0/all/0/1&quot;&gt;Long Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tai_C/0/1/0/all/0/1&quot;&gt;Cheng Tai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+E_W/0/1/0/all/0/1&quot;&gt;Weinan E&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.06719">
<title>Techniques for proving Asynchronous Convergence results for Markov Chain Monte Carlo methods. (arXiv:1711.06719v5 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1711.06719</link>
<description rdf:parseType="Literal">&lt;p&gt;Markov Chain Monte Carlo (MCMC) methods such as Gibbs sampling are finding
widespread use in applied statistics and machine learning. These often lead to
difficult computational problems, which are increasingly being solved on
parallel and distributed systems such as compute clusters. Recent work has
proposed running iterative algorithms such as gradient descent and MCMC in
parallel asynchronously for increased performance, with good empirical results
in certain problems. Unfortunately, for MCMC this parallelization technique
requires new convergence theory, as it has been explicitly demonstrated to lead
to divergence on some examples. Recent theory on Asynchronous Gibbs sampling
describes why these algorithms can fail, and provides a way to alter them to
make them converge. In this article, we describe how to apply this theory in a
generic setting, to understand the asynchronous behavior of any MCMC algorithm,
including those implemented using parameter servers, and those not based on
Gibbs sampling.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Terenin_A/0/1/0/all/0/1&quot;&gt;Alexander Terenin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Xing_E/0/1/0/all/0/1&quot;&gt;Eric P. Xing&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.08240">
<title>Estimating activity cycles with probabilistic methods II. The Mount Wilson Ca H&amp;K data. (arXiv:1712.08240v2 [astro-ph.SR] UPDATED)</title>
<link>http://arxiv.org/abs/1712.08240</link>
<description rdf:parseType="Literal">&lt;p&gt;Debate over the existence of branches in the stellar activity-rotation
diagrams continues. Application of modern time series analysis tools to study
the mean cycle periods in chromospheric activity index is lacking. We develop
such models, based on Gaussian processes, for one-dimensional time series and
apply it to the extended Mount Wilson Ca H&amp;amp;K sample. Our main aim is to study
how the previously commonly used assumption of strict harmonicity of the
stellar cycles as well as handling of the linear trends affects the results. We
introduce three methods of different complexity, starting with the simple
Bayesian harmonic model and followed by Gaussian Process models with periodic
and quasi-periodic covariance functions. We confirm the existence of two
populations in the activity-period diagram. We find only one significant trend
in the inactive population, namely that the cycle periods get shorter with
increasing rotation. This is in contrast with earlier studies, that postulate
the existence of trends in both of the populations. In terms of rotation to
cycle period ratio, our data is consistent with only two activity branches such
that the active branch merges together with the transitional one. The retrieved
stellar cycles are uniformly distributed over the R&apos;HK activity index,
indicating that the operation of stellar large-scale dynamos carries smoothly
over the Vaughan-Preston gap. At around the solar activity index, however,
indications of a disruption in the cyclic dynamo action are seen. Our study
shows that stellar cycle estimates depend significantly on the model applied.
Such model-dependent aspects include the improper treatment of linear trends,
while the assumption of strict harmonicity can result in the appearance of
double cyclicities that seem more likely to be explained by the
quasi-periodicity of the cycles.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Olspert_N/0/1/0/all/0/1&quot;&gt;N. Olspert&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Lehtinen_J/0/1/0/all/0/1&quot;&gt;J. J. Lehtinen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Kapyla_M/0/1/0/all/0/1&quot;&gt;M. J. K&amp;#xe4;pyl&amp;#xe4;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Pelt_J/0/1/0/all/0/1&quot;&gt;J. Pelt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/astro-ph/1/au:+Grigorievskiy_A/0/1/0/all/0/1&quot;&gt;A. Grigorievskiy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.02557">
<title>Sparse Linear Discriminant Analysis under the Neyman-Pearson Paradigm. (arXiv:1802.02557v2 [stat.ME] UPDATED)</title>
<link>http://arxiv.org/abs/1802.02557</link>
<description rdf:parseType="Literal">&lt;p&gt;In classification applications such as severe disease diagnosis and fraud
detection, people have clear priorities over the two types of classification
errors. For instance, diagnosing a patient with cancer to be healthy may lead
to loss of life, which incurs a much higher cost than the other way around. The
classical binary classification paradigm does not take into account such
priorities, as it aims to minimize the overall classification error. In
contrast, the Neyman-Pearson (NP) paradigm seeks classifiers with a minimal
type II error while having the prioritized type I error constrained under a
user-specified level, addressing asymmetric type I/II error priorities in the
previously mentioned scenarios. Despite recent advances in the NP
classification literature, two essential issues pose challenges: i) current
theoretical framework assumes bounded feature support, which does not admit
parametric settings; ii) in practice, existing NP classifiers involve splitting
class 0 samples into two parts using a pre-fixed split proportion. To address
the first challenge, we present NP-sLDA that adapts the popular sparse linear
discriminant analysis (sLDA, Mai et al. (2012)) to the NP paradigm. On the
theoretical front, this is the first theoretically justified NP classifier that
takes parametric assumptions and unbounded feature support. We formulate a new
conditional margin assumption and a new conditional detection condition to
accommodate unbounded feature support and show that NP-sLDA satisfies the NP
oracle inequalities. Numerical results show that NP-sLDA is a valuable addition
to the existing NP classifiers. To address the second challenge, we construct a
general data-adaptive sample splitting scheme that improves the classification
performance upon the default half-half class 0 split used in Tong et al.
(2018).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tong_X/0/1/0/all/0/1&quot;&gt;Xin Tong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Xia_L/0/1/0/all/0/1&quot;&gt;Lucy Xia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jiacheng Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Feng_Y/0/1/0/all/0/1&quot;&gt;Yang Feng&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.02558">
<title>Intentional Control of Type I Error over Unconscious Data Distortion: a Neyman-Pearson Approach to Text Classification. (arXiv:1802.02558v2 [stat.ME] UPDATED)</title>
<link>http://arxiv.org/abs/1802.02558</link>
<description rdf:parseType="Literal">&lt;p&gt;Digital texts have become an increasingly important source of data for social
studies. However, textual data from open platforms are vulnerable to
manipulation (e.g., censorship and information inflation), often leading to
bias in subsequent empirical analysis. This paper investigates the problem of
data distortion in text classification when controlling type I error (a
relevant textual message is classified as irrelevant) is the priority. The
default classical classification paradigm that minimizes the overall
classification error can yield an undesirably large type I error, and data
distortion exacerbates this situation. As a solution, we propose the
Neyman-Pearson (NP) classification paradigm which minimizes type II error under
a user-specified type I error constraint. Theoretically, we show that while the
classical oracle (i.e., optimal classifier) cannot be recovered under unknown
data distortion even if one has the entire post-distortion population, the NP
oracle is unaffected by data distortion and can be recovered under the same
condition. Empirically, we illustrate the advantage of NP classification
methods in a case study that classifies posts about strikes and corruption
published on a leading Chinese blogging platform.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Xia_L/0/1/0/all/0/1&quot;&gt;Lucy Xia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhao_R/0/1/0/all/0/1&quot;&gt;Richard Zhao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wu_Y/0/1/0/all/0/1&quot;&gt;Yanhui Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tong_X/0/1/0/all/0/1&quot;&gt;Xin Tong&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.03065">
<title>Generating Realistic Geology Conditioned on Physical Measurements with Generative Adversarial Networks. (arXiv:1802.03065v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1802.03065</link>
<description rdf:parseType="Literal">&lt;p&gt;An important problem in geostatistics is to build models of the subsurface of
the Earth given physical measurements at sparse spatial locations. Typically,
this is done using spatial interpolation methods or by reproducing patterns
from a reference image. However, these algorithms fail to produce realistic
patterns and do not exhibit the wide range of uncertainty inherent in the
prediction of geology. In this paper, we show how semantic inpainting with
Generative Adversarial Networks can be used to generate varied realizations of
geology which honor physical measurements while matching the expected
geological patterns. In contrast to other algorithms, our method scales well
with the number of data points and mimics a distribution of patterns as opposed
to a single pattern or image. The generated conditional samples are state of
the art.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Dupont_E/0/1/0/all/0/1&quot;&gt;Emilien Dupont&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhang_T/0/1/0/all/0/1&quot;&gt;Tuanfeng Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Tilke_P/0/1/0/all/0/1&quot;&gt;Peter Tilke&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Liang_L/0/1/0/all/0/1&quot;&gt;Lin Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bailey_W/0/1/0/all/0/1&quot;&gt;William Bailey&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05693">
<title>Bandit Learning with Positive Externalities. (arXiv:1802.05693v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1802.05693</link>
<description rdf:parseType="Literal">&lt;p&gt;In many platforms, user arrivals exhibit a self-reinforcing behavior: future
user arrivals are likely to have preferences similar to users who were
satisfied in the past. In other words, arrivals exhibit positive externalities.
We study multiarmed bandit (MAB) problems with positive externalities. We show
that the self-reinforcing preferences may lead standard benchmark algorithms
such as UCB to exhibit linear regret. We develop a new algorithm, Balanced
Exploration (BE), which explores arms carefully to avoid suboptimal convergence
of arrivals before sufficient evidence is gathered. We also introduce an
adaptive variant of BE which successively eliminates suboptimal arms. We
analyze their asymptotic regret, and establish optimality by showing that no
algorithm can perform better.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shah_V/0/1/0/all/0/1&quot;&gt;Virag Shah&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Blanchet_J/0/1/0/all/0/1&quot;&gt;Jose Blanchet&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Johari_R/0/1/0/all/0/1&quot;&gt;Ramesh Johari&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.00636">
<title>Recursive Optimization of Convex Risk Measures: Mean-Semideviation Models. (arXiv:1804.00636v3 [math.OC] UPDATED)</title>
<link>http://arxiv.org/abs/1804.00636</link>
<description rdf:parseType="Literal">&lt;p&gt;We develop and analyze stochastic subgradient methods for optimizing a new,
versatile, application-friendly and tractable class of convex risk measures,
termed here as mean-semideviations. Their construction relies on on the concept
of a risk regularizer, a one-dimensional nonlinear map with certain properties,
essentially generalizing the positive part weighting function in the
mean-upper-semideviation risk measure. After we formally introduce
mean-semideviations, we study their basic properties, and we present a
fundamental constructive characterization result, demonstrating their
generality.
&lt;/p&gt;
&lt;p&gt;We then introduce and rigorously analyze the MESSAGEp algorithm, an efficient
stochastic subgradient procedure for iteratively solving convex
mean-semideviation risk-averse problems to optimality. The MESSAGEp algorithm
may be derived as an application of the T-SCGD algorithm of (Yang et al.,
2018). However, the generic theoretical framework of (Yang et al., 2018) is too
narrow and structurally restrictive, as far as optimization of
mean-semideviations is concerned, including the classical
mean-upper-semideviation risk measure. By exploiting problem structure, we
propose a substantially weaker set of assumptions, under which we establish
pathwise convergence of the MESSAGEp algorithm, under the same strong sense as
in (Yang et al., 2018). The new framework reveals a fundamental trade-off
between the smoothness of the random position function and that of the
particular mean-semideviation risk measure under consideration. Further, we
explicitly show that the class of mean-semideviation problems supported under
our framework is strictly larger than the respective class of problems
supported in (Yang et al., 2018). Thus, applicability of compositional
stochastic optimization is established for a strictly wider spectrum of
mean-semideviation problems, justifying the purpose of our work.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Kalogerias_D/0/1/0/all/0/1&quot;&gt;Dionysios S. Kalogerias&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Powell_W/0/1/0/all/0/1&quot;&gt;Warren B. Powell&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.04503">
<title>Unleashing Linear Optimizers for Group-Fair Learning and Optimization. (arXiv:1804.04503v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1804.04503</link>
<description rdf:parseType="Literal">&lt;p&gt;Most systems and learning algorithms optimize average performance or average
loss -- one reason being computational complexity. However, many objectives of
practical interest are more complex than simply average loss. This arises, for
example, when balancing performance or loss with fairness across people. We
prove that, from a computational perspective, optimizing arbitrary objectives
that take into account performance over a small number of groups is not
significantly harder to optimize than average performance. Our main result is a
polynomial-time reduction that uses a linear optimizer to optimize an arbitrary
(Lipschitz continuous) function of performance over a (constant) number of
possibly-overlapping groups. This includes fairness objectives over small
numbers of groups, and we further point out that other existing notions of
fairness such as individual fairness can be cast as convex optimization and
hence more standard convex techniques can be used. Beyond learning, our
approach applies to multi-objective optimization, more generally.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alabi_D/0/1/0/all/0/1&quot;&gt;Daniel Alabi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Immorlica_N/0/1/0/all/0/1&quot;&gt;Nicole Immorlica&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kalai_A/0/1/0/all/0/1&quot;&gt;Adam Tauman Kalai&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.06223">
<title>A Comparison of Machine Learning Algorithms for the Surveillance of Autism Spectrum Disorder. (arXiv:1804.06223v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1804.06223</link>
<description rdf:parseType="Literal">&lt;p&gt;The Centers for Disease Control and Prevention (CDC) coordinates a
labor-intensive process to measure the prevalence of autism spectrum disorder
(ASD) among children in the United States. Random forests methods have shown
promise in speeding up this process, but they lag behind human classification
accuracy by about 5 percent. We explore whether newer document classification
algorithms can close this gap. We applied 6 supervised learning algorithms to
predict whether children meet the case definition for ASD based solely on the
words in their evaluations. We compared the algorithms? performance across 10
random train-test splits of the data, and then, we combined our top 3
classifiers to estimate the Bayes error rate in the data. Across the 10
train-test cycles, the random forest, neural network, and support vector
machine with Naive Bayes features (NB-SVM) each achieved slightly more than
86.5 percent mean accuracy. The Bayes error rate is estimated at approximately
12 percent meaning that the model error for even the simplest of our
algorithms, the random forest, is below 2 percent. NB-SVM produced
significantly more false positives than false negatives. The random forest
performed as well as newer models like the NB-SVM and the neural network.
NB-SVM may not be a good candidate for use in a fully-automated surveillance
workflow due to increased false positives. More sophisticated algorithms, like
hierarchical convolutional neural networks, would not perform substantially
better due to characteristics of the data. Deep learning models performed
similarly to traditional machine learning methods at predicting the
clinician-assigned case status for CDC&apos;s autism surveillance system. While deep
learning methods had limited benefit in this task, they may have applications
in other surveillance systems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lee_S/0/1/0/all/0/1&quot;&gt;Scott H Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Maenner_M/0/1/0/all/0/1&quot;&gt;Matthew J Maenner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Heilig_C/0/1/0/all/0/1&quot;&gt;Charles M Heilig&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.00616">
<title>$\ell_1$-regression with Heavy-tailed Distributions. (arXiv:1805.00616v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.00616</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we consider the problem of linear regression with heavy-tailed
distributions. Different from previous studies that use the squared loss to
measure the performance, we choose the absolute loss, which is more robust in
the presence of large prediction errors. To address the challenge that both the
input and output could be heavy-tailed, we propose a truncated minimization
problem, and demonstrate that it enjoys an $\widetilde{O}(\sqrt{d/n})$ excess
risk, where $d$ is the dimensionality and $n$ is the number of samples.
Compared with traditional work on $\ell_1$-regression, the main advantage of
our result is that we achieve a high-probability risk bound without exponential
moment conditions on the input and output. Furthermore, if the input is
bounded, we show that the classical empirical risk minimization is competent
for $\ell_1$-regression even when the output is heavy-tailed.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_L/0/1/0/all/0/1&quot;&gt;Lijun Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_Z/0/1/0/all/0/1&quot;&gt;Zhi-Hua Zhou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07281">
<title>An Unsupervised Approach to Solving Inverse Problems using Generative Adversarial Networks. (arXiv:1805.07281v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1805.07281</link>
<description rdf:parseType="Literal">&lt;p&gt;Solving inverse problems continues to be a challenge in a wide array of
applications ranging from deblurring, image inpainting, source separation etc.
Most existing techniques solve such inverse problems by either explicitly or
implicitly finding the inverse of the model. The former class of techniques
require explicit knowledge of the measurement process which can be unrealistic,
and rely on strong analytical regularizers to constrain the solution space,
which often do not generalize well. The latter approaches have had remarkable
success in part due to deep learning, but require a large collection of
source-observation pairs, which can be prohibitively expensive. In this paper,
we propose an unsupervised technique to solve inverse problems with generative
adversarial networks (GANs). Using a pre-trained GAN in the space of source
signals, we show that one can reliably recover solutions to under determined
problems in a `blind&apos; fashion, i.e., without knowledge of the measurement
process. We solve this by making successive estimates on the model and the
solution in an iterative fashion. We show promising results in three
challenging applications -- blind source separation, image deblurring, and
recovering an image from its edge map, and perform better than several
baselines.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Anirudh_R/0/1/0/all/0/1&quot;&gt;Rushil Anirudh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Thiagarajan_J/0/1/0/all/0/1&quot;&gt;Jayaraman J. Thiagarajan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kailkhura_B/0/1/0/all/0/1&quot;&gt;Bhavya Kailkhura&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bremer_T/0/1/0/all/0/1&quot;&gt;Timo Bremer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.07616">
<title>Do Neural Network Cross-Modal Mappings Really Bridge Modalities?. (arXiv:1805.07616v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1805.07616</link>
<description rdf:parseType="Literal">&lt;p&gt;Feed-forward networks are widely used in cross-modal applications to bridge
modalities by mapping distributed vectors of one modality to the other, or to a
shared space. The predicted vectors are then used to perform e.g., retrieval or
labeling. Thus, the success of the whole system relies on the ability of the
mapping to make the neighborhood structure (i.e., the pairwise similarities) of
the predicted vectors akin to that of the target vectors. However, whether this
is achieved has not been investigated yet. Here, we propose a new similarity
measure and two ad hoc experiments to shed light on this issue. In three
cross-modal benchmarks we learn a large number of language-to-vision and
vision-to-language neural network mappings (up to five layers) using a rich
diversity of image and text features and loss functions. Our results reveal
that, surprisingly, the neighborhood structure of the predicted vectors
consistently resembles more that of the input vectors than that of the target
vectors. In a second experiment, we further show that untrained nets do not
significantly disrupt the neighborhood (i.e., semantic) structure of the input
vectors.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Collell_G/0/1/0/all/0/1&quot;&gt;Guillem Collell&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Moens_M/0/1/0/all/0/1&quot;&gt;Marie-Francine Moens&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11182">
<title>GESF: A Universal Discriminative Mapping Mechanism for Graph Representation Learning. (arXiv:1805.11182v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1805.11182</link>
<description rdf:parseType="Literal">&lt;p&gt;Graph embedding is a central problem in social network analysis and many
other applications, aiming to learn the vector representation for each node.
While most existing approaches need to specify the neighborhood and the
dependence form to the neighborhood, which may significantly degrades the
flexibility of representation, we propose a novel graph node embedding method
(namely GESF) via the set function technique. Our method can 1) learn an
arbitrary form of representation function from neighborhood, 2) automatically
decide the significance of neighbors at different distances, and 3) be applied
to heterogeneous graph embedding, which may contain multiple types of nodes.
Theoretical guarantee for the representation capability of our method has been
proved for general homogeneous and heterogeneous graphs and evaluation results
on benchmark data sets show that the proposed GESF outperforms the
state-of-the-art approaches on producing node vectors for classification tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gui_S/0/1/0/all/0/1&quot;&gt;Shupeng Gui&lt;/a&gt; (1), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_X/0/1/0/all/0/1&quot;&gt;Xiangliang Zhang&lt;/a&gt; (2), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qiu_S/0/1/0/all/0/1&quot;&gt;Shuang Qiu&lt;/a&gt; (3), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wu_M/0/1/0/all/0/1&quot;&gt;Mingrui Wu&lt;/a&gt; (4), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ye_J/0/1/0/all/0/1&quot;&gt;Jieping Ye&lt;/a&gt; (3), &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_J/0/1/0/all/0/1&quot;&gt;Ji Liu&lt;/a&gt; (1) ((1) University of Rochester, (2) KAUST, Saudi Arabia, (3) University of Michigan, (4) Alibaba Group)</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11284">
<title>Wasserstein Variational Inference. (arXiv:1805.11284v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1805.11284</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper introduces Wasserstein variational inference, a new form of
approximate Bayesian inference based on optimal transport theory. Wasserstein
variational inference uses a new family of divergences that includes both
f-divergences and the Wasserstein distance as special cases. The gradients of
the Wasserstein variational loss are obtained by backpropagating through the
Sinkhorn iterations. This technique results in a very stable likelihood-free
training method that can be used with implicit distributions and probabilistic
programs. Using the Wasserstein variational inference framework, we introduce
several new forms of autoencoders and test their robustness and performance
against existing variational autoencoding techniques.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ambrogioni_L/0/1/0/all/0/1&quot;&gt;Luca Ambrogioni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Guclu_U/0/1/0/all/0/1&quot;&gt;Umut G&amp;#xfc;&amp;#xe7;l&amp;#xfc;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gucluturk_Y/0/1/0/all/0/1&quot;&gt;Ya&amp;#x11f;mur G&amp;#xfc;&amp;#xe7;l&amp;#xfc;t&amp;#xfc;rk&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hinne_M/0/1/0/all/0/1&quot;&gt;Max Hinne&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Maris_E/0/1/0/all/0/1&quot;&gt;Eric Maris&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gerven_M/0/1/0/all/0/1&quot;&gt;Marcel A. J. van Gerven&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.11845">
<title>An Information-Theoretic Analysis for Thompson Sampling with Many Actions. (arXiv:1805.11845v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1805.11845</link>
<description rdf:parseType="Literal">&lt;p&gt;Information-theoretic Bayesian regret bounds of Russo and Van Roy capture the
dependence of regret on prior uncertainty. However, this dependence is through
entropy, which can become arbitrarily large as the number of actions increases.
We establish new bounds that depend instead on a notion of rate-distortion.
Among other things, this allows us to recover through information-theoretic
arguments a near-optimal bound for the linear bandit. We also offer a bound for
the logistic bandit that dramatically improves on the best previously
available, though this bound depends on an information-theoretic statistic that
we have only been able to quantify via computation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Dong_S/0/1/0/all/0/1&quot;&gt;Shi Dong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Roy_B/0/1/0/all/0/1&quot;&gt;Benjamin Van Roy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1805.12279">
<title>Bayesian Pose Graph Optimization via Bingham Distributions and Tempered Geodesic MCMC. (arXiv:1805.12279v1 [cs.CV] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1805.12279</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce Tempered Geodesic Markov Chain Monte Carlo (TG-MCMC) algorithm
for initializing pose graph optimization problems, arising in various scenarios
such as SFM (structure from motion) or SLAM (simultaneous localization and
mapping). TG-MCMC is first of its kind as it unites asymptotically global
non-convex optimization on the spherical manifold of quaternions with posterior
sampling, in order to provide both reliable initial poses and uncertainty
estimates that are informative about the quality of individual solutions. We
devise rigorous theoretical convergence guarantees for our method and
extensively evaluate it on synthetic and real benchmark datasets. Besides its
elegance in formulation and theory, we show that our method is robust to
missing data, noise and the estimated uncertainties capture intuitive
properties of the data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Birdal_T/0/1/0/all/0/1&quot;&gt;Tolga Birdal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Simsekli_U/0/1/0/all/0/1&quot;&gt;Umut &amp;#x15e;im&amp;#x15f;ekli&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Eken_M/0/1/0/all/0/1&quot;&gt;M. Onur Eken&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ilic_S/0/1/0/all/0/1&quot;&gt;Slobodan Ilic&lt;/a&gt;</dc:creator>
</item></rdf:RDF>