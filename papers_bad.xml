<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Boring papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Bad Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-04-26T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.09882"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.09891"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1706.02887"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.04837"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.02476"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.09843"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.09855"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.10001"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.10147"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09184"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.00268"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.08219"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.08984"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.09720"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.09753"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.09770"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.09784"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.09813"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.09858"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.09893"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.09904"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.10025"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.10070"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.10109"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.10140"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1705.07107"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06300"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.03919"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1803.07276"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1804.09314"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1804.09882">
<title>A Neural Embeddings Approach for Detecting Mobile Counterfeit Apps. (arXiv:1804.09882v1 [cs.CR])</title>
<link>http://arxiv.org/abs/1804.09882</link>
<description rdf:parseType="Literal">&lt;p&gt;Counterfeit apps impersonate existing popular apps in attempts to misguide
users to install them for various reasons such as collecting personal
information, spreading malware, or simply to increase their advertisement
revenue. Many counterfeits can be identified once installed, however even a
tech-savvy user may struggle to detect them before installation as app icons
and descriptions can be quite similar to the original app. To this end, this
paper proposes to use neural embeddings generated by state-of-the-art
convolutional neural networks (CNNs) to measure the similarity between images.
Our results show that for the problem of counterfeit detection a novel approach
of using style embeddings given by the Gram matrix of CNN filter responses
outperforms baseline methods such as content embeddings and SIFT features. We
show that further performance increases can be achieved by combining style
embeddings with content embeddings. We present an analysis of approximately 1.2
million apps from Google Play Store and identify a set of potential
counterfeits for top-1,000 apps. Under a conservative assumption, we were able
to find 139 apps that contain malware in a set of 6,880 apps that showed high
visual similarity to one of the top-1,000 apps in Google Play Store.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rajasegaran_J/0/1/0/all/0/1&quot;&gt;Jathushan Rajasegaran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Seneviratne_S/0/1/0/all/0/1&quot;&gt;Suranga Seneviratne&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jourjon_G/0/1/0/all/0/1&quot;&gt;Guillaume Jourjon&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.09891">
<title>Optimal-margin evolutionary classifier. (arXiv:1804.09891v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1804.09891</link>
<description rdf:parseType="Literal">&lt;p&gt;We introduce a novel approach for discriminative classification using
evolutionary algorithms. We first propose an algorithm to optimize the total
loss value using a modified 0-1 loss function in a one-dimensional space for
classification. We then extend this algorithm for multi-dimensional
classification using an evolutionary algorithm. The proposed evolutionary
algorithm aims to find a hyperplane which best classifies instances while
minimizes the classification risk. We test particle swarm optimization,
evolutionary strategy, and covariance matrix adaptation evolutionary strategy
for optimization purpose. Finally, we compare our results with well-established
and state-of-the-art classification algorithms, for both binary and multi-class
classification, on 19 benchmark classification problems, with and without noise
and outliers. Results show that the performance of the proposed algorithm is
significantly (t-test) better than all other methods in almost all problems
tested. We also show that the proposed algorithm is significantly more robust
against noise and outliers comparing to other methods. The running time of the
algorithm is within a reasonable range for the solution of real-world
classification problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bonyadi_M/0/1/0/all/0/1&quot;&gt;Mohammad Reza Bonyadi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Reutens_D/0/1/0/all/0/1&quot;&gt;David C. Reutens&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1706.02887">
<title>Global Convergence of the (1+1) Evolution Strategy. (arXiv:1706.02887v2 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1706.02887</link>
<description rdf:parseType="Literal">&lt;p&gt;We establish global convergence of the (1+1) evolution strategy, i.e.,
convergence to a critical point independent of the initial state. More
precisely, we show the existence of a critical limit point, using a suitable
extension of the notion of a critical point to measurable functions. At its
core, the analysis is based on a novel progress guarantee for elitist,
rank-based evolutionary algorithms. By applying it to the (1+1) evolution
strategy we are able to provide an accurate characterization of whether global
convergence is guaranteed with full probability, or whether premature
convergence is possible. We illustrate our results on a number of example
applications ranging from smooth (non-convex) cases over different types of
saddle points and ridge functions to discontinuous and extremely rugged
problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Glasmachers_T/0/1/0/all/0/1&quot;&gt;Tobias Glasmachers&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.04837">
<title>Improving Factor-Based Quantitative Investing by Forecasting Company Fundamentals. (arXiv:1711.04837v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1711.04837</link>
<description rdf:parseType="Literal">&lt;p&gt;On a periodic basis, publicly traded companies are required to report
fundamentals: financial data such as revenue, operating income, debt, among
others. These data points provide some insight into the financial health of a
company. Academic research has identified some factors, i.e. computed features
of the reported data, that are known through retrospective analysis to
outperform the market average. Two popular factors are the book value
normalized by market capitalization (book-to-market) and the operating income
normalized by the enterprise value (EBIT/EV). In this paper: we first show
through simulation that if we could (clairvoyantly) select stocks using factors
calculated on future fundamentals (via oracle), then our portfolios would far
outperform a standard factor approach. Motivated by this analysis, we train
deep neural networks to forecast future fundamentals based on a trailing
5-years window. Quantitative analysis demonstrates a significant improvement in
MSE over a naive strategy. Moreover, in retrospective analysis using an
industry-grade stock portfolio simulator (backtester), we show an improvement
in compounded annual return to 17.1% (MLP) vs 14.4% for a standard factor
model.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Alberg_J/0/1/0/all/0/1&quot;&gt;John Alberg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lipton_Z/0/1/0/all/0/1&quot;&gt;Zachary C. Lipton&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.02476">
<title>Associative Compression Networks for Representation Learning. (arXiv:1804.02476v2 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1804.02476</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper introduces Associative Compression Networks (ACNs), a new
framework for variational autoencoding with neural networks. The system differs
from existing variational autoencoders (VAEs) in that the prior distribution
used to model each code is conditioned on a similar code from the dataset. In
compression terms this equates to sequentially transmitting the dataset using
an ordering determined by proximity in latent space. Since the prior need only
account for local, rather than global variations in the latent space, the
coding cost is greatly reduced, leading to rich, informative codes. Crucially,
the codes remain informative when powerful, autoregressive decoders are used,
which we argue is fundamentally difficult with normal VAEs. Experimental
results on MNIST, CIFAR-10, ImageNet and CelebA show that ACNs discover
high-level latent features such as object class, writing style, pose and facial
expression, which can be used to cluster and classify the data, as well as to
generate diverse and convincing samples. We conclude that ACNs are a promising
new direction for representation learning: one that steps away from IID
modelling, and towards learning a structured description of the dataset as a
whole.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Graves_A/0/1/0/all/0/1&quot;&gt;Alex Graves&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Menick_J/0/1/0/all/0/1&quot;&gt;Jacob Menick&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oord_A/0/1/0/all/0/1&quot;&gt;Aaron van den Oord&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.09843">
<title>Hierarchical Density Order Embeddings. (arXiv:1804.09843v1 [cs.CL])</title>
<link>http://arxiv.org/abs/1804.09843</link>
<description rdf:parseType="Literal">&lt;p&gt;By representing words with probability densities rather than point vectors,
probabilistic word embeddings can capture rich and interpretable semantic
information and uncertainty. The uncertainty information can be particularly
meaningful in capturing entailment relationships -- whereby general words such
as &quot;entity&quot; correspond to broad distributions that encompass more specific
words such as &quot;animal&quot; or &quot;instrument&quot;. We introduce density order embeddings,
which learn hierarchical representations through encapsulation of probability
densities. In particular, we propose simple yet effective loss functions and
distance metrics, as well as graph-based schemes to select negative samples to
better learn hierarchical density representations. Our approach provides
state-of-the-art performance on the WordNet hypernym relationship prediction
task and the challenging HyperLex lexical entailment dataset -- while retaining
a rich and interpretable density representation.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Athiwaratkun_B/0/1/0/all/0/1&quot;&gt;Ben Athiwaratkun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wilson_A/0/1/0/all/0/1&quot;&gt;Andrew Gordon Wilson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.09855">
<title>An ASP Methodology for Understanding Narratives about Stereotypical Activities. (arXiv:1804.09855v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1804.09855</link>
<description rdf:parseType="Literal">&lt;p&gt;We describe an application of Answer Set Programming to the understanding of
narratives about stereotypical activities, demonstrated via question answering.
Substantial work in this direction was done by Erik Mueller, who modeled
stereotypical activities as scripts. His systems were able to understand a good
number of narratives, but could not process texts describing exceptional
scenarios. We propose addressing this problem by using a theory of intentions
developed by Blount, Gelfond, and Balduccini. We present a methodology in which
we substitute scripts by activities (i.e., hierarchical plans associated with
goals) and employ the concept of an intentional agent to reason about both
normal and exceptional scenarios. We exemplify the application of this
methodology by answering questions about a number of restaurant stories. This
paper is under consideration for acceptance in TPLP.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Inclezan_D/0/1/0/all/0/1&quot;&gt;Daniela Inclezan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhang_Q/0/1/0/all/0/1&quot;&gt;Qinglin Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Balduccini_M/0/1/0/all/0/1&quot;&gt;Marcello Balduccini&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Israney_A/0/1/0/all/0/1&quot;&gt;Ankush Israney&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.10001">
<title>Profile-guided memory optimization for deep neural networks. (arXiv:1804.10001v1 [cs.DC])</title>
<link>http://arxiv.org/abs/1804.10001</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent years have seen deep neural networks (DNNs) becoming wider and deeper
to achieve better performance in many applications of AI. Such DNNs however
require huge amounts of memory to store weights and intermediate results (e.g.,
activations, feature maps, etc.) in propagation. This requirement makes it
difficult to run the DNNs on devices with limited, hard-to-extend memory,
degrades the running time performance, and restricts the design of network
models. We address this challenge by developing a novel profile-guided memory
optimization to efficiently and quickly allocate memory blocks during the
propagation in DNNs. The optimization utilizes a simple and fast heuristic
algorithm based on the two-dimensional rectangle packing problem. Experimenting
with well-known neural network models, we confirm that our method not only
reduces the memory consumption by up to $49.5\%$ but also accelerates training
and inference by up to a factor of four thanks to the rapidity of the memory
allocation and the ability to use larger mini-batch sizes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sekiyama_T/0/1/0/all/0/1&quot;&gt;Taro Sekiyama&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Imamichi_T/0/1/0/all/0/1&quot;&gt;Takashi Imamichi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Imai_H/0/1/0/all/0/1&quot;&gt;Haruki Imai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Raymond_R/0/1/0/all/0/1&quot;&gt;Rudy Raymond&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.10147">
<title>Detection of Glottal Closure Instants using Deep Dilated Convolutional Neural Networks. (arXiv:1804.10147v1 [cs.SD])</title>
<link>http://arxiv.org/abs/1804.10147</link>
<description rdf:parseType="Literal">&lt;p&gt;Glottal Closure Instants (GCIs) correspond to the temporal locations of
significant excitation to the vocal tract occurring during the production of
voiced speech. Detection of GCIs from speech signals is a well-studied problem
given its importance in speech processing. Most of the existing approaches for
GCI detection adopt a two-stage approach - (i) Transformation of speech signal
into a representative signal where GCIs are localized better, (ii) extraction
of GCIs using the representative signal obtained in first stage. The former
stage is accomplished using signal processing techniques based on the
principles of speech production and the latter with heuristic-algorithms such
as dynamic programming and peak-picking. These methods are thus task-specific
and rely on the methods used for representative signal extraction. However in
this paper, we formulate the GCI detection problem from a representation
learning perspective where appropriate representation is implicitly learned
from the raw-speech data samples. Specifically, GCI detection is cast as a
supervised multi-task learning problem which is solved using a deep dilated
convolutional neural network jointly optimizing a classification and regression
cost. The learning capabilities of the proposed model is demonstrated with
several experiments on standard datasets. The results compare well with the
state-of- the-art algorithms while performing better in the case of presence of
real-world non-stationary noise.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+P%2E_P/0/1/0/all/0/1&quot;&gt;Prathosh A. P.&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goyal_M/0/1/0/all/0/1&quot;&gt;Mohit Goyal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Srivastava_V/0/1/0/all/0/1&quot;&gt;Varun Srivastava&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09184">
<title>Variance Reduction Methods for Sublinear Reinforcement Learning. (arXiv:1802.09184v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1802.09184</link>
<description rdf:parseType="Literal">&lt;p&gt;This work considers the problem of provably optimal reinforcement learning
for episodic finite horizon MDPs, i.e. how an agent learns to maximize his/her
long term reward in an uncertain environment. The main contribution is in
providing a novel algorithm --- Variance-reduced Upper Confidence Q-learning
(vUCQ) --- which enjoys a regret bound of $\widetilde{O}(\sqrt{HSAT} + H^5SA)$,
where the $T$ is the number of time steps the agent acts in the MDP, $S$ is the
number of states, $A$ is the number of actions, and $H$ is the (episodic)
horizon time.
&lt;/p&gt;
&lt;p&gt;This is the first regret bound that is both sub-linear in the model size and
asymptotically optimal. The algorithm is sub-linear in that the time to achieve
$\epsilon$-average regret for any constant $\epsilon$ is $O(SA)$, which is a
number of samples that is far less than that required to learn any non-trivial
estimate of the transition model (the transition model is specified by
$O(S^2A)$ parameters). The importance of sub-linear algorithms is largely the
motivation for algorithms such as $Q$-learning and other &quot;model free&quot;
approaches. vUCQ algorithm also enjoys minimax optimal regret in the long run,
matching the $\Omega(\sqrt{HSAT})$ lower bound.
&lt;/p&gt;
&lt;p&gt;Variance-reduced Upper Confidence Q-learning (vUCQ) is a successive
refinement method in which the algorithm reduces the variance in $Q$-value
estimates and couples this estimation scheme with an upper confidence based
algorithm. Technically, the coupling of both of these techniques is what leads
to the algorithm enjoying both the sub-linear regret property and the
asymptotically optimal regret.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kakade_S/0/1/0/all/0/1&quot;&gt;Sham Kakade&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_M/0/1/0/all/0/1&quot;&gt;Mengdi Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_L/0/1/0/all/0/1&quot;&gt;Lin F. Yang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.00268">
<title>Representation Learning in Partially Observable Environments using Sensorimotor Prediction. (arXiv:1803.00268v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1803.00268</link>
<description rdf:parseType="Literal">&lt;p&gt;In order to explore and act autonomously in an environment, an agent needs to
learn from the sensorimotor information that is captured while acting. By
extracting the regularities in this sensorimotor stream, it can learn a model
of the world, which in turn can be used as a basis for action and exploration.
&lt;/p&gt;
&lt;p&gt;This requires the acquisition of compact representations from a possibly high
dimensional raw observation, which is noisy and ambiguous. In this paper, we
learn sensory representations from sensorimotor prediction. We propose a model
which integrates sensorimotor information over time, and project it in a
sensory representation which is useful for prediction. We emphasize on a simple
example the role of motor and memory for learning sensory representations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kulak_T/0/1/0/all/0/1&quot;&gt;Thibaut Kulak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ortiz_M/0/1/0/all/0/1&quot;&gt;Michael Garcia Ortiz&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.08219">
<title>Adaptive Performance Assessment For Drivers Through Behavioral Advantage. (arXiv:1804.08219v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1804.08219</link>
<description rdf:parseType="Literal">&lt;p&gt;The potential positive impact of autonomous driving and driver assistance
technolo- gies have been a major impetus over the last decade. On the flip
side, it has been a challenging problem to analyze the performance of human
drivers or autonomous driving agents quantitatively. In this work, we propose a
generic method that compares the performance of drivers or autonomous driving
agents even if the environmental conditions are different, by using the driver
behavioral advantage instead of absolute metrics, which efficiently removes the
environmental factors. A concrete application of the method is also presented,
where the performance of more than 100 truck drivers was evaluated and ranked
in terms of fuel efficiency, covering more than 90,000 trips spanning an
average of 300 miles in a variety of driving conditions and environments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Qiu_D/0/1/0/all/0/1&quot;&gt;Dicong Qiu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Paga_K/0/1/0/all/0/1&quot;&gt;Karthik Paga&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.08984">
<title>Computational Approaches for Stochastic Shortest Path on Succinct MDPs. (arXiv:1804.08984v2 [cs.PL] UPDATED)</title>
<link>http://arxiv.org/abs/1804.08984</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the stochastic shortest path (SSP) problem for succinct Markov
decision processes (MDPs), where the MDP consists of a set of variables, and a
set of nondeterministic rules that update the variables. First, we show that
several examples from the AI literature can be modeled as succinct MDPs. Then
we present computational approaches for upper and lower bounds for the SSP
problem: (a)~for computing upper bounds, our method is polynomial-time in the
implicit description of the MDP; (b)~for lower bounds, we present a
polynomial-time (in the size of the implicit description) reduction to
quadratic programming. Our approach is applicable even to infinite-state MDPs.
Finally, we present experimental results to demonstrate the effectiveness of
our approach on several classical examples from the AI literature.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chatterjee_K/0/1/0/all/0/1&quot;&gt;Krishnendu Chatterjee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fu_H/0/1/0/all/0/1&quot;&gt;Hongfei Fu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goharshady_A/0/1/0/all/0/1&quot;&gt;Amir Kafshdar Goharshady&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Okati_N/0/1/0/all/0/1&quot;&gt;Nastaran Okati&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.09720">
<title>JUNIPR: a Framework for Unsupervised Machine Learning in Particle Physics. (arXiv:1804.09720v1 [hep-ph])</title>
<link>http://arxiv.org/abs/1804.09720</link>
<description rdf:parseType="Literal">&lt;p&gt;In applications of machine learning to particle physics, a persistent
challenge is how to go beyond discrimination to learn about the underlying
physics. To this end, a powerful tool would be a framework for unsupervised
learning, where the machine learns the intricate high-dimensional contours of
the data upon which it is trained, without reference to pre-established labels.
In order to approach such a complex task, an unsupervised network must be
structured intelligently, based on a qualitative understanding of the data. In
this paper, we scaffold the neural network&apos;s architecture around a
leading-order model of the physics underlying the data. In addition to making
unsupervised learning tractable, this design actually alleviates existing
tensions between performance and interpretability. We call the framework
JUNIPR: &quot;Jets from UNsupervised Interpretable PRobabilistic models&quot;. In this
approach, the set of particle momenta composing a jet are clustered into a
binary tree that the neural network examines sequentially. Training is
unsupervised and unrestricted: the network could decide that the data bears
little correspondence to the chosen tree structure. However, when there is a
correspondence, the network&apos;s output along the tree has a direct physical
interpretation. JUNIPR models can perform discrimination tasks, through the
statistically optimal likelihood-ratio test, and they permit visualizations of
discrimination power at each branching in a jet&apos;s tree. Additionally, JUNIPR
models provide a probability distribution from which events can be drawn,
providing a data-driven Monte Carlo generator. As a third application, JUNIPR
models can reweight events from one (e.g. simulated) data set to agree with
distributions from another (e.g. experimental) data set.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/hep-ph/1/au:+Andreassen_A/0/1/0/all/0/1&quot;&gt;Anders Andreassen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/hep-ph/1/au:+Feige_I/0/1/0/all/0/1&quot;&gt;Ilya Feige&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/hep-ph/1/au:+Frye_C/0/1/0/all/0/1&quot;&gt;Christopher Frye&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/hep-ph/1/au:+Schwartz_M/0/1/0/all/0/1&quot;&gt;Matthew D. Schwartz&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.09753">
<title>The phase transition for the existence of the maximum likelihood estimate in high-dimensional logistic regression. (arXiv:1804.09753v1 [stat.ME])</title>
<link>http://arxiv.org/abs/1804.09753</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper rigorously establishes that the existence of the maximum
likelihood estimate (MLE) in high-dimensional logistic regression models with
Gaussian covariates undergoes a sharp `phase transition&apos;. We introduce an
explicit boundary curve $h_{\text{MLE}}$, parameterized by two scalars
measuring the overall magnitude of the unknown sequence of regression
coefficients, with the following property: in the limit of large sample sizes
$n$ and number of features $p$ proportioned in such a way that $p/n \rightarrow
\kappa$, we show that if the problem is sufficiently high dimensional in the
sense that $\kappa &amp;gt; h_{\text{MLE}}$, then the MLE does not exist with
probability one. Conversely, if $\kappa &amp;lt; h_{\text{MLE}}$, the MLE
asymptotically exists with probability one.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Candes_E/0/1/0/all/0/1&quot;&gt;Emmanuel J. Candes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sur_P/0/1/0/all/0/1&quot;&gt;Pragya Sur&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.09770">
<title>RULLS: Randomized Union of Locally Linear Subspaces for Feature Engineering. (arXiv:1804.09770v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1804.09770</link>
<description rdf:parseType="Literal">&lt;p&gt;Feature engineering plays an important role in the success of a machine
learning model. Most of the effort in training a model goes into data
preparation and choosing the right representation. In this paper, we propose a
robust feature engineering method, Randomized Union of Locally Linear Subspaces
(RULLS). We generate sparse, non-negative, and rotation invariant features in
an unsupervised fashion. RULLS aggregates features from a random union of
subspaces by describing each point using globally chosen landmarks. These
landmarks serve as anchor points for choosing subspaces. Our method provides a
way to select features that are relevant in the neighborhood around these
chosen landmarks. Distances from each data point to $k$ closest landmarks are
encoded in the feature matrix. The final feature representation is a union of
features from all chosen subspaces.
&lt;/p&gt;
&lt;p&gt;The effectiveness of our algorithm is shown on various real-world datasets
for tasks such as clustering and classification of raw data and in the presence
of noise. We compare our method with existing feature generation methods.
Results show a high performance of our method on both classification and
clustering tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lokare_N/0/1/0/all/0/1&quot;&gt;Namita Lokare&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Silva_J/0/1/0/all/0/1&quot;&gt;Jorge Silva&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kabul_I/0/1/0/all/0/1&quot;&gt;Ilknur Kaynar Kabul&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.09784">
<title>Mathematical Analysis on Out-of-Sample Extensions. (arXiv:1804.09784v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1804.09784</link>
<description rdf:parseType="Literal">&lt;p&gt;Let $X=\mathbf{X}\cup\mathbf{Z}$ be a data set in $\mathbb{R}^D$, where
$\mathbf{X}$ is the training set and $\mathbf{Z}$ is the test one. Many
unsupervised learning algorithms based on kernel methods have been developed to
provide dimensionality reduction (DR) embedding for a given training set $\Phi:
\mathbf{X} \to \mathbb{R}^d$ ( $d\ll D$) that maps the high-dimensional data
$\mathbf{X}$ to its low-dimensional feature representation
$\mathbf{Y}=\Phi(\mathbf{X})$. However, these algorithms do not
straightforwardly produce DR of the test set $\mathbf{Z}$. An out-of-sample
extension method provides DR of $\mathbf{Z}$ using an extension of the existent
embedding $\Phi$, instead of re-computing the DR embedding for the whole set
$X$. Among various out-of-sample DR extension methods, those based on
Nystr\&quot;{o}m approximation are very attractive. Many papers have developed such
out-of-extension algorithms and shown their validity by numerical experiments.
However, the mathematical theory for the DR extension still need further
consideration. Utilizing the reproducing kernel Hilbert space (RKHS) theory,
this paper develops a preliminary mathematical analysis on the out-of-sample DR
extension operators. It treats an out-of-sample DR extension operator as an
extension of the identity on the RKHS defined on $\mathbf{X}$. Then the
Nystr\&quot;{o}m-type DR extension turns out to be an orthogonal projection. In the
paper, we also present the conditions for the exact DR extension and give the
estimate for the error of the extension.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jianzhong Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.09813">
<title>HG-means: A scalable hybrid genetic algorithm for minimum sum-of-squares clustering. (arXiv:1804.09813v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1804.09813</link>
<description rdf:parseType="Literal">&lt;p&gt;Minimum sum-of-squares clustering (MSSC) is a widely used clustering model,
of which the popular K-means algorithm constitutes a local minimizer. It is
well known that the solutions of K-means can be arbitrarily distant from the
true MSSC global optimum, and dozens of alternative heuristics have been
proposed for this problem. However, no other algorithm has been commonly
adopted in the literature. This may be related to differences of computational
effort, or to the assumption that a better solution of the MSSC has only a
minor impact on classification or generalization capabilities. In this article,
we dispute this belief. We introduce an efficient population-based
metaheuristic that uses K-means as a local search in combination with
problem-tailored crossover, mutation, and diversification operators. This
algorithm can be interpreted as a multi-start K-means, in which the initial
center positions are carefully sampled based on the search history. The
approach is scalable and accurate, outperforming all recent state-of-the-art
algorithms for MSSC in terms of solution quality, measured by the depth of
local minima. This enhanced accuracy leads to classification results which are
significantly closer to the ground truth than those of other algorithms, for
overlapping Gaussian-mixture datasets with a large number of features and
clusters. Therefore, improved global optimization methods appear to be
essential to better exploit the MSSC model in high dimension.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gribel_D/0/1/0/all/0/1&quot;&gt;Daniel Gribel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vidal_T/0/1/0/all/0/1&quot;&gt;Thibaut Vidal&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.09858">
<title>Generative Model for Heterogeneous Inference. (arXiv:1804.09858v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1804.09858</link>
<description rdf:parseType="Literal">&lt;p&gt;Generative models (GMs) such as Generative Adversary Network (GAN) and
Variational Auto-Encoder (VAE) have thrived these years and achieved high
quality results in generating new samples. Especially in Computer Vision, GMs
have been used in image inpainting, denoising and completion, which can be
treated as the inference from observed pixels to corrupted pixels. However,
images are hierarchically structured which are quite different from many
real-world inference scenarios with non-hierarchical features. These inference
scenarios contain heterogeneous stochastic variables and irregular mutual
dependences. Traditionally they are modeled by Bayesian Network (BN). However,
the learning and inference of BN model are NP-hard thus the number of
stochastic variables in BN is highly constrained. In this paper, we adapt
typical GMs to enable heterogeneous learning and inference in polynomial
time.We also propose an extended autoregressive (EAR) model and an EAR with
adversary loss (EARA) model and give theoretical results on their
effectiveness. Experiments on several BN datasets show that our proposed EAR
model achieves the best performance in most cases compared to other GMs. Except
for black box analysis, we&apos;ve also done a serial of experiments on Markov
border inference of GMs for white box analysis and give theoretical results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_H/0/1/0/all/0/1&quot;&gt;Honggang Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yunchun Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_H/0/1/0/all/0/1&quot;&gt;Hailong Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_W/0/1/0/all/0/1&quot;&gt;Wei Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jia_J/0/1/0/all/0/1&quot;&gt;Jie Jia&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.09893">
<title>Random Fourier Features for Kernel Ridge Regression: Approximation Bounds and Statistical Guarantees. (arXiv:1804.09893v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1804.09893</link>
<description rdf:parseType="Literal">&lt;p&gt;Random Fourier features is one of the most popular techniques for scaling up
kernel methods, such as kernel ridge regression. However, despite impressive
empirical results, the statistical properties of random Fourier features are
still not well understood. In this paper we take steps toward filling this gap.
Specifically, we approach random Fourier features from a spectral matrix
approximation point of view, give tight bounds on the number of Fourier
features required to achieve a spectral approximation, and show how spectral
matrix approximation bounds imply statistical guarantees for kernel ridge
regression.
&lt;/p&gt;
&lt;p&gt;Qualitatively, our results are twofold: on the one hand, we show that random
Fourier feature approximation can provably speed up kernel ridge regression
under reasonable assumptions. At the same time, we show that the method is
suboptimal, and sampling from a modified distribution in Fourier space, given
by the leverage function of the kernel, yields provably better performance. We
study this optimal sampling distribution for the Gaussian kernel, achieving a
nearly complete characterization for the case of low-dimensional bounded
datasets. Based on this characterization, we propose an efficient sampling
scheme with guarantees superior to random Fourier features in this regime.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Avron_H/0/1/0/all/0/1&quot;&gt;Haim Avron&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kapralov_M/0/1/0/all/0/1&quot;&gt;Michael Kapralov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Musco_C/0/1/0/all/0/1&quot;&gt;Cameron Musco&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Musco_C/0/1/0/all/0/1&quot;&gt;Christopher Musco&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Velingker_A/0/1/0/all/0/1&quot;&gt;Ameya Velingker&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zandieh_A/0/1/0/all/0/1&quot;&gt;Amir Zandieh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.09904">
<title>High-dimensional Penalty Selection via Minimum Description Length Principle. (arXiv:1804.09904v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1804.09904</link>
<description rdf:parseType="Literal">&lt;p&gt;We tackle the problem of penalty selection of regularization on the basis of
the minimum description length (MDL) principle. In particular, we consider that
the design space of the penalty function is high-dimensional. In this
situation, the luckiness-normalized-maximum-likelihood(LNML)-minimization
approach is favorable, because LNML quantifies the goodness of regularized
models with any forms of penalty functions in view of the minimum description
length principle, and guides us to a good penalty function through the
high-dimensional space. However, the minimization of LNML entails two major
challenges: 1) the computation of the normalizing factor of LNML and 2) its
minimization in high-dimensional spaces. In this paper, we present a novel
regularization selection method (MDL-RS), in which a tight upper bound of LNML
(uLNML) is minimized with local convergence guarantee. Our main contribution is
the derivation of uLNML, which is a uniform-gap upper bound of LNML in an
analytic expression. This solves the above challenges in an approximate manner
because it allows us to accurately approximate LNML and then efficiently
minimize it. The experimental results show that MDL-RS improves the
generalization performance of regularized estimates specifically when the model
has redundant parameters.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Miyaguchi_K/0/1/0/all/0/1&quot;&gt;Kohei Miyaguchi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yamanishi_K/0/1/0/all/0/1&quot;&gt;Kenji Yamanishi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.10025">
<title>Extended Vertical Lists for Temporal Pattern Mining from Multivariate Time Series. (arXiv:1804.10025v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1804.10025</link>
<description rdf:parseType="Literal">&lt;p&gt;Temporal Pattern Mining (TPM) is the problem of mining predictive complex
temporal patterns from multivariate time series in a supervised setting. We
develop a new method called the Fast Temporal Pattern Mining with Extended
Vertical Lists. This method utilizes an extension of the Apriori property which
requires a more complex pattern to appear within records only at places where
all of its subpatterns are detected as well. The approach is based on a novel
data structure called the Extended Vertical List that tracks positions of the
first state of the pattern inside records. Extensive computational results
indicate that the new method performs significantly faster than the previous
version of the algorithm for TMP. However, the speed-up comes at the expense of
memory usage.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kocheturov_A/0/1/0/all/0/1&quot;&gt;Anton Kocheturov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Momcilovic_P/0/1/0/all/0/1&quot;&gt;Petar Momcilovic&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bihorac_A/0/1/0/all/0/1&quot;&gt;Azra Bihorac&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pardalos_P/0/1/0/all/0/1&quot;&gt;Panos M. Pardalos&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.10070">
<title>Adaptive pooling operators for weakly labeled sound event detection. (arXiv:1804.10070v1 [cs.SD])</title>
<link>http://arxiv.org/abs/1804.10070</link>
<description rdf:parseType="Literal">&lt;p&gt;Sound event detection (SED) methods are tasked with labeling segments of
audio recordings by the presence of active sound sources. SED is typically
posed as a supervised machine learning problem, requiring strong annotations
for the presence or absence of each sound source at every time instant within
the recording. However, strong annotations of this type are both labor- and
cost-intensive for human annotators to produce, which limits the practical
scalability of SED methods.
&lt;/p&gt;
&lt;p&gt;In this work, we treat SED as a multiple instance learning (MIL) problem,
where training labels are static over a short excerpt, indicating the presence
or absence of sound sources but not their temporal locality. The models,
however, must still produce temporally dynamic predictions, which must be
aggregated (pooled) when comparing against static labels during training. To
facilitate this aggregation, we develop a family of adaptive pooling
operators---referred to as auto-pool---which smoothly interpolate between
common pooling operators, such as min-, max-, or average-pooling, and
automatically adapt to the characteristics of the sound sources in question. We
evaluate the proposed pooling operators on three datasets, and demonstrate that
in each case, the proposed methods outperform non-adaptive pooling operators
for static prediction, and nearly match the performance of models trained with
strong, dynamic annotations. The proposed method is evaluated in conjunction
with convolutional neural networks, but can be readily applied to any
differentiable model for time-series label prediction.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+McFee_B/0/1/0/all/0/1&quot;&gt;Brian McFee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Salamon_J/0/1/0/all/0/1&quot;&gt;Justin Salamon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bello_J/0/1/0/all/0/1&quot;&gt;Juan Pablo Bello&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.10109">
<title>Quantized Compressive K-Means. (arXiv:1804.10109v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1804.10109</link>
<description rdf:parseType="Literal">&lt;p&gt;The recent framework of compressive statistical learning aims at designing
tractable learning algorithms that use only a heavily compressed
representation-or sketch-of massive datasets. Compressive K-Means (CKM) is such
a method: it estimates the centroids of data clusters from pooled, non-linear,
random signatures of the learning examples. While this approach significantly
reduces computational time on very large datasets, its digital implementation
wastes acquisition resources because the learning examples are compressed only
after the sensing stage. The present work generalizes the sketching procedure
initially defined in Compressive K-Means to a large class of periodic
nonlinearities including hardware-friendly implementations that compressively
acquire entire datasets. This idea is exemplified in a Quantized Compressive
K-Means procedure, a variant of CKM that leverages 1-bit universal quantization
(i.e. retaining the least significant bit of a standard uniform quantizer) as
the periodic sketch nonlinearity. Trading for this resource-efficient signature
(standard in most acquisition schemes) has almost no impact on the clustering
performances, as illustrated by numerical experiments.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schellekens_V/0/1/0/all/0/1&quot;&gt;Vincent Schellekens&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jacques_L/0/1/0/all/0/1&quot;&gt;Laurent Jacques&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.10140">
<title>Securing Distributed Machine Learning in High Dimensions. (arXiv:1804.10140v1 [cs.DC])</title>
<link>http://arxiv.org/abs/1804.10140</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider securing a distributed machine learning system wherein the data
is kept confidential by its providers who are recruited as workers to help the
learner to train a $d$--dimensional model. In each communication round, up to
$q$ out of the $m$ workers suffer Byzantine faults; faulty workers are assumed
to have complete knowledge of the system and can collude to behave arbitrarily
adversarially against the learner. We assume that each worker keeps a local
sample of size $n$. (Thus, the total number of data points is $N=nm$.) Of
particular interest is the high-dimensional regime $d \gg n$.
&lt;/p&gt;
&lt;p&gt;We propose a secured variant of the classical gradient descent method which
can tolerate up to a constant fraction of Byzantine workers. We show that the
estimation error of the iterates converges to an estimation error $O(\sqrt{q/N}
+ \sqrt{d/N})$ in $O(\log N)$ rounds. The core of our method is a robust
gradient aggregator based on the iterative filtering algorithm proposed by
Steinhardt et al. \cite{Steinhardt18} for robust mean estimation. We establish
a uniform concentration of the sample covariance matrix of gradients, and show
that the aggregated gradient, as a function of model parameter, converges
uniformly to the true gradient function. As a by-product, we develop a new
concentration inequality for sample covariance matrices of sub-exponential
distributions, which might be of independent interest.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Su_L/0/1/0/all/0/1&quot;&gt;Lili Su&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1&quot;&gt;Jiaming Xu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1705.07107">
<title>Gradient Estimators for Implicit Models. (arXiv:1705.07107v5 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1705.07107</link>
<description rdf:parseType="Literal">&lt;p&gt;Implicit models, which allow for the generation of samples but not for
point-wise evaluation of probabilities, are omnipresent in real-world problems
tackled by machine learning and a hot topic of current research. Some examples
include data simulators that are widely used in engineering and scientific
research, generative adversarial networks (GANs) for image synthesis, and
hot-off-the-press approximate inference techniques relying on implicit
distributions. The majority of existing approaches to learning implicit models
rely on approximating the intractable distribution or optimisation objective
for gradient-based optimisation, which is liable to produce inaccurate updates
and thus poor models. This paper alleviates the need for such approximations by
proposing the Stein gradient estimator, which directly estimates the score
function of the implicitly defined distribution. The efficacy of the proposed
estimator is empirically demonstrated by examples that include meta-learning
for approximate inference, and entropy regularised GANs that provide improved
sample diversity.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Li_Y/0/1/0/all/0/1&quot;&gt;Yingzhen Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Turner_R/0/1/0/all/0/1&quot;&gt;Richard E. Turner&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06300">
<title>Exact and Robust Conformal Inference Methods for Predictive Machine Learning With Dependent Data. (arXiv:1802.06300v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1802.06300</link>
<description rdf:parseType="Literal">&lt;p&gt;We extend conformal inference to general settings that allow for time series
data. Our proposal is developed as a randomization method and accounts for
potential serial dependence by including block structures in the permutation
scheme. As a result, the proposed method retains the exact, model-free validity
when the data are i.i.d. or more generally exchangeable, similar to usual
conformal inference methods. When exchangeability fails, as is the case for
common time series data, the proposed approach is approximately valid under
weak assumptions on the conformity score.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chernozhukov_V/0/1/0/all/0/1&quot;&gt;Victor Chernozhukov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wuthrich_K/0/1/0/all/0/1&quot;&gt;Kaspar Wuthrich&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhu_Y/0/1/0/all/0/1&quot;&gt;Yinchu Zhu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.03919">
<title>Detecting Nonlinear Causality in Multivariate Time Series with Sparse Additive Models. (arXiv:1803.03919v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1803.03919</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a nonparametric method for detecting nonlinear causal relationship
within a set of multidimensional discrete time series, by using sparse additive
models (SpAMs). We show that, when the input to the SpAM is a $\beta$-mixing
time series, the model can be fitted by first approximating each unknown
function with a linear combination of a set of B-spline bases, and then solving
a group-lasso-type optimization problem with nonconvex regularization.
Theoretically, we characterize the oracle statistical properties of the
proposed sparse estimator in function estimation and model selection.
Numerically, we propose an efficient pathwise iterative shrinkage thresholding
algorithm (PISTA), which tames the nonconvexity and guarantees linear
convergence towards the desired sparse estimator with high probability.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yang_Y/0/1/0/all/0/1&quot;&gt;Yingxiang Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yu_A/0/1/0/all/0/1&quot;&gt;Adams Wei Yu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zhaoran Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhao_T/0/1/0/all/0/1&quot;&gt;Tuo Zhao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1803.07276">
<title>Fair Deep Learning Prediction for Healthcare Applications with Confounder Filtering. (arXiv:1803.07276v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1803.07276</link>
<description rdf:parseType="Literal">&lt;p&gt;The rapid development of deep learning methods has permitted the fast and
accurate medical decision making from complex structured data, like CT images
or MRI. However, some problems still exist in such applications that may lead
to imperfect predictions. Previous observations have shown that, confounding
factors, if handled inappropriately, will lead to biased prediction results
towards some major properties of the data distribution. In other words, naively
applying deep learning methods in these applications will lead to unfair
prediction results for the minority group defined by the characteristics
including age, gender, or even the hospital that collects the data, etc. In
this paper, extending previous successes in correcting confounders, we propose
a more stable method, namely Confounder Filtering, that can effectively reduce
the influence of confounding factors, leading to better generalizability of
trained discriminative deep neural networks, therefore, fairer prediction
results. Our experimental results indicate that the Confounder Filtering method
is able to improve the performance for different neural networks including CNN,
LSTM, and other arbitrary architecture, different data types including CT-scan,
MRI, and EEG brain wave data, as well as different confounding factors
including age, gender, and physical factors of medical devices etc
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wu_Z/0/1/0/all/0/1&quot;&gt;Zhenglin Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wang_H/0/1/0/all/0/1&quot;&gt;Haohan Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Cao_M/0/1/0/all/0/1&quot;&gt;Mingze Cao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yin Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Xing_E/0/1/0/all/0/1&quot;&gt;Eric P. Xing&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1804.09314">
<title>Deep Learning for Predicting Asset Returns. (arXiv:1804.09314v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1804.09314</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep learning searches for nonlinear factors for predicting asset returns.
Predictability is achieved via multiple layers of composite factors as opposed
to additive ones. Viewed in this way, asset pricing studies can be revisited
using multi-layer deep learners, such as rectified linear units (ReLU) or
long-short-term-memory (LSTM) for time-series effects. State-of-the-art
algorithms including stochastic gradient descent (SGD), TensorFlow and dropout
design provide imple- mentation and efficient factor exploration. To illustrate
our methodology, we revisit the equity market risk premium dataset of Welch and
Goyal (2008). We find the existence of nonlinear factors which explain
predictability of returns, in particular at the extremes of the characteristic
space. Finally, we conclude with directions for future research.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Feng_G/0/1/0/all/0/1&quot;&gt;Guanhao Feng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+He_J/0/1/0/all/0/1&quot;&gt;Jingyu He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Polson_N/0/1/0/all/0/1&quot;&gt;Nicholas G. Polson&lt;/a&gt;</dc:creator>
</item></rdf:RDF>