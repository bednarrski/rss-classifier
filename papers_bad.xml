<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Boring papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Bad Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-02-14T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04855"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04899"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04986"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05098"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1608.06037"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.05101"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.06509"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.01423"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04799"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04834"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04887"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04987"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05027"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05101"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05141"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05142"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05250"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.03875"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.08287"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.03685"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04826"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04838"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04846"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04849"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04852"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04876"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04893"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04907"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04908"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04911"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04918"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04920"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04944"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04956"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04960"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05035"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05036"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05046"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05074"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05155"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05187"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05193"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05214"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05234"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05249"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.05251"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1605.07950"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1701.07761"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1702.07339"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1702.08420"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1702.08536"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1705.02047"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1706.02524"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1706.05446"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.05115"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.10513"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.00464"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1711.05355"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04725"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1802.04855">
<title>A theoretical guideline for designing an effective adaptive particle swarm. (arXiv:1802.04855v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1802.04855</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper we theoretically investigate underlying assumptions that have
been used for designing adaptive particle swarm optimization algorithms in the
past years. We relate these assumptions to the movement patterns of particles
controlled by coefficient values (inertia weight and acceleration coefficient)
and introduce three factors, namely the autocorrelation of the particle
positions, the average movement distance of the particle in each iteration, and
the focus of the search, that describe these movement patterns. We show how
these factors represent movement patterns of a particle within a swarm and how
they are affected by particle coefficients (i.e., inertia weight and
acceleration coefficients). We derive equations that provide exact coefficient
values to guarantee achieving a desired movement pattern defined by these three
factors within a swarm. We then relate these movements to the searching
capability of particles and provide guideline for designing potentially
successful adaptive methods to control coefficients in particle swarm. Finally,
we propose a new simple time adaptive particle swarm and compare its results
with previous adaptive particle swarm approaches. Our experiments show that the
theoretical findings indeed provide a beneficial guideline for successful
adaptation of the coefficients in the particle swarm optimization algorithm.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bonyadi_M/0/1/0/all/0/1&quot;&gt;Mohammad Reza Bonyadi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04899">
<title>Field-Programmable Deep Neural Network (DNN) Learning and Inference accelerator: a concept. (arXiv:1802.04899v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.04899</link>
<description rdf:parseType="Literal">&lt;p&gt;An accelerator is a specialized integrated circuit designed to perform
specific computations faster than if those were performed by CPU or GPU. A
Field-Programmable DNN learning and inference accelerator (FProg-DNN) using
hybrid systolic and non-systolic techniques, distributed information-control
and deep pipelined structure is proposed and its microarchitecture and
operation presented here. Reconfigurability attends diverse DNN designs and
allows for different number of workers to be assigned to different layers as a
function of the relative difference in computational load among layers. The
computational delay per layer is made roughly the same along pipelined
accelerator structure. VGG-16 and recently proposed Inception Modules are used
for showing the flexibility of the FProg-DNN reconfigurability. Special
structures were also added for a combination of convolution layer, map
coincidence and feedback for state of the art learning with small set of
examples, which is the focus of a companion paper by the author (Franca-Neto,
2018). The accelerator described is able to reconfigure from (1) allocating all
a DNN computations to a single worker in one extreme of sub-optimal performance
to (2) optimally allocating workers per layer according to computational load
in each DNN layer to be realized. Due the pipelined architecture, more than 50x
speedup is achieved relative to GPUs or TPUs. This speed-up is consequence of
hiding the delay in transporting activation outputs from one layer to the next
in a DNN behind the computations in the receiving layer. This FProg-DNN concept
has been simulated and validated at behavioral-functional level.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Franca_Neto_L/0/1/0/all/0/1&quot;&gt;Luiz M Franca-Neto&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04986">
<title>Convolutional Neural Networks over Control Flow Graphs for Software Defect Prediction. (arXiv:1802.04986v1 [cs.SE])</title>
<link>http://arxiv.org/abs/1802.04986</link>
<description rdf:parseType="Literal">&lt;p&gt;Existing defects in software components is unavoidable and leads to not only
a waste of time and money but also many serious consequences. To build
predictive models, previous studies focus on manually extracting features or
using tree representations of programs, and exploiting different machine
learning algorithms. However, the performance of the models is not high since
the existing features and tree structures often fail to capture the semantics
of programs. To explore deeply programs&apos; semantics, this paper proposes to
leverage precise graphs representing program execution flows, and deep neural
networks for automatically learning defect features. Firstly, control flow
graphs are constructed from the assembly instructions obtained by compiling
source code; we thereafter apply multi-view multi-layer directed graph-based
convolutional neural networks (DGCNNs) to learn semantic features. The
experiments on four real-world datasets show that our method significantly
outperforms the baselines including several other deep learning approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Phan_A/0/1/0/all/0/1&quot;&gt;Anh Viet Phan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nguyen_M/0/1/0/all/0/1&quot;&gt;Minh Le Nguyen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bui_L/0/1/0/all/0/1&quot;&gt;Lam Thu Bui&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05098">
<title>DiCE: The Infinitely Differentiable Monte-Carlo Estimator. (arXiv:1802.05098v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.05098</link>
<description rdf:parseType="Literal">&lt;p&gt;The score function estimator is widely used for estimating gradients of
stochastic objectives in Stochastic Computation Graphs (SCG), eg. in
reinforcement learning and meta-learning. While deriving the first-order
gradient estimators by differentiating a surrogate loss (SL) objective is
computationally and conceptually simple, using the same approach for
higher-order gradients is more challenging. Firstly, analytically deriving and
implementing such estimators is laborious and not compliant with automatic
differentiation. Secondly, repeatedly applying SL to construct new objectives
for each order gradient involves increasingly cumbersome graph manipulations.
Lastly, to match the first-order gradient under differentiation, SL treats part
of the cost as a fixed sample, which we show leads to missing and wrong terms
for higher-order gradient estimators. To address all these shortcomings in a
unified way, we introduce DiCE, which provides a single objective that can be
differentiated repeatedly, generating correct gradient estimators of any order
in SCGs. Unlike SL, DiCE relies on automatic differentiation for performing the
requisite graph manipulations. We verify the correctness of DiCE both through a
proof and through numerical evaluation of the DiCE gradient estimates. We also
use DiCE to propose and evaluate a novel approach for multi-agent learning. Our
code is available at https://goo.gl/xkkGxN.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Foerster_J/0/1/0/all/0/1&quot;&gt;Jakob Foerster&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Farquhar_G/0/1/0/all/0/1&quot;&gt;Greg Farquhar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Al_Shedivat_M/0/1/0/all/0/1&quot;&gt;Maruan Al-Shedivat&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rocktaschel_T/0/1/0/all/0/1&quot;&gt;Tim Rockt&amp;#xe4;schel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xing_E/0/1/0/all/0/1&quot;&gt;Eric P. Xing&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Whiteson_S/0/1/0/all/0/1&quot;&gt;Shimon Whiteson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1608.06037">
<title>Lets keep it simple, Using simple architectures to outperform deeper and more complex architectures. (arXiv:1608.06037v7 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1608.06037</link>
<description rdf:parseType="Literal">&lt;p&gt;Major winning Convolutional Neural Networks (CNNs), such as AlexNet, VGGNet,
ResNet, GoogleNet, include tens to hundreds of millions of parameters, which
impose considerable computation and memory overhead. This limits their
practical use for training, optimization and memory efficiency. On the
contrary, light-weight architectures, being proposed to address this issue,
mainly suffer from low accuracy. These inefficiencies mostly stem from
following an ad hoc procedure. We propose a simple architecture, called
SimpleNet, based on a set of designing principles, with which we empirically
show, a well-crafted yet simple and reasonably deep architecture can perform on
par with deeper and more complex architectures. SimpleNet provides a good
tradeoff between the computation/memory efficiency and the accuracy. Our simple
13-layer architecture outperforms most of the deeper and complex architectures
to date such as VGGNet, ResNet, and GoogleNet on several well-known benchmarks
while having 2 to 25 times fewer number of parameters and operations. This
makes it very handy for embedded system or system with computational and memory
limitations. We achieved state-of-the-art result on CIFAR10 outperforming
several heavier architectures, near state of the art on MNIST and competitive
results on CIFAR100 and SVHN. Models are made available at:
https://github.com/Coderx7/SimpleNet
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hasanpour_S/0/1/0/all/0/1&quot;&gt;Seyyed Hossein Hasanpour&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rouhani_M/0/1/0/all/0/1&quot;&gt;Mohammad Rouhani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fayyaz_M/0/1/0/all/0/1&quot;&gt;Mohsen Fayyaz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sabokrou_M/0/1/0/all/0/1&quot;&gt;Mohammad Sabokrou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.05101">
<title>Fixing Weight Decay Regularization in Adam. (arXiv:1711.05101v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1711.05101</link>
<description rdf:parseType="Literal">&lt;p&gt;L$_2$ regularization and weight decay regularization are equivalent for
standard stochastic gradient descent (when rescaled by the learning rate), but
as we demonstrate this is \emph{not} the case for adaptive gradient algorithms,
such as Adam. While common deep learning frameworks of these algorithms
implement L$_2$ regularization (often calling it &quot;weight decay&quot; in what may be
misleading due to the inequivalence we expose), we propose a simple
modification to recover the original formulation of weight decay regularization
by decoupling the weight decay from the optimization steps taken w.r.t. the
loss function. We provide empirical evidence that our proposed modification (i)
decouples the optimal choice of weight decay factor from the setting of the
learning rate for both standard SGD and Adam, and (ii) substantially improves
Adam&apos;s generalization performance, allowing it to compete with SGD with
momentum on image classification datasets (on which it was previously typically
outperformed by the latter). We also propose a version of Adam with warm
restarts (AdamWR) that has strong anytime performance while achieving
state-of-the-art results on CIFAR-10 and ImageNet32x32. Our source code is
available at https://github.com/loshchil/AdamW-and-SGDW
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Loshchilov_I/0/1/0/all/0/1&quot;&gt;Ilya Loshchilov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hutter_F/0/1/0/all/0/1&quot;&gt;Frank Hutter&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.06509">
<title>Bidirectional deep-readout echo state networks. (arXiv:1711.06509v3 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1711.06509</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a deep architecture for the classification of multivariate time
series. By means of a recurrent and untrained reservoir we generate a vectorial
representation that embeds temporal relationships in the data. To improve the
memorization capability, we implement a bidirectional reservoir, whose last
state captures also past dependencies in the input. We apply dimensionality
reduction to the final reservoir states to obtain compressed fixed size
representations of the time series. These are subsequently fed into a deep
feedforward network trained to perform the final classification. We test our
architecture on benchmark datasets and on a real-world use-case of blood
samples classification. Results show that our method performs better than a
standard echo state network and, at the same time, achieves results comparable
to a fully-trained recurrent network, but with a faster training.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bianchi_F/0/1/0/all/0/1&quot;&gt;Filippo Maria Bianchi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Scardapane_S/0/1/0/all/0/1&quot;&gt;Simone Scardapane&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lokse_S/0/1/0/all/0/1&quot;&gt;Sigurd L&amp;#xf8;kse&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jenssen_R/0/1/0/all/0/1&quot;&gt;Robert Jenssen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.01423">
<title>Overcoming catastrophic forgetting with hard attention to the task. (arXiv:1801.01423v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1801.01423</link>
<description rdf:parseType="Literal">&lt;p&gt;Catastrophic forgetting occurs when a neural network loses the information
learned in a previous task after training on subsequent tasks. This problem
remains a hurdle for artificial intelligence systems with sequential learning
capabilities. In this paper, we propose a task-based hard attention mechanism
that preserves previous tasks&apos; information without affecting the current task&apos;s
learning. A hard attention mask is learned concurrently to every task, through
stochastic gradient descent, and previous masks are exploited to condition such
learning. We show that the proposed mechanism is effective for reducing
catastrophic forgetting, cutting current rates by 45 to 80%. We also show that
it is robust to different hyperparameter choices, and that it offers a number
of monitoring capabilities. The approach features the possibility to control
both the stability and compactness of the learned knowledge, which we believe
makes it also attractive for online learning or network compression
applications.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Serra_J/0/1/0/all/0/1&quot;&gt;Joan Serr&amp;#xe0;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Suris_D/0/1/0/all/0/1&quot;&gt;D&amp;#xed;dac Sur&amp;#xed;s&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Miron_M/0/1/0/all/0/1&quot;&gt;Marius Miron&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Karatzoglou_A/0/1/0/all/0/1&quot;&gt;Alexandros Karatzoglou&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04799">
<title>TVM: End-to-End Optimization Stack for Deep Learning. (arXiv:1802.04799v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.04799</link>
<description rdf:parseType="Literal">&lt;p&gt;Scalable frameworks, such as TensorFlow, MXNet, Caffe, and PyTorch drive the
current popularity and utility of deep learning. However, these frameworks are
optimized for a narrow range of server-class GPUs and deploying workloads to
other platforms such as mobile phones, embedded devices, and specialized
accelerators (e.g., FPGAs, ASICs) requires laborious manual effort. We propose
TVM, an end-to-end optimization stack that exposes graph-level and
operator-level optimizations to provide performance portability to deep
learning workloads across diverse hardware back-ends. We discuss the
optimization challenges specific to deep learning that TVM solves: high-level
operator fusion, low-level memory reuse across threads, mapping to arbitrary
hardware primitives, and memory latency hiding. Experimental results
demonstrate that TVM delivers performance across hardware back-ends that are
competitive with state-of-the-art libraries for low-power CPU and server-class
GPUs. We also demonstrate TVM&apos;s ability to target new hardware accelerator
back-ends by targeting an FPGA-based generic deep learning accelerator. The
compiler infrastructure is open sourced.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_T/0/1/0/all/0/1&quot;&gt;Tianqi Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moreau_T/0/1/0/all/0/1&quot;&gt;Thierry Moreau&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_Z/0/1/0/all/0/1&quot;&gt;Ziheng Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shen_H/0/1/0/all/0/1&quot;&gt;Haichen Shen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yan_E/0/1/0/all/0/1&quot;&gt;Eddie Yan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_L/0/1/0/all/0/1&quot;&gt;Leyuan Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hu_Y/0/1/0/all/0/1&quot;&gt;Yuwei Hu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ceze_L/0/1/0/all/0/1&quot;&gt;Luis Ceze&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Guestrin_C/0/1/0/all/0/1&quot;&gt;Carlos Guestrin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Krishnamurthy_A/0/1/0/all/0/1&quot;&gt;Arvind Krishnamurthy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04834">
<title>Challenging Images For Minds and Machines. (arXiv:1802.04834v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.04834</link>
<description rdf:parseType="Literal">&lt;p&gt;There is no denying the tremendous leap in the performance of machine
learning methods in the past half-decade. Some might even say that specific
sub-fields in pattern recognition, such as machine-vision, are as good as
solved, reaching human and super-human levels. Arguably, lack of training data
and computation power are all that stand between us and solving the remaining
ones. In this position paper we underline cases in vision which are challenging
to machines and even to human observers. This is to show limitations of
contemporary models that are hard to ameliorate by following the current trend
to increase training data, network capacity or computational power. Moreover,
we claim that attempting to do so is in principle a suboptimal approach. We
provide a taster of such examples in hope to encourage and challenge the
machine learning community to develop new directions to solve the said
difficulties.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rosenfeld_A/0/1/0/all/0/1&quot;&gt;Amir Rosenfeld&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tsotsos_J/0/1/0/all/0/1&quot;&gt;John K. Tsotsos&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04887">
<title>Probabilistic Warnings in National Security Crises: Pearl Harbor Revisited. (arXiv:1802.04887v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.04887</link>
<description rdf:parseType="Literal">&lt;p&gt;Imagine a situation where a group of adversaries is preparing an attack on
the United States or U.S. interests. An intelligence analyst has observed some
signals, but the situation is rapidly changing. The analyst faces the decision
to alert a principal decision maker that an attack is imminent, or to wait
until more is known about the situation. This warning decision is based on the
analyst&apos;s observation and evaluation of signals, independent or correlated, and
on her updating of the prior probabilities of possible scenarios and their
outcomes. The warning decision also depends on the analyst&apos;s assessment of the
crisis&apos; dynamics and perception of the preferences of the principal decision
maker, as well as the lead time needed for an appropriate response. This
article presents a model to support this analyst&apos;s dynamic warning decision. As
with most problems involving warning, the key is to manage the tradeoffs
between false positives and false negatives given the probabilities and the
consequences of intelligence failures of both types. The model is illustrated
by revisiting the case of the attack on Pearl Harbor in December 1941. It shows
that the radio silence of the Japanese fleet carried considerable information
(Sir Arthur Conan Doyle&apos;s &quot;dog in the night&quot; problem), which was misinterpreted
at the time. Even though the probabilities of different attacks were relatively
low, their consequences were such that the Bayesian dynamic reasoning described
here may have provided valuable information to key decision makers.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Blum_D/0/1/0/all/0/1&quot;&gt;David M. Blum&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pate_Cornell_M/0/1/0/all/0/1&quot;&gt;M. Elisabeth Pate-Cornell&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04987">
<title>PlayeRank: Multi-dimensional and role-aware rating of soccer player performance. (arXiv:1802.04987v1 [stat.AP])</title>
<link>http://arxiv.org/abs/1802.04987</link>
<description rdf:parseType="Literal">&lt;p&gt;The problem of rating the performance of soccer players is attracting the
interest of many companies, websites, and the scientific community, thanks to
the availability of massive data capturing all the events generated during a
game (e.g., tackles, passes, shots, etc.). Existing approaches fail to fully
exploit the richness of the available data and lack of a proper validation. In
this paper, we design and implement {\sf PlayeRank}, a data-driven framework
that offers a principled multi-dimensional and role-aware evaluation of the
performance of soccer players. We validate the framework through an
experimental analysis advised by soccer experts, based on a massive dataset of
millions of events pertaining four seasons of the five prominent European
leagues. Experiments show that {\sf PlayeRank} is robust in agreeing with the
experts&apos; evaluation of players, significantly improving the state of the art.
We also explore an application of PlayeRank --- i.e. searching players --- by
introducing a special form of spatial query on the soccer field. This shows its
flexibility and efficiency, which makes it worth to be used in the design of a
scalable platform for soccer analytics.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pappalardo_L/0/1/0/all/0/1&quot;&gt;Luca Pappalardo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Cintia_P/0/1/0/all/0/1&quot;&gt;Paolo Cintia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ferragina_P/0/1/0/all/0/1&quot;&gt;Paolo Ferragina&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pedreschi_D/0/1/0/all/0/1&quot;&gt;Dino Pedreschi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Giannotti_F/0/1/0/all/0/1&quot;&gt;Fosca Giannotti&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05027">
<title>Not to Cry Wolf: Distantly Supervised Multitask Learning in Critical Care. (arXiv:1802.05027v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.05027</link>
<description rdf:parseType="Literal">&lt;p&gt;Patients in the intensive care unit (ICU) require constant and close
supervision. To assist clinical staff in this task, hospitals use monitoring
systems that trigger audiovisual alarms if their algorithms indicate that a
patient&apos;s condition may be worsening. However, current monitoring systems are
extremely sensitive to movement artefacts and technical errors. As a result,
they typically trigger hundreds to thousands of false alarms per patient per
day - drowning the important alarms in noise and adding to the exhaustion of
clinical staff. In this setting, data is abundantly available, but obtaining
trustworthy annotations by experts is laborious and expensive. We frame the
problem of false alarm reduction from multivariate time series as a
machine-learning task and address it with a novel multitask network
architecture that utilises distant supervision through multiple related
auxiliary tasks in order to reduce the number of expensive labels required for
training. We show that our approach leads to significant improvements over
several state-of-the-art baselines on real-world ICU data and provide new
insights on the importance of task selection and architectural choices in
distantly supervised multitask learning.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schwab_P/0/1/0/all/0/1&quot;&gt;Patrick Schwab&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Keller_E/0/1/0/all/0/1&quot;&gt;Emanuela Keller&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Muroi_C/0/1/0/all/0/1&quot;&gt;Carl Muroi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mack_D/0/1/0/all/0/1&quot;&gt;David J. Mack&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Strassle_C/0/1/0/all/0/1&quot;&gt;Christian Str&amp;#xe4;ssle&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Karlen_W/0/1/0/all/0/1&quot;&gt;Walter Karlen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05101">
<title>Crowd ideation of supervised learning problems. (arXiv:1802.05101v1 [cs.HC])</title>
<link>http://arxiv.org/abs/1802.05101</link>
<description rdf:parseType="Literal">&lt;p&gt;Crowdsourcing is an important avenue for collecting machine learning data,
but crowdsourcing can go beyond simple data collection by employing the
creativity and wisdom of crowd workers. Yet crowd participants are unlikely to
be experts in statistics or predictive modeling, and it is not clear how well
non-experts can contribute creatively to the process of machine learning. Here
we study an end-to-end crowdsourcing algorithm where groups of non-expert
workers propose supervised learning problems, rank and categorize those
problems, and then provide data to train predictive models on those problems.
Problem proposal includes and extends feature engineering because workers
propose the entire problem, not only the input features but also the target
variable. We show that workers without machine learning experience can
collectively construct useful datasets and that predictive models can be
learned on these datasets. In our experiments, the problems proposed by workers
covered a broad range of topics, from politics and current events to problems
capturing health behavior, demographics, and more. Workers also favored
questions showing positively correlated relationships, which has interesting
implications given many supervised learning methods perform as well with strong
negative correlations. Proper instructions are crucial for non-experts, so we
also conducted a randomized trial to understand how different instructions may
influence the types of problems proposed by workers. In general, shifting the
focus of machine learning tasks from designing and training individual
predictive models to problem proposal allows crowdsourcers to design
requirements for problems of interest and then guide workers towards
contributing to the most suitable problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bagrow_J/0/1/0/all/0/1&quot;&gt;James P. Bagrow&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05141">
<title>Deep Learning and Data Assimilation for Real-Time Production Prediction in Natural Gas Wells. (arXiv:1802.05141v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.05141</link>
<description rdf:parseType="Literal">&lt;p&gt;The prediction of the gas production from mature gas wells, due to their
complex end-of-life behavior, is challenging and crucial for operational
decision making. In this paper, we apply a modified deep LSTM model for
prediction of the gas flow rates in mature gas wells, including the
uncertainties in input parameters. Additionally, due to changes in the system
in time and in order to increase the accuracy and robustness of the prediction,
the Ensemble Kalman Filter (EnKF) is used to update the flow rate predictions
based on new observations. The developed approach was tested on the data from
two mature gas production wells in which their production is highly dynamic and
suffering from salt deposition. The results show that the flow predictions
using the EnKF updated model leads to better Jeffreys&apos; J-divergences than the
predictions without the EnKF model updating scheme.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Loh_K/0/1/0/all/0/1&quot;&gt;Kelvin Loh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Omrani_P/0/1/0/all/0/1&quot;&gt;Pejman Shoeibi Omrani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Linden_R/0/1/0/all/0/1&quot;&gt;Ruud van der Linden&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05142">
<title>Morphologic for knowledge dynamics: revision, fusion, abduction. (arXiv:1802.05142v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.05142</link>
<description rdf:parseType="Literal">&lt;p&gt;Several tasks in artificial intelligence require to be able to find models
about knowledge dynamics. They include belief revision, fusion and belief
merging, and abduction. In this paper we exploit the algebraic framework of
mathematical morphology in the context of propositional logic, and define
operations such as dilation or erosion of a set of formulas. We derive concrete
operators, based on a semantic approach, that have an intuitive interpretation
and that are formally well behaved, to perform revision, fusion and abduction.
Computation and tractability are addressed, and simple examples illustrate the
typical results that can be obtained.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bloch_I/0/1/0/all/0/1&quot;&gt;Isabelle Bloch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lang_J/0/1/0/all/0/1&quot;&gt;J&amp;#xe9;r&amp;#xf4;me Lang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Perez_R/0/1/0/all/0/1&quot;&gt;Ram&amp;#xf3;n Pino P&amp;#xe9;rez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Uzcategui_C/0/1/0/all/0/1&quot;&gt;Carlos Uzc&amp;#xe1;tegui&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05250">
<title>Generating Plans that Predict Themselves. (arXiv:1802.05250v1 [cs.RO])</title>
<link>http://arxiv.org/abs/1802.05250</link>
<description rdf:parseType="Literal">&lt;p&gt;Collaboration requires coordination, and we coordinate by anticipating our
teammates&apos; future actions and adapting to their plan. In some cases, our
teammates&apos; actions early on can give us a clear idea of what the remainder of
their plan is, i.e. what action sequence we should expect. In others, they
might leave us less confident, or even lead us to the wrong conclusion. Our
goal is for robot actions to fall in the first category: we want to enable
robots to select their actions in such a way that human collaborators can
easily use them to correctly anticipate what will follow. While previous work
has focused on finding initial plans that convey a set goal, here we focus on
finding two portions of a plan such that the initial portion conveys the final
one. We introduce $t$-\ACty{}: a measure that quantifies the accuracy and
confidence with which human observers can predict the remaining robot plan from
the overall task goal and the observed initial $t$ actions in the plan. We
contribute a method for generating $t$-predictable plans: we search for a full
plan that accomplishes the task, but in which the first $t$ actions make it as
easy as possible to infer the remaining ones. The result is often different
from the most efficient plan, in which the initial actions might leave a lot of
ambiguity as to how the task will be completed. Through an online experiment
and an in-person user study with physical robots, we find that our approach
outperforms a traditional efficiency-based planner in objective and subjective
collaboration metrics.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fisac_J/0/1/0/all/0/1&quot;&gt;Jaime F. Fisac&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_C/0/1/0/all/0/1&quot;&gt;Chang Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hamrick_J/0/1/0/all/0/1&quot;&gt;Jessica B. Hamrick&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sastry_S/0/1/0/all/0/1&quot;&gt;S. Shankar Sastry&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hedrick_J/0/1/0/all/0/1&quot;&gt;J. Karl Hedrick&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Griffiths_T/0/1/0/all/0/1&quot;&gt;Thomas L. Griffiths&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dragan_A/0/1/0/all/0/1&quot;&gt;Anca D. Dragan&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.03875">
<title>Specification Inference from Demonstrations. (arXiv:1710.03875v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1710.03875</link>
<description rdf:parseType="Literal">&lt;p&gt;Learning from expert demonstrations has received a lot of attention in
artificial intelligence and machine learning. The goal is to infer the
underlying reward function that an agent is optimizing given a set of
observations of the agent&apos;s behavior over time in a variety of circumstances,
the system state trajectories, and a plant model specifying the evolution of
the system state for different agent&apos;s actions. The system is often modeled as
a Markov decision process, that is, the next state depends only on the current
state and agent&apos;s action, and the the agent&apos;s choice of action depends only on
the current state. While the former is a Markovian assumption on the evolution
of system state, the later assumes that the target reward function is itself
Markovian. In this work, we explore learning a class of non-Markovian reward
functions, known in the formal methods literature as specifications. These
specifications offer better composition, transferability, and interpretability.
We then show that inferring the specification can be done efficiently without
unrolling the transition system. We demonstrate on a 2-d grid world example.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vazquez_Chanlatte_M/0/1/0/all/0/1&quot;&gt;Marcell Vazquez-Chanlatte&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jha_S/0/1/0/all/0/1&quot;&gt;Susmit Jha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tiwari_A/0/1/0/all/0/1&quot;&gt;Ashish Tiwari&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Seshia_S/0/1/0/all/0/1&quot;&gt;Sanjit A. Seshia&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.08287">
<title>Directly Estimating the Variance of the {\lambda}-Return Using Temporal-Difference Methods. (arXiv:1801.08287v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1801.08287</link>
<description rdf:parseType="Literal">&lt;p&gt;This paper investigates estimating the variance of a temporal-difference
learning agent&apos;s update target. Most reinforcement learning methods use an
estimate of the value function, which captures how good it is for the agent to
be in a particular state and is mathematically expressed as the expected sum of
discounted future rewards (called the return). These values can be
straightforwardly estimated by averaging batches of returns using Monte Carlo
methods. However, if we wish to update the agent&apos;s value estimates during
learning--before terminal outcomes are observed--we must use a different
estimation target called the {\lambda}-return, which truncates the return with
the agent&apos;s own estimate of the value function. Temporal difference learning
methods estimate the expected {\lambda}-return for each state, allowing these
methods to update online and incrementally, and in most cases achieve better
generalization error and faster learning than Monte Carlo methods. Naturally
one could attempt to estimate higher-order moments of the {\lambda}-return.
This paper is about estimating the variance of the {\lambda}-return. Prior work
has shown that given estimates of the variance of the {\lambda}-return,
learning systems can be constructed to (1) mitigate risk in action selection,
and (2) automatically adapt the parameters of the learning process itself to
improve performance. Unfortunately, existing methods for estimating the
variance of the {\lambda}-return are complex and not well understood
empirically. We contribute a method for estimating the variance of the
{\lambda}-return directly using policy evaluation methods from reinforcement
learning. Our approach is significantly simpler than prior methods that
independently estimate the second moment of the {\lambda}-return. Empirically
our new approach behaves at least as well as existing approaches, but is
generally more robust.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sherstan_C/0/1/0/all/0/1&quot;&gt;Craig Sherstan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bennett_B/0/1/0/all/0/1&quot;&gt;Brendan Bennett&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Young_K/0/1/0/all/0/1&quot;&gt;Kenny Young&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ashley_D/0/1/0/all/0/1&quot;&gt;Dylan R. Ashley&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+White_A/0/1/0/all/0/1&quot;&gt;Adam White&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+White_M/0/1/0/all/0/1&quot;&gt;Martha White&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sutton_R/0/1/0/all/0/1&quot;&gt;Richard S. Sutton&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.03685">
<title>Learning a SAT Solver from Single-Bit Supervision. (arXiv:1802.03685v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1802.03685</link>
<description rdf:parseType="Literal">&lt;p&gt;We present NeuroSAT, a message passing neural network that learns to solve
SAT problems after only being trained as a classifier to predict
satisfiability. Although it is not competitive with state-of-the-art SAT
solvers, NeuroSAT can solve problems that are substantially larger and more
difficult than it ever saw during training by simply running for more
iterations. Moreover, NeuroSAT generalizes to novel distributions; after
training only on random SAT problems, at test time it can solve SAT problems
encoding graph coloring, clique detection, dominating set, and vertex cover
problems, all on a range of distributions over small random graphs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Selsam_D/0/1/0/all/0/1&quot;&gt;Daniel Selsam&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lamm_M/0/1/0/all/0/1&quot;&gt;Matthew Lamm&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bunz_B/0/1/0/all/0/1&quot;&gt;Benedikt B&amp;#xfc;nz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liang_P/0/1/0/all/0/1&quot;&gt;Percy Liang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moura_L/0/1/0/all/0/1&quot;&gt;Leonardo de Moura&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dill_D/0/1/0/all/0/1&quot;&gt;David L. Dill&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04826">
<title>Leveraging the Exact Likelihood of Deep Latent Variables Models. (arXiv:1802.04826v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.04826</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep latent variable models combine the approximation abilities of deep
neural networks and the statistical foundations of generative models. The
induced data distribution is an infinite mixture model whose density is
extremely delicate to compute. Variational methods are consequently used for
inference, following the seminal work of Rezende et al. (2014) and Kingma and
Welling (2014). We study the well-posedness of the exact problem (maximum
likelihood) these techniques approximatively solve. In particular, we show that
most unconstrained models used for continuous data have an unbounded
likelihood. This ill-posedness and the problems it causes are illustrated on
real data. We also show how to insure the existence of maximum likelihood
estimates, and draw useful connections with nonparametric mixture models.
Furthermore, we describe an algorithm that allows to perform missing data
imputation using the exact conditional likelihood of a deep latent variable
model. On several real data sets, our algorithm consistently and significantly
outperforms the usual imputation scheme used within deep latent variable
models.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mattei_P/0/1/0/all/0/1&quot;&gt;Pierre-Alexandre Mattei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Frellsen_J/0/1/0/all/0/1&quot;&gt;Jes Frellsen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04838">
<title>Network Estimation from Point Process Data. (arXiv:1802.04838v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.04838</link>
<description rdf:parseType="Literal">&lt;p&gt;Consider observing a collection of discrete events within a network that
reflect how network nodes influence one another. Such data are common in spike
trains recorded from biological neural networks, interactions within a social
network, and a variety of other settings. Data of this form may be modeled as
self-exciting point processes, in which the likelihood of future events depends
on the past events. This paper addresses the problem of estimating
self-excitation parameters and inferring the underlying functional network
structure from self-exciting point process data. Past work in this area was
limited by strong assumptions which are addressed by the novel approach here.
Specifically, in this paper we (1) incorporate saturation in a point process
model which both ensures stability and models non-linear thresholding effects;
(2) impose general low-dimensional structural assumptions that include
sparsity, group sparsity and low-rankness that allows bounds to be developed in
the high-dimensional setting; and (3) incorporate long-range memory effects
through moving average and higher-order auto-regressive components. Using our
general framework, we provide a number of novel theoretical guarantees for
high-dimensional self-exciting point processes that reflect the role played by
the underlying network structure and long-term memory. We also provide
simulations and real data examples to support our methodology and main results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mark_B/0/1/0/all/0/1&quot;&gt;Benjamin Mark&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Raskutti_G/0/1/0/all/0/1&quot;&gt;Garvesh Raskutti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Willett_R/0/1/0/all/0/1&quot;&gt;Rebecca Willett&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04846">
<title>State Space Gaussian Processes with Non-Gaussian Likelihood. (arXiv:1802.04846v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.04846</link>
<description rdf:parseType="Literal">&lt;p&gt;We provide a comprehensive overview and tooling for GP modeling with
non-Gaussian likelihoods using state space methods. The state space formulation
allows for solving one-dimensional GP models in $\mathcal{O}(n)$ time and
memory complexity. While existing literature has focused on the connection
between GP regression and state space methods, the computational primitives
allowing for inference using general likelihoods in combination with the
Laplace approximation (LA), variational Bayes (VB), and assumed density
filtering (ADF) / expectation propagation (EP) schemes has been largely
overlooked. We present means of combining the efficient $\mathcal{O}(n)$ state
space methodology with existing inference methods. We also further extend
existing methods, and provide unifying code implementing all approaches.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Nickisch_H/0/1/0/all/0/1&quot;&gt;Hannes Nickisch&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Solin_A/0/1/0/all/0/1&quot;&gt;Arno Solin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Grigorievskiy_A/0/1/0/all/0/1&quot;&gt;Alexander Grigorievskiy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04849">
<title>Clustering and Semi-Supervised Classification for Clickstream Data via Mixture Models. (arXiv:1802.04849v1 [stat.ME])</title>
<link>http://arxiv.org/abs/1802.04849</link>
<description rdf:parseType="Literal">&lt;p&gt;Finite mixture models have been used for unsupervised learning for over 60
years, and their use within the semi-supervised paradigm is becoming more
commonplace. Clickstream data is one of the various emerging data types that
demands particular attention because there is a notable paucity of statistical
learning approaches currently available. A mixture of first order continuous
time Markov models is introduced for unsupervised and semi-supervised learning
of clickstream data. This approach assumes continuous time, which distinguishes
it from existing mixture model-based approaches; practically, this allows
account to be taken of the amount of time each user spends on each website. The
approach is evaluated, and compared to the discrete time approach, using
simulated and real data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gallaugher_M/0/1/0/all/0/1&quot;&gt;Michael P.B. Gallaugher&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+McNicholas_P/0/1/0/all/0/1&quot;&gt;Paul D. McNicholas&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04852">
<title>Persistence Codebooks for Topological Data Analysis. (arXiv:1802.04852v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.04852</link>
<description rdf:parseType="Literal">&lt;p&gt;Topological data analysis, such as persistent homology has shown beneficial
properties for machine learning in many tasks. Topological representations,
such as the persistence diagram (PD), however, have a complex structure
(multiset of intervals) which makes it difficult to combine with typical
machine learning workflows. We present novel compact fixed-size vectorial
representations of PDs based on clustering and bag of words encodings that cope
well with the inherent sparsity of PDs. Our novel representations outperform
state-of-the-art approaches from topological data analysis and are
computationally more efficient.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zielinski_B/0/1/0/all/0/1&quot;&gt;Bartosz Zielinski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Juda_M/0/1/0/all/0/1&quot;&gt;Mateusz Juda&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zeppelzauer_M/0/1/0/all/0/1&quot;&gt;Matthias Zeppelzauer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04876">
<title>Statistical Inference for Online Learning and Stochastic Approximation via Hierarchical Incremental Gradient Descent. (arXiv:1802.04876v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.04876</link>
<description rdf:parseType="Literal">&lt;p&gt;Stochastic gradient descent (SGD) is an immensely popular approach for online
learning in settings where data arrives in a stream or data sizes are very
large. However, despite an ever-increasing volume of work on SGD, much less is
known about the statistical inferential properties of SGD-based predictions.
Taking a fully inferential viewpoint, this paper introduces a novel procedure
termed HiGrad to conduct statistical inference for online learning, without
incurring additional computational cost compared with SGD. The HiGrad procedure
begins by performing SGD updates for a while and then splits the single thread
into several threads, and this procedure hierarchically operates in this
fashion along each thread. With predictions provided by multiple threads in
place, a t-based confidence interval is constructed by decorrelating
predictions using covariance structures given by the Ruppert--Polyak averaging
scheme. Under certain regularity conditions, the HiGrad confidence interval is
shown to attain asymptotically exact coverage probability. Finally, the
performance of HiGrad is evaluated through extensive simulation studies and a
real data example. An R package higrad has been developed to implement the
method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Su_W/0/1/0/all/0/1&quot;&gt;Weijie Su&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhu_Y/0/1/0/all/0/1&quot;&gt;Yuancheng Zhu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04893">
<title>Uncertainty Estimation via Stochastic Batch Normalization. (arXiv:1802.04893v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.04893</link>
<description rdf:parseType="Literal">&lt;p&gt;In this work, we investigate Batch Normalization technique and propose its
probabilistic interpretation. We propose a probabilistic model and show that
Batch Normalization maximazes the lower bound of its marginalized
log-likelihood. Then, according to the new probabilistic model, we design an
algorithm which acts consistently during train and test. However, inference
becomes computationally inefficient. To reduce memory and computational cost,
we propose Stochastic Batch Normalization -- an efficient approximation of
proper inference procedure. This method provides us with a scalable uncertainty
estimation technique. We demonstrate the performance of Stochastic Batch
Normalization on popular architectures (including deep convolutional
architectures: VGG-like and ResNets) for MNIST and CIFAR-10 datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Atanov_A/0/1/0/all/0/1&quot;&gt;Andrei Atanov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ashukha_A/0/1/0/all/0/1&quot;&gt;Arsenii Ashukha&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Molchanov_D/0/1/0/all/0/1&quot;&gt;Dmitry Molchanov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Neklyudov_K/0/1/0/all/0/1&quot;&gt;Kirill Neklyudov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Vetrov_D/0/1/0/all/0/1&quot;&gt;Dmitry Vetrov&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04907">
<title>Compressive Sensing with Low Precision Data Representation: Radio Astronomy and Beyond. (arXiv:1802.04907v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.04907</link>
<description rdf:parseType="Literal">&lt;p&gt;Modern scientific instruments produce vast amounts of data, which can
overwhelm the processing ability of computer systems. Lossy compression of data
is an intriguing solution but comes with its own dangers, such as potential
signal loss, and the need for careful parameter optimization. In this work, we
focus on a setting where this problem is especially acute compressive sensing
frameworks for radio astronomy and ask: Can the precision of the data
representation be lowered for all input data, with recovery guarantees and good
practical performance? Our first contribution is a theoretical analysis of the
Iterative Hard Thresholding (IHT) algorithm when all input data, that is, the
measurement matrix and the observation, are quantized aggressively, to as
little as 2 bits per value. Under reasonable constraints, we show that there
exists a variant of low precision IHT which can still provide recovery
guarantees. The second contribution is a tailored analysis of our general
quantized framework to radio astronomy, showing that its conditions are
satisfied in this case. We evaluate our approach using an FPGA implementation,
and show that it can achieve up to 9.19x speed up with negligible loss of
recovery quality, on real telescope data
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gurel_N/0/1/0/all/0/1&quot;&gt;Nezihe Merve G&amp;#xfc;rel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kara_K/0/1/0/all/0/1&quot;&gt;Kaan Kara&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Alistarh_D/0/1/0/all/0/1&quot;&gt;Dan Alistarh&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhang_C/0/1/0/all/0/1&quot;&gt;Ce Zhang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04908">
<title>Conditional Density Estimation with Bayesian Normalising Flows. (arXiv:1802.04908v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.04908</link>
<description rdf:parseType="Literal">&lt;p&gt;Modeling complex conditional distributions is critical in a variety of
settings. Despite a long tradition of research into conditional density
estimation, current methods employ either simple parametric forms or are
difficult to learn in practice. This paper employs normalising flows as a
flexible likelihood model and presents an efficient method for fitting them to
complex densities. These estimators must trade-off between modeling
distributional complexity, functional complexity and heteroscedasticity without
overfitting. We recognize these trade-offs as modeling decisions and develop a
Bayesian framework for placing priors over these conditional density estimators
using variational Bayesian neural networks. We evaluate this method on several
small benchmark regression datasets, on some of which it obtains state of the
art performance. Finally, we apply the method to two spatial density modeling
tasks with over 1 million datapoints using the New York City yellow taxi
dataset and the Chicago crime dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Trippe_B/0/1/0/all/0/1&quot;&gt;Brian L Trippe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Turner_R/0/1/0/all/0/1&quot;&gt;Richard E Turner&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04911">
<title>Linear-Time Algorithm for Learning Large-Scale Sparse Graphical Models. (arXiv:1802.04911v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.04911</link>
<description rdf:parseType="Literal">&lt;p&gt;The sparse inverse covariance estimation problem is commonly solved using an
$\ell_{1}$-regularized Gaussian maximum likelihood estimator known as
&quot;graphical lasso&quot;, but its computational cost becomes prohibitive for large
data sets. A recent line of results showed--under mild assumptions--that the
graphical lasso estimator can be retrieved by soft-thresholding the sample
covariance matrix and solving a maximum determinant matrix completion (MDMC)
problem. This paper proves an extension of this result, and describes a
Newton-CG algorithm to efficiently solve the MDMC problem. Assuming that the
thresholded sample covariance matrix is sparse with a sparse Cholesky
factorization, we prove that the algorithm converges to an $\epsilon$-accurate
solution in $O(n\log(1/\epsilon))$ time and $O(n)$ memory. The algorithm is
highly efficient in practice: we solve the associated MDMC problems with as
many as 200,000 variables to 7-9 digits of accuracy in less than an hour on a
standard laptop computer running MATLAB.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhang_R/0/1/0/all/0/1&quot;&gt;Richard Y. Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Fattahi_S/0/1/0/all/0/1&quot;&gt;Salar Fattahi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sojoudi_S/0/1/0/all/0/1&quot;&gt;Somayeh Sojoudi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04918">
<title>Prophit: Causal inverse classification for multiple continuously valued treatment policies. (arXiv:1802.04918v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.04918</link>
<description rdf:parseType="Literal">&lt;p&gt;Inverse classification uses an induced classifier as a queryable oracle to
guide test instances towards a preferred posterior class label. The result
produced from the process is a set of instance-specific feature perturbations,
or recommendations, that optimally improve the probability of the class label.
In this work, we adopt a causal approach to inverse classification, eliciting
treatment policies (i.e., feature perturbations) for models induced with causal
properties. In so doing, we solve a long-standing problem of eliciting
multiple, continuously valued treatment policies, using an updated framework
and corresponding set of assumptions, which we term the inverse classification
potential outcomes framework (ICPOF), along with a new measure, referred to as
the individual future estimated effects ($i$FEE). We also develop the
approximate propensity score (APS), based on Gaussian processes, to weight
treatments, much like the inverse propensity score weighting used in past
works. We demonstrate the viability of our methods on student performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lash_M/0/1/0/all/0/1&quot;&gt;Michael T. Lash&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_Q/0/1/0/all/0/1&quot;&gt;Qihang Lin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Street_W/0/1/0/all/0/1&quot;&gt;W. Nick Street&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04920">
<title>DVAE++: Discrete Variational Autoencoders with Overlapping Transformations. (arXiv:1802.04920v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.04920</link>
<description rdf:parseType="Literal">&lt;p&gt;Training of discrete latent variable models remains challenging because
passing gradient information through discrete units is difficult. We propose a
new class of smoothing transformations based on a mixture of two overlapping
distributions, and show that the proposed transformation can be used for
training binary latent models with either directed or undirected priors. We
derive a new variational bound to efficiently train with Boltzmann machine
priors. Using this bound, we develop DVAE++, a generative model with a global
discrete prior and a hierarchy of convolutional continuous variables.
Experiments on several benchmarks show that overlapping transformations
outperform other recent continuous relaxations of discrete latent variables
including Gumbel-Softmax (Maddison et al., 2016; Jang et al., 2016), and
discrete variational autoencoders (Rolfe 2016).
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vahdat_A/0/1/0/all/0/1&quot;&gt;Arash Vahdat&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Macready_W/0/1/0/all/0/1&quot;&gt;William G. Macready&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bian_Z/0/1/0/all/0/1&quot;&gt;Zhengbing Bian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khoshaman_A/0/1/0/all/0/1&quot;&gt;Amir Khoshaman&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04944">
<title>Edge Attention-based Multi-Relational Graph Convolutional Networks. (arXiv:1802.04944v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.04944</link>
<description rdf:parseType="Literal">&lt;p&gt;Graph convolutional network (GCN) is generalization of convolutional neural
network (CNN) to work with arbitrarily structured graphs. A binary adjacency
matrix is commonly used in training a GCN. Recently, the attention mechanism
allows the network to learn a dynamic and adaptive aggregation of the
neighborhood. We propose a new GCN model on the graphs where edges are
characterized in multiple views or precisely in terms of multiple
relationships. For instance, in chemical graph theory, compound structures are
often represented by the hydrogen-depleted molecular graph where nodes
correspond to atoms and edges correspond to chemical bonds. Multiple attributes
can be important to characterize chemical bonds, such as atom pair (the types
of atoms that a bond connects), aromaticity, and whether a bond is in a ring.
The different attributes lead to different graph representations for the same
molecule. There is growing interests in both chemistry and machine learning
fields to directly learn molecular properties of compounds from the molecular
graph, instead of from fingerprints predefined by chemists. The proposed GCN
model, which we call edge attention-based multi-relational GCN (EAGCN), jointly
learns attention weights and node features in graph convolution. For each bond
attribute, a real-valued attention matrix is used to replace the binary
adjacency matrix. By designing a dictionary for the edge attention, and forming
the attention matrix of each molecule by looking up the dictionary, the EAGCN
exploits correspondence between bonds in different molecules. The prediction of
compound properties is based on the aggregated node features, which is
independent of the varying molecule (graph) size. We demonstrate the efficacy
of the EAGCN on multiple chemical datasets: Tox21, HIV, Freesolv, and
Lipophilicity, and interpret the resultant attention weights.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Shang_C/0/1/0/all/0/1&quot;&gt;Chao Shang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Liu_Q/0/1/0/all/0/1&quot;&gt;Qinqing Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chen_K/0/1/0/all/0/1&quot;&gt;Ko-Shin Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sun_J/0/1/0/all/0/1&quot;&gt;Jiangwen Sun&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lu_J/0/1/0/all/0/1&quot;&gt;Jin Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yi_J/0/1/0/all/0/1&quot;&gt;Jinfeng Yi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bi_J/0/1/0/all/0/1&quot;&gt;Jinbo Bi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04956">
<title>D2KE: From Distance to Kernel and Embedding. (arXiv:1802.04956v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.04956</link>
<description rdf:parseType="Literal">&lt;p&gt;For many machine learning problem settings, particularly with structured
inputs such as sequences or sets of objects, a distance measure between inputs
can be specified more naturally than a feature representation. However, most
standard machine models are designed for inputs with a vector feature
representation. In this work, we consider the estimation of a function
$f:\mathcal{X} \rightarrow \R$ based solely on a dissimilarity measure
$d:\mathcal{X}\times\mathcal{X} \rightarrow \R$ between inputs. In particular,
we propose a general framework to derive a family of \emph{positive definite
kernels} from a given dissimilarity measure, which subsumes the widely-used
\emph{representative-set method} as a special case, and relates to the
well-known \emph{distance substitution kernel} in a limiting case. We show that
functions in the corresponding Reproducing Kernel Hilbert Space (RKHS) are
Lipschitz-continuous w.r.t. the given distance metric. We provide a tractable
algorithm to estimate a function from this RKHS, and show that it enjoys better
generalizability than Nearest-Neighbor estimates. Our approach draws from the
literature of Random Features, but instead of deriving feature maps from an
existing kernel, we construct novel kernels from a random feature map, that we
specify given the distance measure. We conduct classification experiments with
such disparate domains as strings, time series, and sets of vectors, where our
proposed framework compares favorably to existing distance-based learning
methods such as $k$-nearest-neighbors, distance-substitution kernels,
pseudo-Euclidean embedding, and the representative-set method.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wu_L/0/1/0/all/0/1&quot;&gt;Lingfei Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yen_I/0/1/0/all/0/1&quot;&gt;Ian En-Hsu Yen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Xu_F/0/1/0/all/0/1&quot;&gt;Fangli Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ravikuma_P/0/1/0/all/0/1&quot;&gt;Pradeep Ravikuma&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Witbrock_M/0/1/0/all/0/1&quot;&gt;Michael Witbrock&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04960">
<title>Vertex nomination: The canonical sampling and the extended spectral nomination schemes. (arXiv:1802.04960v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.04960</link>
<description rdf:parseType="Literal">&lt;p&gt;Suppose that one particular block in a stochastic block model is deemed
&quot;interesting,&quot; but block labels are only observed for a few of the vertices.
Utilizing a graph realized from the model, the vertex nomination task is to
order the vertices with unobserved block labels into a &quot;nomination list&quot; with
the goal of having an abundance of interesting vertices near the top of the
list. In this paper we extend and enhance two basic vertex nomination schemes;
the canonical nomination scheme ${\mathcal L}^C$ and the spectral partitioning
nomination scheme ${\mathcal L}^P$.
&lt;/p&gt;
&lt;p&gt;The canonical nomination scheme ${\mathcal L}^C$ is provably optimal, but is
computationally intractable, being impractical to implement even on modestly
sized graphs. With this in mind, we introduce a scalable, Markov chain Monte
Carlo-based nomination scheme, called the {\it canonical sampling nomination
scheme} ${\mathcal L}^{CS}$, that converges to the canonical nomination scheme
${\mathcal L}^{C}$ as the amount of sampling goes to infinity. We also
introduce a novel spectral partitioning nomination scheme called the {\it
extended spectral partitioning nomination scheme} ${\mathcal L}^{EP}$.
Real-data and simulation experiments are employed to illustrate the
effectiveness of these vertex nomination schemes, as well as their empirical
computational complexity.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yoder_J/0/1/0/all/0/1&quot;&gt;Jordan Yoder&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chen_L/0/1/0/all/0/1&quot;&gt;Li Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pao_H/0/1/0/all/0/1&quot;&gt;Henry Pao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bridgeford_E/0/1/0/all/0/1&quot;&gt;Eric Bridgeford&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Levin_K/0/1/0/all/0/1&quot;&gt;Keith Levin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Fishkind_D/0/1/0/all/0/1&quot;&gt;Donniell Fishkind&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Priebe_C/0/1/0/all/0/1&quot;&gt;Carey Priebe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lyzinski_V/0/1/0/all/0/1&quot;&gt;Vince Lyzinski&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05035">
<title>Nonnegative PARAFAC2: a flexible coupling approach. (arXiv:1802.05035v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.05035</link>
<description rdf:parseType="Literal">&lt;p&gt;Modeling variability in tensor decomposition methods is one of the challenges
of source separation. One possible solution to account for variations from one
data set to another, jointly analysed, is to resort to the PARAFAC2 model.
However, so far imposing constraints on the mode with variability has not been
possible. In the following manuscript, a relaxation of the PARAFAC2 model is
introduced, that allows for imposing nonnegativity constraints on the varying
mode. An algorithm to compute the proposed flexible PARAFAC2 model is derived,
and its performance is studied on both synthetic and chemometrics data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Cohen_J/0/1/0/all/0/1&quot;&gt;Jeremy E.Cohen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Bro_R/0/1/0/all/0/1&quot;&gt;Rasmus Bro&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05036">
<title>Robust Continuous Co-Clustering. (arXiv:1802.05036v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.05036</link>
<description rdf:parseType="Literal">&lt;p&gt;Clustering consists of grouping together samples giving their similar
properties. The problem of modeling simultaneously groups of samples and
features is known as Co-Clustering. This paper introduces ROCCO - a Robust
Continuous Co-Clustering algorithm. ROCCO is a scalable, hyperparameter-free,
easy and ready to use algorithm to address Co-Clustering problems in practice
over massive cross-domain datasets. It operates by learning a graph-based
two-sided representation of the input matrix. The underlying proposed
optimization problem is non-convex, which assures a flexible pool of solutions.
Moreover, we prove that it can be solved with a near linear time complexity on
the input size. An exhaustive large-scale experimental testbed conducted with
both synthetic and real-world datasets demonstrates ROCCO&apos;s properties in
practice: (i) State-of-the-art performance in cross-domain real-world problems
including Biomedicine and Text Mining; (ii) very low sensitivity to
hyperparameter settings; (iii) robustness to noise and (iv) a linear empirical
scalability in practice. These results highlight ROCCO as a powerful
general-purpose co-clustering algorithm for cross-domain practitioners,
regardless of their technical background.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+He_X/0/1/0/all/0/1&quot;&gt;Xiao He&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moreira_Matias_L/0/1/0/all/0/1&quot;&gt;Luis Moreira-Matias&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05046">
<title>Benchmarking Framework for Performance-Evaluation of Causal Inference Analysis. (arXiv:1802.05046v1 [stat.ME])</title>
<link>http://arxiv.org/abs/1802.05046</link>
<description rdf:parseType="Literal">&lt;p&gt;Causal inference analysis is the estimation of the effects of actions on
outcomes. In the context of healthcare data this means estimating the outcome
of counter-factual treatments (i.e. including treatments that were not
observed) on a patient&apos;s outcome. Compared to classic machine learning methods,
evaluation and validation of causal inference analysis is more challenging
because ground truth data of counter-factual outcome can never be obtained in
any real-world scenario. Here, we present a comprehensive framework for
benchmarking algorithms that estimate causal effect. The framework includes
unlabeled data for prediction, labeled data for validation, and code for
automatic evaluation of algorithm predictions using both established and novel
metrics. The data is based on real-world covariates, and the treatment
assignments and outcomes are based on simulations, which provides the basis for
validation. In this framework we address two questions: one of scaling, and the
other of data-censoring. The framework is available as open source code at
https://github.com/IBM-HRL-MLHLS/IBM-Causal-Inference-Benchmarking-Framework.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Shimoni_Y/0/1/0/all/0/1&quot;&gt;Yishai Shimoni&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yanover_C/0/1/0/all/0/1&quot;&gt;Chen Yanover&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Karavani_E/0/1/0/all/0/1&quot;&gt;Ehud Karavani&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Goldschmnidt_Y/0/1/0/all/0/1&quot;&gt;Yaara Goldschmnidt&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05074">
<title>L4: Practical loss-based stepsize adaptation for deep learning. (arXiv:1802.05074v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.05074</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a stepsize adaptation scheme for stochastic gradient descent. It
operates directly with the loss function and rescales the gradient in order to
make fixed predicted progress on the loss. We demonstrate its capabilities by
strongly improving the performance of Adam and Momentum optimizers. The
enhanced optimizers with default hyperparameters consistently outperform their
constant stepsize counterparts, even the best ones, without a measurable
increase in computational cost. The performance is validated on multiple
architectures including ResNets and the Differential Neural Computer. A
prototype implementation as a TensorFlow optimizer is released.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Michal_R/0/1/0/all/0/1&quot;&gt;Rolinek Michal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Georg_M/0/1/0/all/0/1&quot;&gt;Martius Georg&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05155">
<title>Toward Deeper Understanding of Nonconvex Stochastic Optimization with Momentum using Diffusion Approximations. (arXiv:1802.05155v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.05155</link>
<description rdf:parseType="Literal">&lt;p&gt;Momentum Stochastic Gradient Descent (MSGD) algorithm has been widely applied
to many nonconvex optimization problems in machine learning. Popular examples
include training deep neural networks, dimensionality reduction, and etc. Due
to the lack of convexity and the extra momentum term, the optimization theory
of MSGD is still largely unknown. In this paper, we study this fundamental
optimization algorithm based on the so-called &quot;strict saddle problem.&quot; By
diffusion approximation type analysis, our study shows that the momentum
\emph{helps escape from saddle points}, but \emph{hurts the convergence within
the neighborhood of optima} (if without the step size annealing). Our
theoretical discovery partially corroborates the empirical success of MSGD in
training deep neural networks. Moreover, our analysis applies the martingale
method and &quot;Fixed-State-Chain&quot; method from the stochastic approximation
literature, which are of independent interest.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1&quot;&gt;Tianyi Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Z/0/1/0/all/0/1&quot;&gt;Zhehui Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_E/0/1/0/all/0/1&quot;&gt;Enlu Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_T/0/1/0/all/0/1&quot;&gt;Tuo Zhao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05187">
<title>On the Blindspots of Convolutional Networks. (arXiv:1802.05187v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.05187</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep convolutional network has been the state-of-the-art approach for a wide
variety of tasks over the last few years. Its successes have, in many cases,
turned it into the default model in quite a few domains. In this work we will
demonstrate that convolutional networks have limitations that may, in some
cases, hinder it from learning properties of the data, which are easily
recognizable by traditional, less demanding, models.
&lt;/p&gt;
&lt;p&gt;To this end, we present a series of competitive analysis studies on image
recognition and text analysis tasks, for which convolutional networks are known
to provide state-of-the-art results. In our studies, we inject a truth-reveling
signal, indiscernible for the network, thus hitting time and again the
network&apos;s blind spots. The signal does not impair the network&apos;s existing
performances, but it does provide an opportunity for a significant performance
boost by models that can capture it.
&lt;/p&gt;
&lt;p&gt;The various forms of the carefully designed signals shed a light on the
strengths and weaknesses of convolutional network, which may provide insights
for both theoreticians that study the power of deep architectures, and for
practitioners that consider to apply convolutional networks to the task at
hand.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hoffer_E/0/1/0/all/0/1&quot;&gt;Elad Hoffer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Fine_S/0/1/0/all/0/1&quot;&gt;Shai Fine&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Soudry_D/0/1/0/all/0/1&quot;&gt;Daniel Soudry&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05193">
<title>Security Analysis and Enhancement of Model Compressed Deep Learning Systems under Adversarial Attacks. (arXiv:1802.05193v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.05193</link>
<description rdf:parseType="Literal">&lt;p&gt;DNN is presenting human-level performance for many complex intelligent tasks
in real-world applications. However, it also introduces ever-increasing
security concerns. For example, the emerging adversarial attacks indicate that
even very small and often imperceptible adversarial input perturbations can
easily mislead the cognitive function of deep learning systems (DLS). Existing
DNN adversarial studies are narrowly performed on the ideal software-level DNN
models with a focus on single uncertainty factor, i.e. input perturbations,
however, the impact of DNN model reshaping on adversarial attacks, which is
introduced by various hardware-favorable techniques such as hash-based weight
compression during modern DNN hardware implementation, has never been
discussed. In this work, we for the first time investigate the multi-factor
adversarial attack problem in practical model optimized deep learning systems
by jointly considering the DNN model-reshaping (e.g. HashNet based deep
compression) and the input perturbations. We first augment adversarial example
generating method dedicated to the compressed DNN models by incorporating the
software-based approaches and mathematical modeled DNN reshaping. We then
conduct a comprehensive robustness and vulnerability analysis of deep
compressed DNN models under derived adversarial attacks. A defense technique
named &quot;gradient inhibition&quot; is further developed to ease the generating of
adversarial examples thus to effectively mitigate adversarial attacks towards
both software and hardware-oriented DNNs. Simulation results show that
&quot;gradient inhibition&quot; can decrease the average success rate of adversarial
attacks from 87.99% to 4.77% (from 86.74% to 4.64%) on MNIST (CIFAR-10)
benchmark with marginal accuracy degradation across various DNNs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Q/0/1/0/all/0/1&quot;&gt;Qi Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_T/0/1/0/all/0/1&quot;&gt;Tao Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_Z/0/1/0/all/0/1&quot;&gt;Zihao Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yanzhi Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jin_Y/0/1/0/all/0/1&quot;&gt;Yier Jin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wen_W/0/1/0/all/0/1&quot;&gt;Wujie Wen&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05214">
<title>Learning Privacy Preserving Encodings through Adversarial Training. (arXiv:1802.05214v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.05214</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a framework to learn privacy-preserving encodings of images (or
other high-dimensional data) to inhibit inference of a chosen private
attribute. Rather than encoding a fixed dataset or inhibiting a fixed
estimator, we aim to to learn an encoding function such that even after this
function is fixed, an estimator with knowledge of the encoding is unable to
learn to accurately predict the private attribute, when generalizing beyond a
training set. We formulate this as adversarial optimization of an encoding
function against a classifier for the private attribute, with both modeled as
deep neural networks. We describe an optimization approach which successfully
yields an encoder that permanently limits inference of the private attribute,
while preserving either a generic notion of information, or the estimation of a
different, desired, attribute. We experimentally validate the efficacy of our
approach on private tasks of real-world complexity, by learning to prevent
detection of scene classes from the Places-365 dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pittaluga_F/0/1/0/all/0/1&quot;&gt;Francesco Pittaluga&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Koppal_S/0/1/0/all/0/1&quot;&gt;Sanjeev J. Koppal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chakrabarti_A/0/1/0/all/0/1&quot;&gt;Ayan Chakrabarti&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05234">
<title>Necessary and Sufficient Null Space Condition for Nuclear Norm Minimization in Low-Rank Matrix Recovery. (arXiv:1802.05234v1 [math.OC])</title>
<link>http://arxiv.org/abs/1802.05234</link>
<description rdf:parseType="Literal">&lt;p&gt;Low-rank matrix recovery has found many applications in science and
engineering such as machine learning, signal processing, collaborative
filtering, system identification, and Euclidean embedding. But the low-rank
matrix recovery problem is an NP hard problem and thus challenging. A commonly
used heuristic approach is the nuclear norm minimization. In [12,14,15], the
authors established the necessary and sufficient null space conditions for
nuclear norm minimization to recover every possible low-rank matrix with rank
at most r (the strong null space condition). In addition, in [12], Oymak et al.
established a null space condition for successful recovery of a given low-rank
matrix (the weak null space condition) using nuclear norm minimization, and
derived the phase transition for the nuclear norm minimization. In this paper,
we show that the weak null space condition in [12] is only a sufficient
condition for successful matrix recovery using nuclear norm minimization, and
is not a necessary condition as claimed in [12]. In this paper, we further give
a weak null space condition for low-rank matrix recovery, which is both
necessary and sufficient for the success of nuclear norm minimization. At the
core of our derivation are an inequality for characterizing the nuclear norms
of block matrices, and the conditions for equality to hold in that inequality.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Yi_J/0/1/0/all/0/1&quot;&gt;Jirong Yi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Xu_W/0/1/0/all/0/1&quot;&gt;Weiyu Xu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05249">
<title>Distributionally Robust Submodular Maximization. (arXiv:1802.05249v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.05249</link>
<description rdf:parseType="Literal">&lt;p&gt;Submodular functions have applications throughout machine learning, but in
many settings, we do not have direct access to the underlying function $f$. We
focus on stochastic functions that are given as an expectation of functions
over a distribution $P$. In practice, we often have only a limited set of
samples $f_i$ from $P$. The standard approach indirectly optimizes $f$ by
maximizing the sum of $f_i$. However, this ignores generalization to the true
(unknown) distribution. In this paper, we achieve better performance on the
actual underlying function $f$ by directly optimizing a combination of bias and
variance. Algorithmically, we accomplish this by showing how to carry out
distributionally robust optimization (DRO) for submodular functions, providing
efficient algorithms backed by theoretical guarantees which leverage several
novel contributions to the general theory of DRO. We also show compelling
empirical evidence that DRO improves generalization to the unknown stochastic
submodular function.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Staib_M/0/1/0/all/0/1&quot;&gt;Matthew Staib&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wilder_B/0/1/0/all/0/1&quot;&gt;Bryan Wilder&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jegelka_S/0/1/0/all/0/1&quot;&gt;Stefanie Jegelka&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.05251">
<title>Differentially Private Empirical Risk Minimization Revisited: Faster and More General. (arXiv:1802.05251v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.05251</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper we study the differentially private Empirical Risk Minimization
(ERM) problem in different settings. For smooth (strongly) convex loss function
with or without (non)-smooth regularization, we give algorithms that achieve
either optimal or near optimal utility bounds with less gradient complexity
compared with previous work. For ERM with smooth convex loss function in
high-dimensional ($p\gg n$) setting, we give an algorithm which achieves the
upper bound with less gradient complexity than previous ones. At last, we
generalize the expected excess empirical risk from convex loss functions to
non-convex ones satisfying the Polyak-Lojasiewicz condition and give a tighter
upper bound on the utility than the one in \cite{ijcai2017-548}.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_D/0/1/0/all/0/1&quot;&gt;Di Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ye_M/0/1/0/all/0/1&quot;&gt;Minwei Ye&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Xu_J/0/1/0/all/0/1&quot;&gt;Jinhui Xu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1605.07950">
<title>On Fast Convergence of Proximal Algorithms for SQRT-Lasso Optimization: Don&apos;t Worry About Its Nonsmooth Loss Function. (arXiv:1605.07950v5 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1605.07950</link>
<description rdf:parseType="Literal">&lt;p&gt;Many machine learning techniques sacrifice convenient computational
structures to gain estimation robustness and modeling flexibility. However, by
exploring the modeling structures, we find these &quot;sacrifices&quot; do not always
require more computational efforts. To shed light on such a &quot;free-lunch&quot;
phenomenon, we study the square-root-Lasso (SQRT-Lasso) type regression
problem. Specifically, we show that the nonsmooth loss functions of SQRT-Lasso
type regression ease tuning effort and gain adaptivity to inhomogeneous noise,
but is not necessarily more challenging than Lasso in computation. We can
directly apply proximal algorithms (e.g. proximal gradient descent, proximal
Newton, and proximal Quasi-Newton algorithms) without worrying the
nonsmoothness of the loss function. Theoretically, we prove that the proximal
algorithms combined with the pathwise optimization scheme enjoy fast
convergence guarantees with high probability. Numerical results are provided to
support our theory.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Li_X/0/1/0/all/0/1&quot;&gt;Xingguo Li&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jiang_H/0/1/0/all/0/1&quot;&gt;Haoming Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Haupt_J/0/1/0/all/0/1&quot;&gt;Jarvis Haupt&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Arora_R/0/1/0/all/0/1&quot;&gt;Raman Arora&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liu_H/0/1/0/all/0/1&quot;&gt;Han Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hong_M/0/1/0/all/0/1&quot;&gt;Mingyi Hong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhao_T/0/1/0/all/0/1&quot;&gt;Tuo Zhao&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1701.07761">
<title>Theoretical Foundations of Forward Feature Selection Methods based on Mutual Information. (arXiv:1701.07761v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1701.07761</link>
<description rdf:parseType="Literal">&lt;p&gt;Feature selection problems arise in a variety of applications, such as
microarray analysis, clinical prediction, text categorization, image
classification and face recognition, multi-label learning, and classification
of internet traffic. Among the various classes of methods, forward feature
selection methods based on mutual information have become very popular and are
widely used in practice. However, comparative evaluations of these methods have
been limited by being based on specific datasets and classifiers. In this
paper, we develop a theoretical framework that allows evaluating the methods
based on their theoretical properties. Our framework is grounded on the
properties of the target objective function that the methods try to
approximate, and on a novel categorization of features, according to their
contribution to the explanation of the class; we derive upper and lower bounds
for the target objective function and relate these bounds with the feature
types. Then, we characterize the types of approximations taken by the methods,
and analyze how these approximations cope with the good properties of the
target objective function. Additionally, we develop a distributional setting
designed to illustrate the various deficiencies of the methods, and provide
several examples of wrong feature selections. Based on our work, we identify
clearly the methods that should be avoided, and the methods that currently have
the best performance.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Macedo_F/0/1/0/all/0/1&quot;&gt;Francisco Macedo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Oliveira_M/0/1/0/all/0/1&quot;&gt;M. Ros&amp;#xe1;rio Oliveira&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pacheco_A/0/1/0/all/0/1&quot;&gt;Ant&amp;#xf3;nio Pacheco&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Valadas_R/0/1/0/all/0/1&quot;&gt;Rui Valadas&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1702.07339">
<title>A Converse to Banach&apos;s Fixed Point Theorem and its CLS Completeness. (arXiv:1702.07339v3 [cs.CC] UPDATED)</title>
<link>http://arxiv.org/abs/1702.07339</link>
<description rdf:parseType="Literal">&lt;p&gt;Banach&apos;s fixed point theorem for contraction maps has been widely used to
analyze the convergence of iterative methods in non-convex problems. It is a
common experience, however, that iterative maps fail to be globally contracting
under the natural metric in their domain, making the applicability of Banach&apos;s
theorem limited. We explore how generally we can apply Banach&apos;s fixed point
theorem to establish the convergence of iterative methods when pairing it with
carefully designed metrics.
&lt;/p&gt;
&lt;p&gt;Our first result is a strong converse of Banach&apos;s theorem, showing that it is
a universal analysis tool for establishing global convergence of iterative
methods to unique fixed points, and for bounding their convergence rate. In
other words, we show that, whenever an iterative map globally converges to a
unique fixed point, there exists a metric under which the iterative map is
contracting and which can be used to bound the number of iterations until
convergence. We illustrate our approach in the widely used power method,
providing a new way of bounding its convergence rate through contraction
arguments.
&lt;/p&gt;
&lt;p&gt;We next consider the computational complexity of Banach&apos;s fixed point
theorem. Making the proof of our converse theorem constructive, we show that
computing a fixed point whose existence is guaranteed by Banach&apos;s fixed point
theorem is CLS-complete. We thus provide the first natural complete problem for
the class CLS, which was defined in [Daskalakis, Papadimitriou 2011] to capture
the complexity of problems such as P-matrix LCP, computing KKT-points, and
finding mixed Nash equilibria in congestion and network coordination games.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Daskalakis_C/0/1/0/all/0/1&quot;&gt;Constantinos Daskalakis&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tzamos_C/0/1/0/all/0/1&quot;&gt;Christos Tzamos&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zampetakis_M/0/1/0/all/0/1&quot;&gt;Manolis Zampetakis&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1702.08420">
<title>Embarrassingly parallel inference for Gaussian processes. (arXiv:1702.08420v4 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1702.08420</link>
<description rdf:parseType="Literal">&lt;p&gt;Training Gaussian process-based models typically involves an $ O(N^3)$
computational bottleneck. Popular methods for overcoming this matrix inversion
problem cannot adequately model all types of latent functions, and are often
not parallelizable. We present an embarrassingly parallel method that takes
advantage of inverting block diagonal approximations, while maintaining much of
the expressivity of a full covariance matrix. By using importance sampling to
average over different realizations of low-rank GP approximations, we ensure
our algorithm is both asymptotically unbiased and embarrassingly parallel. We
show comparable or improved performance over competing methods, on a range of
synthetic and real datasets.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhang_M/0/1/0/all/0/1&quot;&gt;Michael Minyi Zhang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Williamson_S/0/1/0/all/0/1&quot;&gt;Sinead A. Williamson&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1702.08536">
<title>Fast Threshold Tests for Detecting Discrimination. (arXiv:1702.08536v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1702.08536</link>
<description rdf:parseType="Literal">&lt;p&gt;Threshold tests have recently been proposed as a useful method for detecting
bias in lending, hiring, and policing decisions. For example, in the case of
credit extensions, these tests aim to estimate the bar for granting loans to
white and minority applicants, with a higher inferred threshold for minorities
indicative of discrimination. This technique, however, requires fitting a
complex Bayesian latent variable model for which inference is often
computationally challenging. Here we develop a method for fitting threshold
tests that is two orders of magnitude faster than the existing approach,
reducing computation from hours to minutes. To achieve these performance gains,
we introduce and analyze a flexible family of probability distributions on the
interval [0, 1] -- which we call discriminant distributions -- that is
computationally efficient to work with. We demonstrate our technique by
analyzing 2.7 million police stops of pedestrians in New York City.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pierson_E/0/1/0/all/0/1&quot;&gt;Emma Pierson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Corbett_Davies_S/0/1/0/all/0/1&quot;&gt;Sam Corbett-Davies&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Goel_S/0/1/0/all/0/1&quot;&gt;Sharad Goel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1705.02047">
<title>Matrix Completion via Factorizing Polynomials. (arXiv:1705.02047v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1705.02047</link>
<description rdf:parseType="Literal">&lt;p&gt;Predicting unobserved entries of a partially observed matrix has found wide
applicability in several areas, such as recommender systems, computational
biology, and computer vision. Many scalable methods with rigorous theoretical
guarantees have been developed for algorithms where the matrix is factored into
low-rank components, and embeddings are learned for the row and column
entities. While there has been recent research on incorporating explicit side
information in the low-rank matrix factorization setting, often implicit
information can be gleaned from the data, via higher-order interactions among
entities. Such implicit information is especially useful in cases where the
data is very sparse, as is often the case in real-world datasets. In this
paper, we design a method to learn embeddings in the context of recommendation
systems, using the observation that higher powers of a graph transition
probability matrix encode the probability that a random walker will hit that
node in a given number of steps. We develop a coordinate descent algorithm to
solve the resulting optimization, that makes explicit computation of the higher
order powers of the matrix redundant, preserving sparsity and making
computations efficient. Experiments on several datasets show that our method,
that can use higher order information, outperforms methods that only use
explicitly available side information, those that use only second-order
implicit information and in some cases, methods based on deep neural networks
as well.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Shah_V/0/1/0/all/0/1&quot;&gt;Vatsal Shah&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rao_N/0/1/0/all/0/1&quot;&gt;Nikhil Rao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ding_W/0/1/0/all/0/1&quot;&gt;Weicong Ding&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1706.02524">
<title>Scaling up the Automatic Statistician: Scalable Structure Discovery using Gaussian Processes. (arXiv:1706.02524v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1706.02524</link>
<description rdf:parseType="Literal">&lt;p&gt;Automating statistical modelling is a challenging problem in artificial
intelligence. The Automatic Statistician takes a first step in this direction,
by employing a kernel search algorithm with Gaussian Processes (GP) to provide
interpretable statistical models for regression problems. However this does not
scale due to its $O(N^3)$ running time for the model selection. We propose
Scalable Kernel Composition (SKC), a scalable kernel search algorithm that
extends the Automatic Statistician to bigger data sets. In doing so, we derive
a cheap upper bound on the GP marginal likelihood that sandwiches the marginal
likelihood with the variational lower bound . We show that the upper bound is
significantly tighter than the lower bound and thus useful for model selection.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kim_H/0/1/0/all/0/1&quot;&gt;Hyunjik Kim&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Teh_Y/0/1/0/all/0/1&quot;&gt;Yee Whye Teh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1706.05446">
<title>Inferring Tweedie Compound Poisson Mixed Models with Adversarial Variational Bayes. (arXiv:1706.05446v4 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1706.05446</link>
<description rdf:parseType="Literal">&lt;p&gt;The Tweedie Compound Poisson-Gamma model is routinely used for modelling
non-negative continuous data with a discrete probability mass at zero. Mixed
models with random effects account for the covariance structure related to the
grouping hierarchy in the data. An important application of Tweedie mixed
models is estimating the aggregated loss for insurance policies. However, the
intractable likelihood function, the unknown variance function, and the
hierarchical structure of mixed effects have presented considerable challenges
for drawing inferences on Tweedie. In this study, we tackle the Bayesian
Tweedie mixed-effects models via variational approaches. In particular, we
empower the posterior approximation by implicit models trained in an
adversarial setting. To reduce the variance of gradients, we reparameterize
random effects, and integrate out one local latent variable of Tweedie. We also
employ a flexible hyper prior to ensure the richness of the approximation. Our
method is evaluated on both simulated and real-world data. Results show that
the proposed method has smaller estimation bias on the random effects compared
to traditional inference methods including MCMC; it also achieves a
state-of-the-art predictive performance, meanwhile offering a richer estimation
of the variance function.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Yang_Y/0/1/0/all/0/1&quot;&gt;Yaodong Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Demyanov_S/0/1/0/all/0/1&quot;&gt;Sergey Demyanov&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Liu_Y/0/1/0/all/0/1&quot;&gt;Yunayuan Liu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wang_J/0/1/0/all/0/1&quot;&gt;Jun Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.05115">
<title>Benefits from Superposed Hawkes Processes. (arXiv:1710.05115v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1710.05115</link>
<description rdf:parseType="Literal">&lt;p&gt;The superposition of temporal point processes has been studied for many
years, although the usefulness of such models for practical applications has
not be fully developed. We investigate superposed Hawkes process as an
important class of such models, with properties studied in the framework of
least squares estimation. The superposition of Hawkes processes is demonstrated
to be beneficial for tightening the upper bound of excess risk under certain
conditions, and we show the feasibility of the benefit in typical situations.
The usefulness of superposed Hawkes processes is verified on synthetic data,
and its potential to solve the cold-start problem of recommendation systems is
demonstrated on real-world data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Xu_H/0/1/0/all/0/1&quot;&gt;Hongteng Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Luo_D/0/1/0/all/0/1&quot;&gt;Dixin Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chen_X/0/1/0/all/0/1&quot;&gt;Xu Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Carin_L/0/1/0/all/0/1&quot;&gt;Lawrence Carin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.10513">
<title>Crime incidents embedding using restricted Boltzmann machines. (arXiv:1710.10513v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1710.10513</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a new approach for detecting related crime series, by unsupervised
learning of the latent feature embeddings from narratives of crime record via
the Gaussian-Bernoulli Restricted Boltzmann Machines (RBM). This is a
drastically different approach from prior work on crime analysis, which
typically considers only time and location and at most category information.
After the embedding, related cases are closer to each other in the Euclidean
feature space, and the unrelated cases are far apart, which is a good property
can enable subsequent analysis such as detection and clustering of related
cases. Experiments over several series of related crime incidents hand labeled
by the Atlanta Police Department reveal the promise of our embedding methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zhu_S/0/1/0/all/0/1&quot;&gt;Shixiang Zhu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Xie_Y/0/1/0/all/0/1&quot;&gt;Yao Xie&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.00464">
<title>Fixing a Broken ELBO. (arXiv:1711.00464v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1711.00464</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent work in unsupervised representation learning has focused on learning
deep directed latent-variable models. Fitting these models by maximizing the
marginal likelihood or evidence is typically intractable, thus a common
approximation is to maximize the evidence lower bound (ELBO) instead. However,
maximum likelihood training (whether exact or approximate) does not necessarily
result in a good latent representation, as we demonstrate both theoretically
and empirically. In particular, we derive variational lower and upper bounds on
the mutual information between the input and the latent variable, and use these
bounds to derive a rate-distortion curve that characterizes the tradeoff
between compression and reconstruction accuracy. Using this framework, we
demonstrate that there is a family of models with identical ELBO, but different
quantitative and qualitative characteristics. Our framework also suggests a
simple new method to ensure that latent variable models with powerful
stochastic decoders do not ignore their latent code.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Alemi_A/0/1/0/all/0/1&quot;&gt;Alexander A. Alemi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Poole_B/0/1/0/all/0/1&quot;&gt;Ben Poole&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fischer_I/0/1/0/all/0/1&quot;&gt;Ian Fischer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dillon_J/0/1/0/all/0/1&quot;&gt;Joshua V. Dillon&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Saurous_R/0/1/0/all/0/1&quot;&gt;Rif A. Saurous&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Murphy_K/0/1/0/all/0/1&quot;&gt;Kevin Murphy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1711.05355">
<title>Automatic Conflict Detection in Police Body-Worn Audio. (arXiv:1711.05355v2 [eess.AS] UPDATED)</title>
<link>http://arxiv.org/abs/1711.05355</link>
<description rdf:parseType="Literal">&lt;p&gt;Automatic conflict detection has grown in relevance with the advent of
body-worn technology, but existing metrics such as turn-taking and overlap are
poor indicators of conflict in police-public interactions. Moreover, standard
techniques to compute them fall short when applied to such diversified and
noisy contexts. We develop a pipeline catered to this task combining adaptive
noise removal, non-speech filtering and new measures of conflict based on the
repetition and intensity of phrases in speech. We demonstrate the effectiveness
of our approach on body-worn audio data collected by the Los Angeles Police
Department.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Letcher_A/0/1/0/all/0/1&quot;&gt;Alistair Letcher&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Trisovic_J/0/1/0/all/0/1&quot;&gt;Jelena Tri&amp;#x161;ovi&amp;#x107;&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Cademartori_C/0/1/0/all/0/1&quot;&gt;Collin Cademartori&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Chen_X/0/1/0/all/0/1&quot;&gt;Xi Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Xu_J/0/1/0/all/0/1&quot;&gt;Jason Xu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04725">
<title>Superposition-Assisted Stochastic Optimization for Hawkes Processes. (arXiv:1802.04725v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1802.04725</link>
<description rdf:parseType="Literal">&lt;p&gt;We consider the learning of multi-agent Hawkes processes, a model containing
multiple Hawkes processes with shared endogenous impact functions and different
exogenous intensities. In the framework of stochastic maximum likelihood
estimation, we explore the associated risk bound. Further, we consider the
superposition of Hawkes processes within the model, and demonstrate that under
certain conditions such an operation is beneficial for tightening the risk
bound. Accordingly, we propose a stochastic optimization algorithm assisted
with a diversity-driven superposition strategy, achieving better learning
results with improved convergence properties. The effectiveness of the proposed
method is verified on synthetic data, and its potential to solve the cold-start
problem of sequential recommendation systems is demonstrated on real-world
data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Xu_H/0/1/0/all/0/1&quot;&gt;Hongteng Xu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Chen_X/0/1/0/all/0/1&quot;&gt;Xu Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Carin_L/0/1/0/all/0/1&quot;&gt;Lawrence Carin&lt;/a&gt;</dc:creator>
</item></rdf:RDF>