<?xml version="1.0" encoding="UTF-8"?>

<rdf:RDF
 xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
 xmlns="http://purl.org/rss/1.0/"
 xmlns:content="http://purl.org/rss/1.0/modules/content/"
 xmlns:taxo="http://purl.org/rss/1.0/modules/taxonomy/"
 xmlns:dc="http://purl.org/dc/elements/1.1/"
 xmlns:syn="http://purl.org/rss/1.0/modules/syndication/"
 xmlns:admin="http://webns.net/mvcb/"
>

<channel rdf:about="http://arxiv.org/">
<title>Boring papers from arXiv</title>
<link>http://arxiv.org/</link>
<description rdf:parseType="Literal">The Bad Papers on ML, AI and Statistics</description>
<dc:language>en-us</dc:language>
<dc:date>2018-02-28T20:30:00-05:00</dc:date>
<dc:publisher>help@arxiv.org</dc:publisher>
<dc:subject>Statistics -- Machine Learning</dc:subject>
<syn:updateBase>1901-01-01T00:00+00:00</syn:updateBase>
<syn:updateFrequency>1</syn:updateFrequency>
<syn:updatePeriod>daily</syn:updatePeriod>
<items>
 <rdf:Seq>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.10206"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.10301"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.10328"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.10353"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.10393"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.10304"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.03916"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.10217"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.10269"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.10446"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.10495"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.10546"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.10548"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1611.10215"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1703.05376"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.06129"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1709.08034"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.05233"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1801.04134"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.02172"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.04127"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06382"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.06604"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.09129"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.10168"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.10238"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.10254"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.10264"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.10275"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.10311"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.10418"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.10489"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.10497"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.10501"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.10510"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.10515"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.10526"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.10529"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.10549"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.10551"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.10558"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.10576"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.10582"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1603.05729"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1705.10934"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.00210"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.06595"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.07462"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1710.10345"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1712.03607"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.03133"/>
<rdf:li rdf:resource="http://arxiv.org/abs/1802.03151"/></rdf:Seq>
</items>
<image rdf:resource="http://arxiv.org/icons/sfx.gif" />
</channel>
<image rdf:about="http://arxiv.org/icons/sfx.gif">
<title>arXiv.org</title>
<url>http://arxiv.org/icons/sfx.gif</url>
<link>http://arxiv.org/</link>
</image><item rdf:about="http://arxiv.org/abs/1802.10206">
<title>Networking the Boids is More Robust Against Adversarial Learning. (arXiv:1802.10206v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1802.10206</link>
<description rdf:parseType="Literal">&lt;p&gt;Swarm behavior using Boids-like models has been studied primarily using
close-proximity spatial sensory information (e.g. vision range). In this study,
we propose a novel approach in which the classic definition of
boids\textquoteright \ neighborhood that relies on sensory perception and
Euclidian space locality is replaced with graph-theoretic network-based
proximity mimicking communication and social networks. We demonstrate that
networking the boids leads to faster swarming and higher quality of the
formation. We further investigate the effect of adversarial learning, whereby
an observer attempts to reverse engineer the dynamics of the swarm through
observing its behavior. The results show that networking the swarm demonstrated
a more robust approach against adversarial learning than a local-proximity
neighborhood structure.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tang_J/0/1/0/all/0/1&quot;&gt;Jiangjun Tang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Leu_G/0/1/0/all/0/1&quot;&gt;George Leu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Abbass_H/0/1/0/all/0/1&quot;&gt;Hussein Abbass&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.10301">
<title>Avoiding overfitting of multilayer perceptrons by training derivatives. (arXiv:1802.10301v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1802.10301</link>
<description rdf:parseType="Literal">&lt;p&gt;Resistance to overfitting is observed for neural networks trained with
extended backpropagation algorithm. In addition to target values, its cost
function uses derivatives of those up to the $4^{\mathrm{th}}$ order. For
common applications of neural networks, high order derivatives are not readily
available, so simpler cases are considered: training network to approximate
analytical function inside 2D and 5D domains and solving Poisson equation
inside a 2D circle. For function approximation, the cost is a sum of squared
differences between output and target as well as their derivatives with respect
to the input. Differential equations are usually solved by putting a multilayer
perceptron in place of unknown function and training its weights, so that
equation holds within some margin of error. Commonly used cost is the
equation&apos;s residual squared. Added terms are squared derivatives of said
residual with respect to the independent variables. To investigate overfitting,
the cost is minimized for points of regular grids with various spacing, and its
root mean is compared with its value on much denser test set. Fully connected
perceptrons with six hidden layers and $2\cdot10^{4}$, $1\cdot10^{6}$ and
$5\cdot10^{6}$ weights in total are trained with Rprop until cost changes by
less than 10% for last 1000 epochs, or when the $10000^{\mathrm{th}}$ epoch is
reached. Training the network with $5\cdot10^{6}$ weights to represent simple
2D function using 10 points with 8 extra derivatives in each produces cost test
to train ratio of $1.5$, whereas for classical backpropagation in comparable
conditions this ratio is $2\cdot10^{4}$.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Avrutskiy_V/0/1/0/all/0/1&quot;&gt;V.I. Avrutskiy&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.10328">
<title>Neural Photometric Stereo Reconstruction for General Reflectance Surfaces. (arXiv:1802.10328v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1802.10328</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a novel convolutional neural network architecture for photometric
stereo (Woodham, 1980), a problem of recovering 3D object surface normals from
multiple images observed under varying illuminations. Despite its long history
in computer vision, the problem still shows fundamental challenges for surfaces
with unknown general reflectance properties (BRDFs). Leveraging deep neural
networks to learn complicated reflectance models is promising, but studies in
this direction are very limited due to difficulties in acquiring accurate
ground truth for training and also in designing networks invariant to
permutation of input images. In order to address these challenges, we propose a
reconstruction based unsupervised learning framework where surface normals and
BRDFs are predicted by the network and fed into the rendering equation to
synthesize observed images. The network is trained during testing by minimizing
reconstruction loss between observed and synthesized images. Thus, our learning
process does not require ground truth normals or even pre-training on external
images. Our method is shown to achieve the state-of-the-art performance on a
challenging real-world scene benchmark.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Taniai_T/0/1/0/all/0/1&quot;&gt;Tatsunori Taniai&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Maehara_T/0/1/0/all/0/1&quot;&gt;Takanori Maehara&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.10353">
<title>Relational Neural Expectation Maximization: Unsupervised Discovery of Objects and their Interactions. (arXiv:1802.10353v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.10353</link>
<description rdf:parseType="Literal">&lt;p&gt;Common-sense physical reasoning is an essential ingredient for any
intelligent agent operating in the real-world. For example, it can be used to
simulate the environment, or to infer the state of parts of the world that are
currently unobserved. In order to match real-world conditions this causal
knowledge must be learned without access to supervised data. To address this
problem we present a novel method that learns to discover objects and model
their physical interactions from raw visual images in a purely
\emph{unsupervised} fashion. It incorporates prior knowledge about the
compositional nature of human perception to factor interactions between
object-pairs and learn efficiently. On videos of bouncing balls we show the
superior modelling capabilities of our method compared to other unsupervised
neural approaches that do not incorporate such prior knowledge. We demonstrate
its ability to handle occlusion and show that it can extrapolate learned
knowledge to scenes with different numbers of objects.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Steenkiste_S/0/1/0/all/0/1&quot;&gt;Sjoerd van Steenkiste&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chang_M/0/1/0/all/0/1&quot;&gt;Michael Chang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Greff_K/0/1/0/all/0/1&quot;&gt;Klaus Greff&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Schmidhuber_J/0/1/0/all/0/1&quot;&gt;J&amp;#xfc;rgen Schmidhuber&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.10393">
<title>A Bayesian Model for Activities Recommendation and Event Structure Optimization Using Visitors Tracking. (arXiv:1802.10393v1 [cs.NE])</title>
<link>http://arxiv.org/abs/1802.10393</link>
<description rdf:parseType="Literal">&lt;p&gt;In events that are composed by many activities, there is a problem that
involves retrieve and management the information of visitors that are visiting
the activities. This management is crucial to find some activities that are
drawing attention of visitors; identify an ideal positioning for activities;
which path is more frequented by visitors. In this work, these features are
studied using Complex Network theory. For the beginning, an artificial database
was generated to study the mentioned features. Secondly, this work shows a
method to optimize the event structure that is better than a random method and
a recommendation system that achieves ~95% of accuracy.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Goulart_H/0/1/0/all/0/1&quot;&gt;Henrique X. Goulart&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wachs_Lopes_G/0/1/0/all/0/1&quot;&gt;Guilherme A. Wachs-Lopes&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.10304">
<title>Few-shot Autoregressive Density Estimation: Towards Learning to Learn Distributions. (arXiv:1710.10304v4 [cs.NE] UPDATED)</title>
<link>http://arxiv.org/abs/1710.10304</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep autoregressive models have shown state-of-the-art performance in density
estimation for natural images on large-scale datasets such as ImageNet.
However, such models require many thousands of gradient-based weight updates
and unique image examples for training. Ideally, the models would rapidly learn
visual concepts from only a handful of examples, similar to the manner in which
humans learns across many vision tasks. In this paper, we show how 1) neural
attention and 2) meta learning techniques can be used in combination with
autoregressive models to enable effective few-shot density estimation. Our
proposed modifications to PixelCNN result in state-of-the art few-shot density
estimation on the Omniglot dataset. Furthermore, we visualize the learned
attention policy and find that it learns intuitive algorithms for simple tasks
such as image mirroring on ImageNet and handwriting on Omniglot without
supervision. Finally, we extend the model to natural images and demonstrate
few-shot image generation on the Stanford Online Products dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Reed_S/0/1/0/all/0/1&quot;&gt;Scott Reed&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chen_Y/0/1/0/all/0/1&quot;&gt;Yutian Chen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Paine_T/0/1/0/all/0/1&quot;&gt;Thomas Paine&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oord_A/0/1/0/all/0/1&quot;&gt;A&amp;#xe4;ron van den Oord&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Eslami_S/0/1/0/all/0/1&quot;&gt;S. M. Ali Eslami&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rezende_D/0/1/0/all/0/1&quot;&gt;Danilo Rezende&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vinyals_O/0/1/0/all/0/1&quot;&gt;Oriol Vinyals&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Freitas_N/0/1/0/all/0/1&quot;&gt;Nando de Freitas&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.03916">
<title>Detecting and Correcting for Label Shift with Black Box Predictors. (arXiv:1802.03916v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1802.03916</link>
<description rdf:parseType="Literal">&lt;p&gt;Faced with distribution shift between training and test set, we wish to
detect and quantify the shift, and to correct our classifiers without test set
labels. Motivated by medical diagnosis, where diseases (targets), cause
symptoms (observations), we focus on label shift, where the label marginal
$p(y)$ changes but the conditional $p(x|y)$ does not. We propose Black Box
Shift Estimation (BBSE) to estimate the test distribution $p(y)$. BBSE exploits
arbitrary black box predictors to reduce dimensionality prior to shift
correction. While better predictors give tighter estimates, BBSE works even
when predictors are biased, inaccurate, or uncalibrated, so long as their
confusion matrices are invertible. We prove BBSE&apos;s consistency, bound its
error, and introduce a statistical test that uses BBSE to detect shift. We also
leverage BBSE to correct classifiers. Experiments demonstrate accurate
estimates and improved prediction, even on high-dimensional datasets of natural
images.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lipton_Z/0/1/0/all/0/1&quot;&gt;Zachary C. Lipton&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_Y/0/1/0/all/0/1&quot;&gt;Yu-Xiang Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Smola_A/0/1/0/all/0/1&quot;&gt;Alex Smola&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.10217">
<title>Investigating Human Priors for Playing Video Games. (arXiv:1802.10217v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.10217</link>
<description rdf:parseType="Literal">&lt;p&gt;What makes humans so good at solving seemingly complex video games? Unlike
computers, humans bring in a great deal of prior knowledge about the world,
enabling efficient decision making. This paper investigates the role of human
priors for solving video games. Given a sample game, we conduct a series of
ablation studies to quantify the importance of various priors on human
performance. We do this by modifying the video game environment to
systematically mask different types of visual information that could be used by
humans as priors. We find that removal of some prior knowledge causes a drastic
degradation in the speed with which human players solve the game, e.g. from 2
minutes to over 20 minutes. Furthermore, our results indicate that general
priors, such as the importance of objects and visual consistency, are critical
for efficient game-play. Videos and the game manipulations are available at
https://rach0012.github.io/humanRL_website/
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dubey_R/0/1/0/all/0/1&quot;&gt;Rachit Dubey&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Agrawal_P/0/1/0/all/0/1&quot;&gt;Pulkit Agrawal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pathak_D/0/1/0/all/0/1&quot;&gt;Deepak Pathak&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Griffiths_T/0/1/0/all/0/1&quot;&gt;Thomas L. Griffiths&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Efros_A/0/1/0/all/0/1&quot;&gt;Alexei A. Efros&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.10269">
<title>Selective Experience Replay for Lifelong Learning. (arXiv:1802.10269v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.10269</link>
<description rdf:parseType="Literal">&lt;p&gt;Deep reinforcement learning has emerged as a powerful tool for a variety of
learning tasks, however deep nets typically exhibit forgetting when learning
multiple tasks in sequence. To mitigate forgetting, we propose an experience
replay process that augments the standard FIFO buffer and selectively stores
experiences in a long-term memory. We explore four strategies for selecting
which experiences will be stored: favoring surprise, favoring reward, matching
the global training distribution, and maximizing coverage of the state space.
We show that distribution matching successfully prevents catastrophic
forgetting, and is consistently the best approach on all domains tested. While
distribution matching has better and more consistent performance, we identify
one case in which coverage maximization is beneficial - when tasks that receive
less trained are more important. Overall, our results show that selective
experience replay, when suitable selection algorithms are employed, can prevent
catastrophic forgetting.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Isele_D/0/1/0/all/0/1&quot;&gt;David Isele&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cosgun_A/0/1/0/all/0/1&quot;&gt;Akansel Cosgun&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.10446">
<title>Identifying Sources and Sinks in the Presence of Multiple Agents with Gaussian Process Vector Calculus. (arXiv:1802.10446v1 [cs.MA])</title>
<link>http://arxiv.org/abs/1802.10446</link>
<description rdf:parseType="Literal">&lt;p&gt;In systems of multiple agents, identifying the cause of observed agent
dynamics is challenging. Often, these agents operate in diverse, non-stationary
environments, where models rely on hand-crafted environment-specific features
to infer influential regions in the system&apos;s surroundings. To overcome the
limitations of these inflexible models, we present GP-LAPLACE, a technique for
locating sources and sinks from trajectories in time-varying fields. Using
Gaussian processes, we jointly infer a spatio-temporal vector field, as well as
canonical vector calculus operations on that field. Notably, we do this from
only agent trajectories without requiring knowledge of the environment, and
also obtain a metric for denoting the significance of inferred causal features
in the environment by exploiting our probabilistic method. To evaluate our
approach, we apply it to both synthetic and real-world GPS data, demonstrating
the applicability of our technique in the presence of multiple agents, as well
as its superiority over existing methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Cobb_A/0/1/0/all/0/1&quot;&gt;Adam D. Cobb&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Everett_R/0/1/0/all/0/1&quot;&gt;Richard Everett&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Markham_A/0/1/0/all/0/1&quot;&gt;Andrew Markham&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Roberts_S/0/1/0/all/0/1&quot;&gt;Stephen J. Roberts&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.10495">
<title>Pop Music Highlighter: Marking the Emotion Keypoints. (arXiv:1802.10495v1 [eess.AS])</title>
<link>http://arxiv.org/abs/1802.10495</link>
<description rdf:parseType="Literal">&lt;p&gt;The goal of music highlight extraction is to get a short consecutive segment
of a piece of music that provides an effective representation of the whole
piece. In a previous work, we introduced an attention-based convolutional
recurrent neural network that uses music emotion classification as a surrogate
task for music highlight extraction, for Pop songs. The rationale behind that
approach is that the highlight of a song is usually the most emotional part.
This paper extends our previous work in the following two aspects. First,
methodology-wise we experiment with a new architecture that does not need any
recurrent layers, making the training process faster. Moreover, we compare a
late-fusion variant and an early-fusion variant to study which one better
exploits the attention mechanism. Second, we conduct and report an extensive
set of experiments comparing the proposed attention-based methods against a
heuristic energy-based method, a structural repetition-based method, and a few
other simple feature-based methods for this task. Due to the lack of
public-domain labeled data for highlight extraction, following our previous
work we use the RWC POP 100-song data set to evaluate how the detected
highlights overlap with any chorus sections of the songs. The experiments
demonstrate the effectiveness of our methods over competing methods. For
reproducibility, we open source the code and pre-trained model at
https://github.com/remyhuang/pop-music-highlighter/.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Huang_Y/0/1/0/all/0/1&quot;&gt;Yu-Siang Huang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Chou_S/0/1/0/all/0/1&quot;&gt;Szu-Yu Chou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/eess/1/au:+Yang_Y/0/1/0/all/0/1&quot;&gt;Yi-Hsuan Yang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.10546">
<title>Computational Theories of Curiosity-Driven Learning. (arXiv:1802.10546v1 [cs.AI])</title>
<link>http://arxiv.org/abs/1802.10546</link>
<description rdf:parseType="Literal">&lt;p&gt;What are the functions of curiosity? What are the mechanisms of
curiosity-driven learning? We approach these questions using concepts and tools
from machine learning and developmental robotics. We argue that
curiosity-driven learning enables organisms to make discoveries to solve
complex problems with rare or deceptive rewards. By fostering exploration and
discovery of a diversity of behavioural skills, and ignoring these rewards,
curiosity can be efficient to bootstrap learning when there is no information,
or deceptive information, about local improvement towards these problems. We
review both normative and heuristic computational frameworks used to understand
the mechanisms of curiosity in humans, conceptualizing the child as a
sense-making organism. These frameworks enable us to discuss the bi-directional
causal links between curiosity and learning, and to provide new hypotheses
about the fundamental role of curiosity in self-organizing developmental
structures through curriculum learning. We present various developmental
robotics experiments that study these mechanisms in action, both supporting
these hypotheses and opening new research avenues in machine learning and
artificial intelligence. Finally, we discuss challenges for the design of
experimental paradigms for studying curiosity in psychology and cognitive
neuroscience. Keywords: Curiosity, intrinsic motivation, lifelong learning,
predictions, world model, rewards, free-energy principle, learning progress,
machine learning, AI, developmental robotics, development, curriculum learning,
self-organization.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oudeyer_P/0/1/0/all/0/1&quot;&gt;Pierre-Yves Oudeyer&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.10548">
<title>Using Deep Learning for Segmentation and Counting within Microscopy Data. (arXiv:1802.10548v1 [cs.CV])</title>
<link>http://arxiv.org/abs/1802.10548</link>
<description rdf:parseType="Literal">&lt;p&gt;Cell counting is a ubiquitous, yet tedious task that would greatly benefit
from automation. From basic biological questions to clinical trials, cell
counts provide key quantitative feedback that drive research. Unfortunately,
cell counting is most commonly a manual task and can be time-intensive. The
task is made even more difficult due to overlapping cells, existence of
multiple focal planes, and poor imaging quality, among other factors. Here, we
describe a convolutional neural network approach, using a recently described
feature pyramid network combined with a VGG-style neural network, for
segmenting and subsequent counting of cells in a given microscopy image.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Hernandez_C/0/1/0/all/0/1&quot;&gt;Carlos X. Hern&amp;#xe1;ndez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Sultan_M/0/1/0/all/0/1&quot;&gt;Mohammad M. Sultan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pande_V/0/1/0/all/0/1&quot;&gt;Vijay S. Pande&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1611.10215">
<title>Unit Commitment using Nearest Neighbor as a Short-Term Proxy. (arXiv:1611.10215v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1611.10215</link>
<description rdf:parseType="Literal">&lt;p&gt;We devise the Unit Commitment Nearest Neighbor (UCNN) algorithm to be used as
a proxy for quickly approximating outcomes of short-term decisions, to make
tractable hierarchical long-term assessment and planning for large power
systems. Experimental results on updated versions of IEEE-RTS79 and IEEE-RTS96
show high accuracy measured on operational cost, achieved in runtimes that are
lower in several orders of magnitude than the traditional approach.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dalal_G/0/1/0/all/0/1&quot;&gt;Gal Dalal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gilboa_E/0/1/0/all/0/1&quot;&gt;Elad Gilboa&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mannor_S/0/1/0/all/0/1&quot;&gt;Shie Mannor&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wehenkel_L/0/1/0/all/0/1&quot;&gt;Louis Wehenkel&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1703.05376">
<title>Finite Sample Analysis of Two-Timescale Stochastic Approximation with Applications to Reinforcement Learning. (arXiv:1703.05376v4 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1703.05376</link>
<description rdf:parseType="Literal">&lt;p&gt;Two-timescale Stochastic Approximation (SA) algorithms are widely used in
Reinforcement Learning (RL). Their iterates have two parts that are updated
using distinct stepsizes. In this work, we develop a novel recipe for their
finite sample analysis. Using this, we provide a concentration bound, which is
the first such result for a two-timescale SA. The type of bound we obtain is
known as &quot;lock-in probability&quot;. We also introduce a new projection scheme, in
which the time between successive projections increases exponentially. This
scheme allows one to elegantly transform a lock-in probability into a
convergence rate result for projected two-timescale SA. From this latter
result, we then extract key insights on stepsize selection. As an application,
we finally obtain convergence rates for the projected two-timescale RL
algorithms GTD(0), GTD2, and TDC.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Dalal_G/0/1/0/all/0/1&quot;&gt;Gal Dalal&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Szorenyi_B/0/1/0/all/0/1&quot;&gt;Balazs Szorenyi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Thoppe_G/0/1/0/all/0/1&quot;&gt;Gugan Thoppe&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Mannor_S/0/1/0/all/0/1&quot;&gt;Shie Mannor&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.06129">
<title>When is a Convolutional Filter Easy To Learn?. (arXiv:1709.06129v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1709.06129</link>
<description rdf:parseType="Literal">&lt;p&gt;We analyze the convergence of (stochastic) gradient descent algorithm for
learning a convolutional filter with Rectified Linear Unit (ReLU) activation
function. Our analysis does not rely on any specific form of the input
distribution and our proofs only use the definition of ReLU, in contrast with
previous works that are restricted to standard Gaussian input. We show that
(stochastic) gradient descent with random initialization can learn the
convolutional filter in polynomial time and the convergence rate depends on the
smoothness of the input distribution and the closeness of patches. To the best
of our knowledge, this is the first recovery guarantee of gradient-based
algorithms for convolutional filter on non-Gaussian input distributions. Our
theory also justifies the two-stage learning rate strategy in deep neural
networks. While our focus is theoretical, we also present experiments that
illustrate our theoretical findings.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Du_S/0/1/0/all/0/1&quot;&gt;Simon S. Du&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lee_J/0/1/0/all/0/1&quot;&gt;Jason D. Lee&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tian_Y/0/1/0/all/0/1&quot;&gt;Yuandong Tian&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1709.08034">
<title>Prioritized Norms in Formal Argumentation. (arXiv:1709.08034v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1709.08034</link>
<description rdf:parseType="Literal">&lt;p&gt;To resolve conflicts among norms, various nonmonotonic formalisms can be used
to perform prioritized normative reasoning. Meanwhile, formal argumentation
provides a way to represent nonmonotonic logics. In this paper, we propose a
representation of prioritized normative reasoning by argumentation. Using
hierarchical abstract normative systems, we define three kinds of prioritized
normative reasoning approaches, called Greedy, Reduction, and Optimization.
Then, after formulating an argumentation theory for a hierarchical abstract
normative system, we show that for a totally ordered hierarchical abstract
normative system, Greedy and Reduction can be represented in argumentation by
applying the weakest link and the last link principles respectively, and
Optimization can be represented by introducing additional defeats capturing the
idea that for each argument that contains a norm not belonging to the maximal
obeyable set then this argument should be rejected.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Liao_B/0/1/0/all/0/1&quot;&gt;Beishui Liao&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oren_N/0/1/0/all/0/1&quot;&gt;Nir Oren&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Torre_L/0/1/0/all/0/1&quot;&gt;Leendert van der Torre&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Villata_S/0/1/0/all/0/1&quot;&gt;Serena Villata&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.05233">
<title>Learners that Use Little Information. (arXiv:1710.05233v3 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1710.05233</link>
<description rdf:parseType="Literal">&lt;p&gt;We study learning algorithms that are restricted to using a small amount of
information from their input sample. We introduce a category of learning
algorithms we term $d$-bit information learners, which are algorithms whose
output conveys at most $d$ bits of information of their input. A central theme
in this work is that such algorithms generalize.
&lt;/p&gt;
&lt;p&gt;We focus on the learning capacity of these algorithms, and prove sample
complexity bounds with tight dependencies on the confidence and error
parameters. We also observe connections with well studied notions such as
sample compression schemes, Occam&apos;s razor, PAC-Bayes and differential privacy.
&lt;/p&gt;
&lt;p&gt;We discuss an approach that allows us to prove upper bounds on the amount of
information that algorithms reveal about their inputs, and also provide a lower
bound by showing a simple concept class for which every (possibly randomized)
empirical risk minimizer must reveal a lot of information. On the other hand,
we show that in the distribution-dependent setting every VC class has empirical
risk minimizers that do not reveal a lot of information.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bassily_R/0/1/0/all/0/1&quot;&gt;Raef Bassily&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Moran_S/0/1/0/all/0/1&quot;&gt;Shay Moran&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nachum_I/0/1/0/all/0/1&quot;&gt;Ido Nachum&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shafer_J/0/1/0/all/0/1&quot;&gt;Jonathan Shafer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yehudayoff_A/0/1/0/all/0/1&quot;&gt;Amir Yehudayoff&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1801.04134">
<title>Deep Episodic Memory: Encoding, Recalling, and Predicting Episodic Experiences for Robot Action Execution. (arXiv:1801.04134v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1801.04134</link>
<description rdf:parseType="Literal">&lt;p&gt;We present a novel deep neural network architecture for representing robot
experiences in an episodic-like memory which facilitates encoding, recalling,
and predicting action experiences. Our proposed unsupervised deep episodic
memory model 1) encodes observed actions in a latent vector space and, based on
this latent encoding, 2) infers most similar episodes previously experienced,
3) reconstructs original episodes, and 4) predicts future frames in an
end-to-end fashion. Results show that conceptually similar actions are mapped
into the same region of the latent vector space. Based on these results, we
introduce an action matching and retrieval mechanism, benchmark its performance
on two large-scale action datasets, 20BN-something-something and ActivityNet
and evaluate its generalization capability in a real-world scenario on a
humanoid robot.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rothfuss_J/0/1/0/all/0/1&quot;&gt;Jonas Rothfuss&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ferreira_F/0/1/0/all/0/1&quot;&gt;Fabio Ferreira&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Aksoy_E/0/1/0/all/0/1&quot;&gt;Eren Erdal Aksoy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhou_Y/0/1/0/all/0/1&quot;&gt;You Zhou&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Asfour_T/0/1/0/all/0/1&quot;&gt;Tamim Asfour&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.02172">
<title>Augmented Artificial Intelligence: a Conceptual Framework. (arXiv:1802.02172v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1802.02172</link>
<description rdf:parseType="Literal">&lt;p&gt;All artificial Intelligence (AI) systems make errors. These errors are
unexpected, and differ often from the typical human mistakes (&quot;non-human&quot;
errors). The AI errors should be corrected without damage of existing skills
and, hopefully, avoiding direct human expertise. This paper presents an initial
summary report of project taking new and systematic approach to improving the
intellectual effectiveness of the individual AI by communities of AIs. We
combine some ideas of learning in heterogeneous multiagent systems with new and
original mathematical approaches for non-iterative corrections of errors of
legacy AI systems. New stochastic separation theorems demonstrate that the
corrector technology can be used to handle errors in data flows with very
general probability distributions and far away from the classical i.i.d.
hypothesis.In particular, in the analysis of mathematical foundations of AI
non-destructive correction, we answer one general problem published by Donoho
and Tanner in 2009.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gorban_A/0/1/0/all/0/1&quot;&gt;Alexander N. Gorban&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Grechuk_B/0/1/0/all/0/1&quot;&gt;Bogdan Grechuk&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tyukin_I/0/1/0/all/0/1&quot;&gt;Ivan Y. Tyukin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.04127">
<title>A New Algorithmic Decision for Catergorical Syllogisms via Caroll&apos;s Diagrams. (arXiv:1802.04127v2 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1802.04127</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we deal with a calculus system SLCD (Syllogistic Logic with
Carroll Diagrams), which gives a formal approach to logical reasoning with
diagrams, for representations of the fundamental Aristotelian categorical
propositions and show that they are closed under the syllogistic criterion of
inference which is the deletion of middle term. Therefore, it is implemented to
let the formalism comprise synchronically bilateral and trilateral
diagrammatical appearance and a naive algorithmic nature. And also, there is no
need specific knowledge or exclusive ability to understand as well as to use
it. Consequently, we give an effective algorithm used to determine whether a
syllogistic reasoning valid or not by using SLCD.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gursoy_A/0/1/0/all/0/1&quot;&gt;Arif Gursoy&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Senturk_I/0/1/0/all/0/1&quot;&gt;Ibrahim Senturk&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Oner_T/0/1/0/all/0/1&quot;&gt;Tahsin Oner&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06382">
<title>Scalable Alignment Kernels via Space-Efficient Feature Maps. (arXiv:1802.06382v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1802.06382</link>
<description rdf:parseType="Literal">&lt;p&gt;String kernels are attractive data analysis tools for analyzing string data.
Among them, alignment kernels are known for their high prediction accuracies in
string classifications when tested in combination with SVMs in various
applications. However, alignment kernels have a crucial drawback in that they
scale poorly due to their quadratic computation complexity in the number of
input strings, which limits large-scale applications in practice. We present
the first approximation named ESP+SFM for alignment kernels by leveraging a
metric embedding named edit-sensitive parsing (ESP) and space-efficient feature
maps (SFM) for random Fourier features (RFF) for large-scale string analyses.
Input strings are projected into vectors of RFF by leveraging ESP and SFM.
Then, SVMs are trained on the projected vectors, which enables to significantly
improve the scalability of alignment kernels while preserving their prediction
accuracies. We experimentally test ESP+ SFM on its ability to learn SVMs for
large-scale string classifications with various massive string data, and we
demonstrate the superior performance of ESP+SFM with respect to prediction
accuracy, scalability and computation efficiency.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Tabei_Y/0/1/0/all/0/1&quot;&gt;Yasuo Tabei&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yamanishi_Y/0/1/0/all/0/1&quot;&gt;Yoshihiro Yamanishi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Pagh_R/0/1/0/all/0/1&quot;&gt;Rasmus Pagh&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.06604">
<title>Learning High-level Representations from Demonstrations. (arXiv:1802.06604v3 [cs.AI] UPDATED)</title>
<link>http://arxiv.org/abs/1802.06604</link>
<description rdf:parseType="Literal">&lt;p&gt;Hierarchical learning (HL) is key to solving complex sequential decision
problems with long horizons and sparse rewards. It allows learning agents to
break-up large problems into smaller, more manageable subtasks. A common
approach to HL, is to provide the agent with a number of high-level skills that
solve small parts of the overall problem. A major open question, however, is
how to identify a suitable set of reusable skills. We propose a principled
approach that uses human demonstrations to infer a set of subgoals based on
changes in the demonstration dynamics. Using these subgoals, we decompose the
learning problem into an abstract high-level representation and a set of
low-level subtasks. The abstract description captures the overall problem
structure, while subtasks capture desired skills. We demonstrate that we can
jointly optimize over both levels of learning. We show that the resulting
method significantly outperforms previous baselines on two challenging
problems: the Atari 2600 game Montezuma&apos;s Revenge, and a simulated robotics
problem moving the ant robot through a maze.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Andersen_G/0/1/0/all/0/1&quot;&gt;Garrett Andersen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vrancx_P/0/1/0/all/0/1&quot;&gt;Peter Vrancx&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bou_Ammar_H/0/1/0/all/0/1&quot;&gt;Haitham Bou-Ammar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.09129">
<title>Multi-Evidence Filtering and Fusion for Multi-Label Classification, Object Detection and Semantic Segmentation Based on Weakly Supervised Learning. (arXiv:1802.09129v1 [cs.CV] CROSS LISTED)</title>
<link>http://arxiv.org/abs/1802.09129</link>
<description rdf:parseType="Literal">&lt;p&gt;Supervised object detection and semantic segmentation require object or even
pixel level annotations. When there exist image level labels only, it is
challenging for weakly supervised algorithms to achieve accurate predictions.
The accuracy achieved by top weakly supervised algorithms is still
significantly lower than their fully supervised counterparts. In this paper, we
propose a novel weakly supervised curriculum learning pipeline for multi-label
object recognition, detection and semantic segmentation. In this pipeline, we
first obtain intermediate object localization and pixel labeling results for
the training images, and then use such results to train task-specific deep
networks in a fully supervised manner. The entire process consists of four
stages, including object localization in the training images, filtering and
fusing object instances, pixel labeling for the training images, and
task-specific network training. To obtain clean object instances in the
training images, we propose a novel algorithm for filtering, fusing and
classifying object instances collected from multiple solution mechanisms. In
this algorithm, we incorporate both metric learning and density-based
clustering to filter detected object instances. Experiments show that our
weakly supervised pipeline achieves state-of-the-art results in multi-label
image classification as well as weakly supervised object detection and very
competitive results in weakly supervised semantic segmentation on MS-COCO,
PASCAL VOC 2007 and PASCAL VOC 2012.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ge_W/0/1/0/all/0/1&quot;&gt;Weifeng Ge&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yang_S/0/1/0/all/0/1&quot;&gt;Sibei Yang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Yu_Y/0/1/0/all/0/1&quot;&gt;Yizhou Yu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.10168">
<title>ADMM-based Networked Stochastic Variational Inference. (arXiv:1802.10168v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.10168</link>
<description rdf:parseType="Literal">&lt;p&gt;Owing to the recent advances in &quot;Big Data&quot; modeling and prediction tasks,
variational Bayesian estimation has gained popularity due to their ability to
provide exact solutions to approximate posteriors. One key technique for
approximate inference is stochastic variational inference (SVI). SVI poses
variational inference as a stochastic optimization problem and solves it
iteratively using noisy gradient estimates. It aims to handle massive data for
predictive and classification tasks by applying complex Bayesian models that
have observed as well as latent variables. This paper aims to decentralize it
allowing parallel computation, secure learning and robustness benefits. We use
Alternating Direction Method of Multipliers in a top-down setting to develop a
distributed SVI algorithm such that independent learners running inference
algorithms only require sharing the estimated model parameters instead of their
private datasets. Our work extends the distributed SVI-ADMM algorithm that we
first propose, to an ADMM-based networked SVI algorithm in which not only are
the learners working distributively but they share information according to
rules of a graph by which they form a network. This kind of work lies under the
umbrella of `deep learning over networks&apos; and we verify our algorithm for a
topic-modeling problem for corpus of Wikipedia articles. We illustrate the
results on latent Dirichlet allocation (LDA) topic model in large document
classification, compare performance with the centralized algorithm, and use
numerical experiments to corroborate the analytical results.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Anwar_H/0/1/0/all/0/1&quot;&gt;Hamza Anwar&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Zhu_Q/0/1/0/all/0/1&quot;&gt;Quanyan Zhu&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.10238">
<title>DeepSOFA: A Real-Time Continuous Acuity Score Framework using Deep Learning. (arXiv:1802.10238v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.10238</link>
<description rdf:parseType="Literal">&lt;p&gt;Traditional methods for assessing illness severity and predicting in-hospital
mortality among critically ill patients require manual, time-consuming, and
error-prone calculations that are further hindered by the use of static
variable thresholds derived from aggregate patient populations. These coarse
frameworks do not capture time-sensitive individual physiological patterns and
are not suitable for instantaneous assessment of patients&apos; acuity trajectories,
a critical task for the ICU where conditions often change rapidly. Furthermore,
they are ill-suited to capitalize on the emerging availability of streaming
electronic health record data. We propose a novel acuity score framework
(DeepSOFA) that leverages temporal patient measurements in conjunction with
deep learning models to make accurate assessments of a patient&apos;s illness
severity at any point during their ICU stay. We compare DeepSOFA with SOFA
baseline models using the same predictors and find that at any point during an
ICU admission, DeepSOFA yields more accurate predictions of in-hospital
mortality.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Shickel_B/0/1/0/all/0/1&quot;&gt;Benjamin Shickel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Loftus_T/0/1/0/all/0/1&quot;&gt;Tyler J. Loftus&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ozrazgat_Baslanti_T/0/1/0/all/0/1&quot;&gt;Tezcan Ozrazgat-Baslanti&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ebadi_A/0/1/0/all/0/1&quot;&gt;Ashkan Ebadi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Bihorac_A/0/1/0/all/0/1&quot;&gt;Azra Bihorac&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Rashidi_P/0/1/0/all/0/1&quot;&gt;Parisa Rashidi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.10254">
<title>Semi-Analytic Resampling in Lasso. (arXiv:1802.10254v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.10254</link>
<description rdf:parseType="Literal">&lt;p&gt;An approximate method for conducting resampling in Lasso, the $\ell_1$
penalized linear regression, in a semi-analytic manner is developed, whereby
the average over the resampled datasets is directly computed without repeated
numerical sampling, thus enabling an inference free of the statistical
fluctuations due to sampling finiteness, as well as a significant reduction of
computational time. The proposed method is employed to implement bootstrapped
Lasso (Bolasso) and stability selection, both of which are variable selection
methods using resampling in conjunction with Lasso, and it resolves their
disadvantage regarding computational cost. To examine approximation accuracy
and efficiency, numerical experiments were carried out using simulated
datasets. Moreover, an application to a real-world dataset, the wine quality
dataset, is presented. To process such real-world datasets, an objective
criterion for determining the relevance of selected variables is also
introduced by the addition of noise variables and resampling.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Obuchi_T/0/1/0/all/0/1&quot;&gt;Tomoyuki Obuchi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Kabashima_Y/0/1/0/all/0/1&quot;&gt;Yoshiyuki Kabashima&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.10264">
<title>Deep Reinforcement Learning for Vision-Based Robotic Grasping: A Simulated Comparative Evaluation of Off-Policy Methods. (arXiv:1802.10264v1 [cs.RO])</title>
<link>http://arxiv.org/abs/1802.10264</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper, we explore deep reinforcement learning algorithms for
vision-based robotic grasping. Model-free deep reinforcement learning (RL) has
been successfully applied to a range of challenging environments, but the
proliferation of algorithms makes it difficult to discern which particular
approach would be best suited for a rich, diverse task like grasping. To answer
this question, we propose a simulated benchmark for robotic grasping that
emphasizes off-policy learning and generalization to unseen objects. Off-policy
learning enables utilization of grasping data over a wide variety of objects,
and diversity is important to enable the method to generalize to new objects
that were not seen during training. We evaluate the benchmark tasks against a
variety of Q-function estimation methods, a method previously proposed for
robotic grasping with deep neural network models, and a novel approach based on
a combination of Monte Carlo return estimation and an off-policy correction.
Our results indicate that several simple methods provide a surprisingly strong
competitor to popular algorithms such as double Q-learning, and our analysis of
stability sheds light on the relative tradeoffs between the algorithms.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Quillen_D/0/1/0/all/0/1&quot;&gt;Deirdre Quillen&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Jang_E/0/1/0/all/0/1&quot;&gt;Eric Jang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Nachum_O/0/1/0/all/0/1&quot;&gt;Ofir Nachum&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Finn_C/0/1/0/all/0/1&quot;&gt;Chelsea Finn&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ibarz_J/0/1/0/all/0/1&quot;&gt;Julian Ibarz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Levine_S/0/1/0/all/0/1&quot;&gt;Sergey Levine&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.10275">
<title>Solving for high dimensional committor functions using artificial neural networks. (arXiv:1802.10275v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.10275</link>
<description rdf:parseType="Literal">&lt;p&gt;In this note we propose a method based on artificial neural network to study
the transition between states governed by stochastic processes. In particular,
we aim for numerical schemes for the committor function, the central object of
transition path theory, which satisfies a high-dimensional Fokker-Planck
equation. By working with the variational formulation of such partial
differential equation and parameterizing the committor function in terms of a
neural network, approximations can be obtained via optimizing the neural
network weights using stochastic algorithms. The numerical examples show that
moderate accuracy can be achieved for high-dimensional problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Khoo_Y/0/1/0/all/0/1&quot;&gt;Yuehaw Khoo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lu_J/0/1/0/all/0/1&quot;&gt;Jianfeng Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ying_L/0/1/0/all/0/1&quot;&gt;Lexing Ying&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.10311">
<title>Fast Maximum Likelihood estimation via Equilibrium Expectation for Large Network Data. (arXiv:1802.10311v1 [stat.ME])</title>
<link>http://arxiv.org/abs/1802.10311</link>
<description rdf:parseType="Literal">&lt;p&gt;Complex network data may be analyzed by constructing statistical models that
accurately reproduce structural properties that may be of theoretical relevance
or empirical interest. In the context of the efficient fitting of models for
large network data, we propose a very efficient algorithm for the maximum
likelihood estimation (MLE) of the parameters of complex statistical models.
The proposed algorithm is similar to the famous Metropolis algorithm but allows
a Monte Carlo simulation to be performed while constraining the desired network
properties. We demonstrate the algorithm in the context of exponential random
graph models (ERGMs) - a family of statistical models for network data. Thus
far, the lack of efficient computational methods has limited the empirical
scope of ERGMs to relatively small networks with a few thousand nodes. The
proposed approach allows a dramatic increase in the size of networks that may
be analyzed using ERGMs. This is illustrated in an analysis of several
biological networks and one social network with 104,103 nodes.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Byshkin_M/0/1/0/all/0/1&quot;&gt;Maksym Byshkin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Stivala_A/0/1/0/all/0/1&quot;&gt;Alex Stivala&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mira_A/0/1/0/all/0/1&quot;&gt;Antonietta Mira&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lomi_A/0/1/0/all/0/1&quot;&gt;Alessandro Lomi&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.10418">
<title>On the Sublinear Convergence of Randomly Perturbed Alternating Gradient Descent to Second Order Stationary Solutions. (arXiv:1802.10418v1 [math.OC])</title>
<link>http://arxiv.org/abs/1802.10418</link>
<description rdf:parseType="Literal">&lt;p&gt;The alternating gradient descent (AGD) is a simple but popular algorithm
which has been applied to problems in optimization, machine learning, data
ming, and signal processing, etc. The algorithm updates two blocks of variables
in an alternating manner, in which a gradient step is taken on one block, while
keeping the remaining block fixed. When the objective function is nonconvex, it
is well-known the AGD converges to the first-order stationary solution with a
global sublinear rate.
&lt;/p&gt;
&lt;p&gt;In this paper, we show that a variant of AGD-type algorithms will not be
trapped by &quot;bad&quot; stationary solutions such as saddle points and local maximum
points. In particular, we consider a smooth unconstrained optimization problem,
and propose a perturbed AGD (PA-GD) which converges (with high probability) to
the set of second-order stationary solutions (SS2) with a global sublinear
rate. To the best of our knowledge, this is the first alternating type
algorithm which takes $\mathcal{O}(\text{polylog}(d)/\epsilon^{7/3})$
iterations to achieve SS2 with high probability [where polylog$(d)$ is
polynomial of the logarithm of dimension $d$ of the problem].
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Lu_S/0/1/0/all/0/1&quot;&gt;Songtao Lu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Hong_M/0/1/0/all/0/1&quot;&gt;Mingyi Hong&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Wang_Z/0/1/0/all/0/1&quot;&gt;Zhengdao Wang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.10489">
<title>As you like it: Localization via paired comparisons. (arXiv:1802.10489v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.10489</link>
<description rdf:parseType="Literal">&lt;p&gt;Suppose that we wish to estimate a vector $\mathbf{x}$ from a set of binary
paired comparisons of the form &quot;$\mathbf{x}$ is closer to $\mathbf{p}$ than to
$\mathbf{q}$&quot; for various choices of vectors $\mathbf{p}$ and $\mathbf{q}$. The
problem of estimating $\mathbf{x}$ from this type of observation arises in a
variety of contexts, including nonmetric multidimensional scaling, &quot;unfolding,&quot;
and ranking problems, often because it provides a powerful and flexible model
of preference. We describe theoretical bounds for how well we can expect to
estimate $\mathbf{x}$ under a randomized model for $\mathbf{p}$ and
$\mathbf{q}$. We also present results for the case where the comparisons are
noisy and subject to some degree of error. Additionally, we show that under a
randomized model for $\mathbf{p}$ and $\mathbf{q}$, a suitable number of binary
paired comparisons yield a stable embedding of the space of target vectors.
Finally, we also that we can achieve significant gains by adaptively changing
the distribution for choosing $\mathbf{p}$ and $\mathbf{q}$.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Massimino_A/0/1/0/all/0/1&quot;&gt;Andrew K. Massimino&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Davenport_M/0/1/0/all/0/1&quot;&gt;Mark A. Davenport&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.10497">
<title>Learning Discriminative Multilevel Structured Dictionaries for Supervised Image Classification. (arXiv:1802.10497v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.10497</link>
<description rdf:parseType="Literal">&lt;p&gt;Sparse representations using overcomplete dictionaries have proved to be a
powerful tool in many signal processing applications such as denoising,
super-resolution, inpainting, compression or classification. The sparsity of
the representation very much depends on how well the dictionary is adapted to
the data at hand. In this paper, we propose a method for learning structured
multilevel dictionaries with discriminative constraints to make them well
suited for the supervised pixelwise classification of images. A multilevel
tree-structured discriminative dictionary is learnt for each class, with a
learning objective concerning the reconstruction errors of the image patches
around the pixels over each class-representative dictionary. After the initial
assignment of the class labels to image pixels based on their sparse
representations over the learnt dictionaries, the final classification is
achieved by smoothing the label image with a graph cut method and an erosion
method. Applied to a common set of texture images, our supervised
classification method shows competitive results with the state of the art.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Mazaheri_J/0/1/0/all/0/1&quot;&gt;Jeremy Aghaei Mazaheri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Vural_E/0/1/0/all/0/1&quot;&gt;Elif Vural&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Labit_C/0/1/0/all/0/1&quot;&gt;Claude Labit&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Guillemot_C/0/1/0/all/0/1&quot;&gt;Christine Guillemot&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.10501">
<title>Predictive Uncertainty Estimation via Prior Networks. (arXiv:1802.10501v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.10501</link>
<description rdf:parseType="Literal">&lt;p&gt;Estimating uncertainty is important to improving the safety of AI systems.
Recently baseline tasks and metrics have been defined and several practical
methods for estimating uncertainty developed. However, these approaches attempt
to model distributional uncertainty either implicitly through model uncertainty
or as data uncertainty. This work proposes a new framework for modeling
predictive uncertainty called Prior Networks (PNs) which explicitly models
distributional uncertainty. PNs do this by parameterizing a prior distribution
over predictive distributions. This work focuses on uncertainty for
classification and evaluates PNs on the tasks of identifying
out-of-distribution (OOD) samples and detecting misclassification on the MNIST
dataset, where they are found to outperform previous methods. Experiments on
synthetic and MNIST data show that unlike previous methods PNs are able to
distinguish between data and distributional uncertainty.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Malinin_A/0/1/0/all/0/1&quot;&gt;Andrey Malinin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Gales_M/0/1/0/all/0/1&quot;&gt;Mark Gales&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.10510">
<title>Decision functions from supervised machine learning algorithms as collective variables for accelerating molecular simulations. (arXiv:1802.10510v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.10510</link>
<description rdf:parseType="Literal">&lt;p&gt;Selection of appropriate collective variables for enhancing molecular
simulations remains an unsolved problem in computational biophysics. In
particular, picking initial collective variables (CVs) is particularly
challenging in higher dimensions. Which atomic coordinates or transforms there
of from a list of thousands should one pick for enhanced sampling runs? How
does a modeler even begin to pick starting coordinates for investigation? This
remains true even in the case of simple two state systems and only increases in
difficulty for multi-state systems. In this work, we attempt to solve the
initial CV problem using a data-driven approach inspired by supervised machine
learning literature. In particular, we show how the decision functions in
supervised machine learning (SML) algorithms can be used as initial CVs for
accelerated sampling. Using solvated alanine dipeptide and Chignolin
mini-protein as our test cases, we illustrate how the distance to the Support
Vector Machines decision hyperplane, the output probability estimates from
Logistic Regression, and other classifiers may be used to reversibly sample
slow structural transitions. We discuss the utility of other SML algorithms
that might be useful for identifying CVs for accelerating molecular
simulations.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sultan_M/0/1/0/all/0/1&quot;&gt;Mohammad M. Sultan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pande_V/0/1/0/all/0/1&quot;&gt;Vijay S. Pande&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.10515">
<title>Stochastic Dynamic Programming Heuristics for Influence Maximization-Revenue Optimization. (arXiv:1802.10515v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.10515</link>
<description rdf:parseType="Literal">&lt;p&gt;The well-known Influence Maximization (IM) problem has been actively studied
by researchers over the past decade, with emphasis on marketing and social
networks. Existing research have obtained solutions to the IM problem by
obtaining the influence spread and utilizing the property of submodularity.
This paper is based on a novel approach to the IM problem geared towards
optimizing clicks and consequently revenue within anOnline Social Network
(OSN). Our approach diverts from existing approaches by adopting a novel,
decision-making perspective through implementing Stochastic Dynamic Programming
(SDP). Thus, we define a new problem Influence Maximization-Revenue
Optimization (IM-RO) and propose SDP as a method in which this problem can be
solved. The SDP method has lucrative gains for an advertiser in terms of
optimizing clicks and generating revenue however, one drawback to the method is
its associated &quot;curse of dimensionality&quot; particularly for problems involving a
large state space. Thus, we introduce the Lawrence Degree Heuristic (LDH),
Adaptive Hill-Climbing (AHC) and Multistage Particle Swarm Optimization (MPSO)
heuristics as methods which are orders of magnitude faster than the SDP method
whilst achieving near-optimal results. Through a comparative analysis on
various synthetic and real-world networks we present the AHC and LDH as
heuristics well suited to to the IM-RO problem in terms of their accuracy,
running times and scalability under ideal model parameters. In this paper we
present a compelling survey on the SDP method as a practical and lucrative
method for spreading information and optimizing revenue within the context of
OSNs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lawrence_T/0/1/0/all/0/1&quot;&gt;Trisha Lawrence&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.10526">
<title>Application of R\&apos;enyi and Tsallis Entropies to Topic Modeling Optimization. (arXiv:1802.10526v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.10526</link>
<description rdf:parseType="Literal">&lt;p&gt;This is full length article (draft version) where problem number of topics in
Topic Modeling is discussed. We proposed idea that Renyi and Tsallis entropy
can be used for identification of optimal number in large textual collections.
We also report results of numerical experiments of Semantic stability for 4
topic models, which shows that semantic stability play very important role in
problem topic number. The calculation of Renyi and Tsallis entropy based on
thermodynamics approach.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sergei_K/0/1/0/all/0/1&quot;&gt;Koltcov Sergei&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.10529">
<title>Maximum likelihood estimation of a finite mixture of logistic regression models in a continuous data stream. (arXiv:1802.10529v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.10529</link>
<description rdf:parseType="Literal">&lt;p&gt;In marketing we are often confronted with a continuous stream of responses to
marketing messages. Such streaming data provide invaluable information
regarding message effectiveness and segmentation. However, streaming data are
hard to analyze using conventional methods: their high volume and the fact that
they are continuously augmented means that it takes considerable time to
analyze them. We propose a method for estimating a finite mixture of logistic
regression models which can be used to cluster customers based on a continuous
stream of responses. This method, which we coin oFMLR, allows segments to be
identified in data streams or extremely large static datasets. Contrary to
black box algorithms, oFMLR provides model estimates that are directly
interpretable. We first introduce oFMLR, explaining in passing general topics
such as online estimation and the EM algorithm, making this paper a high level
overview of possible methods of dealing with large data streams in marketing
practice. Next, we discuss model convergence, identifiability, and relations to
alternative, Bayesian, methods; we also identify more general issues that arise
from dealing with continuously augmented data sets. Finally, we introduce the
oFMLR [R] package and evaluate the method by numerical simulation and by
analyzing a large customer clickstream dataset.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kaptein_M/0/1/0/all/0/1&quot;&gt;Maurits Kaptein&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Ketelaar_P/0/1/0/all/0/1&quot;&gt;Paul Ketelaar&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.10549">
<title>Automatic topography of high-dimensional data sets by non-parametric Density Peak clustering. (arXiv:1802.10549v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.10549</link>
<description rdf:parseType="Literal">&lt;p&gt;Data analysis in high-dimensional spaces aims at obtaining a synthetic
description of a data set, revealing its main structure and its salient
features. We here introduce an approach for charting data spaces, providing a
topography of the probability distribution from which the data are harvested.
This topography includes information on the number and the height of the
probability peaks, the depth of the &quot;valleys&quot; separating them, the relative
location of the peaks and their hierarchical organization. The topography is
reconstructed by using an unsupervised variant of Density Peak clustering
exploiting a non-parametric density estimator, which automatically measures the
density in the manifold containing the data. Importantly, the density estimator
provides an estimate of the error. This is a key feature, which allows
distinguishing genuine probability peaks from density fluctuations due to
finite sampling.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+dErrico_M/0/1/0/all/0/1&quot;&gt;Maria d&amp;#x27;Errico&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Facco_E/0/1/0/all/0/1&quot;&gt;Elena Facco&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Laio_A/0/1/0/all/0/1&quot;&gt;Alessandro Laio&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rodriguez_A/0/1/0/all/0/1&quot;&gt;Alex Rodriguez&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.10551">
<title>A Variational Inequality Perspective on Generative Adversarial Nets. (arXiv:1802.10551v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.10551</link>
<description rdf:parseType="Literal">&lt;p&gt;Stability has been a recurrent issue in training generative adversarial
networks (GANs). One common way to tackle this issue has been to propose new
formulations of the GAN objective. Yet, surprisingly few studies have looked at
optimization methods specifically designed for this adversarial training. In
this work, we review the &quot;variational inequality&quot; framework which contains most
formulations of the GAN objective introduced so far. Taping into the
mathematical programming literature, we counter some common misconceptions
about the difficulties of saddle point optimization and propose to extend
standard methods designed for variational inequalities to GANs training, such
as a stochastic version of the extragradient method, and empirically
investigate their behavior on GANs.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Gidel_G/0/1/0/all/0/1&quot;&gt;Gauthier Gidel&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Berard_H/0/1/0/all/0/1&quot;&gt;Hugo Berard&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Vincent_P/0/1/0/all/0/1&quot;&gt;Pascal Vincent&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lacoste_Julien_S/0/1/0/all/0/1&quot;&gt;Simon Lacoste-Julien&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.10558">
<title>Exactly Robust Kernel Principal Component Analysis. (arXiv:1802.10558v1 [cs.LG])</title>
<link>http://arxiv.org/abs/1802.10558</link>
<description rdf:parseType="Literal">&lt;p&gt;We propose a novel method called robust kernel principal component analysis
(RKPCA) to decompose a partially corrupted matrix as a sparse matrix plus a
high or full-rank matrix whose columns are drawn from a nonlinear
low-dimensional latent variable model. RKPCA can be applied to many problems
such as noise removal and subspace clustering and is so far the only
unsupervised nonlinear method robust to sparse noises. We also provide
theoretical guarantees for RKPCA. The optimization of RKPCA is challenging
because it involves nonconvex and indifferentiable problems simultaneously. We
propose two nonconvex optimization algorithms for RKPCA: alternating direction
method of multipliers with backtracking line search and proximal linearized
minimization with adaptive step size. Comparative studies on synthetic data and
nature images corroborate the effectiveness and superiority of RKPCA in noise
removal and robust subspace clustering.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Fan_J/0/1/0/all/0/1&quot;&gt;Jicong Fan&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chow_T/0/1/0/all/0/1&quot;&gt;Tommy W.S. Chow&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.10576">
<title>Modeling Activity Tracker Data Using Deep Boltzmann Machines. (arXiv:1802.10576v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.10576</link>
<description rdf:parseType="Literal">&lt;p&gt;Commercial activity trackers are set to become an essential tool in health
research, due to increasing availability in the general population. The
corresponding vast amounts of mostly unlabeled data pose a challenge to
statistical modeling approaches. To investigate the feasibility of deep
learning approaches for unsupervised learning with such data, we examine weekly
usage patterns of Fitbit activity trackers with deep Boltzmann machines (DBMs).
This method is particularly suitable for modeling complex joint distributions
via latent variables. We also chose this specific procedure because it is a
generative approach, i.e., artificial samples can be generated to explore the
learned structure. We describe how the data can be preprocessed to be
compatible with binary DBMs. The results reveal two distinct usage patterns in
which one group frequently uses trackers on Mondays and Tuesdays, whereas the
other uses trackers during the entire week. This exemplary result shows that
DBMs are feasible and can be useful for modeling activity tracker data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Treppner_M/0/1/0/all/0/1&quot;&gt;Martin Treppner&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Lenz_S/0/1/0/all/0/1&quot;&gt;Stefan Lenz&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Binder_H/0/1/0/all/0/1&quot;&gt;Harald Binder&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Zoller_D/0/1/0/all/0/1&quot;&gt;Daniela Z&amp;#xf6;ller&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.10582">
<title>Evaluating Overfit and Underfit in Models of Network Community Structure. (arXiv:1802.10582v1 [stat.ML])</title>
<link>http://arxiv.org/abs/1802.10582</link>
<description rdf:parseType="Literal">&lt;p&gt;A common data mining task on networks is community detection, which seeks an
unsupervised decomposition of a network into structural groups based on
statistical regularities in the network&apos;s connectivity. Although many methods
exist, the No Free Lunch theorem for community detection implies that each
makes some kind of tradeoff, and no algorithm can be optimal on all inputs.
Thus, different algorithms will over or underfit on different inputs, finding
more, fewer, or just different communities than is optimal, and evaluation
methods that use a metadata partition as a ground truth will produce misleading
conclusions about general accuracy. Here, we present a broad evaluation of over
and underfitting in community detection, comparing the behavior of 16
state-of-the-art community detection algorithms on a novel and structurally
diverse corpus of 406 real-world networks. We find that (i) algorithms vary
widely both in the number of communities they find and in their corresponding
composition, given the same input, (ii) algorithms can be clustered into
distinct high-level groups based on similarities of their outputs on real-world
networks, and (iii) these differences induce wide variation in accuracy on link
prediction and link description tasks. We introduce a new diagnostic for
evaluating overfitting and underfitting in practice, and use it to roughly
divide community detection methods into general and specialized learning
algorithms. Across methods and inputs, Bayesian techniques based on the
stochastic block model and a minimum description length approach to
regularization represent the best general learning approach, but can be
outperformed under specific circumstances. These results introduce both a
theoretically principled approach to evaluate over and underfitting in models
of network community structure and a realistic benchmark by which new methods
may be evaluated and compared.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ghasemian_A/0/1/0/all/0/1&quot;&gt;Amir Ghasemian&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hosseinmardi_H/0/1/0/all/0/1&quot;&gt;Homa Hosseinmardi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Clauset_A/0/1/0/all/0/1&quot;&gt;Aaron Clauset&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1603.05729">
<title>Convergence of Contrastive Divergence Algorithm in Exponential Family. (arXiv:1603.05729v3 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1603.05729</link>
<description rdf:parseType="Literal">&lt;p&gt;The Contrastive Divergence (CD) algorithm has achieved notable success in
training energy-based models including Restricted Boltzmann Machines and played
a key role in the emergence of deep learning. The idea of this algorithm is to
approximate the intractable term in the exact gradient of the log-likelihood
function by using short Markov chain Monte Carlo (MCMC) runs. The approximate
gradient is computationally-cheap but biased. Whether and why the CD algorithm
provides an asymptotically consistent estimate are still open questions. This
paper studies the asymptotic properties of the CD algorithm in canonical
exponential families, which are special cases of the energy-based model.
Suppose the CD algorithm runs $m$ MCMC transition steps at each iteration $t$
and iteratively generates a sequence of parameter estimates $\{\theta_t\}_{t
\ge 0}$ given an i.i.d. data sample $\{X_i\}_{i=1}^n \sim p_{\theta_\star}$.
Under conditions which are commonly obeyed by the CD algorithm in practice, we
prove the existence of some bounded $m$ such that any limit point of the time
average $\left. \sum_{s=0}^{t-1} \theta_s \right/ t$ as $t \to \infty$ is a
consistent estimate for the true parameter $\theta_\star$. Our proof is based
on the fact that $\{\theta_t\}_{t \ge 0}$ is a homogenous Markov chain
conditional on the data sample $\{X_i\}_{i=1}^n$. This chain meets the
Foster-Lyapunov drift criterion and converges to a random walk around the
Maximum Likelihood Estimate. The range of the random walk shrinks to zero at
rate $\mathcal{O}(1/\sqrt[3]{n})$ as the sample size $n \to \infty$.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Jiang_B/0/1/0/all/0/1&quot;&gt;Bai Jiang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wu_T/0/1/0/all/0/1&quot;&gt;Tung-Yu Wu&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Jin_Y/0/1/0/all/0/1&quot;&gt;Yifan Jin&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Wong_W/0/1/0/all/0/1&quot;&gt;Wing H. Wong&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1705.10934">
<title>Learning Graphs with Monotone Topology Properties and Multiple Connected Components. (arXiv:1705.10934v4 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1705.10934</link>
<description rdf:parseType="Literal">&lt;p&gt;Recent papers have formulated the problem of learning graphs from data as an
inverse covariance estimation with graph Laplacian constraints. While such
problems are convex, existing methods cannot guarantee that solutions will have
specific graph topology properties (e.g., being $k$-partite), which are
desirable for some applications. In fact, the problem of learning a graph with
given topology properties, e.g., finding the $k$-partite graph that best
matches the data, is in general non-convex. In this paper, we develop novel
theoretical results that provide performance guarantees for an approach to
solve these problems. Our solution decomposes this problem into two
sub-problems, for which efficient solutions are known. Specifically, a graph
topology inference (GTI) step is employed to select a feasible graph topology,
i.e., one having the desired property. Then, a graph weight estimation (GWE)
step is performed by solving a generalized graph Laplacian estimation problem,
where edges are constrained by the topology found in the GTI step. Our main
result is a bound on the error of the GWE step as a function of the error in
the GTI step. This error bound indicates that the GTI step should be solved
using an algorithm that approximates the similarity matrix by another matrix
whose entries have been thresholded to zero to have the desired type of graph
topology. The GTI stage can leverage existing methods (e.g., state of the art
approaches for graph coloring) which are typically based on minimizing the
total weight of removed edges. Since the GWE stage is formulated as an inverse
covariance estimation problem with linear constraints, it can be solved using
existing convex optimization methods. We demonstrate that our two step approach
can achieve good results for both synthetic and texture image data.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pavez_E/0/1/0/all/0/1&quot;&gt;Eduardo Pavez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Egilmez_H/0/1/0/all/0/1&quot;&gt;Hilmi E. Egilmez&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Ortega_A/0/1/0/all/0/1&quot;&gt;Antonio Ortega&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.00210">
<title>Testing for Feature Relevance: The HARVEST Algorithm. (arXiv:1710.00210v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1710.00210</link>
<description rdf:parseType="Literal">&lt;p&gt;Feature selection with high-dimensional data and a very small proportion of
relevant features poses a severe challenge to standard statistical methods. We
have developed a new approach (HARVEST) that is straightforward to apply,
albeit somewhat computer-intensive. This algorithm can be used to pre-screen a
large number of features to identify those that are potentially useful. The
basic idea is to evaluate each feature in the context of many random subsets of
other features. HARVEST is predicated on the assumption that an irrelevant
feature can add no real predictive value, regardless of which other features
are included in the subset. Motivated by this idea, we have derived a simple
statistical test for feature relevance. Empirical analyses and simulations
produced so far indicate that the HARVEST algorithm is highly effective in
predictive analytics, both in science and business.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Weisberg_H/0/1/0/all/0/1&quot;&gt;Herbert Weisberg&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Pontes_V/0/1/0/all/0/1&quot;&gt;Victor Pontes&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Thoma_M/0/1/0/all/0/1&quot;&gt;Mathis Thoma&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.06595">
<title>Variational Inference based on Robust Divergences. (arXiv:1710.06595v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1710.06595</link>
<description rdf:parseType="Literal">&lt;p&gt;Robustness to outliers is a central issue in real-world machine learning
applications. While replacing a model to a heavy-tailed one (e.g., from
Gaussian to Student-t) is a standard approach for robustification, it can only
be applied to simple models. In this paper, based on Zellner&apos;s optimization and
variational formulation of Bayesian inference, we propose an outlier-robust
pseudo-Bayesian variational method by replacing the Kullback-Leibler divergence
used for data fitting to a robust divergence such as the beta- and
gamma-divergences. An advantage of our approach is that superior but complex
models such as deep networks can also be handled. We theoretically prove that,
for deep networks with ReLU activation functions, the \emph{influence function}
in our proposed method is bounded, while it is unbounded in the ordinary
variational inference. This implies that our proposed method is robust to both
of input and output outliers, while the ordinary variational method is not. We
experimentally demonstrate that our robust variational method outperforms
ordinary variational inference in regression and classification with deep
networks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Futami_F/0/1/0/all/0/1&quot;&gt;Futoshi Futami&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sato_I/0/1/0/all/0/1&quot;&gt;Issei Sato&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Sugiyama_M/0/1/0/all/0/1&quot;&gt;Masashi Sugiyama&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.07462">
<title>Tracking the gradients using the Hessian: A new look at variance reducing stochastic methods. (arXiv:1710.07462v2 [math.OC] UPDATED)</title>
<link>http://arxiv.org/abs/1710.07462</link>
<description rdf:parseType="Literal">&lt;p&gt;Our goal is to improve variance reducing stochastic methods through better
control variates. We first propose a modification of SVRG which uses the
Hessian to track gradients over time, rather than to recondition, increasing
the correlation of the control variates and leading to faster theoretical
convergence close to the optimum. We then propose accurate and computationally
efficient approximations to the Hessian, both using a diagonal and a low-rank
matrix. Finally, we demonstrate the effectiveness of our method on a wide range
of problems.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Gower_R/0/1/0/all/0/1&quot;&gt;Robert M. Gower&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Roux_N/0/1/0/all/0/1&quot;&gt;Nicolas Le Roux&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Bach_F/0/1/0/all/0/1&quot;&gt;Francis Bach&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1710.10345">
<title>The Implicit Bias of Gradient Descent on Separable Data. (arXiv:1710.10345v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1710.10345</link>
<description rdf:parseType="Literal">&lt;p&gt;We show that gradient descent on an unregularized logistic regression
problem, for almost all separable datasets, converges to the same direction as
the max-margin solution. The result generalizes also to other monotone
decreasing loss functions with an infimum at infinity, and we also discuss a
multi-class generalizations to the cross entropy loss. Furthermore, we show
this convergence is very slow, and only logarithmic in the convergence of the
loss itself. This can help explain the benefit of continuing to optimize the
logistic or cross-entropy loss even after the training error is zero and the
training loss is extremely small, and, as we show, even if the validation loss
increases. Our methodology can also aid in understanding implicit
regularization in more complex models and with other optimization methods.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Soudry_D/0/1/0/all/0/1&quot;&gt;Daniel Soudry&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Hoffer_E/0/1/0/all/0/1&quot;&gt;Elad Hoffer&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Nacson_M/0/1/0/all/0/1&quot;&gt;Mor Shpigel Nacson&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Srebro_N/0/1/0/all/0/1&quot;&gt;Nathan Srebro&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1712.03607">
<title>Gradient Normalization &amp; Depth Based Decay For Deep Learning. (arXiv:1712.03607v2 [cs.LG] UPDATED)</title>
<link>http://arxiv.org/abs/1712.03607</link>
<description rdf:parseType="Literal">&lt;p&gt;In this paper we introduce a novel method of gradient normalization and decay
with respect to depth. Our method leverages the simple concept of normalizing
all gradients in a deep neural network, and then decaying said gradients with
respect to their depth in the network. Our proposed normalization and decay
techniques can be used in conjunction with most current state of the art
optimizers and are a very simple addition to any network. This method, although
simple, showed improvements in convergence time on state of the art networks
such as DenseNet and ResNet on image classification tasks, as well as on an
LSTM for natural language processing tasks.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Kwiatkowski_R/0/1/0/all/0/1&quot;&gt;Robert Kwiatkowski&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Chang_O/0/1/0/all/0/1&quot;&gt;Oscar Chang&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.03133">
<title>Batch Kalman Normalization: Towards Training Deep Neural Networks with Micro-Batches. (arXiv:1802.03133v2 [cs.CV] UPDATED)</title>
<link>http://arxiv.org/abs/1802.03133</link>
<description rdf:parseType="Literal">&lt;p&gt;As an indispensable component, Batch Normalization (BN) has successfully
improved the training of deep neural networks (DNNs) with mini-batches, by
normalizing the distribution of the internal representation for each hidden
layer. However, the effectiveness of BN would diminish with scenario of
micro-batch (e.g., less than 10 samples in a mini-batch), since the estimated
statistics in a mini-batch are not reliable with insufficient samples. In this
paper, we present a novel normalization method, called Batch Kalman
Normalization (BKN), for improving and accelerating the training of DNNs,
particularly under the context of micro-batches. Specifically, unlike the
existing solutions treating each hidden layer as an isolated system, BKN treats
all the layers in a network as a whole system, and estimates the statistics of
a certain layer by considering the distributions of all its preceding layers,
mimicking the merits of Kalman Filtering. BKN has two appealing properties.
First, it enables more stable training and faster convergence compared to
previous works. Second, training DNNs using BKN performs substantially better
than those using BN and its variants, especially when very small mini-batches
are presented. On the image classification benchmark of ImageNet, using BKN
powered networks we improve upon the best-published model-zoo results: reaching
74.0% top-1 val accuracy for InceptionV2. More importantly, using BKN achieves
the comparable accuracy with extremely smaller batch size, such as 64 times
smaller on CIFAR-10/100 and 8 times smaller on ImageNet.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_G/0/1/0/all/0/1&quot;&gt;Guangrun Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Peng_J/0/1/0/all/0/1&quot;&gt;Jiefeng Peng&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Luo_P/0/1/0/all/0/1&quot;&gt;Ping Luo&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Wang_X/0/1/0/all/0/1&quot;&gt;Xinjiang Wang&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/cs/1/au:+Lin_L/0/1/0/all/0/1&quot;&gt;Liang Lin&lt;/a&gt;</dc:creator>
</item>
<item rdf:about="http://arxiv.org/abs/1802.03151">
<title>Deep Private-Feature Extraction. (arXiv:1802.03151v2 [stat.ML] UPDATED)</title>
<link>http://arxiv.org/abs/1802.03151</link>
<description rdf:parseType="Literal">&lt;p&gt;We present and evaluate Deep Private-Feature Extractor (DPFE), a deep model
which is trained and evaluated based on information theoretic constraints.
Using the selective exchange of information between a user&apos;s device and a
service provider, DPFE enables the user to prevent certain sensitive
information from being shared with a service provider, while allowing them to
extract approved information using their model. We introduce and utilize the
log-rank privacy, a novel measure to assess the effectiveness of DPFE in
removing sensitive information and compare different models based on their
accuracy-privacy tradeoff. We then implement and evaluate the performance of
DPFE on smartphones to understand its complexity, resource demands, and
efficiency tradeoffs. Our results on benchmark image datasets demonstrate that
under moderate resource utilization, DPFE can achieve high accuracy for primary
tasks while preserving the privacy of sensitive features.
&lt;/p&gt;
</description>
<dc:creator> &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Osia_S/0/1/0/all/0/1&quot;&gt;Seyed Ali Osia&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Taheri_A/0/1/0/all/0/1&quot;&gt;Ali Taheri&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Shamsabadi_A/0/1/0/all/0/1&quot;&gt;Ali Shahin Shamsabadi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Katevas_K/0/1/0/all/0/1&quot;&gt;Kleomenis Katevas&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Haddadi_H/0/1/0/all/0/1&quot;&gt;Hamed Haddadi&lt;/a&gt;, &lt;a href=&quot;http://arxiv.org/find/stat/1/au:+Rabiee_H/0/1/0/all/0/1&quot;&gt;Hamid R. Rabiee&lt;/a&gt;</dc:creator>
</item></rdf:RDF>